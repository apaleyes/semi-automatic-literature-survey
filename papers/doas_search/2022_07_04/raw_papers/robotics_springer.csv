contentType,identifier,title,publicationName,doi,publisher,publicationDate,abstract,url,database,query_name,query_value
Chapter ConferencePaper,doi:10.1007/978-981-19-3632-6_24,Path Planning of Indoor Mobile Educational Robot Based on Improved Deep Reinforcement Learning,The 2021 International Conference on Smart Technologies and Systems for Internet of Things,10.1007/978-981-19-3632-6_24,Springer,2023-01-01,"With the maturity of artificial intelligence and Internet of Things technology, the research on robots has also become one of the hotspots of artificial intelligence. Indoor mobile educational robots are an important part of machine intelligence. Research on the path of indoor mobile educational robots has become a key point in machine research. The purpose of this paper is to study the path planning of indoor mobile educational robots to improve deep reinforcement learning. This article first summarizes the research status of mobile educational robots at home and abroad. On this basis, the kinematics model of the indoor mobile educational robot is researched and analyzed. This article systematically elaborates the path planning based on the Actor-Critic algorithm and the deep reinforcement learning training model based on the minimum depth of field information. And use comparative analysis method, observation method and other research methods to carry out experimental research on the theme of this article. Research shows that the Actor-Critic algorithm proposed in this paper is shorter in path planning time and path distance than traditional algorithms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-3632-6_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-0108-9_30,"Evaluating the Role of Robotics, Machine Learning and Artificial Intelligence in the Field of Performance Management",Proceedings of Second International Conference in Mechanical and Energy Technology,10.1007/978-981-19-0108-9_30,Springer,2023-01-01,"Although intelligent automation academic production has evolved fast (e.g., artificial intelligence, robots) we currently lack a full knowledge of the effects on organizational (companies) and individual (workforce) levels of the use of these innovations in performance management (PM). The purpose of this study is to systematize scholarly input on smart automation to date and to elucidate their primary contributions to the performance management difficulties. We found 45 publications on artificial intelligence, robotics as well as other technologically advanced within PM settings in the international business (IB) and general management (GM) and information management (IM) journals. The results demonstrate that smart automation technologies provide a new strategy to managing personnel and improving company performance, providing various performance management opportunities and also major technological and ethical problems. Its influence is based on performance management techniques such as job substitution, work collaboration between human robots and AI, policy-making and apprenticeship possibilities, and performance management activities, namely recruitment, education, and job performance. This paper addresses these changes in-depth and the main contribution to future studies theories and practices.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-0108-9_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-1540-6_11,Neural Network-Based Self-tuning Kinematic Control and Dynamic Compensation for Mobile Robots,Proceedings of 10th International Conference on Mechatronics and Control Engineering,10.1007/978-981-19-1540-6_11,Springer,2023-01-01,"This paper proposes a neural network-based self-tuning kinematic controller and dynamic compensation for tracking trajectories, which applied, e.g., in cases where mobile robots are subject to: continuous parametric changes; different trajectories and external disturbances where online gain tuning is a desirable choice. For this kind of controller, the kinematic and dynamic model was developed considering that the mobile robot is confirmed by differential platform, and the operating point is not located at the center of wheel’s axes. The artificial neural network estimates the states of the mobile robot while the gradient descent optimization algorithm adjusts the controller gains that attain the smaller position tracking error, the dynamic model is used to compensate the velocity errors in the robot. Moreover, the stability of the proposed controller is demonstrated analytically. Finally, simulation results are given considering a Turtlebot3 mobile robot, real-time experiments are implemented in the same mobile robot, where the tests are carried out to show the effectiveness of the controller in a real environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-1540-6_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-0561-2_2,Autonomous Navigation for Mobile Robots with Sensor Fusion Technology,Industry 4.0 and Advanced Manufacturing,10.1007/978-981-19-0561-2_2,Springer,2023-01-01,"Autonomous navigation for a mobile robot is a method used to localize and navigate a robot in a random environment. The existing solution leverages a 2D LiDAR on top of the robot for mapping and obstacle avoidance but the LiDAR at times is unable to detect objects due to their size and color properties. This paper aims to develop a robot that uses both LiDAR and a vision-based sensor as fused sensor technology and to navigate the robot in any direction without any constraints using four-wheel Mecanum drive. The method uses 2D LiDAR as the global sensor for mapping and obstacle avoidance and fusing it with a vision sensor for detecting objects which cannot be detected by LiDAR. The vision sensor uses a deep learning object detection method; YOLOv3. Whenever an object is detected by a neural network the program sends a false laser scan, which is updated in the local cost map of the ROS navigation stack, which makes the robot aware of an object ahead and takes an alternate path to reach the goal position. This robot was tested in a gazebo ROS environment and was able to avoid obstacles irrespective of the size or color of the object. This method was successful in a simulation environment and can be used in industries that need 2D LiDAR as an affordable option and as a replacement for 3D LiDAR.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-0561-2_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-08954-1_1,"Industry 5.0: A Panacea in the Phase of Covid-19 Pandemic Concerning Health, Education, and Banking Sector","Explore Business, Technology Opportunities and Challenges ‎After the Covid-19 Pandemic",10.1007/978-3-031-08954-1_1,Springer,2023-01-01,"The fifth industrial revolution focuses on sustainability with the aid of recent technologies and advanced digital information. Industrial revolution 5.0 develops successful procedures and creates quick enhancement in various industries. Resolutions to challenges modeled by COVID-19 Pandemic can be realized with the placement of Industry 5.0 based on smart technologies. During Covid-19 Pandemic where the world is suffering from a crisis, technological innovation is equipped to march forward with the mission, vision, new values, and principles. In COVID-19 Pandemic, these technologies are offering a remote service structure in various sectors and those who have implemented technology in their respective areas are more likely to recover faster than the others. This study focuses on the health care, education, banking, and aims to bring out the role of industry 5.0 in the selected sectors during the COVID-19 Pandemic. The study also identifies the challenges in realizing industry 5.0, identifies the several supportive structures and services of Industry 5.0 to aid out COVID-19 situation, and brings out a model which represents the stages of evolution for each selected sector and supportive features and facilities of Industry 5.0.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-08954-1_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00167-022-07035-x,Artificial intelligence and robotics in TKA surgery: promising options for improved outcomes?,"Knee Surgery, Sports Traumatology, Arthroscopy",10.1007/s00167-022-07035-x,Springer,2022-08-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00167-022-07035-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-021-02902-5,Data-driven physical law learning model for chaotic robot dynamics prediction,Applied Intelligence,10.1007/s10489-021-02902-5,Springer,2022-08-01,"A robot control system is a multivariable, nonlinear automatic control system, as well as a dynamic coupling system. To address the difficult problem of data prediction under a chaotic system, a data-driven physical law learning model (DPM) is proposed, which can learn the underlying physical rules that the data follow. First, two independent autoencoder neural networks are stacked and merged to explore potential physical rules. Then, a virtual Hamiltonian represented as the sum of kinetic energy and potential energy of chaotic data is introduced. Combined with the Hamiltonian equation, the learned Hamiltonian is transformed into a symplectic transformation, whose first-order differential w.r.t. the generalized coordinates and momentum can be regarded as a time-dependent prediction instead of a direct numerical approximation. Finally, the DPM continuously learns implicit Hamiltonian equations from chaotic data until it can fit the law of phase space motion in a chaotic environment. The experimental results show that the model has a better robot dynamics prediction ability in long-term chaotic systems than the existing SOTA methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-021-02902-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-022-00883-0,Enabling AI and Robotic Coaches for Physical Rehabilitation Therapy: Iterative Design and Evaluation with Therapists and Post-stroke Survivors,International Journal of Social Robotics,10.1007/s12369-022-00883-0,Springer,2022-07-23,"Artificial intelligence (AI) and robotic coaches promise the improved engagement of patients on rehabilitation exercises through social interaction. While previous work explored the potential of automatically monitoring exercises for AI and robotic coaches, the deployment of these systems remains a challenge. Previous work described the lack of involving stakeholders to design such functionalities as one of the major causes. In this paper, we present our efforts on eliciting the detailed design specifications on how AI and robotic coaches could interact with and guide patient’s exercises in an effective and acceptable way with four therapists and five post-stroke survivors. Through iterative questionnaires and interviews, we found that both post-stroke survivors and therapists appreciated the potential benefits of AI and robotic coaches to achieve more systematic management and improve their self-efficacy and motivation on rehabilitation therapy. In addition, our evaluation sheds light on several practical concerns (e.g. a possible difficulty with the interaction for people with cognitive impairment, system failures, etc.). We discuss the value of early involvement of stakeholders and interactive techniques that complement system failures, but also support a personalized therapy session for the better deployment of AI and robotic exercise coaches.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-022-00883-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43154-022-00086-5,Review of Current Robotic Approaches for Precision Weed Management,Current Robotics Reports,10.1007/s43154-022-00086-5,Springer,2022-07-22,"Purpose of Review The goal of this review is to provide an overview of current robotic approaches to precision weed management. This includes an investigation into applications within this field during the past 5 years, identifying which major technical areas currently preclude more widespread use, and which key topics will drive future development and utilisation. Recent Findings Studies combining computer vision with traditional machine learning and deep learning are driving progress in weed detection and robotic approaches to mechanical weeding. Integrating key technologies for perception, decision-making, and control, autonomous weeding robots are emerging quickly. These effectively save effort while reducing environmental pollution caused by pesticide use. Summary This review assesses different weed detection methods and weeder robots used in precision weed management and summarises the trends in this area in recent years. The limitations of current systems are discussed, and ideas for future research directions are proposed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43154-022-00086-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-022-07293-4,Research on path planning algorithm of mobile robot based on reinforcement learning,Soft Computing,10.1007/s00500-022-07293-4,Springer,2022-07-21,"In order to solve the problems of low learning efficiency and slow convergence speed when mobile robot uses reinforcement learning method for path planning in complex environment, a reinforcement learning method based on each round path planning result is proposed. Firstly, the algorithm adds obstacle learning matrix to improve the success rate of path planning; and introduces heuristic reward to speed up the learning process by reducing the search space; then proposes a method of dynamically adjusting the exploration factor to balance the exploration and utilization in path planning, so as to further improve the performance of the algorithm. Finally, the simulation experiment in grid environment shows that compared with Q-learning algorithm, the improved algorithm not only shortens the average path length of the robot to reach the target position, but also speeds up the learning efficiency of the algorithm, so that the robot can find the optimal path more quickly. The code of EPRQL algorithm proposed in this paper has been published to GitHub: https://github.com/panpanpanguoguoqian/mypaper1.git .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-022-07293-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-022-00778-3,Development of a hyper CLS data-based robotic interface for automation of production-line tasks using an articulated robot arm,Artificial Life and Robotics,10.1007/s10015-022-00778-3,Springer,2022-07-18,"Cutter location source (CLS) data, which includes goto statements that define position, orientation, and sequence of a cutting tool, are used to generate the final numerical control (NC) data for performing NC machine tool operations. However, most industrial robots and mechatronic systems cannot work with the standardized CLS data, for example, to handle an end-effector or a camera. Moreover, it is not supported by CLS data to have such an extended function as a visual feedback controller or an AI system like convolutional neural networks (CNNs). In this paper, hyper-cutter location source (HCLS) data and its control interface are proposed for a desktop-sized articulated robot to cope with such extended functions for a complete automation in industrial production lines. HCLS data can include extended numerical commands, e.g., for gripper control, selection of joint or linear interpolation, camera snapshot control, estimation of object’s orientation using AI, and visual feedback control to approach to a target object for picking up. The effectiveness and usefulness of the proposed system are demonstrated through pick-and-place experiments using a small 4-DOFs articulated robot named DOBOT Magician.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-022-00778-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-022-00876-z,Visions of Artificial Intelligence and Robots in Science Fiction: a computational analysis,International Journal of Social Robotics,10.1007/s12369-022-00876-z,Springer,2022-07-18,"Driven by the rapid development of artificial intelligence (AI) and anthropomorphic robotic systems, the various possibilities and risks of such technologies have become a topic of urgent discussion. Although science fiction (SF) works are often cited as references for visions of future developments, this framework of discourse may not be appropriate for serious discussions owing to technical inaccuracies resulting from its reliance on entertainment media. However, these science fiction works could help researchers understand how people might react to new AI and robotic systems. Hence, classifying depictions of artificial intelligence in science fiction may be expected to help researchers to communicate more clearly by identifying science fiction elements to which their works may be similar or dissimilar. In this study, we analyzed depictions of artificial intelligence in SF together with expert critics and writers. First, 115 AI systems described in SF were selected based on three criteria, including diversity of intelligence, social aspects, and extension of human intelligence. Nine elements representing their characteristics were analyzed using clustering and principal component analysis. The results suggest the prevalence of four distinctive categories, including human-like characters, intelligent machines, helpers such as vehicles and equipment, and infrastructure, which may be mapped to a two-dimensional space with axes representing intelligence and humanity. This research contributes to the public relations of AI and robotic technologies by analyzing shared imaginative visions of AI in society based on SF works.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-022-00876-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40747-022-00816-4,Decentralized robust interaction control of modular robot manipulators via harmonic drive compliance model-based human motion intention identification,Complex & Intelligent Systems,10.1007/s40747-022-00816-4,Springer,2022-07-15,"In this paper, a human motion intention estimation-based decentralized robust interaction control method of modular robot manipulators (MRMs) is proposed under the situation of physical human–robot interaction (pHRI). Different from traditional interaction control scheme that depends on the biological signal and centralized control method, the decentralized robust interaction control is implemented that using only position measurements of each joint module in this investigation. Based on the harmonic drive compliance model, a novel torque-sensorless human motion intention estimation method is developed, which utilizes only the information of local dynamic position measurements. On this basis, the decentralized robust interaction control scheme is presented to achieve high performance of position tracking and ensure the security of interaction to create the ’safety’ interaction environment. The uniformly ultimately bounded (UUB) of the tracking error is proved by the Lyapunov theory. Finally, pHRI experiments confirm the effectiveness and advancement of the proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40747-022-00816-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43681-022-00185-1,The case for virtuous robots,AI and Ethics,10.1007/s43681-022-00185-1,Springer,2022-07-14,"Is it possible to build virtuous robots? And is it a good idea? In this paper in machine ethics, I offer a positive answer to both questions. Although moral architectures based on deontology and utilitarianism have been most often considered, I argue that a virtue ethics approach may ultimately be more promising to program artificial moral agents (AMA). The basic idea is that a robot should behave as a virtuous person would (or recommend). Now, with the help of machine learning technology, it is conceivable to get an AMA to learn from moral exemplars. To support my claim, I sketch the steps of building such a virtuous robot, using the thought experiment of programming an autonomous car facing a trolley-like dilemma situation. It appears that, at least in certain contexts, the virtue ethics approach can provide its own and original solution. I then give four reasons to favor it. Not only are virtuous robots technically feasible, but they have the advantage over their deontological and utilitarian counterparts of fostering normative consensus between these moral schools, improving social acceptability, and beginning to address the technical challenge of moral perception.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43681-022-00185-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40998-022-00521-5,Adaptive Robust Variable Impedance Controller for Lower Limb Rehabilitation Robot with Augmented Type-2 Fuzzy System,"Iranian Journal of Science and Technology, Transactions of Electrical Engineering",10.1007/s40998-022-00521-5,Springer,2022-07-14,"In this paper, a new $$H_{\infty }$$ H ∞ robust adaptive neural network control is presented for rehabilitation robotic manipulators. Different sources of modelling error are considered, such as friction forces, external disturbances and parameter variations, besides the effects of human force and weight which are the main source of disturbance in rehabilitation robotics. To handle the interaction problems between the robot and the patient, variable impedance control is utilized as it can achieve a stable position and force control by tracking a target impedance model. The desired impedance model is designed by means of a fuzzy system, using force and position errors. Additionally, to suppress undesired oscillation caused by adaptation laws in transient response phase, an interval type 2 fuzzy system (IT2FS) is utilized as an augmented controller. Ultimate boundedness of the tracking error is proved using the Lyapunov function and LMI technique. Simulation results show that the proposed method provides acceptable performance and robustness with regard to the changes in patients weight and conditions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40998-022-00521-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-020-0788-8,Robot Search Path Planning Method Based on Prioritized Deep Reinforcement Learning,"International Journal of Control, Automation and Systems",10.1007/s12555-020-0788-8,Springer,2022-07-12,"The path planning process of the robot relies too much on environmental information, which makes it difficult to obtain the optimal search path when the search and rescue tasks are carried out in a complex postdisaster environment. Thus, a path planning method based on prioritized deep reinforcement learning is proposed in the paper. The core idea of the method is that the robot first builds an environment mathematical model based on the obtained information through the sensors. Then, to make the robot can obtain the optimal search policy in an extremely complex environment, the prioritized replay mechanism is used to improve deep reinforcement learning. Finally, the simulation results show that the search path planning method based on prioritized deep reinforcement learning proposed can not only improve the convergence speed of the model but also is endowed good robustness in this paper.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-020-0788-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43546-022-00260-z,"Simple efficiency-distribution models of production, with an application to robotics",SN Business & Economics,10.1007/s43546-022-00260-z,Nature,2022-07-12,"The “efficiency-distribution” model introduced by Houthakker in 1955 offers a flexible approach to production theory that does not require the measurement of capital and other fixed assets. Thus it avoids the theoretical problems associated with the Cambridge controversies and with Franklin Fisher’s critiques of aggregation. The efficiency distribution model can be empirically implemented using only observed productivity distributions and the share of output received by the non-fixed factors. Applications include estimating, for a variety of potential distributions, the vulnerability of human wages to the introduction of robotic substitutes.",https://www.nature.com/articles/s43546-022-00260-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1245/s10434-022-12007-z,ASO Author Reflections: Can Artificial Intelligence Evaluate the Surgical Learning Curve of Robot-Assisted Minimally Invasive Esophagectomy?,Annals of Surgical Oncology,10.1245/s10434-022-12007-z,Springer,2022-07-08,,http://link.springer.com/openurl/fulltext?id=doi:10.1245/s10434-022-12007-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-022-00433-7,Tactile object recognition in early phases of grasping using underactuated robotic hands,Intelligent Service Robotics,10.1007/s11370-022-00433-7,Springer,2022-07-08,"Identifying objects during the early phases of robotic grasping in unstructured environments is a crucial step toward successful dexterous robotic manipulation. Underactuated hands are versatile and quickly conform to unknown object surfaces to ensure a firm grasp. The trade-off of using such hands is that extracting information and recognizing objects is challenging due to the uncertainty introduced by the hand’s flexibility and unexpected object movements under manipulation. Combining tactile sensors and machine learning models can provide valuable information about manipulated objects to overcome such drawbacks. The present paper explores tactile object identification under two situations: single grasp, analogous to the haptic glance in humans, and through brief exploratory procedures where a robotic thumb displaces the grasped object to excite the sensors. In both scenarios, a fuzzy controller ensures that data collection occurs under approximately the same conditions in terms of forces and vibrations. Machine learning methods used for the single-grasp and short-exploratory data confirm that the former can improve object recognition.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-022-00433-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-022-03823-7,Rehabilitation robot following motion control algorithm based on human behavior intention,Applied Intelligence,10.1007/s10489-022-03823-7,Springer,2022-07-08,"In response to the current problem of low intelligence of mobile lower limb motor rehabilitation aids. This paper proposes an intelligent control scheme based on human movement behavior in order to control the rehabilitation robot to follow the patient’s movement. Firstly, a multi-sensor data acquisition system is designed according to the rehabilitation needs of the patient and the movement characteristics of the human body. A mathematical model of movement behavior is then established. By analyzing and processing motion data, the change in the center of gravity of the human body and the behavior intention signal are derived and used as a control command for the robot to follow the human body’s movement. Secondly, in order to improve the control effect of rehabilitation robot following human motion, an adaptive radial basis function neural network sliding mode controller (ARBFNNSMC) is designed based on the robot dynamic model. The adaptive adjustment of switching gain coefficient is performed by radial basis function neural network. The controller can overcome the influence caused by the change of robot control system parameters due to the fluctuation of the center of gravity of human body, enhance the adaptability of the system to other disturbance factors, and improve the accuracy of following human body motion. Finally, the motion following experiment of the rehabilitation robot is performed. The experimental results show that the robot can recognize the motion intention of human body and perform the training goal of following different subjects to complete straight lines and curves. The correctness of human motion behavior model and robot control algorithm is verified, which shows the feasibility of the intelligent control method proposed in this paper.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-022-03823-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10551-022-05050-z,The Dawn of the AI Robots: Towards a New Framework of AI Robot Accountability,Journal of Business Ethics,10.1007/s10551-022-05050-z,Springer,2022-07-01,"Business, management, and business ethics literature pay little attention to the topic of AI robots. The broad spectrum of potential ethical issues pertains to using driverless cars, AI robots in care homes, and in the military, such as Lethal Autonomous Weapon Systems. However, there is a scarcity of in-depth theoretical, methodological, or empirical studies that address these ethical issues, for instance, the impact of morality and where accountability resides in AI robots’ use. To address this dearth, this study offers a conceptual framework that interpretively develops the ethical implications of AI robot applications, drawing on descriptive and normative ethical theory. The new framework elaborates on how the locus of morality (human to AI agency) and moral intensity combine within context-specific AI robot applications, and how this might influence accountability thinking. Our theorization indicates that in situations of escalating AI agency and situational moral intensity, accountability is widely dispersed between actors and institutions. ‘Accountability clusters’ are outlined to illustrate interrelationships between the locus of morality, moral intensity, and accountability and how these invoke different categorical responses: (i) illegal, (ii) immoral, (iii) permissible, and (iv) supererogatory pertaining to using AI robots. These enable discussion of the ethical implications of using AI robots, and associated accountability challenges for a constellation of actors—from designer, individual/organizational users to the normative and regulative approaches of industrial/governmental bodies and intergovernmental regimes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10551-022-05050-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00170-022-09374-y,Robot arm grasping using learning-based template matching and self-rotation learning network,The International Journal of Advanced Manufacturing Technology,10.1007/s00170-022-09374-y,Springer,2022-07-01,"Applying deep neural network models to robot-arm grasping tasks requires the laborious and time-consuming annotation of a large number of representative examples in the training process. Accordingly, this work proposes a two-stage grasping model, in which the first stage employs learning-based template matching (LTM) algorithm for estimating the object position, and a self-rotation learning (SRL) network is then proposed to estimate the rotation angle of the grasping objects in the second stage. The LTM algorithm measures similarity between the feature maps of the search and template images which are extracted by a pre-trained model, while the SRL network performs the automatic rotation and labelling of the input data for training purposes. Therefore, the proposed model does not consume an expensive human-annotation process. The experimental results show that the proposed model obtains 92.6% when testing on 2400 pairs of the template and target images. Moreover, in performing practical grasping tasks on a NVidia Jetson TX2 developer kit, the proposed model achieves a higher accuracy (88.5%) than other grasping approaches on a split of Cornell-grasp dataset.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00170-022-09374-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-021-02953-8,Offline reinforcement learning with anderson acceleration for robotic tasks,Applied Intelligence,10.1007/s10489-021-02953-8,Springer,2022-07-01,"Offline reinforcement learning (RL) can learn effective policy from a fixed batch of data without interaction. However, the real-world requirements, such as better performance and high sample efficiency, put substantial challenges on current offline RL algorithms. In this paper, we propose a novel offline RL method, Constrained and Conservative Reinforcement Learning with Anderson Acceleration (CCRL-AA), which aims to enable the agent to effectively and efficiently learn from offline demonstration data. In our method, Constrained and Conservative Reinforcement Learning (CCRL) restricts the policy’s actions with respect to a batch of training data and learns a conservative Q-function to make the agent effectively learn from the previously collected demonstrations. The mechanism of Anderson acceleration (AA) is integrated to speed up the learning process and improve sample efficiency. Experiments were conducted on robotic simulation tasks, and the results demonstrate that our method can efficiently learn from given demonstrations and give better performance than several other state-of-the-art methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-021-02953-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10551-022-05059-4,Sex Robots: Are We Ready for Them? An Exploration of the Psychological Mechanisms Underlying People’s Receptiveness of Sex Robots,Journal of Business Ethics,10.1007/s10551-022-05059-4,Springer,2022-07-01,"Artificial Intelligence (AI)-powered products have started to permeate various spheres of our lives. One of the most controversial of such products is the sex robot, an application of the AI-integrated robotic technology in the domain of human sexual gratification. The aim of this research is to understand the general public’s receptiveness towards this controversial new invention. Drawing upon the social intuitionist model, we find that the fear of AI, emblematic of the broader anxiety of technology’s encroachment on the human sphere, shapes the public’s receptiveness to sex robots. Perceived substitutability of sex robots for human-to-human sexual interactions mediates this relationship. Religiosity is found to moderate this mediated relationship. Our findings are first established with a cross-sectional study. A “big data” field study further validates them. The present research is one of the first empirical studies to examine the underlying psychology of the public’s receptiveness to sex robots. By doing so, we aim to provide relevant government and industry bodies with a better understanding of this important topic for more informed policy making, and to raise awareness of the significant social and ethical implications should sex robots become widely accepted and adopted.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10551-022-05059-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-022-00430-w,Drift compensation of a holonomic mobile robot using recurrent neural networks,Intelligent Service Robotics,10.1007/s11370-022-00430-w,Springer,2022-07-01,"Mecanum wheeled robots can exhibit serious slippage problems because of the discontinuous contact between the wheels and the ground which negatively influences the overall navigation quality. Addressing this problem, the aim of this paper is to demonstrate how a learning-based method can be used for the estimation of the drifting error from multiple sensors with distinct measurement types. Here, a recurrent neural network (RNN)-based drift compensation algorithm is proposed for the estimation of the positioning drift. In order to improve the positioning performance in dead reckoning the estimated drift is used within the real-time control loop for proper modification of the motion trajectory. During the training phase, the data acquired from the acceleration sensors attached to the robot chassis and the encoders of the wheels of the robot are used as the main features to train a gated recurrent unit-based RNN. The drift estimator is trained using the computer-generated reference position data, and the response position data which is measured using an optoelectronic motion tracking device. The performance of the proposed learning-based drift estimation and control algorithm is validated through a series of experiments. The responses obtained from the experiments are graphically illustrated and the improvements in the positioning performances are numerically evaluated. The results obtained from the experiments illustrate the effective performance of the proposed algorithm by considerably decreasing the positioning errors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-022-00430-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-022-04416-4,Emotion recognition models for companion robots,The Journal of Supercomputing,10.1007/s11227-022-04416-4,Springer,2022-07-01,"There has been a steep increase in the use of machine learning for various healthcare applications like the diagnosis of diseases, drug discovery, medical image analysis, etc. Machine learning solutions are proven to be more efficient and less time-consuming than conventional approaches. In this paper, we leverage the advantages of machine learning models to enable a humanoid robot to assist mental health patients. Facial expression and human voice are some of the most demonstrative ways to analyze human emotions, especially for the mentally challenged. We carry out this assistance by constantly monitoring the patient’s voice (or audio) and facial expressions to predict human emotions. To implement the model of audio monitoring, we train three different machine learning and deep learning models to compare and choose the better model. Similarly, for facial recognition, we train a deep learning model using a specific dataset to predict facial expressions from the video captured in real time. We then integrate the better-performing machine learning models into a web interface for demonstration.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11227-022-04416-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-021-03011-z,Generative model based robotic grasp pose prediction with limited dataset,Applied Intelligence,10.1007/s10489-021-03011-z,Springer,2022-07-01,"In the present investigation, we propose an architecture which we name as Generative Inception Neural Network (GI-NNet), capable of predicting antipodal robotic grasps intelligently, on seen as well as unseen objects. It is trained on Cornell Grasping Dataset (CGD) and attains a 98.87% grasp pose accuracy for detecting both regular/irregular shaped objects from RGB-Depth images while requiring only one-third of the network trainable parameters as compared to the existing approaches. However, to attain this level of performance the model requires the entire 90% of the available labelled data of CGD keeping only 10% labelled data for testing which makes it vulnerable to poor generalization. Furthermore, getting a sufficient and quality labelled dataset for robot grasping is extremely difficult. To address these issues, we subsequently propose another architecture where our proposed GI-NNet model is attached as a decoder of a Vector Quantized Variational Auto-Encoder (VQ-VAE), which works more efficiently when trained both with the available labelled and unlabelled data. The proposed model, which we name as Representation based GI-NNet (RGI-NNet) has been trained utilizing the various split of available CGD dataset to test the learning ability of our architecture starting from only 10% label data with the latent embedding of VQ-VAE to 90% label data with the latent embedding. However, being trained with only 50% label data of CGD with latent embedding, the proposed architecture produces the best results which, we believe, is a remarkable accomplishment. The logical reasoning of this together with the other relevant technological details have been elaborated in this paper. The performance level, in terms of grasp pose accuracy of RGI-NNet, varies between 92.1348% to 97.7528% which is far better than several existing models trained with only labelled dataset. For the performance verification of both the proposed models, GI-NNet and RGI-NNet, we have performed rigorous experiments on Anukul (Baxter) hardware cobot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-021-03011-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1245/s10434-022-11996-1,Automated Surgical-Phase Recognition for Robot-Assisted Minimally Invasive Esophagectomy Using Artificial Intelligence,Annals of Surgical Oncology,10.1245/s10434-022-11996-1,Springer,2022-06-28,"Background Although a number of robot-assisted minimally invasive esophagectomy (RAMIE) procedures have been performed due to three-dimensional field of view, image stabilization, and flexible joint function, both the surgeons and surgical teams require proficiency. This study aimed to establish an artificial intelligence (AI)-based automated surgical-phase recognition system for RAMIE by analyzing robotic surgical videos. Methods This study enrolled 31 patients who underwent RAMIE. The videos were annotated into the following nine surgical phases: preparation, lower mediastinal dissection, upper mediastinal dissection, azygos vein division, subcarinal lymph node dissection (LND), right recurrent laryngeal nerve (RLN) LND, left RLN LND, esophageal transection, and post-dissection to completion of surgery to train the AI for automated phase recognition. An additional phase (“no step”) was used to indicate video sequences upon removal of the camera from the thoracic cavity. All the patients were divided into two groups, namely, early period (20 patients) and late period (11 patients), after which the relationship between the surgical-phase duration and the surgical periods was assessed. Results Fourfold cross validation was applied to evaluate the performance of the current model. The AI had an accuracy of 84%. The preparation ( p  = 0.012), post-dissection to completion of surgery ( p  = 0.003), and “no step” ( p  < 0.001) phases predicted by the AI were significantly shorter in the late period than in the early period. Conclusions A highly accurate automated surgical-phase recognition system for RAMIE was established using deep learning. Specific phase durations were significantly associated with the surgical period at the authors’ institution.",http://link.springer.com/openurl/fulltext?id=doi:10.1245/s10434-022-11996-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12204-022-2460-3,Adaptive Human-Robot Collaboration Control Based on Optimal Admittance Parameters,Journal of Shanghai Jiaotong University (Science),10.1007/s12204-022-2460-3,Springer,2022-06-25,"In order to help the operator perform the human-robot collaboration task and optimize the task performance, an adaptive control method based on optimal admittance parameters is proposed. The overall control structure with the inner loop and outer loop is first established. The tasks of the inner loop and outer loop are robot control and task optimization, respectively. An inner-loop robot controller integrated with barrier Lyapunov function and radial basis function neural networks is then proposed, which makes the robot with unknown dynamics securely behave like a prescribed robot admittance model sensed by the operator. Subsequently, the optimal parameters of the robot admittance model are obtained in the outer loop to minimize the task tracking error and interaction force. The optimization problem of the robot admittance model is transformed into a linear quadratic regulator problem by constructing the human-robot collaboration system model. The model includes the unknown dynamics of the operator and the task performance details. To relax the requirement of the system model, the integral reinforcement learning is employed to solve the linear quadratic regulator problem. Besides, an auxiliary force is designed to help the operator complete the specific task better. Compared with the traditional control scheme, the security performance and interaction performance of the human-robot collaboration system are improved. The effectiveness of the proposed method is verified through two numerical simulations. In addition, a practical human-robot collaboration experiment is carried out to demonstrate the performance of the proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12204-022-2460-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11119-022-09929-9,Semi-supervised deep learning and low-cost cameras for the semantic segmentation of natural images in viticulture,Precision Agriculture,10.1007/s11119-022-09929-9,Springer,2022-06-21,"Automatic yield monitoring and in-field robotic harvesting by low-cost cameras require object detection and segmentation solutions to tackle the poor quality of natural images and the lack of exactly-labeled datasets of consistent sizes. This work proposed the application of deep learning for semantic segmentation of natural images acquired by a low-cost RGB-D camera in a commercial vineyard. Several deep architectures were trained and compared on 85 labeled images. Three semi-supervised learning methods (PseudoLabeling, Distillation and Model Distillation) were proposed to take advantage of 320 non-annotated images. In these experiments, the DeepLabV3+ architecture with a ResNext50 backbone, trained with the set of labeled images, achieved the best overall accuracy of 84.78%. In contrast, the Manet architecture combined with the EfficientnetB3 backbone reached the highest accuracy for the bunch class (85.69%). The application of semi-supervised learning methods boosted the segmentation accuracy between 5.62 and 6.01%, on average. Further discussions are presented to show the effects of a fine-grained manual image annotation on the accuracy of the proposed methods and to compare time requirements.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11119-022-09929-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-022-10046-9,Deep introspective SLAM: deep reinforcement learning based approach to avoid tracking failure in visual SLAM,Autonomous Robots,10.1007/s10514-022-10046-9,Springer,2022-06-20,"Reliable and consistent tracking is essential to realize the dream of power-on-and-go autonomy in mobile robots. Our investigation with state-of-the-art visual navigation and mapping tools (e.g. ORB-SLAM) reveals that these tools suffer from frequent and unexpected tracking failures, especially when tested in the wild . This hinders the ability of robots to reach a goal position less than 10 meters away, without tracking failure, thereby limiting the prospects of real autonomy. We present an introspection-based approach (Introspective-SLAM) that enables SLAM to evaluate safety of navigation steps with respect to tracking failure, before the steps are actually taken. Navigation steps that appear unsafe are thereby avoided, and an alternative path to the goal is planned. We propose a novel deep reinforcement learning (DQN) based network to evaluate safety of future navigation steps using a single image only. Surprisingly, training of our DQN completes in a short amount of time (< 60 h). Even then, this network outperforms several handcrafted and Q-learning based pipelines to achieve state-of-the-art performance. Interestingly, training the DQN in realistic simulators (MINOS), consisting of reconstructed interiors, shows good generalization across real world indoor-outdoor settings. Finally, extensive testing of visual SLAM, equipped with our DQN, shows that tracking failures occur frequently and are a major hindrance in reaching the goal. Currently, there is no standard benchmark to evaluate active visual SLAM approaches. We have released a benchmark of 50 episodes with this work. We hope these findings/benchmark will encourage progress for power-on-and-go visual SLAM without any manual supervision.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-022-10046-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s44163-022-00027-3,Systems of collaboration: challenges and solutions for interdisciplinary research in AI and social robotics,Discover Artificial Intelligence,10.1007/s44163-022-00027-3,Springer,2022-06-20,"This article examines the challenges and opportunities that arise when engaging with research across disciplines, contributing to the growth of social robotics and artificially intelligent systems. Artificial intelligence has a significant role to play in human–machine communication; however, there are barriers to its adoption and considerations towards systematic implementation for the good of people and societies. This perspective piece considers the position of artificial intelligence in systems of human–machine communication. The study of artificial intelligent systems is one of discovery, trial, and error through a melting pot of methodologies, and this interdisciplinary nature is explored through the perspective of researchers at the centre of collaboration coming from artificial intelligence, robotics, and communication.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s44163-022-00027-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s13007-022-00911-0,Depth image conversion model based on CycleGAN for growing tomato truss identification,Plant Methods,10.1186/s13007-022-00911-0,BioMed Central,2022-06-17,"Background On tomato plants, the flowering truss is a group or cluster of smaller stems where flowers and fruit develop, while the growing truss is the most extended part of the stem. Because the state of the growing truss reacts sensitively to the surrounding environment, it is essential to control its growth in the early stages. With the recent development of information and artificial intelligence technology in agriculture, a previous study developed a real-time acquisition and evaluation method for images using robots. Furthermore, we used image processing to locate the growing truss to extract growth information. Among the different vision algorithms, the CycleGAN algorithm was used to generate and transform unpaired images using generated learning images. In this study, we developed a robot-based system for simultaneously acquiring RGB and depth images of the growing truss of the tomato plant. Results The segmentation performance for approximately 35 samples was compared via false negative (FN) and false positive (FP) indicators. For the depth camera image, we obtained FN and FP values of 17.55 ± 3.01% and 17.76 ± 3.55%, respectively. For the CycleGAN algorithm, we obtained FN and FP values of 19.24 ± 1.45% and 18.24 ± 1.54%, respectively. When segmentation was performed via image processing through depth image and CycleGAN, the mean intersection over union (mIoU) was 63.56 ± 8.44% and 69.25 ± 4.42%, respectively, indicating that the CycleGAN algorithm can identify the desired growing truss of the tomato plant with high precision. Conclusions The on-site possibility of the image extraction technique using CycleGAN was confirmed when the image scanning robot drove in a straight line through a tomato greenhouse. In the future, the proposed approach is expected to be used in vision technology to scan tomato growth indicators in greenhouses using an unmanned robot platform.",https://www.biomedcentral.com/openurl?doi=10.1186/s13007-022-00911-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43154-022-00079-4,"Resilient Robot Teams: a Review Integrating Decentralised Control, Change-Detection, and Learning",Current Robotics Reports,10.1007/s43154-022-00079-4,Springer,2022-06-13,"Purpose of Review This paper reviews opportunities and challenges for decentralised control, change-detection, and learning in the context of resilient robot teams. Recent Findings Exogenous fault-detection methods can provide a generic detection or a specific diagnosis with a recovery solution. Robot teams can perform active and distributed sensing for detecting changes in the environment, including identifying and tracking dynamic anomalies, as well as collaboratively mapping dynamic environments. Resilient methods for decentralised control have been developed in learning perception-action-communication loops, multi-agent reinforcement learning, embodied evolution, offline evolution with online adaptation, explicit task allocation, and stigmergy in swarm robotics. Summary Remaining challenges for resilient robot teams are integrating change-detection and trial-and-error learning methods, obtaining reliable performance evaluations under constrained evaluation time, improving the safety of resilient robot teams, theoretical results demonstrating rapid adaptation to given environmental perturbations, and designing realistic and compelling case studies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43154-022-00079-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-022-01666-5,Surface Electromyography Signal Recognition Based on Deep Learning for Human-Robot Interaction and Collaboration,Journal of Intelligent & Robotic Systems,10.1007/s10846-022-01666-5,Springer,2022-06-10,"The interaction between humans and collaborative robots in performing given tasks has aroused the interest of researchers and industry for the development of gesture recognition systems. Surface electromyography (sEMG) devices are recommended to capture human hand gestures. However, this kind of technology raises significant challenges. sEMG signals are difficult to acquire and isolate reliably. The creation of a gesture representative model is hard due to the non-explicit nature of sEMG signals. Several solutions have been proposed for the recognition of sEMG-based hand gestures, but none of them are entirely satisfactory. This study contributes to take a step forward in finding the solution to this problem. A sEMG capturing prototype device was used to collect human hand gestures and a two-step algorithm is proposed to recognize five valid gestures, invalid gestures and non-gestures. The former algorithm step (segmentation) is used for sEMG signal isolation to separate signals containing gestures from signals containing non-gestures. The latter step of the algorithm (recognition) is based on a deep learning method, a convolutional neural network (CNN) that identifies which gesture is in the sEMG signals. The performances of the prototype device and recognition architecture were compared successfully with the off-the-shelf sEMG device Myo. Results indicated that the segmentation process played an important role in the success of the gesture recognition system, excluding sEMG signals containing non-gestures. The proposed system was applied successfully in the control loop of a collaborative robotic application, in which the gesture recognition system achieved an online class recognition rate (CR) of 98%, outperforming similar studies in the literature.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-022-01666-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-022-00889-8,Real-Time Social Robot’s Responses to Undesired Interactions Between Children and their Surroundings,International Journal of Social Robotics,10.1007/s12369-022-00889-8,Springer,2022-06-08,"Aggression in children is frequent during the early years of childhood. Among children with psychiatric disorders in general, and autism in particular, challenging behaviours and aggression rates are higher. These can take on different forms, such as hitting, kicking, and throwing objects. Social robots that are able to detect undesirable interactions within its surroundings can be used to target such behaviours. In this study, we evaluate the performance of five machine learning techniques in characterizing five possible undesired interactions between a child and a social robot. We examine the effects of adding different combinations of raw data and extracted features acquired from two sensors on the performance and speed of prediction. Additionally, we evaluate the performance of the best developed model with children. Machine learning algorithms experiments showed that XGBoost achieved the best performance across all metrics (e.g., accuracy of 90%) and provided fast predictions (i.e., 0.004 s) for the test samples. Experiments with features showed that acceleration data were the most contributing factor on the prediction compared to gyroscope data and that combined data of raw and extracted features provided a better overall performance. Testing the best model with data acquired from children performing interactions with toys produced a promising performance for the shake and throw behaviours. The findings of this work can be used by social robot developers to address undesirable interactions in their robotic designs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-022-00889-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41315-022-00243-1,Light-weight behavior-based continuous authentication for personalized mobile robot,International Journal of Intelligent Robotics and Applications,10.1007/s41315-022-00243-1,Springer,2022-06-07,"Personal robots contain a lot of private information about users, causing a high security risk. However, the installation of new biometric sensors tends to be costly, and even if they are installed, many of them authenticate one of the users only once before starting the use of the personal robot. For sensor-less and continuous authentication, behavior-based continuous authentication (BCA) has been proposed, which utilizes a series of user-dependent motion data measured by the personal robot. To distinguish the user behavior, long short-term memory (LSTM), which is excellent in analyzing and predicting time-series data, is often applied, but it is known to be computationally expensive. Since BCA should not interfere with the original tasks of the personal robot, the authors develop a new light-weight model, the so-called recurrent unit with forget gate and memory trace (RGaM), to minimize the computational cost and memory usage of BCA. RGaM has a minimum number of gates and a memory trace approximately derived from a fractional-order leaky integrator model, which suppresses the divergence of stored memories and provides long-term memory. This paper demonstrates the light-weight BCA using RGaM on a force-driven mobile robot optimized for individuals. The results suggested that RGaM, which could be implemented at about half the memory usage of LSTM, successfully achieved a higher level of user authentication than other models. In particular, RGaM achieved a 100% recall on the test dataset, and always succeeded in finding fraudulent users.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-022-00243-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10796-022-10303-3,Correction to: Deep Reinforcement Learning-Based Robot Exploration for Constructing Map of Unknown Environment,Information Systems Frontiers,10.1007/s10796-022-10303-3,Springer,2022-06-06,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10796-022-10303-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40436-022-00400-6,Precision measurement and compensation of kinematic errors for industrial robots using artifact and machine learning,Advances in Manufacturing,10.1007/s40436-022-00400-6,Springer,2022-06-02,"Industrial robots are widely used in various areas owing to their greater degrees of freedom (DOFs) and larger operation space compared with traditional frame movement systems involving sliding and rotational stages. However, the geometrical transfer of joint kinematic errors and the relatively weak rigidity of industrial robots compared with frame movement systems decrease their absolute kinematic accuracy, thereby limiting their further application in ultra-precision manufacturing. This imposes a stringent requirement for improving the absolute kinematic accuracy of industrial robots in terms of the position and orientation of the robot arm end. Current measurement and compensation methods for industrial robots either require expensive measuring systems, producing positioning or orientation errors, or offer low measurement accuracy. Herein, a kinematic calibration method for an industrial robot using an artifact with a hybrid spherical and ellipsoid surface is proposed. A system with submicrometric precision for measuring the position and orientation of the robot arm end is developed using laser displacement sensors. Subsequently, a novel kinematic error compensating method involving both a residual learning algorithm and a neural network is proposed to compensate for nonlinear errors. A six-layer recurrent neural network (RNN) is designed to compensate for the kinematic nonlinear errors of a six-DOF industrial robot. The results validate the feasibility of the proposed method for measuring the kinematic errors of industrial robots, and the compensation method based on the RNN improves the accuracy via parameter fitting. Experimental studies show that the measuring system and compensation method can reduce motion errors by more than 30%. The present study provides a feasible and economic approach for measuring and improving the motion accuracy of an industrial robot at the submicrometric measurement level.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40436-022-00400-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43681-022-00174-4,A probabilistic theory of trust concerning artificial intelligence: can intelligent robots trust humans?,AI and Ethics,10.1007/s43681-022-00174-4,Springer,2022-06-02,"In this paper, I argue for a probabilistic theory of trust, and the plausibility of “trustworthy AI” in which we trust (as opposed to mere reliance). I show that the current trust theories cannot accommodate trust pertaining to AI, and I propose an alternative probabilistic theory, which accounts for the four major types of AI-related trust: an AI agent’s trust in another AI agent, a human agent’s trust in an AI agent, an AI agent’s trust in a human agent, and an AI agent’s trust in an object (including mental and complex objects). I draw a broadly neglected distinction between transitive and intransitive senses of trust, each of which calls for a distinctive semantical theory. Based on this distinction, I classify the current theories into the theories of trust and theories of trustworthiness, showing that the current theories fail to model some of the major types of AI-related trust; while the proposed conditional probabilistic theory of trust and theory of trustworthiness, unlike the current trust theories, is scalable, and they would also accommodate major types of trust in non-AI, including interpersonal trust, reciprocal trust, one-sided trust, as well as trust in objects—e.g., thoughts, theories, data, algorithms, systems, and institutions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43681-022-00174-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-021-04292-4,IoHT-based deep learning controlled robot vehicle for paralyzed patients of smart cities,The Journal of Supercomputing,10.1007/s11227-021-04292-4,Springer,2022-06-01,"Paralysis caused by physical trauma is a common disease today, with approximately 30% of paralysis caused by this trauma. The disease in question both physically restricts mobility and brings along psychological problems. Especially in advanced ages, paralysis becomes much more difficult and requires serious care since it causes many effects in elderly people’s daily routines, required specific healthcare services, costs…etc. Therefore, in this study, it was aimed to design an Internet of Health Things (IoHT)-based unmanned robot vehicle for paralyzed patients, by using deep learning for control of the system and creating a connected healthcare synergy. In this context, the electronic part of the robot was designed first and then a deep learning-based model was created. Before creating the model, the data obtained from the sensors were adequately pre-processed, and the related problem formation was shaped for a Deep Learning process. In order to compare the Deep Learning model with other machine learning techniques from the state of the art, different models based on Random Forest (RF), Decision Trees (DT), Naive Bayes (NB), Support Vector Machines (SVM), k-Nearest Neighbors (k-NN), Logistic Regression (LR) and Artificial Neural Network (ANN) were generated using the same data. The performances of these models were compared and the obtained results were analyzed. According to the experimental results, the Deep Learning model has the highest performance with 99.5% success rate and 0.5% loss rate. This work presents some relevant results in which using deep learning techniques point excellent performances in the area of IoHT applications. A second contribution of this paper is related to the evaluation of the communication flow of the systems, to analyze if it was good enough to cover a smart environment. The findings in this manner were positive in terms of technical analysis and the patient feedback taken from a total of 10 paralyzed patients.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11227-021-04292-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43684-022-00031-5,Fault diagnosis of industrial robot based on dual-module attention convolutional neural network,Autonomous Intelligent Systems,10.1007/s43684-022-00031-5,Springer,2022-06-01,"Fault diagnosis plays a vital role in assessing the health management of industrial robots and improving maintenance schedules. In recent decades, artificial intelligence-based data-driven approaches have made significant progress in machine fault diagnosis using monitoring data. However, current methods pay less attention to correlations and internal differences in monitoring data, resulting in limited diagnostic performance. In this paper, a data-driven method is proposed for the fault diagnosis of industrial robot reducers, that is, a dual-module attention convolutional neural network (DMA-CNN). This method aims to diagnose the fault state of industrial robot reducer. It establishes two parallel convolutional neural networks with two different attentions to capture the different features related to the fault. Finally, the features are fused to obtain the fault diagnosis results (normal or abnormal). The fault diagnosis effect of the DMA-CNN method and other attention models are compared and analyzed. The effectiveness of the method is verified on a dataset of real industrial robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43684-022-00031-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-021-00850-1,Technology Acceptance Model for Lawyer Robots with AI: A Quantitative Survey,International Journal of Social Robotics,10.1007/s12369-021-00850-1,Springer,2022-06-01,"The rapid growth of artificial intelligence (AI) robots has brought new opportunities and challenges. The linkage between AI robots and humans has also gained extensive attention from the legal profession. This study focuses on the extended AI Robot Lawyer Technology Acceptance Model (RLTAM). A total of 385 valid questionnaires are collected through quantitative research, and the relationships among the five variables in the model are reanalyzed and revalidated. Results show that the “legal use” variable in the original extended model is not a direct key variable for consumers to accept AI robot lawyers, but it has a direct effect on “perceived ease of use” and “perceived usefulness” variables. AI robots still need to respond actively to attain legitimacy. AI robot lawyers with national legal certification and good user interface design provide humans a sense of trust. AI robot lawyers based on the development of extended intelligence theory can form a closely coordinated working model with humans. In addition, consumers indicate that the normalized use of AI robots could be a trend in the legal industry in the future, and the types of legal profession that robots can replace will not be affected by gender differences. Practitioners using AI robot lawyers need to establish a complete liability risk control system. This study further optimizes the integrity of RLTAM and provides a reference for developers in designing AI robots in the future.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-021-00850-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-022-10039-8,Motion planning and control for mobile robot navigation using machine learning: a survey,Autonomous Robots,10.1007/s10514-022-10039-8,Springer,2022-06-01,"Moving in complex environments is an essential capability of intelligent mobile robots. Decades of research and engineering have been dedicated to developing sophisticated navigation systems to move mobile robots from one point to another. Despite their overall success, a recently emerging research thrust is devoted to developing machine learning techniques to address the same problem, based in large part on the success of deep learning. However, to date, there has not been much direct comparison between the classical and emerging paradigms to this problem. In this article, we survey recent works that apply machine learning for motion planning and control in mobile robot navigation, within the context of classical navigation systems. The surveyed works are classified into different categories, which delineate the relationship of the learning approaches to classical methods. Based on this classification, we identify common challenges and promising future directions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-022-10039-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43154-022-00073-w,Applications for Augmented and Virtual Reality in Robot-Assisted Spine Surgery,Current Robotics Reports,10.1007/s43154-022-00073-w,Springer,2022-06-01,"Surgical innovation is at an all-time high with technologies such as robotics, advanced image-guidance, augmented reality, virtual reality, and artificial intelligence aiming to shape the future of spine surgery. The aim of this review is to analyze these emerging technologies. Combining these technologies with minimally invasive techniques may serve to further minimize disruption of normal anatomy, blood loss, postoperative pain, narcotic requirements, recovery time, and complications. Specific to spine surgery, these advancements may provide for enhanced accuracy of spinal implant placement, optimized surgical ergonomics, and decreased radiation exposure and further facilitate resident and fellow education. Combining augmented and virtual reality with current image-guidance systems and robotics adds a further layer of data for real-time intraoperative feedback, pre-operative planning, and trainee education. This review discusses the current concepts of augmented and virtual reality and their applications to robot-assisted spine surgery.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43154-022-00073-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11554-022-01212-4,An evaluation of EfficientDet for object detection used for indoor robots assistance navigation,Journal of Real-Time Image Processing,10.1007/s11554-022-01212-4,Springer,2022-06-01,"Indoor object detection and recognition present one of the most crucial tasks for computer vision and robotic systems. Developing new intelligent autonomous robots is required in various applications including blind and visually impaired people assistance navigation and smart healthcare. Intelligent robots navigation is still a very challenging problem as it involves various aspects including indoor objects detection, recognition and scene understanding. We propose in this work to develop an indoor object detection system that can be used for intelligent vision of robotics applications. We ensure in this paper a lightweight implementation of the system using EfficientDet neural network. The proposed work presents a vision-based detection system able to work on real mobile robots by studying and considering their limited resources implementations. To ensure a lightweight implementation of the proposed indoor objects detection system and to design a deployable system in mobile robots application, we applied the weights pruning technique. To contribute for an embedded implementation of the proposed system, we used a pruning method which successfully reduced the network size, complexity and computation resources. Experimental results have demonstrated the robustness of the proposed indoor object detection system that can be deployed for indoor robotics assistance navigation systems. Based on the obtained results, we note that the proposed system achieved very competitive results in terms of detection precision as well as processing time. The proposed system can runs in low-end devices as we succeeded to reduce the parameters and FLOPs number, we achieved 89% on the testing set of the proposed indoor data set for EfficientDet D2. We achieved 31 FPS for the basic EfficientDet model and 38 FPS for the pruned model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11554-022-01212-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41315-022-00236-0,Development of improved coyote optimization with deep neural network for intelligent skill knowledge transfer for human to robot interaction,International Journal of Intelligent Robotics and Applications,10.1007/s41315-022-00236-0,Springer,2022-06-01,"New control approaches are being developed to allow robots to undertake increasingly dynamic and dextrous control tasks. Since these abilities need a large amount of investigation for reinforcement learning (RL), they are frequently acquired by imitation learning from physical demonstration. The cost related to the manual demonstration and its inability to scale has prompted research towards skill generalization, via contextual policies and alternatives. Despite promising outcomes, current research in this area is confined to generalizing across variations of a single ability, like throwing an object to distinct places. Modeling a robot system capable of thinking and learning has progressively been a research priority in the robotics profession. Skill Transfer Learning, or the capacity to transfer human abilities to robots, has recently been a hot topic in autonomous robotics and human–robot collaboration research. The main intention of this paper is to design and implement a novel “Transfer Expert Reinforcement Learning (TERL)” for effective skill knowledge transfer within humans and computers. Here, the modified RL is adopted for the robotic arm movement. The involvement of improved Coyote Optimization Algorithm (COA) called Best, and Worst Fitness-based COA (BWF-COA) is used for tuning the action features of RL. As another contribution, the considered movement of the robot is determined by the deep learning model termed deep neural network with the input kinematic movements. The major aim of the modified RL with BWF-COA is to maximize the reward, thus reducing the error difference within the desired and the predicted movement. When compared to traditional models, the results indicate that the introduced systems can benefit from significant information.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-022-00236-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11628-022-00492-x,The effects of gender and personality of robot assistants on customers’ acceptance of their service,Service Business,10.1007/s11628-022-00492-x,Springer,2022-06-01,"The Covid-19 pandemic has stimulated the use of social robots in front-office services. However, some initial applications yielded disappointing results, as managers were unaware of the level of development of the robots’ artificial intelligence systems. This study proposes to adapt the Almere model to estimate the technological acceptance of service robots, which express their gender and personality, whilst assisting consumers. A 2 × 2 (two genders vs. two personalities) between-subjects experiment was conducted with 219 participants. Model estimation with Structural Equation Modelling confirmed seven out of eight hypotheses, and all four scenarios were estimated with Ordinary Least Squares, showing that robot gender and personality affected their technological acceptance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11628-022-00492-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-020-01114-8,Attribution of autonomy and its role in robotic language acquisition,AI & SOCIETY,10.1007/s00146-020-01114-8,Springer,2022-06-01,"The false attribution of autonomy and related concepts to artificial agents that lack the attributed levels of the respective characteristic is problematic in many ways. In this article, we contrast this view with a positive viewpoint that emphasizes the potential role of such false attributions in the context of robotic language acquisition. By adding emotional displays and congruent body behaviors to a child-like humanoid robot’s behavioral repertoire, we were able to bring naïve human tutors to engage in so called intent interpretations. In developmental psychology, intent interpretations can be hypothesized to play a central role in the acquisition of emotion, volition, and similar autonomy-related words. The aforementioned experiments originally targeted the acquisition of linguistic negation. However, participants produced other affect- and motivation-related words with high frequencies too and, as a consequence, these entered the robot’s active vocabulary. We will analyze participants’ non-negative emotional and volitional speech and contrast it with participants’ speech in a non-affective baseline scenario. Implications of these findings for robotic language acquisition in particular and artificial intelligence and robotics more generally will also be discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-020-01114-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-022-10042-z,A hybrid inductive learning-based and deductive reasoning-based 3-D path planning method in complex environments,Autonomous Robots,10.1007/s10514-022-10042-z,Springer,2022-06-01,"Traditional path planning methods, such as sampling-based and iterative approaches, allow for optimal path’s computation in complex environments. Nonetheless, environment exploration is subject to rules which can be obtained by domain experts and could be used for improving the search. The present work aims at integrating inductive techniques that generate path candidates with deductive techniques that choose the preferred ones. In particular, an inductive learning model is trained with expert demonstrations and with rules translated into a reward function, while logic programming is used to choose the starting point according to some domain expert’s suggestions. We discuss, as use case, 3-D path planning for neurosurgical steerable needles. Results show that the proposed method computes optimal paths in terms of obstacle clearance and kinematic constraints compliance, and is able to outperform state-of-the-art approaches in terms of safety distance-from-obstacles respect, smoothness, and computational time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-022-10042-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10845-021-01743-w,An improved approach of task-parameterized learning from demonstrations for cobots in dynamic manufacturing,Journal of Intelligent Manufacturing,10.1007/s10845-021-01743-w,Springer,2022-06-01,"Task-Parameterized Learning from Demonstrations (TP-LfD) is an intelligent intuitive approach to support collaborative robots (cobots) for various industrial applications. Using TP-LfD, human’s demonstrated paths can be learnt by a cobot for reproducing new paths for the cobot to move along in dynamic situations intelligently. One of the challenges to applying TP-LfD in industrial scenarios is how to identify and optimize critical task parameters of TP-LfD, i.e., frames in demonstrations. To overcome the challenge and enhance the performance of TP-LfD in complex manufacturing applications, in this paper, an improved TP-LfD approach is presented. In the approach, frames in demonstrations are autonomously chosen from a pool of generic visual features. To strengthen computational convergence, a statistical algorithm and a reinforcement learning algorithm are designed to eliminate redundant frames and irrelevant frames respectively. Meanwhile, a B-Spline cut-in algorithm is integrated in the improved TP-LfD approach to enhance the path reproducing process in dynamic manufacturing situations. Case studies were conducted to validate the improved TP-LfD approach and to showcase the advantage of the approach. Owing to the robust and generic capabilities, the improved TP-LfD approach enables teaching a cobot to behavior in a more intuitive and intelligent means to support dynamic manufacturing applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10845-021-01743-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-021-00838-x,Crowd-Comfort Robot Navigation Among Dynamic Environment Based on Social-Stressed Deep Reinforcement Learning,International Journal of Social Robotics,10.1007/s12369-021-00838-x,Springer,2022-06-01,"Robot navigation in a dynamic environment is a challenging task because not only the safety but also the comfort of surrounding pedestrians shall be necessarily considered. This paper proposes the concept of social stress based on tension space of robot and human, which is an important part of Human-Robot interaction. Especially, the proposed approach develops crowd-comfort navigation by combining social stress indexes with a deep reinforcement learning framework and the value network. A set of typical simulation experiments show that our method improves the comfort of surrounding pedestrians effectively during the process of robot navigation. In addition, the fine-tuned technology proposed in this paper has also been proven to be suitable for different scenarios.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-021-00838-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1134/S0005117922060054,Simultaneous Learning and Planning in a Hierarchical Control System for a Cognitive Agent,Automation and Remote Control,10.1134/S0005117922060054,Springer,2022-06-01,"Abstract The tasks of behavior planning and decision-making learning in a dynamic environment are usually divided and considered separately in control systems for intelligent agents. A new unified hierarchical formulation of the problem of simultaneous learning and planning (SLAP) is proposed in the context of object-oriented reinforcement learning, and an architecture of a cognitive agent that solves this problem is described. A new algorithm for learning actions in a partially observed external environment is proposed using a reward signal, an object-oriented subject description of the states of the external environment, and dynamically updated action plans. The main properties and advantages of the proposed algorithm are considered, including the lack of a fixed cognitive cycle necessitating the separation of planning and learning subsystems in earlier algorithms and the ability to construct and update the model of interaction with the environment, thus increasing the learning efficiency. A theoretical justification of some provisions of this approach is given, a model example is proposed, and the principle of operation of a SLAP agent when driving an unmanned vehicle is demonstrated.",http://link.springer.com/openurl/fulltext?id=doi:10.1134/S0005117922060054,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41348-022-00600-z,Digital plant pathology: a foundation and guide to modern agriculture,Journal of Plant Diseases and Protection,10.1007/s41348-022-00600-z,Springer,2022-06-01,"Over the last 20 years, researchers in the field of digital plant pathology have chased the goal to implement sensors, machine learning and new technologies into knowledge-based methods for plant phenotyping and plant protection. However, the application of swiftly developing technologies has posed many challenges. Greenhouse and field applications are complex and differ in their study design requirements. Selecting a sensor type (e.g., thermography or hyperspectral imaging), sensor platform (e.g., rovers, unmanned aerial vehicles, or satellites), and the problem-specific spatial and temporal scale adds to the challenge as all pathosystems are unique and differ in their interactions and symptoms, or lack thereof. Adding host–pathogen–environment interactions across time and space increases the complexity even further. Large data sets are necessary to enable a deeper understanding of these interactions. Therefore, modern machine learning methods are developed to realize the fast data analysis of such complex data sets. This reduces not only human effort but also enables an objective data perusal. Especially deep learning approaches show a high potential to identify probable cohesive parameters during plant-pathogen-environment interactions. Unfortunately, the performance and reliability of developed methods are often doubted by the potential user. Gaining their trust is thus needed for real field applications. Linking biological causes to machine learning features and a clear communication, even for non-experts of such results, is a crucial task that will bridge the gap between theory and praxis of a newly developed application. Therefore, we suggest a global connection of experts and data as the basis for defining a common and goal-oriented research roadmap. Such high interconnectivity will likely increase the chances of swift, successful progress in research and practice. A coordination within international excellence clusters will be useful to reduce redundancy of research while supporting the creation and progress of complementary research. With this review, we would like to discuss past research, achievements, as well as recurring and new challenges. Having such a retrospect available, we will attempt to reveal future challenges and provide a possible direction elevating the next decade of research in digital plant pathology.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41348-022-00600-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12206-022-0507-x,User independent hand motion recognition for robot arm manipulation,Journal of Mechanical Science and Technology,10.1007/s12206-022-0507-x,Springer,2022-06-01,"In the present work, tele-manipulation of robot arm and gripper is experimentally performed using inertia measurement unit (IMU) and electromyogram (EMG)-based human motion recognition. The movement of robot arm and motion of robot gripper is determined based on the measured IMU and EMG data, respectively. To overcome user dependence which is one of main disadvantage of EMG-based motion recognition, reference voluntary contraction method-based normalization of measured EMG data is carried out. Training and test data of EMG are obtained from experiments for four kinds of hand motion of four experimental participants. After extraction of feature vectors, artificial neural network is applied for the EMG-based hand motion recognition. Even when training data and test data are obtained from different participants, it is confirmed that classification accuracy can be greatly improved through the proposed simple normalization method. Finally, a real-time tele-manipulation of 6-degree-of-freedom robot arm is demonstrated successfully by adopting the proposed user independent human motion recognition method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12206-022-0507-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40435-021-00832-1,Adaptive neural sliding mode control for two wheel self balancing robot,International Journal of Dynamics and Control,10.1007/s40435-021-00832-1,Springer,2022-06-01,"This paper presents an adaptive sliding mode controller based on a neural network to a control reference trajectory for a two-wheeled self-balancing robot system (TWSBR). In the proposed control scheme, a three-layer neural network is applied to online estimate the unknown model parameters. In addition, a robust adaptive controller is also used to compensate for the estimating errors and uncertainties of the TWSBR control system. The design of the online updating laws for parameters of the neural network and the uncertainties compensator is derived by using the Lyapunov stability theorem. Therefore, the proposed controller can guarantee stability and robustness in the presence of uncertainties. Based on the simulation and experimental results, we found that the output values of the TWSBR control system follow the desired values near a neighborhood of zero, provided evidences to verify the effectiveness and performance of the proposed controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40435-021-00832-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40747-021-00632-2,Motion intensity modeling and trajectory control of upper limb rehabilitation exoskeleton robot based on multi-modal information,Complex & Intelligent Systems,10.1007/s40747-021-00632-2,Springer,2022-06-01,"The motion intensity of patient is significant for the trajectory control of exoskeleton robot during rehabilitation, as it may have important influence on training effect and human–robot interaction. To design rehabilitation training task according to situation of patients, a novel control method of rehabilitation exoskeleton robot is designed based on motion intensity perception model. The motion signal of robot and the heart rate signal of patient are collected and fused into multi-modal information as the input layer vector of deep learning framework, which is used for the human–robot interaction model of control system. A 6-degree of freedom (DOF) upper limb rehabilitation exoskeleton robot is designed previously to implement the test. The parameters of the model are iteratively optimized by grouping the experimental data, and identification effect of the model is analyzed and compared. The average recognition accuracy of the proposed model can reach up to 99.0% in the training data set and 95.7% in the test data set, respectively. The experimental results show that the proposed motion intensity perception model based on deep neural network (DNN) and the trajectory control method can improve the performance of human–robot interaction, and it is possible to further improve the effect of rehabilitation training.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40747-021-00632-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-022-12464-4,A low-cost UAV for detection of Cercospora leaf spot in okra using deep convolutional neural network,Multimedia Tools and Applications,10.1007/s11042-022-12464-4,Springer,2022-06-01,"Artificial Intelligence (AI)-enabled agricultural robotics is expected to significantly disrupt the domain of agriculture with promise of profitable farming. However, significant challenges exist while deploying such technologies in economically backward countries in a cost-effective manner that can ensure profitability. This study focusses on identification of Cercospora Leaf Spot (CLS) disease in the okra plant, which is also referred to as lady’s finger or Abelmoschus esculentus L. The disease is identified by using deep learning models on images acquired using a modified cost-effective quadcopter fitted with a camera. Two deep learning models, namely SqueezeNet and ResNet-18, were used for this study with a validation accuracy of 99.1% and 99% respectively. Testing of the models with the images collected using the modified quadcopter produced an accuracy of 92.3% and 94.6% respectively. The misclassifications have been analysed using confusion matrices and possible reasons affecting the classification process are discussed. In addition, the learning process has been visualized using feature parameters from different layers with t-SNE algorithm that reduces the dimension of the input parameters. The internal representation of the last feature extraction layer has been assessed using Class Activated Mapping (CAM). Further, the effect of motion blur on disease identification has been analysed using confusion matrix and CAM. For effective disease detection, it is required that the proposed quadcopter system is restricted to operate within certain limits. Finally, an insight on the future directions for improvement has been provided.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11042-022-12464-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40747-021-00364-3,Sliding mode-based online fault compensation control for modular reconfigurable robots through adaptive dynamic programming,Complex & Intelligent Systems,10.1007/s40747-021-00364-3,Springer,2022-06-01,"In this paper, a sliding mode (SM)-based online fault compensation control scheme is investigated for modular reconfigurable robots (MRRs) with actuator failures via adaptive dynamic programming. It consists of a SM-based iterative controller, an adaptive robust term and an online fault compensator. For fault-free MRR systems, the SM surface-based Hamilton–Jacobi–Bellman equation is solved by online policy iteration algorithm. The adaptive robust term is added to guarantee the reachable condition of SM surface. For faulty MRR systems, the actuator failure is compensated online to avoid the fault detection and isolation mechanism. The closed-loop MRR system is guaranteed to be asymptotically stable under the developed fault compensation control scheme. Simulation results verify the effectiveness of the present fault compensation control approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40747-021-00364-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-021-03348-7,New CNN and hybrid CNN-LSTM models for learning object manipulation of humanoid robots from demonstration,Cluster Computing,10.1007/s10586-021-03348-7,Springer,2022-06-01,"As the environments that human live are complex and uncontrolled, the object manipulation with humanoid robots is regarded as one of the most challenging tasks. Learning a manipulation skill from human Demonstration (LfD) is one of the popular methods in the artificial intelligence and robotics community. This paper introduces a deep learning based teleoperation system for humanoid robots that imitate the human operator’s object manipulation behavior. One of the fundamental problems in LfD is to approximate the robot trajectories obtained by means of human demonstrations with high accuracy. The work introduces novel models based on Convolutional Neural Networks (CNNs), CNNs-Long Short-Term Memory (LSTM) models combining the CNN LSTM models, and their scaled variants for object manipulation with humanoid robots by using LfD. In the proposed LfD system, six models are employed to estimate the shoulder roll position of the humanoid robot. The data are first collected in terms of teleoperation of a real Robotis-Op3 humanoid robot and the models are trained. The trajectory estimation is then carried out by the trained CNNs and CNN-LSTM models on the humanoid robot in an autonomous way. All trajectories relating the joint positions are finally generated by the model outputs. The results relating to the six models are compared to each other and the real ones in terms of the training and validation loss, the parameter number, and the training and testing time. Extensive experimental results show that the proposed CNN models are well learned the joint positions and especially the hybrid CNN-LSTM models in the proposed teleoperation system exhibit a more accuracy and stable results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10586-021-03348-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40747-021-00359-0,Compensator-critic structure-based event-triggered decentralized tracking control of modular robot manipulators: theory and experimental verification,Complex & Intelligent Systems,10.1007/s40747-021-00359-0,Springer,2022-06-01,"This paper presents a novel compensator-critic structure-based event-triggered decentralized tracking control of modular robot manipulators (MRMs). On the basis of subsystem dynamics under joint torque feedback (JTF) technique, the proposed tracking error fusion function, which includes position error and velocity error, is utilized to construct performance index function. By analyzing the dynamic uncertainties, a local dynamic information-based robust controller is designed to engage the model uncertainty compensation. Based on adaptive dynamic programming (ADP) algorithm and the event-triggered mechanism, the decentralized tracking control is obtained by solving the event-triggered Hamilton–Jacobi–Bellman equation (HJBE) with the critic neural network (NN). The tracking error of the closed-loop manipulators system is proved to be ultimately uniformly bounded (UUB) using the Lyapunov stability theorem. Finally, experimental results illustrate the effectiveness of the developed control method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40747-021-00359-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00138-022-01306-w,"A comprehensive overview of dynamic visual SLAM and deep learning: concepts, methods and challenges",Machine Vision and Applications,10.1007/s00138-022-01306-w,Springer,2022-05-31,"The visual SLAM (vSLAM) is a research topic that has been developing rapidly in recent years, especially with the renewed interest in machine learning and, more particularly, deep-learning-based approaches. Nowadays, main research is carried out to improve accuracy and robustness in complex and dynamic environments. This scorching topic has reached a significant level of maturity. This paper presents a relatively detailed and easily understood survey of vSLAM within deep learning. This study attempts to meet this challenge by better organizing the literature, explaining the basic concepts and tools, and presenting the current trends. The contributions of this study can be summarized in three essential steps. The first one is to provide the state-of-the-art in an incremental way following the classical processes of vSLAM-based systems. The second is to give our short- and medium-term view of the development of this very active and evolving field. Finally, we share our opinions on this subject and its interactions with new trends and, more particularly, the deep learning paradigm. We believe that this contribution will be an overview and, more importantly, a critical and detailed vision that serves as a roadmap in the field of vSLAMs both in terms of models and concepts and in terms of associated technologies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00138-022-01306-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43684-022-00030-6,An attention enhanced dilated CNN approach for cross-axis industrial robotics fault diagnosis,Autonomous Intelligent Systems,10.1007/s43684-022-00030-6,Springer,2022-05-31,"An industrial robot is a complex mechatronics system, whose failure is hard to diagnose based on monitoring data. Previous studies have reported various methods with deep network models to improve the accuracy of fault diagnosis, which can get an accurate prediction model when the amount of data sample is sufficient. However, the failure data is hard to obtain, which leads to the few-shot issue and the bad generalization ability of the model. Therefore, this paper proposes an attention enhanced dilated convolutional neural network (D-CNN) approach for the cross-axis industrial robotics fault diagnosis method. Firstly, key feature extraction and sliding window are adopted to pre-process the monitoring data of industrial robots before D-CNN is introduced to extract data features. And self-attention is used to enhance feature attention capability. Finally, the pre-trained model is used for transfer learning, and a small number of the dataset from another axis of the multi-axis industrial robot are used for fine-tuning experiments. The experimental results show that the proposed method can reach satisfactory fault diagnosis accuracy in both the source domain and target domain.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43684-022-00030-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s40648-022-00230-y,Fruit recognition method for a harvesting robot with RGB-D cameras,ROBOMECH Journal,10.1186/s40648-022-00230-y,Springer,2022-05-28,"In this study, we present a recognition method for a fruit-harvesting robot to automate the harvesting of pears and apples on joint V-shaped trellis. It is necessary to recognize the three-dimensional position of the harvesting target for harvesting by the fruit-harvesting robot to insert its end-effector. However, the RGB-D (red, green, blue and depth) camera on the harvesting robot has a problem in that the point cloud obtained in outdoor environments can be inaccurate. Therefore, in this study, we propose an effective method for the harvesting robot to recognize fruits using not only three-dimensional information obtained from the RGB-D camera but also two-dimensional images and information from the camera. Furthermore, we report a method for determining the ripeness of pears using the information on fruit detection. Through experiments, we confirmed that the proposed method satisfies the accuracy required for a harvesting robot to continuously harvest fruits.",https://www.biomedcentral.com/openurl?doi=10.1186/s40648-022-00230-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-022-07304-3,Adaptive sliding mode attitude control of two-wheel mobile robot with an integrated learning-based RBFNN approach,Neural Computing and Applications,10.1007/s00521-022-07304-3,Springer,2022-05-17,"To eliminate the adverse effects of nonlinear external disturbances and model uncertainties on the attitude motion stability control of two-wheel mobile robot (TWMR), a novel adaptive sliding mode attitude control scheme is proposed for the TWMR by integrating minimum parameter learning method (MPLM) with radial basis function neural network (RBFNN). Based on the established dynamics model of a practical TWMR, a hyperbolic tangent function-based adaptive sliding mode controller is developed to remove the negative impacts imposed by the nonlinear external disturbances on the TWMR, together restraining the chattering effects caused by the large switching gain in sliding mode control. Next, a type of RBFNN is employed to approximate the model uncertainties of the TWMR system, and MPLM is introduced to replace the RBFNN weights with a single parameter, thereby reducing the fluctuations in attitude tracking and improving the real-time control capability. The stability of the developed controller is analyzed via Lyapunov stability theory. Lastly, a comparative simulation study is conducted to show that the proposed control method has better attitude tracking performance and strong anti-interference robustness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-022-07304-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-022-01477-0,Intelligent service robots for elderly or disabled people and human dignity: legal point of view,AI & SOCIETY,10.1007/s00146-022-01477-0,Springer,2022-05-16,"This article aims to present the problem of the impact of artificial intelligence on respect for human dignity in the sphere of care for people who, for various reasons, are described as particularly vulnerable, especially seniors and people with various disabilities. In recent years, various initiatives and works have been undertaken on the European scene to define the directions in which the development and use of artificial intelligence should go. According to the human-centric approach, artificial intelligence should be developed, used and monitored with people in mind, their needs and rights. It is artificial intelligence that should adapt to the rules set by people, not the other way around. The source of all human rights and freedoms is respect for human dignity. This is evidenced by numerous European, international, national regulations and documents. Respecting this value is also one of the works on the AI development. One of the areas of our life into which AI enters more and more boldly and which in the near future, due to demographic reasons and aging population, may be almost dominated by modern technologies, is the medical and care system. The usefulness of industrial co-robots made us think about the possibility of using similar devices in the non-industrial sphere, including in the sphere of care, nursing and therapy. Actually, despite the impressive development of technology and AI, intelligent robots/devices used for care, nursing or therapy (so-called care/nursing or therapy robots) perform rather simple activities. They provide information, navigate, bring something and give it (e.g. medicines, food), help to get up. They are an important support for medical staff in this respect. Performing tasks that are more complex in terms of technology and movement, such as feeding, washing, intimate hygiene, dressing or undressing, is still beyond the reach of the currently used robots. The question we must ask ourselves is whether, in the future, care robots will be able to perform such tasks, and should they do so? Will this lead to the replacement of human medical personnel in the performance of the above-mentioned activities with such robots. Would anyone want to be ""looked after"" by a soulless machine? Should potential wards/patients, in other words all of us in fact, have the right to object to being taken into the care of an intelligent robot? There is no doubt that intelligent robots have great potential, especially when it comes to ensuring or maintaining the independence or mobility of people with various health limitations. However, we must not forget about the risks and dangers they may generate. Even a simple robot generates serious legal and ethical problems. Who should be liable for damage caused in connection with improper care performed with the participation of a robot? Robots based on AI systems are able to collect a significant amount of sensitive data, for example through the face and speech recognition function. There is considerable scope for abuse in this area, not only in terms of personal data protection but also in terms of informational self-determination, privacy and dignity. Bearing in mind the above risks, the creation of a new right to object to being looked after by a robot should be considered.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-022-01477-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11071-022-07472-w,Neural control of uncertain robot manipulator with fixed-time convergence,Nonlinear Dynamics,10.1007/s11071-022-07472-w,Springer,2022-05-05,"In this paper, an adaptive NN (neural network) control scheme is proposed for uncertain robot systems to achieve fixed-time convergence. With the proposed fixed-time NN controller, the system uncertainty can be handled during the operation and the system can achieve semiglobal stability within fixed-time regardless of the initial conditions. In addition, the boundedness of the NNs weight estimation can be proved theoretically in our work, rather than being assumed as in some recent fixed-time NN control design. Finally, the superior control performance of the proposed scheme is demonstrated based on simulation and experiment study using a Baxter robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11071-022-07472-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41315-022-00235-1,A deep reinforcement learning approach for multi-agent mobile robot patrolling,International Journal of Intelligent Robotics and Applications,10.1007/s41315-022-00235-1,Springer,2022-05-04,"Patrolling strategies primarily deal with minimising the time taken to visit specific locations and cover an area. The use of intelligent agents in patrolling has become beneficial in automation and analysing patterns in patrolling. However, practical scenarios demand these strategies to be adaptive in various conditions and robust against adversaries. Traditional Q-learning based patrolling keeps track of all possible states and actions in a Q-table, making them susceptible to the curse of dimensionality. For multi-agent patrolling to be adaptive in various scenarios represented using graphs, we propose a formulation of the Markov Decision Process (MDP) with state-representations that can be utilised for Deep Reinforcement Learning (DRL) approaches such as Deep Q-Networks (DQN). The implemented DQN can estimate the MDP using a finite length state vector trained with a novel reward function. Proposed state-space representation is independent of the number of nodes in the graph, thereby addressing scalability to graph dimensions. We also propose a reward function to penalise the agents for lack of global coordination while providing immediate local feedback on their actions. As independent policy learners subject to the MDP and reward function, the DRL agents formed a collaborative patrolling strategy. The policies learned by the agents generalise and adapt to multiple behaviours without explicit training or design to do so. We provide empirical analysis that shows the strategy’s adaptive capabilities with changes in agents’ position, non-uniform node visit frequency requirements, changes in a graph structure representing the environment, and induced randomness in the trajectories. DRL patrolling proves to be a promising patrolling strategy for intelligent agents by potentially being scalable, adaptive, and robust against adversaries.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-022-00235-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00779-022-01684-y,What is it like to be a bot? Variable perspective embodied telepresence for crowdsourcing robot movements,Personal and Ubiquitous Computing,10.1007/s00779-022-01684-y,Springer,2022-05-04,"Movement and embodiment are communicative affordances central to social robotics, but designing embodied movements for robots often requires extensive knowledge of both robotics and movement theory. More accessible methods such as learning from demonstration often rely on physical access to the robot which is usually limited to research settings. Machine learning (ML) algorithms can complement hand-crafted or learned movements by generating new behaviors, but this requires large and diverse training datasets, which are hard to come by. In this work, we propose an embodied telepresence system for remotely crowdsourcing emotive robot movement samples that can serve as ML training data. Remote users control the robot through the internet using the motion sensors in their smartphones and view the movement either from a first-person or a third-person perspective. We evaluated the system in an online study where users created emotive movements for the robot and rated their experience. We then utilized the user-crafted movements as inputs to a neural network to generate new movements. We found that users strongly preferred the third-person perspective and that the ML-generated movements are largely comparable to the user-crafted movements. This work supports the usability of telepresence robots as a movement crowdsourcing platform.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00779-022-01684-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12206-022-0436-8,Impedance control method with reinforcement learning for dual-arm robot installing slabstone,Journal of Mechanical Science and Technology,10.1007/s12206-022-0436-8,Springer,2022-05-01,"Slabstone installation task in the construction field is associated with large size, heavy weight, and unstructured environment, making it necessary to solve the position/force control problem when contacting with the wall. In this study, according to the characteristics of dual-arm robots with good flexibility and under heavy load operation, the position/force in the installation process is controlled through impedance with reinforcement learning. In this method, a Gaussian process model is implemented as a dynamic transformation model of the system, and energy loss term is added to cost function. By learning the optimal impedance regulation strategy, a balance could be achieved between error and energy. With reinforcement learning, the input state is changed to the average value over a time period to reduce signal interference and improve data efficiency. The results show that the learning-based variable impedance control method is efficient and can help complete position/force control tasks successfully with only a few interactions, thus significantly reducing the interaction time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12206-022-0436-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-021-04221-5,Research into the application of AI robots in community home leisure interaction,The Journal of Supercomputing,10.1007/s11227-021-04221-5,Springer,2022-05-01,"This paper focuses on comprehensive application of artificial intelligence robots for community-based leisure interaction. We propose a multiple-layer perceptron network to design and implement the intelligent interactive home robot system, which includes establishment of an environment map, autonomous navigation, obstacle-avoidance control and human–machine interaction, to complete the positioning and perception functions required by the robot in the home environment. With this system, community residents use an interactive interface to manipulate robots remotely and create an environmental map. In order for the robot to adapt in this changing environment, the robot needs to have a completely autonomous navigation and obstacle-avoidance-control system. In this study, a long-distance obstacle-avoidance fuzzy system and a short-distance anti-fall obstacle-avoidance fuzzy system were used to enable the robot to accommodate unforeseen changes. This technology proved itself capable of navigating a home environment, ensuring that the robot could instantaneously dodge nearby obstacles and correcting the robot’s path of travel. At the same time, it could prevent the robot from falling off a high dropping point and thereby effectively control the robot’s movement trajectory. After combining the above-mentioned multi-sensor and image recognition functions, the intelligent interactive home robot showed that it clearly has the ability to integrate vision, perception and interaction, and we were able to verify that the robot has the necessary adaptability in changing environments and that the design of such interactive robots can be an asset in the home.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11227-021-04221-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10044-021-01053-0,A visual tool for monitoring and detecting anomalies in robot performance,Pattern Analysis and Applications,10.1007/s10044-021-01053-0,Springer,2022-05-01,"In robotic systems, both software and hardware components are equally important. However, scant attention has been devoted until now in order to detect anomalies/failures affecting the software component of robots while many proposals exist aimed at detecting physical anomalies. To bridge this gap, the present paper focuses on the study of anomalies affecting the software performance of a robot by using a novel visualization tool. Unsupervised visualization methods from the machine learning field are applied in order to upgrade the recently proposed Hybrid Unsupervised Exploratory Plots (HUEPs). Furthermore, Curvilinear Component Analysis and t-distributed stochastic neighbor embedding are added to the original HUEPs formulation and comprehensively compared. Furthermore, all the different combinations of HUEPs are validated in a real-life scenario. Thanks to this intelligent visualization of robot status, interesting conclusions can be obtained to improve anomaly detection in robot performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10044-021-01053-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-022-04314-9,Exploring intelligent image recognition technology of football robot using omnidirectional vision of internet of things,The Journal of Supercomputing,10.1007/s11227-022-04314-9,Springer,2022-05-01,"With the improvement and development of intelligent robot technology, such technology is gradually used to improve the intelligence of national sports fitness. The study aims to explore the intelligent image processing methods based on football robots. First, the moving dynamic image is recognized and processed, and computer vision is proposed to simulate animal vision and collect static and dynamic images of football based on the Internet of Things (IoT). Second, a football robot platform is designed to process the collected graphic dataset. Finally, the feature vector and combination matrix of the image in the dataset are calculated, and the obtained feature matrix is input into AdaBoost to obtain the recognition result of football images. The experimental results show that the system error of the auxiliary recognition technology based on IoT is 0.63, and the detection error rate of the auxiliary recognition technology based on AdaBoost is negatively correlated with the number of features. It is concluded that the more training the samples receive, the smaller the detection error rate of the algorithm is. Compared with similar algorithms, the recognition accuracy of the designed algorithm in different datasets is more than 80.1%, and the recognition result is better than that of similar algorithms. Therefore, the algorithm designed and the results obtained prove the feasibility of the proposed intelligent recognition technology in football image recognition. This study provides a reference for the application of artificial intelligence (AI) in the field of physical fitness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11227-022-04314-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-022-00761-y,Crafting a robotic swarm pursuit–evasion capture strategy using deep reinforcement learning,Artificial Life and Robotics,10.1007/s10015-022-00761-y,Springer,2022-05-01,"In this paper we study the multi-agent pursuit–evasion problem, and present an extension of the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) deep reinforcement learning algorithm. Previous pursuit–evasion advancements with MADDPG have focused on training capture strategies dependent on the restriction of evader movement with environmental features. We demonstrate a method to train pursuer agents to collaboratively surround and encircle an evader for reliable capture without a strategy rooted in environment entrapment (i.e. cornering). Our method utilizes a novel two-stage, variable-aggression, continuous reward function based on geometrical inscribed circles (incircles), along with a corresponding observation space, with agents operating in an entrapment-disadvantaged environment. Our results show reliable capture of an intelligent, superior evader by three trained pursuers in open space with our encircling strategy. A key novelty of our work is demonstrating the ability to transition behaviors learned using deep reinforcement learning from a simulated robotic system with imperfect world assumptions to a real-world robotic agents.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-022-00761-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-022-03219-7,Hierarchical dynamic movement primitive for the smooth movement of robots based on deep reinforcement learning,Applied Intelligence,10.1007/s10489-022-03219-7,Springer,2022-04-29,"Although deep reinforcement learning (DRL) algorithms with experience replay have been used to solve many sequential learning problems, applications of DRL in real-world robotics still face some serious challenges, such as the problem of smooth movement. A robot’s motion trajectory needs to be smoothly coded, with no sudden acceleration or jerk. In this paper, a novel hierarchical reinforcement learning control framework named the hierarchical dynamic movement primitive (HDMP) framework is proposed to achieve the smooth movement of robots. In contrast to traditional algorithms, the HDMP framework consists of two learning hierarchies: a lower-level controller learning hierarchy and an upper-level policy learning hierarchy. In the lower-level controller learning hierarchy, modified dynamic movement primitives (DMPs) are utilized to generate a smooth motion trajectory. In the upper-level policy learning hierarchy, an improved local proximal policy optimization (L-PPO) method is proposed to endow the robot with autonomous learning capabilities. The performance achieved with the HDMP algorithm has been evaluated in a classical reaching movement task based on a Sawyer robot. The experimental results demonstrate that the proposed HDMP algorithm can endow a robot with the ability to smoothly execute motor skills and learn autonomously.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-022-03219-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43684-022-00025-3,Machine learning techniques for robotic and autonomous inspection of mechanical systems and civil infrastructure,Autonomous Intelligent Systems,10.1007/s43684-022-00025-3,Springer,2022-04-29,"Machine learning and in particular deep learning techniques have demonstrated the most efficacy in training, learning, analyzing, and modelling large complex structured and unstructured datasets. These techniques have recently been commonly deployed in different industries to support robotic and autonomous system (RAS) requirements and applications ranging from planning and navigation to machine vision and robot manipulation in complex environments. This paper reviews the state-of-the-art with regard to RAS technologies (including unmanned marine robot systems, unmanned ground robot systems, climbing and crawler robots, unmanned aerial vehicles, and space robot systems) and their application for the inspection and monitoring of mechanical systems and civil infrastructure. We explore various types of data provided by such systems and the analytical techniques being adopted to process and analyze these data. This paper provides a brief overview of machine learning and deep learning techniques, and more importantly, a classification of the literature which have reported the deployment of such techniques for RAS-based inspection and monitoring of utility pipelines, wind turbines, aircrafts, power lines, pressure vessels, bridges, etc. Our research provides documented information on the use of advanced data-driven technologies in the analysis of critical assets and examines the main challenges to the applications of such technologies in the industry.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43684-022-00025-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-022-01619-y,Deep Reinforcement Learning for Humanoid Robot Behaviors,Journal of Intelligent & Robotic Systems,10.1007/s10846-022-01619-y,Springer,2022-04-27,"RoboCup 3D Soccer Simulation is a robot soccer competition based on a high-fidelity simulator with autonomous humanoid agents, making it an interesting testbed for robotics and artificial intelligence. Due to the recent success of Deep Reinforcement Learning (DRL) in continuous control tasks, many teams have been using this technique to develop motions in Soccer 3D. This article focuses on learning humanoid robot behaviors: completing a racing track as fast as possible and dribbling against a single opponent. Our approach uses a hierarchical controller where a model-free policy learns to interact model-based walking algorithm. Then, we use DRL algorithms for an agent to learn how to perform these behaviors. Finally, the learned dribble policy was evaluated in the Soccer 3D environment. Simulated experiments show that the DRL agent wins against the hand-coded behavior used by the ITAndroids robotics team in 68.2% of dribble attempts.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-022-01619-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/s41524-022-00765-z,"Accelerating materials discovery using artificial intelligence, high performance computing and robotics",npj Computational Materials,10.1038/s41524-022-00765-z,Nature,2022-04-26,"New tools enable new ways of working, and materials science is no exception. In materials discovery, traditional manual, serial, and human-intensive work is being augmented by automated, parallel, and iterative processes driven by Artificial Intelligence (AI), simulation and experimental automation. In this perspective, we describe how these new capabilities enable the acceleration and enrichment of each stage of the discovery cycle. We show, using the example of the development of a novel chemically amplified photoresist, how these technologies’ impacts are amplified when they are used in concert with each other as powerful, heterogeneous workflows.",https://www.nature.com/articles/s41524-022-00765-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-022-07273-7,Efficient deep learning-based semantic mapping approach using monocular vision for resource-limited mobile robots,Neural Computing and Applications,10.1007/s00521-022-07273-7,Springer,2022-04-25,"Semantic mapping is still challenging for household collaborative robots. Deep learning models have proved their capability to extract semantics from the scene and learn robot odometry. For interfacing semantic information with robot odometry, existing approaches extract both semantics and robot odometry separately and then integrate them using fusion techniques. Such approaches face many issues while integration, and the mapping procedure requires a lot of memory and resources to process the information. In an attempt to produce accurate semantic mapping with resource-limited devices, this paper proposes an efficient deep learning-based model to simultaneously estimate robot odometry by using monocular sequence frames and detecting objects in the frames. The proposed model includes two main components: using a YOLOv3 object detector as a backbone and a convolutional long short-term (Conv-LSTM) recurrent neural network to model the changes in camera pose. The unique advantage of the proposed model is that it boycotts the need for data association and the requirement of multi-sensor fusion. We conducted the experiments on a LoCoBot robot in a laboratory environment, attaining satisfactory results with such limited computational resources. Additionally, we tested the proposed method on the Kitti dataset, reaching an average test loss of 15.93 on various sequences. The experiments are documented in this video https://www.youtube.com/watch?v=hnmqwxpaTEw .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-022-07273-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-022-12794-3,"Optimized, robust, real-time emotion prediction for human-robot interactions using deep learning",Multimedia Tools and Applications,10.1007/s11042-022-12794-3,Springer,2022-04-23,"To enable humanoid robots to share the social space,development in technology is required for natural interaction with the robots using multiple modes of communication such as speech, gestures, and share emotions with them. This research is targeted towards addressing the core issue of emotion recognition problem, which would require fewer computation resources and a much lesser number of network parameters, which will be more adaptive to compute on social robots for real-time communication. Any robots will have limited computation capability for run time actions and decisions. In the present investigation, Inception based Convolution Neural Network(CNN) Architecture is proposed to improve the emotion prediction. The proposed model has achieved improved accuracy of up to 6% improvement over the existing network architecture for emotion classification. The model was tested over seven different datasets to verify its robustness. In addition, real-time implementation capability is verified on humanoid robot NAO, which depicts its social behavior in real-time. The proposed model is reducing the trainable parameters to the extent of 94% as compared to vanilla CNN model, which indicates that its implementation ability in a real-time based application such as human-robot interaction. Rigorous experiments have been performed to validate the methodology, which is sufficiently robust and could achieve a high level of accuracy. Seven datasets are used to build a robust model. Finally, the model is integrated in a humanoid robot, NAO, in real-time. When averaged over all the emotions, the reduction in response time by 60% and 61% and improvement in prediction rate by 42% and 21% when compared in real-time environment with Vanilla CNN and state of the art model respectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11042-022-12794-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-022-01603-6,"Continual Learning for Real-World Autonomous Systems: Algorithms, Challenges and Frameworks",Journal of Intelligent & Robotic Systems,10.1007/s10846-022-01603-6,Springer,2022-04-23,"Continual learning is essential for all real-world applications, as frozen pre-trained models cannot effectively deal with non-stationary data distributions. The purpose of this study is to review the state-of-the-art methods that allow continuous learning of computational models over time. We primarily focus on the learning algorithms that perform continuous learning in an online fashion from considerably large (or infinite) sequential data and require substantially low computational and memory resources. We critically analyze the key challenges associated with continual learning for autonomous real-world systems and compare current methods in terms of computations, memory, and network/model complexity. We also briefly describe the implementations of continuous learning algorithms under three main autonomous systems, i.e., self-driving vehicles, unmanned aerial vehicles, and urban robots. The learning methods of these autonomous systems and their strengths and limitations are extensively explored in this article.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-022-01603-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13347-022-00533-3,Two Steps Forward: An African Relational Account of Moral Standing,Philosophy & Technology,10.1007/s13347-022-00533-3,Springer,2022-04-13,"This paper replies to a commentary by John-Stewart Gordon on our paper, “The Moral Standing of Social Robots: Untapped Insights from Africa.” In the original paper, we set forth an African relational view of personhood and show its implications for the moral standing of social robots. This reply clarifies our position and answers three objections. The objections concern (1) the ethical significance of intelligence, (2) the meaning of ‘pro-social,' and (3) the justification for prioritizing humans over pro-social robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13347-022-00533-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-022-04478-4,Enhancing gas detection-based swarming through deep reinforcement learning,The Journal of Supercomputing,10.1007/s11227-022-04478-4,Springer,2022-04-09,"Swarm-Intelligence (SI), the collective behavior of decentralized and self-organized system, is used to efficiently carry out practical missions in various environments. To guarantee the performance of swarm, it is highly important that each object operates as an individual system while the devices are organized as simple as possible. This paper proposes an efficient, scalable, and practical swarming system using gas detection device. Each object of the proposed system has multiple sensors and detects gas in real time. To let the objects move toward gas rich spot, we propose two approaches for system design, vector-sum based, and Reinforcement Learning (RL) based. We firstly introduce our deterministic vector-sum-based approach and address the RL-based approach to extend the applicability and flexibility of the system. Through system performance evaluation, we validated that each object with a simple device configuration performs its mission perfectly in various environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11227-022-04478-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13347-022-00531-5,The Moral Standing of Social Robots: Untapped Insights from Africa,Philosophy & Technology,10.1007/s13347-022-00531-5,Springer,2022-04-09,"This paper presents an African relational view of social robots’ moral standing which draws on the philosophy of ubuntu (humanness). The introduction (Section 1 ) places the question of moral standing in historical and cultural contexts. Section  2 demonstrates an ubuntu framework by applying it to the fictional case of a social robot named Klara, taken from Ishiguro’s novel, Klara and the Sun . We argue that an ubuntu ethic assigns moral standing to Klara, based on her relational qualities and pro-social virtues. Section  3 introduces a second fictional case, taken from McKeown’s novel, Machines Like Me , in which a social robot named Adam displays intrinsic qualities, such as sentience, rationality, and deductive moral reasoning, yet lacks close social ties to particular people. We argue that Adam is not a person in the African sense; however, he qualifies as a person according to many standard Western views, such as Kantian and utilitarian ethics. Section  4 further elaborates the African relational view by comparing the moral standing of social robots and humans in a forced choice scenario. Section  5 replies to objections. We conclude that an African relational approach captures important insights about the moral standing of social robots that many Western accounts miss and should be better incorporated into global frameworks for designing and deploying social robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13347-022-00531-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40313-021-00829-3,A New Mechanism for Collision Detection in Human–Robot Collaboration using Deep Learning Techniques,"Journal of Control, Automation and Electrical Systems",10.1007/s40313-021-00829-3,Springer,2022-04-01,"Human–robot collaboration is increasingly present not only in research environments, but also in industry and many contemporary day-to-day activities. There is a need for the automation of tasks ranging from the simplest to the most complex ones. The insertion of robotic arms provides a considerable step useful in achieving this goal. In this context, safety remains a concern, however. Among the most frequent issue in this collaboration context is human–robot collision. While focus has been on automation efficiency of the of the activities, there is a growing need to reduce or even prevent damage to the involved agents. As part of this goal, a new mechanism for detecting human–robot collisions is proposed in this article. It has been tested in a well-controlled scenario using equipment commonly present in collaborative scenarios for maintenance on a radio base station. The robot used is a UR5 robotic arm in addition to three 2D cameras and a network rack. In our experimental scenario, a person interacts with the network devices installed within the rack while conducting basic collaborative activities inserted in this context. For collision detection, deep learning models were used and evaluated. These were trained to detect overlap between humans and robots considering the view and perspectives from three different cameras. Finally, a new ensemble learning system is proposed in order to establish whether or not a collision took place. It receives as input the result of overlap detection through deep learning models. Results suggest that the proposed system is capable of detecting collisions with an average global accuracy of 89.81% of correctness in a well-controlled scenario. The effectiveness of the proposed ensemble is exposed in comparison with the use of only one of the cameras for decision-making. Finally, the proposed system is shown to detect collisions in real time and to achieve a low response time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40313-021-00829-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-020-02157-6,Creating a robot localization monitor using particle filter and machine learning approaches,Applied Intelligence,10.1007/s10489-020-02157-6,Springer,2022-04-01,"Robot localization is a fundamental capability of all mobile robots. Because of uncertainties in acting and sensing, and environmental factors such as people flocking around robots, there is always the risk that a robot loses its localization. Very often behaviors of robots rely on a reliable position estimation. Thus, for dependability of robot systems it is of great interest for the system to know the state of its localization component. In this paper we present an approach that allows a robot to asses if the localization is still correct. The approach assumes that the underlying localization approach is based on a particle filter. We use deep learning to identify temporal patterns in the particles in the case of losing/lost localization. These patterns are then combined with weak classifiers from the particle set and sensor perception for boosted learning of a localization estimator. Through the extraction of features generated by neural networks and its usage for training strong classifiers, the robots localization accuracy can be estimated. The approach is evaluated in a simulated transport robot environment where a degraded localization is provoked by disturbances cased by dynamic obstacles. Results show that it is possible to monitor the robots localization accuracy using convolutional as well as recurrent neural networks. The additional boosting using Adaboost also yields an increase in training accuracy. Thus, this paper directly contributes to the verification of localization performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-020-02157-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-022-01429-8,Ethical aspects of AI robots for agri-food; a relational approach based on four case studies,AI & SOCIETY,10.1007/s00146-022-01429-8,Springer,2022-04-01,"These last years, the development of AI robots for agriculture, livestock farming and food processing industries is rapidly increasing. These robots are expected to help produce and deliver food more efficiently for a growing human population, but they also raise societal and ethical questions. As the type of questions raised by these AI robots in society have been rarely empirically explored, we engaged in four case studies focussing on four types of AI robots for agri-food ‘in the making’: manure collectors, weeding robots, harvesting robots and food processing robots which select and package fruits, vegetables and meats. Based on qualitative interviews with 33 experts engaged in the development or implementation of these four types of robots, this article provides a broad and varied exploration of the values that play a role in their evaluation and the ethical questions that they raise. Compared to the recently published literature reviews mapping the ethical questions related to AI robots in agri-food, we conclude that stakeholders in our case studies primarily adopt a relational perspective to the value of AI robots and to finding a solution to the ethical questions. Building on our findings we suggest it is best to seek a distribution of tasks between human beings and robots in agri-food, which helps to realize the most acceptable, good or just collaboration between them in food production or processing that contributes to realizing societal goals and help to respond to the 21 century challenges.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-022-01429-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42438-021-00242-8,Review of Cathrine Hasse (2020). Posthumanist Learning: What Robots and Cyborgs Teach us About Being Ultra-social,Postdigital Science and Education,10.1007/s42438-021-00242-8,Springer,2022-04-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42438-021-00242-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-021-04160-1,Kinematic and dynamic control model of wheeled mobile robot under internet of things and neural network,The Journal of Supercomputing,10.1007/s11227-021-04160-1,Springer,2022-04-01,"This study aims to solve the issues of nonlinearity, non-integrity constraints, under-actuated systems in mobile robots. The wheeled robot is selected as the research object, and a kinematic and dynamic control model based on Internet of Things (IoT) and neural network is proposed. With the help of IoT sensors, the proposed model can realize effective control of the mobile robot under the premise of ensuring safety using the model tracking scheme and the radial basis function adaptive control algorithm. The results show that the robot can be controlled effectively to break the speed and acceleration constraints using the strategy based on the model predictive control, thus realizing smooth movement under the premise of safety. The self-adapting algorithm based on the IoT and neural network shows notable advantages in parameter uncertainty and roller skidding well. The proposed model algorithm shows a fast convergence rate of about 2 s, which has effectively improved performances in trajectory tracking and robustness of the wheeled mobile robot, and can solve the difficulties of wheeled mobile robots in practical applications, showing reliable reference value for algorithm research in this field.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11227-021-04160-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11119-021-09856-1,Field evaluations of a deep learning-based intelligent spraying robot with flow control for pear orchards,Precision Agriculture,10.1007/s11119-021-09856-1,Springer,2022-04-01,"This study proposes a deep learning-based real-time variable flow control system using the segmentation of fruit trees in a pear orchard. The real-time flow rate control, undesired pressure fluctuation and theoretical modeling may differ from those in the real world. Therefore, two types of preliminary experiments were conducted to examine the linear relationship of the flow rate modeling. Through preliminary experiments, the parameters of the pulse width modulation (PWM) controller were optimized, and a field experiment was conducted to confirm the performance of the variable flow rate control system. The field test was conducted for three cases: all open, on/off control, and variable flow rate control, showing results of 56.15 ( $$\pm 17.24$$ ± 17.24 )%, 68.95 ( $$\pm 21.12)$$ ± 21.12 ) % and 57.33 ( $$\pm 21.73$$ ± 21.73 )% for each control. The result revealed that the proposed system performed satisfactorily, showing that pesticide use and the risk of pesticide exposure could be reduced.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11119-021-09856-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13347-022-00519-1,Tragic Choices and the Virtue of Techno-Responsibility Gaps,Philosophy & Technology,10.1007/s13347-022-00519-1,Springer,2022-03-30,"There is a concern that the widespread deployment of autonomous machines will open up a number of ‘responsibility gaps’ throughout society. Various articulations of such techno-responsibility gaps have been proposed over the years, along with several potential solutions. Most of these solutions focus on ‘plugging’ or ‘dissolving’ the gaps. This paper offers an alternative perspective. It argues that techno-responsibility gaps are, sometimes, to be welcomed and that one of the advantages of autonomous machines is that they enable us to embrace certain kinds of responsibility gap. The argument is based on the idea that human morality is often tragic. We frequently confront situations in which competing moral considerations pull in different directions and it is impossible to perfectly balance these considerations. This heightens the burden of responsibility associated with our choices. We cope with the tragedy of moral choice in different ways. Sometimes we delude ourselves into thinking the choices we make were not tragic (illusionism); sometimes we delegate the tragic choice to others (delegation); sometimes we make the choice ourselves and bear the psychological consequences (responsibilisation). Each of these strategies has its benefits and costs. One potential advantage of autonomous machines is that they enable a reduced cost form of delegation. However, we only gain the advantage of this reduced cost if we accept that some techno-responsibility gaps are virtuous.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13347-022-00519-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-022-01584-6,Experimental Verification of the Differential Games and H_∞ Theory in Tracking Control of a Wheeled Mobile Robot,Journal of Intelligent & Robotic Systems,10.1007/s10846-022-01584-6,Springer,2022-03-26,"This paper presents an experimental verification understood as an extension of the existing solutions for the application of the differential games theory in real-time control of a nonholonomic, nonlinear dynamic system, on the example of a wheeled robot. Based on the dissipative systems theory, the solution to the problem of weakening the impact of disturbances and changing working conditions of a mobile robot was obtained using the H _∞ (L_2 gain) control theory. The neural solution of the Hamilton-Jacobi-Isaac equation in the actor-critic structure was applied. Both simulation and experiment result showed very good quality in the wheeled robot tracking control problem taking into account the changing working conditions and other disturbance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-022-01584-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01553-5,Two-Legged Robot Motion Control With Recurrent Neural Networks,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01553-5,Springer,2022-03-18,"Legged locomotion is a desirable ability for robotic systems thanks to its agile mobility and wide range of motions that it provides. In this paper, the use of neural network-based nonlinear controller structures which consist of recurrent and feedforward layers have been examined in the dynamically stable walking problem of two-legged robots. In detail, hybrid neural controllers, in which long short-term memory type of neuron models employed at recurrent layers, are utilized in the feedback and feedforward paths. To train these neural networks, supervised learning data sets are created by using a biped robot platform which is controlled by a central pattern generator. Then, the ability of the neural networks to perform stable gait by controlling the robot platform is examined under various ground conditions in the simulation environment. After that, the stable walking generation capacity of the neural networks and the central pattern generators are compared with each other. It is shown that the inclusion of recurrent layer provides smooth transition and control between stance and flight motion phases and L 2 $$L_2$$ regularization is beneficial for walking performance. Finally, the proposed hybrid neural network models are found to be more successful gait controllers than the central pattern generator, which is employed to generate data sets used in training.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01553-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-022-03191-2,Robot navigation in a crowd by integrating deep reinforcement learning and online planning,Applied Intelligence,10.1007/s10489-022-03191-2,Springer,2022-03-17,"Navigating mobile robots along time-efficient and collision-free paths in crowds is still an open and challenging problem. The key is to build a profound understanding of the crowd for mobile robots, which is the basis of a proactive and foresighted policy. However, since the interaction mechanisms among pedestrians are complex and sophisticated, it is difficult to describe and model them accurately. For the excellent approximation capability of deep neural networks, deep reinforcement learning is a promising solution to the problem. However, current model-free learning-based approaches in crowd navigation always neglect planning and still lead to reactive collision avoidance policies and shortsighted behaviors. Meanwhile, most model-based learning-based approaches are based on state values, imposing a substantial computational burden. To address these problems, we propose a graph-based deep reinforcement learning method, social graph-based double dueling deep Q-network (SG-D3QN), that (i) introduces a social attention mechanism to extract an efficient graph representation for the crowd-robot state, (ii) extends the previous state value approximator to a state-action value approximator, (iii) further optimizes the state-action value approximator with simulated experiences generated by the learned environment model, and (iv) then proposes a human-like decision-making process by integrating model-free reinforcement learning and online planning. Experimental results indicate that our approach helps the robot understand the crowd and achieves a high success rate of more than 0.99 in the crowd navigation task. Compared with previous state-of-the-art algorithms, our approach achieves better performance. Furthermore, with the human-like decision-making process, our approach incurs less than half of the computational cost.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-022-03191-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00779-022-01674-0,Robot intelligent communication based on deep learning and TRIZ ergonomics for personalized healthcare,Personal and Ubiquitous Computing,10.1007/s00779-022-01674-0,Springer,2022-03-11,"With the rapid development and maturity of modern industrial technology, intelligent robot has become an increasingly essential part of our people’s work and life. As an important symbol of technological innovation ability and manufacturing level, robot has become an important field of scientific research, and more experts have invested in the research of robot. At present, the more mature robot is industrial robot, which has been successfully applied in actual industrial production, while the more humanized intelligent robot is still in the research stage of the laboratory. According to different application directions, intelligent robots can be divided into pipeline robots, underwater operation robots, flight robots, ground robots, and so on. The pipeline robot can be used to detect the damage and corrosion of the pipeline in the process of use and can clean, weld, and paint the pipeline in harsh environment. Underwater robots can be used in marine water quality research, offshore oil exploration, marine mineral exploration, submarine salvage, etc. Flying robots are mainly used in satellite communication, road condition monitoring, geological exploration, aerial photography, weather forecast, news broadcast, traffic navigation, etc. It is with a variety of intelligent robots for human services, which makes human science and technology more advanced, work and life more convenient. Therefore, it is very important to study the intelligent robot more deeply. In this paper, inventive problem solving theory is integrated into the product ergonomics design, and a product ergonomic design process model based on pattern recognition and TRIZ is constructed. We considered different intelligent robot forms and analyzed them form different perspectives. To validate the overall performance, the systematic experiment is conducted.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00779-022-01674-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10278-022-00616-9,Lightweight Deep Neural Network for Articulated Joint Detection of Surgical Instrument in Minimally Invasive Surgical Robot,Journal of Digital Imaging,10.1007/s10278-022-00616-9,Springer,2022-03-09,"Vision-based detection and tracking of surgical instrument are attractive because it relies purely on surgical instrument already in the operating scenario. The vision knowledge of the surgical instruments is a crucial piece of topic for surgical task understanding, autonomous robot control and human–robot collaborative surgeries to enhance surgical outcomes. In this work, a novel method has been demonstrated by developing a multitask lightweight deep neural network framework to explore surgical instrument articulated joint detection. The model has an end-to-end architecture with two branches, which share the same high-level visual features provided by a lightweight backbone while holding respective layers targeting for specific tasks. We have designed a novel subnetwork with joint detection branch and an instrument classification branch to sufficiently take advantage of the relatedness of surgical instrument presence detection and surgical instrument articulated joint detection tasks. The lightweight joint detection branch has been employed to efficiently locate the articulated joint position with simultaneously holding low computational cost. Moreover, the surgical instrument classification branch is introduced to boost the performance of joint detection. The two branches are merged to output the articulated joint location with respective instrument type. Extensive validation has been conducted to evaluate the proposed method. The results demonstrate promising performance of our proposed method. The work represents the feasibility to perform real-time surgical instrument articulated joint detection by taking advantage of the components of surgical robot system, contributing to the reference for further surgical intelligence.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10278-022-00616-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11747-021-00832-9,AI increases unethical consumer behavior due to reduced anticipatory guilt,Journal of the Academy of Marketing Science,10.1007/s11747-021-00832-9,Springer,2022-03-02,"The current research focuses on examining how the use of artificial intelligence and robotic technology, emerging non-human agent innovations in service industries, influences consumers’ likelihood of engaging in unethical behavior. Previous research has shown that non-human (vs. human) agents are perceived differently along many dimensions by consumers (e.g., that they lack emotional capability), leading to various behavioral changes when interacting with them. We hypothesize and show across four studies that interacting with non-human (vs. human) agents, such as AI and robots, increases the tendency to engage in unethical consumer behaviors due to reduced anticipatory feelings of guilt. We also demonstrate the moderating role of anthropomorphism such that endowing humanlike features on non-human agents reduces unethical behavior. We also rule out alternative explanations for the effect, including differential perceptions about the agents (e.g., “warmth,” “competence,” or “detection capacity”) and other measures associated with the company capabilities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11747-021-00832-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11747-021-00832-9,AI increases unethical consumer behavior due to reduced anticipatory guilt,Journal of the Academy of Marketing Science,10.1007/s11747-021-00832-9,Springer,2022-03-02,"The current research focuses on examining how the use of artificial intelligence and robotic technology, emerging non-human agent innovations in service industries, influences consumers’ likelihood of engaging in unethical behavior. Previous research has shown that non-human (vs. human) agents are perceived differently along many dimensions by consumers (e.g., that they lack emotional capability), leading to various behavioral changes when interacting with them. We hypothesize and show across four studies that interacting with non-human (vs. human) agents, such as AI and robots, increases the tendency to engage in unethical consumer behaviors due to reduced anticipatory feelings of guilt. We also demonstrate the moderating role of anthropomorphism such that endowing humanlike features on non-human agents reduces unethical behavior. We also rule out alternative explanations for the effect, including differential perceptions about the agents (e.g., “warmth,” “competence,” or “detection capacity”) and other measures associated with the company capabilities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11747-021-00832-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10506-021-09289-1,"Symbiosis with artificial intelligence via the prism of law, robots, and society",Artificial Intelligence and Law,10.1007/s10506-021-09289-1,Springer,2022-03-01,"The rapid advances in Artificial Intelligence and Robotics will have a profound impact on society as they will interfere with the people and their interactions. Intelligent autonomous robots, independent if they are humanoid/anthropomorphic or not, will have a physical presence, make autonomous decisions, and interact with all stakeholders in the society, in yet unforeseen manners. The symbiosis with such sophisticated robots may lead to a fundamental civilizational shift, with far-reaching effects as philosophical, legal, and societal questions on consciousness, citizenship, rights, and legal entity of robots are raised. The aim of this work is to understand the broad scope of potential issues pertaining to law and society through the investigation of the interplay of law, robots, and society via different angles such as law, social, economic, gender, and ethical perspectives. The results make it evident that in an era of symbiosis with intelligent autonomous robots, the law systems, as well as society, are not prepared for their prevalence. Therefore, it is now the time to start a multi-disciplinary stakeholder discussion and derive the necessary policies, frameworks, and roadmaps for the most eminent issues.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10506-021-09289-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-021-00514-y,"Robots, artificial intelligence, and service automation (RAISA) in hospitality: sentiment analysis of YouTube streaming data",Electronic Markets,10.1007/s12525-021-00514-y,Springer,2022-03-01,"Humans in hospitality areas are being replaced by robot concierges, delivery robots, chatbots, and information assistants through a variety of devices, for example, mobile apps and self-service check-in/check-out machines. Powered by artificial intelligence (AI) algorithms, big data, mobile Internet and internet-of-things technologies, inventions supporting a sustainable shift to social robotics have recently been growing exponentially. Despite this unidirectional movement, there has been a lack of effort to monitor customer responses regarding specific situations in a timely manner. In this study, we examine YouTube, an online streaming video website, to uncover what factors affect attitudes towards RAISA (Robot, AI, and Service Automation) applications in the hospitality industry. The findings show that the sentiment of the content of video narration and physical interaction influence potential customer attitudes toward RAISA services in hospitality. This study provides insights about how online buzz can offer an initial reference for potential customers to deal with the uncertainty of innovative services and provide practitioners with information about proper design guidelines for promoting RAISA applications to their businesses by grasping the trend of broad opinion in real time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12525-021-00514-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-021-01168-2,Attitude of college students towards ethical issues of artificial intelligence in an international university in Japan,AI & SOCIETY,10.1007/s00146-021-01168-2,Springer,2022-03-01,"We have examined the attitude and moral perception of 228 college students (63 Japanese and 165 non-Japanese) towards artificial intelligence (AI) in an international university in Japan. The students were asked to select a single most significant ethical issue associated with AI in the future from a list of nine ethical issues suggested by the World Economic Forum, and to explain why they believed that their chosen issues were most important. The majority of students ( n  = 149, 65%) chose unemployment as the major ethical issue related to AI. The second largest group of students ( n  = 29, 13%) were concerned with ethical issues related to emotional AI, including the impact of AI on human behavior and emotion. The paper discusses the results in detail and concludes that, while policymakers must consider how to ameliorate the impact of AI on employment, AI engineers need to consider the emotional aspects of AI in research and development, as well.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-021-01168-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-021-02527-8,Primitive-contrastive network: data-efficient self-supervised learning from robot demonstration videos,Applied Intelligence,10.1007/s10489-021-02527-8,Springer,2022-03-01,"Due to the costly collection of expert demonstrations for robots, robot imitation learning suffers from the demonstration-insufficiency problem. A promising solution to this problem is self-supervised learning that leverages pretext tasks to extract general and high-level features from a relatively small amount of data. Since imitation learning tasks are typically composed of primitives (e.g., primary skills, such as grasping and reaching), learning representations of these primitives is crucial. However, existing methods have a weak ability to represent primitive, leading to unsatisfactory generalizability to learning scenarios with few data. To address this problem, we propose a novel primitive-contrastive network (PCN) and pretext task that optimizes the distances between pseudo-primitive distributions as a learning objective. Experimental results show that the proposed PCN can learn a more discriminative embedding space of primitives than existing self-supervised learning methods. Four representative robot manipulation experiments are conducted to demonstrate the superior data efficiency of the proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-021-02527-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-021-0099-8,Online Gait Generation Method Based on Neural Network for Humanoid Robot Fast Walking on Uneven Terrain,"International Journal of Control, Automation and Systems",10.1007/s12555-021-0099-8,Springer,2022-03-01,"Advanced humanoid robots highlight the ability of fast walking and adaptability to uneven terrain. However, owing to the complexity in walking dynamics, disturbances introduced by terrain height variations can adversely affect the bipedal walking performance. Moreover, to generate periodic gaits, most methods require to solve the gait generation problem by using nonlinear optimization approaches, resulting in difficulties for online control. To solve this problem, this paper proposes an online gait generation method to find periodic gaits for fast walking on uneven terrain by using a pre-trained neural network. First, to enhance the terrain adaptability, this paper proposes an improved walking pattern that allows the robots to skip the last single support phase. Such improvement enlarges the feasible step region when stepping down. A compensation strategy is also proposed to reduce the velocity tracking error. Then the improved whale swarm algorithm (IWSA) is applied to generate various datasets that cover the ranges of target velocities and terrain height variations. A back-propagation (BP) network is employed to train these datasets offline to learn the gait dynamics, which is further used to generate the optimal trajectories. Simulation results suggest that, compared with the current methods, the proposed method can solve the walking return map in a short time, with improvements in both maximum walking speed and terrain adaptability.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-021-0099-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12065-020-00490-w,Towards robot vision using deep neural networks in evolutionary robotics,Evolutionary Intelligence,10.1007/s12065-020-00490-w,Springer,2022-03-01,"In evolutionary robotics, robot controllers are often evolved in simulation, as using the physical robot for fitness evaluation can take a prohibitively long time. Simulators provide a quick way to evaluate controller fitness. A simulator is tasked with providing appropriate sensor information to the controller. If the robot has an on-board camera, an entire virtual visual environment is needed to simulate the camera’s signal. In the past, these visual environments have been constructed by hand, requiring the use of hand-crafted models, textures and lighting, which is a tedious and time-consuming process. This paper proposes a deep neural network-based architecture for simulating visual environments. The neural networks are trained exclusively from images captured from the robot, creating a 3-dimensional visual environment without using hand-crafted models, textures or lighting. It does not rely on any external domain specific datasets, as all training data is captured in the physical environment. Robot controllers were evolved in simulation to discern between objects with different colours and shapes, and they successfully completed the same task in the real world.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12065-020-00490-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00431-021-04285-8,"The pilot study of group robot intervention on pediatric inpatients and their caregivers, using ‘new aibo’",European Journal of Pediatrics,10.1007/s00431-021-04285-8,Springer,2022-03-01,"The study on robot-assisted therapy in a pediatric field has not been applied sufficiently in clinical settings. The purpose of this pilot study is to explore the potential therapeutic effects of a group robot intervention (GRI), using dog-like social robot (SR) ‘aibo’ in pediatric ward. GRI by aibo was conducted for those children with chronic illness (127 in total) who are hospitalized in National Centre for Child Health and Development (NCCHD), and their caregivers (116 in total), from March to April 2018. The observer made structured behavioural observation records, based on which qualitative research on the features of their words and conducts, were carried out. As a result, first, during the GRI, about 2/3 of total expression by children were positive, while about 1/4 were negative or inappropriate. On the other hand, as seen in the ‘change’ group, those children who had originally responded with negative expression eventually came to express positive expression, while getting involved in a ternary relationship or participating in a session more than once. Secondly, as for the expression from the caregivers during the GRI, active expressions such as ‘participation’ and ‘exploration’ accounted for the 2/3, while 1/3 turned out to be rather placid expressions such as ‘watch over’ or ‘encourage.’ Conclusion: There has not been any precedent study on the features of words and conducts expressed by patients and their caregivers during the GRI by aibo. The outcome suggests that aibo could possibly be used as a tool for group robot-assisted therapy in the pediatric treatment setting. What is Known: • The study on robot-assisted therapy in a pediatric field has only just begun. • Though many kinds of social robot have been reportedly used so far, none has yet to be applied in clinical settings What is New: • Our study revealed the features of words and behaviour expressed by the patients and their caregivers, when dog-like social robot ‘aibo’ was used for a group robot intervention in the pediatric ward. • The outcome suggests that aibo could possibly be used as a tool for group robot-assisted therapy in the pediatric treatment setting.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00431-021-04285-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00170-021-08319-1,A smart operator advice model by deep learning for motion recognition in human–robot coexisting assembly line,The International Journal of Advanced Manufacturing Technology,10.1007/s00170-021-08319-1,Springer,2022-03-01,"Operator advice and guidance systems can help junior workers follow standard operating procedures, which are critical to a human–robot coexisting assembly line to guarantee harmonious and complete tasks with high quality. In this study, a smart operator advice model by deep learning is proposed. Two mechanisms are built as the model core in the model, which is an object detection mechanism using convolutional neural network and a motion recognition mechanism using a decision tree classifier. Object detection is carried out by three independent cameras monitoring all of the objects in the system. The study implements the proposed model in a graphic processing unit (GPU) card assembly line consisting of objects such as operator, robot, screwing machine, fan, motherboard, GPU card, screwdriver, hand, and body. The objects are identified by the object detection mechanism by three parallel and independent cameras. Motion detection is achieved by three parallel and independent decision tree classifiers for motion recognition in the three cameras where the inputs are the object coordinates and speeds. Through a majority rule, the right motion with the highest votes is confirmed. The final output is the task checking and advice provided by the proposed operator advice model. Results are evaluated through the GPU final assembly line. F1-score of 0.966 shows a promising performance. This smart model facilitates informative instruction to the junior operator when conducting complex assembly activities in real time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00170-021-08319-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11002-021-09609-0,Affective Computing in Marketing: Practical Implications and Research Opportunities Afforded by Emotionally Intelligent Machines,Marketing Letters,10.1007/s11002-021-09609-0,Springer,2022-03-01,"After years of using AI to perform cognitive tasks, marketing practitioners can now use it to perform tasks that require emotional intelligence. This advancement is made possible by the rise of affective computing, which develops AI and machines capable of detecting and responding to human emotions. From market research, to customer service, to product innovation, the practice of marketing will likely be transformed by the rise of affective computing, as preliminary evidence from the field suggests. In this Idea Corner, we discuss this transformation and identify the research opportunities that it offers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11002-021-09609-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41315-021-00179-y,Robot grasping in dense clutter via view-based experience transfer,International Journal of Intelligent Robotics and Applications,10.1007/s41315-021-00179-y,Springer,2022-03-01,"To perform object grasping in dense clutter, we propose a novel algorithm for grasp detection. To obtain grasp candidates, we developed instance segmentation and view-based experience transfer as part of the algorithm. Subsequently, we established an algorithm for collision avoidance and stability analysis to determine the optimal grasp for robot grasping. The strategy for the view-based experience transfer was to first find the object view and then transfer the grasp experience onto the clutter scenario. This strategy has two advantages over existing learning-based methods for finding grasp candidates. (1) our approach can effectively exclude the influence of noise or occlusion on images and precisely detect grasps that are well aligned on each target object. (2) our approach can efficiently find out optimal grasps on each target object and has the flexibility of adjusting and redefining the grasp experience based on the type of target object. We evaluated our approach using some open-source datasets and with a real-world robot experiment, which involved a six-axis robot arm with a two-jaw parallel gripper and a Kinect V2 RGB-D camera. The experimental results show that our proposed approach can be generalized to objects with complex shape, and is able to grasp on dense clutter scenarios where different types of objects are in a bin. To demonstrate our grasping pipeline, a video is provided at https://youtu.be/gQ3SO6vtTpA .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-021-00179-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42235-021-00142-4,Kinematic Modeling for Biped Robot Gait Trajectory Using Machine Learning Techniques,Journal of Bionic Engineering,10.1007/s42235-021-00142-4,Springer,2022-03-01,"This paper presents the predictive models for biped robot trajectory generation. Predictive models are parametrizing as a continuous function of joint angle trajectories. In a previous work, the authors had collected the human locomotion dataset at RAMAN Lab, MNIT, Jaipur, India. The MNIT gait dataset consists of walking data on a plane surface of 120 human subjects from different age groups and genders. Thirty-two machine learning models (linear, support vector, k-nearest neighbor, ensemble, probabilistic, and deep learning) trained using the collected dataset. In addition, two types of mapping, (a) one-to-one and (b) many-to-one, are presented for each model. These mapping models act as a reference policy for the control of joints and prediction of state for the next time instant in advance if the onboard sensor fails. Results show that the deep learning and probabilistic learning models perform better for both types of mappings. Also, the probabilistic model outperforms the deep learning-based models in terms of maximum error, because the probabilistic model effectively deals with the prediction uncertainty. In addition, many-to-one outperforms the one-to-one mapping because it captures the correlation between knee, hip, and ankle trajectories. Therefore, this study suggests a many-to-one mapping using the probabilistic model for biped robot trajectory generation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42235-021-00142-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00170-021-08299-2,An adaptive human sensor framework for human–robot collaboration,The International Journal of Advanced Manufacturing Technology,10.1007/s00170-021-08299-2,Springer,2022-03-01,"Manufacturing challenges are increasing the demands for more agile and dexterous means of production. At the same time, these systems aim to maintain or even increase productivity. The challenges risen from these developments can be tackled through human–robot collaboration (HRC). HRC requires effective task distribution according to each party’s distinctive strengths, which is envisioned to generate synergetic effects. To enable a seamless collaboration, the human and robot require a mutual awareness, which is challenging, due to the human and robot “speaking” different languages as in analogue and digital. This challenge can be addressed by equipping the robot with a model of the human. Despite a range of models being available, data-driven models of the human are still at an early stage. For this purpose, this paper proposes an adaptive human sensor framework, which incorporates objective, subjective, and physiological metrics, as well as associated machine learning. Thus, it is envisioned to adapt to the uniqueness and dynamic nature of human behavior. To test the framework, a validation experiment was performed, including 18 participants, which aims to predict perceived workload during two scenarios, namely a manual and an HRC assembly task. Perceived workloads are described to have a substantial impact on a human operator’s task performance. Throughout the experiment, physiological data from an electroencephalogram (EEG), an electrocardiogram (ECG), and respiration sensor was collected and interpreted. For subjective metrics, the standardized NASA Task Load Index was used. Objective metrics included task completion time and number of errors/assistance requests. Overall, the framework revealed a promising potential towards an adaptive behavior, which is ultimately envisioned to enable a more effective HRC.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00170-021-08299-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40815-021-01188-6,Adaptive Fuzzy Neural Agent for Human and Machine Co-learning,International Journal of Fuzzy Systems,10.1007/s40815-021-01188-6,Springer,2022-03-01,"This paper proposes an Adaptive Fuzzy Neural Agent ( AFNA ) with a Patch Learning Mechanism and IEEE 1855 Fuzzy Markup Language ( FML ) for human and machine co-learning. There are three phases of patch learning mechanism embedded in AFNA , including (1) training an initial global model, (2) training a patch model for each identified patch, and (3) updating the global model using the training data that do not fall into any patch. The AFNA can be applied to construct the student and robot co-learning regression model, as well as the regression model for the dataset retrieved from the game of Go. First, students generate human learning data through interactions with handheld devices or robots based on the AFNA in Taiwan and Japan. Then, the AFNA utilizes the student learning data collected in the classroom and the Go game data provided by both Google DeepMind and Facebook AI Research open-source OpenGo to train the Fuzzy Machine-Learning Model . In addition, the trained Fuzzy Machine-Learning Model of AFNA is deployed to the robots to make students and machines co-learn together based on IEEE 1855 FML . The experiments show that the AFNA with Patch Learning Mechanism and Fuzzy Machine-Learning Model can improve the performance of regression model based on the datasets of student learning and Go game. In the future, we hope to apply the AFNA with robots to the other domain areas, embed it with the Artificial Intelligence of Things devices, and introduce it to more teaching fields in various countries.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40815-021-01188-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42087-020-00125-7,"First, They Came for the Old and Demented:",Human Arenas,10.1007/s42087-020-00125-7,Springer,2022-03-01,"Health care technology is all the rage, and artificial intelligence (AI) has long since made its inroads into the previously human-dominated domain of care . AI is used in diagnostics, but also in therapy and assistance, sometimes in the form of social robots with fur, eyes and programmed emotions. Patient welfare, working conditions for the caretakers and cost-efficiency are routinely said to be improved by employing new technologies. The old with dementia might be provided with a robot seal, or a humanoid companion robot, and if these companions increase the happiness of the patients, why should we not venture down this road? Come to think of it, when we have these machines, why not use them as tutors in our schools and caretakers for our children? More happiness reported, as our children are entertained, well-nourished, well-trained and never alone. Lovely and loving robots have also been made, and happiness abounds when these are provided to lonely adults. Happiness all around, and a hedonistic heaven – the utilitarian’s dream, as reported, or measured, well-being reaches all-time highs. But there is a reason to be wary of this development. The logic that allows this development ultimately leads to the conclusion that we would all be best off if we could simply be wired to a computer that provided us with whatever we needed to feel perfectly satisfied. The care-giving machines are here.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42087-020-00125-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-021-00807-4,Mind the Robot! Variation in Attributions of Mind to a Wide Set of Real and Fictional Robots,International Journal of Social Robotics,10.1007/s12369-021-00807-4,Springer,2022-03-01,"The rapid rise of computing power has prompted the desire to develop more social, human-like robots. Quantitatively comparing different computing systems on their ability to simulate human qualities has been a major technical challenge. A recent framework put forth by Gray et al. (Science 315(5812):619, 2007. https://doi.org/10.1126/science.1134475 ) provides promise as a new means for comparing robots. While the framework has been validated for assessing individual robots with different descriptions, or different behaviours, the framework has not been applied to a wider landscape of robots and machines situated amongst other characters. The present study sought to investigate attributions of mind towards a wide range of real and fictional robots. We asked participants to rate the agency (the ability “to do”) and experience (the ability “to feel”) of 24 characters made up of humans, robots, inanimate objects, and animals. Although robots were collectively rated lower than humans on agency and experience, there was significant variation among robots—even when fictional robots were omitted. The results of this investigation suggest that building robots that are perceived to feel is a fruitful avenue for future development as people are more open to perceiving aspects of mind in a wider range of robots than previously established. Our results also indicate that age is a critical factor in people’s attributions of mind to robots, suggesting that there may be a generational shift towards greater acceptance of robots’ ability to both do and feel.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-021-00807-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11119-022-09895-2,Citrus fruits maturity detection in natural environments based on convolutional neural networks and visual saliency map,Precision Agriculture,10.1007/s11119-022-09895-2,Springer,2022-03-01,"Citrus fruits do not ripen at the same time in natural environments and exhibit different maturity stages on trees, hence it is necessary to realize selective harvesting of citrus picking robots. The visual attention mechanism reveals a physiological phenomenon that human eyes usually focus on a region that is salient from its surround. The degree to which a region contrasts with its surround is called visual saliency. This study proposes a novel citrus fruit maturity method combining visual saliency and convolutional neural networks to identify three maturity levels of citrus fruits. The proposed method is divided into two stages: the detection of citrus fruits on trees and the detection of fruit maturity. In stage one, the object detection network YOLOv5 was used to identify the citrus fruits in the image. In stage two, a visual saliency detection algorithm was improved and generated saliency maps of the fruits; The information of RGB images and the saliency maps were combined to determine the fruit maturity class using 4-channel ResNet34 network. The comparison experiments were conducted around the proposed method and the common RGB-based machine learning and deep learning methods. The experimental results show that the proposed method yields an accuracy of 95.07%, which is higher than the best RGB-based CNN model, VGG16, and the best machine learning model, KNN, about 3.14% and 18.24%, respectively. The results prove the validity of the proposed fruit maturity detection method and that this work can provide technical support for intelligent visual detection of selective harvesting robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11119-022-09895-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11740-022-01118-x,Intelligent predetection of projected reference markers for robot-based inspection systems,Production Engineering,10.1007/s11740-022-01118-x,Springer,2022-02-28,"Technical advancements in optical devices like sensors and projectors have led to tremendous innovations in manufacturing metrology, not least due to reductions in cost and the use of sophisticated image processing software. More recently, methods based on machine learning have demonstrated their high potential in meeting challenges that are difficult to overcome using conventional image processing techniques. In this context, we present an approach for the intelligent predetection of projected reference markers in robot-based inspection systems. These markers support the alignment of different sensor views and do not need to be physically attached to any parts. However, their robust detection is challenging under unfavorable lighting conditions. Hence, we introduce trained models of a cascade classifier based on both synthetic and real image data. Subsequently, we present the detection performance for different shapes and designs of markers projected onto real-world sheet metal parts as used in the automotive industry. The results demonstrate that properly trained classifiers can achieve a recall and precision of 90% and higher. The use of intelligent predetection promises more robust results in the subsequent detection of projected markers and, thus, benefits image processing in particular in geometric quality assurance applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11740-022-01118-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13347-022-00499-2,Commentary: “Whiteness and Colourblindness”,Philosophy & Technology,10.1007/s13347-022-00499-2,Springer,2022-02-26,"This commentary argues that, in discussing the racial and cultural identities of cinematic representations of humanoid AI robots, nuances and differentiations are beneficial. It suggests that the essay on which the present text comments does not sufficiently acknowledge the range of identities found in AI films, in particular in Alex Garland's Ex Machina (2014).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13347-022-00499-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13347-022-00509-3,"Can Robots Do Epidemiology? Machine Learning, Causal Inference, and Predicting the Outcomes of Public Health Interventions",Philosophy & Technology,10.1007/s13347-022-00509-3,Springer,2022-02-26,"This paper argues that machine learning (ML) and epidemiology are on collision course over causation. The discipline of epidemiology lays great emphasis on causation, while ML research does not. Some epidemiologists have proposed imposing what amounts to a causal constraint on ML in epidemiology, requiring it either to engage in causal inference or restrict itself to mere projection. We whittle down the issues to the question of whether causal knowledge is necessary for underwriting predictions about the outcomes of public health interventions. While there is great plausibility to the idea that it is, conviction that something is impossible does not by itself motivate a constraint to forbid trying. We disambiguate the possible motivations for such a constraint into definitional, metaphysical, epistemological, and pragmatic considerations and argue that “Proceed with caution” (rather than “Stop!”) is the outcome of each. We then argue that there are positive reasons to proceed, albeit cautiously. Causal inference enforces existing classification schema prior to the testing of associational claims (causal or otherwise), but associations and classification schema are more plausibly discovered (rather than tested or justified) in a back-and-forth process of gaining reflective equilibrium. ML instantiates this kind of process, we argue, and thus offers the welcome prospect of uncovering meaningful new concepts in epidemiology and public health—provided it is not causally constrained.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13347-022-00509-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01566-0,A Deep Reinforcement Learning Approach with Visual Semantic Navigation with Memory for Mobile Robots in Indoor Home Context,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01566-0,Springer,2022-02-24,"Navigate is a crucial task to be performed by social robot agents in complex and uncertain environments like homes and offices. Search for specific target objects is usually a required activity. This work aimed to propose a visual semantic navigation with memory architecture model. Based on recent advances in convolutional neural networks and graph neural networks, a visual semantic navigation architecture model (GCN-MLP) was extended with recurrent neural networks for memory mechanisms (GCN-GRU and GCN-LSTM) while exposing a robot agent in navigation experiences to learn navigation policies. The models were evaluated quantitatively and qualitatively, where memory enhanced models demonstrated early convergence, better performance in evaluation metrics, increased successfully terminated episodes, more efficient path trajectories, and lower decrease in performance when exposed to challenger test scheme, presenting a more exploratory behavior. Finally, were analyzed differences between GRU and LSTM, where GRU performed similarly to LSTM in some cases, being a viable option.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01566-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-022-01577-5,Autonomous Learning in a Pseudo-Episodic Physical Environment,Journal of Intelligent & Robotic Systems,10.1007/s10846-022-01577-5,Springer,2022-02-08,"Forpractical considerations reinforcement learning has proven to be a difficult task outside of simulation when applied to a physical experiment. Here we derive an optional approach to model free reinforcement learning, achieved entirely online, through careful experimental design and algorithmic decision making. We design a reinforcement learning scheme to implement traditionally episodic algorithms for an unstable 1-dimensional mechanical environment. The training scheme is completely autonomous, requiring no human to be present throughout the learning process. We show that the pseudo-episodic technique allows for additional learning updates with off-policy actor-critic and experience replay methods. We show that including these additional updates between periods of traditional training episodes can improve speed and consistency of learning. Furthermore, we validate the procedure in experimental hardware. In the physical environment, several algorithm variants learned rapidly, each surpassing baseline maximum reward. The algorithms in this research are model free and use only information obtained by an onboard sensor during training.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-022-01577-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10772-022-09962-z,To deploy trained speech with DNN-LSTM framework for controlling a smart wheeled-robot in limited learning circumstance,International Journal of Speech Technology,10.1007/s10772-022-09962-z,Springer,2022-02-08,"The assessment to a trained speech controller with deep neural network long-short term memory (DNN-LSTM) framework adopted as the commander to control a smart wheeled-robot is implemented in the article. Accordingly, the deployment is implemented in recognition to control remotely a smart wheeled-robot which has been completed previously by other project of authors’ research group. Based on the machine learning skill a framework established with the DNN-LSTM model is embedded into the smart wheeled-robot prototype. Apart from, the control commands are designed over limited learning circumstance where constrained single-track (ST) and double-track (DT) speeches, and only are including 4 Chinese speech commands, “forward” (Chinese”前進”), “backward” (Chinese”後退”), “turn left” (Chinese”左轉”), and “turn right” (Chinese”右轉”). Though, there are just 4 simple speeches collected for data training, the investigation to the accurate ratio is deployed in 3 separated persons training work and each with 1000 to 5000 training times. There are just three parameters (this why “ Limited Learning Circumstance ” is referred as the article name) considered as the dominators for the performance evaluation of the speech controlled wheeled-robot. The results from the testing cases clearly show that the set with DT has the higher accurate comparison with the set of ST. The best outcomes form the performance of testing and validation happens at the case of DT channel, hereafter, the accurate and loss rate are obtained as 0.673 and 0.018 with 50% dropout, respectively. However, the ratio of dropout has been discovered definitely to dominate the accurate and loss rate when it is deployed during the process of training step. Eventually, the trained and developed model of speech command sets are uploaded into a micro-controller after accuracy analyzed, and embedded into the smart wheeled-robot plays as remotely pilot scheme.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10772-022-09962-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s42836-021-00108-1,Augmented Intelligence in Joint Replacement Surgery: How can artificial intelligence (AI) bridge the gap between the man and the machine?,Arthroplasty,10.1186/s42836-021-00108-1,BioMed Central,2022-02-02,"Robot-assisted arthroplasty is likely to grow exponentially in the years to come. While most surgeons recognize their superiority in refining alignment and improving component positioning accuracy, the universal adaptability of robots remains slow due to certain technological and behavioural gaps. Endoprosthesis robots currently suffer from increased reaction time, lack of natural adaptation to the surgeon's abilities, and unavailability and inapplicability in different surgical contexts. As humans and machines have to move forward into the next phase of their relationship, robots enabled with artificial intelligence (AI) may become more advanced and an alternative to overcome existing challenges like cost, training, and improve performance based on feedback provided by surgeons. Augmented intelligence is perhaps a more apt word than artificial, as it reflects more human-machine fusion and several areas are already proactively adopting the terminology. Arthroplasty robots can benefit from AI by using computer vision models, applying sensors, and integrating feedback and loop execution. All of this would help achieve a technical superiority to the surgeon alone. This brief perspective on how humans and machines are likely to benefit from the integration of AI outlines the technical side of this enablement.",https://www.biomedcentral.com/openurl?doi=10.1186/s42836-021-00108-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-021-05898-8,Research on computer vision enhancement in intelligent robot based on machine learning and deep learning,Neural Computing and Applications,10.1007/s00521-021-05898-8,Springer,2022-02-01,"The stable operation of intelligent robots requires the effective support of machine vision technology. In order to improve the effect of robot machine vision recognition, based on deep learning, this paper, under the guidance of machine learning ideas, proposes a target detection framework that combines target recognition and target tracking based on the efficiency advantages of the KCF visual tracking algorithm. Moreover, this paper designs a vision system based on a high-resolution color camera and TOF depth camera. In addition, by modeling the coordinate conversion relationship of the same object in the camera coordinate system of two cameras, the projection relationship of the depth map collected by the TOF camera to the pixel coordinate system of the high-resolution color camera is determined. In addition, this paper designs experiments to verify the performance of the model. The research results show that the method proposed in this paper has a certain effect.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-021-05898-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-021-06537-y,Firefighting robot with deep learning and machine vision,Neural Computing and Applications,10.1007/s00521-021-06537-y,Springer,2022-02-01,"While extinguishing the fire, firefighters find it difficult to reach certain areas due to narrow spaces or debris blocking the way. In urban cities and industrial areas, there is a constant need to have firefighters ready in case of emergencies. This can lead to a shortage of manpower. Thus, the firefighting robot can act as assisting support for firefighters and will also lower down the risk of their life. Even though many firefighter robots have been developed currently to overcome this problem, these robots are expensive and difficult to maintain. We propose an intelligent robot that uses deep learning to not only detect and classify fire but also extinguish the detected fire based on its class. The proposed firefighter robot is cheaper, autonomous, and easier to maintain. We have used a combination of AlexNet to detect fire and ImageNet for detecting the type of fire. We achieved a classification accuracy of fire detection up to 98.25%, and the classification accuracy of fire-type classification was around 92%. The firefighter robot can be deployed in places that are hard to reach for the firefighters and thereby reduce the burden on firefighters.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-021-06537-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10845-021-01867-z,A review of motion planning algorithms for intelligent robots,Journal of Intelligent Manufacturing,10.1007/s10845-021-01867-z,Springer,2022-02-01,"Principles of typical motion planning algorithms are investigated and analyzed in this paper. These algorithms include traditional planning algorithms, classical machine learning algorithms, optimal value reinforcement learning, and policy gradient reinforcement learning. Traditional planning algorithms investigated include graph search algorithms , sampling-based algorithms , interpolating curve algorithms , and reaction-based algorithms . Classical machine learning algorithms include multiclass support vector machine , long short-term memory , Monte-Carlo tree search and convolutional neural network . Optimal value reinforcement learning algorithms include Q learning , deep Q-learning network , double deep Q-learning network , dueling deep Q-learning network . Policy gradient algorithms include policy gradient method , actor-critic algorithm , asynchronous advantage actor-critic , advantage actor-critic , deterministic policy gradient , deep deterministic policy gradient , trust region policy optimization and proximal policy optimization . New general criteria are also introduced to evaluate the performance and application of motion planning algorithms by analytical comparisons. The convergence speed and stability of optimal value and policy gradient algorithms are specially analyzed. Future directions are presented analytically according to principles and analytical comparisons of motion planning algorithms. This paper provides researchers with a clear and comprehensive understanding about advantages, disadvantages, relationships, and future of motion planning algorithms in robots, and paves ways for better motion planning algorithms in academia, engineering, and manufacturing.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10845-021-01867-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-021-09997-9,Reinforcement learning in robotic applications: a comprehensive survey,Artificial Intelligence Review,10.1007/s10462-021-09997-9,Springer,2022-02-01,"In recent trends, artificial intelligence (AI) is used for the creation of complex automated control systems. Still, researchers are trying to make a completely autonomous system that resembles human beings. Researchers working in AI think that there is a strong connection present between the learning pattern of human and AI. They have analyzed that machine learning (ML) algorithms can effectively make self-learning systems. ML algorithms are a sub-field of AI in which reinforcement learning (RL) is the only available methodology that resembles the learning mechanism of the human brain. Therefore, RL must take a key role in the creation of autonomous robotic systems. In recent years, RL has been applied on many platforms of the robotic systems like an air-based, under-water, land-based, etc., and got a lot of success in solving complex tasks. In this paper, a brief overview of the application of reinforcement algorithms in robotic science is presented. This survey offered a comprehensive review based on segments as (1) development of RL (2) types of RL algorithm like; Actor-Critic, DeepRL, multi-agent RL and Human-centered algorithm (3) various applications of RL in robotics based on their usage platforms such as land-based, water-based and air-based, (4) RL algorithms/mechanism used in robotic applications. Finally, an open discussion is provided that potentially raises a range of future research directions in robotics. The objective of this survey is to present a guidance point for future research in a more meaningful direction.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10462-021-09997-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11548-021-02519-6,Automatic and accurate needle detection in 2D ultrasound during robot-assisted needle insertion process,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-021-02519-6,Springer,2022-02-01,"Purpose Robot-assisted needle insertion guided by 2D ultrasound (US) can effectively improve the accuracy and success rate of clinical puncture. To this end, automatic and accurate needle-tracking methods are important for monitoring puncture processes, avoiding the needle deviating from the intended path, and reducing the risk of injury to surrounding tissues. This work aims to develop a framework for automatic and accurate detection of an inserted needle in 2D US image during the insertion process. Methods We propose a novel convolutional neural network architecture comprising of a two-channel encoder and single-channel decoder for needle segmentation using needle motion information extracted from two adjacent US image frames. Based on the novel network, we further propose an automatic needle detection framework. According to the prediction result of the previous frame, a region of interest of the needle in the US image was extracted and fed into the proposed network to achieve finer and faster continuous needle localization. Results The performance of our method was evaluated based on 1000 pairs of US images extracted from robot-assisted needle insertions on freshly excised bovine and porcine tissues. The needle segmentation network achieved 99.7% accuracy, 86.2% precision, 89.1% recall, and an F _1-score of 0.87. The needle detection framework successfully localized the needle with a mean tip error of 0.45 ± 0.33 mm and a mean orientation error of 0.42° ± 0.34° and achieved a total processing time of 50 ms per image. Conclusion The proposed framework demonstrated the capability to realize robust, accurate, and real-time needle localization during robot-assisted needle insertion processes. It has a promising application in tracking the needle and ensuring the safety of robotic-assisted automatic puncture during challenging US-guided minimally invasive procedures.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-021-02519-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40747-021-00538-z,Critic-observer-based decentralized force/position approximate optimal control for modular and reconfigurable manipulators with uncertain environmental constraints,Complex & Intelligent Systems,10.1007/s40747-021-00538-z,Springer,2022-02-01,"A critic-observer decentralized force/position approximate optimal control method is presented to address the joint trajectory and contacted force tracking problem of modular and reconfigurable manipulators (MRMs) with uncertain environmental constraints. The dynamic model of the MRM systems is formulated as an integration of joint subsystems via extensive state observer (ESO) associated with the effect of interconnected dynamic coupling (IDC). A radial basis function neural network (RBF-NN) is developed to deal with the IDC effects among the independent joint subsystems. Based on adaptive dynamic programming (ADP) approach and policy iteration (PI) algorithm, the Hamilton–Jacobi–Bellman (HJB) equation is approximately solved by establishing critic NN structure and then the approximated optimal control policy can be derived. The closed-loop manipulator system is proved to be asymptotic stable by using the Lyapunov theory. Finally, simulation results are provided to demonstrate the effectiveness and advantages of the proposed control method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40747-021-00538-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40430-022-03371-8,Review on key technologies of space intelligent grasping robot,Journal of the Brazilian Society of Mechanical Sciences and Engineering,10.1007/s40430-022-03371-8,Springer,2022-01-29,"Humankind’s yearning for universe has never stopped. Over the past decades, various spacecrafts have played an important role in space exploration. Combined with the development of AI, the space intelligent grasping robot, a new in-orbit service spacecraft, will bring new power to space exploration. This paper reviews the technologies related to configuration design, dynamic modeling and control algorithm. A four-stage task planning is proposed. Firstly, the means of the detection stage are put forward; secondly, the image recognition and visual tracking are described in the docking stage; thirdly, the cooperative control of robot in the capture stage is emphatically discussed, several important problems, such as coupling, path planning and motion control, multi-objective optimization, collision, are proposed. In order to solve these problems, the current research progress is summarized, and some new problem-solving technologies based on AI are analyzed in detail; lastly, the stability and control of the combination are briefly introduced.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40430-022-03371-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s42467-021-00014-x,Human-centered AI and robotics,AI Perspectives,10.1186/s42467-021-00014-x,Springer,2022-01-28,"Robotics has a special place in AI as robots are connected to the real world and robots increasingly appear in humans everyday environment, from home to industry. Apart from cases were robots are expected to completely replace them, humans will largely benefit from real interactions with such robots. This is not only true for complex interaction scenarios like robots serving as guides, companions or members in a team, but also for more predefined functions like autonomous transport of people or goods. More and more, robots need suitable interfaces to interact with humans in a way that humans feel comfortable and that takes into account the need for a certain transparency about actions taken. The paper describes the requirements and state-of-the-art for a human-centered robotics research and development, including verbal and non-verbal interaction, understanding and learning from each other, as well as ethical questions that have to be dealt with if robots will be included in our everyday environment, influencing human life and societies.",http://link.springer.com/openurl/fulltext?id=doi:10.1186/s42467-021-00014-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s42836-021-00109-0,What’s new in artificially intelligent joint surgery in China? The minutes of the 2021 IEEE ICRA and literature review,Arthroplasty,10.1186/s42836-021-00109-0,BioMed Central,2022-01-17,"Objective To outline the main results of the 2021 International Conference on Robotics and Automation (ICRA 2021) of the Institute of Electrical and Electronics Engineers (IEEE) and review the advances in artificially intelligent joint surgery in China. Methods The keynote speeches of the 2021 ICRA were summarized in detail, and publications indexed by five core electronic databases (PubMed, Cochrane, Medline, Embase and CNKI) were systematically surveyed (cutoff date: July 30, 2021) in terms of the main topics of the conference. Publications directly related to artificially intelligent joint surgery in China were identified by using the search strategies of (robotic AND arthroplasty OR replacement), (navigation AND arthroplasty OR replacement), (artificial intelligent AND arthroplasty OR replacement), and (mixed reality AND arthroplasty OR replacement) and systemically reviewed. Results While robot-assisted arthroplasty in China is mainly performed using robots made in other countries ( e . g ., Mako from Stryker, USA), China’s domestic R&D of robots and clinical studies of robotic joint surgery have made some achievements. Although reports on the safety, effectiveness and clinical efficacy of China’s domestic robot-assisted joint surgery were presented at conferences, they have rarely been published in journals. Existing data indicate that, after the learning curve is overcome, robot-assisted hip and knee replacement surgery can fully achieve the established goals of precision and individualization and can significantly improve the accuracy of prosthesis placement angle and the recovery of the mechanical axis as compared with conventional surgery. The downside is that the low level of intelligentization and individualization means that existing designs are not conducive to personalization during surgery, resulting in low cost-effectiveness. Conclusion The safety and efficacy of domestic robot-assisted arthroplasty in China are well documented, and its accuracy and short-term clinical efficacy have been reported. However, the long-term clinical efficacy and the cost-effectiveness of large-scale clinical application of this technique warrants further study. The inadequacies of robot-assisted surgery should be remedied through the deep integration of medicine, engineering and the network.",https://www.biomedcentral.com/openurl?doi=10.1186/s42836-021-00109-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00464-021-08999-6,Ensemble deep learning for the prediction of proficiency at a virtual simulator for robot-assisted surgery,Surgical Endoscopy,10.1007/s00464-021-08999-6,Springer,2022-01-12,"Background Artificial intelligence (AI) has the potential to enhance patient safety in surgery, and all its aspects, including education and training, will derive considerable benefit from AI. In the present study, deep-learning models were used to predict the rates of proficiency acquisition in robot-assisted surgery (RAS), thereby providing surgical programs directors information on the levels of the innate ability of trainees to facilitate the implementation of flexible personalized training. Methods 176 medical students, without prior experience with surgical simulators, were trained to reach proficiency in five tasks on a virtual simulator for RAS. Ensemble deep neural networks (DNN) models were developed and compared with other ensemble AI algorithms, i.e., random forests and gradient boosted regression trees (GBRT). Results DNN models achieved a higher accuracy than random forests and GBRT in predicting time to proficiency, 0.84 vs. 0.70 and 0.77, respectively (Peg board 2), 0.83 vs. 0.79 and 0.78 (Ring walk 2), 0.81 vs 0.81 and 0.80 (Match board 1), 0.79 vs. 0.75 and 0.71 (Ring and rail 2), and 0.87 vs. 0.86 and 0.84 (Thread the rings 2). Ensemble DNN models outperformed random forests and GBRT in predicting number of attempts to proficiency, with an accuracy of 0.87 vs. 0.86 and 0.83, respectively (Peg board 2), 0.89 vs. 0.88 and 0.89 (Ring walk 2), 0.91 vs. 0.89 and 0.89 (Match board 1), 0.89 vs. 0.87 and 0.83 (Ring and rail 2), and 0.96 vs. 0.94 and 0.94 (Thread the rings 2). Conclusions Ensemble DNN models can identify at an early stage the acquisition rates of surgical technical proficiency of trainees and identify those struggling to reach the required expected proficiency level.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00464-021-08999-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10845-021-01882-0,Intelligent monitoring of multi-axis robots for online diagnostics of unknown arm deviations,Journal of Intelligent Manufacturing,10.1007/s10845-021-01882-0,Springer,2022-01-10,"In the age of Industry 4.0, multi-axis robots are widely used in smart manufacturing thanks to their capacity of milling high complex forms and interacting with several systems in production lines. However, during manufacturing, the occurrence of small drifts in the robot arms may lead to critical failures and significant product quality damages and, therefore, high financial losses. Hence, this paper aims to develop an effective and practical methodology for online diagnostics of robot drifts based on information fusion of direct and indirect monitoring. The direct monitoring exploits the already installed encoders on each servomotor of the robot while the indirect monitoring uses heterogeneous sensors (current, vibration, force and torque) placed at the robot tool level. The sensor measurements of the robot tool are processed, in an offline phase, to build health indicators and fused to learn a classifier for drifts detection and diagnostics. Then, during the online phase and in the case of presence of new drift patterns, the encoder measurements are used to label these patterns and update the classifier learned previously to diagnose their origin. The efficiency and robustness of the proposed methodology are verified through a real industrial machining multi-axis robot that investigates different drift severities of its arms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10845-021-01882-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-022-01014-2,Controlling by Showing: i-Mimic: A Video-Based Method to Control Robotic Arms,SN Computer Science,10.1007/s42979-022-01014-2,Nature,2022-01-10,"A novel concept of vision-based intelligent control of robotic arms is developed here in this work. This work enables the controlling of robotic arm motion only with visual input, that is, controlling by showing the videos of correct movements. This work can broadly be sub-divided into two segments. The first part of this work is to develop an unsupervised vision-based method to control robotic arms in 2-D plane, and the second one is with deep convolutional neural network (CNN) in the same task in 3-D plane. The first method is unsupervised, where our aim is to perform mimicking of human arm motion in real-time by a manipulator. We developed a network, namely the vision-to-motion optical network (DON). Given the input of a video stream containing the hand movements of human on the DON, the velocity and torque information of the hand movements shown in the video would be generated as the output. The output information of the DON is then fed to the robotic arm by enabling it to generate motion according to the real hand videos. The method has been tested on both live-stream video feeds as well as on recorded video obtained from a monocular camera even by intelligently predicting the trajectory of the human hand when it gets occluded. This is why the mimicry of the arm incorporates some intelligence to it and becomes an intelligent mimic (i- mimic). Furthermore, to enhance the performance of DON and make it applicable to mimic multi-joint movements with n-link manipulator, a deep network, namely, CNN has been used along with a refiner network as the predecessor of DON. Refiner network has been used to overcome the limitations of inadequate labelled data. Both the proposed methods are validated with off-line as well as with on-line video datasets in real-time. The entire methodology is validated with real-time 1-link and simulated n-link manipulators (an arm with n number of different joints) along with suitable comparisons.",https://www.nature.com/articles/s42979-022-01014-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10961-021-09914-w,Automation and related technologies: a mapping of the new knowledge base,The Journal of Technology Transfer,10.1007/s10961-021-09914-w,Springer,2022-01-07,"Using the entire population of USPTO patent applications published between 2002 and 2019, and leveraging on both patent classification and semantic analysis, this paper aims to map the current knowledge base centred on robotics and AI technologies. These technologies are investigated both as a whole and distinguishing core and related innovations, along a 4-level core-periphery architecture. Merging patent applications with the Orbis IP firm-level database allows us to put forward a twofold analysis based on industry of activity and geographic location. In a nutshell, results show that: (i) rather than representing a technological revolution, the new knowledge base is strictly linked to the previous technological paradigm; (ii) the new knowledge base is characterised by a considerable—but not impressively widespread—degree of pervasiveness; (iii) robotics and AI are strictly related, converging (particularly among the related technologies and in more recent times) and jointly shaping a new knowledge base that should be considered as a whole, rather than consisting of two separate GPTs; (iv) the US technological leadership turns out to be confirmed (although declining in relative terms in favour of Asian countries such as South Korea, China and, more recently, India).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10961-021-09914-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-021-01377-9,The social and ethical impacts of artificial intelligence in agriculture: mapping the agricultural AI literature,AI & SOCIETY,10.1007/s00146-021-01377-9,Springer,2022-01-03,"This paper will examine the social and ethical impacts of using artificial intelligence (AI) in the agricultural sector. It will identify what are some of the most prevalent challenges and impacts identified in the literature, how this correlates with those discussed in the domain of AI ethics, and are being implemented into AI ethics guidelines. This will be achieved by examining published articles and conference proceedings that focus on societal or ethical impacts of AI in the agri-food sector, through a thematic analysis of the literature. The thematic analysis will be divided based on the classifications outlined through 11 overarching principles, from an established lexicon (transparency, justice and fairness, non-maleficence, responsibility, privacy, beneficence, freedom and autonomy, trust, dignity, sustainability, and solidarity). While research on AI agriculture is still relatively new, this paper aims to map the debate and illustrate what the literature says in the context of social and ethical impacts. It aim is to analyse these impacts, based on these 11 principles. This research will contrast which impacts are not being discussed in agricultural AI and which issues are not being discussed in AI ethics guidelines, but which are discussed in relation to agricultural AI. The aim of this is to identify gaps within the agricultural literature, and gaps in AI ethics guidelines, that may need to be addressed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-021-01377-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89511-2_109,Treatment Robot for Children with Autism Based on Deep Learning,The 2021 International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy,10.1007/978-3-030-89511-2_109,Springer,2022-01-01,"Autism is a condition of social communication disorder and repetitive sensory use. In recent years, the incidence of autism has gradually increased, and the number of children with autism has also increased. According to the reality of relevant data investigation, the time to diagnose autism is directly proportional to the effect of intervention treatment. At present, more and more experts have put forward insights on the diagnosis and treatment of children with autism, incorporating the technology of therapeutic robots into it. The application scenario of machine as the main technology builds a system for treating children with autism. By introducing classroom learning videos of children with autism, the current emotions of students can be judged in time, and students’ performance can be evaluated and evaluated in a deep learning environment. Tracking effectively reduces the pressure on teachers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89511-2_109,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85365-5_17,Robust Model for Rural Education Using Deep Learning and Robotics,"Advances in Deep Learning, Artificial Intelligence and Robotics",10.1007/978-3-030-85365-5_17,Springer,2022-01-01,"Rural Education is important for the overall development of villages. National Achievement Survey (NAS) has surveyed and reported in many States of India consistent decline in the learning levels of students in mathematics, language and science from class III to class VIII studying in the government school system. Smart Villages is only possible if the literacy level and infrastructure improves considerably. This paper aims to perform a reality check of the situation by comparing different rural areas of various countries including India and study of related work done. The paper proposes a Robust Model for Rural Education by developing an intelligent humanoid robot using the Deep Learning approach, Human recognition, Object Recognition and Speech Recognition. The data set consists of Primary and Secondary Student data of around 10,000 Students (5 years) from 5 villages. The Proposed Model would be compared with existing models on the parameters of Learnability, Decision making, Flexibility and Cost-effectiveness. The implementation of this Model will help in decreasing the drop out rate, evaluate Students and give them a Learning platform based on their characteristics, increase adaptive and self paced learning. This Model can also be executed for Rural Adult Education and Skill building so that the Smart Village concept can become a reality.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-85365-5_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-5529-6_34,Artificial Intelligence-Based Rubber Tapping Robot,Inventive Communication and Computational Technologies,10.1007/978-981-16-5529-6_34,Springer,2022-01-01,"Rubber tapping is the process of extracting latex from rubber trees. Rubber tree ( Hevea brasiliensis ) is the most prevalent plantation crop in Kerala, India, and it was discovered to be the main source of income for the over 11.5 lakh people who live there. Because of its outstanding qualities, natural rubber is often used in everyday life. Manual tapping is currently the most popular method of accessing natural rubber. Rubber tree tapping is considered a skilled labor-intensive task, and the availability of such labor is dwindling. This is considered to be one of the factors affecting natural rubber production in Indian plantations. As a solution to the problems faced by the rubber industry, an AI-based rubber tapping robot is proposed that can automatically move from one tree to another in a rubber plantation and tap each tree.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-5529-6_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-4546-5_48,A Semi-supervised Learning Based on Variational Autoencoder for Visual-Based Robot Localization,Computer Supported Cooperative Work and Social Computing,10.1007/978-981-19-4546-5_48,Springer,2022-01-01,"Robot localization, the task of determining the current pose of a robot, is a crucial problem of mobile robotic. Visual-based robot localization, which using only cameras as exteroceptive sensors, has become extremely popular due to the relatively cheap cost of cameras. However, current approaches such as Bayes Filter based methods and Visual Odometry need knowledge of prior location and also rely on the feature points in images. This paper presents a novel semi-supervised learning method based on Variational Autoencoder (VAE) for visual-based robot localization, which does not rely on the prior location and feature points. Because our method does not need prior knowledge, it also can be used as a correction of dead reckoning. We adopt VAE as an unsupervised learning method to preprocess the environment images, followed by a supervised learning model to learn the mapping between the robot’s location and processed images. Therefore, one merit of the proposed approach is that it can adopt any state-of-the-art supervised learning models. Furthermore, this semi-supervised learning scheme is also suitable for improving other supervised learning problems by adding extra unlabeled data to the training data set to solve the problem in a semi-supervised manner. We show that this semi-supervised learning scheme can get a high accuracy for pose prediction using a surprisingly small number of labeled images compared to other machine learning methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-4546-5_48,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-92442-3_24,Model Free Error Compensation for Cable-Driven Robot Based on Deep Learning with Sim2real Transfer Learning,"Informatics in Control, Automation and Robotics",10.1007/978-3-030-92442-3_24,Springer,2022-01-01,"The paper deals with model-free error compensation for cable-driven parallel robots based on the sim2real deep transfer learning. Particular attention is paid to simulation-based error estimation for different payloads attached to the robot end-effector and the use of the Transfer Learning approach for error compensation. This allows to reduce physical experiments with a real robot and gather sufficient data set within a reasonable time, which is required for deep learning. The obtained results were applied and validated for underactuated 4-dof (degrees of freedom) cable-driven parallel robot. Model-free Deep learning-based methods for a considerable training dataset provides better accuracy than simple linear error compensators using model-based calibration procedure. The proposed sim2real Transfer Learning method allowed to speed up the process of robotics system integration and recalibration due to the significant sample efficiency improvement.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-92442-3_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-05230-9_80,Real-Time Mobile Robot Perception Based on Deep Learning Detection Model,"New Technologies, Development and Application V",10.1007/978-3-031-05230-9_80,Springer,2022-01-01,"The recent advances in deep learning models have enabled the robotics community to utilize their potential. The mobile robot domain on which deep learning has the most influence is scene understanding. Scene understanding enables mobile robots to exist and execute their tasks through processes such as object detection, semantic segmentation, or instance segmentation. A perception system that can recognize and locate objects in the scene is of the highest importance for achieving autonomous behavior of robotic systems. Having that in mind, we develop the mobile robot perception system based on deep learning. More precisely, we utilize an accurate and fast Convolution Neural Network (CNN) model to enable a mobile robot to detect objects in its scene in a real-time manner. The integration of two CNN models (SSD and MobileNet) is performed and implemented on mobile robot RAICO (Robot with Artificial Intelligence based COgnition). The experimental results show that the proposed perception system enables a high degree of object recognition with satisfying inference speed, even with limited processing power provided by Nvidia Jetson Nano integrated within RACIO.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-05230-9_80,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-92574-1_21,"Automatic Navigation Research for Multi-directional Mobile Robots on the Basis of Artificial Intelligence Application, Q-Learning Algorithm",Advances in Engineering Research and Application,10.1007/978-3-030-92574-1_21,Springer,2022-01-01,"In this article, research on the applications of artificial intelligence in implementing reinforcement learning is a subset of machine learning that deals with learning decisions from rewards given by the environment. Classic reinforcement learning algorithms are usually applied to small sets of states and actions. However, in real applications, the state spaces are of a large scale and this will bring the problems of the generalization and the curse of dimensionality. In this paper, we integrate neural network into reinforcement learning methods to generalize the value of all the states. Simulation results on the Gazebo framework show the feasibility of the proposed method. The robot can complete navigation tasks safely in an unpredicted dynamic environment and becomes a truly intelligent system with strong self-learning and adaptive abilities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-92574-1_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-6554-7_35,Policy Gradient Reinforcement Learning Method for Backward Motion Control of Tractor-Trailer Mobile Robot,Proceedings of the 11th International Conference on Computer Engineering and Networks,10.1007/978-981-16-6554-7_35,Springer,2022-01-01,A policy gradient reinforcement learning method for backward motion control of tractor-trailer mobile robot is proposed in this paper. The kinematic model is built firstly. Then the control action of mobile robot is trained by reinforcement learning. Policy gradient (PG) learning algorithm is designed to train the backward control action of the TTMR system. The PG based neural network structure is constructed and the parameters of neural network are updated through the PG method. The mobile robot learns a strategy by finite iterations finally. The experimental results show that the mobile robot can reverse the trailer stably in large enough iterations. The designed learning method based on PG algorithm is effective in the motion control of mobile robot with trailer.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-6554-7_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-12848-6_5,Understanding Machine Learning Through AI-powered Educational Robotics - Pilot Study with Undergraduate Students,Robotics in Education,10.1007/978-3-031-12848-6_5,Springer,2022-01-01,"Artificial Intelligence (AI) has influenced practically every aspect of our lives in recent years and its speed of development is accelerated every year. Many children may have used or seen AI-assistants in action. There is a broader understanding among politicians, industries, and educators across fields from computer science, AI, to education that it is crucial to promote AI literacy in K-12 schools. What is specifically urgent is to prepare K-12 students for their future professions, which might not currently exist, and become citizens capable of understanding and utilizing AI-enhanced technologies in the right way in the future so that they would not benefit some populations over others. There have been various initiatives developed focusing on promoting AI literacy from around the world. This paper reports a AI-powered educational robotics tool and the process that a group of undergraduate students went through in the development of an AI-powered educational robotics projects introducing AI literacy, specifically machine learning and training data. It specifically focuses on their experience creating training data for object recognition that they used with their robot and, as a result, it has deepened their understanding of what they intend to teach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-12848-6_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-021-11643-z,Modeling and assessing an intelligent system for safety in human-robot collaboration using deep and machine learning techniques,Multimedia Tools and Applications,10.1007/s11042-021-11643-z,Springer,2022-01-01,"The introduction of technological innovations is essential for accident mitigation in work environments. In a human-robot collaboration scenario, the current number of accidents raises a safety problem that must be dealt. This work proposes an intelligent system that aims to address such problems using deep and machine learning techniques. More specifically, this solution is divided into two modules: (i) collision detection between humans and robots and (ii) worker’s clothing detection. We evaluated these modules separately and concluded that the proposed intelligent system is efficient in supporting safe human-robot collaboration. The results achieved a sensitivity level greater than 90% in identifying collisions and an accuracy above 94% in identifying the worker’s clothing.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11042-021-11643-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-11647-6_43,"A Teacher without a Soul? Social-AI, Theory of Mind, and Consciousness of a Robot Tutor","Artificial Intelligence in Education. Posters and Late Breaking Results, Workshops and Tutorials, Industry and Innovation Tracks, Practitioners’ and Doctoral Consortium",10.1007/978-3-031-11647-6_43,Springer,2022-01-01,"Is consciousness required for social robots to serve as a tutor? This study explored the effects of a tutor robot’s social-AI on participants’ perception of social robots’ Theory of Mind abilities, perception of social robots’ consciousness, and acceptance of social robots in education. We were also interested in the relationships between these variables. One hundred and twenty participants from Amazon Mechanical Turk were randomly assigned to one of four conditions. The participants completed an online survey that included two short videos of a robot tutor interacting with a student, followed by several questionnaires. We manipulated the robot’s social-AI abilities with respect to two social abilities: emotion Expression and Detection, resulting in a 2 × 2 controlled research design. Participants’ responses to the Social Robots Theory of Mind Assessment Scale revealed that the robot’s social AI behavior had an impact on its perceived ability to detect and influence others’ feelings. Perceptions of social robots’ TOM and consciousness had a significant positive correlation with acceptance of social robots in education.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-11647-6_43,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85318-1_75,Remarks on a Quaternion Neural Network-Based Controller Applied to a Three-Link Robot Manipulator,15th European Workshop on Advanced Control and Diagnosis (ACD 2019),10.1007/978-3-030-85318-1_75,Springer,2022-01-01,"In this study, the application of a quaternion neural network to control a robot manipulator is investigated. The quaternion neural network is a multilayer feed-forward network with a split-type activation function of neurons and that uses a tapped-delay-line input. In the control system, a feedback error-learning scheme is used to train the network. In the computational experiments, a three-link robot manipulator is controlled using the proposed quaternion neural network-based controller, and the simulation results demonstrate the feasibility of the proposed controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-85318-1_75,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-82544-7_26,AI-Powered Educational Robotics as a Learning Tool to Promote Artificial Intelligence and Computer Science Education,Robotics in Education,10.1007/978-3-030-82544-7_26,Springer,2022-01-01,"AI is considered as a rapidly advancing technological domain capable of altering every aspect of our lives and society. Many children may have used AI-assistants, and some have had the privilege of growing up with AI-assistants or AI-assisted smart devices in their homes. Educators across fields from computer science, AI, to education strongly suggest that it is crucial to help people understand the science behind AI, its limits, and potential societal impacts in our everyday lives as well as in the future. What is specifically urgent is to prepare K-12 students for their future professions, which might not currently exist, and becoming citizens capable of understanding and utilizing AI-enhanced technologies in the right way in the future so that they would not benefit some populations over others. AI4K12, a joint project between CSTA (CS Teacher Association) and AAAI (Association for Advancing Artificial Intelligence, is developing K-12 AI guidelines for teachers and students organized around the Five Big Ideas in AI which were introduced in 2019. Aligned with Computer Science Standards and the standards of the core subjects, the Five Big Ideas in AI can guide students’ learning of AI while learning computer science concepts and the concepts of other subjects. This position paper explores the idea to promote computing education, including computer science and computational thinking skills, and AI education through AI-powered educational robotics as a motivating learning tool.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-82544-7_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-96737-6_1,"Deep Learning in Robotics for Strengthening Industry 4.0.: Opportunities, Challenges and Future Directions",Robotics and AI for Cybersecurity and Critical Infrastructure in Smart Cities,10.1007/978-3-030-96737-6_1,Springer,2022-01-01,"The twenty-first century is undergoing a fundamental transition in the way things are created and services are provided. The digitalization of services has resulted in a compelling, major change in the sector, which is now referred to as Industry 4.0. One of the major changes embracing this industrial revolution is the development of robotics. Today, with the tasks becoming increasingly complex, robots are more trusted to perform the tasks with accuracy. They are rapidly substituting human skills in terms of speed, accuracy, and replaceability. Over the years, they have made vital contributions to some of the major industries, like 3D printing, autonomous vehicles, computer chip building, health and safety, agriculture, and so on. Robotics is a key Industry 4.0 technology that gives significant possibilities in the realm of production. However, with the introduction of Industry 4.0, it has become increasingly impossible for a corporation to remain relevant without incorporating some type of intelligent technology. Big data, which is generated by a wide range of sensors, necessitates complicated systems capable of distilling usable information and making intelligent judgments. This is where technology such as artificial intelligence and deep learning may help. The major result of combining these technologies with modern robotics is the creation of intelligent factories that are very powerful, safe, and cost-effective. The current research discussed the function of deep learning in robots for bolstering Industry 4.0. The authors discussed the various ways in which deep learning algorithms may be employed to improve the performance of robotics systems. Object identification, robotic grip, acoustic modelling, and motion control are the four key subjects covered in the article. A subsequent study discusses some of the significant problems for the same.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-96737-6_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-92442-3_8,A Novel Gradient Feature Importance Method for Neural Networks: An Application to Controller Gain Tuning for Mobile Robots,"Informatics in Control, Automation and Robotics",10.1007/978-3-030-92442-3_8,Springer,2022-01-01,"In the paper, a novel gradient-based feature importance method for neural networks is described. This method is compared to the existing feature importance method using a trained neural network, which predicts the optimal gains in real time, for a steering controller on a mobile robot. The neural network is trained using the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) algorithm, in order to minimize an objective function. From an analysis using the feature importance methods, key inputs are determined, and their contribution to the neural network’s prediction are observed. Furthermore, using a first-order Taylor approximation of the neural network, an improved control law is determined and tested based on the results of the gradient-based feature importance method. This analysis is then applied to an existing neural network using real-world experiments, in order to determine the behavior of the gains with respect to each input, and allows for a glimpse into the neural network’s inner workings in order to improve its explainability.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-92442-3_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-90618-4_5,AI-Based Smart Robot for Restaurant Serving Applications,AI and IoT for Sustainable Development in Emerging Countries,10.1007/978-3-030-90618-4_5,Springer,2022-01-01,"With magnetic trail and infrared matching techniques, limitation in paths and high processing create difficulties in restaurant serving techniques. This article provides a user-friendly serving system by adopting real-time image processing and robot guidance application. SLAM (A technology used by Japan for simultaneously localizing and mapping) can overcome the above-mentioned difficulties but is much costly and has slow processing. To overcome SLAM drawbacks, all map localization processing has been shifted on a server processor which made RSR (Restaurant Serving Robot) less costly than other techniques. RSR is fully equipped by modern innovations in AI (Artificial Intelligence). Map localization in server knows about the little movement in restaurant hall and decides appropriate path for a robot. A restaurant serving robot is a real-time path deciding robot which is designed using simulation software, camera, a database for predefined paths, an android application, a WLAN communication system, and a robot based on Arduino. Simulation software gets real time frames from the camera, declares appropriate path, and keep an eye on serving robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-90618-4_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-98015-3_15,Accelerated Reward Policy (ARP) for Robotics Deep Reinforcement Learning,Advances in Information and Communication,10.1007/978-3-030-98015-3_15,Springer,2022-01-01,"Reward policy is a crucial part for Deep Reinforcement Learning (DRL) applications in Robotics. The challenges for autonomous systems with “human-like” behavior have posed significant need for a better, faster, and more robust training based on optimized reward function. Inspired by the Berkeley and Google’s work, this paper addresses our recent development in reward policy/function design. In particular, we have formulated an accelerated reward policy (ARP) based on a non-linear functions. We have applied this reward function to SAC (Soft Actor Critic) algorithm for 6 DoF (Degree of Freedom) robot training in simulated environment using Unity Gaming platform and a 6 DoF robot. This nonlinear ARP function gives bigger reward to accelerate the robot’s positive behavior during the training. Comparing to the existing algorithm our experimental results demonstrated faster convergence and bigger, better accumulative reward. With limited experimental data, the results show improved accumulative reward function as much as 2 times of the previous results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-98015-3_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-8997-0_14,Understanding the Utilization of Artificial Intelligence and Robotics in the Service Sector,"The Impact of Artificial Intelligence on Governance, Economics and Finance, Volume 2",10.1007/978-981-16-8997-0_14,Springer,2022-01-01,"Artificial Intelligence (AI) is increasingly posing a threat to human service jobs in several sectors. According to projections, AI will put a remarkable percent of service sector employment at risk, including a wide range of jobs. Since AI offers chances to improve service provision efficacy and enhance consumer engagement, it is expected that artificial intelligence and service robots will become widespread in many countries. It is anticipated that service provision tasks will be affected by automation and artificial intelligence in different ways. Regarding the replacement of jobs, it is envisaged that job designs will transform on a task-based rather than top-down basis, with simple cognitive and analytical tasks being performed first by service robots, and then complex emotional and social tasks are likely to be supported by robot-human collaboration. As a result, it is critical to assess artificial intelligence as it penetrates every aspect of our life, particularly in terms of consumer acceptance & use and the service industry, where it is perceived as a significant threat to service jobs. Depending on the predictions regarding the widespread applications of AI shortly and the change of job designs in the service sector, the evaluation of the current research in the area is critical for reducing the gap between practitioners and academic studies. Until far, most AI for service research has classified the service tasks and attempted to explain how the transformation of jobs can take place on a task basis. On the other hand, some research has conceptually discussed the potential benefits and drawbacks of AIs in the service industry. A stream of research has empirically measured user acceptance of different AI applications, their antecedents, and consequences. Hence, this chapter aims to synthesize and discuss the previous literature findings to have a broad understanding of the current research output. Some literature gaps, particularly in terms of human-robot interaction, have been identified, and avenues for future research have been emphasized. Finally, a roadmap for future research is presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-8997-0_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89508-2_20,Adaptive Sliding Mode Control of Crawler Robot Based on Fuzzy Neural Network,The 2021 International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy,10.1007/978-3-030-89508-2_20,Springer,2022-01-01,"For the nonlinear system with structural instability and parameter uncertainty, this paper combines neural network theory and sliding mode control based on fuzzy neural network and designs a controller for the control problem of uncertain nonlinear system. This paper first establishes the kinematic model of crawler robot, based on adaptive sliding mode control theory, equivalent controller and switching controller based on fuzzy neural network theory to ensure the global stability and convergence of the controller. Simulation s demonstrate that it are highly adaptive and robust to the s system, a nonlinear system of crawler robot, using neural networks. And has the characteristics of rapid response and strong tracking performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89508-2_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7011-4_45,Analytical and Deep Neural Network Based Hybrid Modelling of Single-Segment Continuum Robot,Proceedings of International Conference on Industrial Instrumentation and Control,10.1007/978-981-16-7011-4_45,Springer,2022-01-01,"Hyper-redundancy and ability to propagate through complex curvilinear pathways have made the continuum robots immensely popular in different fields of application. Precise control of continuum robot position relies on the accurate knowledge of the manipulator kinematics. However, the inverse kinematic model of continuum robots based on analytical modelling fails to include the unmodeled dynamics and effect of disturbances due to gravity and friction resulting in low accuracy in modelling and control. On the other hand, purely data driven continuum models require huge amount of data and time for training and suffer from high inaccuracy in modelling as well. Hybrid modelling in this scenario has been perceived to achieve better accuracy by combining the advantages of these two modelling approaches. Therefore, in the present work, we focus on the inverse kinematics of the single-segment continuum robot by using the analytical and deep neural network based hybrid modelling approach. Experimental results indicate that the proposed method increases the modelling accuracy and also at the same time it reduces the network training time significantly.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7011-4_45,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-08341-9_6,AI-Driven Intent-Based Networking for 5G Enhanced Robot Autonomy,Artificial Intelligence Applications and Innovations. AIAI 2022 IFIP WG 12.5 International Workshops,10.1007/978-3-031-08341-9_6,Springer,2022-01-01,"Innovative 5G orchestration architectures so far, have been mainly designed and optimized for Quality of Service (QoS), but are not aware of Quality of Experience (QoE). This makes intent recognition and End-to-End interpretability an inherited problem for orchestration systems, leading to possible creation of ineffective control policies. In this paper, an AI-driven intent-based networking for autonomous robots is proposed and demonstrated through the 5G-ERA project. In particular, to map an intent from individual vertical action to a global OSM control policy, a workflow of four tools is proposed: i) Action Sequence Generation, ii) Network Intent Estimation, iii) Resource Usage Forecasting, and iv) OSM Control Policy Generation. All of these tools are described in the paper with specific function descriptions, inputs, outputs and the semantic models/Machine Learning tools that have been used. Finally, the paper presents the developed intent-based dashboard for the visualization of the tools’ outputs, whilst taking QoE into consideration.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-08341-9_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-83620-7_12,Robotics in Healthcare,Handbook of Artificial Intelligence in Healthcare,10.1007/978-3-030-83620-7_12,Springer,2022-01-01,"A robot is a programmed actuated mechanism with a degree of autonomy. Medical robots came a long way since first prototypes based on industrial robots in the 1960s-70 s to become modern complex systems that assist surgeons, patients, and nurses. Over time, robots proved their usefulness and evolved for the ability to operate in confined spaces inside human bodies, help people recover the functions of injured limbs, or provide support to physically and cognitively impaired persons. This chapter provides an overview along with the challenges of current robotics in healthcare.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-83620-7_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-8170-7_15,Romancing & Dancing With Robots,Inventions in Sociology,10.1007/978-981-16-8170-7_15,Springer,2022-01-01,"In this chapter, the author introduces sociological tools for studying and understanding robots in the context of brain and mind studies. He makes a distinction between “social robots” and “sociable robots.” “Social robots” are designed for social interaction with humans on human terms—they are capable in principle of expressing emotions, demonstrating consciousness, and thinking and moving about autonomously. “Sociable robots,” by contrast, are designed for friendly companionship, teddy bears with computer chips. Robots have been advertised as technological boons to human life and on the other hand as existential threats. The author claims that robots are human creations and we have nothing more to fear from them than we do from our fellow humans. Robot engineers have traditionally relied on psychological and biological theories for programming robots. They will have to draw on sociology to construct social robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-8170-7_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-12848-6_17,"Software Testing, AI and Robotics (STAIR) Learning Lab",Robotics in Education,10.1007/978-3-031-12848-6_17,Springer,2022-01-01,"In this paper we presented the Software Testing, AI and Robotics (STAIR) Learning Lab. STAIR is an initiative started at the University of Innsbruck to bring robotics, Artificial Intelligence (AI) and software testing into schools. In the lab physical and virtual learning units are developed in parallel and in sync with each other. Its core learning approach is based the develop of both a physical and simulated robotics environment. In both environments AI scenarios (like traffic sign recognition) are deployed and tested. We present and focus on our newly designed MiniBot that are both built on hardware which was designed for educational and research purposes as well as the simulation environment. Additionally, we describe first learning design concepts and a showcase scenario (i.e., AI-based traffic sign recognition) with different exercises which can easily be extended.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-12848-6_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7618-5_25,From Simulation to Deployment: Transfer Learning of a Reinforcement Learning Model for Self-balancing Robot,Proceedings of International Conference on Information Technology and Applications,10.1007/978-981-16-7618-5_25,Springer,2022-01-01,"Reinforcement learning algorithms are time and resource-intensive and can be influenced by the setup of the physical robot environment and its hardware capabilities. Often, in small-scale projects, it is not workable to build a physical robot equipped with good processing capabilities and to set up a fully controlled and monitored environment for reinforcement learning. During this period, it will be more cost-effective for most of the training to be conducted in a simulated environment and then transferred to a physical robot. In this project, two RL experiments were conducted on a simple two-wheeled robot model in a simulated environment. The first was to make the robot start from a completely fallen down position and learn to stand, and the second to start from a balanced position and learn to maintain the position. It was found that starting from a balanced position gave a better performance, and hence, this learned model was used as a baseline for testing on a physical robot such as the LEGO Mindstorms, but it could be seen that the LEGO hardware was not well suited for this kind of intense reinforcement learning algorithms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7618-5_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-98682-7_14,rSoccer: A Framework for Studying Reinforcement Learning in Small and Very Small Size Robot Soccer,RoboCup 2021: Robot World Cup XXIV,10.1007/978-3-030-98682-7_14,Springer,2022-01-01,"Reinforcement learning is an active research area with a vast number of applications in robotics, and the RoboCup competition is an interesting environment for studying and evaluating reinforcement learning methods. A known difficulty in applying reinforcement learning to robotics is the high number of experience samples required, being the use of simulated environments for training the agents followed by transfer learning to real-world (sim-to-real) a viable path. This article introduces an open-source simulator for the IEEE Very Small Size Soccer and the Small Size League optimized for reinforcement learning experiments. We also propose a framework for creating OpenAI Gym environments with a set of benchmarks tasks for evaluating single-agent and multi-agent robot soccer skills. We then demonstrate the learning capabilities of two state-of-the-art reinforcement learning methods as well as their limitations in certain scenarios introduced in this framework. We believe this will make it easier for more teams to compete in these categories using end-to-end reinforcement learning approaches and further develop this research area.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-98682-7_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-6320-8_72,A Reinforcement Learning Mission Supervisor with Memory for Human-multi-robot Coordination Systems,Proceedings of 2021 Chinese Intelligent Systems Conference,10.1007/978-981-16-6320-8_72,Springer,2022-01-01,"In this paper, a novel reinforcement learning mission supervisor (RLMS) with memory is proposed for human-multi-robot coordination systems (HMRCS). The existing HMRCS are known to suffer from long decision waiting time and large mission error caused by repeated human intervention, restricting the autonomy of multi-robot systems. The proposed supervisor elaborately integrates deep-Q-network (DQN) and long-short-term memory (LSTM) knowledge base within the null-space based behavioral control (NSBC) framework, so as to achieve optimal adjustment strategy of the behavioral priority in the presence of mission conflicts, and to reduce the frequency of human intervention. In particular, the proposed RLMS with memory first memorize human intervention history when robot systems are not confident in decision making when encountering emergencies, and then reload the history information when encountering the same situation that have been tackled by human previously. Simulation demonstrates the effectiveness of proposed RLMS with memory.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-6320-8_72,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-3844-2_53,Multi-Agent Reinforcement Learning for Robot Collaboration,"Robotics, Machinery and Engineering Technology for Precision Agriculture",10.1007/978-981-16-3844-2_53,Springer,2022-01-01,"The paper is devoted to the problems of implementation of intelligent multi-agent systems for monitoring the state of complex infrastructure objects by applying the paradigm of reinforcement learning. The aim of the work is to analyze intelligent multi-agent systems (using the example of monitoring complex infrastructural objects) and adapt their structural components, as well as the methodological apparatus for applying the reinforcement learning method. The following problems are being solved: analysis of intelligent multi-agent systems for monitoring the state of complex infrastructure facilities; analysis of the typical structure of individual intelligent agents; analysis of computer vision subsystems, training, implementation of agent's behavioral strategies, identification of the main problems of the implementation of these components, taking into account the characteristics of complex infrastructure objects. The following results were obtained: the structure of the block for the reconstruction of three-dimensional scenes was proposed, which is based on the use of convolutional neural networks of various types (Mask R-CNN, Siamese networks, generative adversarial networks), which makes it possible to construct three-dimensional models of complex infrastructure objects in an automatic mode with the ability to work with unstructured set of images, as well as performing occlusion processing; an algorithm for segmentation of macro-actions based on the method of distribution of labels has been developed, which makes it possible to take into account the weight coefficients of the edges of the transition graph; an algorithm for the functioning of a centralized multi-agent system has been developed within the framework of the reinforcement learning paradigm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-3844-2_53,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-4083-4_33,Automation in Robotics with Artificial Intelligence,"Recent Trends in Design, Materials and Manufacturing",10.1007/978-981-16-4083-4_33,Springer,2022-01-01,"This document provides an introduction to man-made brain power, robots, and experimental streams that look at the financial and physiological consequences of this and other related innovations. We present a preliminary assessment of man-made knowledge and expertise to work on financial matters with writing managers and integrate existing methods adopted by investigators here. We look at the understanding of non-counterfeit fraud, mechanical autonomy, and the use of system sequences and robust systems, striving for the most remarkable commitment to these points by authoritative and technical analysts, as well as photographs of future experiments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-4083-4_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-98092-4_20,Automatic Image Labelling for Deep-Learning-Based Navigation of Agricultural Robots,"Safety, Health and Welfare in Agriculture and Agro-food Systems",10.1007/978-3-030-98092-4_20,Springer,2022-01-01,"The aim of this work is to define a procedure for the automatic labeling of images used for the training of a deep neural network which is used to learn a direct mapping from images to steering angles and collision probabilities. A state-of-the-art convolutional neural network for robotic vehicle navigation is used, which has been adapted to work for ground vehicles. Steering angles and collision probabilities are then used to generate respectively the angular and the linear velocity commands to drive a tracked vehicle through rough unstructured terrains, as those typically encountered in agricultural applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-98092-4_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-97269-1_18,"Relevance of the National Program of Automatic, Robotics and Artificial Intelligence Projects in Applications",Artificial Intelligence in Project Management and Making Decisions,10.1007/978-3-030-97269-1_18,Springer,2022-01-01,"The use of Automation Robotics and Artificial Intelligence is one of the ways for the effective use of resources, since it guarantees a constant quality and contributes to the technological discipline and in essence a driving force behind the development of the economy and the society in general. The Ministry of Science, Technology and Environment of Cuba, created a National Program of Projects to promote these scientific disciplines and the application and generalization of their results. The work highlights the importance of the interdisciplinary nature of the Program and demonstrates the need, for the successful execution of projects, of the application of correct methologies as a guide to design and development work. It shows, through the converge of Control and Machine Learning Theory in the Iterative Learning Control, how addressing these issues together helps to promote them. The operation of deep reinforcement algorithms is explained and how their applications in robotic allows themto accelerate their development and make their behavior more flexible in an autonomous way. Finally, through three projects that are developed in the program, the relevance of the interdisciplinary conception of the program is demonstrated to carry out the doctoral research topics corresponding to each project.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-97269-1_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-82544-7_27,An Interactive Robot Platform for Introducing Reinforcement Learning to K-12 Students,Robotics in Education,10.1007/978-3-030-82544-7_27,Springer,2022-01-01,"As artificial intelligence (AI) plays a more prominent role in our everyday lives, it becomes increasingly important to introduce basic AI concepts to K-12 students. To help do this, we combined the physical (LEGO® robotics) and the virtual (web-based GUI) worlds for helping students learn some of the fundamental concepts of reinforcement learning (RL). We chose RL because it is conceptually easy to understand but received the least attention in previous research on teaching AI to K-12 students. Our initial pilot study of 6 high school students in an urban city consisted of three separate activities, run remotely on three consecutive Friday afternoons. Students’ engagement and learning were measured through a qualitative assessment of students’ discussions and their answers to our evaluation questions. Even with only three sessions, students were optimizing learning strategies, and understanding key RL concepts and the value of human inputs in RL training.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-82544-7_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-04870-8_11,Towards Dynamic Obstacle Avoidance for Robot Manipulators with Deep Reinforcement Learning,Advances in Service and Industrial Robotics,10.1007/978-3-031-04870-8_11,Springer,2022-01-01,"We use reinforcement learning (RL) to demonstrate an easily reproducible setup to learn dynamic obstacle avoidance for a robotic arm based on sensory input as it follows a pre-planned trajectory. Training takes place exclusively in a simulation environment with random obstacle movements around the robot. We show that training dynamic obstacle avoidance in simulation translates well to the real environment with a UR5 manipulator and yields similar performance and success without further tuning of the learned policy. This is a step towards learning general skills needed to enable robots to operate in dynamic environments shared with humans. Source code, data and application videos are available at:  https://www.robogym.net .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-04870-8_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-64573-1_256,Artificial Intelligence in Trauma and Orthopedics,Artificial Intelligence in Medicine,10.1007/978-3-030-64573-1_256,Springer,2022-01-01,"This chapter will explore artificial intelligence (AI) in trauma and orthopedics (orthopedics). Orthopedics is a branch of surgery that focuses on the prevention of musculoskeletal pathology and the correction and restoration of form and function of these structures. Orthopedics is fertile ground for adoption of technological innovations, including artificial intelligence, where small gains in the treatment of one condition can lead to improved outcomes for some of the largest patient populations in medicine. Orthopedics is well suited to innovation and the application of AI as it has clear pathways for common diseases and is a highly technical field with constant technical innovation. This chapter will review several of the key applications of AI in orthopedics including diagnostics, intraoperative robotics, and predictive analytics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-64573-1_256,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-6324-6_64,A Multi-view Recognition Technology Based on the Prediction of Active Robot’s Optimal Viewing Angle,Proceedings of 2021 Chinese Intelligent Systems Conference,10.1007/978-981-16-6324-6_64,Springer,2022-01-01,"In task of multi-robots exploring unknown environments, the collaborative information between them can be used to improve the accuracy of object recognition. This paper proposes and implements a multi-view active learning model, which uses images obtained from different perspectives to improve the performance of target detection and recognition. Using robot clusters to obtain multi-view information of the target, through the promotion of the target detection network based on deep learning, the algorithm based on multi-view learning comprehensively utilizes the complementarity of multi-view information, combined with the initiative of multiple robots to estimate the best perspective, Constantly adjust the best observation angle of the cluster to improve the accuracy of target detection. The final experiment shows that the recognition rate of the active multi-view recognition technology proposed in this paper is 12% higher than that of a single view.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-6324-6_64,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-06053-3_39,Learning-Based Visual Acuity Test System with Pepper Robot for User Behavior Research,"Cross-Cultural Design. Product and Service Design, Mobility and Automotive Design, Cities, Urban Areas, and Intelligent Environments Design",10.1007/978-3-031-06053-3_39,Springer,2022-01-01,"Hand pose estimation based on deep learning is widely used in Human-Computer Interaction (HCI) field. This paper combines state-of-the-art hand pose estimation to build a gesture recognition model based on Long Short-Term Memory (LSTM) for a visual acuity test system with the Pepper robot. The size of the optotype is updated according to the distance between a user and the robot and displayed on the table. Experimental results show that the system is robust for users to perform well with different fingers. In the future, the HRI system is good to design a questionnaire to investigate users’ preferences which include acceptances, a distance of visual acuity test, sit or stand, number of fingers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-06053-3_39,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-04870-8_66,Assessment of the Human-Robot Collaborative Polishing Task by Using EMG Sensors and 3D Pose Estimation,Advances in Service and Industrial Robotics,10.1007/978-3-031-04870-8_66,Springer,2022-01-01,"Safe human-robot collaboration, especially considering ergonomics, still represents a challenging problem. The objective of this paper is to develop the procedure for assessing human-robot collaboration with the help of computer vision system and electromyography (EMG) data. The conducted study involved three participants performing the polishing task in four different configurations interacting with Franka Emika’s Panda Robot. The robot is controlled in the impedance mode to achieve safe human-robot interaction and, at the same time, to achieve desired robot impedance in the translational and the rotational axis. In order to study human kinematics, the experiment was recorded using four IP cameras, while muscle activity was measured by Trigno Avanti Duo sensors by Delsys to account for human dynamics in the contact task. The collected EMG signals were processed using a bandpass filter, a notch filter, envelope calculation, and normalization. The reconstruction of a human pose from the collected videos was performed using the VIBE algorithm, while body pose parameters (characteristic postural angles) were computed from the output SMPL parametric human model. The obtained results showed significant variations among different body configurations, as verified by the trend of the EMG signals. The proposed approach demonstrates the potential to be an effective tool for enhancing ergonomics in an industrial environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-04870-8_66,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-05740-3_18,Artificial Intelligence in Healthcare,Applied Artificial Intelligence in Business,10.1007/978-3-031-05740-3_18,Springer,2022-01-01,"This chapter explores the AI technologies in healthcare. We start with emphasis on a backward-chaining expert system MYCIN and IBM Watson for Oncology cognitive technology-incorporating and AI-integrating project. Then we describe the current AI technologies in healthcare like machine learning, artificial neural networks, computer vision, human unstructured natural language processing, and others. AI applications in healthcare like virtual nursing assistants, robot-assisted surgery, fraud detection, dosage error reduction, connected machines and clinical trial participant identifiers, diagnosis applications, and wearable tech are explored. Case studies include COTA Health, Babylon, and wearable technologies supporting AI in healthcare.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-05740-3_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-6309-3_33,Human–Robot Intermittency and Invariants,Intelligent Sustainable Systems,10.1007/978-981-16-6309-3_33,Springer,2022-01-01,"Heiden, Bernhard Tonino-Heiden, Bianca Alieksieiev, Volodymyr Isac Asimov’s famous “I, Robot” was an inspiration for many generations, and we are still before increasing daily applications of robots in our lives. From generation to generation, the idea of a robot becomes more realistic and less dystopic, as robots are becoming increasingly human and animal-like, hence, similar to our environment. Therefore, it becomes more and more a legitimate question: what is the difference between humans and robots? This paper investigates fundamental principles of some invariants between humans and robots. It gives a two-dimensional order map that relates robot and similarly human properties, where it seems that the human–robot gap becomes increasingly smaller. The interrelatedness of humans and robots increases robotic applications in Industry 4.0 and leads to a new definition of culture and humanity. Since Cartesian times, the notation of rationality is ceasing increasingly chaotic irrational behaviour. We systematically get an order increase by focussing on the paradoxically irrational and creative human part, his creative potential. This creative potential is what Roger Penrose relates to as non-algorithmic. Moreover, we will argue with six axioms why this is of human–robot existential importance. We then give a short logistic example as application and a conclusion and outlook.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-6309-3_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-3930-2_13,Robots as My Future Colleagues: Changing Attitudes Toward Collaborative Robots by Means of Experience-Based Workshops,"Ludic, Co-design and Tools Supporting Smart Learning Ecosystems and Smart Education",10.1007/978-981-16-3930-2_13,Springer,2022-01-01,"Artificial intelligence-driven robots are increasingly being introduced in various workplaces. Research implies that people’s negative attitudes toward intelligent and collaborative robots might hinder their willingness to use them. We propose that interactive educational activities such as specialized workshops help people to overcome such negative attitudes. We designed a two-day workshop that introduced two quasi-industrial robots (Poppy Ergo Jr and ClearBot) to 16 university students. Students’ attitudes were qualitatively measured before and after the workshop. The results imply that the workshop helped students to increase their understanding of the nature of the intelligent collaborative robots. More precisely, robots became to be seen as empowering tools, rather than friends or enemies. Interestingly, there were significant gender differences, as the female participants had a greater tendency to view robots as animated objects. We concluded that specialized workshops effectively lead participants to become aware of various promising opportunities for their robotic co-workers in the possible future.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-3930-2_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-19-0737-1_4,"The Impact of Artificial
Intelligence Educational Robots in the Field of Education: a PRISMA
Review",Current State of Art in Artificial Intelligence and Ubiquitous Cities,10.1007/978-981-19-0737-1_4,Springer,2022-01-01,"Education is an indispensable part of everyone's life. It lays the ground for the future generation and is a prerequisite for an independent life. It also determines the future of a country and a nation, and affects a country’s development. With the advancement of technology, the world has tremendous changes. People have changed their lifestyles and use new technologies for connecting, interacting, reading, and obtaining information. Hence education needs to adapt to the new era and changes in social customs. This research throws light on the impact of artificial intelligence robots on the education sector. We initially found one hundred thirteen articles published between 1999 and 2019 and only 18 articles meeting the criteria. We then categorise these studies into the following topics: (1) the impact of artificial intelligence educational robots on the creativity and motivation of students’ learning, and (2) the impact of artificial intelligence robots in education. This chapter comprises of six parts: the first part is the introduction, the second part summarises the purpose and research questions of this chapter, the third part is a literature review of educational robots concluding that robotics has a unique role in education, the fourth part discusses the research methods and survey results of this study, the fifth part provides a summary and discovery, and the last part is the conclusion.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-0737-1_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-0739-4_10,Robots and Artificial Intelligence: An Aid to Dependent People,Information and Communication Technology for Competitive Strategies (ICTCS 2020),10.1007/978-981-16-0739-4_10,Springer,2022-01-01,"In the world of digitalization and automation, there were astonishing myths coexistent that were not only surprising, but also incredible. Whilst the move is on to usher into the world of automation, where even the manufacturing units are devising the methods to automate their functions, it is only ironic to note that people have also developed several myths on using a robot. For one, robots have been associated with a device that would take away one job. For another, a robot is considered risky as if it will start ruling the very person that made it. Apparently, a research gap exists that needs to be plugged along with the understanding gaps to demystify the use of robots. COVID-19 has brought the world to such a stage where companies are now rethinking about the use of robots. This paper is written to explain the use of robots, clarify the need of robots in the society and present the growing demand of this technology. A research was also conducted to present the availability and state-of-art robot technology. It was also shown in the paper as to how some domains like health care are in dire need of robots, as the pandemic continues to wreak havoc on society.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-0739-4_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-12848-6_2,Implementation of a Multi-disciplinary Robotics Curriculum for master’s Student: The Use Case of AMSCC^1 International Semester,Robotics in Education,10.1007/978-3-031-12848-6_2,Springer,2022-01-01,"Designing a complete semester curriculum in robotics from scratch is a challenging task, especially in the context of multidisciplinary teaching using lecturers from the computer science, electronics, mathematics, and physics-mechanics departments. This task is even more complex for a semester offered to local and European students, adding a level of heterogeneous background, even at a bachelor’s degree in STEM. This article emphasizes on a robotics projects-oriented approach to overcome the numerous and various challenges at hand. It will also describe the requirements to fulfill introducing general guidelines considered during the design process. The hardware specifications of the robots and the computing platform are then explained. During the implementation step, a focus is given on the more efficient way to introduce Robot Operating System (ROS) to students. We propose a nice and efficient solution that has been experimented during the first iteration of the semester. It showed to give interesting results, both from the students and the teaching team point of view.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-12848-6_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-98404-5_30,Smart Trashcan Brothers: Early Childhood Environmental Education Through Green Robotics,Intelligent Human Computer Interaction,10.1007/978-3-030-98404-5_30,Springer,2022-01-01,"One of the main concerns of modern life would be the potential risk of irreversible ecological damage. However, due to the lack of focus on the subject within education, this type of risk will only get worse when being left unattended. This is where the robotics system, known as the “Smart Trashcan Brothers”, can provide better environmental consciousness with the current, younger generation attending primary school. This paper goes over the concepts that make up the Smart Trashcan Brothers system, as well with a functional evaluation to verify that the described parts of the robotics system function as intended. From there, a discussion of future works will be brought up with regards to further Child Human Interaction works.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-98404-5_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-05643-7_24,Object Size Prediction from Hand Movement Using a Single RGB Sensor,Artificial Intelligence in HCI,10.1007/978-3-031-05643-7_24,Springer,2022-01-01,"Human intention prediction is essential, among others, for safe and fluent human-robot collaboration. Prediction of the intention from human movement offers the advantage of a context-free paradigm. Naturally, such robot capabilities require high spatial and temporal resolution. While certain sensing devices, such as the motion capture systems, satisfy these requirements, in many applications visual sensors might be preferable. However, the information regarding human movement from RGB-D cameras is noisy and of lower frequency. In the present work, we study if it is possible to predict human intentions from hand movements observed by a single RGB-D sensor. We collected data from eight participants as they were grasping objects of three different sizes. OpenPose was used to extract the 2D hand and arm joint pixel coordinates that were then processed to extract human movement kinematic information and engineer appropriate features. Traditional machine learning methods were applied to evaluate the usability of our dataset. Overall, the results were significantly above chance level and showed that it is possible to predict the size of the object a human intents to grasp using hand kinematics extracted from a single visual sensor. Finally, it is feasible, under certain conditions, to use this prediction in real-time human-robot collaboration.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-05643-7_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-05740-3_13,"Artificial Intelligence in Credit, Lending, and Mortgage",Applied Artificial Intelligence in Business,10.1007/978-3-031-05740-3_13,Springer,2022-01-01,"This chapter presents AI technology development in the credit and mortgage industry. It explores AI applications in various areas of the industry like predictive analytics applications, customer service chatbots, robo-advisor, credit scoring and others. Types of AI technologies used in credit and mortgage include machine learning (deep learning, supervised and unsupervised), natural language processing, expert systems, virtual agents, machine vision, speech processing, digital footprint analysis, and accounting automation. Case studies on lending platforms and related implementation of artificial intelligence tools include Upstart, Affirm, and Monedo.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-05740-3_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-19-0737-1_3,Artificial Intelligence Robot Safety: A Conceptual Framework and Research Agenda Based on New Institutional Economics and Social Media,Current State of Art in Artificial Intelligence and Ubiquitous Cities,10.1007/978-981-19-0737-1_3,Springer,2022-01-01,"According to “Huang's law”, Artificial intelligence (AI)-related hardware increases in power 4–10 times per year. AI can benefit various stages of real estate development, from planning and construction to occupation and demolition. However, Hong Kong's legal system is currently behind when it comes to technological abilities, while the field of AI safety in built environments is still in its infancy. Negligent design and production processes, irresponsible data management, questionable deployment, algorithm training, sensor design and/or manufacture, unforeseen consequences from multiple data inputs, and erroneous AI operation based on sensor or remote data can all lead to accidents. Yet, determining how legal rules should apply to liability for losses caused by AI systems takes time. Traditional product liability laws can apply for some systems, meaning that the manufacturer will bear responsibility for a malfunctioning part. That said, more complex cases will undoubtedly have to come before the courts to determine whether something unsafe should be the manufacturer's fault or the individual's fault, as well as who should receive the subsequent financial and/or non-financial compensation, etc. Since AI adoption has an inevitable relationship with safety concerns, this project intends to shed light on responsible AI development and usage, with a specific focus on AI safety laws, policies, and people's perceptions. We will conduct a systematic literature review via the PRISMA approach to study the academic perspectives of AI safety policies and laws and data-mining publicly available content on social media platforms such as Twitter, YouTube, and Reddit to study societal concerns about AI safety in built environments. We will then research court cases and laws related to AI safety in 61 jurisdictions, in addition to policies that have been implemented globally. Two case studies on AI suppliers that sell AI hardware and software to users of built environment will also be included. Another two case studies will be conducted on built environment companies (a contractor and Hong Kong International Airport) that use AI safety tools. The results obtained from social media, court cases, legislation, and policies will be discussed with local and international experts via a workshop, then released to the public to provide the international community and Hong Kong with unique policy and legal orientations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-0737-1_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-6320-8_22,Path Planning for Mobile Robots Based on Improved Reinforcement Learning,Proceedings of 2021 Chinese Intelligent Systems Conference,10.1007/978-981-16-6320-8_22,Springer,2022-01-01,"This paper proposed an improved reinforcement learning algorithm to optimize the path planning problem of the robot. First of all, in order to solve the problem that the robot spends invalid time exploring the optimal path in the initial exploration, this paper puts forward a target-oriented method based on artificial potential field and a way to deepen the learning process. So as to speed up the stability and speed of the robot learning, this paper proposed an improved hierarchical reinforcement learning algorithm, which can effectively solve the problem of sparse rewards in the process of robot moving, and the execution efficiency of the algorithm is significantly improved.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-6320-8_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-6320-8_68,Robot Path Planning via Deep Reinforcement Learning with Improved Reward Function,Proceedings of 2021 Chinese Intelligent Systems Conference,10.1007/978-981-16-6320-8_68,Springer,2022-01-01,"The robot path planning technology based on deep reinforcement learning algorithm enables the robot arm to realize intelligent trajectory planning and capture task in unknown environment. However, due to the characteristics of redundant degrees of freedom, continuous workspace and non-unique mapping between joint space and Cartesian space, deep reinforcement learning algorithms often have the problems of unnecessary exploration, slow learning efficiency, low accuracy and poor robustness. In order to improve this problem, this paper proposes a path planning algorithm based on twin delayed deep deterministic policy gradient (TD3) algorithm to train an end-to-end network between the expected pose and current joint space variables. In addition, to measure the tip position and attitude of the robot more reasonably, the reward function is improved to clarify its physical meaning. Training and testing in the simulation environment proved that this method can realize the auto-path planning and capture task. Compared with other reward function, this method can avoid unnecessary exploration and improved the convergence speed and robustness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-6320-8_68,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-6893-4_78,CNN-Based Obstacle Avoidance Using RGB-Depth Image Fusion,WITS 2020,10.1007/978-981-33-6893-4_78,Springer,2022-01-01,"In the last few years, deep learning has attracted wide interest and achieved great success in many computer vision related applications, such as image classification, object detection, object tracking, pose estimation and action recognition. One specific application that can greatly benefit from the recent advance of deep learning is robot vision-based obstacle avoidance. Vision-based obstacle avoidance systems are mostly based on classification algorithms. Most of these algorithms use either color images or depth images as the main source of information. In this paper, the aim is to investigate whether using information extracted from both types of images simultaneously would give better performance than using each one separately. To do this, we chose the convolutional neural network (CNN) as the classifier and HSV-based method to achieve the fusion. We tested this approach using two widely used pre-trained CNN architectures, namely Resnet-50 and GoogLeNet using a dataset locally collected. The results indicate that the image fusion-based classification algorithm achieve a higher accuracy (91.3%) than the one based on depth images (80.4%) but lower than the one based on color images (93.7%). These results can be partly explained by the fact that the used classifiers were pre-trained using color image datasets.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-6893-4_78,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-92574-1_24,Building Intelligent Navigation System for Mobile Robots Based on the Actor – Critic Algorithm,Advances in Engineering Research and Application,10.1007/978-3-030-92574-1_24,Springer,2022-01-01,"This article presents the construction of an intelligent automatic navigation system for mobile robots in a flat environment with defined and unknown obstacles. Programming tools used in the studies are the operating system for mobile robots (Robot Operating System – ROS). From the updated information on maps, operating environment, robot control position and obstacles (Simultaneous Localization and Mapping (SLAM)), we can calculate the motion trajectory of the mobile robot. The navigation system calculates the global and local trajectory for the robot based on the application of Actor-Critic (AC) algorithm. The results of simulation studies in the Gazebo environment and the experimental run on the real Turtlebot mobile robot showed the practical efficiency of automatic navigation for this mobile robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-92574-1_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-6372-7_36,Cooperative Control of Backstepping Neural Network and Port-Controlled Hamiltonian for Robot System,Proceedings of 2021 Chinese Intelligent Automation Conference,10.1007/978-981-16-6372-7_36,Springer,2022-01-01,"It is difficult for a single control method to track the position quickly and accurately at the end of the robot. To solve this problem, a cooperative control strategy of backstepping adaptive neural network (BS-RBFNN) signal control and port controlled Hamiltonian (PCH) energy control is proposed. BS-RBFNN solves the problem of rapidity when the system is in dynamic state, PCH control solves the problem of accuracy when the system is in steady state. The cooperative function based on the error is designed, and the cooperative control of the robot joint system is realized by using this function. The robot joint position servo system can not only realize the rapid adjustment of the dynamic position, but also realize the high precision tracking control in the steady state. Simulation results show that the system achieves fast dynamic response and accurate steady-state position tracking by using cooperative control method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-6372-7_36,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-72834-2_3,AI and Robotics in the Fight Against COVID-19 Pandemic,"Modeling, Control and Drug Development for COVID-19 Outbreak Prevention",10.1007/978-3-030-72834-2_3,Springer,2022-01-01,"The outbreak of the novel coronavirus and its disease COVID-19 present an unprecedented challenge for humanity. Artificial Intelligence (AI) and robotics may help fighting COVID-19. Potential applications of AI in this accelerating pandemic include, but are not limited to, early detection and diagnosis, massive agent modeling and simulation, data analytics, assistive robots, disinfection robots, public awareness and patrolling, contactless delivery services, virtual healthcare assistants, drug repurposing and vaccination discovery. This chapter sheds light on the roles AI and robotics can play in fighting this disastrous pandemic, and possible future ones, and highlights several potential applications to transform this challenge into opportunities. This chapter also discusses the ethical implications of AI and robotics during the pandemic and in the post-pandemic world.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-72834-2_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-2937-2_10,Object Recognition and Classification for Robotics Using Virtualization and AI Acceleration on Cloud and Edge,"Data Management, Analytics and Innovation",10.1007/978-981-16-2937-2_10,Springer,2022-01-01,"With the development of cloud robotics, a much broader scope of multidisciplinary applications to create smart systems is now available. The “Artificially Intelligent” system's brains are in the cloud. The cloud can hold data centers, deep learning, communication support, etc. With the help of edge computing, VM-based cloudlets, deploying deep learning implementation systems are a more practical option rather than one single system doing all the tasks. The mobile applications and IoT devices often produce streaming data which requires real-time analysis and control. When the application involves end devices as hardware like Raspberry Pi and laptops working at edge, an acceleration in the result generation is also necessary. This paper presents its observations with the implementation of one such machine learning application of object detection and recognition, i.e., You-Only-Look-Once (YOLO) on a robotic environment working on the number of clients and servers ends. Differentiating cloud and edge, we have demonstrated the analysis and results where output efficiency leverage is seen with AI acceleration with toolkits like Intel's OpenVINO.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-2937-2_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-4621-8_11,Using Artificial Intelligence in Dispute Resolution,Smart Technologies for the Digitisation of Industry: Entrepreneurial Environment,10.1007/978-981-16-4621-8_11,Springer,2022-01-01,"The authors investigate the features of the legal regulation of using artificial intelligence in dispute resolution. It was revealed that (1) To date, no generally accepted definition of “artificial intelligence” has been created; (2) Artificial intelligence can be divided into two levels—low-level (collection of materials, legal expertise, review of contracts, and alike) and strong-level (independent dispute resolution, robot judge); (3) The use of artificial intelligence of the first level (low-level) occurs everywhere—in courts, commercial arbitration, in mediation, and others; cases of using artificial intelligence of the second level (robot mediator) are rare; (4) However, if in the process a human judge is replaced by a robotic judge, then the result in this process (court decision) will be based solely on the algorithms used in the AI system program; therefore, the power of a court decision will not be in the hands of the judge, but in the hands of the programmer; in addition, if the decision is based solely on algorithms, then the goal of ensuring fairness will not be achieved in all cases; (5) The introduction of AI technologies in combination with a human judge may be more successful: (a) a robot can act as a court clerk; (b) the AI can manage the analyzed documents before the decision is made and answer the questions asked by the judge during the final decision; (c) the robot can perform the functions of an expert and present an expert opinion to the court based on the evidence presented during the trial.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-4621-8_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-87869-6_11,Visually Monitoring the Performance of a Component-Based Robot,16th International Conference on Soft Computing Models in Industrial and Environmental Applications (SOCO 2021),10.1007/978-3-030-87869-6_11,Springer,2022-01-01,"The ever-increasing complexity of robots usually implies a parallel increase in the number of failures of such systems. Due to this, monitoring and anomaly detection plays a key role in the implementation of smart robotics and soft computing can significantly contribute to this task. In keeping with this idea, recently proposed Hybrid Unsupervised Exploratory Plots (HUEPs) are proposed in present paper to monitor the performance and improve anomaly detection in a component-based robotic software. Furthermore, the original HUEP formulation is extended by means of density-based clustering. Such clustering techniques are validated in conjunction with unsupervised exploratory projection ones. This novel proposal is validated on an open and up-to-date dataset containing information about the software performance of a collaborative robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-87869-6_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-2814-6_17,Approach to Image-Based Segmentation of Complex Surfaces Using Machine Learning Tools During Motion of Mobile Robots,Electromechanics and Robotics,10.1007/978-981-16-2814-6_17,Springer,2022-01-01,"In development of formation control systems for modular robotic devices, especially relevant is the problem of analysis and, particularly, segmentation of complex surfaces, down which the robotic device will move. An approach based on fine-tuning of a neural network model HRNet was developed to solve the problem of segmentation of complex surfaces. Model fine-tuning was performed based on a custom dataset, which included 15,000 labeled images. The training dataset included the scenes of the following types: scenes with stairways, scenes with even surfaces, scenes with isolated obstacles and with groups of obstacles. Approbation and functional quality assessment of the developed approach were performed based on the test dataset, which included 3000 images with different levels of scene illumination. According to the results of the testing, the developed approach shows decent quality of segmentation on images with even surfaces (IoU = 90.2%) and with stairways (IoU = 71.3%) as well maintains some resilience to the variations in the scene luminosity levels. After fine-tuning, the averaged performance metrics of this neural network model on images with luminosity levels of 100% and 70% increased by 9.1% and 7.3% at average and resulted in 65.5% and 52%, respectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-2814-6_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-9605-3_64,Semi-Supervised Self-Training Approach for Web Robots Activity Detection in Weblog,Evolutionary Computing and Mobile Sustainable Networks,10.1007/978-981-16-9605-3_64,Springer,2022-01-01,"Due to the significant added value of web servers, they are vulnerable to attacks, so web security has received a lot of attention. Web server logging systems that record each user request performed by users have become an important data analysis object in web security. Traditionally, system experts’ analyses log data manually using keyword searches and regular expressions. However, the amount of log data and attack types makes routine detection ineffective. Machine learning-based supervised and unsupervised detection approaches have been employed extensively during the last decade to improve traditional detection methods. The proposed semi-supervised STBOOST web robot detection system uses self-training with XGBoost as its base classifier. Experimental data are taken from the open-source data repository, the NASA 95 dataset, and e-commerce site access logs. In both datasets, self-training XGBoost outperforms XGBoost and can detect anonymous web robots using unlabeled data.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-9605-3_64,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-77163-8_10,Workers’ Trust in Collaborative Construction Robots: EEG-Based Trust Recognition in an Immersive Environment,"Automation and Robotics in the Architecture, Engineering, and Construction Industry",10.1007/978-3-030-77163-8_10,Springer,2022-01-01,"Today, advances in robotics and autonomous systems enable construction workers to collaboratively work with robots, assigning physically demanding tasks to them. However, working alongside an industrial robot is a novel experience that may take a heavy toll on workers’ bodies and minds, particularly in dynamic and uncertain environments, such as construction sites. Given that trust is identified as a critical element for successful cooperation between humans and robots, effective measurement of workers’ trust in collaborative robots can lead to practical evaluation of human-robot partnership. In this context, most studies of trust have relied on self-reports. Nevertheless, questionnaires are unable to determine the trust promptly, impeding early preventive interventions. Furthermore, they are invasive, interfering with workers’ daily operations. To address these issues, this study proposes a procedure to non-invasively and continuously recognize workers’ trust in collaborative construction robots using electroencephalogram (EEG) signals. To that end, an experiment was conducted in which human workers performed a collaborative construction task (i.e., handling materials) with a virtual robot in an immersive environment. Meanwhile, workers’ EEG signals were recorded using a wearable sensor. Subsequently, the level of trust of the workers in collaborative robots was measured using the Trust Perception Scale-HRI. By analyzing acquired signals and applying different machine learning algorithms, it was found that EEG signals can be implemented to differentiate levels of trust of construction workers in their robotic counterparts. These findings suggest the feasibility of using workers’ EEG signals as a reliable, real-time indicator of trust in collaborative construction robots, which can be regarded as a practical approach for evaluating human-robot collaboration.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77163-8_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-87869-6_45,Generation of Restricted Zones for AGVs Routes by Clustering Algorithms,16th International Conference on Soft Computing Models in Industrial and Environmental Applications (SOCO 2021),10.1007/978-3-030-87869-6_45,Springer,2022-01-01,"Automated Guided Vehicles (AGVs) and autonomous robots share their workspace with humans and other manned industrial vehicles. This may not only cause unexpected stops and losses of performance but, still more important, compromise the safety of people and other vehicles. To prevent them from colliding with people or things, it is possible to define restricted zones through which AGVs cannot circulate in any case. In this work, an architecture to update restricted areas of an AGV trajectory is designed. This safety system is based on machine learning techniques. Specifically, different clustering methods have been applied. The clusters are shaped as ellipses by a Gaussian mixture model distribution. Three clustering methods are compared regarding some metrics, such as wasted space and places non-covered by the forbidden zones. Results show how the best performance is obtained with the Gaussian method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-87869-6_45,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-981-16-2210-6_57,Artificial Intelligence and Robotics Driving Tourism 4.0: An Exploration,Handbook of Technology Application in Tourism in Asia,10.1007/978-981-16-2210-6_57,Springer,2022-01-01,"With massive technological revolutions in place, Tourism 4.0 is gearing up to a new world of possibilities driven by the colossal amount of data generated from the tourist mobility across the world. In this context, AI and robotics are emerging out to be the game changers in the era of Tourism 4.0. This chapter aims to bring forth the various facets of AI and robotics driving the tourism industry towards a sustainable future. Some of the challenges that lie ahead have also been discussed in this work. It is concluded that with many new integrations to the field of AI and robotics, the tourism industry is expected to reach new heights of customization, service delivery, and experience management amplified by the accurate forecasting techniques in the days to come.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-2210-6_57,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-77163-8_9,Worker-Aware Task Planning for Construction Robots: A Physiologically Based Communication Channel Interface,"Automation and Robotics in the Architecture, Engineering, and Construction Industry",10.1007/978-3-030-77163-8_9,Springer,2022-01-01,"Unsafe workplace environment, labor shortage, and low productivity rate are among the most critical challenges faced by the construction industry. These ongoing challenges have prompted the construction research community to explore robotization as a new direction of improvement. Most of these endeavors have focused on human-robot collaboration (HRC) as the design and development of adaptable and scalable robots for the dynamic work environment of construction sites are excessively difficult. Although HRC can facilitate the design and implementation process, it can pose new threats to human workers’ physical and mental health. One promising approach for a safe and productive HRC is that the co-workers’ physiological responses are captured, interpreted, and infused as a new sensory information level into robotics optimization and planning systems. However, strict compliance of the robot to the system’s prediction results may lead to unstable robotic adjustments because the robot modifies its performance by blindly following the imperfect system information. The present research seeks to optimize such reliance through physiologically aware signal classification algorithms that can appropriately establish harmony between worker physiology and robotic performance. The backbone of this algorithm is grounded in the fact that human physiological alterations are relatively gradual as opposed to electronic alterations of the systems that can happen in a fracture of a second. The proposed algorithm innovatively screens the machine-generated prediction results so as to produce logically sound decisions for robotic control and manipulations. To validate the algorithm in a real robotic system, the authors examined its performance in a collaboration between an unmanned terrestrial robot and a construction worker, with the total of eight subjects in the study. The terrestrial robot was designed to capture physiological signals from the workers’ wearable biosensors, promptly translate them into high-level information, and modify its performance based on trained ML classifiers. The experiment results demonstrated the potentials of the proposed screening algorithm to improve the probability of the correct system decisions in adjusting the robot’s performance. This research shows the algorithm can facilitate the stable implementation of robots within physiologically based HRC at construction sites. This algorithmic filtering process can also be extended to human-system interactions that can facilitate the design and development of interfaces between workers and computer systems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77163-8_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7167-8_46,Obstacle Detection by Power Transmission Line Inspection Robot,Innovative Data Communication Technologies and Application,10.1007/978-981-16-7167-8_46,Springer,2022-01-01,"Inspection of a power transmission line (PTL) is crucial for fault detection and maintenance of the line cable but it is a job that comes with high-occupational hazard. PTL inspection robots are developed to minimize risks to humans, while doing maintenance work on PTL cables. These robots are capable of traversing the power line cables with minimal manual intervention provided they detect the obstacles present on the line and are able to overcome them. This paper discusses a technique that incorporates image texture analysis using popular gray-level co-occurrence matrices (GLCM) algorithm for obstacle detection and then, followed by standard machine learning approach to classify the obstacles. Our results indicate that this approach can be effectively used by autonomous armed robot for traversing a PTL cable.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7167-8_46,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-04870-8_40,EMG Driven Robotic-Aided Arm Rehabilitation,Advances in Service and Industrial Robotics,10.1007/978-3-031-04870-8_40,Springer,2022-01-01,"Robotic-assisted systems have been gaining significant traction in supporting rehabilitation tasks, enabling patients to manipulate objects by using a robotic arm controlled by the means of biological signals. In this regard, electromyography (EMG) signals are key for detecting the patient’s intention of motion, that can be replicated by the robotic arm with higher accuracy and precision. In this paper, we present an integrated EMG-driven robotic system capable of performing manipulation tasks by understanding 3 hand gestures associated with certain pick and place commands. Comprehensive experimental tests were conducted to demonstrate that the proposed system can decode EMG-based commands with an accuracy $$93\%$$ 93 % , undergoing precise robotic-assisted object manipulation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-04870-8_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-09726-3_1,A Bio-Inspired Neural Network Approach to Robot Navigation and Mapping with Nature-Inspired Algorithms,Advances in Swarm Intelligence,10.1007/978-3-031-09726-3_1,Springer,2022-01-01,"Nature-inspired algorithms have been successfully applied to autonomous robot path planning, vision and mapping. However, concurrent path planning and mapping with replanning feature is still a challenge for autonomous robot navigation. In this paper, a new framework in light of the replanning-based methodology of concurrent mapping and path planning is proposed. It initially performs global path planning through a developed Gravitational Search Algorithm (GSA) to generate a global trajectory. The surrounding environment can then be described through a monocular framework and transformed into occupancy grid maps (OGM) for autonomous robot path planning. With updated moving obstacles and road conditions, the robot can replan the trajectory with the GSA based on the updated map. Local trajectory in the vicinity of the obstacles is generated by a developed bio-inspired neural network (BNN) method integrated with speed profile mechanism, and safe border patrolling waypoints. Simulation and comparative studies demonstrate the effectiveness and robustness of the proposed model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-09726-3_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-021-11113-6,A graph neural network to model disruption in human-aware robot navigation,Multimedia Tools and Applications,10.1007/s11042-021-11113-6,Springer,2022-01-01,"Autonomous navigation is a key skill for assistive and service robots. To be successful, robots have to minimise the disruption caused to humans while moving. This implies predicting how people will move and complying with social conventions. Avoiding disrupting personal spaces, people’s paths and interactions are examples of these social conventions. This paper leverages Graph Neural Networks to model robot disruption considering the movement of the humans and the robot so that the model built can be used by path planning algorithms. Along with the model, this paper presents an evolution of the dataset SocNav1 (Manso et al 2020 ) which considers the movement of the robot and the humans, and an updated scenario-to-graph transformation which is tested using different Graph Neural Network blocks. The model trained achieves close-to-human performance in the dataset. In addition to its accuracy, the main advantage of the approach is its scalability in terms of the number of social factors that can be considered in comparison with handcrafted models. The dataset and the model are available in a public repository ( https://github.com/gnns4hri/sngnnv2 ).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11042-021-11113-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-04870-8_71,"Robots Are Actor-Networks: Awareness, Bottom-Up Ethics and Transforming Responsibility",Advances in Service and Industrial Robotics,10.1007/978-3-031-04870-8_71,Springer,2022-01-01,"Robotic systems increasingly take part in many practices of the everyday life. Technological development and innovation continuously transform fields, including the realm of industrial robotics. However, new sets of possibilities challenge new forms of responsibilities. This paper discusses responsibility and ethics in robotics. Based on three expert talks, three qualitative expert interviews and five qualitative narrative interviews with robotic engineers, it gives three preliminary findings of the research project Collective Ethical Responsibility for Robotic Systems Engineering with Safety & Security (CERSE): 1. Robotics are networks (The term network, used in this paper, does not refer to computer or technological networks, but to the assemblage of interconnected actors [ 1 , p. 228] as used in Actor-Network Theory (ANT).) formed by hybrid actors. 2. These networks distribute and (self-)govern responsibility. 3. Engineers call for pro-active reflection and communication to raise awareness. This paper supports a radical transformation of the notion of responsibility within the realms of robotics. In line with the complexity, interconnectedness, and fluidity of robotics, robot ethics must move towards more openness, inclusion, and transdisciplinary research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-04870-8_71,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-3357-7_9,Efficient Deployment of Deep Learning Models on Autonomous Robots in the ROS Environment,"Deep Learning Applications, Volume 3",10.1007/978-981-16-3357-7_9,Springer,2022-01-01,"Sarwar Murshed, M. G. Carroll, James J. Khan, Nazar Hussain, Faraz Autonomous robots are often deployed in applications to continually monitor changing environments such as supermarket floors or inventory monitoring, patient monitoring, and autonomous driving. With the increasing use of deep learning techniques in robotics, a large number of robot manufacturing companies have started adopting deep learning techniques to improve the monitoring performance of autonomous robots. The Robot Operating System (ROS) is a widely used middleware platform for building autonomous robot applications. However, the deployment of deep learning models to autonomous robots using ROS remains an unexplored area of research. Most recent research has focused on using deep learning techniques to solve specific problems (e.g., shopping assistant robots, autopilot systems, automatic annotation of 3D maps for safe flight). However, integrating the data collection hardware (e.g., sensors) and deep learning models within ROS is difficult and expensive in terms of computational power, time, and energy (battery). To address these challenges, we have developed EasyDLROS, a novel framework for robust deployment of pre-trained deep learning models on robots. Our framework is open-source, independent of the underlying deep learning framework, and easy to deploy. To test the performance of EasyDLROS, we deployed seven pre-trained deep learning models for hazard detection on supermarkets floors in a simulated environment and evaluated their performances. Experimental results show that our framework successfully deploys the deep learning models on ROS environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-3357-7_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-7633-8_4,"Smart Technologies in Agriculture as the Basis of Its Innovative Development: AI, Ubiquitous Computing, IoT, Robotization, and Blockchain",Smart Innovation in Agriculture,10.1007/978-981-16-7633-8_4,Springer,2022-01-01,"The paper aims to determine the contribution of various smart technologies (artificial intelligence [AI], ubiquitous computing, the Internet of Things [IoT], robotization, and blockchain) to food security. This study also seeks to develop recommendations for improving the innovative development of agriculture for ensuring food security and determining the limits of the implementation of the “Zero hunger” sustainable development goal based on smart technology. The authors apply the method of regression and correlation analysis. The paper substantiates that different smart technology contributes to food security in different ways. The most contribution is registered on the part of the blockchain (− 1.54 points). The contribution of AI, ubiquitous computing, and IoT is also quite significant (− 0.46 points). The contribution of robotization is much less pronounced, especially in countries dependent on food imports. The authors developed recommendations to improve the innovative development of agriculture for food security based on blockchain, AI, ubiquitous computing, and the IoT. The authors revealed the limits of implementation of the second SDG based on smart technology and quantitative availability (non-deficiency) of food. It is shown that the implementation of the given recommendations increases the affordability of food to the maximum.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7633-8_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-90033-5_26,Deep Learning for Safe Human-Robot Collaboration,Advances in Automation and Robotics Research,10.1007/978-3-030-90033-5_26,Springer,2022-01-01,"Recent advances in computer vision and deep learning have lead to implementations in different industrial applications such as collaborative robotics, making robots able to perform harder tasks and giving them consciousness of their environment, easing interaction with humans. With the objective of eliminating physical barriers between humans and robots, a security system for industrial collaborative robots based on computer vision and deep learning is proposed, where an RGBD camera is used to detect and track people located inside the robot’s workspace. Detection is made with a previously trained convolutional neural network. The position of every detection is fed to the tracker, that identifies the subjects in scene and keeps record of them in case the detector fails. The detected subject’s 3D position and height are represented in a simulation of the workspace, where the robot’s speed changes depending on its distance to the manipulator following international safety guidelines. This paper shows the implementation of the detector and tracker algorithms, the subject’s 3D position, the security zones definition and the integration of the vision system with the robot and workspace. Results show the system’s ability to detect and track subjects in scene, and the robot’s capacity to change its speed depending on the subject’s location.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-90033-5_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7389-4_3,Machine Vision-Based Conveyor and Structural Health Monitoring Robot for Industrial Application Using Deep Learning,Proceedings of Second International Conference on Advances in Computer Engineering and Communication Systems,10.1007/978-981-16-7389-4_3,Springer,2022-01-01,"The autonomous robot has been successfully developed for industrial applications such as inspection. The gap is filled by making use of a robust machine vision algorithm for crack detection using ResNet-based deep learning technique. A novel navigation algorithm is fine-tuned for Firebird V, for its manoeuvres thus making this robot fully autonomous in its functionalities. It navigates in designated areas autonomously and identifies cracks or obstacles. The robot can be effectively used for structural health monitoring or in the case of a conveyor belt inspector. The developed algorithm can navigate on the track with the ability to avoid front collision and Zigzag motion; if any obstacle comes in front of the robot, the buzzer beeps to alert. This autonomous robot can be deployed in various industrial applications which makes use of fundamental concepts of our research. Our set-up for conveyor belt inspector and structural health monitoring requires further automation for repairs or obstacle removals. Further, the safety and reliability issues arising from the practical need to be addressed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7389-4_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-82199-9_19,"Small Scale Mobile Robot Auto-parking Using Deep Learning, Image Processing, and Kinematics-Based Target Prediction",Intelligent Systems and Applications,10.1007/978-3-030-82199-9_19,Springer,2022-01-01,"Autonomous parking is a valuable feature in many mobile robot applications. As compared to self-driving automobiles, auto-parking is more challenging for a small scale robot equipped with a front camera only, due to the camera view limited by the height of robot and the narrow Field of View (FOV) provided by the inexpensive camera. In this research, auto-parking of such a small scale mobile robot is accomplished in a four-step process: identification of available parking space using transfer learning based on the AlexNet; image processing for the detection of parking space boundary lines; kinematics-based target prediction when the parking space disappears from the camera view partially or completely; and motion control on the robot navigating towards the center of the parking space. Results show that a 95% accuracy has been achieved on identification of available parking spaces. The detection of boundary lines and prediction of target have also been successfully implemented in MATLAB. The testing of motion control and image capture for deep learning is performed on a self-built small-scale mobile robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-82199-9_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-04881-4_30,An Innovative Vision System for Floor-Cleaning Robots Based on YOLOv5,Pattern Recognition and Image Analysis,10.1007/978-3-031-04881-4_30,Springer,2022-01-01,"The implementation of a robust vision system in floor-cleaning robots enables them to optimize their navigation and analysing the surrounding floor, leading to a reduction on power, water and chemical products’ consumption. In this paper, we propose a novel pipeline of a vision system to be integrated into floor-cleaning robots. This vision system was built upon the YOLOv5 framework, and its role is to detect dirty spots on the floor. The vision system is fed by two cameras: one on the front and the other on the back of the floor-cleaning robot. The goal of the front camera is to save energy and resources of the floor-cleaning robot, controlling its speed and how much water and detergent is spent according to the detected dirt. The goal of the back camera is to act as evaluation and aid the navigation node, since it helps the floor-cleaning robot to understand if the cleaning was effective and if it needs to go back later for a second sweep. A self-calibration algorithm was implemented on both cameras to stabilize image intensity and improve the robustness of the vision system. A YOLOv5 model was trained with carefully prepared training data. A new dataset was obtained in an automotive factory using the floor-cleaning robot. A hybrid training dataset was used, consisting on the Automation and Control Institute dataset (ACIN), the automotive factory dataset, and a synthetic dataset. Data augmentation was applied to increase the dataset and to balance the classes. Finally, our vision system attained a mean average precision (mAP) of 0.7 on the testing set.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-04881-4_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-07520-9_12,Gesture-Based Feedback in Human-Robot Interaction for Object Manipulation,Technological Innovation for Digitalization and Virtualization,10.1007/978-3-031-07520-9_12,Springer,2022-01-01,"Human-Robot Interaction is a currently highly active research area with many advances in interfaces that allow humans and robots to have bi-directional feedback of their intentions. However, in an industrial setting, current robot feedback methods struggle to successfully deliver messages since the environment makes it difficult and inconvenient for the user to perceive them. This paper proposes a novel method for robot feedback, leveraging the addition of social cues to robot movement to notify the human of its intentions. Through the use of robotic gestures, we believe it is possible to successfully convey the robots’ goals in interactions with humans. To verify this hypothesis, a proof of concept was developed in a simulated environment using a robotic arm manipulator that notifies the user using gestures when it needs to correct the pose of an object.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-07520-9_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-4258-6_25,Application of Artificial Intelligence in News Communication,Innovative Computing,10.1007/978-981-16-4258-6_25,Springer,2022-01-01,"With the development of artificial intelligence technology, all aspects of society have been changed, and artificial intelligence technology has penetrated into all aspects of news communication activities. The application of artificial intelligence technology in news communication has accelerated the speed and scope of news dissemination. However, due to the immature technology, there are still many deficiencies. Therefore, this paper puts forward the application of artificial intelligence in news communication. This paper makes an in-depth study on the existing AI news writing mode, and analyzes the main problems in the current AI news writing. In view of these shortcomings, based on the characteristics of artificial intelligence technology, combined with the actual needs of news communication, this paper puts forward the optimization and improvement measures of artificial intelligence news communication system. This measure mainly from the short-term and long-term development as the focus of research, and analyzes the optimal solution of the elements and structure problems in the artificial intelligence news production mode. The solution of this paper effectively improves the shortcomings of the current AI news writing mode, and strengthens the supervision of news content while strengthening the writing level. It is suggested that a set of effective supervision and management mechanism should be established to guide the artificial intelligence news format scientifically.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-4258-6_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-05760-1_24,Requirements Engineering for Collaborative Artificial Intelligence Systems: A Literature Survey,Research Challenges in Information Science,10.1007/978-3-031-05760-1_24,Springer,2022-01-01,"Artificial Intelligence (AI) systems are pervasively exploited to manipulate large sets of data, support data-driven decisions, as well as to replace or collaborate with humans in performing boring tasks that require high level precision. Awareness of the need of engineering approaches that align with ethical principles is increasing and motivates attention by diverse research communities, such as AI research and Software Engineering research communities. In our research, we focus on Requirements Engineering (RE) for Collaborative Artificial Intelligence Systems (CAIS), such as robot arms that collaborate with human operators to perform repetitive and tiring tasks. A systematic literature review was conducted to assess the state of research, which resulted in the analysis of 41 research publications. Among the main findings, a set of challenges pointed out by researchers, such as the lack of a well-structured definition for CAIS requirements and the inadequacy of current standards. A discussion of these challenges and of recommendations for addressing them is proposed, taking into account similar results from recent related work. Similarly, the requirements types mentioned in the analysed literature are analysed according to categories proposed in related work.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-05760-1_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-05434-1_31,Will Robots Know That They Are Robots? The Ethics of Utilizing Learning Machines,Culture and Computing,10.1007/978-3-031-05434-1_31,Springer,2022-01-01,"The aspirations for a global society of learning technology are high these days. Machine Learning (ML) and artificial intelligence (AI) are two key terms of any socio-political and technological discourse. Both terms however, are riddled with confusion both on practical and conceptual levels. Learning for one thing, assumes that an entity gains and develops their knowledge bank in ways that are meaningful to the entity’s existence. Intelligence entails not just computationality but flexibility of thought, problem-solving skills and creativity. At the heart of both concepts rests the philosophy and science of consciousness. For in order to meaningfully acquire information, or build upon knowledge, there should be a core or executive function that defines the concerns of the entity and what newly encountered information means in relation to its existence. A part of this definition of concerns is also the demarcation of the self in relation to others. This paper takes a socio-cognitive scientific approach to deconstructing the two currently overused terms of ML and AI by creating a design fiction of sorts. This design fiction serves to illustrate some complex problems of consciousness, identity and ethics in a potential future world of learning machines.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-05434-1_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-6460-1_58,Multi-Label Classification of Cotton Plant with Agriculture Mobile Robot,Data Intelligence and Cognitive Informatics,10.1007/978-981-16-6460-1_58,Springer,2022-01-01,"Technology-driven agriculture is the need of an hour to eliminate traditional labor-driven unreliable agriculture methods. This paper proposes a technique that will eradicate conventional unreliable high-cost human-driven methods of pesticides and fertilizer spraying with a technology-driven, reliable, and low-cost process. The traditional approach has no control over the quantity of pesticides/fertilizer to be sprayed on the required location on a plant, leading to an inverse effect on the plant and increasing the cost because of excessive use of pesticides/fertilizer; it also has health effect on human labor spraying the pesticides. This paper discusses an Artificial intelligence-based autonomous agriculture robot that can detect infection on a cotton plant while navigating and localizing itself on a cotton farm field. The independent agriculture mobile robot has integrated with the deep learning-based algorithm that aims to detect and classify seven classes, namely: healthy leaf, healthy cotton, healthy repining ball, diseased leaf, diseased damages cotton, diseased repining ball, and insect. The proposed method is proven to be 90% accurate for detecting and classifying cotton plants while navigating the mobile robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-6460-1_58,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7330-6_73,Robotic Vehicle Control by Hand Gestures of Authorized Users,"Proceedings of Third International Conference on Intelligent Computing, Information and Control Systems",10.1007/978-981-16-7330-6_73,Springer,2022-01-01,"We all know how robot technology is advancing and emerging as an integral part of innovation. One such great innovation is the smart robots, not controlled by a remote but by hand gestures using computer vision, deep learning, and face recognition. To implement this, we have collected the photos of authorized persons and the data of different hand gestures with appropriate labels. We have trained a convolutional neural network model for hand gesture recognition and used LBPH face recognizer for face recognition. The person (controller) gets authenticated through face recognition. The detected hand gesture image of the authorized user from the real-time video is passed as test data to our model to predict the gesture the image refers to. The processed gesture acts as a command to the microcontroller that controls the motion of the robot. The potential technique of controlling the robot with hand gestures is explained in detail.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7330-6_73,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-98682-7_7,6D Object Pose Estimation Using Keypoints and Part Affinity Fields,RoboCup 2021: Robot World Cup XXIV,10.1007/978-3-030-98682-7_7,Springer,2022-01-01,"The task of 6D object pose estimation from RGB images is an important requirement for autonomous service robots to be able to interact with the real world. In this work, we present a two-step pipeline for estimating the 6 DoF translation and orientation of known objects. Keypoints and Part Affinity Fields (PAFs) are predicted from the input image adopting the OpenPose CNN architecture from human pose estimation. Object poses are then calculated from 2D-3D correspondences between detected and model keypoints via the PnP-RANSAC algorithm. The proposed approach is evaluated on the YCB-Video dataset and achieves accuracy on par with recent methods from the literature. Using PAFs to assemble detected keypoints into object instances proves advantageous over only using heatmaps. Models trained to predict keypoints of a single object class perform significantly better than models trained for several classes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-98682-7_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-06427-2_62,Relaxing the Forget Constraints in Open World Recognition,Image Analysis and Processing – ICIAP 2022,10.1007/978-3-031-06427-2_62,Springer,2022-01-01,"In the last few years deep neural networks has significantly improved the state-of-the-art of robotic vision. However, they are mainly trained to recognize only the categories provided in the training set (closed world assumption), being ill equipped to operate in the real world, where new unknown objects may appear over time. In this work, we investigate the open world recognition (OWR) problem that presents two challenges: (i) learn new concepts over time (incremental learning) and (ii) discern between known and unknown categories (open set recognition). Current state-of-the-art OWR methods address incremental learning by employing a knowledge distillation loss. It forces the model to keep the same predictions across training steps, in order to maintain the acquired knowledge. This behaviour may induce the model in mimicking uncertain predictions, preventing it from reaching an optimal representation on the new classes. To overcome this limitation, we propose the Poly loss that penalizes less the changes in the predictions for uncertain samples, while forcing the same output on confident ones. Moreover, we introduce a forget constraint relaxation strategy that allows the model to obtain a better representation of new classes by randomly zeroing the contribution of some old classes from the distillation loss. Finally, while current methods rely on metric learning to detect unknown samples, we propose a new rejection strategy that sidesteps it and directly uses the model classifier to estimate if a sample is known or not. Experiments on three datasets demonstrate that our method outperforms the state of the art.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-06427-2_62,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-05061-9_5,Improving EEG-based Motor Execution Classification for Robot Control,"Social Computing and Social Media: Design, User Experience and Impact",10.1007/978-3-031-05061-9_5,Springer,2022-01-01,"Brain Computer Interface (BCI) systems have the potential to provide a communication tool using non-invasive signals which can be applied to various fields including neuro-rehabilitation and entertainment. Interpreting multi-class movement intentions in a real time setting to control external devices such as robotic arms remains to be one of the main challenges in the BCI field. We propose a learning framework to decode upper limb movement intentions before and during the movement execution (ME) with the inclusion of motor imagery (MI) trials. The design of the framework allows the system to evaluate the uncertainty of the classification output and respond accordingly. The EEG signals collected during MI and ME trials are fed into a hybrid architecture consisting of Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) with limited pre-processing. Outcome of the proposed approach shows the potential to anticipate the intended movement direction before the onset of the movement, while waiting to reach a certainty level by potentially observing more EEG data from the beginning of the actual movement before sending control commands to the robot to avoid undesired outcomes. Presented results indicate that both the accuracy and the confidence level of the model improves with the introduction of MI trials right before the movement execution. Our results confirm the possibility of the proposed model to contribute to real-time and continuous decoding of movement directions for robotic applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-05061-9_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-11647-6_51,AI-Based Open-Source Gesture Retargeting to a Humanoid Teaching Robot,"Artificial Intelligence in Education. Posters and Late Breaking Results, Workshops and Tutorials, Industry and Innovation Tracks, Practitioners’ and Doctoral Consortium",10.1007/978-3-031-11647-6_51,Springer,2022-01-01,"Gestures and speech modalities play potent roles in social learning, especially in educational settings. Enabling artificial learning companions (i.e., humanoid robots) to perform human-like gestures and speech will facilitate interactive social learning in classrooms. In this paper, we present the implementation of human-generated gestures and speech on the Pepper robot to build a robotic teacher. To this end, we transferred a human teacher gesture to a humanoid robot using a web and a kinect cameras and applied a video-based markerless motion capture technology and an observation-based motion mirroring method. To evaluate the retargeting methods, we presented different types of a humanoid robotic teacher to six teachers and collect their impressions on the practical usage of a robotic teacher in the classroom. Our results show that the presented AI-based open-source gesture retargeting technology was found attractive, as it gives the teachers an agency to design and employ the Pepper robot in their classes. Future work entails the evaluation of our solution to the stakeholders (i.e. teachers) for its usability.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-11647-6_51,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-95346-1_111,The Robot Won’t Judge Me: How AI Healthcare Benefits the Stigmatized: An Abstract,Celebrating the Past and Future of Marketing and Discovery with Social Impact,10.1007/978-3-030-95346-1_111,Springer,2022-01-01,"The rise of AI healthcare applications is changing the way consumers receive treatment, diagnosis, and health advice. Despite the rapid growth of AI in healthcare contexts, prior literature suggests that consumers experience reservations about AI in healthcare due to the concerns that automation reduces providers’ ability to take into consideration the uniqueness of consumers’ health-related characteristics in comparison to human providers (Longoni et al. 2019) and privacy concerns (Brooks 2019). However, might there be times when consumers might prefer an AI provider over a human healthcare provider? Consumers who suffer stigmatized health issues often experience self-conscious emotions such as fear, shame, and embarrassment. Negative emotions can create barriers for communication between patients and doctors and negative health outcomes. Thus, by developing solutions which reduce consumers’ negative emotions related to stigmatized health issues, consumer well-being may be enhanced. In the current research, we suggest consumers with stigmatized (versus non-stigmatized) health issues will prefer AI to human health care providers. In Study 1, two hundred and forty-two undergraduates were randomly assigned to a 2 (disease type: contagious or non-contagious) × 2 (healthcare provider type: human or AI) between-subjects design. In the heart disease scenario, participants were significantly more likely to schedule a screening appointment if the healthcare provider was a human physician. However, in the seasonal flu scenario, which was perceived as a more stigmatized disease, participants were significantly more likely to schedule a screening appointment if the healthcare provider was a computer. In Study 2, one hundred and fifty four undergraduates were randomly assigned to either a human or AI healthcare provider conditions. All participants were asked to imagine that they had a close friend who was overweight/obese and experienced health issues as a result. Participants were then shown a brochure of a workout program with either a virtual workout program or an in-person one. Results showed that participants expected their obese friend would feel more shame and negative judgement if he/she enrolled in the in-person program compared to the virtual workout program. In summary, findings from two studies provided support for our hypotheses that consumers dealing with stigmatized health conditions prefer artificial intelligence healthcare providers to human ones. These findings have important implications for early diagnosis and potential recovery of these health conditions, as well as to prevent spreading of contagious diseases.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-95346-1_111,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-03918-8_17,Robo-Nurse Healthcare Complete System Using Artificial Intelligence,The 8th International Conference on Advanced Machine Learning and Technologies and Applications (AMLTA2022),10.1007/978-3-031-03918-8_17,Springer,2022-01-01,"Significant with COVID-19 pandemic breakout, and the high risk of acquiring this infection that is facing the Healthcare Workers (HCWs), a safe alternative was needed. As a result, robotics, artificial intelligence (AI) and internet of things (IoT) usage rose significantly to assist HCWs in their missions. This paper aims to represent a humanoid robot capable of performing HCWs’ repetitive scheduled tasks such as monitoring vital signs, transferring medicine and food, or even connecting the doctor and patient remotely, is an ideal option for reducing direct contact between patients and HCWs, lowering the risk of infection for both parties. Humanoid robots can be employed in a variety of settings in hospitals, including cardiology, post-anesthesia care, and infection control. The creation of a humanoid robot that supports medical personnel by detecting the patient's body temperature and cardiac vital signs automatically and often and autonomously informs the HCWs of any irregularities is described in this study. It accomplishes this objective thanks to its integrated mobile vital signs unit, cloud database, image processing, and Artificial Intelligence (AI) capabilities, which enable it to recognize the patient and his situation, analyze the measured values, and alert the user to any potentially worrisome signals.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-03918-8_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-12848-6_14,Playing Tic-Tac-Toe with a Lightweight Robot,Robotics in Education,10.1007/978-3-031-12848-6_14,Springer,2022-01-01,"This article presents an interdisciplinary approach to developing a robot demonstrator, combining the research fields of robot force/torque control, image processing, artificial intelligence, robot programming, and human-robot cooperation. In this regard, we chose to implement the game tic-tac-toe , also known as noughts and crosses or Xs and Os with a robot manipulator playing against a human. For this purpose, we observed with a camera and exploited them using image processing. Thereafter, artificial intelligence planned the robot move, the execution of which required the application of force control while drawing on the whiteboard. The presented robot system is appropriate for teaching students in different subject areas and is also scalable with respect to the complexity factor. In addition to the education of students, the resulting demonstrator presents an attractive scenario to inspire pupils and students to pursue a career in robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-12848-6_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-90944-4_10,Social Robots in Education: Conceptual Overview and Case Study of Use,Orchestration of Learning Environments in the Digital World,10.1007/978-3-030-90944-4_10,Springer,2022-01-01,"Social robots are increasingly being used in education. They can take over various roles including teaching assistant, tutor, and novice. This chapter aims to provide a conceptual overview of the phenomenon. A classification of social robots is outlined; the criteria are visual appearance, social capabilities, and autonomy and intelligence. The majority of robots used in education are humanoid; Nao from SoftBank Robotics is a quasi-standard type. An important social capability is empathy; a model illustrating how a robot can show empathy is discussed. A taxonomy is presented in order to capture the various degrees of robot autonomy. To achieve autonomy, artificial intelligence is necessary. This chapter advocates for a symbiotic design approach where tasks are collaboratively carried out by the teacher and the social robot, utilizing the complementary strength of both parties. This may be in line with the concept of hybrid intelligence. The ethical aspects of social robot use are explored, including privacy, control, responsibility, and the role of teachers. Moreover, the acceptance of social robots is discussed. Overall, attitudes toward social robots seem to be positive; however, there are also contrary findings. Finally, results are presented from a technology acceptance study with a sample of N = 462 university students from the social sciences. The chapter closes with suggestions for further research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-90944-4_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-90700-6_17,Comparison of AI-based Task Planning Approaches for Simulating Human-Robot Collaboration,Towards Sustainable Customization: Bridging Smart Products and Manufacturing Systems,10.1007/978-3-030-90700-6_17,Springer,2022-01-01,"Today, increased demands for personalized products are making human-robot collaborative tasks a focus of research mainly for improving production cycle time, precision, and accuracy. It is also required to simplify how human-robot tasks and motions are generated. A graphical flow control-based programming can be one of such methods. This work investigates whether the graphical approaches (e.g., using RAFCON) yield a better real-time simulation or not compared to agent approaches (e.g., using MOSIM-AJAN). This work may support the agility of the digital manufacturing process by enhancing the efficiency of human-robot collaboration.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-90700-6_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-95903-6_40,Path Control Algorithm for Weeding AI Robot,"Advances in Internet, Data & Web Technologies",10.1007/978-3-030-95903-6_40,Springer,2022-01-01,"This paper addresses a path control algorithm for an AI robot that performs automatic weeding work. An AI robot can grasp the situation (locations of weeds to be weeded, crops not to be weeded, and obstacles, etc.) of the limited range of the circumference of the AI robot by installed cameras and sensors. The AI robot carries out the weeding work simultaneously, while the path which removes all weeds in a short time is determined and renewed by collecting the situation of the whole object region by moving. Since the object area is wide, it is generally necessary to carry out the weeding work continuously, because the weed may grow again or it may grow from the new place, even if it is the plot which weeded once. In this way, the AI robot basically carries out the weeding work of the whole object region continuously without manual intervention. In this paper, some weeding path control algorithms suitable for such an AI robot are designed, and several algorithms are evaluated by simulation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-95903-6_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-04305-5_17,Taxing Robots or Artificial Intelligence,"Interactive Robotics: Legal, Ethical, Social and Economic Aspects",10.1007/978-3-031-04305-5_17,Springer,2022-01-01,"This paper intends to replace the debate about the current situation with regards to the taxation of robots and to summarize the main legal arguments in favor of a robot tax. In particular, since so far robots as such do not have an economic ability to pay, at least under the current state of law, the justification of a robot tax should clearly distinguish between taxing the use of robots on the one hand, and robots as such on the other hand. A more recent argument in favor of taxing robots as such has also emerged with a view to keep the integrity of the tax system and to fight against tax avoidance and fraud. In any event, the implementation of such proposal would require an international coordination.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-04305-5_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-02359-0_16,Biolaw Beyond Biology: Artificial Intelligence and Smart Robots,The Emergence of Biolaw,10.1007/978-3-031-02359-0_16,Springer,2022-01-01,"Biolaw presupposes a well-determined concept of “life,” which is given by life sciences. In general, “life” means organic entities, forming self-reproducing functional systems, with the presence of DNA; that concept embraces microorganisms, plants, and animals, including humans.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-02359-0_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-92084-5_2,The Technological Revolution: The Rise of Machines,Making the Global Economy Work for Everyone,10.1007/978-3-030-92084-5_2,Springer,2022-01-01,"We are living in the most innovative period in all of human history. On the one hand, the technological and scientific revolution opens up unprecedented opportunities: accelerating human progress, improving the quality of life and overcoming many constraints. From an economic point of view, technology and science can increase productivity and expand the economy generating wealth, relieve humans from heavy and dangerous activities, and increase labour flexibility. On the other hand, some technologies can be used for criminal activities, terrorism, sabotage, restriction of personal freedoms, repression and other ethically controversial objectives. The risks also affect the sustainability of economic growth, the fabric of society and the future of labour, humanity as a whole and its role. Simply witnessing technological development as a mere spectator is not possible. New technologies influence the way we live, think, produce and work. Beyond the technical aspects, they introduce new mental, cultural and strategic models. The upcoming wave of innovation affects everyone. To ride this wave instead of being overwhelmed by it, one must grasp the main innovations and understand how they work and are connected to one another.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-92084-5_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-4177-0_45,Underwater Robotics,ICT with Intelligent Applications,10.1007/978-981-16-4177-0_45,Springer,2022-01-01,"In the age of technology, the world is slowly moving toward the automated system and self-traveling vehicles in all the fields. The emerging development of the underwater security are in defense and other exploration. The underwater robot is a type of bionic robot, which has the locomotion-link living thing. The type of resemblance of the prototype that creates the virtual habitat of marine life for ocean environment researches. This bionic robot can also gather much information about corals by going deep inside the corals where humans cannot possibly go. This model can also help in estimating the amount of oil spills in oceans. This robotic model can also be used for locating leakages in pipelines deep inside the ocean by giving exact coordinates of that location. And, the most important thing is this robot goes inside the water (sea), measures and detects the level of pollution done due to leakage of the pipeline, as well as, it can detect the level of natural pollution cause due to human activates.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-4177-0_45,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-8881-2_37,The Future of Machine Learning,Machine Learning in Biological Sciences,10.1007/978-981-16-8881-2_37,Springer,2022-01-01,Machine learning has diverse applications in different domains of technology and more so in the different and diverse domains of science of biology and industry. We have discussed in the previous chapters the different applications of machine learning in biology. In this chapter we will discuss the promises and future scope of research areas in machine learning.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-8881-2_37,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-95346-1_89,Will Robots Judge Me? Examining Consumer-Service Robots Interactions in Embarrassing Service Encounters: An Abstract,Celebrating the Past and Future of Marketing and Discovery with Social Impact,10.1007/978-3-030-95346-1_89,Springer,2022-01-01,"Service robots are gradually replacing humans service providers in numerous industries and their development is profoundly impacting the way in which service is delivered (Bornet et al. 2021; Wirtz et al. 2018). Accordingly, service robots encounters represent a primary research area in service. To date, researcher and practitioners have applied service robot across various contexts such as medical (Yoon and Lee 2019), hospitality (Tung and Au 2018) and tourism (Murphy et al. 2019), and have focused on the general application and acceptance of the technology (Huang and Rust 2017; van Doorn et al. 2016; Wirtz et al. 2018) and on services that may be executed by or improved by such technologies (Paluch and Blut 2013; Jörling, Bohm, and Paluch 2019). In addition, few studies have analysed service robot interactions in the service and consumer behaviour fields (Longoni et al. 2019), mainly focusing on the consumers’ reactions to specific service robot characteristics such as the level of human-likeness (Castelo et al. 2019; Kim et al. 2019; Mende et al. 2019). These approaches usually try to determine general principles of the service robot delivery, yet not much attention has been given to the particular boundary condition of the service delivery context under which human-robots encounters might be more beneficial than traditional human-to-human encounters. A typical consumption setting where the presence of other individuals can damage the general consumers’ experience is embarrassing service encounters. Consumer embarrassment is a widespread social emotion induced when a transgression is witnessed or perceived to be witnessed by others ( Krishna et al. 2019). For embarrassment to be elicited, individuals have to be concerned for what others are perceiving or thinking about them (Dahl et al. 2001), thus embarrassment is dependent on the presence of others. In this study, we suggest that interactions with a service robots in the context of a potentially embarrassing service encounter may reduce consumer embarrassment. We posit that this occurs because of the global attribution of mind to the robots such that consumers do not ascribe intentionality, cognition, and emotion to a service robot, thus ability to socially evaluate one’s purchase or behaviour (Gray et al. 2007). Moreover, we propose to investigate the impact of service robot human-likeness on consumer embarrassment (Mende et al. 2019). The study employs a mixed-method approach. Preliminary findings from the qualitative analysis identifies perceptions of mind and human-likeness appearance as potential factors influencing feelings of embarrassment. Further, findings from a first experimental study show that, in embarrassment service encounters, interaction with service robots decrease feelings of individuals’ consumer embarrassment. Theoretical and managerial contributions are discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-95346-1_89,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-05740-3_14,Artificial Intelligence in Tourism and Hospitality,Applied Artificial Intelligence in Business,10.1007/978-3-031-05740-3_14,Springer,2022-01-01,"This chapter presents the enabling technologies for AI in tourism and hospitality highlighting expert systems, voice chatbots, query engines, artificial neural networks, belief networks, sentiment analysis, fuzzy logic systems and virtual reality. The major applications of AI in tourism including smart tourism, demand forecasting, and customer data analytics are explored. Case studies include Henn Na Hotel, Hilton Hotel, Airbnb, and Expedia.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-05740-3_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-86144-5_14,Fictionalizing the Robot and Artificial Intelligence,Perspectives on Digital Humanism,10.1007/978-3-030-86144-5_14,Springer,2022-01-01,This text explores the contemporary fascination with robots and digitality and points out how this distorts our view on what digitization can do for us. It pleads for a realist and non-fictionalized view on robots and artificial intelligence.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-86144-5_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7469-3_104,Robot Path Planning Based on Artificial Intelligence Algorithm,2021 International Conference on Big Data Analytics for Cyber-Physical System in Smart City,10.1007/978-981-16-7469-3_104,Springer,2022-01-01,"Path planning is the most important part in the process of mobile robot research. A good path planning algorithm can greatly improve the efficiency of the robot, and can be accurately and effectively applied to the designated and scheduled tasks. The path planning of a mobile robot can be regarded as an optimization problem with constraints. The optimization algorithm can be divided into global path planning and local path planning. Local planning enhances the real-time control of the robot and makes the planning path smoother. The combination of global planning and local planning can make the goal of local planning more clear, thus avoiding the blindness of robot motion caused by simple local path planning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7469-3_104,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-95459-8_32,Multi-class Target Tracking Using the Semantic PHD Filter,Robotics Research,10.1007/978-3-030-95459-8_32,Springer,2022-01-01,"In order for a mobile robot to be able to effectively operate in complex, dynamic environments it must be capable of understanding both where and what the objects around them are. In this paper we introduce the semantic probability hypothesis density (SPHD) filter, which allows robots to simultaneously track multiple classes of targets despite measurement uncertainty, including false positive detections, false negative detections, measurement noise, and target misclassification. The SPHD filter is capable of incorporating a different motion model for each type of target and of functioning in situations where the number of targets is unknown and time-varying. We demonstrate the efficacy of the SPHD filter via simulations with multiple target types containing both static and dynamic targets. We show that the SPHD filter performs better than a collection of PHD filters running in parallel, one for each target class.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-95459-8_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-83368-8_4,Design of a Mobile Robot to Work in Hospitals and Trajectory Planning Using Proposed Neural Networks Predictors,International Conference on Reliable Systems Engineering (ICoRSE) - 2021,10.1007/978-3-030-83368-8_4,Springer,2022-01-01,"Considering the intense and tiring working conditions in hospitals, healthcare personnel’s performance decreases during prolonged working times, and patients are directly affected by this decrease in performance. This study aims to design and implement a mobile robot that can help healthcare professionals improve the healthcare industry conditions. In this context, the focus is on the mobile robot performing two main tasks. The first task is dispensing medication to patients with an eight-chamber mechanical feeding unit. Thus, patients can take only their medicines from the defined reservoir by selecting their names or photos on the touch screen. The second task is to interact with patients to give moral support with phrases such as “good morning”, “you look great today”. Also, drug delivery activity is recorded in a database, and the health status of the patients can be kept under surveillance with the camera on the mobile robot. The designed mobile robot goes to the patient rooms with magnetic strip tracking. For this purpose, a controller is designed for the omni-drive robot using MATLAB, and its performance is simulated. Also, the control velocities that enable tracking the trajectories are taught to artificial neural networks (ANN), and the requirement magnetic strip for trajectory tracking is eliminated. In this direction, two artificial neural networks are compared in terms of their learning performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-83368-8_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-05740-3_17,Artificial Intelligence in Education,Applied Artificial Intelligence in Business,10.1007/978-3-031-05740-3_17,Springer,2022-01-01,"This chapter highlights the implementation of AI technologies in education with particular interest in personalization of educational ecosystems, development of online learning, and adaptive learning. The chapter explores evolution of AI in education and application of AI in online learning platforms. Features of AI in education include learning personalization, teaching personalization, effectiveness, smart content, and big data-driven system implementation. Case analyses comprise Realizeit, Nuance, and Civitas.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-05740-3_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-7909-4_7,Self-directed Robot for Car Driving Using Genetic Algorithm,Technology Innovation in Mechanical Engineering,10.1007/978-981-16-7909-4_7,Springer,2022-01-01,"The big issue with a human driving car is traffic, with the current continuous growth in the world population. The second big issue with the growing population is creating huge chaos, which leads to accidents. Every year nearly 1.35 million people lose their lives due to traffic crashes, and 20 to 50 million face serious injuries with some untreatable disability as of their road injury. Over 80% of accidents happen due to driver error. Other issues are the efficiency of the car as we are slowly transforming into the electric car. This paper introduced car with the self-driving feature using genetic algorithm to reduce the traffic with route optimization, and by reducing traffic, so that many problems related to driving can be solved. It minimizes the rate of an accident and also maximizes the efficiency of the car.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7909-4_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-05484-6_8,Artificial Intelligence Applied in Electrical Engineering Automation,Application of Intelligent Systems in Multi-modal Information Analytics,10.1007/978-3-031-05484-6_8,Springer,2022-01-01,"Electrical engineering automation is an independent discipline, which contains many research projects, such as electrical automation control systems, electronic information applications, and computer intelligent design. The experiments in this paper found that the speed and angular velocity of the intelligent robot gradually stabilized and were close to the expected values; the position deviation and angle of the intelligent robot gradually became consistent and stable in the later stage, indicating that during the operation of the intelligent robot, fuzzy controllers were used to perform the trajectory. The feasibility of real-time tracking and its ability to control the operation path of the intelligent robot close to the ideal trajectory.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-05484-6_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-99581-2_31,Analysis of Three-Dimensional Multi-motion Simulation of Intelligent Snake Robot Based on Reconfigurable Modularity,Forthcoming Networks and Sustainability in the IoT Era,10.1007/978-3-030-99581-2_31,Springer,2022-01-01,"The biological snake has several kinds of motion modes, such as winding movement, peristalsis and rolling lateral movement, and has the ability to survive in various environments on land and water. According to the motion characteristics of biological snakes, researchers put forward bionic robots, which make snake robots have the same advantages as snakes, and use them in various complex scenes to assist human rescue activities. Based on the structure optimization design of reconfigurable modular intelligent snake robot, this paper puts forward the idea of three-dimensional multi-motion simulation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-99581-2_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-04870-8_13,Explaining Local Path Plans Using LIME,Advances in Service and Industrial Robotics,10.1007/978-3-031-04870-8_13,Springer,2022-01-01,"As robots are becoming a more significant part of humans’ daily life, there is a challenge to bridge the gap between robots’ actions and humans’ understanding of what robots are doing and how they make their decisions. We present an approach to local navigation explanation based on Local Interpretable Model-agnostic Explanations (LIME), a popular approach from the Explainable Artificial Intelligence (XAI) community for explaining individual predictions of black-box models. We show how LIME can be applied to a robot’s local path planner. We experimentally evaluate the explanation method’s runtime, quality, and robustness, and discuss implications for the robotic domain.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-04870-8_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-06417-3_62,Human and Machine Symbiosis - An Experiment of Human and Robot Co-creation of Calligraphy-Style Drawing,HCI International 2022 Posters,10.1007/978-3-031-06417-3_62,Springer,2022-01-01,"Artificial Intelligence (AI) and robots impact creative jobs such as art-making. There have been many AI tools assisting average users in imitating the styles of renowned painters from the past. The Convolutional neural network (CNN) and generative adversarial network (GAN) emergence as a method to “hallucinate” and create expressions of styled drawings. This paper discussed an experiment to study how AI, Automation, and Robots (AAR) will interact with humans and form a unique symbiotic relationship in art-making. Our project, called “robot painter,” established a co-creation in calligraphy-style painting with the following steps: (1) Use CNN tools to translate a raster image into a calligraphy-style image. (2) Develop an algorithm in Grasshopper and Rhino program for the Kuka robot. This generative tool allowed the artist to translate the image into a parametrically controlled 3D toolpath for a robotic arm. (3) A KUKA robot executed the art-making by holding a paintbrush and completing the painting with customized stoke, force, and angle on a canvas. In conclusion, the paper discussed that AAR makes human intervention and co-creation possible. The ability of A. I and robots to mimic artists’ expressions have undoubtedly achieved a convincing level and will affect art-making in the years to come.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-06417-3_62,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-9808-8_23,Robotization of Civil Proceedings: Reality or Future,New Technology for Inclusive and Sustainable Growth,10.1007/978-981-16-9808-8_23,Springer,2022-01-01,"The consistent introduction of artificial intelligence technologies in Russia and abroad creates the necessary prerequisites for changing the legal and ethical standards for this phenomenon. The judicial form of legal protection was also changed in a number of countries, due to the replacement of judges with computers in human form. For China, this experience was successful, as main and pioneer participants in the simplest cases were absolutely not against the replacement. A number of countries have already adopted special laws and legal acts regulating the integration of robots in judicial processes. In almost all countries of the world, there is an irreversible process of replacing the basic legal framework. In the course of the study, the positive and negative features of this phenomenon will be figured out and because of the fact that many of the basic provisions governing the legal regulation of artificial intelligence technology were borrowed from various acts of an economic nature, since in many respects this area is autonomous and does not involve performing any additional actions other than pressing a button on a computer.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-9808-8_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-06409-8_32,Artificial Neural Network Modelling of Cable Robots,"ROMANSY 24 - Robot Design, Dynamics and Control",10.1007/978-3-031-06409-8_32,Springer,2022-01-01,"In this paper, artificial neural network-based cable models are developed for cable-driven parallel robots. A variety of scenarios, including the transfer learning-based ANN, are examined to predict the deflections while improving the efficiency and performance of ANN. The predicted deflections for the previously unseen poses from the same region, as well as the adjacent regions, are highly satisfactory and comparable to the results obtained by a nonlinear optimization method. In addition, ANN models could predict the deflections for poses that the nonlinear optimization methods may not.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-06409-8_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-04245-4_26,Research on Engineering Project Process and Method that Applied Talents Should Master Under Intelligent Manufacturing Technology,6GN for Future Wireless Networks,10.1007/978-3-031-04245-4_26,Springer,2022-01-01,"With the application of 5G network technology and the popularization and improvement of information technology, many applications of industrial Internet of Things have been born corresponding to industrial technology. Almost every industrial field has its corresponding industrial APP, constantly approaching the direction of “Internet of Everything”. Engineering projects include a large number of intelligent manufacturing, artificial intelligence, industrial robots, automation project transformation, in this field, there is a special group of talents, that is, many higher vocational colleges and application-oriented undergraduate universities training engineering application-oriented talents. They are the core participants of the industrial Internet of Things and intelligent manufacturing industry, and they need to master the research methods and project process of engineering projects in the era of information and intelligence.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-04245-4_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-9492-9_243,Using Affordances to Improve Robotic Understanding Based on Deep Learning,Proceedings of 2021 International Conference on Autonomous Unmanned Systems (ICAUS 2021),10.1007/978-981-16-9492-9_243,Springer,2022-01-01,"The affordance theory provides a biology-inspired approach to enable a robot to act, think and develop like human beings. Based on existing affordance relationships, a robot understands its environment and task in terms of potential actions that it can execute. Deep learning makes it possible for a robot to perceive the environment in an efficient manner. As a result, affordance-based perception together with deep learning provides a possible solution for a robot to provide good service to us. However, affordance knowledge can not be gained just by visual perception and a single object might have multiply affordances. In this paper, we propose a novel framework to combine affordance knowledge and visual perception. Our method has the following features: (i) map human instructions into affordance knowledge; (ii) perceive the environment based on deep neural networks and associate each object with its affordances. In our experiments, a humanoid robot NAO is used and the results demonstrate that affordance knowledge can improve robotic understanding based on deep learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-9492-9_243,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-0332-8_19,Towards Robotic Knee Arthroscopy: Spatial and Spectral Learning Model for Surgical Scene Segmentation,Proceedings of International Joint Conference on Advances in Computational Intelligence,10.1007/978-981-19-0332-8_19,Springer,2022-01-01,"Minimally invasive surgeries are complex to perform, and surgical outcomes are varied due to a limited view of the surgical scene. There is a lack of reliable vision systems that can identify and segment different tissue types intra-operatively. Here we introduce a novel approach towards overcoming this limitation. Our approach extracts geometric and spectral information captured by a miniaturized camera using deep learning algorithms. We have successfully implemented a deep neural network and trained it for in-situ labelling of soft and hard tissues acquired from clinically relevant cadaveric studies. Although presented and validated for knee arthroscopy our approach can be implemented across different endoscopic platforms. The intraoperative nature of tissue segmentation could be easily implemented in medical imaging systems for achieving better outcomes in minimally invasive procedures. In addition to segmenting different tissue types like, ACL, femur, tibia, cartilage, and meniscus, our network can also segment surgical tools present inside the knee cavity. The achieved dice similarity score for the tissue types femur, tibia, ACL, and meniscus were 0.91, 0.71, 0.39, and 0.62.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-0332-8_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-92442-3_13,A Localization Approach Based on Omnidirectional Vision and Deep Learning,"Informatics in Control, Automation and Robotics",10.1007/978-3-030-92442-3_13,Springer,2022-01-01,"The present work introduces a study about the use of a deep learning tool to tackle the visual localization. The approach proposed consists in developing a Convolutional Neural Network (CNN) with the aim of addressing the room retrieval task. Additionally, the network can be used to extract holistic descriptors from intermediate layers. Therefore, the localization can be carried out by meas of comparing the holistic descriptor obtained during the localization process with the descriptors obtained during the mapping process, but it can be carried out by using a hierarchical strategy. Concerning the hierarchical localization approach, in previous works, it has been addressed by means of a nearest neighbour search using different layers of information. In the present work, first is addressed a rough step which consists in solving the room retrieval with the CNN and, after that, a nearest neighbour search is carried out by using the holistic descriptors contained in the room selected. Hence, this work evaluates firstly the validity of the holistic descriptors extracted from the CNN and, secondly, evaluates the hierarchical method based on the CNN tool. The experiments to evaluate the validity of the proposed methods are carried out with an indoor dataset with real-operation conditions. The results show that the proposed approach based on deep learning is a robust solution to tackle the visual localization task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-92442-3_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-04881-4_29,Domain Adaptation in Robotics: A Study Case on Kitchen Utensil Recognition,Pattern Recognition and Image Analysis,10.1007/978-3-031-04881-4_29,Springer,2022-01-01,"Recognition methods based on Deep Learning (DL) currently represent the state of the art in a number of robot-related tasks as, for instance, computer vision for autonomous guidance or object manipulation. Nevertheless, the large requirements of annotated data constitute one of their main drawbacks, at least when considering supervised frameworks. In this context, the Domain Adaptation (DA) paradigm stands as a promising, yet largely unexplored, framework for tackling such cases avoiding the need for manually data annotation. This work presents a case of study of unsupervised DA algorithms for robot-based kitchenware manipulation. The influence of combining several source or target domains is also analyzed as a proposal to improve the adaptation process. For that, we evaluate three representative state-of-the-art techniques (DANN, PixelDA, and DeepCORAL) and assess them using four corpora of kitchen household images, being three of them specifically developed for this work. The results obtained show that the DeepCORAL strategy generally outperforms the rest of the cases. Moreover, the various scenarios posed suggest that the combination of source sets enhances the adaptation to novel target domains. Finally, the experimentation state the relevance of DA methods and their usefulness in robotic applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-04881-4_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-95892-3_13,Autonomous Off-Road Navigation Using Near-Feature-Based World Knowledge Incorporation on the Example of Forest Path Detection,Intelligent Autonomous Systems 16,10.1007/978-3-030-95892-3_13,Springer,2022-01-01,"This paper presents a novel approach for robust off-road navigation based on deep convolutional neural networks which are combined with OpenStreetMap data to perform a forest path-based local localization approach. Corresponding near features are used to integrate navigation relevant world knowledge into a local multi-feature map. A behavior-based controller adapts the robot’s trajectory based on available features and its detection quality. The approach was tested in the Rhineland-Palatinate forest. Different forest way detection setups were evaluated and are discussed in detail. Additionally, the autonomous mobile robot GatorX855D followed a forest trail using the resulting multi-feature map.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-95892-3_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-8155-7_99,A ROS-Based Universal Robotic Platform for Artificial Intelligence Education,"Advances in Guidance, Navigation and Control",10.1007/978-981-15-8155-7_99,Springer,2022-01-01,"With the rapid development of Artificial Intelligence (AI), related education and teaching activities need to be followed up urgently. Robotics curriculum system and teaching pattern related to AI also need to be innovated and reformed. In this case, we designed the robot software engineering course, which includes robotic core functions: navigation, vision, speech interaction and manipulator operation, etc. To accelerate novice learners to grasp the basic knowledge about AI, we developed the universal robotic platform based on ROS, and apply it to a variety of specific environments and scenarios. To investigate the effect of the proposed education method, we provided opportunities for the novice learners to attend the International RoboCup Competitions, and obtained not only the Champion but also a serial of remarkable achievements.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-8155-7_99,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-2377-6_21,Neural Network-Based TID Controller for Wheeled Mobile Robot Trajectory Tracking,Proceedings of Sixth International Congress on Information and Communication Technology,10.1007/978-981-16-2377-6_21,Springer,2022-01-01,"This brief proposes a novel control scheme for tracking a differential drive wheeled mobile robot. A neural network-based tilt integral derivative controller is introduced to track the wheeled mobile robot. Conventional control algorithms fail to satisfy the desired performance in terms of accuracy, total control effort, and maximum control input. By properly training a neural network, optimal values of the parameters of the tilt integral derivative (TID) controller are obtained. The proposed controller is used to track circular, lemniscate, straight line, and B spline trajectories. Performance of the proposed controller is compared with conventional TID and PID controllers using different performance analysis indices. Simulation studies show that the integral squared error and total control effort are small for the proposed controller as compared to the TID and PID controllers. Hassan, Najva Saleem, Abdul",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-2377-6_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-64573-1_172,Artificial Intelligence in Urology,Artificial Intelligence in Medicine,10.1007/978-3-030-64573-1_172,Springer,2022-01-01,"Urology is intertwined with surgical technology. Endoscopic and robotic surgery found early acceptance within the practice of urology. Artificial intelligence research has begun to permeate through the urologic literature. In urologic oncology, AI systems have been developed to diagnose malignancy, guide therapeutics, and predict surgical outcomes. These systems have been shown to grade prostate cancer biopsies more accurately than general pathologists and can accurately predict postoperative length of stay based upon robotic laparoscope kinetics. AI enables accurate prediction of kidney stone passage and stone clearance rates after surgery. Robotic systems using AI have successfully guided renal puncture in early clinical trials. The evaluation and treatment of the infertile male is seeing a paradigm shift as AI systems predict fertility potential and sperm retrieval success. In the future, AI algorithms may inform sperm retrieval for in vitro fertilization optimization. While many of the aforementioned AI systems remain isolated within single-institution research endeavors, published online AI predictors make these analyses accessible to general urologists. In time, AI can be expected to take a larger foothold into modern urologic practice.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-64573-1_172,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-19-1746-2_3,Prospects of Smart Aquaculture in Indian Scenario: A New Horizon in the Management of Aquaculture Production Potential,Smart and Sustainable Food Technologies,10.1007/978-981-19-1746-2_3,Springer,2022-01-01,"As the scale and density of aquaculture operations have expanded, overproduction in contemporary aquaculture has resulted in an unbalanced water environment, increased fish disease outbreaks, and decreased aquatic product quality. The intelligent fish farm attempts to deal with the precise work of increasing oxygen, optimising feeding, reducing disease incidences, and accurately harvesting through the concept of “replacing man with machine” in order to completely free human labour and complacency, as a result of a labour shortage and an urgent need for innovation in aquaculture technologies. Thus, IoT adoption is increasing at an alarming rate. IoT is currently widely employed in a wide range of industries and applications. Take aquaculture, for instance, as an example of one of a number of options. Traditional farmers struggle to keep up with changes in their cultural system and the quality of their water. Cloud-based aquaculture monitoring and control systems are built on model integration. Client data visualisations were part of a system that included an open-ended smart sensor module for the management of the system’s aeration as well as components for a local network and the cloud computing infrastructure. The smart sensor module gives us information about the water that we use to monitor it. This high-tech sensor module has sensors for hydrogen potential, dissolved oxygen, temperature, and level. For every type of aquaculture, web and Android apps can assist you determine the ideal water temperature for your pond. Additionally, in India, feed dispensing and sensors have been adopted recently. Artificial neural networks and machine learning must be integrated in the logarithm in order for the system to run smoothly AI and machine learning are summarised below, along with their present state and challenges and prospects in the field of smart aquaculture.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-1746-2_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-64573-1_177,AIM in Rehabilitation,Artificial Intelligence in Medicine,10.1007/978-3-030-64573-1_177,Springer,2022-01-01,"Technological advancements in the past decade, especially in the field of Artificial Intelligence (AI), have influenced almost every industry, and the field of medicine is not an exception. From robots taking care of time-consuming, repetitive tasks in hospitals to rapid cancer diagnosis methodologies developing every day, it is visible that AI has potential to help further the medical discipline. AI in rehabilitation has broad usability, such as assisting in the rehabilitation session, evaluating the treatment progress (decision support), and providing prognosis regarding risk of complications or success of the treatment. In this chapter, firstly rehabilitation and its specialties will be explained followed by a thorough explanation of why AI can be helpful in rehabilitation. Furthermore, different applications of AI in this field will be discussed. The chapter also brings some examples from recent studies and state-of-the-art research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-64573-1_177,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-74648-3_1,Drive Towards 6G,Enabling 6G Mobile Networks,10.1007/978-3-030-74648-3_1,Springer,2022-01-01,"As fifth-generation (5G) mobile networks are being rolled out, the telecom industry and academia are now coordinating the 6G research effort towards defining the requirements and use cases for beyond 5G (B5G) or so-called sixth-generation (6G) mobile networks. 6G envisages an evolutionary communication platform based on complete network softwarisation, inclusive communications mediums including satellite, and ultra-dense networks to cater for the market demands that requires ultra-high speeds, tactile response time, and lower cost of network ownership by 2030. This chapter provides an overview of the use cases for B5G/6G systems, including holographic telepresence, digital twin, connected robotics, distributed artificial intelligence, and blockchain technologies. It further reviews the current standardisation and deployment status of 5G technology as a baseline and the drive towards 6G by identifying key enabling technologies, system requirements, and an overview on global B5G/6G activities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-74648-3_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-83864-5_32,The Role of Technology and Innovation,Global Cardiac Surgery Capacity Development in Low and Middle Income Countries,10.1007/978-3-030-83864-5_32,Springer,2022-01-01,"Technology Technology holds a significant role in the past, present, and future of cardiac surgical care capacity in low-to-middle income countries (LMICs): a role that holds positive value overall in opportunity and outcome, despite recurrent and emerging practical and ethical challenges to different stakeholder Stakeholders groups. Aided by case studies, this chapter discusses the value of both creating technologies to benefit cardiac surgical care directly, and creating environments Environments for technological innovation Innovation . This is addressed by examining the value of technology Technology for, and within, human and physical resource Physical resource development Development . Human resource Human resource development, consisting of cognitive, technical, and reflective components, is developed through two complementary approaches: increasing the minimum quality Quality standard achieved by healthcare professionals, and increasing the maximum quality Quality standard achievable. Both of these strategies are hugely helped by the implementation Implementation of technology Technology to facilitate new training Training methods, relationships, and career opportunities. The discussion of physical resource Physical resource development is guided by the journey of development and implementation taken by individual technologies, identifying key forms of support required to combat potential issues and increase the chance of success. Technology Technology requires significant resource investment by a varied portfolio of stakeholder Stakeholders groups to deliver on its current achievable, and future potential promise to contribute significantly towards cardiac surgical capacity development Development in LMICs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-83864-5_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-95675-2_4,Data Analytics for Accountable Care Organisations in a Shifting Landscape of Health and Medicine,Digital Disruption in Healthcare,10.1007/978-3-030-95675-2_4,Springer,2022-01-01,"The US government spends close to $580 billion on the Medicare health insurance program every year. The governmental spending on health care in the United States exceeds $1 trillion on an annual basis. Despite these high expenses, there is a concern that the health outcomes for patients are not improving. In this chapter, we present techniques to analyze healthcare data using examples. We discuss the quality measures that accountable care organizations need to demonstrate. We present an infrastructure schematic that can be used to analyze volumes of healthcare data. We present specific examples of healthcare decisions that can be made using data analytics and how healthcare technical infrastructure can be utilized for data analytics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-95675-2_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-99826-4_5,Full-Closed Loop Tracking Control Based on Multi-factor Coupling Compensations Using Artificial Neural Network for a Cable-Pulley-Driven Surgical Robotic Manipulator,Proceedings of the 2022 USCToMM Symposium on Mechanical Systems and Robotics,10.1007/978-3-030-99826-4_5,Springer,2022-01-01,"The Cable-Pulley-Driven System (CPDS) is widely used in surgical robots. It is an important foundation for long-distance drive and design of small-sized end-effectors. It is generally used as one of the key components of the minimally invasive surgical machine-driven unit. Compared with the traditional rigid driven system, CPDS is light in weight, compact in structure and flexible in movement. CPDS can complete long-distance and high-load transmission in the narrow and curved space of the human body. However, due to the non-linear characteristics of CPDS, the tension loss of the cable will be caused, and the positioning accuracy and position control performance of the operating device will be significantly affected. This paper proposed a full-closed loop tracking control method for CPDS surgical robotic manipulator with PID position control strategy. This method used an Artificial Neural Network (ANN) for Multi-factor Coupling Compensation (MCC). The feasibility and effectiveness of this method are verified by a series of experimental analyses on a Backdrivable Cable-Driven Series Elastic Actuator (BCDSEA).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-99826-4_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-81007-8_141,An Emotional Interaction Robot with Facial Expression Recognition Realized on Raspberry Pi and STM32,Advances in Intelligent Automation and Soft Computing,10.1007/978-3-030-81007-8_141,Springer,2022-01-01,"In this paper, we propose a framework of emotional interaction robot which can recognize seven basic facial expressions of users and make responses accordingly. Considering the benefits provided by the facial expression recognition system, it is applied to the companion robot to greatly enrich the emotional communications between human and robots. The proposed framework mainly consists of two modules, the module of facial expression recognition and the interaction module. The module of facial expression recognition is implemented based on a CNN trained on the FER2013 dataset and realized on Raspberry Pi 3b+. The interaction module is realized by a TFT-LCD and a speaker controlled by the STM32 single-chip microcomputer. When receiving the signal from the control button on STM32, the recognition module reads in a frame from the video stream taken by the camera, and then performs the preprocessing and recognizes the facial expression. After successfully recognizing a kind of emotion, the recognition result is sent to the interaction model, and then it displays one of emojis stored in its SD card and plays music accordingly.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-81007-8_141,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-82199-9_38,"Creating a Robot Brain with Object Recognition Using Vocal Control, Text-to-Speech Support and a Simple Webcam",Intelligent Systems and Applications,10.1007/978-3-030-82199-9_38,Springer,2022-01-01,"This paper presents the creation of a robot brain from a computing device. The robot brain is software which can recognize an object based on the taken picture. The system is a neural network which was previously trained with images and the decision is made by comparing a similar known picture to the actual picture of the object which needs to be recognized. The images from the neural network have name associated. The name of most similar picture from the neural network is associated with the newly taken picture and that will be the name of the recognized object. The system can be voice controlled and reads the recognized word loud with text-to-speech software. This way the user can talk to the system to recognize an object and say it loud what it is. The software can be used by children, who are learning objects' name, by blind people who would like to know what specific object they have in their hand or by anyone who has a strange object in hand and does not know what it is.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-82199-9_38,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-2541-2_61,Implementation of Artificial Intelligence and Robotics that Replace Employees in Indonesia,Ubiquitous Intelligent Systems,10.1007/978-981-19-2541-2_61,Springer,2022-01-01,"Artificial intelligence is a technology that is widely adopted in the industry 4.0 era. Artificial intelligence is capable of connecting all devices, so that one can automate all devices without having to be in place. Especially now many machines can interpret certain conditions or events with Artificial Intelligence. The project aims to understand the cause and effect of Artificial Intelligence in human resources in Indonesia. Survey method is used to gather information and through surveys, it is determined that people think AI is a good influence to open new jobs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-2541-2_61,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7657-4_28,The Future Warfare with Multidomain Applications of Artificial Intelligence: Research Perspective,Proceedings of Second International Conference on Sustainable Expert Systems,10.1007/978-981-16-7657-4_28,Springer,2022-01-01,"We live in a period when historical fiction has become current reality. With our future being automated, using AI on a daily basis will only get more convenient. Making military weapons to detect, monitor, and engage a human being with attacks may all be done in the privacy of one's own garden. There is a plethora of AI software out there that can be readily integrated into combat weapons. The automobile industry is already incorporating AI into vehicles to assess driving circumstances and give augmented reality to drivers via heads-up displays in order to assist avert accidents. Similarly, artificial intelligence will be utilized to study the battlefield and give soldiers with augmented reality information via heads-up displays and weapon control systems. Since AI is not a single technology, it has been argued that it might be used by the military in a variety of ways. Intelligence, surveillance, and reconnaissance (ISR) activities, as well as processing and interpreting sensor data and geographic imaging analysis, are all examples of AI. Artificial intelligence has the potential to reduce human involvement in conflict, whether it is employed for combat robots or data analysis. AI has the potential to profoundly alter the nature of war. The article mainly focussed on warfare technologies and applications. The main aim of this review is to understand the current applications being used in armed forces and proposed technologies of artificial intelligence.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7657-4_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-9551-3_6,Artificial Intelligence in Rehabilitation Evaluation-Based Robotic Exoskeletons: A Review,Bio-inspired Motor Control Strategies for Redundant and Flexible Manipulator with Application to Tooling Tasks,10.1007/978-981-16-9551-3_6,Springer,2022-01-01,"The center and foundation of recovery is evaluation, which will lead to the whole therapy phase. Healthcare professionals or clinicians must evaluate patients’ lower/upper limb activity based on discretionary and objective assessments during recovery. Existing approaches can result in a significant error and high expense. As a result, AI is being used in the area of medical recovery. The implementation of analytical estimation approaches based on AI, such as error of trajectory function, joint angular velocity, and joint angels, and function of sEMG's signal will be summarized in this analysis. Eventually, the study suggests that the size of data and the number of features affect current objective approaches. This chapter will include guidance for a more extensive application in the area of recovery.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-9551-3_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-93244-2_36,Legal Regulation of Artificial Intelligence in the Area of Investment in the Economy,Imitation Market Modeling in Digital Economy: Game Theoretic Approaches,10.1007/978-3-030-93244-2_36,Springer,2022-01-01,"The article is devoted to the hot issues of legal regulation of artificial intelligence and robotics (AI and RT) of various countries, including the Russian Federation and the Republic of Belarus. The article shows the principal results of the analysis of existing approaches to the legal regulation of AI and RT in investment in the economy. From the said positions, the author researches the basic ideas in the formation of legislation on AI and RT systems. Simultaneously, the existing and potential legal problems arising in the Digital Age and competition in attracting investment are investigated and identified. The author also has developed proposals for further discussion of such issues as legally relevant problems for the growth of the AI and RT; creation of a concept of legal regulation in AI and RT, necessary for the development (revision) of legislation concerning the formation, exploitation, distribution of robots and systems with AI, and the fundamental principles and limits of legal regulation of these relations. The foundation for identifying the directions of legislative development should be the principle of “stimulation before regulation”, with the balance of interests of individuals, society, and the state, concerning the proper provision of security and protection of rights and interests associated with the development of innovations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-93244-2_36,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-81166-2_50,PyChrono and gym-chrono: A Deep Reinforcement Learning Framework Leveraging Multibody Dynamics to Control Autonomous Vehicles and Robots,Advances in Nonlinear Dynamics,10.1007/978-3-030-81166-2_50,Springer,2022-01-01,"gym-chrono is a set of simulated environments for Deep Reinforcement Learning (DRL) extending OpenAI Gym (Brockman et al., Openai gym, 2016) with robotics and autonomous driving tasks. The physics of these environments is simulated thanks to Project Chrono (Tasora et al., Chrono: An open source multi-physics dynamics engine, 2016), an open-source multi-physics simulation engine capable of simulating Multibody Dynamics with constraints and smooth or non-smooth contacts. The most used Deep Learning frameworks (such as PyTorch and Tensorflow) have Python API, and thus using Python to implement DRL algorithms is the most convenient option. For this reason, a condition for the creation of these environments has been the development of PyChrono, a Python module consisting of the Python bindings to Project Chrono C++ API, to effectively interface the simulation capabilities of Project Chrono with Deep Learning frameworks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-81166-2_50,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-2266-4_36,A Review on Financial Robot Process Auto-mining Based on Reinforcement Learning,Digital TV and Wireless Multimedia Communications,10.1007/978-981-19-2266-4_36,Springer,2022-01-01,"In recent years, with the rapid development of science and technology, human society has ushered in the digital information era. Facing the gradually expanding office field and complex business processes, robotics process automation (RPA) technology oriented process auto-discovery and process auto-mining have shown great potential for development. Most of enterprise’s financial personnel are also faced with tedious business processes and other situations. Thus, research of the financial robot process auto-mining method based on reinforcement learning becomes particularly important. Based on the traditional financial robot design, through the exploration and understanding of reinforcement learning, the Model-Based strategy optimization algorithm is used to establish a high-frequency business process auto-discovery model. The unmanned underwater vehicle (UUV) autonomous decision-making technology is used to establish an autonomous decision-making model for infrequent business processes, and then the application of natural language understanding and image recognition technology in human-computer interaction is used to study the human-computer high-frequency interaction technology. Finally, based on the time decay model and batch update model, we design a business process mining model for semi-structured data flow, which makes the research of financial robot process automatic mining method complete. The research of automatic mining method of financial robot process based on reinforcement learning will promote the further development of financial automation, and RPA technology will be brilliant in the future.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-2266-4_36,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-98883-8_17,Automatic Tuning of the Motion Control System of a Mobile Robot Along a Trajectory Based on the Reinforcement Learning Method,Pattern Recognition and Information Processing,10.1007/978-3-030-98883-8_17,Springer,2022-01-01,"The is a description of the development process of an adaptive motion controller for a two-wheeled mobile robot along a color-contrast line. The learning process of the controller took place on the basis of the digital twin of the indicated robot, with the use of reinforcement learning technology. The digital twin and reinforcement learning implemented in MATLAB/Simulink frameworks, for the latter, the Reinforcement Learning Toolbox library was used. The mobile robot equipped with a differential driver, and the PID-controller adjusted the angular speed of the rotation of both wheels. Therefore, the main purpose of the research work was to determine the coefficients of the PID-controller. The Twin-Delayed Deep Deterministic Policy Gradient Agents was used as a learning algorithm, which used a deterministic actor and a Q-value critic. As a function of reward, the minimization of the distance between the center of the robot and the edge of the nearest section of the color-contrast line was used, as well as the calculation of the angle (γ) between the tangent to the edge of the ellipse curve, where the robot should be located and guided at the current time. The developed environment, which would be influenced by the agent, as well as the policy of the agent, which provides a detailed diagram of the neural network for the actor and the critic. Different methods carried out for the comparison of the results, such as genetic algorithms and reinforcement learning by the TD3 algorithm. The experiments have shown that the founded coefficients of the PID-controller afford control the movement of the robot accurately, even on an unfamiliar track.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-98883-8_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-5857-0_41,Ethics of Robotics Applications,International Conference on Cognitive based Information Processing and Applications (CIPA 2021),10.1007/978-981-16-5857-0_41,Springer,2022-01-01,"Although artificial intelligence (AI), especially robotics technology, has gained rapid growth and been applied in many areas, bringing numerous positive outcomes, it has also resulted in many ethical concerns, most notably in the development of AI and robot interaction technology. To better realize the “ benign interaction between man and machine” and open a new era of intelligence in which man and machine coexist harmoniously, it is necessary to coordinate efforts in strengthening legislative research, formulating ethical standards, improving safety standards, establishing a regulatory system, and promoting global governance in order to effectively prevent and respond to the multiple ethical issues caused by robots in the process of design, R&D, production, and use.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-5857-0_41,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-87428-5_19,On the Horizon: Innovative Techniques and Procedures,Neurointervention in the Medical Specialties,10.1007/978-3-030-87428-5_19,Springer,2022-01-01,The neurointerventional field is rapidly growing in all its modalities. Advances in technology and engineering as well as a commitment to basic science and clinical research are rapidly expanding the scope of neuroendovascular interventions.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-87428-5_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-97672-9_40,"Comparison of Deep Q-Learning, Q-Learning and SARSA Reinforced Learning for Robot Local Navigation",Robot Intelligence Technology and Applications 6,10.1007/978-3-030-97672-9_40,Springer,2022-01-01,"This paper presents a performance comparison of mobile robot obstacle avoidance between using Deep Reinforcement Learning (DRL) and two classical Reinforcement Learning (RL). For the DRL-based method, Deep Q-Learning (DQN) algorithm was used whereas for the RL-based method, Q-Learning and Sarsa algorithms were used. In our experiments, we have used the extended OpenAI Gym ToolKit to compare the performances of DQN, Q-Learning, and Sarsa algorithms in both simulated and real-world environments. Turtlebot3 Burger was used as the mobile robot hardware to evaluate the performance of the RL models in the real-world environment. The average rewards, episode steps, and rate of successful navigation were used to compare the performance of the navigation ability of the RL agents. Based on the simulated and real-world results, DQN has performed significantly better than both Q-Learning and Sarsa. It has achieved 100% success rates during the simulated and real-world tests.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-97672-9_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-92790-5_16,Multi-agent Reinforcement Learning and Individuality Analysis for Cooperative Transportation with Obstacle Removal,Distributed Autonomous Robotic Systems,10.1007/978-3-030-92790-5_16,Springer,2022-01-01,"Cooperative transportation is one of the essential tasks for multi-robot systems to imitate the decentralized systems of social insects. However, in a situation involving an obstacle on the pathway, multiple robots need to realize transportation and obstacle removal simultaneously. To address this multitasking problem, we first introduce a learning scenario and train robots’ decentralized policies via multi-agent reinforcement learning. Next, we propose two virtual experiments with blindfold teams and homogeneous teams to analyze the individual behaviors of the trained robots. The results showed that three robots with different policies performed two tasks simultaneously as a team. One robot’s policy tended to perform obstacle removal, and the other robots’ policies tended to perform cooperative transportation. Further, the first robot’s policy had the potential to perform two tasks simultaneously depending on the situation. Finally, we demonstrated the trained policies with three ground robots to show the feasibility of the system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-92790-5_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-8155-7_453,Application of Actor-Critic Deep Reinforcement Learning Method for Obstacle Avoidance of WMR,"Advances in Guidance, Navigation and Control",10.1007/978-981-15-8155-7_453,Springer,2022-01-01,"A state-of-the-art framework, i.e., deep deterministic policy gradient (DDPG), has obtained a certain effect in the robotic control field. When the wheeled mobile robot (WMR) executes operation in unstructured environment, it is critical to endow the WMR with the capacity to avoid the static and dynamic obstacles. Thus, a obstacle avoidance algorithm based on DDPG is proposed to realize the autonomous navigation in the unknown environment. The WMR in this study installs the requisite sensors to provide the fully observable environment information at any moment. The continuous state space description for WMR and obstacles is designed, together with the reward mechanism and action space. The learning agent. i.e., the studied mobile robot, utilizes the DDPG model, through the continuous interaction with the surrounding environment and the application of historical experience data, the WMR can learn the optimal action behavior. Simulation along with test works strongly verify the collision-free ability in static and dynamic scenarios with multiple observable obstacles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-8155-7_453,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7996-4_24,Goal-Oriented Obstacle Avoidance by Two-Wheeled Self Balancing Robot,Machine Learning and Autonomous Systems,10.1007/978-981-16-7996-4_24,Springer,2022-01-01,"Gurnani, Rajat Rastogi, Shreya Chitkara, Simrat Singh Kumari, Surbhi Gagneja, Abhishek A solution to an age-old problem of keeping the inverted pendulum-based robot upright and its collision-free navigation through an unknown environment is presented in this paper. Two deep reinforcement learning models run simultaneously on a two-wheeled self-balancing robot. The robot acts as the agent in the learning environment created in Unity3D, a real-time development platform. Proximal Policy Optimization algorithm, an on-policy gradient method for reinforcement learning, has been used in both models. The navigation model feeds the intermediate position of the robot to the balancing model, which then outputs a set of actions to the robot. In addition, the navigation model uses curiosity-driven learning thus expanding the set of solvable tasks. The algorithm consequently generates an intrinsic reward function, which makes the robot generalize better with unexplored environments. Furthermore, the resultant intelligent controller is made to navigate both dynamic and static obstacle-filled courses. The simulations were run using Unity and the Nvidia PhysX engine.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7996-4_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-9247-5_28,Sample-Efficient Reinforcement Learning Based on Dynamics Models via Meta-policy Optimization,Cognitive Systems and Information Processing,10.1007/978-981-16-9247-5_28,Springer,2022-01-01,"Model-based reinforcement learning (RL) can acquire remarkable sample efficiency, which makes it a suitable choice for applications where experiment data is hard to collect. However, it is difficult to learn an accurate dynamics model fully matched with the real-world, and the accuracy of the model usually affects the agent’s final performance. In this paper, we propose a novel model-based RL approach called Meta-policy Optimization method with branched rollouts (MPOBR), which gets rid of strong dependency on an accurate model. In MPOBR, meta-learning is used to train a policy prior on an ensemble of learned dynamics models, so that this prior can be rapidly adapted to the environment when combined with environment rollouts. To reduce the affect of model compounding bias, short model-generated rollouts branched from real data are used to update the meta-policy. The experiments on simulated robotic tasks are designed to verify the effectiveness of our method. Results show that our approach can achieve the same asymptotic performance of state-of-the-art model-free algorithms while significantly reducing sample complexity.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-9247-5_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86294-7_34,Learning and Transfer of Movement Gaits Using Reinforcement Learning,Robotics for Sustainable Future,10.1007/978-3-030-86294-7_34,Springer,2022-01-01,"In this paper, a four-legged robot is trained to walk in the real world, without any manual engineering or programmed movement sequences. The goal is to enable robots to learn to walk on their own using reinforcement learning algorithms. Since each leg has three joints and the robot has four legs in total, this is a very complicated behavior to learn, so doing the training process in the real world would not be feasible. To accelerate the learning progress, an accurate simulated environment is used in which the robot can safely be trained using state-of-the-art learning algorithms, such as soft-actor critic and proximal policy optimization. The learnt behavior has then successfully been transferred to the real robot, with the real robot mirroring the behavior of the robot in the simulation. This resulted in the real robot moving forward. The Unity3D engine will be used for the simulation of the robot, along with the recently introduced ml-agents toolkit, which enable easy TensorFlow integration into the training environment. After a successful training in the simulation, the learned locomotion skills from the simulation is transferred to the robot in the real world. To transfer the data with minimal losses, the simulation environment will have to accurately mirror the real-world environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-86294-7_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-021-11112-7,Optimization and improvement of a robotics gaze control system using LSTM networks,Multimedia Tools and Applications,10.1007/s11042-021-11112-7,Springer,2022-01-01,"Gaze control represents an important issue in the interaction between a robot and humans. Specifically, deciding who to pay attention to in a multi-party conversation is one way to improve the naturalness of a robot in human-robot interaction. This control can be carried out by means of two different models that receive the stimuli produced by the participants in an interaction, either an on-center off-surround competitive network or a recurrent neural network. A system based on a competitive neural network is able to decide who to look at with a smooth transition in the focus of attention when significant changes in stimuli occur. An important aspect in this process is the configuration of the different parameters of such neural network. The weights of the different stimuli have to be computed to achieve human-like behavior. This article explains how these weights can be obtained by solving an optimization problem. In addition, a new model using a recurrent neural network with LSTM layers is presented. This model uses the same set of stimuli but does not require its weighting. This new model is easier to train, avoiding manual configurations, and offers promising results in robot gaze control. The experiments carried out and some results are also presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11042-021-11112-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-96993-6_11,Walking Through the Turing Wall,Biologically Inspired Cognitive Architectures 2021,10.1007/978-3-030-96993-6_11,Springer,2022-01-01,"Can the machines that play board games or recognize images only in the comfort of the virtual world be intelligent? To become reliable and convenient assistants to humans, machines need to learn how to act and communicate in the physical reality just like people do. The authors propose two novel ways of designing and building Artificial General Intelligence (AGI). The first one seeks to unify all participants in any instance of the Turing test – the judge, the machine, the human-subject as well as the means of observation instead of building a separating wall. The second one aims to design AGI programs in such a way that they can move in various environments. The authors thoroughly discuss four areas of interaction for robots with AGI and are introducing a new idea of techno-umwelt bridging artificial intelligence with biology in a new way.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-96993-6_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-74032-0_21,Web Service for Point Cloud Supported Robot Programming Using Machine Learning,"Annals of Scientific Society for Assembly, Handling and Industrial Robotics 2021",10.1007/978-3-030-74032-0_21,Springer,2022-01-01,"In industrial automation, the use of robots is already standard. But there is still a lot of room for further automation. One such place where improvements can be made is in the adjustment of a production system to new and unknown products. Currently, this task includes the reprogramming of the robot and a readjustment of the image processing algorithms if sensors are involved. This takes time, effort, and a specialist, something especially small and middle-sized companies shy away from. We propose to represent a physical production line with a digital twin, using the simulated production system to generate labeled data to be used for training in a deep learning component. An artificial neural network will be trained to both recognize and localize the observed products. This allows the production line to handle both known and unknown products more flexible. The deep learning component itself is located in a cloud and can be accessed through a web service, allowing any member of the staff to initiate the training, regardless of their programming skills. In summary, our approach addresses not only further automation in manufacturing but also the use of synthesized data for deep learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-74032-0_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-98682-7_27,Vision-Based Machine Learning in Robot Soccer,RoboCup 2021: Robot World Cup XXIV,10.1007/978-3-030-98682-7_27,Springer,2022-01-01,"Robots need to perceive their environment in order to properly interact with it. In the RoboCup Soccer Middle Size League (MSL) this happens primarily through cameras mounted on the robots. Machine Learning can be used to extract relevant features from camera imagery. The real-time analysis of camera data is a challenge for both traditional and Machine Learning algorithms, since all computations in the MSL have to be performed on the robot itself. This contribution shows that it is possible to process camera imagery in real-time using Machine Learning. It does this by presenting the current state of Machine Learning in MSL and providing two examples that won the Scientific and Technical Challenges at RoboCup 2021. Both examples focus on semantic detection of objects and humans in imagery. The Scientific Challenge winner presents how YOLOv5 can be used for object detection in the MSL. The Technical Challenge winner demonstrates how to improve interaction between robots and humans in soccer using OpenPose. This contributes towards the goal of RoboCup to arrive at robots that can beat the human soccer world champion by 2050.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-98682-7_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-80119-9_46,Machine Learning Control for Mobile Robot by Approximation Extremals by Symbolic Regression,Intelligent Computing,10.1007/978-3-030-80119-9_46,Springer,2022-01-01,"The control system synthesis problem is considered for mobile robot. It is necessary to find a control as function of state space vector that supplies achievement of terminal position from some compact set of initial conditions with optimal value of quality criterion. For solution of this problem symbolic regression is used. This allows to find a structure of control function mathematical expression. General properties of symbolic regression are presented. Search of mathematical expression structure for control system is performed on the space of codes, therefore here a specific forms of genetic algorithms are used. They are differed crossover and mutation operations in depend on form of mathematical expression codding. At the searching optimal mathematical expression for control system by symbolic regression methods two approaches can be applied two approaches, as in artificial neural network technology, with teacher and without one. For obtaining a training set it is necessary to solve the optimal control problem some times for set of initial conditions. It is shown, that for decreasing the search space the principle of small variations of basic solution can be used and a basic solution should be set as closed to optimal one intuitively. In this case crossover and mutation operations will be performed the same on sets of variation vectors independently on symbolic regression method. In a computational experiment the control system synthesis problem for mobile robot is considered, that must be move from an area of initial conditions to the set terminal position on the plane with phase constraints.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-80119-9_46,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-92790-5_23,Classification-Aware Path Planning of Network of Robots,Distributed Autonomous Robotic Systems,10.1007/978-3-030-92790-5_23,Springer,2022-01-01,"We propose a classification-aware path planning architecture for a team of robots in order to traverse along the most informative paths with the objective of completing map classification tasks using localized (partial) observations from the environment. In this method, the neural network layers with parallel structure utilize each agent’s memorized history and solve the path planning problem to achieve classification. The objective is to avoid visiting less informative regions and significantly reduce the total energy cost (e.g., battery life) when solving the classification problem. Moreover, the parallel design of the path planning structure reduces the training complexity drastically. The efficacy of our approach has been validated by a map classification problem in the simulation environment of satellite campus maps using quadcopters with onboard cameras.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-92790-5_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-74032-0_18,An Approach for Direct Offline Programming of High Precision Assembly Tasks on 3D Scans Using Tactile Control and Automatic Program Adaption,"Annals of Scientific Society for Assembly, Handling and Industrial Robotics 2021",10.1007/978-3-030-74032-0_18,Springer,2022-01-01,"This contribution defines a methodology for the direct offline programming of robotic high-precision assembly tasks without the need for real-world teach-in, even for less-accurate lightweight robots. Using 3D scanning technologies, the relevant geometrical relations of the offline programming environment are adjusted to the real application. To bridge remaining accuracy gaps, tactile insertion algorithms are provided. As repetitive inaccuracy compensation through tactile search is considered wasteful, a method to automatically adapt the robot program to continuously increase precision over time, taking into account multiple influence sets is derived. The presented methodology is validated on a real-world use case from electronics production.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-74032-0_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-92790-5_31,Using Reinforcement Learning to Herd a Robotic Swarm to a Target Distribution,Distributed Autonomous Robotic Systems,10.1007/978-3-030-92790-5_31,Springer,2022-01-01,"In this paper, we present a reinforcement learning approach to designing a control policy for a “leader” agent that herds a swarm of “follower” agents, via repulsive interactions, as quickly as possible to a target probability distribution over a strongly connected graph. The leader control policy is a function of the swarm distribution, which evolves over time according to a mean-field model in the form of an ordinary difference equation. The dependence of the policy on agent populations at each graph vertex, rather than on individual agent activity, simplifies the observations required by the leader and enables the control strategy to scale with the number of agents. Two Temporal-Difference learning algorithms, SARSA and Q-Learning, are used to generate the leader control policy based on the follower agent distribution and the leader’s location on the graph. A simulation environment corresponding to a grid graph with 4 vertices was used to train and validate the control policies for follower agent populations ranging from 10 to 1000. Finally, the control policies trained on 100 simulated agents were used to successfully redistribute a physical swarm of 10 small robots to a target distribution among 4 spatial regions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-92790-5_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-97672-9_23,Towards Autonomous Pipeline Inspection with Hierarchical Reinforcement Learning,Robot Intelligence Technology and Applications 6,10.1007/978-3-030-97672-9_23,Springer,2022-01-01,"Inspection and maintenance are two crucial aspects of industrial pipeline plants. While robotics has made tremendous progress in the mechanic design of in-pipe inspection robots, the autonomous control of such robots is still a big open challenge due to the high number of actuators and the complex manoeuvres required. To address this problem, we investigate the usage of Deep Reinforcement Learning for achieving autonomous navigation of in-pipe robots in pipeline networks with complex topologies. We introduce a hierarchical policy decomposition based on Hierarchical Reinforcement Learning to learn robust high-level navigation skills. We show that the hierarchical structure introduced in the policy is fundamental for solving the navigation task through pipes and necessary for achieving navigation performances superior to human-level control. A video of our experiments can be found at: https://youtu.be/uyjSHulpGoI .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-97672-9_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-2814-6_24,Pilot Studies on Avrora Unior Car-Like Robot Control Using Gestures,Electromechanics and Robotics,10.1007/978-981-16-2814-6_24,Springer,2022-01-01,"Nikiforov, Nikita Tsoy, Tatyana Safin, Ramil Bai, Yang Svinin, Mikhail Magid, Evgeni Gesture recognition is not only an important communication channel in human-human interaction but it also allows a human to communicate with other intelligent devices. This paper presents a concept for controlling the car-like robot Avrora Unior locomotion using gestures. We created a list of 18 control commands that contains basic and compound commands. A group of 17 volunteers used this list to create individual control gestures independently. A small part of the obtained dataset of gestures was used with the Teachable machine service in order to preliminary evaluate a possibility of constructing a full-scale model and to train it appropriately. The obtained model demonstrated acceptable recognition rate. We also attempted to apply SURF and FLANN techniques for matching with the direct matching approach and the skeleton-based approach, but the matching results were not satisfactory.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-2814-6_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-99310-8_3,Robust Adversarial Reinforcement Learning for Optimal Assembly Sequence Definition in a Cobot Workcell,Advances in Manufacturing III,10.1007/978-3-030-99310-8_3,Springer,2022-01-01,"The fourth industrial (I4.0) revolution encourages automatic online monitoring of all products to achieve zero-defect and high-quality production. In this scenario, collaborative robots, in which humans and robots share the same workspace, are a suitable solution that integrates the precision of a robot with the ability and flexibility of a human. To improve human-robot collaboration, human changeable choices or even non-significant mistakes should be allowed or corrected during work. This paper proposes a robust online optimization of the assembly sequence through Robust Adversarial Reinforcement Learning (RARL), where an artificial agent is deliberately trying to boycott the assembly completion. To demonstrate the applicability of robust human-robot collaborative assembly using adversarial RL, an environment composed of Markov Decision Process (MDP) like grid world is developed and a multi-agent RL approach is integrated. The results of the framework are promising: the robot observation on human activities has been successfully achieved thanks to a penalty-reward system adopted and the alternation of human to robot actions for the wrong terminal state is the one pursued by the human, but due to robot blockage wrong actions, the right terminal state is followed by human, which is the same as the robot target.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-99310-8_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-04870-8_16,A Brief Survey of Sim2Real Methods for Robot Learning,Advances in Service and Industrial Robotics,10.1007/978-3-031-04870-8_16,Springer,2022-01-01,"Simulation has been crucial for robotics research development almost from the beginning of its existence. While simulation has been widely used for education, testing, and prototyping, only very recently the robotics community has attempted transferring behaviors learned in simulation to the real world (this process is usually referred to as Sim2Real). Those attempts have opened-up a novel research direction that has produced some exciting results that were previously thought impossible to achieve. In this paper, we attempt to give a quick overview of the most promising Simulation-To-Reality (Sim2Real) methods, results and directions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-04870-8_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-021-11614-4,Age group classification and gender recognition from speech with temporal convolutional neural networks,Multimedia Tools and Applications,10.1007/s11042-021-11614-4,Springer,2022-01-01,"This paper analyses the performance of different types of Deep Neural Networks to jointly estimate age and identify gender from speech, to be applied in Interactive Voice Response systems available in call centres. Deep Neural Networks are used, because they have recently demonstrated discriminative and representation capabilities in a wide range of applications, including speech processing problems based on feature extraction and selection. Networks with different sizes are analysed to obtain information on how performance depends on the network architecture and the number of free parameters. The speech corpus used for the experiments is Mozilla’s Common Voice dataset, an open and crowdsourced speech corpus. The results are really good for gender classification, independently of the type of neural network, but improve with the network size. Regarding the classification by age groups, the combination of convolutional neural networks and temporal neural networks seems to be the best option among the analysed, and again, the larger the size of the network, the better the results. The results are promising for use in IVR systems, with the best systems achieving a gender identification error of less than 2% and a classification error by age group of less than 20%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11042-021-11614-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-04870-8_20,Fitting Constrained Trajectory with High Variability into Redundant Robot Workspace,Advances in Service and Industrial Robotics,10.1007/978-3-031-04870-8_20,Springer,2022-01-01,"One of the important aspects of the robotic tasks is their variability. Most of the nowadays tasks are not pre-programmed and because of increased usage of reinforcement learning and other autonomous learning techniques, robotic trajectories have to be fitted in the robot workspace so that they have as much space for learning as possible, i.e., as high variability as possible. In this paper, we present and compare our methods for fitting a trajectory in a 2-D sagittal plane in the robot workspace. The method is shown on the example of robotic throwing action with the TALOS humanoid robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-04870-8_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-6265-523-2_16,Automated Care-Taking and the Constitutional Rights of the Patient in an Aging Population,Law and Artificial Intelligence,10.1007/978-94-6265-523-2_16,Springer,2022-01-01,"Social Robots represent a broad spectrum of AI-based AI- based technologies in care robotic applications that could be largely deployed in the care of elderly and frail individuals, primarily to reduce associated welfare costs. Indeed, they could provide assistive (feeding, cleaning, moving), monitoring (health parameters and overall well-being of the user), and companionship (entertaining and interacting with the user) services. This chapter questions whether all these uses are to be deemed licit, and pursuant to which criteria. To do so, it first describes the different kinds of robotic applications divided into categories pursuant to the functions they serve. Then it defines the right to care Right to care within the existing legal framework, in light of international conventions, constitutional principles, and national provisions. In so doing it shows how care is kept distinct from mere cure, and entails addressing the overall well-being of patients, including their socialization, personal independence and dignity. The different technologies are then assessed. To do so, alternative ethical paradigms are considered, typically recalled in the bioethical debate revolving around the use and acceptability of advanced technologies. The analysis shows how a deontological approach Deontological approach is the only one that conforms to the current constitutional framework. Reference is made to the ethical and legal notion of human dignity Human dignity as an external and objective criterion that limits freedom of self-determination Freedom of self-determination , and prevents humans from being manipulated (in their emotions), instrumentalized and isolated. Technologies that could be deemed deceptive—inducing the delusional perception that the machine cares for the user—and whose primary purpose is to replace human relations and contact, should be deemed violating the fundamental rights to care and the dignity of the individuals being cared for. Instead, those technologies that favour physical and psychological independence should be not just welcomed but eventually supported through ad-hoc policy initiatives.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-6265-523-2_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-91828-6_47,Toward a New Service Reality: Human–Robot Collaboration at the Service Frontline,The Palgrave Handbook of Service Management,10.1007/978-3-030-91828-6_47,Springer,2022-01-01,"The digital service revolution will significantly change the way we do business. A big part of this revolution is service robots in various forms and shapes. In this chapter, we illustrate the implication of service robots for the service industry. We compare service robots with traditional self-service technologies as well as human service personnel and identify opportunities and challenges. In the Service Robot Deployment Model, we highlight promising areas for human–robot collaboration and derive managerial implications for the service frontline in this new reality with service robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-91828-6_47,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-08421-8_3,Enhancing Telepresence Robots with AI: Combining Services to Personalize and React,AIxIA 2021 – Advances in Artificial Intelligence,10.1007/978-3-031-08421-8_3,Springer,2022-01-01,"Mobile Telepresence Robots represent a class of robotic platforms, characterized by a video conferencing system mounted on a mobile robotic base, which allows a pilot user to move around in the robot’s environment. These commercially available platforms are relatively cheap and straightforward, yet robust enough to operate continuously in a dynamic environment. Their simplicity and robustness make them particularly suitable for the application in an elderly care context. Although the technology used on these robotic platforms has evolved considerably in recent years, these tools are meant to have no or minimal autonomy and are, hence, mostly relegated to provide pure telepresence services for video calls between the older users and their carers. This work aims to lay the foundations to increase the autonomy of mobile telepresence robots, both by supporting teleoperation through shared approaches and offering services to users in total autonomy. To this purpose, different artificial intelligence technologies such as Reasoning, Knowledge Representation, Automated Planning, Machine Learning, Natural Language Processing, Advanced Perception and Navigation must coexist on limited hardware. An architecture aiming to integrate these technologies is proposed together with backbone services that integrate classical and innovative AI with robotics. Additionally, the problems that arise from the integration of heterogeneous technologies such as plan adaptation needs, shared navigation challenges and the generation of data-driven models able to run on not-performant hardware, are presented along with possible solutions exemplified on the older users assistance domain.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-08421-8_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-021-10023-8,Bayes–Nash: Bayesian inference for Nash equilibrium selection in human-robot parallel play,Autonomous Robots,10.1007/s10514-021-10023-8,Springer,2022-01-01,"We consider shared workspace scenarios with humans and robots acting to achieve independent goals, termed as parallel play. We model these as general-sum games and construct a framework that utilizes the Nash equilibrium solution concept to consider the interactive effect of both agents while planning. We find multiple Pareto-optimal equilibria in these tasks. We hypothesize that people act by choosing an equilibrium based on social norms and their personalities. To enable coordination, we infer the equilibrium online using a probabilistic model that includes these two factors and use it to select the robot’s action. We apply our approach to a close-proximity pick-and-place task involving a robot and a simulated human with three potential behaviors—defensive, selfish, and norm-following. We showed that using a Bayesian approach to infer the equilibrium enables the robot to complete the task with less than half the number of collisions while also reducing the task execution time as compared to the best baseline. We also performed a study with human participants interacting either with other humans or with different robot agents and observed that our proposed approach performs similar to human-human parallel play interactions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-021-10023-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-3346-1_17,A Comparative Study on Face Recognition AI Robot,Proceedings of Second Doctoral Symposium on Computational Intelligence,10.1007/978-981-16-3346-1_17,Springer,2022-01-01,"Face recognition, the application of image processing, has gained a lot of attention. People have started researching and working on it to enhance the field of automation, security, and surveillance. The main reason behind this hype is the vast availability of commercial applications and accessibility to the latest technologies. Though the machine level recognition systems have gained a certain level of perfection, their success rate can be limited based on the application. This is because the image captured by the outdoor system is hard to detect and recognize due to change in light, different background conditions, and variations in the position of the person or object. So, we can say that the present system is far behind the perfection that a human possesses. This paper provides information on both still and moving, i.e., video-based face recognition. The main reason behind writing this review paper is to shed light on the existing literature on this topic and add some more value to knowledge gained concerning machine-based face recognition. Most of the system uses the local binary pattern (LBP) approach to perform face recognition. For detecting the face in the captured image, the Haar cascade algorithm is used where the person's facial feature is extracted and saved in a database for future reference. So, to provide an effective survey, we have classified the existing method for face recognition and explored the latest emerging technologies in this field.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-3346-1_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/16495_2021_38,Let the Robot Speak! AI-Generated Speech and Freedom of Expression,YSEC Yearbook of Socio-Economic Constitutions 2021,10.1007/16495_2021_38,Springer,2022-01-01,"Up until very recently, AI-generated, or more precisely, machine learning (ML)-generated content was still in the realm of sci-fi. A recent series of important inventions gave AI the power of creation: Variational Autoencoders (VAEs) in 2013, Generative Adversarial Networks (GANs) in 2014, and Generative Pre-trained Transformers (GPT) in 2017. Synthetic products based on generative ML are useful in diverse fields of application. For example, generative ML can be used for the synthetic resuscitation of a dead actor, or a deceased loved one. Can ML be a source of speech that is protected by the right to freedom of expression in Article 10 ECHR? In contrast to a tool, such as a pen or a typewriter, ML can be such a decisive element in the generative process, that speech is no longer (indisputably) attributable to a human speaker. Is speech generated by a machine protected by the right to freedom of expression in Article 10 ECHR? I first discuss if ML-generated utterances fall within the protective scope of freedom of expression (Article 10(1) ECHR). After concluding that this is the case, I look at specific complexities raised by ML-generated content in terms of limitations to freedom of expression (Article 10(2) ECHR). The first set of potential limitations that I explore are those following from copyright, data protection, privacy and confidentiality law. Some types of ML-generated content could potentially circumvent these limitations. Second, I study how new types of content generated by ML can create normative grey areas where the boundaries of constitutionally protected and unprotected speech are not always easy to draw. In this context, I discuss two types of ML-generated content: virtual child pornography and fake news/disinformation. Third, I argue that the nuances of Article 10 ECHR are not easily captured in an automated filter and I discuss the potential implications of the arms race between automated filters and ML-generated content.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/16495_2021_38,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-19-2531-3_6,AI and Robot: Darwin and Rebellious Machine,AI Ethics and Governance,10.1007/978-981-19-2531-3_6,Springer,2022-01-01,"As emerging technologies such as AI promote the development of technology to the paradigm of ubiquity and intelligence, it is particularly important to keep an eye on the development trend of technologies and human beings. As we have discussed before, modern technology not only brings benefits but also risks and uncertainties to human society, which makes people begin to worry about the alienation of human society and the loss of human essence caused by technologies. Therefore, how to promote the evolution of technology in the direction of “supporting” rather than “hijacking” human civilization is an issue that needs to be taken seriously. As Martin Rees, a professor at Cambridge University, said, “more technologies are needed to deal with global threats, but they need to be guided by sociology and ethics”. Hence, this chapter mainly discusses some ethical issues related to the evolution and development of human society in AI, including AI consciousness, brain-computer interfaces, and automatic driving.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-2531-3_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-04870-8_2,Kinematics of the “Ai-Gerim” Robot Arm,Advances in Service and Industrial Robotics,10.1007/978-3-031-04870-8_2,Springer,2022-01-01,"In this paper, the direct and inverse kinematics of the “Ai-Gerim” humanoid robot arm are solved. This robot is a remotely controlled social robot. For the study of kinematics of the robot arm, the Denavit – Hartenberg transformation matrices are derived. The pose of the end-effector (hand) in the direct kinematics is determined by multiplying these matrices. For the study of the inverse kinematics of the robot arm, a reverse decoupling method is used to analytically determine the joint angles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-04870-8_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-04305-5_22,"Artificial Intelligence and Robots: The Role of Tax Legislator, A Conundrum to Solve","Interactive Robotics: Legal, Ethical, Social and Economic Aspects",10.1007/978-3-031-04305-5_22,Springer,2022-01-01,"The paper aims to investigate if and how the tax legislator can intervene in the implementation phase of artificial intelligence and robots so that their use in the production of goods and services generates a social utility for the community. The questions that arise are different. In particular, it is necessary not only to understand whether to encourage or tax the use of robots/AI but it is also necessary to explore options for the introduction of legal tools to improve both the relationship between citizens and tax administrations and the system’s efficiency in monitoring and tackling evasion and fraud.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-04305-5_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-021-00781-x,The CARESSES Randomised Controlled Trial: Exploring the Health-Related Impact of Culturally Competent Artificial Intelligence Embedded Into Socially Assistive Robots and Tested in Older Adult Care Homes,International Journal of Social Robotics,10.1007/s12369-021-00781-x,Springer,2022-01-01,"This trial represents the final stage of the CARESSES project which aimed to develop and evaluate a culturally competent artificial intelligent system embedded into social robots to support older adult wellbeing. A parallel group, single-blind randomised controlled trial was conducted across older adult care homes in England and Japan. Participants randomly allocated to the Experimental Group or Control Group 1 received a Pepper robot for up 18 h across 2 weeks. Two versions of the CARESSES artificial intelligence were tested: a fully culturally competent system (Experimental Group) and a more limited version (Control Group 1). Control Group 2 (Care As Usual) participants did not receive a robot. Quantitative outcomes of interest reported in the current paper were health-related quality of life (SF-36), loneliness (ULS-8), and perceptions of robotic cultural competence (CCATool-Robotics). Thirty-three residents completed all procedures. The difference in SF-36 Emotional Wellbeing scores between Experimental Group and Care As Usual participants over time was significant (F[1] = 6.614, sig = .019, η_p^2 = .258), as was the comparison between Any Robot used and Care As Usual (F[1] = 5.128, sig = .031, η_p^2 = .146). There were no significant changes in SF-36 physical health subscales. ULS-8 loneliness scores slightly improved among Experimental and Control Group 1 participants compared to Care As Usual participants, but this was not significant. This study brings new evidence which cautiously supports the value of culturally competent socially assistive robots in improving the psychological wellbeing of older adults residing in care settings.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-021-00781-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-93921-2_22,Robots in the Neighborhood: Application and Criminalization of the Artificial Intelligence in Education,"Technologies, Artificial Intelligence and the Future of Learning Post-COVID-19",10.1007/978-3-030-93921-2_22,Springer,2022-01-01,"In this era of modern technology, artificial intelligence (hereinafter—AI) is performing various activities, which were previously tasked by a human. Despite the significant development and advancement of AI, the AI consciousness is still fiction. One of the far-reaching impacts of Artificial Intelligence in education is that it could change the teaching and learning strategy by maximizing the success of the students. Artificial intelligence in education could be incorporated into education administration, providing instruction or teaching, and as a medium of learning. Like the dark side of every technology, AI is now used by criminals to fuel cybercrimes and to commit cyber-attacks on a larger scale. The secure society and the people, we need new regulations which are adaptive to the change. As the AI is incapable of holding consciousness, in case of any crime committed, the creator or developer could not escape the liability. During the COVID-19 pandemic crisis, most of the educational institutions were forced to shift their academic and administrative works online and online learning based on the distant learning management platforms is the new normal. While distance learning is playing a vital role globally in the response to the pandemic, cybercriminals are using Artificial Intelligence based programs for performing several crimes. As online life and education is the new normal, it is high time to formulate effective regulation to punish AI crimes and in the long run, to prevent such technological malfeasance. We have provided a structured literature analysis of AI-Crime by gradually shifting the focus from history, classification, general application, criminalization, and regulation of AI or AI-based crimes. We have also recommended some principles for countering the regulatory challenges.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-93921-2_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-91352-6_2,Adapting Multi-agent Swarm Robotics to Achieve Synchronised Behaviour from Production Line Automata,2nd IMA Conference on Mathematics of Robotics,10.1007/978-3-030-91352-6_2,Springer,2022-01-01,"This paper describes a novel approach to swarm robotics that enables synchronised behaviour from a number of automata that individually follow simple control rules, but whose interactions necessitate more complex behavioural patterns. A variation on Q-Learning is introduced, and it is shown that synchronised behaviour within set constraints can be learned. This paper reports on initial experimentation with these approaches, and on some of the promising results on behavioural synchronisation that have been obtained. The motivating application for this research was to enable greater concurrency from production line automata, where higher throughput or reduced footprint could be achieved if individual automata could be located closer together operating in tightly choreographed synchrony. However, the research was designed in expectation that similar techniques might apply more widely to any circumstances featuring multiple interacting robotic systems but with practical or commercial drivers against long periods of configuration or ramp-up time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-91352-6_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-58080-3_56-2,The New Frontiers of AI in Medicine,Artificial Intelligence in Medicine,10.1007/978-3-030-58080-3_56-2,Springer,2022-01-01,"This chapter reflects upon the research and innovation innovation at the forefront of artificial intelligence (AI) from hardware to software and their application to draw the potential future applications of AI that will change how care is delivered irrevocably. Techniques including machine learning machine learning , natural language processing natural language processing , and computer vision will be applied to enable earlier diagnosis, give patient control, and create entirely new categories of diagnostics diagnostics . AI has the potential to not just digitalize what healthcare currently does but provide uniquely different ways forward that will revolutionize care delivery.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58080-3_56-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-74032-0_28,Evaluation of ML-Based Grasping Approaches in the Field of Automated Assembly,"Annals of Scientific Society for Assembly, Handling and Industrial Robotics 2021",10.1007/978-3-030-74032-0_28,Springer,2022-01-01,"Petrovic, Oliver Blanke, Philipp Belke, Manuel Wefelnberg, Eike Storms, Simon Brecher, Christian Current trends in the manufacturing industry lead to high competitive pressure and requirements regarding process autonomy and flexibility in the production environment. Especially in assembly, automation systems are confronted with a high number of variants. Robot-based processes are a powerful tool for addressing these challenges. For this purpose, robots must be made capable of grasping a variety of diverse components, which are often provided in unknown poses. In addition to existing analytical algorithms, empirical ML-based approaches have been developed, which offer great potentials in increasing flexibility. In this paper, the functionalities and potentials of these approaches will be presented and then compared to the requirements from production processes in order to analyze the status quo of ML-based grasping. Functional gaps are identified that still need to be overcome in order to enable the technology for the use in industrial assembly.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-74032-0_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-82544-7_28,The BRAIINS AI for Kids Platform,Robotics in Education,10.1007/978-3-030-82544-7_28,Springer,2022-01-01,"BRAIINS (BRingAIIN Schools) 2020–2023 Erasmus+ project is first and foremost a bottom-up educational alliance between schools in EU with different backgrounds, expertise and focus and among students. Although already permeating our world, AI is not explicitly taught in most schools and has not found an appropriate place in curricula yet. While some platforms for kids and professional tools can be found, BRAIINS is targeting 15–18 year olds with a peer-to-peer approach. This paper explains how students with technical background provide online-learning materials and a ready to use website for their peers from the partner schools using ML4Kids, KNIME, the ML Kit for Firebase and robotic platforms such as Misty, Nao, Botball. This will give them the opportunity to learn from each other, collaborate to enhance the website with self-written exercises and examples as well as use it for their discussions about ethics and creative mindsets.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-82544-7_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-1740-9_46,An In-Memory Physics Environment as a World Model for Robot Motion Planning,Soft Computing: Theories and Applications,10.1007/978-981-16-1740-9_46,Springer,2022-01-01,"A 2D replica of real-world terrain was created in a physics simulation environment, allowing a robot to “imagine” a simulated version of itself navigating the terrain. The physics of the environment simulates the movement of robot parts and its interaction with objects, thus avoiding the need for explicitly programming various calculations. Since the complexity of motion increases with each degree of freedom of the robot’s joints, the utility of uniform randomness was also investigated as an alternative to computational intelligence algorithms for exploring the fitness landscape. Such techniques potentially simplify the algorithmic complexity of programming multi-jointed robots and could adapt by dynamically adjusting simulation parameters, on encountering environments with varied gravity, viscosity or traction. Ipe, Navin K. Chatterjee, Subarna",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-1740-9_46,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-64573-1_56,The New Frontiers of AI in Medicine,Artificial Intelligence in Medicine,10.1007/978-3-030-64573-1_56,Springer,2022-01-01,"This chapter reflects upon the research and innovation innovation at the forefront of artificial intelligence (AI) from hardware to software and their application to draw the potential future applications of AI that will change how care is delivered irrevocably. Techniques including machine learning machine learning , natural language processing natural language processing , and computer vision will be applied to enable earlier diagnosis, give patient control, and create entirely new categories of diagnostics diagnostics . AI has the potential to not just digitalize what healthcare currently does but provide uniquely different ways forward that will revolutionize care delivery.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-64573-1_56,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-77163-8_2,"Essential Knowledge, Skills, and Abilities Required for Talent Cultivation in Construction Automation and Robotics","Automation and Robotics in the Architecture, Engineering, and Construction Industry",10.1007/978-3-030-77163-8_2,Springer,2022-01-01,"With the global rise in the level of advanced automation and robotics technologies deployed in construction technology and innovation practice, successful implementation of these technologies requires the inclusion of a workforce with the competencies necessary to drive automation and robotics processes. To meet the market demand for these professionals, there is a need to integrate automation and robotics technologies and processes in construction curricula. However, to ensure proper planning of the integration of automation and robotics in construction education, it is necessary to establish a consensus on the competencies required from construction technology and innovation specialists. Using the Delphi method with contributions from professionals, this chapter identifies and examines the fundamental knowledge, skills, and abilities (KSAs) that should be represented in construction education. After a semi-structured interview round and two rounds of the Delphi study, four competency groups with a total of 99 KSA line items were identified, and a consensus was measured for each of the line items with the importance ratings and levels of agreement (LOAs) attained between the professionals. By identifying these essential KSAs, a competency benchmark and performance assessment framework was developed to support industry professionals and educators in talent cultivation in the advancement of construction innovations in automation and robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77163-8_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10479-020-03526-7,Increasing flexibility and productivity in Industry 4.0 production networks with autonomous mobile robots and smart intralogistics,Annals of Operations Research,10.1007/s10479-020-03526-7,Springer,2022-01-01,"Manufacturing flexibility improves a firm’s ability to react in timely manner to customer demands and to increase production system productivity without incurring excessive costs and expending an excessive amount of resources. The emerging technologies in the Industry 4.0 era, such as cloud operations or industrial Artificial Intelligence, allow for new flexible production systems. We develop and test an analytical model for a throughput analysis and use it to reveal the conditions under which the autonomous mobile robots (AMR)-based flexible production networks are more advantageous as compared to the traditional production lines. Using a circular loop among workstations and inter-operational buffers, our model allows congestion to be avoided by utilizing multiple crosses and analyzing both the flow and the load/unload phases. The sensitivity analysis shows that the cost of the AMRs and the number of shifts are the key factors in improving flexibility and productivity. The outcomes of this research promote a deeper understanding of the role of AMRs in Industry 4.0-based production networks and can be utilized by production planners to determine optimal configurations and the associated performance impact of the AMR-based production networks in as compared to the traditionally balanced lines. This study supports the decision-makers in how the AMR in production systems in process industry can improve manufacturing performance in terms of productivity, flexibility, and costs. ",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10479-020-03526-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-72204-3_40,Humanizing Business in the Age of Artificial Intelligence,Humanizing Business,10.1007/978-3-030-72204-3_40,Springer,2022-01-01,"In this chapter, we address the problem of humanizing business when we must interact with intelligent robots and other AI systems, rather than real people, on a daily basis. There is a strong tendency to anthropomorphize pets and other animals that carries over to smart machines, leading us to replace human relationships with something less sophisticated and subtle. As a result, we argue, humanizing machines actually tends to dehumanize the workplace. We take an anthropological approach to this phenomenon that teaches three important lessons. One is that Western cultures have a particularly strong tendency to anthropomorphize machines, due to what Max Weber called the disenchantment of nature. Another is that humans have long interacted with intelligent nonhuman beings, such as domesticated work animals, without anthropomorphizing them. Finally, we can take a cue from these interactions to create analogous relationships with robots by neither humanizing nor objectifying them, but by relating to them in a manner that suits their capabilities. In particular, we can avoid anthropomorphism by involving workers in the training of AI systems, much as our ancestors trained domesticated animals, and by introducing ritual activities involving robots that clarify their ethical status and guide our interaction with them.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-72204-3_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-96210-4_7,The Future of Knowledge Work: Working Smarter and Greener in the Age of Digitalization,Reimagining Sustainable Organization,10.1007/978-3-030-96210-4_7,Springer,2022-01-01,"This chapter investigates what forms the knowledge work design in the future on a corporate level. The future is 2030. The methodology includes 20 in-depth interviews (before and during the Covid-19 worldwide pandemic) with researchers working with these issues in the Swedish telecommunication company Telia and the Norwegian telecommunication company Telenor. These are both companies making their living from understanding the future of work on a corporate level. The difference between the two rounds of interviewing is that online homework is the actual work situation in the pandemic March–April 2020, and the interviewed believe that 50% of the work will be done online outside the workplace. The corona crisis changed the way we are working for the future.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-96210-4_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-94751-4_5,Users Versus Non-users: The Impact of Experience on Hotel Guests’ Attitudes Towards Service Robots in Hotels,Information and Communication Technologies in Tourism 2022,10.1007/978-3-030-94751-4_5,Springer,2022-01-01,"The use of robotics and artificial intelligence have created a shift in the ways the service-based hospitality and tourism industry can fulfill the needs and wants of consumers that were earlier fulfilled only by humans. Robots have added the automation and self-service experience that play a vital role in the improvements of efficiency, speed, and the overall experience for the guests using technology. While there are many benefits of using robots in the industry, there are also risks associated with the excessive usage of robots on guest experience. As a result of the pros and cons on the topic, it is very important to gather data and analyze the results to further investigate and understand what the outcomes will be for the industry, its employees, and its customers. The purpose of this study is to examine the perceptions of the use of robots in the hotels as perceived by hotel guests who used a service robot and who did not. A self-administered survey was developed, and 939 usable responses were collected from hotel guests. Factor analysis showed that five factors emerged in the study: Advantages, Attitudes, Disadvantages, Pandemic Related, and Fear. Guests recognize the opportunities that service robots are bringing to their experience while voicing their concerns and fears about the use of them. Findings also showed that there are significant differences between users and non-users.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-94751-4_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-84729-6_8,Supporting Social and Emotional Well-Being with Artificial Intelligence,Bridging Human Intelligence and Artificial Intelligence,10.1007/978-3-030-84729-6_8,Springer,2022-01-01,"Social and emotional well-being are important and integral aspects of general health. Artificial intelligence (AI)-based technologies, such as conversational chatbots, virtual assistants, and socially assistive robots, have been increasingly integrated in society to address the needs of those individuals whose social or emotional well-being have been compromised. Given the growing concern for mental health issues, this chapter discusses two factors that undermine human emotional and mental states, that is, issues related to mental conditions (e.g., depression or anxiety) and social interactions (e.g., loneliness or social isolation). The discussion embraces assistive benefits of AI-based technologies and underlines existing challenges regarding their use.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-84729-6_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-94259-5_51,Transformation of Legal Labor Regulation Under Influence of Artificial Intelligence,Integrated Computer Technologies in Mechanical Engineering - 2021,10.1007/978-3-030-94259-5_51,Springer,2022-01-01,"The article is devoted to research on prospects artificial intelligence implementation in the field of labor relations. The tendencies inherent in digitalization processes influencing labor field are marked, and also the changes which will occur in the field of labor law are forecasted. It is proved that artificial intelligence implementation leads to rapid changes not only in technologies used in workflow but to changes in labor nature, employment, management of relations, labor protection and labor guarantees. Necessity of modernization of the system of professional training, education and advanced training of staff in conditions of digitalization is determined. Issues of transformation of employee status in labor legal relations are investigated. It is determined that with development of artificial intelligence, the range of subjects of labor law will be expanded. With acquisition of the legal status of Electronic personhood in civil law, “smart” jobs will be able to obtain the status of a subject in the employment relationship. Emphasis is placed on the emergence of workers with neural prostheses that restore or enhance natural human abilities. As a result, it will be necessary to determine the legal status of at least three categories of employees: employees with disabilities who need neural prostheses for medical reasons; employees who have expressed a desire to install neural prosthesis without medical indications: employees who do not use biotechnological means. It is concluded that labor legislation requires reformulation of labor law principles in accordance with the new conditions for implementation of labor relations, as well as the development of new standards and guarantees for labor protection.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-94259-5_51,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-6265-523-2_1,Humanizing Machines: Introduction and Overview,Law and Artificial Intelligence,10.1007/978-94-6265-523-2_1,Springer,2022-01-01,"This chapter provides an introduction to this book (Law and Artificial Intelligence: Regulating AI and Applying it in Legal Practice Legal practice ) and an overview of all the chapters. The book deals with the intersection of law and Artificial Intelligence (AI). Law and AI interact in two different ways, which are both covered in this book: law can regulate AI and AI can be applied in legal practice Legal practice . AI is a new generation of technologies, mainly characterized by being self-learning Self-learning technologies and autonomous. This means that AI technologies can continuously improve without (much) human intervention and can make decisions that are not pre-programmed. Artificial Intelligence can mimic human intelligence Human intelligence , but not necessarily so. Similarly, when AI is implemented in physical technologies, such as robots Robots , it can mimic human beings (e.g., socially assistive robots Robots acting like nurses), but it can also look completely different if it has a more functional shape (e.g., like an industrial arm that picks boxes in a factory). AI without a physical component can sometimes be hardly visible to end users, but evident to those that created and manage the system. In all its different shapes and sizes, AI is rapidly and radically changing the world around us, which may call for regulation in different areas of law. Relevant areas in public law Public law include non-discrimination law Non-discrimination law , labour law Labour law , humanitarian law Humanitarian law , constitutional law Constitutional law , immigration law Immigration law , criminal law Criminal law and tax law Tax law . Relevant areas in private law Private law include liability law, intellectual property law, corporate law, competition law Competition law and consumer law Consumer law . At the same time, AI can be applied in legal practice Legal practice . In this book, the focus is mostly on legal technologies, such as the use of AI in legal teams, law-making, and legal scholarship. This introductory chapter concludes with an overview of the structure of this book, containing introductory chapters on what AI is, chapters on how AI is (or could be) regulated in different areas of both public and private law Private law , chapters on applying AI in legal practice Legal practice , and chapters on the future of AI and what these developments may entail from a legal perspective.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-6265-523-2_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-88241-9_4,AI Implications for the Future of Work,Artificial Intelligence for Business,10.1007/978-3-030-88241-9_4,Springer,2022-01-01,"Over the course of history, people have tried to find ways to improve their quality of life and to make their jobs easier, and that has required innovation and, more recently, technology. In barely three decades, the appearance of the Internet, social networks, mobile phones, big data, cloud computing, cybersecurity, robotics or Artificial Intelligence (AI) have wrought enormous, far-reaching changes in the world of work. Their appearance has brought changes in production, in the economy and finances, in cities, trade, health care, agriculture, education and so on. All of that has altered the way we work, consume and communicate with each other, moving from highly personal relations to relations between people and machines. The technological change we are experiencing presages a disruptive transformation in the forms and understanding of work in the future.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-88241-9_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7088-6_8,Tracking Misleading News of COVID-19 Within Social Media,Soft Computing and Signal Processing,10.1007/978-981-16-7088-6_8,Springer,2022-01-01,"The individuals locked themselves in their residences and turned to social media to stay updated on COVID-19 news and to pass the time when the pandemic struck and governments announced lockdowns. As a consequence, dealing with the fake news about COVID-19 posed a significant challenge for the public. So, the World Health Organization (WHO) has asked that its formally approved information and reports be portrayed as top results in any COVID-19-related search on Google, YouTube, Facebook, LinkedIn, Microsoft, Yahoo, and Twitter. We conducted a thorough investigation to assess and select appropriate solutions, knowledge, and skills for current issues, as well as the use of tools for tracking fake news within social media in this study. The search for this work started with a physical search of scientific publications and papers concerning fake news related to COVID-19. During pandemic, the majority of hospitals utilized artificial intelligence techniques to diagnose virus-infected patients, and most governments and businesses used robots to limit the virus's exposure to their employees and customers, distribute sanitizers, and advise the public to “stay safe, stay home.”",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7088-6_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-81986-6_15,Bold Future of Human Resources Development in Healthcare,Innovative Staff Development in Healthcare,10.1007/978-3-030-81986-6_15,Springer,2022-01-01,"Courageous and innovative staff development is the order of the day. Healthcare is one of the biggest growth sectors. The explosive spreading of digitization will produce enormous amounts of data in healthcare, which will lead to an end of some activities, while new ones will be needed. Besides technical competences soft skills will be on great demand. The biggest part of treatment mistakes arises from inaccurate communication and collaboration. That is why communicative, relational, and interpersonal competences are needed in healthcare. In order that the two professions nursing and medicine become real team players communication gaps must be closed. Both are missing a specific competence for collaboration, which can be trained. Emotional intelligence will become a bigger focus in future, not just in leadership. Everything, what computers can do, they will do. Emotional work as a human factor is still not replaceable. Globalization is not just a key driver for change, but enlarges crisis. Transition management, change management, and crisis management will become an important piece in leadership, which includes the management of challenges as well as leading employees with emotional intelligence.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-81986-6_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-93921-2_2,"The Future of Education After Covid-19, What is the Role of Technology","Technologies, Artificial Intelligence and the Future of Learning Post-COVID-19",10.1007/978-3-030-93921-2_2,Springer,2022-01-01,"This article mainly focused on upcoming technology and strategical approach for the future education system. According to previous literature work about the education improvement, technology development, and implementation of Artificial Intelligence (AI) are discussed in detail. However, the factors affecting the future technology after cataclysmic are also mentioned in brief. The covid-19 plays a crucial role in the vigorous implementation of the newer technologies in the education system, due to the sudden increased demand around the world. The feasibility of future education and technology is more dominant over the traditional education culture because the new concept which was thought to be imaginary is now possible to implement. Moreover, before covid-19, there are many prestigious institutions already providing digital and online education. This article also glimpses a teacher and student relationship through the virtual mode. In subsequent years the education system provides efficient learning methodologies in the virtual mode because previously it was only a theoretical-based teaching method, nowadays the experimentation and result analysis are also performed through animation by digital mode. The paper also highlights the challenges faced by human society in the implementation of the future education system, article urges technological optimization for the educational variables and developing it more efficient for future needs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-93921-2_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-6554-7_27,Research on Assistant Application of Artificial Intelligence Robot Coach in University Sports Courses,Proceedings of the 11th International Conference on Computer Engineering and Networks,10.1007/978-981-16-6554-7_27,Springer,2022-01-01,"With the development of China's economy, the development of science and technology changes with each passing day. In various industries, the use of computers is becoming more and more common. The cloud platform is built on virtual technology, and people can use the data stored in the computer without being restricted by space and time. Multimedia network teaching platform plays an important role in college teaching. The multimedia network teaching platform in sports has also been paid more and more attention. This paper analyzes the application of the cloud platform multimedia network teaching platform in college physical education, and proposes the use of artificial intelligence robots to improve the teaching quality of physical education courses, which is conducive to the development and promotion of scientific and technological achievements. The use of cloud platforms can make resources fully shared and teaching methods more vivid and enriched. In addition, this is conducive to improving the level of teaching.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-6554-7_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-97255-4_2,AGRIBOT: Energetic Agricultural Field Monitoring Robot Based on IoT Enabled Artificial Intelligence Logic,Emerging Technology Trends in Internet of Things and Computing,10.1007/978-3-030-97255-4_2,Springer,2022-01-01,"In these modern days agriculture is one of the major concern to take out from the loss and need to be improvised in next level of production ratio. The latest technologies such as Internet of Things and Artificial Intelligence are associated with many applications to improve the standards as well as provide a drastic support to customers to achieve their communication needs. In this paper, a new agricultural robot is designed called as agriBOT, in which it is used to monitor the entire agricultural field and the associated crops in an intelligent manner by using Artificial Intelligence logic. The agriBOT has a provision to act like a drone to survey all fields in an intelligent manner. This provision allows the robot to move in all fields even the crops are in so dense, in which the agriBOT is integrated with many smart sensors to monitor the crop details well such as Soil Moisture Level Identifier, Crop Leaf Image Accumulator, Rain Identification Sensor and Surrounding Temperature level Identification Sensor. These sensors are associated with the proposed agriBOT to make the robot as powerful and robust in association with Artificial Intelligence and Internet of Things (IoT) strategies. The Internet of Things is used to carry the local sensor data from the agriBOT to the remote server for processing as well as the data available into the remote server can easily be monitored by the respective farmer from anywhere in the world at any time. The alert is utilized over the proposed agriBOT to pass the emergency condition alerts to the respective farmers instantly as well as the Global Positioning System (GPS) is utilized to retrieve the location details of the crop and report that to the server immediately by using IoT. This paper introduced a new machine learning strategy to analyze the server data, in which it is called as Modified Convolutional Neural Scheme (MCNS). This approach of MCNS provides the facility to predict the climate conditions and the associated crop details instantly based on the data which is collected already and stored into the server. With the association of these two strategies made the proposed approach of agricultural field monitoring system too robust and efficient to analyze the crop related details as well as the plant lea disease is also identified by using this approach based on the images captured by the agriBOT in an intellectual manner. All these details are experimentally tested and the resulting section provides the proper proof for the mentioned things.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-97255-4_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-98084-9_16,Conversational Machinations,Ethical Inquiries after Wittgenstein,10.1007/978-3-030-98084-9_16,Springer,2022-01-01,"In this chapter, I am discussing the issue of assigning thought to AI entities. Using the example of Sophia the Robot, I try to show that “assigning thought” to an AI entity is less a statement made based on an empirical inquiry, and more the matter of a complex attitude relying on the assigning person’s conceptual sensitivity and imagination. In that respect, most AIs fail simply because people lack the right kind of conceptual resources for relating to them as to persons “speaking out of a life”. However, in the second part I am showing that Sophia represents a case of a coordinated and intentional attempt at shifting our conceptual intuitions, by means of creating and curating conversation situations in such a way that people can relate to “her” as to a genuine person and speaker. Toward the end, I mention a few aspects of this practice that appear morally problematic in a more straightforward sense.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-98084-9_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-5180-9_2,Historical Developments on Computer Applications in Pharmaceutics,Computer Aided Pharmaceutics and Drug Delivery,10.1007/978-981-16-5180-9_2,Springer,2022-01-01,"A lot of mathematical and statistical calculations are involved in optimization of pharmaceutical formulations. Computations involving correlating variables with responses, regression analysis, predictions, and simulations are now better handled with computers equipped with specially designed softwares. These softwares have been developed from simple programs to artificial intelligence (AI) integrated packages. In addition to these, computers are playing a larger role in designing internal architecture and outer appearance of dosage forms with the advancements in computer-aided designing and 3D printing technologies. Initial robots were made to automate pick and place operations but significant developments of programming softwares and AI have gradually advanced robots with more flexibility, adaptability, and intelligence. Soft robots with greater degrees of freedom and locomotion abilities have a potential role in delivering drugs to targeted locations. Software packages for pharmacokinetics perform tedious calculations, data analysis, and modeling to enhance the speed of drug discovery and formulation development programs. This chapter focuses on some significant historical developments on different applications of computers in the field of formulation optimization, robotics, artificial intelligence, 3D printing, and pharmacokinetics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-5180-9_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-94141-3_28,Software Development for Agricultural Tillage Robot Based on Technologies of Machine Intelligence,"High-Performance Computing Systems and Technologies in Scientific Research, Automation of Control and Production",10.1007/978-3-030-94141-3_28,Springer,2022-01-01,"The article is devoted to the development of software for robots designed for spot mechanical tillage. The need to develop software for the digital twin of the agro-robot with the use of artificial intelligence technologies is dictated by the need of farmers in its practical use. The article describes four high-level nodes of an agricultural robot: the control unit, which is an NVIDIA Jetson NANO computing module; the executive mechanism, which is a 6-axis desktop robotic arm; the machine vision unit, consisting of an Intel RealSense camera; the chassis unit, represented as crawler tracks and drivers for their control. The implementation of the software is carried out independently of the manufacture of the robot, so for the developer there is a task to minimize the risk of its implementation in the manufactured robot. The developed software fully meets the requirements imposed by the customer. For instance, the digital robot twin takes into account the environmental conditions, as well as the terrain in which the prototype robot will work, and then the serial device. Second, the use of ROS (Robot Operating System) in software development will allow one with minimal effort to transfer the digital model to the physical one (prototype and serial robot), without changing the source code. Third, taking into account the physical environment conditions when programming the digital robot twin allowed one to build mathematical models of device control that are close to reality, as well as to debug and test them.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-94141-3_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85540-6_12,"Iteration of Children with Attention Deficit Disorder, Impulsivity and Hyperactivity, Cognitive Behavioral Therapy, and Artificial Intelligence","Human Interaction, Emerging Technologies and Future Systems V",10.1007/978-3-030-85540-6_12,Springer,2022-01-01,"Cognitive Behavioral Therapy (CBT) is a variety of psychoeducational procedures that allow a variety of disturbances including attention deficit disorder, impulsivity, and hyperactivity to be intervened - ADHD to children essentially in school, improving their abilities and integrating into society with better fitness. Cognitive behavioral therapy is based on continuously observing, analyzing, evaluating and evolving; Meanwhile, ADHD is difficult to detect in children under the age of 6 because the symptoms are similar to the behavior of this age, which makes this combination playful, motivating, constant and modifiable in a school group, i.e. a group of children with an average of three years who have no or no disorder through learning through technology such as a robot, toy, computer or any other instrument with artificial intelligence. This iteration has as pillars the game, quantitative observation, discipline, motivation, simulation and creation of solutions, allowing variables, symptoms or causes to be collected automatically from each and the entire school group, instantly analyzed by the robot or tool with artificial intelligence using algorithms or implemented models that systematize what is quantitatively observed to a diagnosis or clinical picture of each and every one of them at that time while continuing the progressive evaluation of each child during iteration with the school group strengthening their qualities, developing their creativity by reducing their anomaly individually. This iteration of child-home-school - artificial intelligence; in the early years of education facilitates the inclusion of each child who suffers from attention deficit disorder, impulsivity, and hyperactivity.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-85540-6_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-91581-0_5,Possibility of Harmonious Coexistence of Human and Artificial Beings,"Advances in Neural Computation, Machine Learning, and Cognitive Research V",10.1007/978-3-030-91581-0_5,Springer,2022-01-01,"We examine a way to achieve harmony in the community of people and intelligent artificial beings (robots). A simple model allows us to show that equilibrium is possible when robots are busy producing resources and people are busy manufacturing the robots. We determine conditions under which the ratio of people population to robot population tends to a constant with time, and simultaneously the populations tend to stationary values or increase exponentially. We examine the cases of a non-stop robot manufacturing and the case of stoppage in their production when consumption is low. We show that the first possibility is safer from the point of view of the civilization evolution and discuss the issues of organizing a correct production of robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-91581-0_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-5180-9_12,Robotic Automation of Pharmaceutical and Life Science Industries,Computer Aided Pharmaceutics and Drug Delivery,10.1007/978-981-16-5180-9_12,Springer,2022-01-01,"Robotic automation brings flexibility, speed, accuracy, and durability to almost all processes in industries. Robots have significantly advanced from machines to collaborative robots to humanoids. Stringent safety regulations have made deployment of robots in industries safer and catalyzed the entry of collaborative robots (cobots) and humanoids in research laboratories, offices, and hospitals as assistants to humans. Robots are working at places where human cannot work or human involvement is a concern for quality issues. Internet of Things (IoT), artificial intelligence (AI), and robotic advancements are continuously decreasing human interventions in drug discovery, synthetic chemistry, and biotechnology laboratories. Robots equipped with vision guidance systems, sensors, softwares, and AI-based algorithms are re-shaping pharmaceutical and life science industries. This chapter gives a most recent update on robotic innovations for automation of manufacturing, packaging, warehousing, and laboratory processes of industries, in particular pharmaceutical and life science industries.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-5180-9_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-97672-9_44,Solving Delivery Assignment in Hybrid-Transit Network Using Multi-agent Reinforcement Learning,Robot Intelligence Technology and Applications 6,10.1007/978-3-030-97672-9_44,Springer,2022-01-01,"A robust logistics delivery infrastructure is an essential part in our life. The increasing demand of delivery service requires an optimization in the operation to reduce delivery cost and time. In this paper, the logistic delivery problem is modeled as a task-assignment problem. The problem is then solved using multi-agent reinforcement learning approach, particularly using graph convolutional reinforcement learning algorithm. The goal is to deliver the packages to their respective destinations using least possible fuel, which is the shared resource. Our results show that by encouraging cooperative between the couriers, which act as the agents, the couriers are able to discover ways to preserve resource while completing the delivery tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-97672-9_44,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-04870-8_14,A Fast Method for Explanations of Failures in Optimization-Based Robot Motion Planning,Advances in Service and Industrial Robotics,10.1007/978-3-031-04870-8_14,Springer,2022-01-01,"The transparent interaction between an operator and a robot system is essential for successful task completion. This requires a mutual understanding of decisions and processes in order to provide accurate diagnoses and troubleshooting alternatives in the event of a failure. Due to inaccuracies in the environmental perception or planner configuration, errors can occur in robot motion planning that are hard to understand by the operator. In this work we present a method that is able to provide explanations for motion planning failures quickly. In the context of optimization-based planners, failures origin from planning constraints can be identified using an adaption of the FastDiag algorithm. It is able to provide one preferred minimal diagnosis in logarithmic time, also for large constraint sets. To evaluate the applicability of the proposed method, experiments are conducted that compare the computational performance to an existing method while considering different parameters such as number of constraints and requested diagnoses.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-04870-8_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-98668-1_5,Yearning for Vitality: The Italian Avant-Garde and the Puppet,"The Image of the Puppet in Italian Theater, Literature and Film",10.1007/978-3-030-98668-1_5,Springer,2022-01-01,"This chapter discusses how the puppet image, including its incarnations as mannequin and robot, are employed by the early twentieth-century Italian avant-garde, particularly by futurist and metaphysical artists. Among the works analyzed are Marinetti’s Fantocci elettrici (1909), Giorgio de Chirico’s paintings, Bontempelli’s Siepe a nordovest (1918) and Eva ultima (1922). The puppet image is revealed to relate to the idea of a quest for freedom and vitality, which acquires different forms in relation to the artist’s ideological position.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-98668-1_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-05409-9_40,User Profile-Driven Large-Scale Multi-agent Learning from Demonstration in Federated Human-Robot Collaborative Environments,Human-Computer Interaction. Technological Innovation,10.1007/978-3-031-05409-9_40,Springer,2022-01-01,"Learning from Demonstration (LfD) has been established as the dominant paradigm for efficiently transferring skills from human teachers to robots. In this context, the Federated Learning (FL) conceptualization has very recently been introduced for developing large-scale human-robot collaborative environments, targeting to robustly address, among others, the critical challenges of multi-agent learning and long-term autonomy. In the current work, the latter scheme is further extended and enhanced, by designing and integrating a novel user profile formulation for providing a fine-grained representation of the exhibited human behavior, adopting a Deep Learning (DL)-based formalism. In particular, a hierarchically organized set of key information sources is considered, including: a) User attributes (e.g. demographic, anthropomorphic, educational, etc.), b) User state (e.g. fatigue detection, stress detection, emotion recognition, etc.) and c) Psychophysiological measurements (e.g. gaze, electrodermal activity, heart rate, etc.) related data. Then, a combination of Long Short-Term Memory (LSTM) and stacked autoencoders, with appropriately defined neural network architectures, is employed for the modelling step. The overall designed scheme enables both short- and long-term analysis/interpretation of the human behavior (as observed during the feedback capturing sessions), so as to adaptively adjust the importance of the collected feedback samples when aggregating information originating from the same and different human teachers, respectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-05409-9_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7258-3_20,Random-Optimal Differential Evolution Neural Network Model for Inverse Calculation of Demolition Robot,Advances in Precision Instruments and Optical Engineering,10.1007/978-981-16-7258-3_20,Springer,2022-01-01,"For the inverse calculation of laser-guided autonomous positioning of the demolition robot, a direct mapping model of laser measurement to the driving space of the joint hydraulic cylinder is established by using artificial neural network (ANN) so as to avoid the inverse calculation accuracy depending on the parameters and the accuracy of calibration. In order to improve the convergence rate of the differential evolution (DE) optimizing ANN, a new random-optimal differential evolution (RODE) is proposed to improve the balance of the evolutionary population exploring and exploiting process. Simulation results show that the RODE can significantly improve the convergence speed and maintain good optimization stability and the output precision of optimized inverse calculation ANN can meet the global positioning control requirements of the demolition manipulator.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7258-3_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-021-06465-x,A gradient-based neural network accelerated for vision-based control of an RCM-constrained surgical endoscope robot,Neural Computing and Applications,10.1007/s00521-021-06465-x,Springer,2022-01-01,"This paper presents an accelerated gradient-based neural network (GNN) to achieve visual servoing of a surgical endoscope robot. A KUKA LWR 4+ robot with seven joints is used to serve as an endoscope holder. Kinematic mapping is established between the joint space of the robot and the image space of the camera. For surgical applications, the motions of the KUKA robot are constrained with respect to a remote-center-of-motion (RCM) point. Meanwhile, each joint of the KUKA robot has its own physical limits (e.g., joint-angle and joint velocity limits) that cannot be violated. By taking into account the kinematic equation, RCM constraints and physical limits, a control scheme possessing a quadratic programming (QP) formulation is constructed. To solve the QP problem, an inverse-free GNN model is accelerated to be finite-time convergent using a powerful activation function. Mathematical derivations of the accelerated GNN model and theoretical proofs relevant to the finite-time convergence are detailed. Comparative validations are conducted with the superior convergence performance of the accelerated GNN model substantiated. The effectiveness of the proposed GNN solution for vision-based control of the surgical endoscope is verified with RCM constraints and physical limits respected simultaneously.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-021-06465-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-1740-9_44,Stability Analysis of HJB-Based Optimal Control for Hybrid Motion/Force Control of Robot Manipulators Using RBF Neural Network,Soft Computing: Theories and Applications,10.1007/978-981-16-1740-9_44,Springer,2022-01-01,"This paper presents intelligent optimal control approach based on Hamilton–Jacobi–Bellman (HJB) optimization for hybrid motion/force control problem of constrained robot manipulators. For designing of control scheme, first of all a state-space form of error dynamics is derived for quadratic optimization describing the constrained and unconstrained motion separately. Then, the explicit solution of HJB equation for optimal control is obtained by Riccati equation. The uncertainties of the system are compensated using radial basis function neural network (RBFNN) and adaptive compensator. Thus, the proposed control scheme is combination of the linear optimal control, neural network, and adaptive bound. The asymptotic stability of the system is demonstrated using Lyapunov stability analysis, and the simulated results are produced with two-link constrained manipulator. Rani, Komal Kumar, Naveen",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-1740-9_44,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-1740-9_45,RBF Neural Network-Based Terminal Sliding Mode Control for Robot Manipulators,Soft Computing: Theories and Applications,10.1007/978-981-16-1740-9_45,Springer,2022-01-01,"The primarily focus of this paper is to develop a novel terminal sliding mode controller based on RBF neural network. To improve the control performance, a nonlinear term is included in control operation. The neural network system is adopted for estimation of nonlinear components. The neural network reconstruction error and bound on unstructured uncertainties are compensated with the help of adaptive control. Finally, simulation is performed with given manipulator that will provide the benefit of given method. Ruchika Kumar, Naveen",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-1740-9_45,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89508-2_15,Application of Neural Network Algorithm in Robot Eye-Hand System,The 2021 International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy,10.1007/978-3-030-89508-2_15,Springer,2022-01-01,"With the advent of the intelligent era, intelligent industrial robots integrated with vision systems have penetrated into many fields. Especially robots with hand-eye functions play an important role in the fields of automobile manufacturing, logistics, and aviation exploration. Radial basis function (RBF) neural network has a high degree of non-linear mapping ability. This paper analyzes the structure characteristics, learning algorithm and application of RBF neural network in the robot eye-hand system, and analyzes the non-linearity of RBF neural network. The linear approximation characteristics are theoretically verified. The purpose of this article is to study the application of neural network algorithms in robot eye-hand systems. Simulation experiments show that the designed algorithm can track the ideal position well, and can significantly reduce chattering, and improve the control performance of the manipulator system when the system itself has uncertainty and external interference.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89508-2_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-6320-8_57,Automatic Training Method of Deep Neural Network for Robot Vision,Proceedings of 2021 Chinese Intelligent Systems Conference,10.1007/978-981-16-6320-8_57,Springer,2022-01-01,"Thanks to the breakthrough of deep learning in machine vision, robots have been widely applied in industrial and family services in recent years. Object capture is one of the most important functions for robots, and two-dimensional object detection is the premise for robot to capture objects. However, the training cost of obtaining the high recognition rate model is very large, as the deep neural network needs huge data samples. Based on this, this paper proposes an automatic training method of deep neural network for robot vision. The Tracking-Learning-Detection (TLD) algorithm tracks and collects the object samples by online learning. Then the offline Single-Shot-Detector (SSD) model studies the features of the object so as to realize the robotic object recognition function. In order to ensure the stability and continuity of the tracking process of the target, the sample acquisition process is accomplished automatically by the robot manipulator. Two methods of manual annotation and TLD algorithm are all used in this paper for increasing the persuasiveness of the data. The results show that the time cost of automatic data annotation by TLD algorithm is 77.75% less than the manual data annotation, and the recognition rate of model trained with automatic labeling data is 97.75%, which verify the validity and feasibility of the novel method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-6320-8_57,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-2069-1_57,Determining Trajectories for Hair Wash and Head Massage Robot Based on Artificial Neural Network,Mobile Computing and Sustainable Informatics,10.1007/978-981-19-2069-1_57,Springer,2022-01-01,"The medical and healthcare field is more interesting and studied in the era of science and technology development. Hair washing helps remove dirt and healthy hair and reduces the risk of scalp diseases, and according to Vietnamese traditional medicine, massage according to acupressure points is one of the methods of treating pain and fatigue, and it helps to recover from the treatment process, reducing stress, etc. In the stage of the COVID-19 epidemic, the shortage of medical staff occurs in many hospitals that are overloaded with patient care, especially bedridden patients, who need special care and hair washing, and massage head can help them relax and help recover from some diseases. This study proposes an approach to identify acupressure points on the head, and it is used for the hair washes and head massage robot for the patient's head. Hair wash and head massage robot by using water jets is proposed, which avoids the spread of some diseases by direct contact, and it reduces the shortage of medical care workers at hospitals. The study proposes a CNN to recognize the home point of the robot mounted on the face with the accuracy of, combined with signals from sensors, to determine the necessary dimensions of the human head. The ANN is used to predict the massage trajectories for the robot to suit each different patient. The overall results are evaluated with an accuracy of 97.56% with the training dataset and 95.12% with the test data.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-2069-1_57,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89912-7_50,Enhancing Student Learning of Disruptive Technologies,"Proceedings of the Future Technologies Conference (FTC) 2021, Volume 3",10.1007/978-3-030-89912-7_50,Springer,2022-01-01,"Disruptive technologies such as artificial intelligence, 3D printing, 5G, the Internet of Things (IoT), virtual/augmented reality, automation, robotics, blockchain, and quantum computing are reshaping industries such as healthcare, financial services, retail, transportation, construction and education. Developments of these technologies are all building on and amplifying one another and the rate of technological change is accelerating. According to the World Economic Forum, we are entering a fourth industrial revolution. These technologies will create millions of new jobs in the next few years, however the supply of talent is not meeting the demand. This requires a plan to develop new talent quickly and a change in the way we educate. Changes in higher education must be made to ensure that students have the skills needed for future jobs. These changes should include offering applied workplace skills through competency-based and outcome-based learning, such as micro-credentialing and Massive Open On-Line Courses (MOOCs). This paper discusses disruptive technology areas, online competency-based approaches and how universities can begin to incorporate these approaches into existing educational frameworks to improve student preparation for the technologically disruptive marketplace.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89912-7_50,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-64573-1_323,AI in Surgical Robotics,Artificial Intelligence in Medicine,10.1007/978-3-030-64573-1_323,Springer,2022-01-01,"The future of surgery is tightly knit with the evolution of artificial intelligence (AI) and its thorough involvement in surgical robotics. Robotics long ago became an integral part of the manufacturing industry. The area of healthcare though adds several more layers of complication. In this chapter we elaborate a broad range of issues to be dealt with when a robotic system enters the surgical theater and interacts with human surgeons – from overcoming the limitations of minimally invasive surgery to the enhancement of performance in open surgery. We present the latest from the fields of cognitive surgical robots, focusing on proprioception, intraoperative decision-making, and, ultimately, autonomy. More specifically, we discuss how AI has advanced the research field of surgical tool tracking, haptic feedback and tissue interaction sensing, advanced intraoperative visualization, robot-assisted task execution, and finally land in the crucial development of context-aware decision support.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-64573-1_323,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-93758-4_6,"The Artificial Scientist: Logicist, Emergentist, and Universalist Approaches to Artificial General Intelligence",Artificial General Intelligence,10.1007/978-3-030-93758-4_6,Springer,2022-01-01,"We attempt to define what is necessary to construct an Artificial Scientist, explore and evaluate several approaches to artificial general intelligence (AGI) which may facilitate this, conclude that a unified or hybrid approach is necessary and explore two theories that satisfy this requirement to some degree.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-93758-4_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-9476-9_14,The Future Healthcare Technologies: A Roadmap to Society 5.0,Geospatial Data Science in Healthcare for Society 5.0,10.1007/978-981-16-9476-9_14,Springer,2022-01-01,"The 5th Science and Technology Basic Plan, adopted by the Japanese Cabinet in January 2016, presented a core concept, called Society 5.0. Society 5.0 will create new values through technological innovation to eliminate, regional, age, gender, and language gaps, and enable the provision of services customized to various individual needs. It is an information society aiming for a prosperous human-centered society which has the potential to resolve a variety of challenges in various fields, such as Mobility, Healthcare, Agriculture, Food, Manufacturing, Disaster Control, Energy, and many more. The Society 5.0 offers a high degree of convergence between cyber space (virtual space) and physical space (real space). The modern technologies, such as AI, IoT, cyber-physical systems, VR/AR, Big Data analytics, Blockchain etc., play an important role for achieving the goals of super-smart society. These digital technologies can be used to improve health, and make healthcare system more affordable and cost-effective. The Society 5.0 has a number of challenges that offer opportunities to create new systems and processes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-9476-9_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-95459-8_43,Probabilistic Mapping of Tissue Elasticity for Robot-Assisted Medical Ultrasound,Robotics Research,10.1007/978-3-030-95459-8_43,Springer,2022-01-01,"A novel modality of ultrasound imaging known as elastography has been shown to improve cancer detection for women with dense breast tissue. However, the scanning procedure for this technique is often difficult for a human to perform in a consistent manner and could conceivably benefit from robot assistance. In this work, we present a novel robot-assisted probabilistic elasticity mapping algorithm which uses Gaussian filter techniques to produce elastograms and uncertainty maps. We demonstrate the proposed approach using a 7-DOF robot manipulator on a gelatin phantom designed to imitate the elasticity of human tissue. The results indicate the algorithm is capable of imaging a $${6.5\,\mathrm{\text {m}\text {m}}}$$ 6.5 mm lesion and reducing map uncertainty in the observable region.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-95459-8_43,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-94141-3_27,Neuro-Computer Interface Control of Cyber-Physical Systems,"High-Performance Computing Systems and Technologies in Scientific Research, Automation of Control and Production",10.1007/978-3-030-94141-3_27,Springer,2022-01-01,"The paper proposes an approach to and solves the problem of controlling a robot by using neural interface technology, describes the general scheme and working principle of the main idea of non-invasive neural interface control of a robot using the original convolutional neural network. The authors describe the principles of an original convolutional neural network and an approach to the modern network design, present a model of a one-dimensional convolutional network based on the principles of a human inner ear. The structure of a software package is proposed. The results of a comparison of algorithms for the analysis of human brain evoked potentials used in the design of brain-computer interfaces are presented. The authors used the Fourier transform algorithm and the multidimensional synchronization index (MSI) algorithm in various modifications to perform the experiment. Analysis of the initial signal, the accumulated evoked potential, in addition to the accumulated evoked potential spectrum were proposed as variations. Linear correlation was also evaluated with analysis using a user-derived reference signal sample and various variations of wavelet filtering. In addition, model signals, which were a combination of white noise and a harmonic oscillation simulating a stable visual evoked potential, were used. The best results (error rate <10%) with an analysis time of 3 s were obtained for the MSI of the original signal, MSI with the Fourier transform. Also in this list, there is a MSI where the wavelet filtering result of coherent accumulation was used as an etalon, a linear correlation coefficient. In a MSI the evoked potential, recovered after the wavelet transform, was used as an etalon.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-94141-3_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-95388-1_7,Fast On-Road Object Detector on ROS-Based Mobile Robot,Algorithms and Architectures for Parallel Processing,10.1007/978-3-030-95388-1_7,Springer,2022-01-01,"The application environment of mobile robot is gradually expanding from indoor to outdoor. Vision-based detection, which acquires traffic information through the camera, is a state-of-the-art auxiliary technology. In this paper, a robotic middleware Robot Operating System (ROS) is applied to detect object and control application based on embedded processor. And, we present an effective On-road object detector which is suitable for embedded GPU by improving the performance of Single Shot MultiBox Detector (SSD). Our approach is to construct detection network by using depth-wise separable convolution for saving computing resource and present multi-category clustering to adjust the generated default boxes for optimizing accuracy. Experiments on KITTI dataset show that the proposed network runs 2.1 times faster than original SSD network on embedded GPU and maintains 71% mean average precision. Finally, a mobile robot is designed based on the detector and controller to demonstrate On-road assisted driving intuitively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-95388-1_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-97672-9_9,Neural Network Self Tuning PI Control for Thin McKibben Muscles in an Antagonistic Pair Configuration,Robot Intelligence Technology and Applications 6,10.1007/978-3-030-97672-9_9,Springer,2022-01-01,"This paper proposes a model free neural network self-tuning proportional integral (NNPI) controller for a biceps-triceps thin McKibben muscle (TMM) platform in an antagonistic pair configuration. The study intends to explore the proposed model independent control strategy for TMMs in an antagonistic assembly for time varying joint angle tracking. In practice, PI controllers are tuned offline to obtain control parameters which suits the system. A change in the desired joint angle specifications may degrade the performance of the controller, hence the gains are no longer adequate. The proposed NNPI controller updates the control parameters in real-time according to the gradient descent method to minimize the error. To test the effectiveness of the proposed method, experiments are carried out on the TMM platform and injected with sinusoidal input signals with two different frequencies. Experiments conducted showed the TMM platform able to produce better accuracy for both conditions by implementing the NNPI control scheme compared to a Proportional Integral (PI) controller and a Model Free Adaptive Controller (MFAC). The control can be very useful in other TMM applications requiring antagonistic muscle actuation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-97672-9_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-3089-8_10,Adversarial Surround Localization and Robust Obstacle Detection with Point Cloud Mapping,Computational Intelligence in Pattern Recognition,10.1007/978-981-19-3089-8_10,Springer,2022-01-01,"Significant research issues and experimental possibilities on autonomous vehicles are in vogue around the world. Among these, collision-free navigation has constituted one of the significant fields to research. Along with the vigorous emergence of definite sensors, challenges are coming in new avenues. This paper proposes a keen way to detect on-route obstacles using training of model through adversarial neural network along with 3D reconstruction of a surrounding under GPS-denied Indoor Environment (IE) using point cloud map. The depth sensor used here has been systematically analysed to tackle the challenge. This paper also studies the possible challenges and hurdles faced by the customized mobile robot to create point cloud map using depth sensor integrated with Robot Operating System (ROS) platform to reconstruct the surrounding. The reconstructed visuals been used as memory trail of environment along with visual reference. This array of references would prove to be credential for path planning algorithm and promises finding near optimal collision-free Indoor Mobile Robot Navigation (IMRN).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-3089-8_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-6372-7_60,Multi-robot Cooperate Region Coverage Search Algorithm Based on Distributed Control,Proceedings of 2021 Chinese Intelligent Automation Conference,10.1007/978-981-16-6372-7_60,Springer,2022-01-01,"Aiming at the situation that multi-robot system cannot establish global communication when performing region coverage task in unknown environment, a multi-robot cooperative region coverage search algorithm based on distributed control is proposed. Bio-inspired neural network and raster map are combined to represent dynamic search environment. Weighted average method (WAM) is used to fuse environmental information collected by different robots. In addition, several dynamic search alliances are formed among robots under the framework of distributed model prediction (DMPC). Within the alliance, each member makes iterative collaborative decision in turn, and the genetic algorithm (GA) is used to optimize the solution to obtain the next movement path of each robot. Simulation results show the effectiveness and superiority of the proposed algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-6372-7_60,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-4284-5_40,The Practical Enactment of Robotics and Artificial Intelligence Technologies in E-Commerce,Cyber Intelligence and Information Retrieval,10.1007/978-981-16-4284-5_40,Springer,2022-01-01,"This paper maps and portrays the current and anticipated relationship between two different consistent pieces of exhibiting science and programming. It takes a gander at the association of cutting-edge displaying and artificial cognizance (computerized reasoning) in the insightful network, proposing, at the same time, an artificial intelligence model that could fit in a couple of parts of cutting edge displaying coherent zone. There are different consistent disseminations concerning artificial mental ability (human-made knowledge) across the requests. Regardless, suggesting automated promoting points of view, this number excess parts nearly nothing. Coherent research on artificial cognizance (computerized reasoning) could benefit from displaying science in different ways. Nowadays, simply a restricted amount of consistent investigation insinuating progressed publicizing and synthetic thinking (human-made brainpower) is related to unequivocal electronic advancing techniques. This paper includes man-made review (man-made knowledge) applications on cutting-edge promoting temperate zone, establishment dissemination, and refers to potential comparative reasons that occur. It gives an artificial intelligence model that could fit in a couple of cutting-edge publicizing occasions. This paper depicts the internet business, advancement circumstance, and possibilities of AI innovation, examines the current circumstance of the use of AI innovation in the field of internet business, fundamentally consider and talk about in detail from the part of the partner of AI, smart coordination, proposal motor, and the ideal valuing application through the exploration of online business insightful activity case—noon.ae, amazon.ae, tests into the significant effect and incredible noteworthiness on the internet business improvement of artificial brainpower.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-4284-5_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-2078-2_2,"Ocean Explorations Using Autonomy: Technologies, Strategies and Applications",Offshore Robotics,10.1007/978-981-16-2078-2_2,Springer,2022-01-01,"Ocean exploration has become one of the most important strategies for a sustainable development for our world. To better understand the ocean and make an efficient use of its resources, autonomous marine vehicles (AMVs) including both surface and underwater vehicles play an essential role to extend and accelerate the exploration capabilities. This chapter provides an in-depth review of the key technologies in the development of autonomous surface vehicles (ASVs) and autonomous underwater vehicles (AUVs), which are two main types of AMVs. With the illustration of some typical vehicle prototypes, the control methods and deployment strategies of ASVs and AUVs, especially the collaborative operation of these two types of vehicles, have been discussed to inspire a wide application of marine autonomy in future ocean explorations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-2078-2_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-87524-4_2,Race and Robotics: Black Theology in the Digital Age,Africa and the Fourth Industrial Revolution,10.1007/978-3-030-87524-4_2,Springer,2022-01-01,"The Fourth Industrial Revolution has been pedestalized as the greatest leap of human intellect. 4IR does not hide the serious destruction to traditional approaches to the sciences (theoretical and applied), technology, economics, politics, and human psychology. The rise of robotics change of the workplace, biotechnology, artificial intelligence, and the change in human beings seem extremely noble and worthy of celebration. However, the greatest neglect in this “great” leap is that of human beings who for centuries have remained engulfed in a contestation and defense of their humanity by the same superpowers that are holding countries and continents at gunpoint—convert or die! The Third World becomes subservient to the dominant change in societies. Issues of politics, the land question, the centuries of the exploitation of resources, and the debt owed to the oppressed and absolute destruction of worldviews, which have evolved over millennia’s are expected to change and be forgotten. In short, the 4IR despite the language of technology and science often presented by geeks is extremely political. This paper seeks to argue that the projection of (white) human “intellect” has and continues to ignore the humanity and intelligence of blacks/oppressed. They rather favor artificial intelligence and robotics than correct the previously disembodiment of the oppressed, ontologically, politically, cultural, and physiologically. 4IR is a prerogative of “superpowers” meant to replace the oppressed and continues the project of the rulers of the world. The paper seeks to point out the nuances of 4IR, however, reflecting 4IR political implication for the oppressed who are the majority in the world.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-87524-4_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-64573-1_334,AIM in Nursing Practice,Artificial Intelligence in Medicine,10.1007/978-3-030-64573-1_334,Springer,2022-01-01,"Global emergence and exponential growth of artificial intelligence (AI) is becoming seamlessly integrated in our lives. By definition, AI describes a set of advanced technologies enabling machines to perform highly complex tasks effectively otherwise requiring intelligence that can’t be matched if human beings were to perform them. How this reflects on the human mind is certain to continue being an area of ongoing research. This said, science fiction books and the numerous AI-induced apocalyptic scenarios presented to us in films and television series depicting AI gone wrong have cultivated a sense of fear and apprehension. However, to date, the healthcare industry does not evoke Orwellian concerns. Instead, the impact of this technology is particularly evident in the healthcare sector where this innovation promises transformation of the landscape of nursing practice along with the process involved in the delivery of collaborative, compassionate, ethically sound, and evidence-based patient care. In so doing, AI will likely resolve the current problem of global staff shortage and the decline in funding growth driven by an aging baby boomer generation living with multiple complex chronic health conditions. During this transformative time, nurses must reflect on how healthcare technologies can ensure the patient’s experience of care is embedded with understanding and compassion. The loss of these essential characteristics may lead patients to feel that in an AI-driven world their rights become an after-thought in the relentless pursuit of efficiency. To address this, formal and informal educational programs need to be reviewed. Besides enhancing the educators’ AI knowledge, it would be logical to include AI-related professionals to create a truly collaborative approach to training nurses.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-64573-1_334,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-05061-9_23,"Multimodal Emotion Analysis Based on Visual, Acoustic and Linguistic Features","Social Computing and Social Media: Design, User Experience and Impact",10.1007/978-3-031-05061-9_23,Springer,2022-01-01,"In this paper, a computational reasoning framework that can interpret social signals of the person in interaction by focusing on the person’s emotional state is presented. Two distinct sources of social signals are used for this study: facial and voice emotion modalities. As a part of the first modality, a Convolutional Neural Network (CNN) is used to extract and process the facial features based on live stream video. The voice emotion analysis containing two sub-modalities is driven by CNN and Long Short-Term Memory (LSTM) networks. The networks are analyzing the acoustic and linguistic features of the voice to determine the possible emotional cues of the person in interaction. Relying on the multimodal information fusion, the system then fuses data into a single hypothesis. Results of such reasoning are used to autonomously generate the robot responses which are shown in a form of non-verbal facial animations projected on the ‘face’ surface of the affective robot head PLEA. Built-in functionalities of the robot can provide a degree of situational embodiment, self-explainability and context-driven interaction.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-05061-9_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-0976-4_53,Factorization of AI Application in HRM,Proceedings of International Conference on Communication and Artificial Intelligence,10.1007/978-981-19-0976-4_53,Springer,2022-01-01,"Last decade has witnessed drastic change in the field of technology, resulting into transformational change in the way an organization operates. This radical technological transformation is referring to as Industry 4.0 further known as intelligent industry. This talks about the inclusion of some disruptive technologies such as Artificial intelligence (AI) for handling and managing the different business operations or managerial functions. AI applications play a very significant role in the area of human resource management. The use of AI technology facilitated the organizations to extract benefit through effective utilization of human resources. Thus it is important to find out the significant factors responsible for adopting AI in Indian context through empirical investigation. For this, 247 professionals working in NCR and UP west were surveyed through online and offline mode. Principle component analysis was used to make factorization of AI indicators in HR. Results provide four major factors responsible for adopting AI in Indian organizations namely-association, robotics, channelization, and position factors. Research findings reflect association factor as most critical factor in adopting AI in Indian organizations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-0976-4_53,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-64573-1_64,AIM in Medical Robotics,Artificial Intelligence in Medicine,10.1007/978-3-030-64573-1_64,Springer,2022-01-01,"Medical robotics emerged in the 1980s to improve clinicians’ technical capability and increase safety in clinical procedures. This chapter specifically addresses the topic of surgical robots. Major opportunities for artificial intelligence (AI) here include (i) surgical planning, (ii) intra-operative registration, (iii) surgical execution, and (iv) surgery evaluation/ assessment. This chapter provides an overview of AI methodologies developed so far in these four fields, reporting main limitations and open challenges. Deep learning (DL) models for pre-operative image segmentation, classification, and detection are presented, along with DL architectures for intra-operative registration. In the context of surgical execution, intra-operative image analysis is described, focusing on endoscopic images for tissue and surgical tool segmentation. Considering the rapid evolution of AI applications in the field of surgical robotics, the proposed contribution is aimed at giving to young researchers and surgeons working in the field of surgical robotics a complete overview on the current AI applications proposed in literature.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-64573-1_64,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-19-0770-8_2,"Prospects of ‘SMART Farming’ in Cold Arid Region of Ladakh, India",Intelligent Systems for Social Good,10.1007/978-981-19-0770-8_2,Springer,2022-01-01,"From traditional to subsistence and from the modern to emerging ‘Smart Farming’ era, Indian agriculture has achieved many milestones. This has ultimately put the country into a league of food-sufficient countries ensuring food security for all of us. Smart farming is the management of farms using technologies like the Internet of Things (IoT), robotics, drones, and artificial intelligence (AI). It helps in increasing the quantity and quality of products while reducing the human labor required for production. Smart farming is opening the way for a more productive and sustainable kind of agricultural production in the country, based on a more accurate and resource-efficient method. This review book chapter presents a detailed analysis of various smart farming technologies with a special focus on IoT and their prospects in agriculture with special reference to the cold arid Ladakh region.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-0770-8_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-97054-3_11,Education and Artificial Intelligence: A New Perspective,Digital Humanism,10.1007/978-3-030-97054-3_11,Springer,2022-01-01,"Education and artificial intelligence? The question forces us to ask ourselves about the limits and potential of machines and algorithms, or rather about the responsibilities of our choices, about their effects. Technological devices that are increasingly sophisticated, autonomous and integrable with our organism are simulating human capabilities. What we call artificial intelligence marks everyday life and constitutes a challenge for the future of civilization. Challenge and therefore unknowns, risks and opportunities. A new alliance between education and artificial intelligence means cultivating people's creative and civic resources in relational contexts where digital connectivity is so pervasive that it is unthinkable to interpret its logic without adequate pedagogical awareness. It is a question of educating to discernment and understanding how radical innovations, of process and product, can contribute to the common good in addressing educational needs and social fragility, inequality and poverty. A pedagogy of artificial intelligence urges us to take care of the human. It speaks to parents, teachers and those involved in design, manufacture and training of intelligent machines, encouraging them to foster the development of a responsible conscience that will give rise to fair values and actions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-97054-3_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-95798-8_1,What Is Industry 4.0?,Innovation in Construction,10.1007/978-3-030-95798-8_1,Springer,2022-01-01,"This chapter briefly presents an introduction to key technological innovations in construction and their potential/current uses in the industry. Some of these technologies have been written about extensively; however, the summaries presented below are provided as a convenient introduction and reference for subsequent chapters.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-95798-8_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-04870-8_50,Recent Trends in Mobile Robotics for 3D Mapping in Agriculture,Advances in Service and Industrial Robotics,10.1007/978-3-031-04870-8_50,Springer,2022-01-01,"This article presents trends and future developments in mobile robotics for 3D mapping in agriculture. Recent examples of robotic platforms and sensors are first presented to highlight the technologies adopted for autonomous surveying in the agricultural field. Then, localization and mapping approaches are discussed, as well as path planning algorithms for the navigation of mobile robots in orchards and crops. Finally, insights into applications of artificial intelligence to robotic mapping are given to evaluate the potentiality of neural networks in this field. The results of the survey indicate research directions and suggest future applications of mobile robotics as an efficient tool for smart agriculture.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-04870-8_50,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-91135-5_6,Artificial Intelligence in Fashion Manufacturing: From Factory Operation to Advisory Role,Leading Edge Technologies in Fashion Innovation,10.1007/978-3-030-91135-5_6,Springer,2022-01-01,"The fashion industry has experienced an unprecedented application of artificial intelligence (AI) in the last decade. At the manufacturing, distribution, and consumer retention stages, the implementation of AI technologies has afforded fashion retailers assistance in diverse fields, such as production, trend analysis and forecasting, hyperpersonalized marketing, and overall consumer engagement. Specific technologies, such as robotics, intelligent sensors, digital agents, and smart algorithms and machine learning, have altered the trajectory of the fashion industry. By delineating integral cases of technologies in fashion manufacturing and operation, this chapter aims to enhance the reader’s understanding of where the fashion industry stands in relation to AI and provide discussion points where these advances are progressing in terms of productivity and sustainable efforts for the industry, both economically and theoretically.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-91135-5_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-981-13-6106-7_134-1,Future of Health Professions Education Curricula,Clinical Education for the Health Professions,10.1007/978-981-13-6106-7_134-1,Springer,2022-01-01,"This chapter discusses the future of health professions education (HPE) curricula using David Kern’s six steps of curriculum development as an organizing principle. It discusses several problems that future healthcare professionals (HCPs) will face including challenges of greater scope, less time, and less resources to promote health and provide patient care. It also discusses the transition from declarative knowledge and rote memorization to more application of information and problem-solving while leveraging the technology at HCPs’ fingertips. There will also be highlights of future technologies that enhance and transform patient care, the massive amounts of data that will be generated, and the future of technology-enabled learning, teaching, and assessment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-6106-7_134-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89776-5_1,Adaptive System for Object Detection and Picking Based on Efficient Convolutional Neural Networks,"4th International Conference on Wireless, Intelligent and Distributed Environment for Communication",10.1007/978-3-030-89776-5_1,Springer,2022-01-01,"Thanks to the rapid development of technology and urbanization, the generation of a vast amount of waste has created an environmental problem that demands an urgent solution. The conventional approach to dealing with the problem is to hire more human workers. However, humans are vulnerable to musculoskeletal injuries from repetitive motions. In recent years, many experts and scholars have committed to the development of robots to replace or complement human beings. As part of this effort, this work aims to develop a mobile robot, which can be combined with cellular phones and the Internet of Things to realize long-distance control, query, and monitoring. A camera is affixed to the robot to return environmental information. A sophisticated yet effective machine learning-based image recognition method is used to detect several common types of garbage in the surrounding area. Test data shows a precision of 0.42 for bottles and 0.99 for cans, and an F1_score of 0.57 for bottles and 0.94 for trash. After the garbage is identified, the robot will move toward it and pick it up. In the design and implementation of the system, great care has been taken to enhance its efficiency and dependability. Wireless communication and lightweight messaging protocol have also been used to facilitate agile mobility and fast information exchanges.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89776-5_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-95459-8_15,Embedded Neural Networks for Robot Autonomy,Robotics Research,10.1007/978-3-030-95459-8_15,Springer,2022-01-01,"We present a library to automatically embed signal processing and neural network predictions into the material robots are made of. Deep and shallow neural network models are first trained offline using state-of-the-art machine learning tools and then transferred onto general purpose microcontrollers that are co-located with a robot’s sensors and actuators. We validate this approach using multiple examples: a smart robotic tire for terrain classification, a robotic finger sensor for load classification and a smart composite capable of regressing impact source localization. In each example, sensing and computation are embedded inside the material, creating artifacts that serve as stand-in replacement for otherwise inert conventional parts. The open source software library takes as inputs trained model files from higher level learning software, such as Tensorflow/Keras [ 1 , 2 ], and outputs code that is readable in a microcontroller that supports C. We compare the performance of this approach for various embedded platforms. In particular, we show that low-cost off-the-shelf microcontrollers can match the accuracy of a desktop computer, while being fast enough for real-time applications at different neural network configurations. We provide means to estimate the maximum number of parameters that the hardware will support based on the microcontroller’s specifications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-95459-8_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-95459-8_40,Introspective Robot Perception Using Smoothed Predictions from Bayesian Neural Networks,Robotics Research,10.1007/978-3-030-95459-8_40,Springer,2022-01-01,"This work focuses on improving uncertainty estimation in the field of object classification from RGB images and demonstrates its benefits in two robotic applications. We employ a Bayesian Neural Network (BNN), and evaluate two practical inference techniques to obtain better uncertainty estimates, namely Concrete Dropout (CDP) and Kronecker-factored Laplace Approximation (LAP). We show a performance increase using more reliable uncertainty estimates as unary potentials within a Conditional Random Field (CRF), which is able to incorporate contextual information as well. Furthermore, the obtained uncertainties are exploited to achieve domain adaptation in a semi-supervised manner, which requires less manual efforts in annotating data. We evaluate our approach on two public benchmark datasets that are relevant for robot perception tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-95459-8_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-99170-8_10,An Approach to Estimate the Orientation and Movement Trend of a Person in the Vicinity of an Industrial Robot,"Smart Technologies, Systems and Applications",10.1007/978-3-030-99170-8_10,Springer,2022-01-01,"Implementation of industrial robots worldwide -not only typical caged robots, manipulating heavy machinery and performing repetitive tasks, but also collaborative robots-, comes with the challenge of guaranteeing the safety of human operators, whether they work aside from the robot or in its vicinity. The UNE-EN ISO10218 safety standards for industrial robots set that robots and people can work in common spaces if robots have safety devices or are supported by them, to avoid hurt human operators. This paper introduces an approach that allows estimating the orientation and movement trend of a person in the vicinity of a robotized industrial task, aiming to avoid the collision between human and robot. As a previous requirement of the approach, a PointNet architecture was trained with the point clouds obtained from Depth images of a proprietary RGB-D image dataset. This task, in turn, required detecting people in the corresponding RGB images, through the application of a pre-trained saliency algorithm. To estimate the orientation of the detected person, a modified Biternion network was trained with the resized images from the same proprietary database. At evaluating the system, depth images captured by a Kinect sensor were used as inputs, then, for a set of four iterations (four frames), the movement trend was calculated since the orientation of the person was known for every frame. The prediction capability of the proposed approach was evaluated with three groups of images and resulted in a general precision greater than 0.5.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-99170-8_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-021-09997-2,Heterogeneous graph attention networks for scalable multi-robot scheduling with temporospatial constraints,Autonomous Robots,10.1007/s10514-021-09997-2,Springer,2022-01-01,"Robot teams are increasingly being deployed in environments, such as manufacturing facilities and warehouses, to save cost and improve productivity. To efficiently coordinate multi-robot teams, fast, high-quality scheduling algorithms are essential to satisfy the temporal and spatial constraints imposed by dynamic task specification and part and robot availability. Traditional solutions include exact methods, which are intractable for large-scale problems, or application-specific heuristics, which require expert domain knowledge to develop. In this paper, we propose a novel heterogeneous graph attention network model, called ScheduleNet, to learn scheduling policies that overcome the limitations of conventional approaches. By introducing robot- and proximity-specific nodes into the simple temporal network encoding temporal constraints, we obtain a heterogeneous graph structure that is nonparametric in the number of tasks, robots and task resources or locations. We show that our model is end-to-end trainable via imitation learning on small-scale problems, and generalizes to large, unseen problems. Empirically, our method outperforms the existing state-of-the-art methods in a variety of testing scenarios involving both homogeneous and heterogeneous robot teams.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-021-09997-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-03502-9_22,Neural Dynamic Programming with Application to Wheeled Mobile Robot,"Automation 2022: New Solutions and Technologies for Automation, Robotics and Measurement Techniques",10.1007/978-3-031-03502-9_22,Springer,2022-01-01,"In this paper we propose a new application sensor-based navigation method for navigation of wheeled mobile robot, based on neural dynamic programming (NDP). We discuss a sensor-based approach to path design and control of wheeled mobile robot (WMR) in an unknown 2-D environment with static obstacles. A strategy of navigation is developed including two main behaviors: a reaching the middle of a collision-free space behavior, and a goal-seeking. The NDP navigator which is the main theme of this paper, can fuse behaviors so that the mobile robot can go for the goal position without colliding with obstacles for the concave and convex obstacles. This solution is based on the reinforcement learning (RL) method of actor-critic architecture for continuous-time, and does not require pre-learning and working on-line. Computer simulations have been conducted to illustrate the performance of the proposed solution by a series of experiments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-03502-9_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-08421-8_21,Vision-Based Holistic Scene Understanding for Context-Aware Human-Robot Interaction,AIxIA 2021 – Advances in Artificial Intelligence,10.1007/978-3-031-08421-8_21,Springer,2022-01-01,"Human activity recognition systems from static images or video sequences are becoming more and more present in our life. Most computer vision applications such as human-computer interaction, virtual reality, public security, smart home monitoring, or autonomous robotics, to name a few, highly rely on human activity recognition. Of course, basic human activities, such as “walking” and “running”, are relatively easy to recognize. On the other hand, identifying more complex activities is still a challenging task that could be solved by retrieving contextual information from the scene, such as objects, events, or concepts. Indeed, a careful analysis of the scene can help to recognize human activities taking place. In this work, we address a holistic video understanding task to provide a complete semantic level description of the scene. Our solution can bring significant improvements in human activity recognition tasks. Besides, it may allow equipping a robotic and autonomous system with contextual knowledge of the environment. In particular, we want to show how this vision module can be integrated into a social robot to build a more natural and realistic context-based Human-Robot Interaction. We think that social robots must be aware of the surrounding environment to react in a proper and socially acceptable way, according to the different scenarios.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-08421-8_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-95070-5_15,Avoiding Unexpected Obstacles During Robotic Navigation Using Rapidly-Exploring Random Trees and a Neural Network Simulator,Artificial Intelligence Research,10.1007/978-3-030-95070-5_15,Springer,2022-01-01,"Well-known environments allow for the creation of open-loop robotic controllers (controllers that do not rely on sensor feedback). Unexpected obstacles in the robot path would render an open-loop controller useless and would require a sophisticated and complex closed-loop controller. This problem is addressed by the developed approach that uses command sampling and neural network based localization to temporarily take control and safely navigate around unexpected obstacles, when detected. Control is then relinquished back to the base controller to perform the original task. Experiments performed on a real robot highlight the viability of the approach for short-term navigation, but adjustments are required for longer paths.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-95070-5_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-70601-2_217,Artificial Neural Network-Based Shared Control for Smart Wheelchairs: A Fully-Manual Driving for the User,XXVII Brazilian Congress on Biomedical Engineering,10.1007/978-3-030-70601-2_217,Springer,2022-01-01,"Wheelchairs play an important role in regaining lost mobility and in the social reintegration of its users. However, users with quadriplegia yet have a few low cost solutions that meet their needs. The present work proposes a shared control strategy designed to operate together with discrete human-machine interfaces, where the user has few commands, and capable to integrate different types of sensors that can be attached to a commercial powered wheelchairs, without the necessity of localization. Simulations show that the proposed strategy provides a robust and safe navigation through daily environments and does not take away the navigation autonomy from the user, who performs a fully-manual driving.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-70601-2_217,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-03502-9_23,Predicting Dynamics of a Rehabilitation Exoskeleton with Free Degrees of Freedom,"Automation 2022: New Solutions and Technologies for Automation, Robotics and Measurement Techniques",10.1007/978-3-031-03502-9_23,Springer,2022-01-01,"The challenges of the modern world accelerated the development of many fields of technology, including rehabilitation robotics. The focus of the robot-aided motor therapy is put on providing remote, home treatment. According to the conducted research, also, functional kinesiotherapy is a leading trend for the future. Therefore, designing a mechatronic device enabling such a workout is needed. The presented study is based on a concept of an upper extremity exoskeleton with free degrees of freedom. However, it is applicable for any exoskeleton with non-controlled joints. The paper corresponds to the problem of a control system for a not fully controlled robot; especially, as the mass parameters of the user’s limb remain unknown. Investigated prediction control is based on a recurrent neural network model of the system. The dynamics simulations are all performed without the usage of a physical device. Nevertheless, the outcomes of the trials prove, that such a control approach is suitable for the exoskeletons with free degrees of freedom. The results may be the base to adjust basic parameters of the neural networks used for similar applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-03502-9_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-82193-7_6,Performance Analysis of Data-Driven Techniques for Solving Inverse Kinematics Problems,Intelligent Systems and Applications,10.1007/978-3-030-82193-7_6,Springer,2022-01-01,"Inverse kinematics is one of the most important, most researched but still one among the most challenging problems in the robotics domain, for problems like motion generation and trajectory optimization. Various attempts have been made to propose a neural network that can solve the inverse kinematics problems. But not much emphasis has been given to analyze and compare its performance with other state-of-the-art methods. The major contribution of this paper is to present the performance analysis of one of the best neural networks proposed so far, and compare its results with the analytical approach. The main reason for using data-driven techniques like neural networks for inverse kinematics solution of robotic manipulators is that it can be extended to any number of links without much effort, while in other methods we have to consider number of links, types of links beforehand...",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-82193-7_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01555-3,Towards the Achievement of Path Planning with Multi-robot Systems in Dynamic Environments,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01555-3,Springer,2021-12-28,"Recent advances in technology lead to the use of robotic systems as part of the modern working environment. Single and multiple robotic systems work closely with humans to accomplish desired tasks, and the recent advancements have made the usage of multi-robot teams more appealing. One critical problem in utilizing the robot’s full potential is the Path planning problem and, while in the case of a single’s robot, path planning has been extensively investigated, in the case of Multiple Robotic Systems (MRS), especially in dynamic changing environments, there are significant open challenges. Based on the statement mentioned above, a detailed survey has been conducted to highlight these challenges and identify potential solutions. In addition, the beneficial use of MRS is presented, as opposed to single robotic systems through the literature, and already-achievable industry-related results are provided. It is concluded that the practical application of path planning in dynamic environments using MRS is still a field of research and development, requiring the community to engage more with practical applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01555-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11432-020-3170-2,Reinforcement learning based energy efficient robot relay for unmanned aerial vehicles against smart jamming,Science China Information Sciences,10.1007/s11432-020-3170-2,Springer,2021-12-27,"Unmanned aerial vehicles (UAVs) with limited energy resources, severe path loss, and shadowing to the ground base stations are vulnerable to smart jammers that aim to degrade the UAV communication performance and exhaust the UAV energy. The UAV anti-jamming communication performance, such as the outage probability, degrades if the robot relay is not aware of the jamming policies and the UAV network topology. In this paper, we propose a robot relay scheme for UAVs against smart jamming, which combines reinforcement learning with a function approximation approach named tile coding, to jointly optimize the robot moving distance and relay power with the unknown jamming channel states and locations. The robot mobility and relay policy are chosen based on the received jamming power, the robot received signal quality, location and energy consumption, and the bit error rate of the UAV messages. We also present a deep reinforcement learning version for the robot with sufficient computing resources. It uses three deep neural networks to choose the robot mobility and relay policy with reduced sample complexity, so as to avoid exploring dangerous policies that lead to the high outage probability of the UAV messages. The network architecture of the three networks is designed with fully connected layers instead of convolutional layers to reduce the computational complexity, which is analyzed by theoretical analyses. We provide the performance bound of the proposed schemes in terms of the bit error rate, robot energy consumption and utility based on a game-theoretic study. Simulation results show that the performance of our proposed relay schemes, including the bit error rate, the outage probability, and the robot energy consumption outperforms the existing schemes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11432-020-3170-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01540-w,Classical and Deep Learning based Visual Servoing Systems: a Survey on State of the Art,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01540-w,Springer,2021-12-24,"Computer vision, together with bayesian estimation algorithms, sensors, and actuators, are used in robotics to solve a variety of critical tasks such as localization, obstacle avoidance, and navigation. Classical approaches in visual servoing systems relied on extracting features from images to control robot movements. Now, state of the art computer vision systems use deep neural networks in tasks such as object recognition, detection, segmentation, and tracking. These networks and specialized controllers play a predominant role in the design and implementation of modern visual servoing systems due to their accuracy, flexibility, and adaptability. Recent research in direct systems for visual servoing has created robotic systems capable of relying only on the information contained in the whole image. Furthermore, end-to-end systems learn the control laws during training, eliminating entirely the controller. This paper presents a comprehensive survey on the state of the art in visual servoing systems, discussing the latest classical methods not included in other surveys but emphasizing the new approaches based on deep neural networks and their applications in a broad variety of applications within robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01540-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42452-021-04916-7,Material removal predictions in the robot glass polishing process using machine learning,SN Applied Sciences,10.1007/s42452-021-04916-7,Nature,2021-12-21,"Abstract Robot polishing is increasingly being used in the production of high-end glass workpieces such as astronomy mirrors, lithography lenses, laser gyroscopes or high-precision coordinate measuring machines. The quality of optical components such as lenses or mirrors can be described by shape errors and surface roughness. Whilst the trend towards sub nanometre level surfaces finishes and features progresses, matching both form and finish coherently in complex parts remains a major challenge. With increasing optic sizes, the stability of the polishing process becomes more and more important. If not empirically known, the optical surface must be measured after each polishing step. One approach is to mount sensors on the polishing head in order to measure process-relevant quantities. On the basis of these data, machine learning algorithms can be applied for surface value prediction. Due to the modification of the polishing head by the installation of sensors and the resulting process influences, the first machine learning model could only make removal predictions with insufficient accuracy. The aim of this work is to show a polishing head optimised for the sensors, which is coupled with a machine learning model in order to predict the material removal and failure of the polishing head during robot polishing. The artificial neural network is developed in the Python programming language using the Keras deep learning library. It starts with a simple network architecture and common training parameters. The model will then be optimised step-by-step using different methods and optimised in different steps. The data collected by a design of experiments with the sensor-integrated glass polishing head are used to train the machine learning model and to validate the results. The neural network achieves a prediction accuracy of the material removal of 99.22%. Article highlights First machine learning model application for robot polishing of optical glass ceramics The polishing process is influenced by a large number of different process parameters. Machine learning can be used to adjust any process parameter and predict the change in material removal with a certain probability. For a trained model,empirical experiments are no longer necessary Equipping a polishing head with sensors, which provides the possibility for 100% control",https://www.nature.com/articles/s42452-021-04916-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s40648-021-00213-5,LiDAR DNN based self-attitude estimation with learning landscape regularities,ROBOMECH Journal,10.1186/s40648-021-00213-5,Springer,2021-12-20,"This paper presents an EKF (extended Kalman filter) based self-attitude estimation method with a LiDAR DNN (deep neural network) learning landscape regularities. The proposed DNN infers the gravity direction from LiDAR data. The point cloud obtained with the LiDAR is transformed to a depth image to be input to the network. It is pre-trained with large synthetic datasets. They are collected in a flight simulator because various gravity vectors can be easily obtained, although this study focuses not only on UAVs. Fine-tuning with datasets collected with real sensors is done after the pre-training. Data augmentation is processed during the training in order to provide higher general versatility. The proposed method integrates angular rates from a gyroscope and the DNN outputs in an EKF. Static validations are performed to show the DNN can infer the gravity direction. Dynamic validations are performed to show the DNN can be used in real-time estimation. Some conventional methods are implemented for comparison.",https://www.biomedcentral.com/openurl?doi=10.1186/s40648-021-00213-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-021-01330-w,Caring in the in-between: a proposal to introduce responsible AI and robotics to healthcare,AI & SOCIETY,10.1007/s00146-021-01330-w,Springer,2021-12-16,"In the scenario of growing polarization of promises and dangers that surround artificial intelligence (AI), how to introduce responsible AI and robotics in healthcare? In this paper, we develop an ethical–political approach to introduce democratic mechanisms to technological development, what we call “Caring in the In-Between”. Focusing on the multiple possibilities for action that emerge in the realm of uncertainty, we propose an ethical and responsible framework focused on care actions in between fears and hopes. Using the theoretical perspective of Science and Technology Studies and empirical research, “Caring in the In-Between” is based on three movements: the first is a change of focus from the world of promises and dangers to the world of uncertainties; the second is a conceptual shift from assuming a relationship with robotics based on a Human–Robot Interaction to another focused on the network in which the robot is embedded (the “Robot Embedded in a Network”); and the last is an ethical shift from a general normative framework to a discussion on the context of use. Based on these suggestions, “Caring in the In-Between” implies institutional challenges, as well as new practices in healthcare systems. It is articulated around three simultaneous processes, each of them related to practical actions in the “in-between” dimensions considered: monitoring relations and caring processes, through public engagement and institutional changes; including concerns and priorities of stakeholders, with the organization of participatory processes and alternative forms of representation; and making fears and hopes commensurable, through the choice of progressive and reversible actions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-021-01330-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-021-00983-0,Towards Richer Assisted Living Environments,SN Computer Science,10.1007/s42979-021-00983-0,Nature,2021-12-08,"This paper describes an ongoing research project which explores the design and use of inexpensive robotics, artificial intelligence techniques, and human–computer interaction methods, to enrich assisted living environments. Such environments provide help to the inhabitants of a home or office, assisting them to perform daily activities, helping them to socialize and interact with others, and to provide enhanced levels of security and safeness. We present the development of an inexpensive robotic solution to help people with disabilities and/or older adults to perform their daily activities. It can be used as a remote controlled surveillance system, and also as a personal assistant. It is able to recognize each inhabitant, his/her emotions, and detect abnormal situations such as falls and health problems. The whole system is designed to operate solely within a local network and special attention is given to the privacy and data protection of the users.",https://www.nature.com/articles/s42979-021-00983-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10845-021-01862-4,Autoencoder-based anomaly detection of industrial robot arm using stethoscope based internal sound sensor,Journal of Intelligent Manufacturing,10.1007/s10845-021-01862-4,Springer,2021-12-02,"Sound and vibration analysis are prominent tools for machine health diagnosis. Especially, neural network (NN) strategies have focused on finding complex and nonlinear relationships between the sensor signal and the machine status to detect machine faults. However, it is difficult to collect enough amount of fault data as much as normal status data for training general NN models. To resolve the issue, this paper proposes the autoencoder-based anomaly detection framework for industrial robot arms using an internal sound sensor. The autoencoder uses signals in the normal state of the robots for training the model. It reconstructs the input signals as output, and anomalous states are found from high reconstruction error. Two stethoscopes were attached to the surface of the robot joint as sensors, and the sounds were recorded by USB microphone attached to the outlet of the stethoscopes. Features were extracted from STFT spectrogram images of the gathered sound, then used to train and test an autoencoder model. The reconstruction errors of the autoencoder were compared to distinguish the abnormal status from normal one. The experimental results suggest that the stethoscopes prevent the interference of noise, and the collected sound signals can be utilized for detecting machine anomalies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10845-021-01862-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11023-021-09579-2,"Robot Autonomy vs. Human Autonomy: Social Robots, Artificial Intelligence (AI), and the Nature of Autonomy",Minds and Machines,10.1007/s11023-021-09579-2,Springer,2021-12-01,"Social robots are robots that can interact socially with humans. As social robots and the artificial intelligence (AI) that powers them becomes more advanced, they will likely take on more social and work roles. This has many important ethical implications. In this paper, we focus on one of the most central of these, the impacts that social robots can have on human autonomy. We argue that, due to their physical presence and social capacities, there is a strong potential for social robots to enhance human autonomy as well as several ways they can inhibit and disrespect it. We argue that social robots could improve human autonomy by helping us to achieve more valuable ends, make more authentic choices, and improve our autonomy competencies. We also argue that social robots have the potential to harm human autonomy by instead leading us to achieve fewer valuable ends ourselves, make less authentic choices, decrease our autonomy competencies, make our autonomy more vulnerable, and disrespect our autonomy. Whether the impacts of social robots on human autonomy are positive or negative overall will depend on the design, regulation, and use we make of social robots in the future.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11023-021-09579-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11063-021-10610-x,Multi-stage Genetic Algorithm and Deep Neural Network for Robot Execution Failure Detection,Neural Processing Letters,10.1007/s11063-021-10610-x,Springer,2021-12-01,"In this paper, we propose a multi-stage genetic algorithm that allows to automatically initialize deep multilayer perceptron neural network models to train it for prediction of robot execution failures. The proposed genetic algorithm system is divided on three stages, the first stage consists of initializing number of hidden layers. The second stage aims to fix number of neurons in each hidden layer. The final stage generates the activation function and the optimizer used to train neural network models. The next step is the application of the generated neural network models to predict robot execution failures. The aim of this approach is giving a robot many models so it can better take a more precise decision, since there is no scientific method to choose neural network model, genetic algorithm allows to generate many models automatically. Results obtained in this study show the efficiency of deep neural networks on robotic failures detection, as well as the efficiency of genetic algorithms to generate different models automatically which prevent the manual setup.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-021-10610-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11119-021-09806-x,Automation in Agriculture by Machine and Deep Learning Techniques: A Review of Recent Developments,Precision Agriculture,10.1007/s11119-021-09806-x,Springer,2021-12-01,"Recently, agriculture has gained much attention regarding automation by artificial intelligence techniques and robotic systems. Particularly, with the advancements in machine learning (ML) concepts, significant improvements have been observed in agricultural tasks. The ability of automatic feature extraction creates an adaptive nature in deep learning (DL), specifically convolutional neural networks to achieve human-level accuracy in various agricultural applications, prominent among which are plant disease detection and classification, weed/crop discrimination, fruit counting, land cover classification, and crop/plant recognition. This review presents the performance of recent uses in agricultural robots by the implementation of ML and DL algorithms/architectures during the last decade. Performance plots are drawn to study the effectiveness of deep learning over traditional machine learning models for certain agricultural operations. The analysis of prominent studies highlighted that the DL-based models, like RCNN (Region-based Convolutional Neural Network), achieve a higher plant disease/pest detection rate (82.51%) than the well-known ML algorithms, including Multi-Layer Perceptron (64.9%) and K-nearest Neighbour (63.76%). The famous DL architecture named ResNet-18 attained more accurate Area Under the Curve (94.84%), and outperformed ML-based techniques, including Random Forest (RF) (70.16%) and Support Vector Machine (SVM) (60.6%), for crop/weed discrimination. Another DL model called FCN (Fully Convolutional Networks) recorded higher accuracy (83.9%) than SVM (67.6%) and RF (65.6%) algorithms for the classification of agricultural land covers. Finally, some important research gaps from the previous studies and innovative future directions are also noted to help propel automation in agriculture up to the next level.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11119-021-09806-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10676-021-09598-8,"How to feel about emotionalized artificial intelligence? When robot pets, holograms, and chatbots become affective partners",Ethics and Information Technology,10.1007/s10676-021-09598-8,Springer,2021-12-01,"Interactions between humans and machines that include artificial intelligence are increasingly common in nearly all areas of life. Meanwhile, AI-products are increasingly endowed with emotional characteristics. That is, they are designed and trained to elicit emotions in humans, to recognize human emotions and, sometimes, to simulate emotions (EAI). The introduction of such systems in our lives is met with some criticism. There is a rather strong intuition that there is something wrong about getting attached to a machine, about having certain emotions towards it, and about getting involved in a kind of affective relationship with it. In this paper, I want to tackle these worries by focusing on the last aspect: in what sense could it be problematic or even wrong to establish an emotional relationship with EAI-systems? I want to show that the justifications for the widespread intuition concerning the problems are not as strong as they seem at first sight. To do so, I discuss three arguments: the argument from self-deception, the argument from lack of mutuality, and the argument from moral negligence.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10676-021-09598-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11548-021-02462-6,Force-guided autonomous robotic ultrasound scanning control method for soft uncertain environment,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-021-02462-6,Springer,2021-12-01,"Purpose Autonomous ultrasound imaging by robotic ultrasound scanning systems in complex soft uncertain clinical environments is important and challenging to assist in therapy. To cope with the complex environment faced by the ultrasound probe during the scanning process, we propose an autonomous robotic ultrasound (US) control method based on reinforcement learning (RL) model to build the relationship between the environment and the system. The proposed method requires only contact force as input information to achieve robot control of the posture and contact force of the probe without any a priori information about the target and the environment. Methods First, an RL agent is proposed and trained by a policy gradient theorem-based RL model with the 6-degree-of-freedom (DOF) contact force of the US probe to learn the relationship between contact force and output force directly. Then, a force control strategy based on the admittance controller is proposed for synchronous force, orientation and position control by defining the desired contact force as the action space. Results The proposed method was evaluated via collected US images, contact force and scan trajectories by scanning an unknown soft phantom. The experimental results indicated that the proposed method differs from the free-hand scanned approach in the US images within 3 ± 0.4%. The analysis results of contact forces and trajectories indicated that our method could make stable scanning processes on a soft uncertain skin surface and obtained US images. Conclusion We propose a concise and efficient force-guided US robot scanning control method for soft uncertain environment based on reinforcement learning. Experimental results validated our method's feasibility and validity for complex skin surface scanning, and the volunteer experiments indicated the potential application value in the complex clinical environment of robotic US imaging system especially with limited visual information.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-021-02462-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13347-021-00486-z,Race and AI: the Diversity Dilemma,Philosophy & Technology,10.1007/s13347-021-00486-z,Springer,2021-12-01,"This commentary is a response to ‘More than Skin Deep’ by Shelley M. Park (Park, More than skin deep: A response to “The Whiteness of AI”, Philosophy & Technology, 2021 ), and a development of our own 2020 paper ‘The Whiteness of AI’. We aim to explain how representations of AI can be varied in one sense, whilst not being diverse. We argue that Whiteness’s claim to universal humanity permits a broad range of roles to White humans and White-presenting machines, whilst assigning a much narrower range of stereotypical roles to people of colour. Because the attributes of AI in the popular imagination, such as intelligence, power and passing as human, are associated by the White racial frame with Whiteness, AI is cast predominantly as White. Following Sparrow (Science, Technology, & Human Values 45:538–560, 2020 ), we suggest this presents a dilemma for those creating or representing AI. We discuss three possible solutions: avoiding anthropomorphisation, explicitly critiquing racial role-typing, and representing powerful AI as non-White.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13347-021-00486-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10676-021-09617-8,A willingness to be vulnerable: norm psychology and human–robot relationships,Ethics and Information Technology,10.1007/s10676-021-09617-8,Springer,2021-12-01,"Should we welcome social robots into interpersonal relationships? In this paper I show that an adequate answer to this question must take three factors into consideration: (1) the psychological vulnerability that characterizes ordinary interpersonal relationships, (2) the normative significance that humans attach to other people’s attitudes in such relationships, and (3) the tendency of humans to anthropomorphize and “mentalize” artificial agents, often beyond their actual capacities. I argue that we should welcome social robots into interpersonal relationships only if they are endowed with a social capacity that is functionally similar to our own capacity for social norms. Drawing on an interdisciplinary body of research on norm psychology, I explain why this capacity is importantly different from pre-programmed, top-down conformity to rules, in that it involves an open-ended responsiveness to social corrective feedback, such as that which humans provide to each other in expressions of praise and blame.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10676-021-09617-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13347-021-00454-7,Group Agency and Artificial Intelligence,Philosophy & Technology,10.1007/s13347-021-00454-7,Springer,2021-12-01,"The aim of this exploratory paper is to review an under-appreciated parallel between group agency and artificial intelligence. As both phenomena involve non-human goal-directed agents that can make a difference to the social world, they raise some similar moral and regulatory challenges, which require us to rethink some of our anthropocentric moral assumptions. Are humans always responsible for those entities’ actions, or could the entities bear responsibility themselves? Could the entities engage in normative reasoning? Could they even have rights and a moral status? I will tentatively defend the (increasingly widely held) view that, under certain conditions, artificial intelligent systems, like corporate entities, might qualify as responsible moral agents and as holders of limited rights and legal personhood. I will further suggest that regulators should permit the use of autonomous artificial systems in high-stakes settings only if they are engineered to function as moral (not just intentional) agents and/or there is some liability-transfer arrangement in place. I will finally raise the possibility that if artificial systems ever became phenomenally conscious, there might be a case for extending a stronger moral status to them, but argue that, as of now, this remains very hypothetical.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13347-021-00454-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10676-021-09596-w,Is it time for robot rights? Moral status in artificial entities,Ethics and Information Technology,10.1007/s10676-021-09596-w,Springer,2021-12-01,"Some authors have recently suggested that it is time to consider rights for robots. These suggestions are based on the claim that the question of robot rights should not depend on a standard set of conditions for ‘moral status’; but instead, the question is to be framed in a new way, by rejecting the is/ought distinction, making a relational turn, or assuming a methodological behaviourism. We try to clarify these suggestions and to show their highly problematic consequences. While we find the suggestions ultimately unmotivated, the discussion shows that our epistemic condition with respect to the moral status of others does raise problems, and that the human tendency to empathise with things that do not have moral status should be taken seriously—we suggest that it produces a “derived moral status”. Finally, it turns out that there is typically no individual in real AI that could even be said to be the bearer of moral status. Overall, there is no reason to think that robot rights are an issue now.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10676-021-09596-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40313-021-00786-x,An Improved Q-learning Approach with Kalman Filter for Self-balancing Robot Using OpenAI,"Journal of Control, Automation and Electrical Systems",10.1007/s40313-021-00786-x,Springer,2021-12-01,"A two-wheeled self-balancing robot (SBR) is a typical example in control systems that works on the principle of an inverted pendulum. In this paper, we experiment to see how the learning and stability performance varies based on Kalman filter introduction for IMU noise filtering and controlling the robot using reinforcement learning. All the implementation is performed in ROS and Gazebo, and Q- learning is implemented using OpenAI (toolkit for development of Reinforcement learning) for ROS, i.e., Openai_ros package. Our work deals with a novel approach of providing the angular output from IMU to Kalman filter and passing it to the input of Q- learning for balancing control. Finally, we analyze the results with and without using Kalman filter from the output of IMU before passing it to Q-learning and evaluate the performance based on robot’s learning behavior and its robustness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40313-021-00786-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13347-021-00485-0,More than Skin Deep: a Response to “The Whiteness of AI”,Philosophy & Technology,10.1007/s13347-021-00485-0,Springer,2021-12-01,"This commentary responds to Stephen Cave and Kanta Dihal’s ( 2020 ) call for further investigations of the whiteness of AI. My response focuses on three overlapping projects needed to more fully understand racial bias in the construction of AI and its representations in pop culture: (1) unpacking the intersections of gender and other variables with whiteness in AI’s construction, marketing, and intended functions; (2) observing the many different ways in which whiteness is scripted, and (3) noting how white racial framing exceeds white casting and thus cannot be undone by more diverse and inclusive hiring (or engineering). Our techno-utopian fantasies, I conclude, are morally suspect in ways that go beneath and beyond the white plastic covering on robotic bodies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13347-021-00485-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13347-021-00448-5,Liability for Robots: Sidestepping the Gaps,Philosophy & Technology,10.1007/s13347-021-00448-5,Springer,2021-12-01,"In this paper, I outline a proposal for assigning liability for autonomous machines modeled on the doctrine of respondeat superior . I argue that the machines’ users’ or designers’ liability should be determined by the manner in which the machines are created, which, in turn, should be responsive to considerations of the machines’ welfare interests. This approach has the twin virtues of promoting socially beneficial design of machines, and of taking their potential moral patiency seriously. I then argue for abandoning the retributive approach to machine crime in favor of prioritizing restitution. I argue that this shift better conforms to what justice demands when sophisticated artificial agents of uncertain moral status are concerned.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13347-021-00448-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-020-0582-7,Neural Network Based Adaptive Dynamic Surface Control for Omnidirectional Mobile Robots Tracking Control with Full-state Constraints and Input Saturation,"International Journal of Control, Automation and Systems",10.1007/s12555-020-0582-7,Springer,2021-12-01,"This paper presents an adaptive neural network dynamic surface controller for four-Macanum-wheeled omnidirectional mobile robots (MWOMRs) trajectory tracking with full state constraints and input saturation. First of all, an adaptive dynamic surface controller is proposed for the MIMO nonlinear systems with uncertainties and disturbances. The neural network is utilized to approximate the uncertain dynamics. A second-order tracking differentiator, instead of the traditional first-order filter, is introduced to overcome the problem of “explosion of complexity” in back-stepping technique and reduce the filtering error. By employing a barrier Lyapunov function and an auxiliary compensator based on Nussbaum function, the full state constraints and input saturation of the MWOMRs are not violated. Moreover, it is proved that all the signals in the closed-loop system with suitable parameters are semi-global uniformly bounded and the tracking error converges to an arbitrarily small compact set to zero. Finally, experiment results are presented to verify the effectiveness and robustness of the proposed adaptive control approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-020-0582-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-021-06342-7,Cooperative learning control of uncertain nonholonomic wheeled mobile robots with state constraints,Neural Computing and Applications,10.1007/s00521-021-06342-7,Springer,2021-12-01,"This article investigates the cooperative tracking control of multiple homogeneous uncertain nonholonomic wheeled mobile robots with state constraints. Transforming each mobile robot system into a chained form, a cooperative learning control scheme based on the adaptive neural network is proposed. Firstly, a virtual control law is designed for the kinematic model of the constrained chain system combined with the barrier Lyapunov function (BLF). Then, radial basis function neural networks (RBF NNs) are exploited to deal with the unknown nonlinear dynamics in the mobile robot system, a robust term is introduced to compensate for the NN approximation errors and the external disturbance, and the Moore–Penrose inverse is adopted to avoid the violation of state constraints. Communication network is used to realize the online sharing of NN weights of each mobile robot individuals, such that locally accurate identification of the unknown nonlinear dynamics with common optimal weights can be obtained. As a result, the learned knowledge can be reused in the cooperative learning control tasks and the trained network model has better generalization capabilities than the normal decentralized learning control. Finally, numerical simulation verifies the effectiveness of the control scheme.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-021-06342-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13042-021-01405-6,An improved neural dynamics based approach with territorial mechanism to online path planning of multi-robot systems,International Journal of Machine Learning and Cybernetics,10.1007/s13042-021-01405-6,Springer,2021-12-01,"The coordination of multi-robot system (MRS) are applied commonly to various fields of the automotive industry. In a variety of cooperative modes, online path planning with obstacles avoidance is a fundamentally important hotspot, especially in a 3-D, complex, or dynamic environment. In the paper, an improved neural dynamics based approach with territorial mechanism is proposed to online path planning of MRS, which can be used as the online path planner for multi-AUVs and multi-UAVs in complex and dynamic environments. This approach integrates biological neural network, computational fluid dynamics, and territorial mechanism of animals, which has the characteristics and advantages of the biological nervous system, namely self-regulation, self-adaptation, self-organization, etc. It can cope with a variety of accidents during path planning, such as the disappearance of targets, the breakdown of robots, the change of environments, and so forth. Meanwhile, the proposed approach has better time performance and is insensitive to the number of robots in MRS. During the path planning of MRS, it can also guarantee to balance workload and to reduce entire workload and total time, which enhance robustness and fairness. The effectiveness and efficiency of the proposed approach are demonstrated by simulations and comparative studies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13042-021-01405-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-021-00842-1,Video Captioning Based on Both Egocentric and Exocentric Views of Robot Vision for Human-Robot Interaction,International Journal of Social Robotics,10.1007/s12369-021-00842-1,Springer,2021-11-30,"Robot vision provides the most important information to robots so that they can read the context and interact with human partners successfully. Moreover, to allow humans recognize the robot’s visual understanding during human-robot interaction (HRI), the best way is for the robot to provide an explanation of its understanding in natural language. In this paper, we propose a new approach by which to interpret robot vision from an egocentric standpoint and generate descriptions to explain egocentric videos particularly for HRI. Because robot vision equals to egocentric video on the robot’s side, it contains as much egocentric view information as exocentric view information. Thus, we propose a new dataset, referred to as the global, action, and interaction (GAI) dataset, which consists of egocentric video clips and GAI descriptions in natural language to represent both egocentric and exocentric information. The encoder-decoder based deep learning model is trained based on the GAI dataset and its performance on description generation assessments is evaluated. We also conduct experiments in actual environments to verify whether the GAI dataset and the trained deep learning model can improve a robot vision system",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-021-00842-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13198-021-01514-z,Target location detection of mobile robots based on R-FCN deep convolutional neural network,International Journal of System Assurance Engineering and Management,10.1007/s13198-021-01514-z,Springer,2021-11-24,"In order to improve the target location detection effect of mobile robots, this paper combines convolutional neural network and recurrent neural network to construct a model for solving abnormal sound event detection. Moreover, this paper constructs a convolutional neural network architecture suitable for feature extraction of audio signals, uses the recurrent neural network to classify each frame of audio signals, and applies the improved R-FCN deep convolutional neural network to the target location detection of mobile robots. In addition, this article uses Matlab to carry out system simulation construction, and design and use the system to carry out performance verification. Through experimental research, it can be seen that the target location system of mobile robot based on R-FCN deep convolutional neural network constructed in this paper can effectively improve the location speed and location accuracy compared with traditional location systems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13198-021-01514-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-021-01266-1,“I Am Not Your Robot:” the metaphysical challenge of humanity’s AIS ownership,AI & SOCIETY,10.1007/s00146-021-01266-1,Springer,2021-11-23,"Despite the reality that self-learning artificial intelligence systems (SLAIS) are gaining in sophistication, humanity’s focus regarding SLAIS-human interactions are unnervingly centred upon transnational commercial sectors and, most generally, around issues of intellectual property law. But as SLAIS gain greater environmental interaction capabilities in digital spaces, or the ability to self-author code to drive their development as algorithmic models, a concern arises as to whether a system that displays a “deceptive” level of human-like engagement with users in our physical world ought to be uniquely protected. Although many voices in the legal and technology realms have continued to argue against unique protections for digital entities, the fact at hand is that SLAIS design is becoming increasingly anthropomorphic so as to make these systems more capable of interacting with a wide range of (potentially) vulnerable populations—generally as a means to enhance these populations’ overall well-being. To frame this concern in a different way, the specific question at hand is whether a human’s “ownership” of such an advanced SLAIS is legal , considering that it (or they) may possess intelligence on par with a human or a convincing-enough display of such behaviour. Given that “ownership” over entities with (seemingly) intelligent behaviours consistent with human populations has been effectively banned by the international community, an examination into this subject and its implications is wholly necessary given humanity’s quest to exist solely in digital environments through whatever means possible.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-021-01266-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01506-y,Falling Prediction based on Machine Learning for Biped Robots,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01506-y,Springer,2021-11-18,"Biped robots are expected to be able to work in complex environments. However, these robots will inevitably fall at times and such falls may cause injury to the robot itself or to people nearby. Therefore, it is necessary to detect that the robot is falling to be able to warn the robot in sufficient time when it is about to fall and to switch its controller to protect the vulnerable parts of the robot. Modeling and analysis of the biped robot falling problem cannot be fully accurate and many current learning-based methods rely on large quantities of fall data that are difficult to use to train fragile robots. A machine learning-based fall detection method is therefore proposed in this paper. This method requires only a small amount of training data to obtain good fall detection, making the training process on the robot platform much safer. A support vector machine is used to determine the state of the robot and the decision boundary of the stable state is updated during motion to enable the classifier to match the motion capability of the robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01506-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/s41598-021-01170-0,Remote drain inspection framework using the convolutional neural network and re-configurable robot Raptor,Scientific Reports,10.1038/s41598-021-01170-0,Nature,2021-11-17,"Drain blockage is a crucial problem in the urban environment. It heavily affects the ecosystem and human health. Hence, routine drain inspection is essential for urban environment. Manual drain inspection is a tedious task and prone to accidents and water-borne diseases. This work presents a drain inspection framework using convolutional neural network (CNN) based object detection algorithm and in house developed reconfigurable teleoperated robot called ‘Raptor’. The CNN based object detection model was trained using a transfer learning scheme with our custom drain-blocking objects data-set. The efficiency of the trained CNN algorithm and drain inspection robot Raptor was evaluated through various real-time drain inspection field trial. The experimental results indicate that our trained object detection algorithm has detect and classified the drain blocking objects with 91.42% accuracy for both offline and online test images and is able to process 18 frames per second (FPS). Further, the maneuverability of the robot was evaluated from various open and closed drain environment. The field trial results ensure that the robot maneuverability was stable, and its mapping and localization is also accurate in a complex drain environment.",https://www.nature.com/articles/s41598-021-01170-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-021-00830-5,Experience with an Affective Robot Assistant for Children with Hearing Disabilities,International Journal of Social Robotics,10.1007/s12369-021-00830-5,Springer,2021-11-16,"This study presents an assistive robotic system enhanced with emotion recognition capabilities for children with hearing disabilities. The system is designed and developed for the audiometry tests and rehabilitation of children in a clinical setting and includes a social humanoid robot (Pepper), an interactive interface, gamified audiometry tests, sensory setup and a machine/deep learning based emotion recognition module. Three scenarios involving conventional setup, tablet setup and setup with the robot+tablet are evaluated with 16 children having cochlear implant or hearing aid. Several machine learning techniques and deep learning models are used for the classification of the three test setups and for the classification of the emotions (pleasant, neutral, unpleasant) of children using the recorded physiological signals by E4 wristband. The results show that the collected signals during the tests can be separated successfully and the positive and negative emotions of children can be better distinguished when they interact with the robot than in the other two setups. In addition, the children’s objective and subjective evaluations as well as their impressions about the robot and its emotional behaviors are analyzed and discussed extensively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-021-00830-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-021-00822-5,Detecting Lies is a Child (Robot)’s Play: Gaze-Based Lie Detection in HRI,International Journal of Social Robotics,10.1007/s12369-021-00822-5,Springer,2021-11-16,"Robots destined to tasks like teaching or caregiving have to build a long-lasting social rapport with their human partners. This requires, from the robot side, to be capable of assessing whether the partner is trustworthy. To this aim a robot should be able to assess whether someone is lying or not, while preserving the pleasantness of the social interaction. We present an approach to promptly detect lies based on the pupil dilation, as intrinsic marker of the lie-associated cognitive load that can be applied in an ecological human–robot interaction, autonomously led by a robot. We demonstrated the validity of the approach with an experiment, in which the iCub humanoid robot engages the human partner by playing the role of a magician in a card game and detects in real-time the partner deceptive behavior. On top of that, we show how the robot can leverage on the gained knowledge about the deceptive behavior of each human partner, to better detect subsequent lies of that individual. Also, we explore whether machine learning models could improve lie detection performances for both known individuals (within-participants) over multiple interaction with the same partner, and with novel partners (between-participant). The proposed setup, interaction and models enable iCub to understand when its partners are lying, which is a fundamental skill for evaluating their trustworthiness and hence improving social human–robot interaction.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-021-00822-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-021-00821-6,Knowledge Engineering Framework for IoT Robotics Applied to Smart Healthcare and Emotional Well-Being,International Journal of Social Robotics,10.1007/s12369-021-00821-6,Springer,2021-11-16,"Social companion robots are getting more attention to assist elderly people to stay independent at home and to decrease their social isolation. When developing solutions, one remaining challenge is to design the right applications that are usable by elderly people. For this purpose, co-creation methodologies involving multiple stakeholders and a multidisciplinary researcher team (e.g., elderly people, medical professionals, and computer scientists such as roboticists or IoT engineers) are designed within the ACCRA (Agile Co-Creation of Robots for Ageing) project. This paper will address this research question: How can Internet of Robotic Things (IoRT) technology and co-creation methodologies help to design emotional-based robotic applications? This is supported by the ACCRA project that develops advanced social robots to support active and healthy ageing, co-created by various stakeholders such as ageing people and physicians. We demonstra this with three robots, Buddy, ASTRO, and RoboHon, used for daily life, mobility, and conversation. The three robots understand and convey emotions in real-time using the Internet of Things and Artificial Intelligence technologies (e.g., knowledge-based reasoning).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-021-00821-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-021-01278-x,Can we wrong a robot?,AI & SOCIETY,10.1007/s00146-021-01278-x,Springer,2021-11-12,"With the development of increasingly sophisticated sociable robots, robot-human relationships are being transformed. Not only can sociable robots furnish emotional support and companionship for humans, humans can also form relationships with robots that they value highly. It is natural to ask, do robots that stand in close relationships with us have any moral standing over and above their purely instrumental value as means to human ends. We might ask our question this way, ‘Are there ways we can act towards robots that would be wrong to the robot?’ To address this, Part I lays out standard approaches to moral standing: appealing to intrinsic properties, human responses, and values inhering in relationships. Part II explores the third, relational strategy in detail. Looking beyond Western analyses, it considers Eastern philosophy and the environmental philosophy of 'deep ecology' and extends these approaches to sociable robots. Part III examines practical implications for the case of Samantha, a sex robot that was allegedly raped. Part IV identifies and replies to objections.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-021-01278-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42452-021-04853-5,Roboethics principles and policies in Europe and North America,SN Applied Sciences,10.1007/s42452-021-04853-5,Nature,2021-11-07,"Robotics and artificial intelligence (AI) are revolutionizing all spheres of human life. From industrial processes to graphic design, the implementation of automated intelligent systems is changing how industries work. The spread of robots and AI systems has triggered academic institutions to closely examine how these technologies may affect the humanity—this is how the fields of roboethics and AI ethics have been born. The identification of ethical issues for robotics and AI and creation of ethical frameworks were the first steps to creating a regulatory environment for these technologies. In this paper, we focus on regulatory efforts in Europe and North America to create enforceable regulation for AI and robotics. We describe and compare ethical principles, policies, and regulations that have been proposed by government organizations for the design and use of robots and AI. We also discuss proposed international regulation for robotics and AI. This paper tries to highlight the need for a comprehensive, enforceable, and agile policy to ethically regulate technology today and in the future. Through reviewing existing policies, we conclude that the European Unition currently leads the way in defining roboethics and AI ethical principles and implementing them into policy. Our findings suggest that governments in Europe and North America are aware of the ethical risks that robotics and AI pose, and are engaged in policymaking to create regulatory policies for these new technologies.",https://www.nature.com/articles/s42452-021-04853-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10796-021-10218-5,Deep Reinforcement Learning-Based Robot Exploration for Constructing Map of Unknown Environment,Information Systems Frontiers,10.1007/s10796-021-10218-5,Springer,2021-11-06,"In traditional environment exploration algorithms, two problems are still waiting to be solved. One is that as the exploration time increases, the robot will repeatedly explore the areas that have been explored. The other is that in order to explore the environment more accurately, the robot will cause slight collisions during the exploration process. In order to solve the two problems, a DQN-based exploration model is proposed, which enables the robot to quickly find the unexplored area in an unknown environment, and designs a DQN-based navigation model to solve the local minima problem generated by the robot during the exploration. Through the switching mechanism of exploration model and navigation model, the robot can quickly complete the exploration task through selecting the modes according to the environment exploration situation. In the experiment results, the difference between the proposed unknown environment exploration method and the previous known-environment exploration methods research is less than 5% under the same exploration time. And in the proposed method, the robot can achieve zero collision and almost zero repeated exploration of the area when it has been trained for 30w rounds. Therefore, it can be seen that the proposed method is more practical than the previous methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10796-021-10218-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-021-00398-z,A survey on deep learning and deep reinforcement learning in robotics with a tutorial on deep reinforcement learning,Intelligent Service Robotics,10.1007/s11370-021-00398-z,Springer,2021-11-01,"This article is about deep learning (DL) and deep reinforcement learning (DRL) works applied to robotics. Both tools have been shown to be successful in delivering data-driven solutions for robotics tasks, as well as providing a natural way to develop an end-to-end pipeline from the robot’s sensing to its actuation, passing through the generation of a policy to perform the given task. These frameworks have been proven to be able to deal with real-world complications such as noise in sensing, imprecise actuation, variability in the scenarios where the robot is being deployed, among others. Following that vein, and given the growing interest in DL and DRL, the present work starts by providing a brief tutorial on deep reinforcement learning, where the goal is to understand the main concepts and approaches followed in the field. Later, the article describes the main, recent, and most promising approaches of DL and DRL in robotics, with sufficient technical detail to understand the core of the works and to motivate interested readers to initiate their own research in the area. Then, to provide a comparative analysis, we present several taxonomies in which the references can be classified, according to high-level features, the task that the work addresses, the type of system, and the learning techniques used in the work. We conclude by presenting promising research directions in both DL and DRL.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-021-00398-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42235-021-00104-w,Biomimetic Quadruped Robot with a Spinal Joint and Optimal Spinal Motion via Reinforcement Learning,Journal of Bionic Engineering,10.1007/s42235-021-00104-w,Springer,2021-11-01,"Feline animals can run quickly using spinal joints as well as the joints that make up their four legs. This paper describes the development of a quadruped robot including a spinal joint that biomimics feline animals. The developed robot platform consists of four legs with a double 4-bar linkage type and one simplified rotary joint. In addition, Q-learning, a type of machine learning, was used to find the optimal motion profile of the spinal joint. The bounding gait was implemented on the robot system using the motion profile of the spinal joint, and it was confirmed that using the spinal joint can achieve a faster Center of Mass (CoM) forward speed than not using the spinal joint. Although the motion profile obtained through Q-learning did not exactly match the spinal angle of a feline animal, which is more multiarticular than that of the developed robot, the tendency of the actual feline animal spinal motion profile, which is sinusoidal, was similar.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42235-021-00104-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11768-021-00069-5,Sequencing of multi-robot behaviors using reinforcement learning,Control Theory and Technology,10.1007/s11768-021-00069-5,Springer,2021-11-01,"Given a collection of parameterized multi-robot controllers associated with individual behaviors designed for particular tasks, this paper considers the problem of how to sequence and instantiate the behaviors for the purpose of completing a more complex, overarching mission. In addition, uncertainties about the environment or even the mission specifications may require the robots to learn, in a cooperative manner, how best to sequence the behaviors. In this paper, we approach this problem by using reinforcement learning to approximate the solution to the computationally intractable sequencing problem, combined with an online gradient descent approach to selecting the individual behavior parameters, while the transitions among behaviors are triggered automatically when the behaviors have reached a desired performance level relative to a task performance cost. To illustrate the effectiveness of the proposed method, it is implemented on a team of differential-drive robots for solving two different missions, namely, convoy protection and object manipulation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11768-021-00069-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-021-00762-0,Adaptive Control of Robot Series Elastic Drive Joint Based on Optimized Radial Basis Function Neural Network,International Journal of Social Robotics,10.1007/s12369-021-00762-0,Springer,2021-11-01,"For the social robot with serial elastic actuator, the joint dynamics model has the problems of strong coupling and high nonlinear, and the traditional PD control algorithm cannot achieve accurate trajectory tracking effect on the joint position of social robot using series elastic actuator. Therefore, an optimized Radial basis function (RBF) neural network adaptive control algorithm was proposed. The method based on RBF neural network approximates the social robot joint model parameters, an adaptive law was designed to estimate the weights of the neural network and the joint model online. The dynamic plane method is combined to improve the robustness of the control algorithm. The simulation results show that the trajectory tracking error peak of PD control algorithm is 0.2 rad. Compared with PD control algorithm, the trajectory tracking error peak of RBF neural network adaptive control algorithm based on dynamic surface optimization is reduced to ± 0.05 rad, which realizes accurate approximation of the parameters of social robot joint model, and accurate dynamics model approximation provides a theoretical basis for further research on human–robot interaction (HRI) of social robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-021-00762-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-021-00387-2,Reinforcement learning-based dynamic obstacle avoidance and integration of path planning,Intelligent Service Robotics,10.1007/s11370-021-00387-2,Springer,2021-11-01,"Deep reinforcement learning has the advantage of being able to encode fairly complex behaviors by collecting and learning empirical information. In the current study, we have proposed a framework for reinforcement learning in decentralized collision avoidance where each agent independently makes its decision without communication with others. In an environment exposed to various kinds of dynamic obstacles with irregular movements, mobile robot agents could learn how to avoid obstacles and reach a target point efficiently. Moreover, a path planner was integrated with the reinforcement learning-based obstacle avoidance to solve the problem of not finding a path in a specific situation, thereby imposing path efficiency. The robots were trained about the policy of obstacle avoidance in environments where dynamic characteristics were considered with soft actor critic algorithm. The trained policy was implemented in the robot operating system (ROS), tested in virtual and real environments for the differential drive wheel robot to prove the effectiveness of the proposed method. Videos are available at https://youtu.be/xxzoh1XbAl0 .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-021-00387-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-021-06068-6,Zeroing neural network for bound-constrained time-varying nonlinear equation solving and its application to mobile robot manipulators,Neural Computing and Applications,10.1007/s00521-021-06068-6,Springer,2021-11-01,"A typical class of recurrent neural networks called zeroing neural network (ZNN) has been considered as a powerful alternative for time-varying problems solving. In this paper, a new ZNN model is proposed and studied to solve the bound-constrained time-varying nonlinear equation (BCTVNE). Specifically, by introducing a time-varying nonnegative vector, the BCTVNE is reformulated as a combined system of nonlinear equations. On the basis of two indefinite error functions and the exponential decay formula, the new ZNN model is thus developed, which can zero in on the combined system. Theoretical analysis and simulation results are provided to verify the effectiveness of the proposed ZNN model. The applicability is further indicated under the simulations on an omnidirectional mobile robot manipulator via the proposed ZNN model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-021-06068-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-021-03768-7,An optimized hybrid deep learning model using ensemble learning approach for human walking activities recognition,The Journal of Supercomputing,10.1007/s11227-021-03768-7,Springer,2021-11-01,"Recent advancements in edge computing devices motivate us to develop a sustainable and reliable technique for multiple gait activities recognition using wearable sensors. This research work presents the multitask human walking activities recognition using human gait patterns. Human locomotion is defined as the change in the joint angles of hip, knee and ankle. To achieve the aforementioned objective, the data are collected for 50 subjects in a controlled laboratory environment using inertial measurement unit (IMU) sensors for 7 different activities. The IMU sensor is placed on the chest, left thigh, and right thigh. Total 100 samples are collected for all 7 activities. The sampling rate considered was 50 Hz. Following 7 walking activities are performed for all the 50 subjects: (i) natural walk, (ii) standing, (iii) climbing stairs, (iv) cycling, (v) jogging, (vi)running, (vii) knees bending(Crouching). The major contribution of this research paper is the design of four hybrid deep learning models to provide the generic activity recognition framework and tune the performance. The following combination of the deep learning model is designed for the classification of gait activities, namely, convolution neural network–long short-term memory (CNN–LSTM), CNN–gated recurrent unit (CNN–GRU), LSTM–CNN and LSTM–GRU. To support edge computing, the ensemble learning is utilized to optimized the model size. The proposed ensemble learning-based hybrid deep learning framework has provided a promising classification accuracy of 99.34% over other models. The other models namely CNN, LSTM, GRU, CNN–LSTM, LSTM–CNN, CNN–GRU, GRU–CNN have achieved 97.26%, 90.67%, 77.38%, 97.83%, 94.35%, 97.64%, 96.98% accuracy, respectively, on our HAG data set. The proposed technique is also validated on MHEALTH data set for comparative analysis. The hybrid deep learning model in combination with ensemble learning has outperformed other techniques. The optimized code can be used on small computation devices for walking activity recognition.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11227-021-03768-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43681-021-00064-1,Workplace automation without achievement gaps: a reply to Danaher and Nyholm,AI and Ethics,10.1007/s43681-021-00064-1,Springer,2021-11-01,"In a recent article in this journal, John Danaher and Sven Nyholm raise well-founded concerns that the advances in AI-based automation will threaten the values of meaningful work. In particular, they present a strong case for thinking that automation will undermine our achievements, thereby rendering our work less meaningful. It is also claimed that the threat to achievements in the workplace will open up ‘achievement gaps’—the flipside of the ‘responsibility gaps’ now commonly discussed in technology ethics. This claim, however, is far less worrisome than the general concerns for widespread automation, namely because it rests on several conceptual ambiguities. With this paper, I argue that although the threat to achievements in the workplace is problematic and calls for policy responses of the sort Danaher and Nyholm outline, when framed in terms of responsibility, there are no ‘achievement gaps’.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43681-021-00064-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/s41598-021-00557-3,Automated segmentation by deep learning of loose connective tissue fibers to define safe dissection planes in robot-assisted gastrectomy,Scientific Reports,10.1038/s41598-021-00557-3,Nature,2021-10-27,"The prediction of anatomical structures within the surgical field by artificial intelligence (AI) is expected to support surgeons’ experience and cognitive skills. We aimed to develop a deep-learning model to automatically segment loose connective tissue fibers (LCTFs) that define a safe dissection plane. The annotation was performed on video frames capturing a robot-assisted gastrectomy performed by trained surgeons. A deep-learning model based on U-net was developed to output segmentation results. Twenty randomly sampled frames were provided to evaluate model performance by comparing Recall and F1/Dice scores with a ground truth and with a two-item questionnaire on sensitivity and misrecognition that was completed by 20 surgeons. The model produced high Recall scores (mean 0.606, maximum 0.861). Mean F1/Dice scores reached 0.549 (range 0.335–0.691), showing acceptable spatial overlap of the objects. Surgeon evaluators gave a mean sensitivity score of 3.52 (with 88.0% assigning the highest score of 4; range 2.45–3.95). The mean misrecognition score was a low 0.14 (range 0–0.7), indicating very few acknowledged over-detection failures. Thus, AI can be trained to predict fine, difficult-to-discern anatomical structures at a level convincing to expert surgeons. This technology may help reduce adverse events by determining safe dissection planes.",https://www.nature.com/articles/s41598-021-00557-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13369-021-06245-8,Humanoid Robot Portrait Drawing Based on Deep Learning Techniques and Efficient Path Planning,Arabian Journal for Science and Engineering,10.1007/s13369-021-06245-8,Springer,2021-10-20,"This paper presents a complete robotic portrait drawing system. First, facial features are extracted robustly using deep learning-based approaches. Then an efficient path planning algorithm is proposed to draw the portrait. To extract facial features, it goes through the following steps: face detection, facial edge extraction, image synthesis and image binarization. Given the processed image, the robot maps the coordinates of the image pixels to the coordinates of the drawing board after calibration. Then drawing paths are planned. The path planning principle is that the robot tries to travel as minimum distance as possible. To evaluate the proposed system, the facial landmarks are extracted from both the reference image and the binary image output of our system. Point-to-point distances are calculated to measure the binary image quality. On the other hand, the drawing time of each individual portrait is saved for efficiency comparison.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13369-021-06245-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00170-021-08086-z,Learning and generalising object extraction skill for contact-rich disassembly tasks: an introductory study,The International Journal of Advanced Manufacturing Technology,10.1007/s00170-021-08086-z,Springer,2021-10-18,"Remanufacturing automation must be designed to be flexible and robust enough to overcome the uncertainties, conditions of the products, and complexities in the planning and operation of the processes. Machine learning methods, in particular reinforcement learning, are presented as techniques to learn, improve, and generalise the automation of many robotic manipulation tasks (most of them related to grasping, picking, or assembly). However, not much has been exploited in remanufacturing, in particular in disassembly tasks. This work presents the state of the art of contact-rich disassembly using reinforcement learning algorithms and a study about the generalisation of object extraction skills when applied to contact-rich disassembly tasks. The generalisation capabilities of two state-of-the-art reinforcement learning agents (trained in simulation) are tested and evaluated in simulation, and real world while perform a disassembly task. Results show that at least one of the agents can generalise the contact-rich extraction skill. Besides, this work identifies key concepts and gaps for the reinforcement learning algorithms’ research and application on disassembly tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00170-021-08086-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40430-021-03219-7,An intelligent hexapod robot for inspection of airframe components oriented by deep learning technique,Journal of the Brazilian Society of Mechanical Sciences and Engineering,10.1007/s40430-021-03219-7,Springer,2021-10-11,"The global competition in the manufacturing industry is becoming more and more aggressive each day. The technologies of Industry 4.0, based on the Internet of Things (IoT), have been pursued in Research and Development, manufacturing, and management processes. In this way, the research consolidated in this paper aims to extend the use of nature-inspired robots in aircraft manufacturing, exploiting the state-of-art technologies and their benefits for productive purposes. This research presents an integrated robotic solution for the inspection of fastened structural joints by a hexapod crawler robot, equipped with a vision sensor, embedded systems, managed by a deep learning algorithm and coordinated in the cloud that moves on the surface of an aircraft providing real-time monitoring via mobile devices. A case study regarding the inspection of airframe fasteners was carried out to demonstrate the application of the proposed solution, the developed method, and its tasks. The automation of the inspection process strives to increase efficiency, cost reduction, streamline ergonomics issues, and support aircraft fabricators. This novel proposal looks for an innovative application in the aeronautical sector based on state-of-art technology faced by intelligent manufacturing.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40430-021-03219-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10796-021-10207-8,Exploring the Attractiveness of Service Robots in the Hospitality Industry: Analysis of Online Reviews,Information Systems Frontiers,10.1007/s10796-021-10207-8,Springer,2021-10-09,"As the hospitality industry has begun adopting service robots to replace frontline human services, service robots’ attractiveness becomes a salient factor in their design and implementation. However, it is unclear what consist of service robots’ attractiveness and how they affect customer responses. This study examines the effects of multiple dimensions of service robots’ attractiveness on customers’ emotions using a text mining approach. For the data analysis, we collected 50,629 online reviews on 59 hotels and restaurants using service robots from the largest social commerce platform in China. Using the Linguistic Inquiry and Word Count (LIWC) method, we analyzed 7570 online reviews that are directly related to service robots. With the LIWC outcomes, the relationships between the attractiveness dimensions and customer emotions were investigated. Based on our findings, finally, we provide propositions for understanding the attractiveness of service robots. The theoretical and practical implications of the findings are discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10796-021-10207-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-021-01299-6,Artificial intelligence in fiction: between narratives and metaphors,AI & SOCIETY,10.1007/s00146-021-01299-6,Springer,2021-10-05,"Science-fiction (SF) has become a reference point in the discourse on the ethics and risks surrounding artificial intelligence (AI). Thus, AI in SF—science-fictional AI—is considered part of a larger corpus of ‘AI narratives’ that are analysed as shaping the fears and hopes of the technology. SF, however, is not a foresight or technology assessment, but tells dramas for a human audience. To make the drama work, AI is often portrayed as human-like or autonomous, regardless of the actual technological limitations. Taking science-fictional AI too literally, and even applying it to science communication, paints a distorted image of the technology's current potential and distracts from the real-world implications and risks of AI. These risks are not about humanoid robots or conscious machines, but about the scoring, nudging, discrimination, exploitation, and surveillance of humans by AI technologies through governments and corporations. AI in SF, on the other hand, is a trope as part of a genre-specific mega-text that is better understood as a dramatic means and metaphor to reflect on the human condition and socio-political issues beyond technology.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-021-01299-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43681-021-00104-w,Identifying key ethical debates for autonomous robots in agri-food: a research agenda,AI and Ethics,10.1007/s43681-021-00104-w,Springer,2021-10-04,"Agribusinesses are investing in different forms of AI robots, as there is a lot of hope that these machines will help meet the challenges within the agricultural industry, which is to efficiently produce more food for a growing world population. AI robots are expected to enhance production, while compensating for lack of manpower, reducing production costs, taking over unattractive (risky, heavy, and dirty) jobs and reducing the burden of food production on the environment. In spite of these promises, however, AI robots for agri-food also give rise to ethical questions and concerns, which have been little researched and discussed until now. To fill this gap, we developed a research agenda for future research in this area. To do this, we opened our analysis to focus on ethics AI robots generally to specifically identify which of these issues are most relevant to agro-robots. The question we want to find an answer to is: what are the most relevant ethical questions raised about AI robots for robots developed for the agri-food sector? And which questions are not mentioned in the literature, which are particularly relevant for agro-robots? Our paper will provide an overview over the key issues and areas which deserve further elaboration to come to a more mature ethics of AI agro-robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43681-021-00104-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-021-03487-0,BCI-based hit-loop agent for human and AI robot co-learning with AIoT application,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-021-03487-0,Springer,2021-10-02,"In this paper, we propose a brain–computer interface (BCI)-based Human-in-the-Loop (Hit-Loop) agent for human and artificial intelligence (AI) colearning in music listening and appreciation with an Artificial Intelligence of Things (AIoT) application. The novel BCI-based Hit-Loop agent contains human intelligence with BCI-based AIoT-Fuzzy Markup Language (FML) and BCI-FML agents , as well as machine intelligence with AI-FML Hit-Loop and AIoT-FML agents . We used FML to facilitate communication between humans and the AI-FML robots through an AIoT-FML Learning Tool ( AIoT-FML-LT ), which was the core technology of the AI-FML Hit-Loop agent for the BCI-based music listening and appreciation application. Furthermore, the novel AIoT-FML-LT in conjunction with the BCI-FML and AIoT-FML agents was developed and presented for music listening and student learning. Moreover, the BCI-based AIoT-FML and AI-FML Hit-Loop agents were applied in English language learning, and the AIoT-FML-LT assisted in measuring student learning performance in Taiwan and Japan. The human-like high-level knowledge base and rule base were constructed by various domain experts, as well as the personalized electroencephalography (EEG) and student English learning data sets collected using the BCI device and AIoT-FML-LT , respectively, and were applied to machine learning models such as deep learning and particle swarm optimization. Additionally, the AIoT-FML-LT was connected to the AIoT-FML Hit-Loop agent for human and robot colearning. The relationship between human perceptions and the AIoT-FML Hit-Loop agent in terms of eyes , ears , nose , tongue , body , and brain corresponding to sights , sounds , smells , tastes , objects of touch , and mind are discussed. Finally, the students learned human language and AI language by using the AI-FML robots and AIoT-FML-LT together with the human English learning and AI-FML machine learning models, respectively. The experimental results reveal that the BCI-based Hit-Loop agent for human and AI-FML robot colearning in conjunction with AIoT applications can effectively facilitate music listening and appreciation application as well as English listening in Taiwan and Japan. The learning behavior and performance of the students also improved after incorporation of the human and robot colearning model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-021-03487-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-021-06190-6,A full freedom pose measurement method for industrial robot based on reinforcement learning algorithm,Soft Computing,10.1007/s00500-021-06190-6,Springer,2021-10-01,"In this current era, the field of robotics has made much advancement and has also produced novelties than any other advanced research areas. The usage of robots has become an imperative part of the defense-oriented applications. The missions which are difficult to be performed by human beings can certainly be accomplished by the robots nowadays. The most crucial part for an industrial- and defense-based robot is to perform pose movements accurately for optimal usage of robotics as a replacement of human beings. This paper proposes a comprehensive introduction to the proposed hybrid approach PSO–RL which uses reinforcement learning (RL) and Particle swarm optimization (PSO). It summarizes the usage of proposed PSO-RL for pose measurement of robots in defense and industrial manufacturing systems. The hybrid PSO–RL is a promising technique for measuring poses in robots with accuracy and for optimizing obstacle avoidance error. In this paper, robot’s core movements are analyzed; speed of movements is given importance, and an attempt is made to provide more accurate moves with high precision. In order to optimize the efficiency of robotic operations, a full freedom pose measurement method based on PSO–RL is proposed. By using the characteristics of two-wheel independent driving industrial robot, the performance of the robot in three moving modes is evaluated. The experimental results show that the proposed PSO-RL method has the advantages of high accuracy, high measurement efficiency, high success rate of grabbing and avoiding obstacles. It outperforms the existing methods such as least square method and micro-displacement cyclic correction method with respect to maximum error, RMSE score and time complexity.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-021-06190-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11063-021-10516-8,A faster and better robustness zeroing neural network for solving dynamic Sylvester equation,Neural Processing Letters,10.1007/s11063-021-10516-8,Springer,2021-10-01,"In this paper, a new zeroing neural network (NZNN) with a new activation function (AF) is presented and investigated for solving dynamic Sylvester equation (DSE). The proposed NZNN not only finds the solutions of the DSE in fixed-time but also has better robustness, and its superior effectiveness and robustness are proved by rigorous mathematical analysis. Numerical simulation results of the proposed NZNN, the original zeroing neural network activated by other recently reported AFs and the existing robust nonlinear ZNN (RNZNN) for solving second-order dynamic Sylvester equation and third-order dynamic Sylvester equation are provided for the purpose of comparison. Comparing with the existing ZNN models, the proposed NZNN has better robustness and faster convergence performance for solving DSE in the same noise environment. Moreover, a successful robot manipulator trajectory tracking example in noise-disturbed environment using the proposed NZNN is also applied for illustrating its further practical applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-021-10516-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11063-020-10311-x,Knowledge Acquisition and Design Using Semantics and Perception: A Case Study for Autonomous Robots,Neural Processing Letters,10.1007/s11063-020-10311-x,Springer,2021-10-01,"The pervasive use of artificial intelligence and neural networks in several different research fields has noticeably improved multiple aspects of human life. The application of these techniques to machines has made them progressively more “intelligent” and able to solve tasks considered extremely complex for a human being. This technological evolution has deeply influenced the way we interact with machines. Purely symbolic artificial intelligence and techniques like ontologies, have also been successfully used in the past applied to robotics, but have also shown some limitations and failings in the knowledge construction task. In fact, the exhibited “intelligence” is rarely the result of a real autonomous decision, but it is rather hard-encoded in the machine. While a number of approaches have already been proposed in literature concerning knowledge acquisition from the surrounding environment, they are either exclusively based on low-level features or they involve solely high-level semantics-based attributes. Moreover, they often don’t use a general high-level knowledge base for grounding the acquired knowledge. In this contexts, the use of semantics technologies, such as ontologies, is mostly employed for action-oriented tasks. In this article we propose an extension of a novel approach for knowledge acquisition based on a general semantic knowledge-base and the fusion of semantics and visual information by means of neural networks and ontologies. The proposed approach has been implemented on a humanoid robotic platform and the experimental results are shown and discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-020-10311-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40747-021-00522-7,A peduncle detection method of tomato for autonomous harvesting,Complex & Intelligent Systems,10.1007/s40747-021-00522-7,Springer,2021-09-28,"For automating the harvesting of bunches of tomatoes in a greenhouse, the end-effector needs to reach the exact cutting point and adaptively adjust the pose of peduncles. In this paper, a method is proposed for peduncle cutting point localization and pose estimation. Images captured in real time at a fixed long-distance are detected using the YOLOv4-Tiny detector with a precision of 92.7% and a detection speed of 0.0091 s per frame, then the YOLACT +  + Network with mAP of 73.1 and a time speed of 0.109 s per frame is used to segment the close-up distance. The segmented peduncle mask is fitted to the curve using least squares and three key points on the curve are found. Finally, a geometric model is established to estimate the pose of the peduncle with an average error of 4.98° in yaw angle and 4.75° in pitch angle over the 30 sets of tests.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40747-021-00522-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43681-021-00091-y,Coarse ethics: how to ethically assess explainable artificial intelligence,AI and Ethics,10.1007/s43681-021-00091-y,Springer,2021-09-12,"The integration of artificial intelligence (AI) into human society mandates that their decision-making process is explicable to users, as exemplified in Asimov’s Three Laws of Robotics. Such human interpretability calls for explainable AI (XAI), of which this paper cites various models. However, the transaction between computable accuracy and human interpretability can be a trade-off, requiring answers to questions about the negotiable conditions and the degrees of AI prediction accuracy that may be sacrificed to enable user-interpretability. The extant research has focussed on technical issues, but it is also desirable to apply a branch of ethics to deal with the trade-off problem. This scholarly domain is labelled coarse ethics in this study, which discusses two issues vis-à-vis AI prediction as a type of evaluation. First, which formal conditions would allow trade-offs? The study posits two minimal requisites: adequately high coverage and order-preservation. The second issue concerns conditions that could justify the trade-off between computable accuracy and human interpretability, to which the study suggests two justification methods: impracticability and adjustment of perspective from machine-computable to human-interpretable. This study contributes by connecting ethics to autonomous systems for future regulation by formally assessing the adequacy of AI rationales.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43681-021-00091-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01459-2,ROSI: A Robotic System for Harsh Outdoor Industrial Inspection - System Design and Applications,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01459-2,Springer,2021-09-11,"Belt Conveyors are essential for transporting dry bulk material in different industries. Such structures require permanent inspections, traditionally executed by human operators based on cognition. To improve working conditions and process standardization, we propose a novel procedure to inspect conveyor structures with a ground robot composed by a mobile platform, a robotic arm, and a sensor-set. Based on field experience, we introduce ROSI, a new robotic device designed for long-term operations in harsh outdoor environments. The mobile robot has a hybrid locomotion system, using wheels to reduce energy consumption while covering long distances, and also flippers with tracks to improve mobility during obstacle negotiation. A mechanical passive switch allows decoupling tracks’ traction, reducing components wear and energy consumption without raising mechanical complexity. Aiming the robot-assisted operation, control strategies help to (i) command both the mobile platform and a robotic manipulator considering the system whole-body model, (ii) adjust the contact force for touching the conveyor structure during vibration inspection, and (iii) climb stairs while automatically adjusting the flippers. Machine Learning algorithms detect conveyors’ dirt build-ups, roller failures, and bearing faults by processing visual, thermal and sound data as inspection functionalities. The algorithms training and validation use a dataset collected from running conveyors at Vale, presenting detection accuracy superior to 90%. Field test results in a mining site demonstrate the robot capabilities to stand for the harsh operating conditions while executing all the required inspection tasks, stating ROSI as a disruptive solution for Belt Conveyor inspections and other general industrial operations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01459-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11948-021-00336-3,Implementing Ethics in Healthcare AI-Based Applications: A Scoping Review,Science and Engineering Ethics,10.1007/s11948-021-00336-3,Springer,2021-09-03,"A number of Artificial Intelligence (AI) ethics frameworks have been published in the last 6 years in response to the growing concerns posed by the adoption of AI in different sectors, including healthcare. While there is a strong culture of medical ethics in healthcare applications, AI-based Healthcare Applications (AIHA) are challenging the existing ethics and regulatory frameworks. This scoping review explores how ethics frameworks have been implemented in AIHA, how these implementations have been evaluated and whether they have been successful. AI specific ethics frameworks in healthcare appear to have a limited adoption and they are mostly used in conjunction with other ethics frameworks. The operationalisation of ethics frameworks is a complex endeavour with challenges at different levels: ethics principles, design, technology, organisational, and regulatory. Strategies identified in this review are proactive, contextual, technological, checklist, organisational and/or evidence-based approaches. While interdisciplinary approaches show promises, how an ethics framework is implemented in an AI-based Healthcare Application is not widely reported, and there is a need for transparency for trustworthy AI.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-021-00336-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10994-021-06006-6,Air Learning: a deep reinforcement learning gym for autonomous aerial robot visual navigation,Machine Learning,10.1007/s10994-021-06006-6,Springer,2021-09-01,"We introduce Air Learning, an open-source simulator, and a gym environment for deep reinforcement learning research on resource-constrained aerial robots. Equipped with domain randomization, Air Learning exposes a UAV agent to a diverse set of challenging scenarios. We seed the toolset with point-to-point obstacle avoidance tasks in three different environments and Deep Q Networks (DQN) and Proximal Policy Optimization (PPO) trainers. Air Learning assesses the policies’ performance under various quality-of-flight (QoF) metrics, such as the energy consumed, endurance, and the average trajectory length, on resource-constrained embedded platforms like a Raspberry Pi. We find that the trajectories on an embedded Ras-Pi are vastly different from those predicted on a high-end desktop system, resulting in up to $$40\%$$ 40 % longer trajectories in one of the environments. To understand the source of such discrepancies, we use Air Learning to artificially degrade high-end desktop performance to mimic what happens on a low-end embedded system. We then propose a mitigation technique that uses the hardware-in-the-loop to determine the latency distribution of running the policy on the target platform (onboard compute on aerial robot). A randomly sampled latency from the latency distribution is then added as an artificial delay within the training loop. Training the policy with artificial delays allows us to minimize the hardware gap (discrepancy in the flight time metric reduced from 37.73% to 0.5%). Thus, Air Learning with hardware-in-the-loop characterizes those differences and exposes how the onboard compute’s choice affects the aerial robot’s performance. We also conduct reliability studies to assess the effect of sensor failures on the learned policies. All put together, Air Learning enables a broad class of deep RL research on UAVs. The source code is available at:  https://github.com/harvard-edge/AirLearning .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10994-021-06006-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00264-021-05175-2,"Digital twins, artificial intelligence, and machine learning technology to identify a real personalized motion axis of the tibiotalar joint for robotics in total ankle arthroplasty",International Orthopaedics,10.1007/s00264-021-05175-2,Springer,2021-09-01,"Purpose Axial alignment of the talar implant in total ankle arthroplasty remains a major issue, since the real axis of motion of each patient is impossible to determine with usual techniques. Further knowledge regarding individual axis of motion of the ankle is therefore needed. Material and methods Therefore, digital twins, artificial intelligence, and machine learning technology were used to identify a real personalized motion axis of the tibiotalar joint. Three-dimensional (3D) models of distal extremities were generated using computed tomography data of normal patients. Digital twins were used to reproduce the mobility of the ankles, and the real ankle of the patients was matched to the digital twin with machine learning technology. Results The results showed that a personalized axis can be obtained for each patient. When the origin of the axis is the centre of mass of the talus, this axis can be represented in a geodesic system. The mean value of the axis is a line passing in first approximation through the centre of the sphere (with a variation of 3 mm from the centre of the mass of the talus) and through a point with the coordinates 91.6° west and 7.4° north (range 84° to 98° west; − 2° to 12° north). This study improves the understanding of the axis of the ankle, as well as its relationship to the possibility to use the geodesic system for robotic in ankle arthroplasty. Conclusion The consideration of a personalized axis of the ankle might be helpful for better understanding of ankle surgery and particularly total ankle arthroplasty.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00264-021-05175-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11023-021-09561-y,Value Sensitive Design to Achieve the UN SDGs with AI: A Case of Elderly Care Robots,Minds and Machines,10.1007/s11023-021-09561-y,Springer,2021-09-01,"Healthcare is becoming increasingly automated with the development and deployment of care robots. There are many benefits to care robots but they also pose many challenging ethical issues. This paper takes care robots for the elderly as the subject of analysis, building on previous literature in the domain of the ethics and design of care robots. Using the value sensitive design (VSD) approach to technology design, this paper extends its application to care robots by integrating the values of care, values that are specific to AI, and higher-scale values such as the United Nations Sustainable Development Goals (SDGs). The ethical issues specific to care robots for the elderly are discussed at length alongside examples of specific design requirements that work to ameliorate these ethical concerns.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11023-021-09561-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-021-00494-z,"Artificial intelligence (AI) and robotics in travel, hospitality and leisure",Electronic Markets,10.1007/s12525-021-00494-z,Springer,2021-09-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12525-021-00494-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-020-00439-y,Challenges in re-designing operations and jobs to embody AI and robotics in services. Findings from a case in the hospitality industry,Electronic Markets,10.1007/s12525-020-00439-y,Springer,2021-09-01,"The adoption of artificial intelligence (AI) and service robots in the tourism industry for frontline service automation is generating a growing interest. Although there is a fairly large body of literature about this research field, the impacts on the service encounter need to be further investigated. The paper presents an action research project that led to employ the humanoid robot “Pepper”, equipped with a supervised machine-learning AI system, at the reception of an Italian hotel to provide information to clients. This allowed to explore the role played by this agent and the effects on the changing role taken by frontline employees (FLE) and customers. Findings show that this technology can act as an augmentation force and that FLEs’ role can evolve mainly into that of enabler - of the customers and of technology -, innovator and coordinator, while customers may take above all the role of enabler of the technology. The study also contributes to introduce the new role of “AI supervisor” among FLEs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12525-020-00439-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-020-00712-2,Performing the Kick During Walking for RoboCup 3D Soccer Simulation League Using Reinforcement Learning Algorithm,International Journal of Social Robotics,10.1007/s12369-020-00712-2,Springer,2021-09-01,"Nowadays, humanoid soccer serves as a benchmark for artificial intelligence and robotic problems. The factors such as the kicking speed and the number of kicks by robot soccer players are the most significant aims that the participating teams are pursued in the RoboCup 3D Soccer Simulation League. The proposed method presents a kicking strategy during walking for humanoid soccer robots. Achieving an accurate and powerful kicking while robots are moving requires a dynamic optimization of the speed and motion parameters of the robot. In this paper, a curved motion path has been designed based on the robot position relative to the ball and the goal. Ultimately, the robot will be able to kick at the goal by walking along this curve path. The speed and angle of the walking robot are set towards the ball with regard to the robots curved motion path. After the final step of the robot, the accurate and effective adjustment of these two parameters ensures that the robot is located in the ideal position to perform the perfect kick. Due to the noise and walking condition of the robot, it is essential that the speed and angle of motion to be measured more accurately. For this purpose, we use a reinforcement learning model to adjust the robots step size and so does achieve the optimal value of two abovementioned parameters. Using reinforcement learning, robot would learn to pursue an optimal policy to correctly kick towards designated points. Therefore, the proposed method is a model-free and based on dynamic programming. The experiments reveal that the proposed method has significantly improved the team overall performance and robots ability to kick. Our proposed method has been 9.32% successful on average and outperformed the UTAustinVilla agent in terms of goal-scoring time in a non-opponent simulator.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-020-00712-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-020-00443-2,AI and robotics in the European restaurant sector: Assessing potentials for process innovation in a high-contact service industry,Electronic Markets,10.1007/s12525-020-00443-2,Springer,2021-09-01,"The restaurant technology market is rapidly evolving and is transforming the restaurant business as a significant sector of tourism and hospitality. Enabled by artificial intelligence (AI), mobile apps, kiosks and chatbots revolutionize the guest experience and robots automate restaurant operations. Despite the increasing interest, the use of AI and robotics in restaurants is still in its early stage and restaurant managers are seeking guidance to leverage these technologies for service excellence. In this high-contact service sector, emotional skills need to be balanced with the possible automation potentials. The present research analyzes the current state of AI and robotics in the restaurant sector and proposes a systematic identification of process innovation potentials. For this purpose, a market analysis of the European AI and robotics market for restaurant operations is conducted, which yields a first knowledge base for future research and conceptual work. Besides detailed empirical data, a reference process is developed for leveraging new technologies for process innovation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12525-020-00443-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-020-00442-3,The adoption of artificial intelligence and robotics in the hotel industry: prospects and challenges,Electronic Markets,10.1007/s12525-020-00442-3,Springer,2021-09-01,"The growth of technology has resulted in the use of state-of-the-art systems such as artificial intelligence (AI) and robot-based applications and services in the hotel industry. Recently, there has been some discussion on the adoption of such technologies and their impact on hotels’ operational costs as well as the quality of service to customers. Considering the importance of these new technologies, this paper investigates the trend related to the adoption of AI and robotics in the hotel industry. For this purpose, we interviewed senior hotel asset managers using an in-depth case study method. The context is Dubai-based hotels as Dubai is already established as one of the premier smart cities of the world (Khan et al., 2017 ). The TOE framework was used, and three domains were investigated: technology, organization, and environment to expose the underlying factors effecting AI adoption. The findings expose the factors that influence the adoption of AI and robotics in hotels. This study is one of early attempts to investigate the full spectrum of AI in relation to the hotel industry while detailing how its adoption could be effectuated.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12525-020-00442-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-020-01123-7,"Where is the human got to go? Artificial intelligence, machine learning, big data, digitalisation, and human–robot interaction in Industry 4.0 and 5.0",AI & SOCIETY,10.1007/s00146-020-01123-7,Springer,2021-09-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-020-01123-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-020-01089-6,Making moral machines: why we need artificial moral agents,AI & SOCIETY,10.1007/s00146-020-01089-6,Springer,2021-09-01,"As robots and Artificial Intelligences become more enmeshed in rich social contexts, it seems inevitable that we will have to make them into moral machines equipped with moral skills. Apart from the technical difficulties of how we could achieve this goal, we can also ask the ethical question of whether we should seek to create such Artificial Moral Agents (AMAs). Recently, several papers have argued that we have strong reasons not to develop AMAs. In response, we develop a comprehensive analysis of the relevant arguments for and against creating AMAs, and we argue that all things considered we have strong reasons to continue to responsibly develop AMAs. The key contributions of this paper are threefold. First, to provide the first comprehensive response to the important arguments made against AMAs by Wynsberghe and Robbins (in “Critiquing the Reasons for Making Artificial Moral Agents”, Science and Engineering Ethics 25, 2019) and to introduce several novel lines of argument in the process. Second, to collate and thematise for the first time the key arguments for and against AMAs in a single paper. Third, to recast the debate away from blanket arguments for or against AMAs in general, to a more nuanced discussion about the use of what sort of AMAs, in what sort of contexts, and for what sort of purposes is morally appropriate.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-020-01089-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-020-00724-y,A Systematic Review for Service Humanoid Robotics Model in Hospitality,International Journal of Social Robotics,10.1007/s12369-020-00724-y,Springer,2021-09-01,"Nowadays, the Fourth Industrial Revolution has brought artificial intelligence to the forefront, and more and more intelligent robots begin to be used in the hospitality industry. In this study, the application of service humanoid robots in the hospitality industry is investigated based on Cardiff Metropolitan University EUREKA Robotics Lab’s robot as reported by Lab (in Eureka robotics lab, 2017, https://www.cardiffmet.ac.uk/technologies/Pages/EUREKA-Robotics-Lab.aspx ). The research ontology of this study is post-positivism. The research philosophy of this research is phenomenology. Phenomenological studies have indicated that this phenomenon can only be truly understood and experienced through subjective immersive research directly involving researchers, and the interaction among researchers is an integral part of the research. In this study, the data are collated through case researches and experimental interviews. Finally, Some proposals for transforming the traditional hospitality industry into the direction of intelligence is summarized. In future research, a technical model combining artificial intelligence will be further developed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-020-00724-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00464-021-08509-8,A learning robot for cognitive camera control in minimally invasive surgery,Surgical Endoscopy,10.1007/s00464-021-08509-8,Springer,2021-09-01,"Background We demonstrate the first self-learning, context-sensitive, autonomous camera-guiding robot applicable to minimally invasive surgery. The majority of surgical robots nowadays are telemanipulators without autonomous capabilities. Autonomous systems have been developed for laparoscopic camera guidance, however following simple rules and not adapting their behavior to specific tasks, procedures, or surgeons. Methods The herein presented methodology allows different robot kinematics to perceive their environment, interpret it according to a knowledge base and perform context-aware actions. For training, twenty operations were conducted with human camera guidance by a single surgeon. Subsequently, we experimentally evaluated the cognitive robotic camera control. A VIKY EP system and a KUKA LWR 4 robot were trained on data from manual camera guidance after completion of the surgeon’s learning curve. Second, only data from VIKY EP were used to train the LWR and finally data from training with the LWR were used to re-train the LWR. Results The duration of each operation decreased with the robot’s increasing experience from 1704 s ± 244 s to 1406 s ± 112 s, and 1197 s. Camera guidance quality (good/neutral/poor) improved from 38.6/53.4/7.9 to 49.4/46.3/4.1% and 56.2/41.0/2.8%. Conclusions The cognitive camera robot improved its performance with experience, laying the foundation for a new generation of cognitive surgical robots that adapt to a surgeon’s needs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00464-021-08509-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-021-01226-9,"Pasquale, Frank. New Laws of Robotics: Defending Human Expertise in the Age of AI. Cambridge, Massachusetts: The Belknap Press of Harvard University Press, 2020",AI & SOCIETY,10.1007/s00146-021-01226-9,Springer,2021-09-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-021-01226-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10994-021-05982-z,Grounded action transformation for sim-to-real reinforcement learning,Machine Learning,10.1007/s10994-021-05982-z,Springer,2021-09-01,"Reinforcement learning in simulation is a promising alternative to the prohibitive sample cost of reinforcement learning in the physical world. Unfortunately, policies learned in simulation often perform worse than hand-coded policies when applied on the target, physical system. Grounded simulation learning ( gsl ) is a general framework that promises to address this issue by altering the simulator to better match the real world (Farchy et al. 2013 in Proceedings of the 12th international conference on autonomous agents and multiagent systems (AAMAS)). This article introduces a new algorithm for gsl —Grounded Action Transformation (GAT)—and applies it to learning control policies for a humanoid robot. We evaluate our algorithm in controlled experiments where we show it to allow policies learned in simulation to transfer to the real world. We then apply our algorithm to learning a fast bipedal walk on a humanoid robot and demonstrate a 43.27% improvement in forward walk velocity compared to a state-of-the art hand-coded walk. This striking empirical success notwithstanding, further empirical analysis shows that gat may struggle when the real world has stochastic state transitions. To address this limitation we generalize gat to the stochastic gat ( sgat ) algorithm and empirically show that sgat leads to successful real world transfer in situations where gat may fail to find a good policy. Our results contribute to a deeper understanding of grounded simulation learning and demonstrate its effectiveness for applying reinforcement learning to learn robot control policies entirely in simulation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10994-021-05982-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-020-01119-3,Artificial intelligence and responsibility,AI & SOCIETY,10.1007/s00146-020-01119-3,Springer,2021-09-01,"In the debate on whether to ban LAWS, moral arguments are mainly used. One of these arguments, proposed by Sparrow, is that the use of LAWS goes hand in hand with the responsibility gap. Together with the premise that the ability to hold someone responsible is a necessary condition for the admissibility of an act, Sparrow believes that this leads to the conclusion that LAWS should be prohibited. In this article, it will be shown that Sparrow’s argumentation for both premises is not convincing. If one interprets the thesis that responsibility (first premise) is necessary in a descriptive sense, this assertion clashes with military theory and practice. And even if you focus on the normative interpretation, that claim does not stand. The second premise for Sparrow’s conclusion, namely that you cannot hold anyone responsible for LAWS’ (mis)deeds, is based on the idea that control is a necessary condition for responsibility. It will be shown that this idea too is not correct, which means that Sparrow’s control argument does not do the work it should do. From this, we can conclude that Sparrow’s justification for his claim that LAWS should be banned is insufficient, and neither can we conclude that the thesis of a responsibility gap has in any case been undermined. However, it will also be argued that someone may be responsible for the actions of LAWS, or that it cannot be excluded that one can be held responsible.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-020-01119-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-020-00434-3,Man vs machine: examining the three themes of service robotics in tourism and hospitality,Electronic Markets,10.1007/s12525-020-00434-3,Springer,2021-09-01,"There is a growing need in the tourism and hospitality literature to harmonise service robots and artificial intelligence’s (AI) meaning and foundations, while also offering guidance on future discussions and research. We operationalize MacInnis’ Journal of Marketing, 75 (4), 136–154, ( 2011 ) conceptual contribution to derive insights regarding service robots in the tourism and hospitality domain. This paper adopts an interdisciplinary stance and integrates insights from the tourism, hospitality, philosophy, psychology, sociology, management, robotics, information technology and marketing fields. Service robotics and related tourism and hospitality research follow three basic themes: deployment, acceptance and ethical considerations. The findings on the use of service robotics are subsequently delineated and a summary of the tourism and hospitality field’s current research needs is provided.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12525-020-00434-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13347-020-00414-7,There Is No Techno-Responsibility Gap,Philosophy & Technology,10.1007/s13347-020-00414-7,Springer,2021-09-01,"In a landmark essay, Andreas Matthias claimed that current developments in autonomous, artificially intelligent (AI) systems are creating a so-called responsibility gap, which is allegedly ever-widening and stands to undermine both the moral and legal frameworks of our society. But how severe is the threat posed by emerging technologies? In fact, a great number of authors have indicated that the fear is thoroughly instilled. The most pessimistic are calling for a drastic scaling-back or complete moratorium on AI systems, while the optimists aim to show that the gap can be bridged nonetheless. Contrary to both camps, I argue against the prevailing assumption that there is a technology-based responsibility gap. I show how moral responsibility is a dynamic and flexible process, one that can effectively encompass emerging technological entities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13347-020-00414-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-021-00819-0,Dynamic Iranian Sign Language Recognition Using an Optimized Deep Neural Network: An Implementation via a Robotic-Based Architecture,International Journal of Social Robotics,10.1007/s12369-021-00819-0,Springer,2021-08-29,"Sign language is a non-verbal communication tool used by the deaf. A robust sign language recognition framework is needed to develop Human–Robot Interaction (HRI) platforms that are able to interact with humans via sign language. Iranian sign language (ISL) is composed of both static postures and dynamic gestures of the hand and fingers. In this paper, we present a robust framework using a Deep Neural Network (DNN) to recognize dynamic ISL gestures captured by motion capture gloves in Real-Time. To this end, first, a dataset of fifteen ISL classes was collected in time series; then, this dataset was virtually augmented and pre-processed using the “state-image” method to produce a unique collection of images, each image corresponding to a specific set of sequential data representing a class. Next, by implementing a continuous Genetic algorithm, an optimal deep neural network with the minimum number of weights (trainable parameters) and the maximum overall accuracy was found. Finally, the dataset was fed to the DNN to train the model. The results showed that the optimization process was successful at finding a DNN structure highly suitable for this application, with 99.7% accuracy on the verification (test) data. Then, after implementing the module in a robotic architecture, an HRI experiment was conducted to assess the system’s performance in real-time applications. Preliminary statistical analysis on the standard UTAUT model for eight participants showed that the system can recognize ISL signs quickly and accurately during human–robot interaction. The proposed methodology can be used for other sign languages as no specific characteristics of ISL were used in the preprocessing or training stage.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-021-00819-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40747-021-00499-3,Hybrid type multi-robot path planning of a serial manipulator and SwarmItFIX robots in sheet metal milling process,Complex & Intelligent Systems,10.1007/s40747-021-00499-3,Springer,2021-08-28,"This work investigates on the coordinated locomotion between a ceiling-mounted serial manipulator and two SwarmItFIX robots. The former holds the machining tool as an end effector, and the other two robots act as swarm robotic fixtures in a sheet metal milling process. A novel offline coordination planner which follows the hierarchical based hybrid type decentralized planning strategy has been proposed. Motion of the serial manipulator and SwarmItFIX robots’ coordinated locomotion are divided into three sub-problems, viz, trajectory planning of serial manipulator, task planning of SwarmItFIX robots, and homogenous prioritized multi-robot path planning of SwarmItFIX robots. Mathematical formulation of all the three sub-problems is developed and presented in this paper. A hexagonal segment that fits inside the boundaries of the workspace is considered as the machining trajectory. The tool velocity is assumed to be constant as it improves the quality of machining. The results obtained from the proposed planner is found to be efficient as the task planning module has computed the precise support locations and support duration for the SwarmItFIX robots. The multi-robot path planning module of the planner computes the optimal collision-free paths of SwarmItFIX robots for all goal positions. Finally, trajectories of SwarmItFIX robots are found to be completely in-line with the trajectory of tool center point (TCP) of the serial manipulator.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40747-021-00499-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40430-021-03157-4,Task-space impedance control of a parallel Delta robot using dual quaternions and a neural network,Journal of the Brazilian Society of Mechanical Sciences and Engineering,10.1007/s40430-021-03157-4,Springer,2021-08-28,"The Delta robot, widely used in fast pick-and-place applications with pure position control, is a parallel kinematic chain with three rotational inputs resulting in three pure translations at the end-effector. This paper proposes a complete task-space impedance control with inverse dynamics to give this robot compliant behavior, enabling it to be used in tasks involving physical interaction. For that purpose, the well-known usage of dual quaternion algebra for kinematics modeling is novelly integrated with a neural network to compose a compact representation for the forward kinematics function, that is singularity-free and suitable for real-time calculation. This network computes the forward kinematics more than 150 times faster than a numeric equation solving algorithm, with an average estimation error of less than 0.5 mm. The proposed algorithm is implemented in a rigid body simulator, and the performance of the complete system is analyzed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40430-021-03157-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11948-021-00334-5,Technological Answerability and the Severance Problem: Staying Connected by Demanding Answers,Science and Engineering Ethics,10.1007/s11948-021-00334-5,Springer,2021-08-24,"Artificial intelligence (AI) and robotic technologies have become nearly ubiquitous. In some ways, the developments have likely helped us, but in other ways sophisticated technologies set back our interests. Among the latter sort is what has been dubbed the ‘severance problem’—the idea that technologies sever our connection to the world, a connection which is necessary for us to flourish and live meaningful lives. I grant that the severance problem is a threat we should mitigate and I ask: how can we stave it off? In particular, the fact that some technologies exhibit behavior that is unclear to us seems to constitute a kind of severance. Building upon contemporary work on moral responsibility, I argue for a mechanism I refer to as ‘technological answerability’, namely the capacity to recognize human demands for answers and to respond accordingly. By designing select devices—such as robotic assistants and personal AI programs—for increased answerability, we see at least one way of satisfying our demands for answers and thereby retaining our connection to a world increasingly occupied by technology.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-021-00334-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-021-01261-6,"What dangers lurk in the development of emotionally competent artificial intelligence, especially regarding the trend towards sex robots? A review of Catrin Misselhorn’s most recent book",AI & SOCIETY,10.1007/s00146-021-01261-6,Springer,2021-08-24,"The discussion around artificial empathy and its ethics is not a new one. This concept can be found in classic science fiction media such as Star Trek and Blade Runner and is also pondered on in more recent interactive media such as the video game Detroit: Become Human. In most depictions, emotions and empathy are presented as the key to being human. Misselhorn's new publication shows that these futuristic stories are becoming more and more relevant today. We must ask ourselves whether we are socially responsible enough to deal with the consequences of artificial empathy/awareness. If we create artificial life, we should be prepared to treat them accordingly as living beings with respect and no longer categorize them as objects. The author does not rule out the idea that machines might one day become more human than humans themselves and that we humans might even lose our own specific cognitive, emotional and social abilities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-021-01261-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-021-00817-z,Deep Reinforcement Learning of Map-Based Obstacle Avoidance for Mobile Robot Navigation,SN Computer Science,10.1007/s42979-021-00817-z,Nature,2021-08-18,"Autonomous and safe navigation in complex environments without collisions is particularly important for mobile robots. In this paper, we propose an end-to-end deep reinforcement learning method for mobile robot navigation with map-based obstacle avoidance. Using the experience collected in the simulation environment, a convolutional neural network is trained to predict the proper steering operation of the robot based on its egocentric local grid maps, which can accommodate various sensors and fusion algorithms. We use dueling double DQN with prioritized experienced replay technology to update parameters of the network and integrate curriculum learning techniques to enhance its performance. The trained deep neural network is then transferred and executed on a real-world mobile robot to guide it to avoid local obstacles for long-range navigation. The qualitative and quantitative evaluations of the new approach were performed in simulations and real robot experiments. The results show that the end-to-end map-based obstacle avoidance model is easy to deploy, without any fine-tuning, robust to sensor noise, compatible with different sensors, and better than other related DRL-based models in many evaluation indicators.",https://www.nature.com/articles/s42979-021-00817-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-021-00818-1,One-shot Learning from Demonstration Approach Toward a Reciprocal Sign Language-based HRI,International Journal of Social Robotics,10.1007/s12369-021-00818-1,Springer,2021-08-10,"This paper addresses the lack of proper Learning from Demonstration (LfD) architectures for Sign Language-based Human–Robot Interactions to make them more extensible. The paper proposes and implements a Learning from Demonstration structure for teaching new Iranian Sign Language signs to a teacher assistant social robot, RASA. This LfD architecture utilizes one-shot learning techniques and Convolutional Neural Network to learn to recognize and imitate a sign after seeing its demonstration (using a data glove) just once. Despite using a small, low diversity data set (~ 500 signs in 16 categories), the recognition module reached a promising 4-way accuracy of 70% on the test data and showed good potential for increasing the extensibility of sign vocabulary in sign language-based human–robot interactions. The expansibility and promising results of the one-shot Learning from Demonstration technique in this study are the main achievements of conducting such machine learning algorithms in social Human–Robot Interaction.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-021-00818-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11948-021-00331-8,The Moral Consideration of Artificial Entities: A Literature Review,Science and Engineering Ethics,10.1007/s11948-021-00331-8,Springer,2021-08-09,"Ethicists, policy-makers, and the general public have questioned whether artificial entities such as robots warrant rights or other forms of moral consideration. There is little synthesis of the research on this topic so far. We identify 294 relevant research or discussion items in our literature review of this topic. There is widespread agreement among scholars that some artificial entities could warrant moral consideration in the future, if not also the present. The reasoning varies, such as concern for the effects on artificial entities and concern for the effects on human society. Beyond the conventional consequentialist, deontological, and virtue ethicist ethical frameworks, some scholars encourage “information ethics” and “social-relational” approaches, though there are opportunities for more in-depth ethical research on the nuances of moral consideration of artificial entities. There is limited relevant empirical data collection, primarily in a few psychological studies on current moral and social attitudes of humans towards robots and other artificial entities. This suggests an important gap for psychological, sociological, economic, and organizational research on how artificial entities will be integrated into society and the factors that will determine how the interests of artificial entities are considered.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-021-00331-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01443-w,Machine Learning and Data Visualization to Evaluate a Robotics and Programming Project Targeted for Women,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01443-w,Springer,2021-08-03,"Around the world women end up being less interested in areas related to the sciences, technology, engineering and mathematics, or shortly STEM. Therefore, it is important that governments around the world maintain an active interest in getting women to continue in STEM careers. In this context, this work was divided into three main phases, the first was to conduct a search through a related works that were published involving the development of projects aimed at the engagement of girls students or female teachers/professionals within the context of STEM or Robotics, between the years 2018 and 2020. In this case, seven works were found within these criteria, including one Brazilian project. Subsequently, analyzes were carried out of the 85 projects that are being financed by the federal government of Brazil within STEM. The last analysis was a case study to evaluate the engagement of female teachers and students in a medium-sized city in the interior of the southeastern region of Brazil. In this case, we carried out the analysis with the teachers and students, as well as with an external audience. We carry out our analyzes through statistics and analysis of feelings and opinions, in addition to data visualizations. In the end, we conducted through data mining of unsupervised machine learning, analyzes of the groups of people we are interested in engaging, which are groups of young people, especially girls who are interested in STEM, but with little knowledge in Robotics. This strategy was put on the schedule, because we will aim to increase the knowledge of these girls in STEM, especially in robotics, which is the focus of our study and research group. Finally, results have shown that this project has improved a major social and encouraging role for these girls in the field of exact sciences, computing and engineering.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01443-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-020-00683-4,A Reinforcement Learning Based Cognitive Empathy Framework for Social Robots,International Journal of Social Robotics,10.1007/s12369-020-00683-4,Springer,2021-08-01,"Robots that express human’s social norms, like empathy, are perceived as more friendly, understanding, and caring. However, appropriate human-like empathic behaviors cannot be defined in advance, instead, they must be learned through daily interaction with humans in different situations. Additionally, to learn and apply the correct behaviors, robots must be able to perceive and understand the affective states of humans. This study presents a framework to enable cognitive empathy in social robots, which uses facial emotion recognition to perceive and understand the affective states of human users. The perceived affective state is then provided to a reinforcement learning model to enable a robot to learn the most appropriate empathic behaviors for different states. The proposed framework has been evaluated through an experiment between 28 individual humans and the humanoid robot Pepper. The results show that by applying empathic behaviors selected by the employed learning model, the robot is able to provide participants comfort and confidence and help them enjoy and feel better.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-020-00683-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40313-021-00719-8,Toward Robotic Cognition by Means of Decision Tree of Deep Neural Networks Applied in a Humanoid Robot,"Journal of Control, Automation and Electrical Systems",10.1007/s40313-021-00719-8,Springer,2021-08-01,"One of the challenges of Deep Learning research is to develop algorithms for mobile robotic agents that operate in uncontrolled environments, in which dynamic changes and limited processing power are common restrictions. A common solution is to develop separate vision and decision modules, so that the former is based on deep neural network architectures and the latter is based on rules, and then interconnect them. The drawback of this solution is that the modules need to exchange high-level information about the objects in the scene, which are usually the positions of all objects in the scene, and this is computationally expensive. To address this problem, this paper presents a Decision Tree of Deep Neural Networks (DT-DNN) that aims to perform end to end—from image to decision—processing, and, thus, eliminating the need for quantitative and relational information about the image. This model is composed of smaller and more specialized modular DNNs, thus solving the trade-off between performance and inference time. Experiments were carried out using a real robot in the RoboCup Humanoid League domain in a soccer field, and also in simulation. We compared DT-DNN with several traditional DNN architectures. From the results, it is possible to conclude that the use of the DT-DNN made the system simpler and more robust, with fewer parameters to be adjusted, reducing the time spent with inference and also increasing the performance when compared to the traditional approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40313-021-00719-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00170-021-07265-2,Task-level decision-making for dynamic and stochastic human-robot collaboration based on dual agents deep reinforcement learning,The International Journal of Advanced Manufacturing Technology,10.1007/s00170-021-07265-2,Springer,2021-08-01,"Human-robot collaboration as a multidisciplinary research topic is still pursuing the robots’ enhanced intelligence to be more human-compatible and fit the dynamic and stochastic characteristics of human. However, the uncertainties brought by the human partner challenge the task-planning and decision-making of the robot. When aiming at industrial tasks like collaborative assembly, dynamics on temporal dimension and stochasticities on the order of procedures need to be further considered. In this work, we bring a new perspective and solution based on reinforcement learning, where the problem is regarded as training an agent towards tasks in dynamic and stochastic environments. Concretely, an adapted training approach based on the deep Q learning method is proposed. This method regards both the robot and the human as the agents in the interactive training environment for deep reinforcement learning. With the consideration of task-level industrial human-robot collaboration, the training logic and the agent-environment interaction have been proposed. For the human-robot collaborative assembly tasks in the case study, it is illustrated that our method could drive the robot represented by one agent to collaborate with the human partner even the human performs randomly on the task procedures.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00170-021-07265-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-021-00687-x,Comparison of high-dimensional neural networks using hypercomplex numbers in a robot manipulator control,Artificial Life and Robotics,10.1007/s10015-021-00687-x,Springer,2021-08-01,"This study considers high-dimensional neural networks based on hypercomplex numbers that form a four-dimensional algebra over the field of real numbers, such as quaternion, coquaternion, hyperbolic-quaternion, bicomplex and dual-complex numbers. In addition, the applicability of the networks in the robot manipulator’s control system is explored. In the control system, the output of the high-dimensional neural network is used as the control input for the robot manipulator to ensure that the end-effector of the robot manipulator tracks the desired trajectory in a three-dimensional space. Computational experiments are conducted on controlling a three-link robot manipulator to evaluate the learning and control performance of the high-dimensional neural networks. The simulation results demonstrate that the quaternion-valued neural network achieves better performance in learning and control tasks compared to other networks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-021-00687-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11229-020-02533-2,Interactive biorobotics,Synthese,10.1007/s11229-020-02533-2,Springer,2021-08-01,"What can interactive robots offer to the study of social behaviour? Philosophical reflections about the use of robotic models in animal research have focused so far on methods (including the so-called synthetic method) involving robots which do not interact with the target system. Yet, leading researchers have claimed that interactive robots may constitute powerful experimental tools to study collective behaviour. Can they live up to these epistemic expectations? This question is addressed here by focusing on a particular experimental methodology involving interactive robots which has been often adopted in animal research. This methodology is shown to differ from other robot-supported methods for the study of animal behaviour analysed in the philosophical literature, chiefly including the synthetic method. It is also discussed whether biomimicry (i.e., similarity between the robot and the target animal in behaviour, appearance, and internal mechanisms) and acceptability (i.e., whether or not the robot is accepted as a conspecific by the animal) are necessary for an interactive robot to be sensibly used in animal research according to this method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11229-020-02533-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-021-00813-6,Negotiating anthropomorphism in the Ai-Da robot,International Journal of Social Robotics,10.1007/s12369-021-00813-6,Springer,2021-07-30,"The central interest of this paper is the anthropomorphic social robot Ai-Da (Aidan Meller Gallery/Oxford University), perceived as an actor in the interplay of cultural and representational gestures. These gestures determine how this robot is presented—that is, how its activities are articulated, interpreted and promoted. This paper criticises the use of a transhistorical discourse in the presentational strategies around this robot, since this discourse reinforces the so-called “myth of a machine”. The discussion focuses on the individuation and embodiment of this drawing robot. It is argued that the choice to provide Ai-Da with an evocative silicone face, coupled with an anthropomorphic body, is a socio-political decision that shapes public imaginaries about social robots in general.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-021-00813-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11220-021-00351-5,GPNRBNN: A Robot Image Edge Detection Method Based on Gaussian Positive-Negative Radial Basis Neural Network,Sensing and Imaging,10.1007/s11220-021-00351-5,Springer,2021-07-21,"In the traditional edge detection models, due to the influence of artifact, occlusion and other factors, the detection efficiency is poor and the error is large, which affects the subsequent image processing. Therefore, this paper proposes a new edge detection method based on Gaussian positive-negative radial basis neural network (GPNRBNN). Firstly, a novel GPNRBNN is constructed in this paper. Each pixel preprocessed by Gaussian filter in the image is taken as the central point of the GPNRBNN and input into the neural network. Then, the weight sharing and sparse connection in the convolutional neural network are used for processing the pixels. The results are output after the calculation in the extended layer and the hidden layer. Thirdly, the edge is extracted by contour tracking according to the output results. Finally, experiments are conducted on the composite image, part of the uneven gray image and medical images etc. Compared with other models, the efficiency of the proposed model is improved, and the edge connectivity is better.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11220-021-00351-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-020-04952-1,Neural network control system of cooperative robot based on genetic algorithms,Neural Computing and Applications,10.1007/s00521-020-04952-1,Springer,2021-07-01,"Attitude detection of cooperative robots can help robots recognize environment, understand tasks, and improve the safety, accuracy and efficiency of robot work. For robots with unknown configuration parameters, their configuration can be estimated; it is convenient for further kinematics and dynamics analysis. For an economical cooperative robot, its kinematic parameters can be corrected by attitude detection. An independent robot attitude detection system can be used as a secondary auxiliary system, and the fault diagnosis system of the robot is composed of the high-precision encoder system of the robot body. This paper studies the neural network control system of cooperative robot based on genetic algorithm. In this paper, the robot is taken as the research object. Aiming at its strong conjunction, non-linearity and multivariable characteristics, the problem of robot motion control based on neural network is mainly discussed. On this basis, the basic genetic algorithm and an improved genetic algorithm called messy are used to optimize the structure of the neural network, so as to better realize the motion control problem of the robot. The results of this study show that: After optimization with messy genetic algorithm, not only the tracking effect is better, but also the number of hidden layer nodes of the network is reduced from 12 to 7. This greatly simplifies the structure of the network and makes the design and training of the network relatively simple.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-020-04952-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11548-021-02404-2,Mask then classify: multi-instance segmentation for surgical instruments,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-021-02404-2,Springer,2021-07-01,"Purpose The detection and segmentation of surgical instruments has been a vital step for many applications in minimally invasive surgical robotics. Previously, the problem was tackled from a semantic segmentation perspective, yet these methods fail to provide good segmentation maps of instrument types and do not contain any information on the instance affiliation of each pixel. We propose to overcome this limitation by using a novel instance segmentation method which first masks instruments and then classifies them into their respective type. Methods We introduce a novel method for instance segmentation where a pixel-wise mask of each instance is found prior to classification. An encoder–decoder network is used to extract instrument instances, which are then separately classified using the features of the previous stages. Furthermore, we present a method to incorporate instrument priors from surgical robots. Results Experiments are performed on the robotic instrument segmentation dataset of the 2017 endoscopic vision challenge. We perform a fourfold cross-validation and show an improvement of over 18% to the previous state-of-the-art. Furthermore, we perform an ablation study which highlights the importance of certain design choices and observe an increase of 10% over semantic segmentation methods. Conclusions We have presented a novel instance segmentation method for surgical instruments which outperforms previous semantic segmentation-based methods. Our method further provides a more informative output of instance level information, while retaining a precise segmentation mask. Finally, we have shown that robotic instrument priors can be used to further increase the performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-021-02404-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11747-020-00762-y,"Understanding anthropomorphism in service provision: a meta-analysis of physical robots, chatbots, and other AI",Journal of the Academy of Marketing Science,10.1007/s11747-020-00762-y,Springer,2021-07-01,"An increasing number of firms introduce service robots, such as physical robots and virtual chatbots, to provide services to customers. While some firms use robots that resemble human beings by looking and acting humanlike to increase customers’ use intention of this technology, others employ machinelike robots to avoid uncanny valley effects, assuming that very humanlike robots may induce feelings of eeriness. There is no consensus in the service literature regarding whether customers’ anthropomorphism of robots facilitates or constrains their use intention. The present meta-analysis synthesizes data from 11,053 individuals interacting with service robots reported in 108 independent samples. The study synthesizes previous research to clarify this issue and enhance understanding of the construct. We develop a comprehensive model to investigate relationships between anthropomorphism and its antecedents and consequences. Customer traits and predispositions (e.g., computer anxiety), sociodemographics (e.g., gender), and robot design features (e.g., physical, nonphysical) are identified as triggers of anthropomorphism. Robot characteristics (e.g., intelligence) and functional characteristics (e.g., usefulness) are identified as important mediators, although relational characteristics (e.g., rapport) receive less support as mediators. The findings clarify contextual circumstances in which anthropomorphism impacts customer intention to use a robot. The moderator analysis indicates that the impact depends on robot type (i.e., robot gender) and service type (i.e., possession-processing service, mental stimulus-processing service). Based on these findings, we develop a comprehensive agenda for future research on service robots in marketing.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11747-020-00762-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-020-00653-w,Trust in and Ethical Design of Carebots: The Case for Ethics of Care,International Journal of Social Robotics,10.1007/s12369-020-00653-w,Springer,2021-07-01,"The paper has two main objectives: to examine the challenges arising from the use of carebots as well as to discuss how the design of carebots can deal with these challenges. First, it notes that the use of carebots to take care of the physical and mental health of the elderly, children and the disabled as well as to serve as assistive tools and social companions encounter a few main challenges. They relate to the extent of the care robots’ ability to care for humans, potential deception by robot morphology and communications, (over)reliance on or attachment to robots, and the risks of carebot use without informed consent and potential infringements of privacy. Secondly, these challenges impinge upon issues of ethics and trust which are somewhat overlapping in terms of concept and practice. The existing ethical guidelines, standards and regulations are general in nature and lack a central ethical framework and concrete principles applicable to the care contexts. Hence, to deal with these important challenges, it is proposed in the third part of the paper that carebots be designed by taking account of Ethics of Care as the central ethical framework. It argues that the Ethics of Care offer the following advantages: (a) it provides sufficiently concrete principles and embodies values that are sensitive and applicable to the design of carebots and the contexts of caring practices; (b) it coheres with the tenets of Principlism and select ethical theories (utilitarianism, deontology and virtue ethics); and (c) it is closely associated with the preservation and maintenance of trust.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-020-00653-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-020-00660-x,Inference of Other’s Minds with Limited Information in Evolutionary Robotics,International Journal of Social Robotics,10.1007/s12369-020-00660-x,Springer,2021-07-01,"Theory of mind (ToM) is the ability to understand others’ mental states (e.g., intentions). Studies on human ToM show that the way we understand others’ mental states is very efficient, in the sense that observing only some portion of others’ behaviors can lead to successful performance. Recently, ToM has gained interest in robotics to build robots that can engage in complex social interactions. Although it has been shown that robots can infer others’ internal states, there has been limited focus on the data utilization of ToM mechanisms in robots. Here we show that robots can infer others’ intentions based on limited information by selectively and flexibly using behavioral cues similar to humans. To test such data utilization, we impaired certain parts of an actor robot’s behavioral information given to the observer, and compared the observer’s performance under each impairment condition. We found that although the observer’s performance was not perfect compared to when all information was available, it could infer the actor’s mind to a degree if the goal-relevant information was intact. These results demonstrate that, similar to humans, robots can learn to infer others’ mental states with limited information.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-020-00660-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01333-1,Deep Reinforcement Learning for a Humanoid Robot Soccer Player,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01333-1,Springer,2021-06-26,"This paper investigates the use of Deep Reinforcement Learning (DRL) applied to the humanoid robot soccer environment, where a robot must learn from basic to complex skills while it interacts with the environment through images received by its own camera. To do so, the Dueling Double DQN algorithm is used: it receives the images from the robot’s camera and decides on which discrete action should be performed, such as walk forward, turn to the left or kick the ball. The first experiments were performed in a robotic simulator in which the robot could learn, with DRL, three different tasks: to walk towards the ball, to act like a penalty taker and to act like a goalkeeper. In the second experiment, the learning obtained in the task to walk towards the ball was transferred to a real humanoid robot and a similar behavior could be observed, even though the environment was not exactly the same when the domain was changed. Results showed that it is possible to use DRL to learn tasks related to the role of a humanoid robot-soccer player, such as goalkeeper and penalty taker.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01333-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10994-021-06019-1,Bayesian optimization with safety constraints: safe and automatic parameter tuning in robotics,Machine Learning,10.1007/s10994-021-06019-1,Springer,2021-06-24,"Selecting the right tuning parameters for algorithms is a pravelent problem in machine learning that can significantly affect the performance of algorithms. Data-efficient optimization algorithms, such as Bayesian optimization, have been used to automate this process. During experiments on real-world systems such as robotic platforms these methods can evaluate unsafe parameters that lead to safety-critical system failures and can destroy the system. Recently, a safe Bayesian optimization algorithm, called  SafeOpt , has been developed, which guarantees that the performance of the system never falls below a critical value; that is, safety is defined based on the performance function. However, coupling performance and safety is often not desirable in practice, since they are often opposing objectives. In this paper, we present a generalized algorithm that allows for multiple safety constraints separate from the objective. Given an initial set of safe parameters, the algorithm maximizes performance but only evaluates parameters that satisfy safety for all constraints with high probability. To this end, it carefully explores the parameter space by exploiting regularity assumptions in terms of a Gaussian process prior. Moreover, we show how context variables can be used to safely transfer knowledge to new situations and tasks. We provide a theoretical analysis and demonstrate that the proposed algorithm enables fast, automatic, and safe optimization of tuning parameters in experiments on a quadrotor vehicle.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10994-021-06019-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-021-06192-3,A deep learning framework for realistic robot motion generation,Neural Computing and Applications,10.1007/s00521-021-06192-3,Springer,2021-06-15,"Humanoid robots are being developed to play the role of personal assistants. With the development of artificial intelligence technology, humanoid robots are expected to perform many human tasks, such as housework, human care, and even medical treatment. However, robots cannot currently move flexibly like humans, which affects their fine motor skill performance. This is primarily because traditional robot control methods use manipulators that are difficult to articulate well. To solve this problem, we propose a nonlinear realistic robot motion generation method based on deep learning. Our method benefits from decomposing human motions into basic motions and realistic motions using the multivariate empirical mode decomposition and learning the biomechanical relationships between them by using an autoencoder generation network. The experimental results show that realistic motion features can be learned by the generation network and motion realism can be increased by adding the learned motions to the robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-021-06192-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01355-9,Learning Humanoid Robot Running Motions with Symmetry Incentive through Proximal Policy Optimization,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01355-9,Springer,2021-06-03,"This article contributes with a methodology based on deep reinforcement learning to develop running skills in a humanoid robot with no prior knowledge. Specifically, the algorithm used for learning is the Proximal Policy Optimization (PPO). The chosen application domain is the RoboCup 3D Soccer Simulation (Soccer 3D), a competition where teams composed by 11 autonomous agents each compete in simulated soccer matches. In our approach, the state vector used as the neural network’s input consists of raw sensor measurements or quantities which could be obtained through sensor fusion, while the actions are the joint positions, which are sent to joint controllers. Our running behavior outperforms the state-of-the-art in terms of sprint speed by approximately 50%. We present results regarding the training procedure and also evaluate the controllers in terms of speed, reliability, and human similarity. Since the running policies with top speed display asymmetric motions, we also investigate a technique to encourage symmetry in the sagittal plane. Finally, we discuss key factors that lead us to surpass previous results in the literature and share some ideas for future research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01355-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41315-021-00174-3,A modern deep learning framework in robot vision for automated bean leaves diseases detection,International Journal of Intelligent Robotics and Applications,10.1007/s41315-021-00174-3,Springer,2021-06-01,"The bean leaves can be affected by several diseases, such as angular leaf spots and bean rust, which can cause big damage to bean crops and decrease their productivity. Thus, treating these diseases in their early stages can improve the quality and quantity of the product. Recently, several robotic frameworks based on image processing and artificial intelligence have been used to treat these diseases in an automated way. However, incorrect diagnosis of the infected leaf can lead to the use of chemical treatments for normal leaf thereby the issue will not be solved, and the process may be costly and harmful. To overcome these issues, a modern deep learning framework in robot vision for the early detection of bean leaves diseases is proposed. The proposed framework is composed of two primary stages, which detect the bean leaves in the input images and diagnosing the diseases within the detected leaves. The U-Net architecture based on a pre-trained ResNet34 encoder is employed for detecting the bean leaves in the input images captured in uncontrolled environmental conditions. In the classification stage, the performance of five diverse deep learning models (e.g., Densenet121, ResNet34, ResNet50, VGG-16, and VGG-19) is assessed accurately to identify the healthiness of bean leaves. The performance of the proposed framework is evaluated using a challenging and extensive dataset composed of 1295 images of three different classes (e.g., Healthy, Angular Leaf Spot, and Bean Rust). In the binary classification task, the best performance is achieved using the Densenet121 model with a CAR of 98.31%, Sensitivity of 99.03%, Specificity of 96.82%, Precision of 98.45%, F1-Score of 98.74%, and AUC of 100%. The higher CAR of 91.01% is obtained using the same model in the multi-classification task, with less than 2 s per image to produce the final decision.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-021-00174-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43154-021-00049-2,Recent Advances in Formations of Multiple Robots,Current Robotics Reports,10.1007/s43154-021-00049-2,Springer,2021-06-01,"Purpose of Review Formation control is a canonical problem in multi-robot systems, which focuses on the ability of a group of robots to travel in coordination through an area, while maintaining a certain shape or a particular behavior. The robot groups vary in their communication, computation, and sensing capabilities. Moreover, the formation control task itself may have various objectives. These divergences force the use of different models for controlling the formation and for analyzing the task performance. In this paper, we describe the formation control problem and survey recent advances focusing on aspects of maintaining a formation by a group of robots distinguished by the means of analysis. Recent Findings Various approaches may be applied for the sake of formation maintenance, whereas each approach possesses a different perspective in regard with formation control. Recent research focuses on combining those approaches, due to their applicability regarding certain scenarios. For instance, consensus-based control and collision avoidance are usually intertwined together for the sake of reaching a consensus in a manner which is collision-free. Furthermore, machine learning (ML)–based methods for navigating a robot team through unknown complex environments can be incorporated, where the robot team aims to reach a goal position while avoiding collisions and maintaining connectivity. Moreover, recent approaches focus on developing new mechanisms or adapt existing ones for formation control for tolerating limitations in sensing, communication, and coordination, preferably distributively while providing performance guarantees. Conclusion Such combined approaches yield that the means of analysis, which can be applied to each one separately, can also be utilized in an intertwined manner, and thus provide us with novel methods for preserving formation. Whereas some approaches were vastly investigated (e.g., consensus-based formation control) and need to be adapted to distributed imperfect settings, others still require further insight for unveiling brand new architectures and tools (e.g., ML-based formation control).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43154-021-00049-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-020-01063-2,Artificial moral and legal personhood,AI & SOCIETY,10.1007/s00146-020-01063-2,Springer,2021-06-01,"This paper considers the hotly debated issue of whether one should grant moral and legal personhood to intelligent robots once they have achieved a certain standard of sophistication based on such criteria as rationality, autonomy, and social relations. The starting point for the analysis is the European Parliament’s resolution on Civil Law Rules on Robotics (2017) and its recommendation that robots be granted legal status and electronic personhood. The resolution is discussed against the background of the so-called Robotics Open Letter, which is critical of the Civil Law Rules on Robotics (and particularly of §59 f.). The paper reviews issues related to the moral and legal status of intelligent robots and the notion of legal personhood, including an analysis of the relation between moral and legal personhood in general and with respect to robots in particular. It examines two analogies, to corporations (which are treated as legal persons) and animals, that have been proposed to elucidate the moral and legal status of robots. The paper concludes that one should not ascribe moral and legal personhood to currently existing robots, given their technological limitations, but that one should do so once they have achieved a certain level at which they would become comparable to human beings.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-020-01063-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43154-021-00053-6,"Ethics of Corporeal, Co-present Robots as Agents of Influence: a Review",Current Robotics Reports,10.1007/s43154-021-00053-6,Springer,2021-06-01,"Purpose of Review To summarize the set of roboethics issues that uniquely arise due to the corporeality and physical interaction modalities afforded by robots, irrespective of the degree of artificial intelligence present in the system. Recent Findings One of the recent trends in the discussion of ethics of emerging technologies has been the treatment of roboethics issues as those of “embodied AI,” a subset of AI ethics. In contrast to AI, however, robots leverage human’s natural tendency to be influenced by our physical environment. Recent work in human-robot interaction highlights the impact a robot’s presence, capacity to touch, and move in our physical environment has on people, and helping to articulate the ethical issues particular to the design of interactive robotic systems. Summary The corporeality of interactive robots poses unique sets of ethical challenges. These issues should be considered in the design irrespective of and in addition to the ethics of artificial intelligence implemented in them.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43154-021-00053-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-021-00716-8,EDLRIS: A European Driving License for Robots and Intelligent Systems,KI - Künstliche Intelligenz,10.1007/s13218-021-00716-8,Springer,2021-06-01,"This article presents a novel educational project aiming at the development and implementation of a professional, standardized, internationally accepted system for training and certifying teachers, school students and young people in Artificial Intelligence (AI) and Robotics. In recent years, AI and Robotics have become major topics with a huge impact not only on our everyday life but also on the working environment. Hence, sound knowledge about principles and concepts of AI and Robotics are key skills for this century. Nonetheless, hardly any systematic approaches exist that focus on teaching principles of intelligent systems at K-12 level, addressing students as well as teachers who act as multipliers. In order to meet this challenge, the European Driving License for Robots and Intelligent Systems—EDLRIS was developed. It is based on a number of previously implemented and evaluated projects and comprises teaching curricula and training modules for AI and Robotics, following a competency-based, blended learning approach. Additionally, a certification system proves peoples’ acquired competencies. After developing the training and certification system, the first 32 trainer and trainee courses with a total of 445 participants have been implemented and evaluated. By applying this innovative approach—a standardized and widely recognized training and certification system for AI and Robotics at K-12 level for both high school teachers and students—we envision to foster AI/Robotics literacy on a broad basis.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-021-00716-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/s42256-021-00330-1,Integration of deep learning and soft robotics for a biomimetic approach to nonlinear sensing,Nature Machine Intelligence,10.1038/s42256-021-00330-1,Nature,2021-06-01,"Traditional approaches to sensing have often been aimed at simple sensor characteristics to make interpretation of the sensor outputs easier, but this has also limited the quality of the encoded sensory information. Integrating a complex sensor with deep learning could hence be a strategy for removing current limitations on the information that sensory inputs can carry. Here, we demonstrate this concept with a soft-robotic sensor that mimics fast non-rigid deformation of the ears in certain bat species. We show that a deep convolutional neural network can use the nonlinear Doppler shift signatures generated by these motions to estimate the direction of a sound source with an estimation error of ~0.5°. Previously, determining the direction of a sound source based on pressure receivers required either multiple frequencies or multiple receivers. Our current results demonstrate a third approach that makes do with only a single frequency and a single receiver. Bats with sophisticated biosonar systems move their ears at a high speed to help localize sound sources. Yin and Müller present a system inspired by this strategy, which can localize sounds with high accuracy and with a single detector, using a flexible silicone model of a bat’s ear and a deep convolutional neural network to process the complex Doppler signatures.",https://www.nature.com/articles/s42256-021-00330-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-021-09969-6,"Partial caging: a clearance-based definition, datasets, and deep learning",Autonomous Robots,10.1007/s10514-021-09969-6,Springer,2021-06-01,"Caging grasps limit the mobility of an object to a bounded component of configuration space. We introduce a notion of partial cage quality based on maximal clearance of an escaping path. As computing this is a computationally demanding task even in a two-dimensional scenario, we propose a deep learning approach. We design two convolutional neural networks and construct a pipeline for real-time planar partial cage quality estimation directly from 2D images of object models and planar caging tools. One neural network, CageMaskNN, is used to identify caging tool locations that can support partial cages, while a second network that we call CageClearanceNN is trained to predict the quality of those configurations. A partial caging dataset of 3811 images of objects and more than 19 million caging tool configurations is used to train and evaluate these networks on previously unseen objects and caging tool configurations. Experiments show that evaluation of a given configuration on a GeForce GTX 1080 GPU takes less than 6 ms. Furthermore, an additional dataset focused on grasp-relevant configurations is curated and consists of 772 objects with 3.7 million configurations. We also use this dataset for 2D Cage acquisition on novel objects. We study how network performance depends on the datasets, as well as how to efficiently deal with unevenly distributed training data. In further analysis, we show that the evaluation pipeline can approximately identify connected regions of successful caging tool placements and we evaluate the continuity of the cage quality score evaluation along caging tool trajectories. Influence of disturbances is investigated and quantitative results are provided.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-021-09969-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-020-05366-9,Structural health monitoring of railway tracks using IoT-based multi-robot system,Neural Computing and Applications,10.1007/s00521-020-05366-9,Springer,2021-06-01,"A multi-robot-based fault detection system for railway tracks is proposed to eliminate manual human visual inspection. A hardware prototype is designed to implement a master–slave robot mechanism capable of detecting rail surface defects, which include cracks, squats, corrugations, and rust. The system incorporates ultrasonic sensor inputs coupled with image processing using OpenCV and deep learning algorithms to classify the surface faults detected. The proposed Convolutional Neural Network (CNN) model fared better compared to the Artificial Neural Network (ANN), random forest, and Support Vector Machine (SVM) algorithms based on accuracy, R-squared value, F1 score, and Mean-Squared Error (MSE). To eliminate manual inspection, the location and status of the fault can be conveyed to a central location enabling immediate attention by utilizing GSM, GPS, and cloud storage-based technologies. The system is extended to a multi-robot framework designed to optimize energy utilization, increase the lifetime of individual robots, and improve the overall network throughput. Thus, the Low Energy Adaptive Clustering Hierarchy (LEACH) protocol is simulated using 100 robot nodes, and the corresponding performance metrics are obtained.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-020-05366-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12193-021-00366-y,Grounding behaviours with conversational interfaces: effects of embodiment and failures,Journal on Multimodal User Interfaces,10.1007/s12193-021-00366-y,Springer,2021-06-01,"Conversational interfaces that interact with humans need to continuously establish, maintain and repair common ground in task-oriented dialogues. Uncertainty, repairs and acknowledgements are expressed in user behaviour in the continuous efforts of the conversational partners to maintain mutual understanding. Users change their behaviour when interacting with systems in different forms of embodiment, which affects the abilities of these interfaces to observe users’ recurrent social signals. Additionally, humans are intellectually biased towards social activity when facing anthropomorphic agents or when presented with subtle social cues. Two studies are presented in this paper examining how humans interact in a referential communication task with wizarded interfaces in different forms of embodiment. In study 1 (N = 30), we test whether humans respond the same way to agents, in different forms of embodiment and social behaviour. In study 2 (N = 44), we replicate the same task and agents but introduce conversational failures disrupting the process of grounding. Findings indicate that it is not always favourable for agents to be anthropomorphised or to communicate with non-verbal cues, as human grounding behaviours change when embodiment and failures are manipulated.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12193-021-00366-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-020-01129-1,Debate: what is personhood in the age of AI?,AI & SOCIETY,10.1007/s00146-020-01129-1,Springer,2021-06-01,"In a friendly interdisciplinary debate, we interrogate from several vantage points the question of “personhood” in light of contemporary and near-future forms of social AI. David J. Gunkel approaches the matter from a philosophical and legal standpoint, while Jordan Wales offers reflections theological and psychological. Attending to metaphysical, moral, social, and legal understandings of personhood, we ask about the position of apparently personal artificial intelligences in our society and individual lives. Re-examining the “person” and questioning prominent construals of that category, we hope to open new views upon urgent and much-discussed questions that, quite soon, may confront us in our daily lives.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-020-01129-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-020-00973-5,Tying the knot with a robot: legal and philosophical foundations for human–artificial intelligence matrimony,AI & SOCIETY,10.1007/s00146-020-00973-5,Springer,2021-06-01,"Technological progress may eventually produce sophisticated robots with human-like traits that result in humans forming meaningful relationships with them. Such relationships would likely lead to a demand for human–artificial intelligence (AI) matrimony. U.S. Supreme Court decisions that expanded the definition of marriage to include interracial and same-sex couples, as well as those that have not extended marriage to polygamous relationships, provide guidance regarding the criteria that human–AI would have to meet to successfully assert a right to marry. Ultimately, robots will have to possess certain characteristics of personhood to marry, including the capacity to contract and to engage in an intimate relationship. Alternatively, if AIs can simulate these abilities sufficiently, we may believe that they have these capacities. Even if AIs genuinely possess the capabilities necessary to enter into a marriage, it is social acceptance of intelligent non-humans as life partners that will likely influence legal development is this realm rather than personhood criteria. However, AIs are likely to face bias due to their “artificial” rather than biological nature. Yet, Peter Singer’s influential argument regarding speciesism in the context of animal rights implies that AIs with specific human-like qualities cannot be justifiably denied certain rights.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-020-00973-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-020-01009-8,Legal dilemmas of Estonian artificial intelligence strategy: in between of e-society and global race,AI & SOCIETY,10.1007/s00146-020-01009-8,Springer,2021-06-01,"Estonia has successfully created a digital society within the past 2 decades. It is best known for its eGovernment achievements, but it is also home for four unicorn star-ups. While the state is aiming to attract tech investments with e-Residency program and has recently started to invest into protecting national IP and safeguarding data from cybercrime by applying blockchain technology and creating its “digital embassy” in Luxembourg, emerging technologies such as and applications of artificial intelligence but also internet of things have posed the question on legal regulation and standardization. The dilemma, however, seems to be that since the new technologies, such artificial intelligence is much more overwhelming phenomenon than e-governance and presumably, before deciding the legal standards, the political and economic strategies that go beyond the e-governance should be set.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-020-01009-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-020-05393-6,Mental imagery classification using one-dimensional convolutional neural network for target selection in single-channel BCI-controlled mobile robot,Neural Computing and Applications,10.1007/s00521-020-05393-6,Springer,2021-06-01,"This paper introduces the use of the one-dimensional convolutional neural network (1D-CNN) for end-to-end EEG decoding with application towards a BCI system with a shared control scheme. In general, subjects wearing a single-channel EEG electrode located at F _8 (10–20 international standards) were required to perform mental tasks by mentally visualising the rotation of a star and mind relaxation at a specific time and by robot orientation. The visualisation of a rotating star suggests that the mobile robot is currently oriented towards a target, thus enabling target selection. We showed that proposed classifier obtained the best accuracy of 92.09% in classifying the subject’s performing mental rotation task or mental relaxation when compared with conventional classification methods such as support vector machine—75.69%, K th-nearest neighbour—65.50% and linear discriminant analysis—65.20%. Furthermore, different from conventional methods, the use of 1D-CNN enables end-to-end learning, that is the automatic decoding of EEG signals without requiring feature selection or extraction. To validate that the proposed classifier performs better than conventional methods, the extracted kernel weights of proposed 1D-CNN filters were visualised as a temporal plot, and spectral analysis was performed on the extracted weights. The obtained results confirmed that the proposed 1D-CNN was able to generate filters that resemble the EEG wave patterns of different frequencies and spectral analysis confirmed that the filters exploited information from multiple frequency bands (such as alpha band and beta band) that are often associated with a heightened mental state when performing mental tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-020-05393-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43154-021-00046-5,Multi-robot Coordination and Planning in Uncertain and Adversarial Environments,Current Robotics Reports,10.1007/s43154-021-00046-5,Springer,2021-06-01,"Purpose of Review Deploying a team of robots that can carefully coordinate their actions can make the entire system robust to individual failures. In this report, we review recent algorithmic development in making multi-robot systems robust to environmental uncertainties, failures, and adversarial attacks. Recent Findings We find the following three trends in the recent research in the area of multi-robot coordination: (1) resilient coordination to either withstand failures and/or attack or recover from failures/attacks; (2) risk-aware coordination to manage the trade-off risk and reward, where the risk stems due to environmental uncertainty; (3) Graph neural networks based coordination to learn decentralized multi-robot coordination policies. These algorithms have been applied to tasks such as formation control, task assignment and scheduling, search and planning, and informative data collection. Summary In order for multi-robot systems to become practical, we need coordination algorithms that can scale to large teams of robots dealing with dynamically changing, failure-prone, contested, and uncertain environments. There has been significant recent research on multi-robot coordination that has contributed resilient and risk-aware algorithms to deal with these issues and reduce the gap between theory and practice. Learning-based approaches have been seen to be promising, especially since they can learn who, when, and how to communicate for effective coordination. However, these algorithms have also been shown to be vulnerable to adversarial attacks, and as such developing learning-based coordination strategies that are resilient to such attacks and robust to uncertainties is an important open area of research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43154-021-00046-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42452-021-04653-x,“Does cinema form the future of robotics?”: a survey on fictional robots in sci-fi movies,SN Applied Sciences,10.1007/s42452-021-04653-x,Nature,2021-05-22,"Abstract Robotics and Artificial Intelligence (AI) have always been among the most popular topics in science fiction (sci-fi) movies. This paper endeavors to review popular movies containing Fictional Robots (FR) to extract the most common characteristics and interesting design ideas of robots portrayed in science fiction. To this end, 134 sci-fi films, including 108 unique FRs, were investigated regarding the robots’ different design aspects (e.g., appearance design, interactive design and artificial intelligence, and ethical and social design). Also, in each section of this paper, some characteristics of FRs are compared with real social robots. Since some researches point to the significant role of the cinema in forming the community’s expectations, it is very important to consider these characteristics and differences in choosing the future pathway of robotics. As some examples of findings, we have found that unlike the non-metallic skins/covers of real social robots, most FRs are still covered by highly detailed metal components. Moreover, the FR ability of interactions are generally (more than 90%) shown to be similar or even more advanced than normal Human–Human interactions, and this milestone was achieved by ignoring the AI challenges of real HRI. On the other hand, the ethical aspects of movies do inspire us to consider the potential ethical aspects of real robot design. All in all, according to popularity of movies, studying FR could be a step toward more appropriate development of robotics and AI entities to be accepted by general users in the real world. Highlights: We reviewed 134 sci-fi movies containing 108 unique fictional robots regarding different design aspects. Fictional Robot (FR) is an artificial entity acting as a result of a fictional technology and playing a role in a movie. Investigating fictional robots can shed light on the development of real robotics and AI entities.",https://www.nature.com/articles/s42452-021-04653-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10845-021-01776-1,Automated visual detection of geometrical defects in composite manufacturing processes using deep convolutional neural networks,Journal of Intelligent Manufacturing,10.1007/s10845-021-01776-1,Springer,2021-05-19,"Detection of fiber composite material boundaries and defects is critical to the automation of the manufacturing process in the aviation industry. This paper describes a process to evaluate four well-performing deep convolutional neural network models (Mask R-CNN, U-Net, DeepLab V3+, and IC-Net) for use in such a process. A custom-captured dataset of images showing fiber cut-pieces with geometrical defects was annotated and augmented for training deep convolutional neural network models; results show acceptable detection accuracy for gripper and fabric based on the Intersection over Union (IoU) scores of up to 0.92 and 0.86, respectively. However, wrinkle detection initially achieves a significantly lower IoU score of 0.40 in the best case. This discrepancy is mainly due to geometrical ambiguities, as wrinkles do not have a clearly defined boundary and are hard to distinguish even for human eye. The model is then evaluated as a binary predictor based on per-component detection success; the model achieves a recall rate (i.e., the ratio of the wrinkles detected to all existing wrinkles) of 0.71 and a precision score (i.e., the ratio of those detected being actually wrinkles) of 0.76. From a practical point of view, this model can outperform a human operator based on the results presented. Two complementary approaches are also introduced for the detection of wrinkles at the early stages of formation as well as the completely formed wrinkles. The developed method can be readily used in a variety of composite manufacturing processes or adapted to other similar tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10845-021-01776-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s13634-021-00734-6,A robot vision navigation method using deep learning in edge computing environment,EURASIP Journal on Advances in Signal Processing,10.1186/s13634-021-00734-6,Springer,2021-05-17,"In the development of modern agriculture, the intelligent use of mechanical equipment is one of the main signs for agricultural modernization. Navigation technology is the key technology for agricultural machinery to control autonomously in the operating environment, and it is a hotspot in the field of intelligent research on agricultural machinery. Facing the accuracy requirements of autonomous navigation for intelligent agricultural robots, this paper proposes a visual navigation algorithm for agricultural robots based on deep learning image understanding. The method first uses a cascaded deep convolutional network and hybrid dilated convolution fusion method to process images collected by a vision system. Then, it extracts the route of processed images based on the improved Hough transform algorithm. At the same time, the posture of agricultural robots is adjusted to realize autonomous navigation. Finally, our proposed method is verified by using non-interference experimental scenes and noisy experimental scenes. Experimental results show that the method can perform autonomous navigation in complex and noisy environments and has good practicability and applicability.",https://www.biomedcentral.com/openurl?doi=10.1186/s13634-021-00734-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01367-5,Soft Actor-Critic for Navigation of Mobile Robots,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01367-5,Springer,2021-05-14,"This paper provides a study of two deep reinforcement learning techniques for application in navigation of mobile robots, one of the techniques is the Soft Actor Critic (SAC) that is compared with the Deep Deterministic Policy Gradients (DDPG) algorithm in the same situation. In order to make a robot to arrive at a target in an environment, both networks have 10 laser range findings, the previous linear and angular velocity, and relative position and angle of the mobile robot to the target are used as the network inputs. As outputs, the networks have the linear and angular velocity of the mobile robot. The reward function created was designed in a way to only give a positive reward to the agent when it gets to the target and a negative reward when colliding with any object. The proposed architecture was applied successfully in two simulated environments, and a comparison between the two referred techniques was made using the results obtained as a basis and it was demonstrated that the SAC algorithm has a superior performance for the navigation of mobile robots than the DDPG algorithm (Code available at https://github.com/dranaju/project ).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01367-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01385-3,6D Localization and Kicking for Humanoid Robotic Soccer,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01385-3,Springer,2021-05-12,"Robotic soccer simulation is a challenging area, where the development of new techniques is paramount to remain competitive. Robotic skill evolution has accelerated with recent developments in deep learning algorithms, leading to improvements in behavior number and complexity. Shooting a ball towards a defined target is one of the most basic yet indispensable skills in soccer. However, fast and accurate kicks pose several challenges. In order to reach that target, the skill is highly dependent on the ability of the agent to self-locate and self-orient, in order to better position itself before the kick. To tackle these issues, a 6D localization technique was devised. To optimize the kick behavior, two scenarios were proposed. In the first, the robot walks to the ball, stops, and then kicks. In the second, it kicks the ball while moving. We used state-of-the-art algorithms — Proximal Policy Optimization and Soft Actor Critic — to solve these complex problems and show their applicability in the context of RoboCup. Obtained results have shown very significant improvements over previously used behaviors by FC Portugal 3D team. The new kick in motion executes 5 times faster than the previous kick, and the new 6D pose estimator has an average error of just 6.3mm, a reduction of more than 97 % .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01385-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-020-00662-y,Automatic analog meter reading for plant inspection using a deep neural network,Artificial Life and Robotics,10.1007/s10015-020-00662-y,Springer,2021-05-01,"The high demand for automatic plant inspections by robots has been because a plant has many dangerous locations to cover during daily inspections. In this study, we propose automatically reading an analog meter using a Deep Neural Network (DNN), because reading an analog meter is included in the daily inspections. In particular, we artificially generate training data including shooting noise and apply these data for training the DNN. The learned DNN is robust against readable angles, meter contamination, and meter light reflection, and achieves a reading absolute error within 0.05. Additionally, we verify the effectiveness of the proposed method using cross-validation and accuracy comparison with conventional methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-020-00662-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12626-021-00067-8,Robots and AI Artifacts in Plural Perspective(s) of Japan and the West: The Cultural–Ethical Traditions Behind People’s Views on Robots and AI Artifacts in the Information Era,The Review of Socionetwork Strategies,10.1007/s12626-021-00067-8,Springer,2021-05-01,"In this paper, we examine the meanings of robots and AI artifacts in our societies and cultures, in particular the question: ‘How do Japanese people and Western people understand and interpret the phenomena and problems happening around them such as human–robot interaction, the encounter with AI, especially regarding plurality of meanings and wholeness of life experience in the information era?’ This is a kind of topic of information ethics or IIE (intercultural information ethics) in a broad sense. We focus our attention on world views in the informatized environments by examining the related views and theories as well as our own empirical research. In addition to these points, we will compare Japanese survey data with data from other cultural–social traditions and we will examine how the Japanese ways of seeing matters and their emphasis on the matters in process of awareness can be considered to have potentially universal connotations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12626-021-00067-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43681-020-00023-2,"If robots are people, can they be made for profit? Commercial implications of robot personhood",AI and Ethics,10.1007/s43681-020-00023-2,Springer,2021-05-01,"It could become technologically possible to build artificial agents instantiating whatever properties are sufficient for personhood. It is also possible, if not likely, that such beings could be built for commercial purposes. This paper asks whether such commercialization can be handled in a way that is not morally reprehensible, and answers in the affirmative. There exists a morally acceptable institutional framework that could allow for building artificial persons for commercial gain. The paper first considers the minimal ethical requirements that any system of commercial production of such artificial persons would have to meet. It then shows that it is possible for these requirements to be met, and that doing so will make the commercial production of artificial persons permissible. Lastly, it briefly presents one potential blueprint for how such a framework could look like—inspired by the real-world model of compensating the training of athletes—and then addresses some objections to the view.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43681-020-00023-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-020-05426-0,Privacy-preserving image multi-classification deep learning model in robot system of industrial IoT,Neural Computing and Applications,10.1007/s00521-020-05426-0,Springer,2021-05-01,"Deep learning in robot systems is a popular application that can learn and train the results per requirements, but that collects sensitive information in the training process, easily causing leakage of users’ private information. To date, privacy-preserving deep learning models in robot systems have been sparsely researched. To solve the privacy leakage problem of deep learning in robot systems and fill the gap in robotics deep learning privacy research, in this paper a novel privacy-preserving image multi-classification deep-learning (PIDL) model in robot systems is presented. In PIDL, two schemes are proposed that adopt two groups of encrypted activation and cost functions—sigmoid plus cross-entropy function (PIDLSC) and softmax plus log-likelihood function (PIDLSL)—with secure calculation protocols, which are applied in a fog control center (FCC) with a non-colluding honest server by homomorphic encryption to improve the training efficiency, solve the encryption computation questions, and protect data and model privacy in robot systems. Security analysis and performance evaluation demonstrate that the proposed schemes realize security, correctness, and efficiency with low communication and computational costs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-020-05426-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-021-10673-x,Cost-effective real-time recognition for human emotion-age-gender using deep learning with normalized facial cropping preprocess,Multimedia Tools and Applications,10.1007/s11042-021-10673-x,Springer,2021-05-01,"Because of technological advancement, human face recognition has been commonly applied in various fields. There are some HCI-related applications, such as camera-ready chatbot and companion robot, require gathering more information from user’s face. In this paper, we developed a system called EAGR for emotion, age, and gender recognition, which can perceive user’s emotion, age and gender based on the face detection. The EAGR system first applies normalized facial cropping (NFC) as a preprocessing method for training data before data augmentation, then uses convolution neural network (CNN) as three training models for recognizing seven emotions (six basics plus one neutral emotion), four age groups, and two genders. For better emotion recognition, the NFC will extract facial features without hair retained. On the other hand, the NFC will extract facial features with hair retained for better age and gender recognition. The experiments were conducted on these three training models of emotion, age and gender recognitions. The recognition performance results from the testing dataset, which has been normalized for tilted head by proposed binocular line angle correction (BLAC), showed that the optimal mean accuracy rates of real-time recognition for seven emotions, four age groups and two genders were 82.4%, 74.95%, and 96.65% respectively. Furthermore, the training time can be substantially reduced via NFC preprocessing. Therefore, we believe that EAGR system is cost-effective in recognizing human emotions, ages, and genders. The EAGR system can be further applied in social applications to help HCI service provide more accurate feedback from pluralistic facial classifications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11042-021-10673-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43681-020-00009-0,Responsible AI and moral responsibility: a common appreciation,AI and Ethics,10.1007/s43681-020-00009-0,Springer,2021-05-01,"Responsibility is among the most widespread buzzwords in the ethics of artificial intelligence (AI) and robotics. Yet, the term often remains unsubstantiated when employed in these important technological domains. Indeed, notions like ‘responsible AI’ and ‘responsible robotics’ may sound appealing, for they seem to convey a sense of moral goodness or ethical approval, thereby inciting psychological connections to self-regulation, social acceptance, or political correctness. For AI and ethics to come together in truly harmonious ways, we will need to work toward establishing a common appreciation. In this commentary, I breakdown three varieties of the term and invoke insights from the analytic ethics literature as a means of offering a robust understanding of moral responsibility in emerging technology. While I do not wish to accuse any parties of incorrect usage, my hope is that together researchers in AI and ethics can be better positioned to appreciate and to develop notions of responsibility for technological domains.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43681-020-00009-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-021-09981-w,A fully distributed multi-robot navigation method without pre-allocating target positions,Autonomous Robots,10.1007/s10514-021-09981-w,Springer,2021-05-01,"This study focuses on the multi-robot navigation problem with unpredictable state transition disturbance. The primary goal is to construct a fully distributed multi-robot navigation method without pre-allocating target positions. To this aim, a reinforcement learning based method is presented, in which a distribution of state transition module is proposed to guarantee adaptiveness when trained policies are applied in physical multi-robot systems. The method incorporates a centralized training but fully distributed execution framework. The former can eliminate non-stationarity of the environment, and the latter enables the robots to collaboratively handle partially observable scenarios. Mean while, the designed reward function can guide the robots to approach not pre-allocated target positions and the nearly optimal trajectories are achieved in continuous environment. After training, the robots make decisions independently, coordinate, and cooperate with each other to determine the next actions from their current positions before arriving in target positions without pre-allocation, in which the trajectories are nearly optimal with partial observation available for each robot. Simulations are performed with increasingly complex environments, such as the addition of static obstacles and randomly moving obstacles. The results show that the robots are able to achieve the primary goal with different state transition disturbance, which demonstrates the feasibility, effectiveness, and robustness. Furthermore, experiments are carried out using our multi-robot system corresponding to the simulation. The experimental results demonstrate the effectiveness and robustness of the proposed navigation method to handle a variety of typical robotic scenarios.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-021-09981-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/s42256-021-00320-3,Real-world embodied AI through a morphologically adaptive quadruped robot,Nature Machine Intelligence,10.1038/s42256-021-00320-3,Nature,2021-05-01,"Robots are traditionally bound by a fixed morphology during their operational lifetime, which is limited to adapting only their control strategies. Here we present the first quadrupedal robot that can morphologically adapt to different environmental conditions in outdoor, unstructured environments. Our solution is rooted in embodied AI and comprises two components: (1) a robot that permits in situ morphological adaptation and (2) an adaptation algorithm that transitions between the most energy-efficient morphologies on the basis of the currently sensed terrain. We first build a model that describes how the robot morphology affects performance on selected terrains. We then test continuous adaptation on realistic outdoor terrain while allowing the robot to constantly update its model. We show that the robot exploits its training to effectively transition between different morphological configurations, exhibiting substantial performance improvements over a non-adaptive approach. The demonstrated benefits of real-world morphological adaptation demonstrate the potential for a new embodied way of incorporating adaptation into future robotic designs. The morphology of a robot determines how efficiently it can traverse different terrain. Nygaard and colleagues present here a robot that can adapt it’s morphology when it is detecting different terrain and learn which configuration is most effective.",https://www.nature.com/articles/s42256-021-00320-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11548-021-02343-y,Cross-modal self-supervised representation learning for gesture and skill recognition in robotic surgery,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-021-02343-y,Springer,2021-05-01,"Purpose Multi- and cross-modal learning consolidates information from multiple data sources which may offer a holistic representation of complex scenarios. Cross-modal learning is particularly interesting, because synchronized data streams are immediately useful as self-supervisory signals. The prospect of achieving self-supervised continual learning in surgical robotics is exciting as it may enable lifelong learning that adapts to different surgeons and cases, ultimately leading to a more general machine understanding of surgical processes. Methods We present a learning paradigm using synchronous video and kinematics from robot-mediated surgery. Our approach relies on an encoder–decoder network that maps optical flow to the corresponding kinematics sequence. Clustering on the latent representations reveals meaningful groupings for surgeon gesture and skill level. We demonstrate the generalizability of the representations on the JIGSAWS dataset by classifying skill and gestures on tasks not used for training. Results For tasks seen in training, we report a 59 to 70% accuracy in surgical gestures classification. On tasks beyond the training setup, we note a 45 to 65% accuracy. Qualitatively, we find that unseen gestures form clusters in the latent space of novice actions, which may enable the automatic identification of novel interactions in a lifelong learning scenario. Conclusion From predicting the synchronous kinematics sequence, optical flow representations of surgical scenes emerge that separate well even for new tasks that the model had not seen before. While the representations are useful immediately for a variety of tasks, the self-supervised learning paradigm may enable research in lifelong and user-specific learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-021-02343-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12559-020-09716-6,SOAR Improved Artificial Neural Network for Multistep Decision-making Tasks,Cognitive Computation,10.1007/s12559-020-09716-6,Springer,2021-05-01,"Recently, artificial neural networks (ANNs) have been applied to various robot-related research areas due to their powerful spatial feature abstraction and temporal information prediction abilities. Decision-making has also played a fundamental role in the research area of robotics. How to improve ANNs with the characteristics of decision-making is a challenging research issue. ANNs are connectionist models, which means they are naturally weak in long-term planning, logical reasoning, and multistep decision-making. Considering that a small refinement of the inner network structures of ANNs will usually lead to exponentially growing data costs, an additional planning module seems necessary for the further improvement of ANNs, especially for small data learning. In this paper, we propose a state operator and result (SOAR) improved ANN (SANN) model, which takes advantage of both the long-term cognitive planning ability of SOAR and the powerful feature detection ability of ANNs. It mimics the cognitive mechanism of the human brain to improve the traditional ANN with an additional logical planning module. In addition, a data fusion module is constructed to combine the probability vector obtained by SOAR planning and the original data feature array. A data fusion module is constructed to convert the information from the logical sequences in SOAR to the probabilistic vector in ANNs. The proposed architecture is validated in two types of robot multistep decision-making experiments for a grasping task: a multiblock simulated experiment and a multicup experiment in a real scenario. The experimental results show the efficiency and high accuracy of our proposed architecture. The integration of SOAR and ANN is a good compromise between logical planning with small data and probabilistic classification with big data. It also has strong potential for more complicated tasks that require robust classification, long-term planning, and fast learning. Some potential applications include recognition of grasping order in multiobject environment and cooperative grasping of multiagents.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12559-020-09716-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12626-021-00071-y,We Mostly Think Alike: Individual Differences in Attitude Towards AI in Sweden and Japan,The Review of Socionetwork Strategies,10.1007/s12626-021-00071-y,Springer,2021-05-01,"Attitudes towards artificial intelligence (AI) and social robots are often depicted as different in Japan, compared to other western countries, such as Sweden. Several different reasons for why there are general differences in attitudes have been suggested. In this study, five hypotheses based on previous literature were investigated. Rather than attempting to establish general differences between groups, subjects were sampled from the respective populations, and correlations between the hypothesized confounding factors and attitudes were investigated within the groups between individuals. The hypotheses in this exploratory study concerned: (H1) animistic beliefs in inanimate objects and phenomena, (H2) worry about unemployment due to AI deployment, (H3) perceived positive or negative portrayal of AI in popular culture, (H4) familiarity with AI, and (H5) relational closeness and privacy with AI. No clear correlations between attitudes and animistic belief (H1), or portrayal of AI in popular culture (H3) could be observed. When it comes to the other attributes, worry about unemployment (H2), familiarity with AI (H4), and relational closeness and privacy (H5), the correlations were similar for the individuals in both groups and in line with the hypotheses. Thus, the general picture following this exploratory study is that individuals in the two populations are more alike than different.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12626-021-00071-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-020-05536-9,Decoding movement intent patterns based on spatiotemporal and adaptive filtering method towards active motor training in stroke rehabilitation systems,Neural Computing and Applications,10.1007/s00521-020-05536-9,Springer,2021-05-01,"Upper extremity (UE) neuromuscular dysfunction critically affects post-stroke patients from performing activities of daily life. In this regard, various rehabilitation robotics have been developed for providing assistive and/or resistive forces that allow stroke survivors to train their arms towards regaining the lost arm function. However, most of the rehabilitation systems function in a passively such that they only allow patients navigate already-defined trajectories that often does not align with their UE movement intention, thus hindering adequate motor function recovery. One possible way to address this problem is to use a decoded UE motion intent to trigger active and intuitive motor training for the patients, which would help restore their UE arm functions. In this study, a new approach based on spatiotemporal neuromuscular descriptor and adaptive filtering technique (STD-AFT) is proposed to optimally characterize multiple patterns of UE movements in post-stroke patients towards providing inputs for intelligently driven motor training in the rehabilitation robotic systems. The proposed STD-AFT performance was systematically investigated and assessed in comparison with commonly adopted methods via high-density surface electromyogram recordings obtained from post-stroke survivors who performed 21 distinct classes of pre-defined limb movements. Furthermore, the movement intent decoding was done using four different classification algorithms. The experimental results showed that the proposed STD-AFT achieved significant improvement of up to 13.36% ( p  < 0.05) in characterizing the multiple patterns of movement intents with relatively lower standard-error value even in the presence of the external interference in form of noise compared to the existing benchmark methods. Also, the STD-AFT showed obvious pattern seperability for individual movement class in a two-dimensional space. The outcomes of this study suggest that the proposed STD-AFT could provide potential inputs for active and intuitive motor training in robotic systems targeted towards stroke-rehabilitation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-020-05536-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-021-00573-0,Integrated Commonsense Reasoning and Deep Learning for Transparent Decision Making in Robotics,SN Computer Science,10.1007/s42979-021-00573-0,Nature,2021-04-29,"A robot’s ability to provide explanatory descriptions of its decisions and beliefs promotes effective collaboration with humans. Providing the desired transparency in decision making is challenging in integrated robot systems that include knowledge-based reasoning methods and data-driven learning methods. As a step towards addressing this challenge, our architecture combines the complementary strengths of non-monotonic logical reasoning with incomplete commonsense domain knowledge, deep learning, and inductive learning. During reasoning and learning, the architecture enables a robot to provide on-demand explanations of its decisions, the evolution of associated beliefs, and the outcomes of hypothetical actions, in the form of relational descriptions of relevant domain objects, attributes, and actions. The architecture’s capabilities are illustrated and evaluated in the context of scene understanding tasks and planning tasks performed using simulated images and images from a physical robot manipulating tabletop objects. Experimental results indicate the ability to reliably acquire and merge new information about the domain in the form of constraints, preconditions, and effects of actions, and to provide accurate explanations in the presence of noisy sensing and actuation.",https://www.nature.com/articles/s42979-021-00573-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-021-00630-8,Fully Responsive Image and Speech Detection Artificial Yankee (FRIDAY): Human Assistant,SN Computer Science,10.1007/s42979-021-00630-8,Nature,2021-04-29,"A Human Assistant is one which aids any person in accomplishing a task in his routine without the person himself carrying it out solitarily. Given a Human Assistant the vision and the ability to communicate with humans through speech, it becomes more utilitarian and can be used in much more advanced tasks. The key idea of this paper is building a system by incorporating existing processing algorithms which are modified to provide a modeled humanoid with vision and Human–Robot Interaction (HRI) making it carry out function as a human assistant in general. In particular to the experiment carried out here, different processing algorithms are built onto a simple yet capable microprocessor and enabling the machine that this system is built onto to navigate in a confined terrain by detecting objects through camera, detect short texts through the camera and also carry out certain tasks in response to the HRI through speech. This paper also provides a possible solution to incorporate speech and image processing on a simple processor without overloading it using the concept of distributed processing.",https://www.nature.com/articles/s42979-021-00630-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-021-00627-3,Design and Development of a Humanoid Robot for Sign Language Interpretation,SN Computer Science,10.1007/s42979-021-00627-3,Nature,2021-04-20,"Purpose With an indisputable complexity of communication for hearing and speaking impaired people, most sign language recognition systems utilize virtual reality or onscreen robots. This paper presents the design and development of a special and low-cost humanoid robot that can perform as a sign language interpreter. To the best of our knowledge, this is the first endeavor to fabricate a humanoid robot for Bangla sign language (BdSL) and Medical signs interpretation. Methods Considering the plethora of design criteria and balancing between rigidity and flexibility 3D models of the robotics parts are designed and 3D printed ensuring cost efficiency. With the help of modern fabrication technology, the robot is developed and assembled with proper actuators and circuitry. An image dataset is built comprising 950 images for BdSL recognition and made publicly available. We utilized the Recurrent neural network (RNN) and Convolutional neural network (CNN) for deep learning model establishment and feature extraction from video and image data. Results The developed humanoid robot has 43 Degrees of freedom (DoF) which includes two 15 DoF hands. It can imitate 16 BdSL alphabets in sign language, can capture a video or image input in real-time from the user, and recognize 10 medical signs and 38 alphabets of BdSL. The learning model for video-based medical sign recognition achieved 87.5% test accuracy. Image-based Bangla sign language recognition achieved an overall test accuracy of 98.19% in our dataset and 93.8% in another available dataset. Conclusion Compared to the state-of-the-art robotic systems for sign language interpretation, our approach has achieved higher kinematic characteristics, remarkable results in sign recognition, and impressive competency in sign imitation; all at almost 10 times lower cost than the state-of-the-art systems. The results are evidence that our approach is efficient and suitable in helping hearing and speaking impaired people. Moreover, this work initiates a research scope that can be further extended for creating equal opportunities for the hearing and speaking impaired community.",https://www.nature.com/articles/s42979-021-00627-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11948-021-00306-9,"Rights for Robots: Artificial Intelligence, Animal and Environmental Law (2020) by Joshua Gellers",Science and Engineering Ethics,10.1007/s11948-021-00306-9,Springer,2021-04-19,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-021-00306-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-021-05972-1,Fully neural object detection solutions for robot soccer,Neural Computing and Applications,10.1007/s00521-021-05972-1,Springer,2021-04-15,"RoboCup is one of the major global AI events, gathering hundreds of teams from the world’s best universities to compete in various tasks ranging from soccer to home assistance and rescue. The commonality of these three seemingly dissimilar tasks is that in order to perform well, the robot needs to excel at the all major AI tasks: perception, control, navigation, strategy and planning. In this work, we focus on the first of these by presenting what is—to our knowledge—the first fully neural vision system for the Nao robot soccer. This is a challenging task, mainly due to the limited computational capabilities of the Nao robot. In this paper, we propose two novel neural network architectures for semantic segmentation and object detection that ensure low-cost inference, while improving accuracy by exploiting the properties of the environment. These models use synthetic transfer learning to be able to learn from a low number of hand-labeled images. The experiments show that our models outperform state-of-the-art methods such as Tiny YOLO at a fraction of the cost.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-021-05972-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42452-021-04508-5,Neural dynamics based complete grid coverage by single and multiple mobile robots,SN Applied Sciences,10.1007/s42452-021-04508-5,Nature,2021-04-08,"Navigation of mobile robots in a grid based environment is useful in applications like warehouse automation. The environment comprises of a number of free grid cells for navigation and remaining grid cells are occupied by obstacles and/or other mobile robots. Such obstructions impose situations of collisions and dead-end. In this work, a neural dynamics based algorithm is proposed for complete coverage of a grid based environment while addressing collision avoidance and dead-end situations. The relative heading of the mobile robot with respect to the neighbouring grid cells is considered to calculate the neural activity. Moreover, diagonal movement of the mobile robot through inter grid cells is restricted to ensure safety from the collision with obstacles and other mobile robots. The circumstances where the proposed algorithm will fail to provide completeness are also discussed along with the possible ways to overcome those situations. Simulation results are presented to show the effectiveness of the proposed algorithm for a single and multiple mobile robots. Moreover, comparative studies illustrate improvements over other algorithms on collision free effective path planning of mobile robots within a grid based environment.",https://www.nature.com/articles/s42452-021-04508-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-021-00581-0,On the Performance Analyses of a Modified Force Field Algorithm and Neural Network Approach for Obstacle Avoidance in Swarm Robotics,SN Computer Science,10.1007/s42979-021-00581-0,Nature,2021-04-08,"Obstacle avoidance is a major hurdle when implementing mobile robots and swarm robots. Swarm robots work in groups and therefore require an efficient and functional obstacle avoidance algorithm to stay collision free between themselves and their surroundings. This paper reviews previous research in obstacle avoidance implementation using the force field method (FFM), also known as potential field method (PFM) and a neutral network approach. Moreover, this paper aims to execute simulations using a modified force field algorithm and a neural network approach and compare them. The obtained results are analyzed to identify the performance characteristics and the time taken to perform tasks using a singular mobile robot against a swarm robot environment consisting of four and ten robots, respectively, in both simulation cases. Simulations showed that the algorithm was successful in navigating obstacles for both single and swarm robot environments. A single robot was found to take up to 340% longer to arrive at the required location compared to the first robot in the experiment. Moreover, it was found that the neural network approach showed ~ 27% improvement over the modified force field algorithm when it comes to cases where more than four robots are being used.",https://www.nature.com/articles/s42979-021-00581-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11277-021-08073-3,An Optimal Approach to Enhance Context Aware Description Administration Service for Cloud Robots in a Deep Learning Environment,Wireless Personal Communications,10.1007/s11277-021-08073-3,Springer,2021-04-01,"As the advancements in the field of artificial intelligence technologies continue to grow, robots are being built by the researchers as an attempt to render services to the people. In this regard, the robots can communicate effectively with the people and be able to complete all the tasks adequately given to them. These service robots while being developed requires the dialogue services to be developed to interact effectively with human beings providing far better user experience. Thus, the robot been built can provide domain-specific knowledge as well as able to provide consultations in various domains. We in this paper adopted a service-oriented approach for developing context-aware communication services for the cloud robot. The proposed work aims at training the context-aware model developed. The context-aware model is responsible for answering the questions put forward by the users and possess the ability to exploit the answers corresponding to the questions presented. An integrated framework is used to combine the contextual information and communication services. The performance of the proposed model can be evaluated based on Inverse Rank Mean (IRM). Evolutionary testing methods are used for testing the data in the proposed model. The results thus obtained shows the effectiveness of the proposed approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11277-021-08073-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-020-00636-x,"Evaluating the Co-dependence and Co-existence between Religion and Robots: Past, Present and Insights on the Future",International Journal of Social Robotics,10.1007/s12369-020-00636-x,Springer,2021-04-01,"The relationship between religions and science can be considered historically controversial in nature. In constantly evolving global societies, it is important to provide a new perspective on the past and present relationship between religions and technological developments in the different societies. In this regard, this paper will provide insights into the different ways in which ancient societies and their religious traditions helped in the development of technological progress. At one end, it will highlight some of the positive contributions of different religions towards technological progress in the past. At the other end, this discussion will aid in dispelling the viewpoint that perceived the ancient cultures and societies as bereft of technological knowledge and innovation. This paper will provide a historical perspective on the development of relationship between religion and robotics in the past. A brief look at the existing scenario within the contemporary societies will also be examined, along with discussion of socio-cultural norms and values related to perception of robots in different Eastern and Western cultures. The discussion will conclude with some predictions regarding the future, along with the different ways in which the relationship of co-existence and co-dependence is expected to evolve between religion and robotics in the future, which goes beyond the predictions of mass annihilation and mass enslavement by sentient AI-based robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-020-00636-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-019-1004-6,Adaptive Control for Uncertain Model of Omni-directional Mobile Robot Based on Radial Basis Function Neural Network,"International Journal of Control, Automation and Systems",10.1007/s12555-019-1004-6,Springer,2021-04-01,"The paper proposes the method to deal with control problems of unmodeled components of the four-wheeled Omni-directional mobile robot. It is commonly challenging to design a model-based control scheme to achieve smooth movement in the tracking process due to the unknown elements in the mathematical model of the robot or external disturbances. Our main contribution focuses on designing an adaptive controller based on neural networks with online weight updating laws and Fuzzy logic to guarantee the high accuracy of the robot’s movement when the unknown factors adversely affect the robot control. At the initial step, a Dynamic Surface Control plays a role as a core of the controller for the robot system. Then, with the ability to estimate the appropriate value for uncertain nonlinear parts, a Radial Basis Function Neural Network is designed. Finally, a Fuzzy law is to utilize control parameters in each period to increase the adaptive behavior of the system. The stability and convergence of the system are proven by the Lyapunov’s stability theory. The simulation results illustrate the validity and the efficiency of the proposed control algorithm when the system is lack of robot model’s information.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-019-1004-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-021-00358-7,Combining CNN and LSTM for activity of daily living recognition with a 3D matrix skeleton representation,Intelligent Service Robotics,10.1007/s11370-021-00358-7,Springer,2021-04-01,"In socially assistive robotics, human activity recognition plays a central role when the adaptation of the robot behavior to the human one is required. In this paper, we present an activity recognition approach for activities of daily living based on deep learning and skeleton data. In the literature, ad hoc features extraction/selection algorithms with supervised classification methods have been deployed, reaching an excellent classification performance. Here, we propose a deep learning approach, combining CNN and LSTM, that exploits both the learning of spatial dependencies correlating the limbs in a skeleton 3D grid representation and the learning of temporal dependencies from instances with a periodic pattern that works on raw data and so without requiring an explicit feature extraction process. These models are proposed for real-time activity recognition, and they are tested on the CAD-60 dataset. Results show that the proposed model behaves better than an LSTM model thanks to the automatic features extraction of the limbs’ correlation. “New Person” results show that the CNN-LSTM model achieves $$95.4\%$$ 95.4 % of precision and $$94.4\%$$ 94.4 % of recall, while the “Have Seen” results are $$96.1\%$$ 96.1 % of precision and $$94.7\%$$ 94.7 % of recall.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-021-00358-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-020-01766-w,Toward intelligent continuous assistance,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-020-01766-w,Springer,2021-04-01,"Technology supported assistance is a research area dedicated to support both older adults and, at some level, their caregivers in a variety of situations and contexts. A number of projects doing detailed evaluation both with robots and/or ICT-based intelligent devices have identified as open challenges the need to guarantee both continuity and variability of service according to context interpretation. This paper starts from the willingness to study how both continuity and variability can be pursued by leveraging and integrating results from research areas like artificial intelligence (AI), cognitive systems, psychology and sensor networks. Some of these technological skills are needed for example by an assistive robot and still represent open challenges in AI. This paper presents a medium term research initiative aiming at synthesizing an enhanced (intelligent) control architecture for assistive robots that take advantage from the continuous flow of information provided by a sensor network. The paper presents two main results: (a) starting from the analysis of requirements coming from the real world, it envisages a conceptual cognitive architecture highlighting the functional requirements and the key capabilities characterizing an “ideal” intelligent assistive robot; (b) it presents a prototype of a testbed architecture called KOaLa (Knowledge-based cOntinuous Loop) which integrates sensor data representation, knowledge reasoning and decision making capabilities showing its novelty in a realistic scenario.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-020-01766-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-020-0069-6,Positioning of the Robotic Arm Using Different Reinforcement Learning Algorithms,"International Journal of Control, Automation and Systems",10.1007/s12555-020-0069-6,Springer,2021-04-01,"Robots are programmed using either the on-line mode, in which the robot programmer manually controls the movement of the robot indicating individual trajectory points or the off mode, in which the programmer enters the program code with predefined trajectory points. Both methods are not easy to be successfully implemented in practice, which is why the research on the development of self-learning methods can be useful. In this paper, for the robot’s positioning task, the four Reinforcement Learning (RL) algorithms in six combinations are investigated. At first, the basics of these algorithms are described. Then they are used in positioning control of the robot’s arm model and the evaluation of positioning accuracy, motion trajectory, and the number of steps required to achieve the goal is taken into account. The simulation results are recorded. The same tests were repeated in laboratory conditions, in which the Mitsubishi robot was controlled. The simulation results are compared with results obtained in reality. Positive results that have been obtained indicate, that the RL algorithms can be successfully applied for the learning of positioning control of a robot arm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-020-0069-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-019-01595-6,Mood classification through physiological parameters,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-019-01595-6,Springer,2021-04-01,"Future smart agents, like robots, should produce personalized behaviours based on user emotions and moods to fit more in ordinary users’ activities. Besides, the emotions are also linked to human cognitive systems, thus their monitoring could be extremely useful in the case of neurodegenerative diseases such as dementia and Alzheimer. Literature works propose the use of music tracks and videos to stimulate emotions, and cameras to recorder the evoked reactions in human beings. However, these approaches may not be effective in everyday life, due to camera obstructions and different types of stimulation which can be related also with the interaction with other human beings. In this work, we investigate the Electrocardiogram, the ElectroDermal Activity and the Brain Activity signals as main informative channels, acquired through a wireless wearable sensor network. An experimental methodology was built to induce three different emotional states through social interaction. Collected data were classified with three supervised machine learning approaches with different kernels (Support Vector Machine, Decision Tree and k-nearest neighbour) considering the valence dimension and a combination of valence and arousal dimension evoked during the interaction. 34 healthy young participants were involved in the study and a total of 239 instances were analyzed. The supervised algorithms achieve an accuracy of 0.877 in the best case.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-019-01595-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11063-021-10440-x,A Vary-Parameter Convergence-Accelerated Recurrent Neural Network for Online Solving Dynamic Matrix Pseudoinverse and its Robot Application,Neural Processing Letters,10.1007/s11063-021-10440-x,Springer,2021-04-01,"Among this study, a vary-parameter convergence-accelerated neural network (VPCANN) model is generalized to solving dynamic matrix pseudoinverse, which can achieve super exponential convergence and noise-resistant, compared to the traditional Zhang neural network (ZNN) designed for dynamic problems. Simulative experiments reveal that the neural state solutions synthesized by the VPCANN can quickly approach to the theoretical pseudoinverse. Moreover, based on three types of noise disturbance including constant noise, random noise and dynamic noise, comparisons between the VPCANN and ZNN model are also investigated, verifying noise-resistant of the VPCANN model is better than the ZNN. In addition, to show the potential application of the VPCANN in practice, the kinematic motion planning of a six-links robot manipulator is considered, further substantiating the efficacy of the VPCANN in the dynamic matrix pseudoinverse.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-021-10440-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13346-021-00929-2,"Robotics, microfluidics, nanotechnology and AI in the synthesis and evaluation of liposomes and polymeric drug delivery systems",Drug Delivery and Translational Research,10.1007/s13346-021-00929-2,Springer,2021-04-01,"The field of nanotechnology and personalised medicine is undergoing drastic changes in the approach and efficiency of experimentation. The COVID-19 pandemic has spiralled into mass stagnation of major laboratories around the globe and led to increased investment into remote systems for nanoparticle experiments. A significant number of laboratories now operate using automated systems; however, the extension to nanoparticle preparation and artificial intelligence–dependent databases holds great translational promise. The strive to combine automation with artificial intelligence (AI) grants the ability to optimise targeted therapeutic nanoparticles for unique cell types and patients. In this perspective, the current and future trends of automated approaches to nanomedicine synthesis are discussed and compared with traditional methods. Graphical abstract ",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13346-021-00929-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40747-021-00341-w,Lower limb movement intention recognition for rehabilitation robot aided with projected recurrent neural network,Complex & Intelligent Systems,10.1007/s40747-021-00341-w,Springer,2021-03-30,"For the lower limb rehabilitation robot, how to better realize intention recognition is the key issue in the practical application. Recognition of the patient’s movement intention is a challenging research work, which needs to be studied from the shallow to the deep. Specifically, it is necessary to ensure that the movement intention of the normal person can be accurately recognized, and then improve the model to realize the recognition of the movement intention of the patients. Therefore, before studying the patient’s movement intention, it is essential to consider the normal person first, which is also for safety considerations. In recent years, a new Hill-based muscle model has been demonstrated to be capable of directly estimating the joint angle intention in an open-loop form. On this basis, by introducing a recurrent neural network (RNN), the whole prediction process can achieve more accuracy in a closed-loop form. However, for the traditional RNN algorithms, the activation function must be convex, which brings some limitations to the solution of practical problems. Especially, when the convergence speed of the traditional RNN model is limited in the practical applications, as the error continues to decrease, the convergence performance of the traditional RNN model will be greatly affected. To this end, a projected recurrent neural network (PRNN) model is proposed, which relaxes the condition of the convex function and can be used in the saturation constraint case. In addition, the corresponding theoretical proof is given, and the PRNN method with saturation constraint has been successfully applied in the experiment of intention recognition of lower limb movement compared with the traditional RNN model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40747-021-00341-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-021-00572-1,A Follow-the-Leader Strategy Using Hierarchical Deep Neural Networks with Grouped Convolutions,SN Computer Science,10.1007/s42979-021-00572-1,Nature,2021-03-18,"The task of following-the-leader is implemented using a hierarchical deep neural network (DNN) end-to-end driving model to match the direction and speed of a target pedestrian. The model uses a classifier DNN to determine if the pedestrian is within the field of view of the camera sensor. If the pedestrian is present, the image stream from the camera is fed to a regression DNN which simultaneously adjusts the autonomous vehicle’s steering and throttle to keep cadence with the pedestrian. If the pedestrian is not visible, the vehicle uses a straightforward exploratory search strategy to reacquire the tracking objective. The classifier and regression DNNs incorporate grouped convolutions to boost model performance as well as to significantly reduce parameter count and compute latency. The models are trained on the intelligence processing unit (IPU) to leverage its fine-grain compute capabilities to minimize time-to-train. The results indicate very robust tracking behavior on the part of the autonomous vehicle in terms of its steering and throttle profiles, while requiring minimal data collection to produce. The throughput in terms of processing training samples has been boosted by the use of the IPU in conjunction with grouped convolutions by a factor $$\sim \,3.5$$ ∼ 3.5 for training of the classifier and a factor of $$\sim \,7$$ ∼ 7 for the regression network. A recording of the vehicle tracking a pedestrian has been produced and is available on the web.",https://www.nature.com/articles/s42979-021-00572-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42452-021-04376-z,Switched time delay control based on artificial neural network for fault detection and compensation in robot manipulators,SN Applied Sciences,10.1007/s42452-021-04376-z,Nature,2021-03-06,"This work proposes a switched time delay control scheme based on neural networks for robots subjected to sensors faults. In this scheme, a multilayer perceptron ( MLP ) artificial neural network ( ANN ) is introduced to reproduce the same behavior of a robot in the case of no faults. The reproduction characteristic of the MLP s allows instant detection of any important sensor faults. In order to compensate the effects of these faults on the robot’s behavior, a time delay control ( TDC ) procedure is presented. The proposed controller is composed of two control laws: The first one contains a small gain applied to the faultless robot, while the second scheme uses a high gain that is applied to the robot subjected to faults. The control method applied to the system is decided based on the ANN detection results which switches from the first control law to the second one in the case where an important fault is detected. Simulations are performed on a SCARA arm manipulator to illustrate the feasibility and effectiveness of the proposed controller. The results demonstrate that the free-model aspect of the proposed controller makes it highly suitable for industrial applications.",https://www.nature.com/articles/s42452-021-04376-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s40648-021-00196-3,EKF-based self-attitude estimation with DNN learning landscape information,ROBOMECH Journal,10.1186/s40648-021-00196-3,Springer,2021-03-06,"This paper presents an EKF-based self-attitude estimation with a DNN (deep neural network) learning landscape information. The method integrates gyroscopic angular velocity and DNN inference in the EKF. The DNN predicts a gravity vector in a camera frame. The input of the network is a camera image, the outputs are a mean vector and a covariance matrix of the gravity. It is trained and validated with a dataset of images and corresponded gravity vectors. The dataset is collected in a flight simulator because we can easily obtain various gravity vectors, although the method is not only for UAVs. Using a simulator breaks the limitation of amount of collecting data with ground truth. The validation shows the network can predict the gravity vector from only a single shot image. It also shows that the covariance matrix expresses the uncertainty of the inference. The covariance matrix is used for integrating the inference in the EKF. Flight data of a drone is also recorded in the simulator, and the EKF-based method is tested with it. It shows the method suppresses accumulative error by integrating the network outputs.",https://www.biomedcentral.com/openurl?doi=10.1186/s40648-021-00196-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01327-z,A Survey of Machine Learning Techniques for Indoor Localization and Navigation Systems,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01327-z,Springer,2021-03-04,"In the recent past, we have witnessed the adoption of different machine learning techniques for indoor positioning applications using WiFi, Bluetooth and other technologies. The techniques range from heuristically derived hand-crafted feature-based traditional machine learning algorithms, feature selection algorithms to the hierarchically self-evolving feature-based Deep Learning algorithms. The transient and chaotic nature of the WiFi/Bluetooth fingerprint data along with different signal sensitivity of different device configurations presents numerous challenges that influence the performance of the indoor localization system in the wild. This article is intended to offer a comprehensive state-of-the-art survey on machine learning techniques that have recently been adopted for localization purposes. Hence, we review the applicability of machine learning techniques in this domain along with basic localization principles, applications, and the underlying problems and challenges associated with the existing systems. We also articulate the recent advances and state-of-the-art machine learning techniques to visualize the possible future directions in the research field of indoor localization.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01327-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-021-09966-9,Deep learning applied to humanoid soccer robotics: playing without using any color information,Autonomous Robots,10.1007/s10514-021-09966-9,Springer,2021-03-01,"The goal of this paper is to describe a vision system for humanoid robot soccer players that does not use any color information, and whose object detectors are based on the use of convolutional neural networks. The main features of this system are the following: (i) real-time operation in computationally constrained humanoid robots, and (ii) the ability to detect the ball, the pose of the robot players, as well as the goals, lines and other key field features robustly. The proposed vision system is validated in the RoboCup Standard Platform League, where humanoid NAO robots are used. Tests are carried out under realistic and highly demanding game conditions, where very high performance is obtained: a robot detection accuracy of 94.90%, a ball detection accuracy of 97.10%, and a correct determination of the robot orientation 99.88% of the times when the observed robot is static, and 95.52% when the robot is moving.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-021-09966-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42360-020-00290-3,Disease sniffing robots to apps fixing plant diseases: applications of artificial intelligence in plant pathology—a mini review,Indian Phytopathology,10.1007/s42360-020-00290-3,Springer,2021-03-01,"The recent advancements in artificial intelligence (AI) and machine learning have wide applications in plant pathology with sensors, drones, robots and intelligent monitoring systems. Computer vision based phenotyping of plant stress, diagnostics and severity assessment of plant diseases has gained momentum in horticultural and field crops. Internet of things based on networking sensors for biomarkers of disease like volatile organic compounds are being used for early detection and prediction of plant diseases and host-pathogen interaction studies. Unmanned arial vehicles are employed for phenotyping orchards for precise application of plant protection chemicals. Smartphone based field diagnostics are gaining popularity across the world especially in the remote locations where the laboratory diagnostics of diseases is difficult. AI in plant pathology is still at its infancy. Integration of AI and augmented reality will enhance the accuracy and automation for remote diagnostics of plant diseases and precision plant protection. The “self sufficient, disease free, perfect plant” concept will soon become reality with the help of plant-robot bio-hybrids. This mini review explores the present status of AI technologies in plant pathology and tries to find answers for the questions like what are the common platforms used, which are the diseases where technology is applied, what are the challenges and the future prospects.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42360-020-00290-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41347-020-00153-8,"Employees’ Perceptions of the Implementation of Robotics, Artificial Intelligence, and Automation (RAIA) on Job Satisfaction, Job Security, and Employability",Journal of Technology in Behavioral Science,10.1007/s41347-020-00153-8,Springer,2021-03-01,"The study aimed at qualitatively exploring working adult’s perceptions of the implementation of robotics, artificial intelligence (AI), and automation (RAIA) on their job security, job satisfaction, and employability. By means of a cross-sectional and exploratory design, the researchers conducted 21 semi-structured interviews with a diverse sample. The heterogeneous sample came from numerous industries for instance consulting, accounting and finance, and hospitality and varied seniority levels. The thematic analysis led to the emergence of five high-level themes and several sub-themes. The findings indicate that (a) “human touch” and “soft skills” remain irreplaceable and cannot be replicated by RAIA, (b) employees need to perceive RAIA as an opportunity and not a threat, (c) employees might experience a job satisfaction dilemma, and (d) organizations have to be well prepared pre- and post-industrial change. The findings could be used by industrial and organizational psychologists, human resource practitioners, and strategic information technology decision-makers when managing RAIA-related technological changes in organizations. Employees’ suggestions and perceptions could be considered to mitigate the consequences of technological changes in organizations. Both employees and employers need to change their perspective toward RAIA technology, work with a flexible, open mind, and embrace the potential impact of RAIA advancements on job roles and responsibilities. Employees will have to follow a path of continuous learning and keep up with technology.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41347-020-00153-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10710-021-09398-5,"Tim Taylor and Alan Dorin: Rise of the self-replicators—early visions of machines, AI and robots that can reproduce and evolve",Genetic Programming and Evolvable Machines,10.1007/s10710-021-09398-5,Springer,2021-03-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10710-021-09398-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-020-01010-1,From machine ethics to computational ethics,AI & SOCIETY,10.1007/s00146-020-01010-1,Springer,2021-03-01,"Research into the ethics of artificial intelligence is often categorized into two subareas—robot ethics and machine ethics. Many of the definitions and classifications of the subject matter of these subfields, as found in the literature, are conflated, which I seek to rectify. In this essay, I infer that using the term ‘machine ethics’ is too broad and glosses over issues that the term computational ethics best describes. I show that the subject of inquiry of computational ethics is of great value and indeed is an important frontier in developing ethical artificial intelligence systems (AIS). I also show that computational is a distinct, often neglected field in the ethics of AI. In contrast to much of the literature, I argue that the appellation ‘machine ethics’ does not sufficiently capture the entire project of embedding ethics into AI/S, and hence the need for computational ethics. This essay is unique for two reasons; first, it offers a philosophical analysis of the subject of computational ethics that is not found in the literature. Second, it offers a finely grained analysis that shows the thematic distinction among robot ethics, machine ethics and computational ethics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-020-01010-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-020-00340-9,A hybrid tactile sensor-based obstacle overcoming method for hexapod walking robots,Intelligent Service Robotics,10.1007/s11370-020-00340-9,Springer,2021-03-01,"Walking robots are considered as a promising solution for locomotion across irregular or rough terrain. While wheeled or tracked robots require flat surface like roads or driveways, walking robots can adapt to almost any terrain type. However, overcoming diverse terrain obstacles still remains a challenging task even for multi-legged robots with a high number of degrees of freedom. Here, we present a novel method for obstacle overcoming for walking robots based on the use of tactile sensors and generative recurrent neural network for positional error prediction. By using tactile sensors positioned on the front side of the legs, we demonstrate that a robot is able to successfully overcome obstacles close to robots height in the terrains of different complexity. The proposed method can be used by any type of a legged machine and can be considered as a step toward more advanced walking robot locomotion in unstructured terrain and uncertain environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-020-00340-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10230-020-00736-0,The Use of Accurate Pore Pressure Monitoring for Risk Reduction in Tailings Dams,Mine Water and the Environment,10.1007/s10230-020-00736-0,Springer,2021-03-01,"Die bloße Bewegungsüberwachung der Dämme von Bergeteichen geht nicht auf die Ursache des Versagens der Dämme ein und wird daher niemals eine wirksame Methode zur Verringerung oder Verhinderung von Versagen sein. Effektiver ist das Monitoring der Ursachen des Versagens. Die Hauptursache für das Versagen der Dämme ist die Böschungsinstabilität, die durch zu viel Wasser an der falschen Stelle verursacht wird. Eine genaue Überwachung des Porenwasserdrucks (Gewichts) des Wassers in den Böschungen des Bergeteichs (TSF) und die Darstellung von Fließlinien unterhalb und oberhalb des TSF können als Richtschnur dienen und ein frühzeitiges Eingreifen ermöglichen, um das Versagen zu verhindern oder zu verzögern. Fernüberwachung in Verbindung mit künstlicher Intelligenz und Robotik zum Einschalten von Pumpen und offenen Abflüssen, um die Ursache des Versagens anzugehen und zu beseitigen, kann zur Risikominderung beitragen. Die Installation von Mehrpunkt-Piezometern in einem genauen Muster ermöglicht die dreidimensionale Darstellung von Äquipotentialen und Strömungslinien. Jeder TSF ist einzigartig und erfordert ein eigenes Überwachungsdesign, das auf das Alter, die Struktur und die spezifischen Risikoursachen zugeschnitten sein sollte. Einmal verstanden, kann das Überwachungssystem mit einem Berichtssystem gekoppelt werden, um das Risiko eines Ausfalls sowohl an Alt- als auch an aktiven Standorten deutlich zu reduzieren. 简单的尾矿坝体活动监测无法解释尾矿库溃坝原因, 不能作为减少或防止溃坝的有效方法。监测溃坝原因是更有效的预防策略。尾矿坝破坏主要原因是不合理雍水过高引发的边坡失稳。精确地监测尾矿库设施 (TSF) 斜坡内孔隙水压力和绘制尾矿库设施 (TSF) 上、下游流线,能够指导和实现早期干预,阻止或推迟事故发生。远程监测与能够打开水泵和排水系统的人工智能和机器人相联,能够解决和消除溃坝隐患,有助于降低溃坝风险。以精确方式安装多点测压计可以实现三维等水压线和流线绘制。每套尾矿库设施 (TSF) 具有独特性,应根据使用年限、结构特征及特定溃坝风险制定监控方案。一旦明确监测方案,监控系统就能与报告系统相结合,显著降低历史遗留坝体和运行坝体的溃坝灾害风险。 Simply monitoring movement of the tailings dam wall does not address the cause of tailings dam failures and will therefore never be an effective method to reduce or prevent failures. Monitoring the causes of failures is more effective. The main cause of tailings dam failure is slope instability, which is caused by too much water in the wrong place. Accurate pore pressure monitoring of the pressure (weight) of water in the tailings storage facility (TSF) slopes and plotting of flow lines beneath and upstream of the TSF can guide and enable early intervention to prevent or delay failure. Remote monitoring linked to artificial intelligence and robotics to turn on pumps and open drains to address and remove the cause of failure can help reduce risk. Installation of multiple point piezometers in an accurate pattern allows the plotting of equipotentials and flow lines in three dimensions. Each TSF is unique and requires its own monitoring design, which should be tailored to match the age, structure, and specific causes of risk. Once understood, the monitoring system can be coupled to a reporting system to significantly reduce the risk of failure at both legacy and active sites.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10230-020-00736-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-020-01048-1,Operations of power in autonomous weapon systems: ethical conditions and socio-political prospects,AI & SOCIETY,10.1007/s00146-020-01048-1,Springer,2021-03-01,"The purpose of this article is to provide a multi-perspective examination of one of the most important contemporary security issues: weaponized, and especially lethal, artificial intelligence. This technology is increasingly associated with the approaching dramatic change in the nature of warfare. What becomes particularly important and evermore intensely contested is how it becomes embedded with and concurrently impacts two social structures: ethics and law. While there has not been a global regime banning this technology, regulatory attempts at establishing a ban have intensified along with acts of resistance and blocking coalitions. This article aims to reflect on the prospects and limitations, as well as the ethical and legal intensity, of the emerging regulatory framework. To allow for such an investigation, a power-analytical approach to studying international security regimes is utilized.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-020-01048-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41315-020-00159-8,Adaptive dynamic programming enhanced admittance control for robots with environment interaction and actuator saturation,International Journal of Intelligent Robotics and Applications,10.1007/s41315-020-00159-8,Springer,2021-03-01,"This paper focuses on the optimal tracking control problem for robot systems with environment interaction and actuator saturation. A control scheme combined with admittance adaptation and adaptive dynamic programming (ADP) is developed. The unknown environment is modelled as a linear system and admittance controller is derived to achieve compliant behaviour of the robot. In the ADP framework, the cost function is defined with non-quadratic form and the critic network is designed with radial basis function neural network which introduces to obtain an approximate optimal control of the Hamilton–Jacobi–Bellman equation, which guarantees the optimal trajectory tracking. The system stability is analysed by Lyapunov theorem and simulations demonstrate the effectiveness of the proposed strategy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-020-00159-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43154-020-00040-3,Robotics and Artificial Intelligence in Gastrointestinal Endoscopy: Updated Review of the Literature and State of the Art,Current Robotics Reports,10.1007/s43154-020-00040-3,Springer,2021-03-01,"Purpose of Review Gastrointestinal endoscopy includes a wide range of procedures that has dramatically evolved over the past decades. Robotic endoscopy and artificial intelligence are expanding the horizons of traditional techniques and will play a key role in clinical practice in the near future. Understanding the main available devices and procedures is a key unmet need. This review aims to assess the current and future applications of the most recently developed endoscopy robots. Recent Findings Even though a few devices have gained approval for clinical application, the majority of robotic and artificial intelligence systems are yet to become an integral part of the current endoscopic instrumentarium. Some of the innovative endoscopic devices and artificial intelligence systems are dedicated to complex procedures such as endoscopic submucosal dissection, whereas others aim to improve diagnostic techniques such as colonoscopy. Summary A review on flexible endoscopic robotics and artificial intelligence systems is presented here, showing the m3ost recently approved and experimental devices and artificial intelligence systems for diagnosis and robotic endoscopy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43154-020-00040-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01332-2,A Novel Speech to Mouth Articulation System for Realistic Humanoid Robots,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01332-2,Springer,2021-02-27,"A significant ongoing issue in realistic humanoid robotics (RHRs) is inaccurate speech to mouth synchronisation. Even the most advanced robotic systems cannot authentically emulate the natural movements of the human jaw, lips and tongue during verbal communication. These visual and functional irregularities have the potential to propagate the Uncanny Valley Effect (UVE) and reduce speech understanding in human-robot interaction (HRI). This paper outlines the development and testing of a novel Computer Aided Design (CAD) robotic mouth prototype with buccinator actuators for emulating the fluidic movements of the human mouth. The robotic mouth system incorporates a custom Machine Learning (ML) application that measures the acoustic qualities of speech synthesis (SS) and translates this data into servomotor triangulation for triggering jaw, lip and tongue positions. The objective of this study is to improve current robotic mouth design and provide engineers with a framework for increasing the authenticity, accuracy and communication capabilities of RHRs for HRI. The primary contributions of this study are the engineering of a robotic mouth prototype and the programming of a speech processing application that achieved a 79.4% syllable accuracy, 86.7% lip synchronisation accuracy and 0.1s speech to mouth articulation differential.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01332-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01336-y,Detecting Soccer Balls with Reduced Neural Networks,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01336-y,Springer,2021-02-27,"Object detection techniques that achieve state-of-the-art detection accuracy employ convolutional neural networks, implemented to have lower latency in graphics processing units. Some hardware systems, such as mobile robots, operate under constrained hardware situations, but still benefit from object detection capabilities. Multiple network models have been proposed, achieving comparable accuracy with reduced architectures and leaner operations. Motivated by the need to create a near real-time object detection system for a soccer team of mobile robots operating with x86 CPU-only embedded computers, this work analyses the average precision and inference time of multiple object detection systems in a constrained hardware setting. We train open implementations of MobileNetV2 and MobileNetV3 models with different underlying architectures, achieved by changing their input and width multipliers, as well as YOLOv3, TinyYOLOv3, YOLOv4 and TinyYOLOv4 in an annotated image dataset captured using a mobile robot. We emphasize the speed/accuracy trade-off in the models by reporting their average precision on a test data set and their inference time in videos at different resolutions, under constrained and unconstrained hardware configurations. Results show that MobileNetV3 models have a good trade-off between average precision and inference time in constrained scenarios only, while MobileNetV2 with high width multipliers are appropriate for server-side inference. YOLO models in their official implementations are not suitable for inference in CPUs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01336-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-020-01304-y,Three-Dimensional Mapping with Augmented Navigation Cost through Deep Learning,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01304-y,Springer,2021-02-22,"This work addresses the problem of mapping terrain features based on inertial and LiDAR measurements to estimate navigation cost, for an autonomous ground robot. The navigation cost quantifies the degree of how easy or difficult it is to navigate through different areas. Unlike most indoor applications, where surfaces are usually human-made, flat, and structured, external environments may be unpredictable as to the types and conditions of the travel surfaces, such as traction characteristics and inclination. Attaining full autonomy in outdoor environments requires a mobile ground robot to perform the fundamental localization and mapping tasks in unfamiliar environments, but with the added challenge of unknown terrain conditions. Autonomous motion in uneven terrain has been widely explored by the research community focusing on one or more of the several factors involved aiming at both safety and efficient displacement. A fuller representation of the environment is fundamental to increase confidence and to reduce navigation costs. To this end we propose a methodology composed of five main steps: (i) speed-invariant inertial transformation; (ii) roughness level classification; (iii) navigation cost estimation; (iv) sensor fusion through Deep Learning; and (v) estimation of navigation costs for untraveled regions. To validate the methodology, we carried out experiments using ground robots in different outdoor environments with different terrain characteristics. Results show that the inertial data transformation reduces the dispersion of signal magnitude for different speeds and scenarios. Meanwhile, the roughness level classification achieved a mean accuracy of 95.4%, for the speed of 0.6 m / s . Finally, the obtained terrain maps are a faithful representation of outdoor environments allowing accurate and reliable path planning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-020-01304-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01324-2,Guided Sonar-to-Satellite Translation,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01324-2,Springer,2021-02-13,"Underwater navigation and localization are greatly enhanced by the use of acoustic images. However, such images are of difficult interpretation. Contrarily, aerial images are easier to interpret, but require Global Positioning System (GPS) sensors. Due to absorption phenomena, GPS sensors are unavailable in underwater environments. Thus, we propose a method to translate sonar images acquired underwater to an aerial counterpart. This process is called sonar-to-satellite translation. To perform the conversion, a U-Net based neural network is proposed, enhanced with state-of-the-art techniques, such as dilated convolutions and guided filters. Afterwards, our approach is validated on two datasets containing sonar images and their satellite analogue. Qualitative experimental results indicate that the proposed method can transfer features from acoustic images to aerial images, generating satellite images that are easier to interpret and visualize.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01324-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-021-05747-8,Composite dynamic movement primitives based on neural networks for human–robot skill transfer,Neural Computing and Applications,10.1007/s00521-021-05747-8,Springer,2021-02-13,"In this paper, composite dynamic movement primitives (DMPs) based on radial basis function neural networks (RBFNNs) are investigated for robots’ skill learning from human demonstrations. The composite DMPs could encode the position and orientation manipulation skills simultaneously for human-to-robot skills transfer. As the robot manipulator is expected to perform tasks in unstructured and uncertain environments, it requires the manipulator to own the adaptive ability to adjust its behaviours to new situations and environments. Since the DMPs can adapt to uncertainties and perturbation, and spatial and temporal scaling, it has been successfully employed for various tasks, such as trajectory planning and obstacle avoidance. However, the existing skill model mainly focuses on position or orientation modelling separately; it is a common constraint in terms of position and orientation simultaneously in practice. Besides, the generalisation of the skill learning model based on DMPs is still hard to deal with dynamic tasks, e.g., reaching a moving target and obstacle avoidance. In this paper, we proposed a composite DMPs-based framework representing position and orientation simultaneously for robot skill acquisition and the neural networks technique is used to train the skill model. The effectiveness of the proposed approach is validated by simulation and experiments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-021-05747-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11432-019-2735-6,Tracking control of redundant manipulator under active remote center-of-motion constraints: an RNN-based metaheuristic approach,Science China Information Sciences,10.1007/s11432-019-2735-6,Springer,2021-02-05,"In this paper, we propose a recurrent neural network (RNN) for the tracking control of surgical robots while satisfying remote center-of-motion (RCM) constraints. RCM constraints enforce rules suggesting that the surgical tip should not go beyond the region of incision while tracking the commands of the surgeon. Violations of RCM constraints can result in serious injury to the patient. We unify the RCM constraints with the tracing control by formulating a single constrained optimization problem using a penalty-term approach. The penalty-term actively rewards the optimizer for satisfying the RCM constraints. We then propose an RNN-based metaheuristic optimization algorithm called “Beetle Antennae Olfactory Recurrent Neural Network (BAORNN)” for solving the formulated optimization problem in real time. The proposed control framework can track the surgeon’s commands and satisfy the RCM constraints simultaneously. Theoretical analysis is performed to demonstrate the stability and convergence of the BAORNN algorithm. Simulations using LBR IIWA14, a 7-degree-of-freedom robotic arm, are performed to analyze the performance of the proposed framework.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11432-019-2735-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-020-00630-6,Path planning of mobile robot in dynamic environment: fuzzy artificial potential field and extensible neural network,Artificial Life and Robotics,10.1007/s10015-020-00630-6,Springer,2021-02-01,"Path planning in dynamic environment is a great challenge for mobile robot. A large number of approaches have been used to deal with it. Since the neural network algorithm has the ability to find the optimal solution at high speed and self-learning function, it has achieved extensive applications in the path planning tasks. Considering that the optimization performance of the neural network heavily depends on the quality of the training sample, this paper proposes a novel way to provide the training samples for the neural network. Work space of the robot is divided into two parts: global safe area and local dangerous area. In the global safe area, the robot only receives the attraction force from the target and it moves towards the target directly. In the dangerous area, except the attraction force, the robot also receives the repulsion force from the obstacle(s). The repulsion force and the angle between the obstacle and the target (origin of the coordinate is in the position of the robot) are used to be the inputs of the fuzzy inferencing system, and the deflection angle of the robot is the output. The final moving direction of the robot is determined by summing this deflection angle and the direction of the attraction force. The coordinates of the target and obstacle, and the moving direction of the robot corresponding to this position relationship, constitute the training samples for the neural network. Benefited from the precise moving direction obtained by the fuzzy artificial potential field algorithm, the neural network gets excellent path optimization ability. Simulation and physical experiment results demonstrate the potential of the proposed algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-020-00630-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10845-020-01582-1,Reinforcement learning-based collision-free path planner for redundant robot in narrow duct,Journal of Intelligent Manufacturing,10.1007/s10845-020-01582-1,Springer,2021-02-01,"Compared with obstacle avoidance in open environment, collision-free path planning for duct-enter task is often challenged by narrow and complex space inside ducts. For obstacle avoidance, redundant robot is usually applied for this task. The motion of redundant robot can be decoupled to end-effector motion and self-motion. Current methods for duct-enter task are not robust due to the difficulty to properly define the self-motion. This difficulty mainly comes from two aspects: the definition of distances from robot to obstacles and the fusion of multiple data. In this work, we adapt the ideas underlying the success of human to handling this kind tasks, variable optimization strategies and learning, for one robust path planner. Proposed planner applies reinforcement learning skills to learn proper self-motion and achieves robust planning. For achieving robust behavior, state-action planner is creatively designed with three especially designed strategies. Firstly, optimization function, the kernel part of self-motion, is considered as part of action. Instead of taking every joint motion, this strategy embeds reinforcement learning skills on self-motion, reducing the search domain to null space of redundant robot. Secondly, robot end orientation is taken into action. For duct-enter task, robot end link is the motion starter for exploring movement just like the snake head. The orientation of robot end link when passing through some position can be referred by following links. Hence the second strategy can accelerate exploring by reduce the null space to possible redundant robot manifold. Thirdly, path guide point is also added into action part. This strategy can divide one long distance task into several short distance tasks, reducing the task difficulty. After these creative designs, the planner has been trained with reinforcement learning skills. With the feedback of robot and environment state, proposed planner can choose proper optimization strategies, just like the human brain, for avoiding collision between robot body and target duct. Compared with two general methods, Virtual Axis method with orientation Guidance and Virtual Axis, experiment results show that the success rate is separately improved by 5.9% and 49.7%. And two different situation experiments are carried out on proposed planner. Proposed planner achieves 100% success rate in the situation with constant start point and achieves 98.7% success rate in the situation with random start point meaning that the proposed planner can handle the perturbation of start point and goal point. The experiments proves the robustness of proposed planner.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10845-020-01582-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-020-01308-8,Crowded Environment Navigation with NEAT: Impact of Perception Resolution on Controller Optimization,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01308-8,Springer,2021-02-01,"Crowd navigation with autonomous systems is a topic which has seen a rapid increase in interest recently. While it appears natural to humans, being able to reach a target can prove difficult or impossible to a mobile robot because of the safety issues related to collisions with people. In this work we propose an approach to control a robot in a crowded environment; the method employs an Artificial Neural Network (ANN) that is trained with the NeuroEvolution of Augmented Topologies (NEAT) method. Models for the kinematics, perception, and cognition of the robot are presented. In particular, perception is based on a raycasting model which is tailored on the ANN. An in-depth analysis of a number of parameters of the environment and the robot is performed and a comparative analysis is presented; finally, results of the performance of the controller trained with NEAT are compared to those of a human driver who takes over the controller itself. Results show that the intelligent controller is able to perform on par with the human, within the simulated environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-020-01308-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-020-05022-2,Optimization analysis of sport pattern driven by machine learning and multi-agent,Neural Computing and Applications,10.1007/s00521-020-05022-2,Springer,2021-02-01,"The intelligent simulation of Sports can match the actual game and is of great significance to the development of Sports. Sports is a system in which multiple agents work together. Compared with a single agent, the learning space of multiple agents increases sharply as the number of agents increases, so the learning difficulty increases. Therefore, based on machine learning technology, this study combines with the actual situation to build a Sports simulation system. Moreover, after establishing a more reasonable team defensive formation and strategy, the overall movement of the agent is optimized, and the corresponding structural model has been established in combination with various actions. In addition, this study designs a controlled trial to analyze the performance of the model. The research shows that the proposed method has certain effects and can provide theoretical reference for subsequent related research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-020-05022-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-021-05572-0,Deep belief network-based probabilistic generative model for detection of robotic manipulator failure execution,Soft Computing,10.1007/s00500-021-05572-0,Springer,2021-01-28,"This paper addresses an effective deep learning-based technique for detection of robotic manipulator’s failure execution. The problem is based on the control strategy of robotic manipulators subjected to uncertain dynamics. The main contribution is to detect the failures at each different position and instance of robotic manipulators with a certain control strategy. An efficient deep belief neural network-based model is developed with an effective distribution of features at each layer of the network to demonstrate the accurate detection of failures at each instance. With the help of various suitable learning parameters at different stages of network and contrastive divergence operation, the proposed method is able to be an emergent solution for the failure detection. The performance of the proposed DBN is compared with other seven standard machine learning-based classifiers and the results are evident toward the significant impact on the high detection rate as well as the robustness of the proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-021-05572-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11948-021-00283-z,Three Risks That Caution Against a Premature Implementation of Artificial Moral Agents for Practical and Economical Use,Science and Engineering Ethics,10.1007/s11948-021-00283-z,Springer,2021-01-26,"In the present article, I will advocate caution against developing artificial moral agents (AMAs) based on the notion that the utilization of preliminary forms of AMAs will potentially negatively feed back on the human social system and on human moral thought itself and its value—e.g., by reinforcing social inequalities, diminishing the breadth of employed ethical arguments and the value of character. While scientific investigations into AMAs pose no direct significant threat, I will argue against their premature utilization for practical and economical use. I will base my arguments on two thought experiments. The first thought experiment deals with the potential to generate a replica of an individual’s moral stances with the purpose to increase, what I term, ’moral efficiency’. Hence, as a first risk, an unregulated utilization of premature AMAs in a neoliberal capitalist system is likely to disadvantage those who cannot afford ’moral replicas’ and further reinforce social inequalities. The second thought experiment deals with the idea of a ’moral calculator’. As a second risk, I will argue that, even as a device equally accessible to all and aimed at augmenting human moral deliberation, ’moral calculators’ as preliminary forms of AMAs are likely to diminish the breadth and depth of concepts employed in moral arguments. Again, I base this claim on the idea that the current most dominant economic system rewards increases in productivity. However, increases in efficiency will mostly stem from relying on the outputs of ’moral calculators’ without further scrutiny. Premature AMAs will cover only a limited scope of moral argumentation and, hence, over-reliance on them will narrow human moral thought. In addition and as the third risk, I will argue that an increased disregard of the interior of a moral agent may ensue—a trend that can already be observed in the literature.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-021-00283-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s41239-020-00237-8,Exploring the impact of Artificial Intelligence and robots on higher education through literature-based design fictions,International Journal of Educational Technology in Higher Education,10.1186/s41239-020-00237-8,Springer,2021-01-18,"Artificial Intelligence (AI) and robotics are likely to have a significant long-term impact on higher education (HE). The scope of this impact is hard to grasp partly because the literature is siloed, as well as the changing meaning of the concepts themselves. But developments are surrounded by controversies in terms of what is technically possible, what is practical to implement and what is desirable, pedagogically or for the good of society. Design fictions that vividly imagine future scenarios of AI or robotics in use offer a means both to explain and query the technological possibilities. The paper describes the use of a wide-ranging narrative literature review to develop eight such design fictions that capture the range of potential use of AI and robots in learning, administration and research. They prompt wider discussion by instantiating such issues as how they might enable teaching of high order skills or change staff roles, as well as exploring the impact on human agency and the nature of datafication.",https://www.biomedcentral.com/openurl?doi=10.1186/s41239-020-00237-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43545-020-00043-z,In support of “no-fault” civil liability rules for artificial intelligence,SN Social Sciences,10.1007/s43545-020-00043-z,Nature,2021-01-11,"Civil liability is traditionally understood as indirect market regulation, since the risk of incurring liability for damages gives incentives to invest in safety. Such an approach, however, is inappropriate in the markets of artificial intelligence devices. In fact, according to the current paradigm of civil liability, compensation is allowed only to the extent that “someone” is identified as a debtor. However, in many cases it would not be useful to impose the obligation to pay such compensation to producers and programmers: the algorithms, in fact, can “behave” far independently from the instructions initially provided by programmers so that they can err despite no flaw in design or implementation. Therefore, application of “traditional” civil liability to AI may represent a disincentive to new technologies based on artificial intelligence. This is why I think artificial intelligence requires that the law evolves, on this matter, from an issue of civil liability into one of financial management of losses. No-fault redress schemes could be an interesting and worthy regulatory strategy in order to enable this evolution. Of course, such schemes should apply only in cases where there is no evidence that producers and programmers have acted under conditions of negligence, imprudence or unskillfulness and their activity is adequately compliant with scientifically validated standards.",https://www.nature.com/articles/s43545-020-00043-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13205-020-02581-y,Smart technologies driven approaches to tackle COVID-19 pandemic: a review,3 Biotech,10.1007/s13205-020-02581-y,Springer,2021-01-11,"The novel coronavirus infection (COVID-19) is not diminishing without vaccine, but it impinges on human safety and economy can be minimized by adopting smart technology to combat pandemic situation. The implementation of new innovations and novel tactics has proven to be effective in curbing the risk of COVID-19. The present study covers the role of smart technology in mitigating the spread of COVID-19 with specific focus on advancement in the field of drone, robotics, artificial intelligence (AI), mask, and sensor technology. The findings shed light on the robotics and drone technology-driven approaches that have been applied for assisting health system, surveillance, and disinfection process, etc. The AI technology strategies and framework is highlighted in terms of bulk data computing, predicting infection threats, providing medical assistance, and analyzing diagnosis results. Besides this, the technological shift in mask and sensor technology during the pandemic have been illustrated, which includes fabrication method like 3D printing and optical sensing, respectively. Furthermore, the strength, weakness, opportunities, and possible threats that have been shaped by the rigorous implementation of these technologies are also covered in detail.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13205-020-02581-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12206-020-1230-0,Reinforcement learning and neural network-based artificial intelligence control algorithm for self-balancing quadruped robot,Journal of Mechanical Science and Technology,10.1007/s12206-020-1230-0,Springer,2021-01-01,"This paper proposes an artificial intelligence (AI)-based new control algorithm for a self-balancing quadruped robot. A quadruped robot is a good example of a redundant degree-of-freedom (DOF) system and is designed for locomotion over extreme terrain conditions. Even though a relevant control algorithm exerts a great effect on the performance of the locomotion control of quadruped robots, controlling them is difficult and complex because of the redundant DOF and interlocked movement of their four legs. This paper presents an effective control algorithm that can replace the typical analysis-based control theory, including inverse kinematics, differential equations of motion, and governing equations, which is based on reinforcement learning (RL) and artificial neural network (ANN). RL generates the training data to train the ANN model, and the trained ANN model is finally used to control a quadruped robot. The proposed AI-based robot-control algorithm is validated experimentally using a customized test-bed and a self-balancing quadruped robot. The results show that the proposed method is a promising new control algorithm that can replace the mathematically incomprehensible robot-control system.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s12206-020-1230-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-68017-6_79,Image Processing-Based Supervised Learning to Predict Robot Intention for Multimodal Interactions Between a Virtual Human and a Social Robot,Intelligent Human Systems Integration 2021,10.1007/978-3-030-68017-6_79,Springer,2021-01-01,"A humanoid robot and a virtual human with human-like appearance were developed, and various similar intelligence, functions, autonomy and interaction modalities were developed for them that were deemed necessary for their real-world collaboration. The virtual human was integrated with the robot through a common platform based on some control algorithms so that they were capable of cooperating with each other in a real-world task, which was the task of assisting each other in searching for a hidden object in a homely environment. One important activity for such dynamic collaboration was the virtual human’s ability to predict the robot’s intention so that the virtual human could plan to collaborate with the robot, and vice versa. To address this problem, three representative robot behaviors such as hand shaking, hand pointing and hand waving were analyzed using supervised learning-based algorithms associated with image processing to help the virtual human learn robot behaviors so that the learned behaviors could help the virtual human predict the robot’s intention during their intended social interactions. In the training phase, the robot showed each of the three behaviors separately for 500 times. Images of each type of behaviors were taken separately, and the properties of the images were extracted following the image processing method. Then, each robot behavior extracted through image processing was labeled properly. Then, the supervised learning algorithm was developed that classified three different robot behaviors into three different classes. In the testing phase, the robot showed each of its three behaviors to the virtual human randomly for 100 times, the images were taken in real-time, and sent to the image processing-based machine learning algorithm. It was monitored whether the virtual human was able to recognize the robot behavior properly. The results showed that the virtual human was able to recognize robot behaviors and thus predict the robot’s intention with above 95% accuracy level.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-68017-6_79,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89092-6_31,An Online Intelligent Kinematic Calibration Method for Quadruped Robots Based on Machine Vision and Deep Learning,Intelligent Robotics and Applications,10.1007/978-3-030-89092-6_31,Springer,2021-01-01,"Quadruped robot leg calibration has great significance in improving positioning accuracy. However, the traditional calibration method is to manually measure the actual joint angles using protractors, which is time-consuming and inconvenient. To improve the calibration efficiency and accuracy, this paper presents an online intelligent kinematic calibration method for quadruped robots based on machine vision and deep learning. The proposed method contains three parts: detect the marker fixed on the robot leg using machine vision methods, transform coordinates into the reference coordinate system by camera internal and external parameters calibration, calculate joint angles and compensate errors by deep-learning-based inverse kinematics. The experimental validation result shows that the proposed intelligent method can significantly improve the calibration speed with an acceptable accuracy compared to the manual calibration method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89092-6_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-63403-2_48,Dynamic Target Detection and Tracking in Water for Mobile Robot Based on Deep Learning,ICGG 2020 - Proceedings of the 19th International Conference on Geometry and Graphics,10.1007/978-3-030-63403-2_48,Springer,2021-01-01,"Digital image processing is an important part of information perception of mobile robots. Unlike simple geometry, the shape of real objects is always irregular. An accurate and real-time dynamic image processing strategy for mobile robots based on deep learning is developed in this paper. To ensure the dynamic target in water always in the center of the mobile robot’s vision field, a target object detection strategy is designed according to the YOLO-V3 algorithm. 2279 pictures of the target object at different draught depths and different motion directions are collected to retrain the YOLO-V3 model. After testing, the accuracy of the model reaches 94.82%. Besides, considering the high accuracy and high efficiency of the Siamese network, SiamFC (a highly representative algorithm) is selected to support dynamic target tracking. An improved target tracking algorithm based on detection and supervision feedback is designed based on IOU (Intersection over Union) concept. Also, to guarantee the smooth motion of the mobile robot, a strategy of terrain information perception and obstacle terrain passing based on lidar scanning is designed. By analyzing the results of lidar scanning, the mobile robot can judge and avoid the obstacle terrains. The real-time and accuracy of each algorithm is verified by a comprehensive experiment of dynamic target search, detection, and tracking.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-63403-2_48,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-66913-3_6,"Digitization: Learnings from Ancient Disruptions, AI and the Digital Trio’s Functional Stage, and AI Superpowers Disrupting Us",AI for the Good,10.1007/978-3-030-66913-3_6,Springer,2021-01-01,"“Digitization,” the buzzword of the 2010s, along with “disruption” characterizes a fundamental change to individuals and societies. Initially in this chapter, a little trust is built up by setting the current digital transformation into a historical context. Examples that show the potential and risks emerging from AI-based applications are discussed. Obviously, disruption is not new and key lessons can be learnt from the past. The “digital trio” (Robot Process Automation, blockchain, and quantum/supercomputing), i.e., digital technologies surrounding and contributing to AI, is explained for non-engineers and the performance is critically reflected. Using openly accessible AI platform Kaggle, a demonstration illustrates the output dependency on both key ingredients for AI: data and algorithms. Readers can immediately recheck calculation results themselves (without any software coding skills required): Based on a test dataset, different AI algorithms are used in an early warning system. It will be shown that even slight variations in the parametrization will lead to significantly different results. Obviously, this indicates a key problem of AI applications discussed as well in Part III, as misalignment on data and algorithms will ultimately lead to biased decisions and hence discrimination. The AI world emerged with an exponential pace. While there is a broad awareness of AI potential, for the last few years there is a clear duopoly on driving the AI agenda. The technologies used, the applications derived, and the impact on individuals’ and social lives will be illustrated by contrasting the two superpowers, the USA and China, in their approach to rule in the digital age. Despite the ethical consequences of the two very different endeavors, the USA with a so-called surveillance capitalism and China with the so-called market Leninism, there are massive implications not only on the social lives but as well on resource consumption, which provokes an exponential increase in energy demand (and with that realistically an increase in CO_2) as well as costs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-66913-3_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-68017-6_9,Psychophysics-Based Cognitive Reinforcement Learning to Optimize Human-Robot Interaction in Power-Assisted Object Manipulation,Intelligent Human Systems Integration 2021,10.1007/978-3-030-68017-6_9,Springer,2021-01-01,"This paper introduces a novel method of inclusion of human cognition in the form of weight perception in the dynamics and control of a power assist robotic system (PARS) for object manipulation. A 1-DOF test-bed PARS is developed. The dynamics for human-robot co-manipulation of objects is derived that includes weight perception. Then, an admittance control scheme with position feedback and velocity controller is derived from the weight-perception-based dynamics. In the control model, the mass parameter of the inertial force is considered different from that of the gravitational force. The system is simulated in MATLAB/Simulink for 36 different pairs of inertial and gravitational mass parameters. Human subjects lift an object with the system for each pair of parameters separately. The levels of human-robot interaction (HRI) is psychophysically evaluated by subjects separately using a Likert scale. In each trial, the subject evaluates the system for appropriate level of HRI. Then, a training database is generated following the reinforcement learning approach that includes inputs (pairs of mass parameter values) and corresponding outputs (levels of HRI). Then, the labeled database is used to predict a condition where subjects feel the highest level of HRI. Then, the mass parameters for the best HRI pattern are selected as the mass parameters to be used in the control system. In the testing phase, the best mass parameters are used in the control system, and the subjects evaluate the HRI for the system. The results show that the best mass parameters predicted through the reinforcement learning method produce satisfactory HRI, and in the contrary, the mass parameters deviated from the best mass parameters do not produce satisfactory HRI. The results show that inclusion of weight perception in the dynamics and control and optimization of HRI through reinforcement learning are effective.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-68017-6_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-77022-8_7,AI-Robotics and AI Literacy,Education in & with Robotics to Foster 21st-Century Skills,10.1007/978-3-030-77022-8_7,Springer,2021-01-01,"AI is considered as a rapidly advancing technological domain capable of altering every aspect of our lives and society. However, many developing countries lack the basic infrastructure needed for taking advantage of AI systems, which could worsen the new technological, economic, and social divides. Ensuring the inclusion and equity of AI in education is one of the challenges that we need to solve. How can we support the urgent needs of developing countries and the underprivileged communities so that the divide between “haves” and “have-nots” will not continue to grow? This is the core question that this project is trying to address. This paper introduces the AI-robotics project focusing on developing an open-source affordable AI-robotics tool to address the need to promote AI literacy around the world. CogBots, the AI-empowered educational learning tool, has been in development collaboratively with Google, CogLabs and UNESCO. The project targets upper elementary and middle school students to promote AI literacy, including the 5 Big Ideas in AI, using the AI-powered educational robotics tool and the Teachable Machine by Google Creative Lab providing a machine learning experience.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77022-8_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-75472-3_5,Autonomous Navigation with Mobile Robots Using Deep Learning and the Robot Operating System,Robot Operating System (ROS),10.1007/978-3-030-75472-3_5,Springer,2021-01-01,"Autonomous navigation is a long-standing field of robotics research, which provides an essential capability for mobile robots to execute a series of tasks on the same environments performed by human everyday. In this chapter, we present a set of algorithms to train and deploy deep networks for autonomous navigation of mobile robots using the Robot Operation System (ROS). We describe three main steps to tackle this problem: (i) collecting data in simulation environments using ROS and Gazebo; (ii) designing deep network for autonomous navigation, and (iii) deploying the learned policy on mobile robots in both simulation and real-world. Theoretically, we present deep learning architectures for robust navigation in normal environments (e.g., man-made houses, roads) and complex environments (e.g., collapsed cities, or natural caves). We further show that the use of visual modalities such as RGB, Lidar, and point cloud is essential to improve the autonomy of mobile robots. Our project website and demonstration video can be found at https://sites.google.com/site/autonomousnavigationros .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-75472-3_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-60372-4_25,In-Hand Manipulation via Deep Reinforcement Learning for Industrial Robots,Multibody Mechatronic Systems,10.1007/978-3-030-60372-4_25,Springer,2021-01-01,"Robotics manipulation is still a challenge in many scenarios, especially when the orientation of the tool or part is determinant for task success. A study with pivoting, an in-hand manipulation technique, was conducted, which consists in re-orienting the part around one rotational axis without dropping. It gets more complex in industrial robots, which are position controlled and often the user does not have access to the dynamic parameters. Deep reinforcement learning has been successful with model free approaches as it learns the behavior of the whole system. A simulated experiment for pivoting was conducted for part alignment to a desired angle with a one degree of freedom robot and a parallel gripper. Position control and torque control were simulated and compared.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60372-4_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-77939-9_7,Uncertainty-Aware Autonomous Mobile Robot Navigation with Deep Reinforcement Learning,Deep Learning for Unmanned Systems,10.1007/978-3-030-77939-9_7,Springer,2021-01-01,"Autonomous robots are capable of making decisions based on the information they can obtain from their environments, as opposed to simply following a program. Reinforcement learning is a machine learning paradigm that is widely used in autonomous robotics, since their principles are very similar. Reinforcement learning is based on how humans and animals perceive, reason and act on their environments by trial-and-error, learning which actions are better and which are worse depending on the reward they produce. Likewise, robots interact with their environments using their sensors to perceive and their actuators, motors and end effectors to actuate. The main drawback of reinforcement learning is the steep computational cost in processes that involve large state and action spaces. However, this problem has been mitigated by the use of deep learning, which has proved to be an outstanding solution by automatically discovering relevant features and representations in raw and high-dimensional data. This combination results in a new paradigm known as deep reinforcement learning, that has been successfully employed in robotic tasks such as navigation and manipulation. Developments in robotics have enabled the presence of robots in increasingly dynamic, unpredictable, unstructured and partially observable environments, wherein uncertainty is a key element that stems from the lack of information. Thus, the ability to cope with uncertainty is crucial for autonomous robots. However, this scarcity of information has been widely ignored in most robotics works for the sake of simplicity, leading to inaccurate, approximate and unsafe solutions. In order to improve the navigation as well as other robotic tasks and, therefore, the safety of the robot itself and all the objects and beings that surround it, more research is needed on the different approaches and methods for dealing with uncertain information. This chapter aims to provide an overview of deep reinforcement learning algorithms and strategies for mobile robot navigation with handling of uncertainty.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77939-9_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-5258-8_25,Identification of Online Auction Bidding Robots Using Machine Learning,Evolutionary Computing and Mobile Sustainable Networks,10.1007/978-981-15-5258-8_25,Springer,2021-01-01,"Maan, Pooja Eswari, R. The aim of this project is to identify the bidding robots using machine learning, which bids in an online auction. Bidding robot is basically an application which helps to place a bid or click automatically on a website. So, this project will help the site owners to prevent unfair auction by easily flag the robots and remove them from their sites. The major steps are feature extraction, feature selection, model implementation, and classification. Feature engineering is done which includes feature extraction, dropping unnecessary features, and selecting necessary features. Various machine learning classification models are applied with new features to classify human and robot online auction bids and the best performance achieved is ROC score 0.954 using Random Forest.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-5258-8_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-0598-7_2,Machine Learning-Enabled Human Activity Recognition System for Humanoid Robot,Machine Learning for Robotics Applications,10.1007/978-981-16-0598-7_2,Springer,2021-01-01,"Human activity recognition (HAR) system plays a very impactful role in providing precise and opportune information on people’s activities and behaviors. It is applicable in many diversified fields like surveillance, human–computer interaction, health care, entertainment and robotics. There are two main streams of HAR systems: vision-based systems and sensor-based systems. The vision-based systems use cameras to capture images or videos to recognize human behavior. But the use of cameras for capturing data is a difficult task due to limited coverage area background noise, viewpoint, lighting and appearance. On the other hand, the sensor-based systems use different types of easily available wearable devices, smart phones to capture the data for HAR. In this context, it would be great, if an AI-enabled HAR application can be explored for predicting different human activities, like walking, talking, standing, and sitting. They will even be additional targeted activities like those varieties of activities performed during a room or on a manufactory floor. The device knowledge could also be remotely recorded, like video, radar or alternative wireless ways. Alternately, knowledge could also be recorded directly on the topic like by carrying custom hardware or good phones that have accelerometers and gyroscopes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-0598-7_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-90321-3_36,Method for Reconfiguring Kinematic Structure of Modular Robots Using Deep Reinforcement Learning,Data Science and Intelligent Systems,10.1007/978-3-030-90321-3_36,Springer,2021-01-01,"Modular robotic systems are a group of identical robots capable of reconfiguring depending on the assigned tasks. The task of reconfiguring the kinematic structure is the construction of a trajectory connecting the initial and target positions for each module of the system. This paper presents a method for reconfiguring the kinematic structure of a modular robotic system using deep reinforcement learning. This method is based on the deep Q-learning algorithm. In addition, a method for the formation of Q-tables has been developed, which makes it possible to effectively scale the system, as well as to obtain the most complete information about the joint position of the system and transfer it to the neural network, a mechanism for forming the observation vector has been developed. The aim of the training is to build a reward-maximizing control algorithm. To assess the effectiveness of the proposed method, a computer simulation of a modular robotic system consisting of 5, 10 and 15 modules was created. The percentage of test episodes completed without collision was about 94% at 5 modules, 89% at 10 and 82% at 15, and the percentage of successfully completed episodes was about 87%, 64% and 0%, respectively. In addition, in most of the episodes that were completed without a collision, most of the modules were in target positions. In this connection, we can conclude that for the agent was successfully trained to reconfigure 5 and 10 modules, and for 15 a partial solution of the reconfiguration problem was obtained.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-90321-3_36,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-75275-0_82,Visual Deep Learning-Based Mobile Robot Control: A Novel Weighted Fitness Function-Based Image Registration Model,"New Technologies, Development and Application IV",10.1007/978-3-030-75275-0_82,Springer,2021-01-01,"The recent development of faster and more accurate deep learning models has enabled researchers to utilize the potential of deep learning in robotics. Convolutional neural networks used for the process of semantic segmentation are being applied to improve the traditional robotic tasks by adding an additional level of intelligence, through the execution of context-aware tasks. Having that in mind, visual servoing can now be performed in a completely new manner, by exploiting only semantic and geometric knowledge about the environment. To carry out visual servoing, the mathematical model of the error between the images generated at the current and the desired mobile robot pose (i.e. position and orientation) in the image space needs to be adequately defined. In this paper, we propose the novel mathematical model for the weighted fitness function evaluation, which is utilized for the image registration process within the visual servoing framework. By weighting the classes by their importance in the desired image, the convergence domain of the initial error in the visual servoing process can be greatly extended. The experimental evaluation is carried out on the mobile robot RAICO (Robot with Artificial Intelligence based COgnition), where it is shown that weighted fitness function enables more robust intelligent visual servoing systems with a lower possibility of failure, easier real-world implementation, and feasible object driven navigation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-75275-0_82,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-2094-2_40,Development of an Autonomous Intelligent Mobile Robot Based on AI and SLAM Technology,Intelligent Systems and Networks,10.1007/978-981-16-2094-2_40,Springer,2021-01-01,"This paper describes the development of an autonomous intelligent mobile robot. By using a multi-layer sensor fusion, an algorithm which is the combination of the SLAM algorithm and the bubble rebound algorithm is presented. The algorithm allows the robot to perform navigation tasks more efficient. Furthermore, the robot is integrated with artificial intelligence applications including the object detection and the voice processing. All of algorithms and models are so efficient that they can be deployed on a limited-resource embedded computer offering many potential applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-2094-2_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-49100-0_3,Artificial Intelligence for Next-Generation Medical Robotics,Digital Surgery,10.1007/978-3-030-49100-0_3,Springer,2021-01-01,"Technology-based advancements have the potential to empower every surgeon with the ability to improve the quality of global surgical care. Innovation in robotic surgery will continue to parallel advancements in technology, especially with the considerable progress in computer science and artificial intelligence (AI). It is also known that high-quality surgical techniques and skill sets correlate positively with patient outcomes. AI could help pool this surgical experience to standardize decision-making, thus creating a global consensus in operating theaters worldwide. Next-generation surgical robots will be integral in augmenting a surgeon’s skills effectively to achieve accuracy and high precision during complex procedures. The next level of surgery will be achieved by surgical robotics which likely evolve to include AI and machine learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-49100-0_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-80091-8_119,People’s Perception of Artificial Intelligence Objects-Focusing on People’s Emotional Response to Robot Cleaner Designs,"Advances in Usability, User Experience, Wearable and Assistive Technology",10.1007/978-3-030-80091-8_119,Springer,2021-01-01,"Robot cleaners have been general artificial intelligence products for nearly two decades, and people’s perspectives have changed in line with this tendency. This study explores the user’s emotional response to robot cleaners by analyzing the results from interviews after watching videos of working robot cleaners. These results suggest that people commonly preferred several factors such as the robot cleaner’s appearance, sound and behavior, and there were slight differences between people who owned a robot cleaner and those who never used one before. These findings have implications for design factors that we claim could be hints to the next artificial intelligence objects.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-80091-8_119,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-7779-6_52,Navigation Method for Pioneer P3-DX Ground Wheeled Robot in V-REP Platform Using Type-2 Fuzzy Neural Network (T2FNN) Architecture,Advances in Mechanical Processing and Design,10.1007/978-981-15-7779-6_52,Springer,2021-01-01,"This article presents the navigational architecture for a Pioneer P3-DX Ground Wheeled Robot (PGWR) by applying the minimum rule-based type-2 fuzzy neural network (T2FNN) architecture to control the motion, direction and orientation of PGWR between obstacles and help the PGWR to reach the goal. The real-time obstacle distance information received from the ring of ultrasonic sensors of PGWR is feed to the T2FNN as inputs, and necessary wheel velocity control commands for obstacle avoidance are obtained as outputs form rule-based system architecture of T2FNN. The experimental results in the Virtual Robot Experimentation Platform (V-REP) software show that the T2FNN method has successfully guided the PGWR under unknown scenarios. Also, the comparison analysis has been done with the previous benchmark neural network (NN) approach and found smoother trajectory during obstacle avoidance because the T2FNN provided an additional degree of freedom over NN to handle uncertainty situations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-7779-6_52,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-77939-9_13,Image Registration Algorithm for Deep Learning-Based Stereo Visual Control of Mobile Robots,Deep Learning for Unmanned Systems,10.1007/978-3-030-77939-9_13,Springer,2021-01-01,"Since the emergence of deep learning as a dominant technique for numerous tasks in the computer vision domain, the robotics community has strived to utilize its potential. Deep learning represents a framework capable of learning the most complex models necessary to carry out various robotic tasks. We propose to integrate deep learning and one of the fundamental robotic algorithms—visual servoing. Fully convolutional neural networks are used for semantic segmentation, which represents the process of labeling every pixel within the image. The obtained information from labeled (categorical) images can be crucial for mobile robot control in dynamic environments. To adequately utilize semantic segmentation for mobile robot control, the segmented images acquired at the desired and the current pose need to be registered (aligned). Since the accuracy of visual servoing depends on the accuracy of the image registration process, we propose to increase the accuracy of mobile robot positioning by analyzing three different optimization algorithms devoted to the registration of categorical images. The standard gradient descent algorithm is compared to the OnePlusOneEvolutionary algorithm, and simulated annealing. Moreover, different cost functions such as Mattes mutual information, global accuracy, and mean intersection over union are also investigated. All the algorithms are tested on our own wheeled mobile robot RAICO (Robot with Artificial Intelligence based COgnition) developed within the Laboratory for robotics and artificial intelligence. The results indicate that the algorithm with a larger exploration to exploitation ratio provides better results. Moreover, the cost function with the steepest convex domain is more advantageous.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77939-9_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89098-8_20,Leveraging Expert Demonstrations in Robot Cooperation with Multi-Agent Reinforcement Learning,Intelligent Robotics and Applications,10.1007/978-3-030-89098-8_20,Springer,2021-01-01,"While deep reinforcement learning (DRL) enhances the flexibility and intelligence of a single robot, it has proven challenging to solve the cooperatively of even basic tasks. And robotic manipulation is cumbersome and can easily yield getting trapped in local optima with reward shaping. As such sparse rewards are an attractive alternative. In this paper, we demonstrate how teams of robots are able to solve cooperative tasks. Additionally, we provide insights on how to facilitate exploration and faster learning in collaborative systems. First, we increased the amount of effective data samples in the replay buffer by leveraging virtual targets. Secondly, we introduce a small number of expert demonstrations to guide the robot during training via an additional loss that forces the policy network to learn the expert data faster. Finally, to improve the quality of behavior cloning, we propose a Judge mechanism that updates the strategy by selecting optimal action while training. Furthermore, our algorithms were tested in simulation using both dual arms and teams of two robots with single arms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89098-8_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-70516-9_3,AI and ML for Human-Robot Cooperation in Intelligent and Flexible Manufacturing,Implementing Industry 4.0 in SMEs,10.1007/978-3-030-70516-9_3,Springer,2021-01-01,"Human–robot cooperation aims to increase the flexibilization of manufacturing systems. This requires safe human–machine interaction (e.g. with collaborative robots) as well as self and environment awareness capabilities to interact autonomously and smartly between humans and machines. Therefore, the goal of this chapter is to conceptualize and identify the set of real-time information processing and decision-making capabilities required for collaborative robots to be considered as a safe companion in the context of human–robot cooperation (HRC). In particular, the chapter provides an overview of appropriate artificial intelligence (AI) and machine learning (ML) concepts, formally introduces the concept of a safety-aware cyber-physical system and defines a general taxonomy for the perceptive and cognitive problems arising in the context of intelligent and flexible HRC.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-70516-9_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89177-0_22,Deep Learning Traversability Estimator for Mobile Robots in Unstructured Environments,Towards Autonomous Robotic Systems,10.1007/978-3-030-89177-0_22,Springer,2021-01-01,"Terrain traversability analysis plays a major role in ensuring safe robotic navigation in unstructured environments. However, real-time constraints frequently limit the accuracy of online tests especially in scenarios where realistic robot-terrain interactions are complex to model. In this context, we propose a deep learning framework trained in an end-to-end fashion from elevation maps and trajectories to estimate the occurrence of failure events. The network is first trained and tested in simulation over synthetic maps generated by the OpenSimplex algorithm. The prediction performance of the Deep Learning framework is illustrated by being able to retain over $$94\%$$ 94 % recall of the original simulator at $$30\%$$ 30 % of the computational time. Finally, the network is transferred and tested on real elevation maps collected by the SEEKER consortium during the Martian rover test trial in the Atacama desert in Chile. We show that transferring and fine-tuning of an application-independent pre-trained model retains better performance than training uniquely on scarcely available real data.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89177-0_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-54173-6_14,The AI and Robot Entity,"Robotics, AI, and Humanity",10.1007/978-3-030-54173-6_14,Springer,2021-01-01,"Robots are instruments of the human being who is intelligent and free. Aristotle defines being free as the one that is cause of himself or exists on his own and for himself ( causa sui or causa sui ipsius ). By contrast, the instrument is not a cause of itself and does not work by the power of its entity, but only by the motion imparted by the principal agent, so that the effect is not likened to the instrument but to the principal agent. From the Christian perspective, for a being to be free and a cause of himself, it is necessary that he/she be a person endowed with a spiritual and incorruptible soul, on which his or her cognitive and free activity is based. An artificially intelligent robotic entity does not meet this standard. As an artefact and not a natural reality, the AI/robotic entity is invented by human beings to fulfil a purpose imposed by human beings. It can become a perfect entity that performs operations in quantity and quality more precisely than a human being, but it cannot choose for itself a different purpose from what it was programmed for by a human being. As such, the artificially intelligent robot is a means at the service of humans.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54173-6_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-62579-5_20,Embedded Deep Learning Solution for Person Identification and Following with a Robot,Advances in Physical Agents II,10.1007/978-3-030-62579-5_20,Springer,2021-01-01,"This research presents a robust embedded system for following a person, making use of a pipeline of convolutional neural networks. Besides, it features an optical tracking system for supporting the inferences of the neural networks, allowing to determine the position of a person using an RGBD camera. The system is deployed using ROS, and runs in a NVIDIA Jetson TX2, an embedded SoM ( System-on-Module ), capable of performing computationally demanding tasks onboard, and coping with the complexity required to run a robust tracking and following algorithm. The board is attached to a robotic mobile base, which receives velocity commands to move the system towards the target person.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-62579-5_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-1-4614-6434-1_126-4,Modeling Neuronal Systems,Neuroscience in the 21st Century,10.1007/978-1-4614-6434-1_126-4,Springer,2021-01-01,"This chapter provides a summary of current approaches to modeling neuronal systems at the levels of single cells, networks, and more complex multinetwork systems. It begins with a brief history describing how models based on neurophysiological data diverged from artificial intelligence research and became increasingly sophisticated as available computational power increased. It is shown how, in order to make the simulation of large network systems practical, models based on detailed ion channel properties can be replaced by increasingly simple “integrate-and-fire” models, “rate-coded” models that do not instantiate individual neuronal action potential spikes and even ensemble models that provide statistical summaries of the activity of masses of neurons. Event-driven models that reduce the need to perform routine membrane-potential decay calculations at small time intervals are discussed. Models for synaptic modification presumed to be involved in learning are described for both rate-coded and spiking neuron models. The chapter ends with some discussion of nervous system aspects that have often been omitted from models but which are of increasing interest and which may form suitable bases for future research, as well as pitfalls that need to be avoided by newcomers to this field.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4614-6434-1_126-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86230-5_3,Tomato Detection Using Deep Learning for Robotics Application,Progress in Artificial Intelligence,10.1007/978-3-030-86230-5_3,Springer,2021-01-01,"The importance of agriculture and the production of fruits and vegetables has stood out mainly over the past few years, especially for the benefits for our health. In 2021, in the international year of fruit and vegetables, it is important to encourage innovation and evolution in this area, with the needs surrounding the different processes of the different cultures. This paper compares the performance between two datasets for robotics fruit harvesting using four deep learning object detection models: YOLOv4, SSD ResNet 50, SSD Inception v2, SSD MobileNet v2. This work aims to benchmark the Open Images Dataset v6 (OIDv6) against an acquired dataset inside a tomatoes greenhouse for tomato detection in agricultural environments, using a test dataset with acquired non augmented images. The results highlight the benefit of using self-acquired datasets for the detection of tomatoes because the state-of-the-art datasets, as OIDv6, lack some relevant characteristics of the fruits in the agricultural environment, as the shape and the color. Detections in greenhouses environments differ greatly from the data inside the OIDv6, which has fewer annotations per image and the tomato is generally riped (reddish). Standing out in the use of our tomato dataset, YOLOv4 stood out with a precision of 91%. The tomato dataset was augmented and is publicly available (See https://rdm.inesctec.pt/ and https://rdm.inesctec.pt/dataset/ii-2021-001 ).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-86230-5_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-5580-0_15,Hand Gestures Recognition Model for Augmented Reality Robotic Applications,"Proceedings of 15th International Conference on Electromechanics and Robotics ""Zavalishin's Readings""",10.1007/978-981-15-5580-0_15,Springer,2021-01-01,"Augmented reality (AR) is a research promising field. Its main idea is to integrate and merge the virtual world with the real world. Augmented reality could improve or enhance our perception of the real world by integrating virtual objects. The existing hand gesture applications related to augmented reality can detect hand motion or track it in addition to the ability to construct a 3D model of tracked hand using markers and motion sensing devices like Kinect, LeapMotion, and AR/VR instruments. In this paper, a hand gesture recognition model based on deep convolutional neural network is proposed to be used in 3D virtual environments for robotic teleportation. This model is tested on HTC VIVE Pro AR/VR instruments using the VIVE eye and on a Kinect v2 to control an industrial manipulator in real time using only the hand movements in both online and offline control modes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-5580-0_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-75789-2_5,Neural Network-Based Inverse Kineto-Static Analysis of Cable-Driven Parallel Robot Considering Cable Mass and Elasticity,Cable-Driven Parallel Robots,10.1007/978-3-030-75789-2_5,Springer,2021-01-01,"Inverse kinematic problem of a cable-driven parallel robot (CDPR) is a straightforward problem for massless inextensible cables. However, the problem becomes a non-linear kineto-static problem with the consideration of cable mass and elasticity. This problem is conventionally solved using numerical methods. These methods are iterative in nature, have slow convergence speed, and are highly dependent on initial values, which makes them difficult to be used in real-time applications. Therefore, this paper proposes a deep neural network-based approach to obtain the inverse kineto-static (IKS) solution of CDPR considering cable mass and elasticity. The training dataset has been obtained from IKS solutions attained by using numerical methods. Then, appropriate parameters as well as training algorithm is utilized for off-line training of the network. The performance of the proposed approach is validated by the simulation results for a redundantly constrained planar CDPR. From the simulation results, it has been observed that the proposed approach shows an 83% reduction in computational time in comparison to conventional numerical methods. In addition, the proposed neural network-based approach has performed satisfactorily with a minor error in the IKS solution. Therefore, the proposed approach can be employed for real-time applications due to its low and bounded computational time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-75789-2_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-8221-9_57,Friction Compensation in Robot Manipulator Using Artificial Neural Network,"Advances in Automation, Signal Processing, Instrumentation, and Control",10.1007/978-981-15-8221-9_57,Springer,2021-01-01,"In this work, an experimental friction forces were generated and then inserted in the joints of a robot manipulator. The artificial neural network (ANN) is used for the estimation of the friction forces in the joints of the robot. The estimated friction is implemented in the compensation of the real friction. The approach demonstrated its effectiveness in the control of the robot with a tracking error converging to zero. The overall objective of this work is to compensate for the effect of the friction in a robot manipulator using artificial neural network techniques. The end of the paper investigated the effect of the factors that could degrade the performance of the system such as modeling error or noise in the measurement. However, the modeling error showed no effect on the performance as well as noise.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-8221-9_57,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-88972-2_4,Ethical Conditions of the Use of Artificial Intelligence in the Modern Battlefield—Towards the “Modern Culture of Killing”,Artificial Intelligence and Its Contexts,10.1007/978-3-030-88972-2_4,Springer,2021-01-01,"The use of artificial intelligence (AI) on the modern battlefield causes justified semantic and ethical controversies. Semantic, i.e., relating to meaning, controversies are related to delineating artificial intelligence (AI) used by a human during military operations, e.g., precision weapons capable of independent decision-making about the choice of target; and completely autonomous machines, i.e. thinking and deciding autonomously/independently from the human being. In this broad, and still nascent filed, several legal and ethical challenges emerge. This chapter sheds light on the emerging ethical considerations pertinent to the use of robots and other machines relying on unsupervised learning in resolving conflicts and crises of strategic importance for security.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-88972-2_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-68017-6_4,Sensor Fusion-Based Supervised Learning Approach to Developing Collaborative Manipulation System with Variable Autonomy,Intelligent Human Systems Integration 2021,10.1007/978-3-030-68017-6_4,Springer,2021-01-01,"The objective is to create and program a demonstration of a manipulator arm that is capable of detecting objects, distinguishing between them, and relocating target objects to corresponding locations. The experiments are carried out to evaluate and improve the arm’s design, and to gather preliminary data from the sensors to better program the system’s behavior. The proposed manipulation system design makes the robot arm capable of performing a predetermined series of object relocation tasks with or without outside (human) commands from an unknown initial state. During the experiments, the performance of the robotic manipulation system is compared between two separate sensing conditions: (i) use of an ultrasonic sensor alone, and (ii) use of an ultrasonic sensor plus a light sensor. The human operator has a varying role in the manipulation. The operator may reset system inputs, put command, observe the operation, and collaborate with the system as a complementary performer or co-worker when the system needs human’s support. A survey is conducted to determine the potential human involvement and human factors associated with the manipulation system, which helps determine and vary the autonomy levels of the system. Then, an experiment is conducted to determine the autonomy levels of the system based on assessing the varying contribution of the human operator. A supervised learning approach is then proposed that may learn from previous events, predict required autonomy levels for future events, and thus may help maintain appropriate autonomy levels with task requirements. The results may help develop intelligent robotic manipulation systems in industries that may work independently or in collaboration with human workers with varying levels of autonomy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-68017-6_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85099-9_32,Autonomous Docking of Mobile Robots by Reinforcement Learning Tackling the Sparse Reward Problem,Advances in Computational Intelligence,10.1007/978-3-030-85099-9_32,Springer,2021-01-01,"Most mobile robots are powered by batteries, which must be charged before their level become too low to continue providing services. This paper contributes a novel method based on Reinforcement Learning (RL) for the autonomous docking of mobile robots at their charging stations. Our proposal considers a RL network that is fed with images to visually sense the environment and with distance measurements to safely avoid obstacles, and produces motion commands to be executed by the robot. Additionally, since the autonomous docking is in essence a sparse reward task (the only state that returns a positive reward is when the robot docks at the charging station), we propose the usage of reward shaping to successfully learn to dock. For that we have designed extrinsic rewards that are built on the results of a Convolutional Neural Network in charge of detecting the pattern typically used to visually identify charging stations. The experiments carried out support our design decisions and validate the method implementation, reporting a $$\sim $$ ∼ 100% of success in the docking task with obstacle-free paths, and $$\sim $$ ∼ 93% when obstacles are considered, along with short execution times (10 s and 14 s on average, respectively).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-85099-9_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-5580-0_14,"Collaborative Robots: Development of Robotic Perception System, Safety Issues, and Integration of AI to Imitate Human Behavior","Proceedings of 15th International Conference on Electromechanics and Robotics ""Zavalishin's Readings""",10.1007/978-981-15-5580-0_14,Springer,2021-01-01,"The development of collaborative robotics as a research area is based on the study of safety and machine vision issues. The process of integrating artificial intelligence into robotic systems is gradually taking place. The process of intelligent robotic automation is based on a combination of machine learning of robots and high vision technologies on the way to interactive intelligent collaborative robotics. Given the lack of barriers for modern robots that work with humans, the issues of safety interaction remain the basic basis, which is considered an integral part of any implementation of new technological solutions. Such intelligent robotic solutions aimed to provide complementing and augmenting human capabilities, not replacing them. To take full advantage of this collaboration between robots and humans, we must understand how humans can most effectively augment robots and how robots can enhance what humans do best.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-5580-0_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86230-5_32,Exploiting Symmetry in Human Robot-Assisted Dressing Using Reinforcement Learning,Progress in Artificial Intelligence,10.1007/978-3-030-86230-5_32,Springer,2021-01-01,"In this work, we address the problem of symmetry transfer in human-robot collaborative tasks, i.e., how certain actions can be extended to their symmetrical by exploiting symmetries in their execution. We contribute an approach capable of considering the symmetry inherent to a given task, such as the human or robot’s lateral symmetry, abstracting them from the robot’s decision process. We instantiate our approach in a robot-assisted backpack dressing scenario. A two-manipulator Baxter robot assists a human user in sequentially putting on both straps of a backpack. We evaluate the proposed symmetry-transfer approach in two complementary perspectives: the quality of the agent’s learned policy in a simulated environment and the efficiency of the complete system in a real-life scenario with a robotic platform. The results show that our approach allows the extension of the execution of single-side trained collaborative tasks to their symmetrical with no additional training and minimal performance loss.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-86230-5_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13042-020-01167-7,Multi-agent reinforcement learning for redundant robot control in task-space,International Journal of Machine Learning and Cybernetics,10.1007/s13042-020-01167-7,Springer,2021-01-01,"Task-space control needs the inverse kinematics solution or Jacobian matrix for the transformation from task space to joint space. However, they are not always available for redundant robots because there are more joint degrees-of-freedom than Cartesian degrees-of-freedom. Intelligent learning methods, such as neural networks (NN) and reinforcement learning (RL) can learn the inverse kinematics solution. However, NN needs big data and classical RL is not suitable for multi-link robots controlled in task space. In this paper, we propose a fully cooperative multi-agent reinforcement learning (MARL) to solve the kinematic problem of redundant robots. Each joint of the robot is regarded as one agent. The fully cooperative MARL uses a kinematic learning to avoid function approximators and large learning space. The convergence property of the proposed MARL is analyzed. The experimental results show that our MARL is much more better compared with the classic methods such as Jacobian-based methods and neural networks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13042-020-01167-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89098-8_12,DOREP 2.0: An Upgraded Version of Robot Control Teaching Experimental Platform with Reinforcement Learning and Visual Analysis,Intelligent Robotics and Applications,10.1007/978-3-030-89098-8_12,Springer,2021-01-01,"The Deep Open Robot Experiment Platform (DOREP) is an experimental system for general robot control. It includes a robot toolbox, a Linux based real-time controller and corresponding environment deployment tools. It is compatible with ROKAE robots, Universal robots, ABB robots, AUBO robots and other 6-DOF small low load general robots. It aims to provide users with a direct, high-level, more open and comprehensive programming interface. The toolbox of the original version of DOREP system contains more than 30 functions, including forward and inverse kinematics calculation, point-to-point joint and Cartesian control, trajectory generation, graphic display, 3D animation and diagnosis. On the basis of the original version, DOREP 2.0 system adds some new functional modules such as reinforcement learning and visual analysis, which further improves the performance of DOREP system. Taking the newly added module as an example, this paper expounds the functions of reinforcement learning module and visual analysis module, and applies them to simulation and experiment successfully.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89098-8_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-58282-1_51,Towards Intelligent Pick and Place Assembly of Individualized Products Using Reinforcement Learning,Human Systems Engineering and Design III,10.1007/978-3-030-58282-1_51,Springer,2021-01-01,"Individualized manufacturing is becoming an important approach to fulfill increasingly diverse consumer expectations. While there are various solutions for the manufacturing process, such as additive manufacturing, the subsequent automated assembly remains a challenging task. As an approach to this problem, we aim to teach a collaborative robot to successfully perform pick and place tasks by implementing reinforcement learning. For the assembly of an individualized product in a constantly changing manufacturing environment, the simulated geometric and dynamic parameters will be varied. Using reinforcement learning algorithms capable of meta-learning, the tasks will first be trained in simulation, and then performed in a real-world environment where new factors are introduced that were not simulated in training to confirm the robustness of the algorithms. A concept comprised of selected machine learning algorithms, hardware components as well as further research questions to realize the outlined production scenario are the results of the presented work.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58282-1_51,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-77584-1_11,Artificial Intelligence,A Primer on Multiple Intelligences,10.1007/978-3-030-77584-1_11,Springer,2021-01-01,"The chapter provides an introduction to artificial intelligence (AI), which is a science with research activities in the areas of image processing, natural language processing, robotics, machine learning, etc. Artificial intelligence, with the capacity to make computers learn from experience, is playing a predominant role in many industries. AI algorithms, such as machine learning and deep learning, are most commonly used to make intelligent predictions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77584-1_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-60039-6_7,Robotics and Drone-Based Solution for the Impact of COVID-19 Worldwide Using AI and IoT,Emerging Technologies for Battling Covid-19,10.1007/978-3-030-60039-6_7,Springer,2021-01-01,"Coronavirus disease 2019 (COVID-19) is an infectious disease caused by the SARS-CoV-2 virus. The disease causes a respiratory illness with symptoms like cough and fever and, in more severe cases, causes difficulty while breathing. COVID-19 spreads primarily through contact with an infected person when they sneeze or cough or by touching a surface that has that virus on it and then touching our mouth, nose, or eyes. The disease was first observed in the central Chinese city of Wuhan at the end of 2019. The outbreak has been declared a global pandemic. The novel coronavirus is already reorienting our lives, but the crisis moments also present an opportunity for more sophisticated and flexible use of technology. The epidemic is impacting the global population as the number of cases is increasing rapidly, and there is an urgent need to stop the virus from spreading. The outbreak has triggered massive demand for digital health solutions, and for this, the drones and robots present an excellent method for automation of manual activities. Drones and robots can be used to provide services to the patients and those who are quarantined and are the most desirable and safe way to fight against the outbreak and limit contamination and spread of the virus. The following chapter will discuss the various solutions based on drones and robots in the field of AI and IoT, such as drones being used for social distancing and robots for sanitization. Further, analysis has been made about the total number of cases and deaths around the world and also how it has affected humanity and what measures have been taken to control this deadly disease.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60039-6_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-54173-6_11,Designing Robots for the Battlefield: State of the Art,"Robotics, AI, and Humanity",10.1007/978-3-030-54173-6_11,Springer,2021-01-01,"There is currently a global arms race for the development of artificial intelligence (AI) and unmanned robotic systems that are empowered by AI (AI-robots). This paper examines the current use of AI-robots on the battlefield and offers a framework for understanding AI and AI-robots. It examines the limitations and risks of AI-robots on the battlefield and posits the future direction of battlefield AI-robots. It then presents research performed at the Johns Hopkins University Applied Physics Laboratory (JHU/APL) related to the development, testing, and control of AI-robots, as well as JHU/APL work on human trust of autonomy and developing self-regulating and ethical robotic systems. Finally, it examines multiple possible future paths for the relationship between humans and AI-robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54173-6_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-58080-3_256-1,Artificial Intelligence in Trauma and Orthopaedics,Artificial Intelligence in Medicine,10.1007/978-3-030-58080-3_256-1,Springer,2021-01-01,"This chapter will explore artificial intelligence (AI) in trauma and orthopedics (orthopedics). Orthopedics is a branch of surgery that focuses on the prevention of musculoskeletal pathology and the correction and restoration of form and function of these structures. Orthopedics is fertile ground for adoption of technological innovations, including artificial intelligence, where small gains in the treatment of one condition can lead to improved outcomes for some of the largest patient populations in medicine. Orthopedics is well suited to innovation and the application of AI as it has clear pathways for common diseases and is a highly technical field with constant technical innovation. This chapter will review several of the key applications of AI in orthopedics including diagnostics, intraoperative robotics, and predictive analytics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58080-3_256-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-79763-8_1,Human-Autonomy Teaming with Learning Capable Agents: Performance and Workload Outcomes,Advances in Simulation and Digital Human Modeling,10.1007/978-3-030-79763-8_1,Springer,2021-01-01,"Each of twenty participants teamed with a learning capable agent to conduct a threat classification task. The agent’s reasoning and learning transparency varied across four scenarios. Access to agent reasoning transparency improved task performance as assessed by percent of correct classifications. Agent learning transparency of inferred knowledge improved task response time and reduced cognitive workload. However, when the human was burdened with directly teaching the agent, task completion time and perceived workload increased dramatically, while satisfaction in task performance decreased. These findings indicate that when teamed with learning capable agents, human performance and workload are best supported when the autonomy can derive its needed information with minimal human input.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-79763-8_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-88458-1_6,Teaching Real Robots: The Right Way to Set up Learning-Based Systems for Your Robot,Modern Problems of Robotics,10.1007/978-3-030-88458-1_6,Springer,2021-01-01,"The typical robotics system consists of perception, planning, and control modules. Each module is built upon information about its components, where modeling each part of the system plays an essential role in the design process. In practice, working with the non-linear models in robotics systems involves a lot of approximations which hinders reaching the optimal behavior for the goal task. Alongside the difficulties in redeploying the system to solve other similar tasks. Learning-based methods provide a promising approach for robotic systems. In the last decade, the interest in incorporating machine learning into robotics systems has been evolving rapidly. The benefit of using learning is the possibility to design systems that are independent of the dynamical model of the robot, with the flexibility to adopt new tasks and learn to excel in performance over time. The theory behind designing a learning-based system is still under development, ranges from end-to-end systems to hybrid systems that use inaccurate approximate models. In this paper, we are proposing the results of our research in learning-based systems, presenting our view for the right way to set up learning systems for robotics. The results are a whole learning-based framework for robotics applications, works efficiently (1 h of training – 10 min robot movement) with minimum human intervention (user has to provide video demonstrations only).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-88458-1_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-77939-9_14,Search-Based Planning and Reinforcement Learning for Autonomous Systems and Robotics,Deep Learning for Unmanned Systems,10.1007/978-3-030-77939-9_14,Springer,2021-01-01,"In this chapter, we address the competent Autonomous Vehicles should have the ability to analyze the structure and unstructured environments and then to localize itself relative to surrounding things, where GPS, RFID or other similar means cannot give enough information about the location. Reliable SLAM is the most basic prerequisite for any further artificial intelligent tasks of autonomous mobile robots. The goal of this paper is to simulate a SLAM process on advanced software development. The model represents the system itself, whereas the simulation represents the operation of the system over time. And the software architecture will help us to focus our work to realize our wish with least trivial work. It is an open-source meta-operating system, which provides us tremendous tools for robotics related problems. Specifically, we address the advanced vehicles should have the ability to analyze the structured and unstructured environment based on solving the search-based planning and then we move to discuss interested in reinforcement learning-based model to optimal trajectory in order to apply to autonomous systems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77939-9_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-52190-5_8,On Image Compression for Mobile Robots Using Feed-Forward Neural Networks,Soft Computing Applications,10.1007/978-3-030-52190-5_8,Springer,2021-01-01,"In mobile robots control, the vision system is placed in the feedback loop, and it requires the ability to extract the necessary information for multiple real-time image and video processing tasks. Image compression techniques are useful in vision systems for large data streaming, like image transmission, archival and retrieval purposes. Neural networks (NN) are widely used in image processing, for solving different issues, with different NN topology, training and testing sets selection, and learning algorithms. Aspects of grayscale image compression for vision system in mobile robots using artificial NNs are discussed in this paper. Several feed-forward neural networks (FFNN) are analyzed, using different structures, input dimensions, neuron numbers, and performance criteria. The goal of the paper is to study the behavior of low-complexity FFNN models for grayscale image compression, with good compression rate and small enough errors for the vision system purposes in mobile robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-52190-5_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-33-4698-7_16,Development of Algorithm for Precise Movement Controller for Robotic Arm,Technical Advancements of Machine Learning in Healthcare,10.1007/978-981-33-4698-7_16,Springer,2021-01-01,"Robotics and automation play a vital role all around and it emerges in the medical field also. Movement control of the robot moved well beyond its conventional uses in manufacturing. Medical devices, automotive robotics electronic gadgets benefited from motion control subsystems due to the advantages such as less cost, power saving. The critical elements are complexity of the electronics and embedded software for motion control. It is very essential to care about the proper accuracy and precision. Many research works have been implemented in order to achieve the accuracy and precision. But maintaining the precision of the movements of medical robotic arm controller is a challenging task. This work addresses this problem and enumerates a suitable proposed work in order to overcome this. The suitability of the proposed work, which employs Image processing, Deep learning network is well authenticated by developing a hardware model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-4698-7_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-90525-5_67,A Collaborative Robotic Approach for Inspection and Anomaly Detection in Industrial Applications,Social Robotics,10.1007/978-3-030-90525-5_67,Springer,2021-01-01,"Inspection and quality assurance is an important step in manufacturing systems, including newly manufactured or re-manufactured parts. Currently, there is a heavy reliance on the knowledge of experienced workers in interpreting the data from inspection sensors and detecting anomalies. Using robots to perform automated inspection becomes challenging in high-mix settings, where the work-pieces to be inspected change frequently and require the robot to be re-programmed. In this paper, we propose a human-robot collaboration approach, where part of the work involving fixturing, sensor attachment and work-piece handling is done by the human, whereas the data collection, processing and anomaly detection is done autonomously using AI techniques. Our inspection algorithm is a generic approach using dilated convolutional neural network (DCNN) based multivariate time series predictive analytics. We demonstrate our approach on a gearbox inspection application, where we use time-series data streams captured from vibration sensors mounted on the gearbox. We have conducted experiments to demonstrate the effectiveness of the proposed DCNN solution for anomaly detection in a human robot collaborative assembly system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-90525-5_67,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-90321-3_2,One Step Deep Learning Approach to Grasp Detection in Robotics,Data Science and Intelligent Systems,10.1007/978-3-030-90321-3_2,Springer,2021-01-01,"Grasp point detection is a necessary ability to handle for industrial robots. In recent years, various deep learning-based techniques for robotic grasping have been introduced. To follow this trend, we introduce a convolutional neural network-based approach for model-free one step method for grasp point detection. This method provides all feasible grasp points suitable for parallel grippers, based on a single RGB image of the scene. A case study, which shows the outstanding accuracy of the presented approach as well as its acceptable response time, is presented at the end of this contribution.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-90321-3_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-51992-6_12,A Genetic Deep Learning Model for Electrophysiological Soft Robotics,Soft Computing Applications,10.1007/978-3-030-51992-6_12,Springer,2021-01-01,"Deep learning methods are modelled by means of multiple layers of predefined set of operations. These days, deep learning techniques utilizing un-supervised learning for training neural networks layers have shown effective results in various fields. Genetic algorithms, by contrast, are search and optimization algorithm that mimic evolutionary process. Previous scientific literatures reveal that genetic algorithms have been successfully implemented for training three-layer neural networks. In this paper, we propose a novel genetic approach to evolving deep learning networks. The performance of the proposed method is evaluated in the context of an electrophysiological soft robot-like system, the results of which demonstrate that our proposed hybrid system is capable of effectively training a deep learning network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-51992-6_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-79463-7_17,A Cloud-Based Robot Framework for Indoor Object Identification Using Unsupervised Segmentation Technique and Convolution Neural Network (CNN),Advances and Trends in Artificial Intelligence. From Theory to Practice,10.1007/978-3-030-79463-7_17,Springer,2021-01-01,"Nowadays autonomous indoor mobile robot is getting more attention in many application areas. A cloud-based multi-robot framework provides highspeed data processing and inter robot’s communication efficiently for the indoor mobile robot system. However, efficient detection and recognition of the environmental objects are vital issues for indoor mobile robots. Thus, this paper proposes a cloud-based multi-robot system, where Indoor objects are detected using a new unsupervised object segmentation model and object identification using cloud-based Convolutional Neural Networks (CNN) model. In the object segmentation model, a segmentation algorithm is developed with the combination of Canny edge detection, Floodfill, and BoundingBox image processing technique for efficiently segmenting the objects of the indoor environment. After detecting objects, a cloud-based CNN model with SoftMax classifier is used for classifying objects. Besides, an iterative learning is introduced in our proposed model for identifying unknown objects. Some indoor images captured by the camera are used to test the proposed system. To validate the proposed model, a benchmarked object image dataset from an open resource repository is used in this paper to train the CNN model. The model shows good object detection and identification result and the cloud-based framework enhance the usability of the proposed system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-79463-7_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-63128-4_23,Syntropic Counterpoints: Singularity Dadaism as Novel AI Creative Practice Paradigm,"Proceedings of the Future Technologies Conference (FTC) 2020, Volume 1",10.1007/978-3-030-63128-4_23,Springer,2021-01-01,"The recent development in the field of machine learning is filled with encounters of interesting robots’ creative responses and is becoming a challenging creative medium for artists. There are two possible directions in the future development of robots’ creativity, replicating the human mental processes or liberating machine creativity itself. In this paper, we are presenting artworks created within project Syntropic Counterpoints. In our aesthetical approach, we incline to the 21st-century avant-garde conceptual tradition. We intend to draw parallels between Dadaism and machine-made content and encompass Singularity and Dadaism into one, as a human less paradigm of uncontrollable creative practice closely related to AI aesthetic and machine abstraction phenomena. Key novelty in applied creative practice is use of artificial intelligence clones as creative medium for machine supervised content creation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-63128-4_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-66222-6_1,IoT-Aided Robotics Development and Applications with AI,Emergence of Cyber Physical System and IoT in Smart Automation and Robotics,10.1007/978-3-030-66222-6_1,Springer,2021-01-01,"Global research and developments in robotics and IoT have received noteworthy consideration in the present years. The chapter highlights some efforts of researchers in robotics and artificial intelligence using IoT applications and advancements. The intelligent robotics structures exploit the physical shapes of robotics and have the ability to think and perform duties like human beings. Artificial intelligence focusses on the aspects like how the robot or machine performs duties, such as reasoning, learning, and problem solving. The IoT of robotics is an emerging area of research and development that brings together universal sensors and autonomous systems. The fusion of robotics and IoT technologies will increase the capabilities of new creation in both the existing IoT and the robotics systems. Integration of the IoT and robotics gives birth to new concept titled “Internet of Robotic Things (IoRT)”; it talks about the beginning of cloud robotics and its support toward robotic functions like sensing, manipulation, and mobility. The IoRT-aided systems are very useful in various applications of every domain in life like medical, defense, farming, industrial plants, and rescue operations. Moreover, the track to an established evolution of IoT-aided robotics products needs several essential issues to be resolved, designing methods to be associated, and strong structural choices to be deliberated. This chapter covers scientific consequences, open problems, challenges, and target applications in the IoRT area. In today’s scenario, IoT-aided robotics has diverse fields and services like: communication networks, distributed and pervasive computing, semantic-oriented approaches to consensus, network security, and many others.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-66222-6_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-5859-7_17,AI-HI…The Technological Transgenders (AI-HI Techno-Trans),Proceedings of Fifth International Congress on Information and Communication Technology,10.1007/978-981-15-5859-7_17,Springer,2021-01-01,"The evolution of technology (specifically artificial intelligence and machine learning) in the recent time has made the human life easier, fast, and providing real-time solutions, but at the same time, its negative impacts are also simultaneously affecting the human intelligence and human behavior. This paper discusses some observations on the impact of technology (AI) upon the human intelligence (HI) and human behaviors, and the possible threats as an outcome of the uncontrolled and excess use of the technology enabling loss in the human intelligence, resulting in the emergence of ‘AI-HI…The Technological Transgenders’ abbreviated as ‘AI-HI Techno-Trans.’ The paper defines Techno-Trans Children, Techno-Trans Youth, and Techno-Trans Robots, who would collectively forms a Techno-Trans Society enabling the benefits and threats together. The rapid increase in the development of artificial intelligence (AI) technology, along with the simultaneous decline in human intelligence (HI) might be the outcome of the excess use of the technology, and dependency upon it at large toward the formation of the Techno-Trans Society.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-5859-7_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-5421-6_16,Drive into Future World Using Artificial Intelligence with Its Application in Sensor-Based Car Without Driver,Advances in Information Communication Technology and Computing,10.1007/978-981-15-5421-6_16,Springer,2021-01-01,"In the cutting edge period, artificial intelligence (AI) revolutionizes the world. Intelligent machines will alter the human capabilities in several areas. Artificial knowledge is the insight shown by different machines and software. It is considered as the subordinate of software engineering. Computerized analysis is turning into a renowned field in as it has upgraded the life of humans in many areas. Artificial insight over the last two decades has significantly improved the execution of the manufacturing and management systems. Study in the sector of artificial intelligence has offered ascend to the master framework, and its application in the vehicles is engaged to be computerized to give human driver loosened up driving. In the field of car, different viewpoints have been viewed as which makes a vehicle computerized. This paper discusses the artificial intelligence, types, space of artificial intelligence and its applications in field of the car without the driver using sensor-based technology and also talks about difficulty in the pathway of sensor-based cars and its future scope.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-5421-6_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-9956-9_48,Development of Vehicular Robots With Machine Learning Capability,Advances in Interdisciplinary Engineering,10.1007/978-981-15-9956-9_48,Springer,2021-01-01,"A prototype of any vehicle/robot is developed for having a better understanding of functional parts and behavior under restricted environment. In the present work an electric moving vehicle that resembles a robot called rover is designed and developed. The study consists of findings during the development of a rover with machine learning through Tensor Flow Lite, running on a Raspberry Pi 4B. The designed electronics rover has a 12 kg structure, 10 kg battery load, and ability to take 8 kg of load with a speed of 6.7 cm/sec when tested on flat surface. The same can also be maneuvered over different gradient terrains. This rover has independent suspension and two 4-Axis arms, one on each side. The power to the wheels is supplied by 6 motor of 12 V 1.2 A having rated torque of 80 kg-cm and stall torque 400 kg-cm. They provide details of part selection and its fitments to work as a combined unit. Once the prototype is scaled on a bigger scale it can be used for heavy industrial applications without compromising human safety.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-9956-9_48,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-90525-5_68,Personalization and Localization to Improve Social Robots’ Behaviors: A Literature Review,Social Robotics,10.1007/978-3-030-90525-5_68,Springer,2021-01-01,"Personalization and localization are essential when developing social robots for different sectors, including education, industry, healthcare or restaurants. This requires adjusting the robot's behavior to an individual's needs, preferences, or personality when referring to personalization or the social convention or country's culture when referring to localization. Current literature presents different models that enable personalization and localization, each with its advantages and drawbacks. This work aims to help researchers in social robotics by reviewing and analyzing different papers in this domain. We focus our review on exploring various technical methods used to make decisions and adapt social robots’ non-verbal and verbal skills, including the state-of-the-art techniques in the sector of artificial intelligence.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-90525-5_68,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-87595-4_21,"Initial Evaluation of an Intelligent Virtual Museum Prototype Powered by AI, XR and Robots","Augmented Reality, Virtual Reality, and Computer Graphics",10.1007/978-3-030-87595-4_21,Springer,2021-01-01,"This paper presents the design, development and initial evaluation of an intelligent virtual museum prototype based on a new type of Cyber-Physical-Social Eco-System (CPSeS) framework aiming to merge the real with virtual worlds interchangeably using AI, XR and Robots. Whereas virtual environments have become prominent tools in many domains, offering shared and interactive virtual worlds, the proposed prototype incorporates multi-user and interactive functionalities together with a new agent, namely, a physical robot and its digital twin. The physical robot is located and acts in a real environment whilst its avatar (further referred to as its digital twin) lives in the virtual world. The users are able to see and explore both worlds simultaneously through the ‘eyes’ of the robot. Together with multi-user infrastructure and communication capabilities, the environment also involves additional agents guiding the user in the virtual world, and an educational game, aiming at developing a CPSeS capable of blending the real with digital worlds, and to be influenced by its users, real and artificial agents and elements. The user-based qualitative evaluation of the proposed system was favourable but also constructive providing the research team with valuable observations on its performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-87595-4_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-5788-0_2,Sense Scheduling for Robotics Cognitive Intelligence,Evolution in Computational Intelligence,10.1007/978-981-15-5788-0_2,Springer,2021-01-01,"Gawali, Mahendra Bhatu Gawali, Swapnali Sunil Probably human is t he most intelligent animal live on the earth as compared to other animals. Human is intelligent because nature gifted him an extraordinary speciality that is thinking ability. On the basis of this thinking ability, human can decide what is wrong or correct for him or others. Twenty-first century is known for the artificial intelligence. Where humans are forming artificial intelligence (robots) to complete the daily works. But, it is a long lasting challenge for researchers/scientist to introduce sense in artificial intelligence. We proposed a human thought process method (HTPM) to decide a certain thing out of many options. We recorded every person’s thought while taking a decision. Scientifically, we concluded that our proposed HTPM method has given outstanding results when implemented in humanoid.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-5788-0_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-7961-5_114,Fruit Detection Using Recurrent Convolutional Neural Network (RCNN),ICCCE 2020,10.1007/978-981-15-7961-5_114,Springer,2021-01-01,"An accurate image based fruit detection model is crucial for agriculture task, Robotic harvesting. The features such as color similarity, shape irregularity and back ground are complex. Hence the fruit detection turns to be a difficult task. Many machine learning techniques such as Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Naïve bayes, have been used for the fruit recognition system which doesn’t yield a good accuracy. This paper brings out the various techniques used in the fruit detection model and also how the deep learning techniques can be used for detecting the fruit by considering the various features of fruit.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-7961-5_114,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-77246-8_8,Digital Social Contracts with AI Robots: Some Implications for Amazon.Com,Artificial Intelligence Systems and the Internet of Things in the Digital Era,10.1007/978-3-030-77246-8_8,Springer,2021-01-01,"The use of AI robots on platforms in the digital world is ubiquitous. Amazon.com has AI features that significantly enhance users’ productivity. There is no question that Amazon is subject to competition. Their competitors have their own standards. If standards can differentiate platforms, they could coexist. This study’s evaluation of Amazon along public policy guidelines suggests that there is no reason for imposing additional regulations for Amazon based on its current trend of operations. This study proposes a new thinking, passing beyond the analogy between platform operations and city operations, notably along the dimension of  private  vs.  public spaces , since people are familiar with thinking of issues in that paradigm as the pre-internet days.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77246-8_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-54173-6_15,Friendship Between Human Beings and AI Robots?,"Robotics, AI, and Humanity",10.1007/978-3-030-54173-6_15,Springer,2021-01-01,"In this chapter the case for potential Robophilia is based upon the positive properties and powers deriving from humans and AI co-working together in synergy. Hence, Archer asks ‘Can Human Beings and AI Robots be Friends?’ The need to foreground social change for structure culture and agency is being stressed. Human enhancement speeded up with medical advances with artificial insertions in the body, transplants, and genetic modification. In consequence, the definition of ‘being human’ is carried further away from naturalism and human essentialism. With the growing capacities of AI robots the tables are turned and implicitly pose the question, ‘so are they not persons too?’ Robophobia dominates Robophilia, in popular imagination and academia. With AI capacities now including ‘error-detection’, ‘self-elaboration of their pre-programming’ and ‘adaptation to their environment’, they have the potential for active collaboration with humankind, in research, therapy and care. This would entail synergy or co-working between humans and AI beings.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54173-6_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-78191-0_41,Future Frame Prediction for Robot-Assisted Surgery,Information Processing in Medical Imaging,10.1007/978-3-030-78191-0_41,Springer,2021-01-01,"Predicting future frames for robotic surgical video is an interesting, important yet extremely challenging problem, given that the operative tasks may have complex dynamics. Existing approaches on future prediction of natural videos were based on either deterministic models or stochastic models, including deep recurrent neural networks, optical flow, and latent space modeling. However, the potential in predicting meaningful movements of robots with dual arms in surgical scenarios has not been tapped so far, which is typically more challenging than forecasting independent motions of one arm robots in natural scenarios. In this paper, we propose a ternary prior guided variational autoencoder (TPG-VAE) model for future frame prediction in robotic surgical video sequences. Besides content distribution, our model learns motion distribution, which is novel to handle the small movements of surgical tools. Furthermore, we add the invariant prior information from the gesture class into the generation process to constrain the latent space of our model. To our best knowledge, this is the first time that the future frames of dual arm robots are predicted considering their unique characteristics relative to general robotic videos. Experiments demonstrate that our model gains more stable and realistic future frame prediction scenes with the suturing task on the public JIGSAWS dataset.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-78191-0_41,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-75275-0_1,Service Robots and Artificial Intelligence for Faster Diagnostics and Treatment in Medicine,"New Technologies, Development and Application IV",10.1007/978-3-030-75275-0_1,Springer,2021-01-01,"The development of new technologies such as information and communication technologies, electronics, sensor technology, etc. lead to the development of service robots and systems, which are used in all segments of human life. One of the most important roles of service robots today is application in the field of medicine. Service robots in medical institutions are used to perform simple or complex tasks. Simple tasks include deliveries of drugs, food or mail to medical facilities, while complex tasks include robotic systems used in operating rooms or even to perform operations using suitable robotic systems whose design and applied technology allow it, such as Zeus and Da Vinci systems. Service robots help doctors perform their tasks easier, safer, more accurately and faster. The paper illustrates examples of the application of service robots in diagnostics, radiation, surgery, remote treatment, rehabilitation, drug distribution, patient care and disinfection of rooms in medical institutions. The rapid development of new technologies had made it possible to free people from routine mental activities, and in the future more and more complex thought activities, such as: learning, analyzing, adapting, concluding, making decisions, etc. We come to the conclusion that there is a need for the application of artificial intelligence. The combination of service robots and artificial intelligence leads to the development of autonomous systems. Autonomous systems are developed in a targeted way so that they can surpass man himself in some properties, such as: physical strength, memory capacity, computational speed, parallel execution of several control actions, etc. The paper presents the role and application of artificial intelligence in diagnostics and treatment of various diseases.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-75275-0_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-68787-8_33,Image Segmentation of Bricks in Masonry Wall Using a Fusion of Machine Learning Algorithms,Pattern Recognition. ICPR International Workshops and Challenges,10.1007/978-3-030-68787-8_33,Springer,2021-01-01,"Autonomous mortar raking requires a computer vision system which is able to provide accurate segmentation masks of close-range images of brick walls. The goal is to detect and ultimately remove the mortar, leaving the bricks intact, thus automating this construction-related task. This paper proposes such a vision system based on the combination of machine learning algorithms. The proposed system fuses the individual segmentation outputs of eight classifiers by means of a weighted voting scheme and then performing a threshold operation to generate the final binary segmentation. A novel feature of this approach is the fusion of several segmentations using a low-cost commercial off-the-shelf hardware setup. The close-range brick wall segmentation capabilities of the system are demonstrated on a total of about 9 million data points.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-68787-8_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-76620-7_22,Constructing an Intelligent Navigation System for Autonomous Mobile Robot Based on Deep Reinforcement Learning,Soft Computing: Biomedical and Related Applications,10.1007/978-3-030-76620-7_22,Springer,2021-01-01,"Motion planning plays an essential role in motion control for autonomous mobile robots (ARMs). When the information about the operating environment and robot's position obtained from a simultaneous localization and mapping (SLAM) system, a navigation system guarantees that the robot can autonomously and safely move to the desired position in the virtual environments and simultaneously avoid any collisions. This paper presents an intelligent navigation system in unknown 2D environments based on deep reinforcement learning (DRL). Our work was constructed base on the Robot Operating System (ROS). The proposed method's efficiency and accuracy are shown in Gazebo's simulation results and the physical robot's actual results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-76620-7_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-75259-0_13,Accelerating Robot Reinforcement Learning with Accumulation of Knowledge,Advances in Service and Industrial Robotics,10.1007/978-3-030-75259-0_13,Springer,2021-01-01,"Reinforcement Learning (RL) can be applied in robotics to refine robot skills, but it may take several tens or even hundreds of attempts, which are typically just forgotten. In this paper, we show how all learning attempts, even those that do not fulfill the intended task, can be used to accelerate RL on the long-run. In a manner of non-continual lifelong learning we re-train a deep neural network that maps between the desired target/action outcome and the action in order to provide an initial estimate. Furthermore, for even faster learning, it is performed in reduced – latent space of a deep autoencoder. Robot throwing experiments clearly indicate, that the proposed methodology accelerates RL.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-75259-0_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-70665-4_57,Research on Robot Grasping Planning Method Based on Deep Reinforcement Learning,"Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery",10.1007/978-3-030-70665-4_57,Springer,2021-01-01,"Robot intelligent grasping plays an important role for achieving robot intelligence. With the complexity of the shape and size of the object to be grasped and the grasping environment, the traditional grasping technology can no longer meet the intelligent requirements. This article establishes a target grasping network model based on deep reinforcement learning, sets a task of grasping parts as the Markov decision process, uses deep Q learning networks for training, and uses fully convolutional networks to approximate the Actions − Values function in Q learning, which selects the best grasping action by maximizing the Q function. Finally, the feasibility of the established model is verified by simulation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-70665-4_57,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86230-5_34,Neural Network Classifier and Robotic Manipulation for an Autonomous Industrial Cork Feeder,Progress in Artificial Intelligence,10.1007/978-3-030-86230-5_34,Springer,2021-01-01,"This paper presents a solution for an autonomous cork puncher feeder with a robotic arm using image processing techniques and a convolutional neural network. Due to the need for cork strips to be inserted into the puncher with a specific orientation, to produce high quality cork stoppers, the identification of the orientation of each cork strip on the conveyor belt is a necessity. In response to this problem a convolutional neural network is used to analyse images processed with subtracted background, to create a robust solution for cork strips classification. In the tests carried out, a classification accuracy of 100% was obtained in a test data set with 12 different cork strips.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-86230-5_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-4477-4_34,A Neurodynamic Approach to Stabilization of a 10 DOF Biped Mechanism Using Reinforcement Learning,Mechanism and Machine Science,10.1007/978-981-15-4477-4_34,Springer,2021-01-01,"In this paper, we propose a Reinforcement Learning (RL) based approach to stabilizing and control of a biped robot. Bipeds have complex requirements of stabilization and gait planning in multiple degrees of freedom. A reinforcement learning strategy is presented in this work for the stabilization of a single leg as well as a biped to create a learned behavior of a system. In this paper, each leg of the Humanoid biped robot is approximated as a double inverted pendulum, and its static stabilization is studied in the sagittal plane. The equations of motion are derived using Lagrange’s formulation method. An equivalent Humanoid robot single leg and biped model developed in Gazebo. Through Robotic Operating System (ROS), a reinforcement learning based control algorithm was developed for static stabilization, and the simulation was carried out on the Gazebo model. A total of 1458 states are used for training the reinforcement learning algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-4477-4_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-90525-5_7,Automated Lip-Reading Robotic System Based on Convolutional Neural Network and Long Short-Term Memory,Social Robotics,10.1007/978-3-030-90525-5_7,Springer,2021-01-01,"In Iranian Sign Language (ISL), alongside the movement of fingers/arms, the dynamic movement of lips is also essential to perform/recognize a sign completely and correctly. In a follow up of our previous studies in empowering the RASA social robot to interact with individuals with hearing problems via sign language, we have proposed two automated lip-reading systems based on DNN architectures, a CNN-LSTM and a 3D-CNN, on the robotic system to recognize OuluVS2 database words. In the first network, CNN was used to extract static features, and LSTM was used to model temporal dynamics. In the second one, a 3D-CNN network was used to extract appropriate visual and temporal features from the videos. The accuracy rate of 89.44% and 86.39% were obtained for the presented CNN-LSTM and 3D-CNN networks, respectively; which were fairly promising for our automated lip-reading robotic system. Although the proposed non-complex networks did not provide the highest accuracy for this database (based on the literature), 1) they were able to provide better results than some of the more complex and even pre-trained networks in the literature, 2) they are trained very fast, and 3) they are quite appropriate and acceptable for the robotic system during Human-Robot Interactions (HRI) via sign language.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-90525-5_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-4803-8_11,Human-Like Control System Design of the Lower Limb Rehabilitation Robot Based on Adaptive RBF Neural Network,RiTA 2020,10.1007/978-981-16-4803-8_11,Springer,2021-01-01,"Lower limb rehabilitation robot (LLRR) brings hope to the patients with lower-limb paralysis. However, the security and stability of the LLRR are still the challenging problems. To provide safer and more effective rehabilitation training for patients, a human-like control system of LLRR based on adaptive radial basis function (ARBF) neural network is proposed. The optical 3D motion capture platform (O3DMCP) is adopted to collect the human gait data (HGD) from the healthy subjects. The HGD is used as the expected trajectory for LLRR, this can make the rehabilitation training more consistent with the human kinematics characteristics. To improve the tracking accuracy, the ARBF neural network controller is adopted estimate the model uncertain parameters. Simulation results demonstrate the effectiveness of the proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-4803-8_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.3103/S014641162101003X,Local Path Planning of Mobile Robot Based on Long Short-Term Memory Neural Network,Automatic Control and Computer Sciences,10.3103/S014641162101003X,Springer,2021-01-01,"Abstract In order to solve the local path planning problem of mobile robot in the unknown environment, more complex control algorithms and solutions are needed for various special situations; however, they cannot be suitable for every environment. A local path planning algorithm of the mobile robot based on Long Short-Term Memory (LSTM) neural network is proposed to simplify the complexity of control, increase the ability of learning and generalization, and improve the efficiency of path planning. Firstly, the model structure of LSTM neural network is designed based on the task requirements of the local path planning of mobile robot. Then, the training data needed by the neural network are collected based on the fuzzy control algorithm and used to train the LSTM model. Finally, the trained model is tested according to the local path planning task. The experimental results show that compared with the fuzzy control algorithm, the designed method improves the calculation velocity, and can adapt to the environment with more obstacles compared with the BP neural network algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.3103/S014641162101003X,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-62324-1_15,A Flexible Sliding Mode Controller for Robot Manipulators Using a New Type of Neural-Network Predictor,Computational Intelligence Methods for Green Technology and Sustainable Development,10.1007/978-3-030-62324-1_15,Springer,2021-01-01,This paper presents a free-model high-precision controller for robot manipulators using variation sliding mode scheme and a semi-positive neural-network design. The total dynamics of the robot is first estimated by the neural network in which a new type of learning laws is proposed based on twisting excitation signals. A flexible sliding mode control interface is then developed to realize control objectives using the estimation result of the neural network. The control performance of the closed-loop system is verified by the intensively theoretical proof and simulation results.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-62324-1_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7502-7_23,Compound Fault Diagnosis of Industrial Robot Based on Improved Multi-label One-Dimensional Convolutional Neural Network,Data Mining and Big Data,10.1007/978-981-16-7502-7_23,Springer,2021-01-01,"Industrial robot is one kind of complex infrastructure in industrial production and applications. Fault diagnosis is an important part of the intelligent application and monitoring of industrial robots. For multi-axis industrial robot compound fault prediction and diagnosis problem, this paper proposes a fault diagnosis model based on improved multi-label one-dimensional convolutional neural network (ML-SRIPCNN-1D). Firstly, the compound fault data set is enhanced by random sampling and Mixup. Then, the single fault data and compound fault data were trained end-to-end by the improved multi-label one-dimensional convolutional neural network. Finally, accurate diagnosis and prediction of compound faults of industrial robots are implemented. The compound fault data set was derived from a company's multi-axis industrial robot. The characteristic variables of fault diagnosis are torque, current, velocity, position, etc. Compared with SRIPCNN-1D, MLCNN, WT-MLCNN, T-FSM-MLCNN, ELM + AE + SVM, LMD + TDSF + ML-KNN models, the average diagnosis accuracy of ML-SRIPCNN-1D reached 98.67%. The model has good diagnosis effect and high accuracy for the prediction and diagnosis of industrial robot compound fault.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7502-7_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7476-1_35,Multi-axis Industrial Robot Fault Diagnosis Model Based on Improved One-Dimensional Convolutional Neural Network,Data Mining and Big Data,10.1007/978-981-16-7476-1_35,Springer,2021-01-01,"Industrial robots have become indispensable equipment in the automated manufacturing process. However, there are currently few deep learning fault diagnosis methods based on industrial robot operation. Aiming at the problems of low fault diagnosis accuracy and slow speed during the operation of industrial robots, a fault diagnosis model based on an improved one-dimensional convolutional neural network is proposed. To solve the problem of lack of industrial robot fault datasets, this paper uses the method based on random sampling and Mixup data augmentation to enhance data. Then, the model based on the original operation data of industrial robot are trained end-to-end by orthogonal regularization (SRIP) that combines with a one-dimensional convolutional neural network (CNN-1D). The experiment tests the diagnostic accuracy based on 3 million pieces of industrial robot operating data, which includes torque, speed, position, and current. Compared with the WDCNN and CNN-1D models, SRIPCNN-1D method can diagnose industrial robot faults effectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7476-1_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-66937-9_15,Prometheus (PN-2003016) Digital Medical Device Collaborative E-Training and Cognitive Ergonomics to Integrate AI and Robotics in Organ Transplantations,Proceedings of the 8th International Ergonomics Conference,10.1007/978-3-030-66937-9_15,Springer,2021-01-01,"Computer Assisted Collaborative E-Training integrating Cognitive Ergonomics of AI and Robotics to interactively train specialists in the procurement phase of Organ Transplantation (OT) is dealt. It is analyzed the clinical simulating collaborative training session among 10 specialists in OT that took place in the Megaron Hall of Athens trial on 26.02.2019 training them interactively how cognitive ergonomics integrated with AI promote the remote evaluation of the grafts and the pre- and post-grafting and pre-transplant decision making and planning so as to minimize the rates of the damaged organs focusing on infections, by using the Prometheus digital medical device (pn:2003016) integrated with the Robotic framework “Stamoulis” Rb. The results showed that AI and Robotic based cognitive ergonomics integration in ΟΤ interactive e-training enhances significantly operational maneuverability and inter-operability to remotely and with the minimum errors: a. Make accurate diagnosis and minimize damaged or diseased, with infection, trauma and cancer, grafts, b. Intensify an international clinical surveillance ergonomic system development in the procurement phase of OT, and c. Integrate ergonomically robotics in OT with the minimum errors in the clinical process.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-66937-9_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-66937-9_16,Prometheus I (PN 1008239) Digital Medical Device Integrated with AI and Robotics Cognitive Ergonomics in Breast Cancer Prevention,Proceedings of the 8th International Ergonomics Conference,10.1007/978-3-030-66937-9_16,Springer,2021-01-01,"The necessity, technology, process, service, and ergonomics of the clinical remote massive public education, primary, secondary and tertiary breast cancer prevention upon innovative networks for specialists and citizens in the context of the clinical prevention operations of the tele-medicine and cloud technology based novel mobile clinical unit (MCU) called “Macedonia” has been studied, tried and standardized in the program of Excellence 2014–16. It is analyzed the clinical prevention operability, maneuverability and reliability of the above mentioned technology and method empowered with cognitive ergonomics of AI and a robotic framework the “Charicleia” Rb integrated with Prometheus Ι (pn 1008239) digital medical device all integrated with (MCU) in the tenth and the eleventh clinical diseases prevention action in Promyrion village of the Municipality of South Pelion Mountain and in the Parish of Agioi Anargyroi of Volos on 05-06.06 and in Demene village of Municipality of Aisonia on 07.07.2020 for remote clinical remote massive public education, primary, secondary and tertiary breast cancer prevention. Ergonomic Integration of (MCU) operations enriched with AI and Big Data analytics and Robotics may optimize: (1) breast cancer prevention status, (2) quality of healthcare especially in developing countries.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-66937-9_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-88081-1_24,"Adam Smith’s Invisible Hand as a New, Powerful and Robust Control Paradigm for Collective AI Robotics",Computational Collective Intelligence,10.1007/978-3-030-88081-1_24,Springer,2021-01-01,"The market launch of Tesla electric cars with an intelligent autopilot capable of dealing with the chaos of street traffic, shows how dramatic the need to develop a theory of building control systems for autonomous intelligent robots is, where there is no central control or it only exists locally. However, a suitable theory exists in the area of economics, for free (quasi free) markets, called “Adam Smith’s Invisible Hand” (ASIH). The general assumption of this theory is “ that there is no control system, which will do better for the welfare of the free market, than spontaneous, unconscious, distributed, self-control/optimization that (ASIH) is able to perform ”. In general, this theory is the front line of a harsh dispute between advocates of interventionism and advocates of liberalism. This paper presents how the ASIH theory could be distilled to obtain a general control theory for systems of autonomous, mobile, quasi-intelligent robots, for unmanned building sites, deep mines, etc. such that collective self-control is inborn into the nature of robots and no centralized control is necessary. The first theoretical results indicate that self-control and optimization systems based on such a theory should be much more intelligent in terms of problem solving than centralized systems could be and incomparably more resistant, e.g. when parts of a robot group are destroyed. The reason for this is, that such systems better exploit the potential of individual intelligences of agents.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-88081-1_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-65785-7_55,Enhancing the Visitor Experience in the Time of COVID 19: The Use of AI Robotics in Pembrokeshire Coastal Pathway,Information and Communication Technologies in Tourism 2021,10.1007/978-3-030-65785-7_55,Springer,2021-01-01,"AI and Robots represent a major innovation opportunity for the tourism sector, and their potential impact and application offer several new opportunities to enhance and develop the visitor experience. Nevertheless, there has been limited academic research on the use of robots, together with a limited number of destinations embracing this technology. Focusing on the Pembrokeshire Coastal Path, this research paper outlines how a multi methodological approach could be utilised to examine the use of AI and robotics in helping to enhance the visitor experience during the ongoing COVID-19 pandemic. The researchers anticipate that outcomes from such a study could not only provide theoretical contributions in the area of addressing concerns about accessibility in tourism and leisure settings, but also serve to inform both academia and the wider tourism industry to the benefits such technology can have towards enhancing the visitor experience within social distancing parameters.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-65785-7_55,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-4604-8_50,A Study on Steam Cleaning Devices and Its Impact on Health and Hygiene,Applications of Artificial Intelligence in Engineering,10.1007/978-981-33-4604-8_50,Springer,2021-01-01,"Health and hygiene are topics that are inextricably intertwined from ages. Off late, steam cleaning has overtaken the traditional cleaning techniques in many places, due to the many advantages it offers. There is numerous health benefit of using steam for cleaning as we are only using heat and water to generate the steam to clean with. Many cleaning agents contain sodium hypochlorite, and since it is an oxidizing agent, it can cause a burning sensation or can even damage the skin. Cleaning with steam does not use poisonous and toxic chemicals like bleach and ammonia. Therefore, it does not leave residues of the harmful chemicals. Moreover, apart from cleaning, the comfort of the person involved in cleaning has been prioritized in many of the development so far. With time, the steam cleaning must be accepted globally for a better future which promises a healthy growing environment than the one we are dealing with now. Till now, there is various kind of steam cleaners that has been proposed by various inventors and researchers. A steam cleaner after all provides complete sterilization thus enhancing the living condition. The various steam cleaners include the upright steam cleaner, one with the rotatable brush, then in some inventions clean water is subjected to super atmospheric pressure, the steam cleaner that automatically powers off, pressure and temperature control steam cleaner, robotic extraction cleaner with dusting pad, an autonomous floor-cleaning robot, artificial intelligence robot cleaner, robot cleaning system, and many more which has been discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-4604-8_50,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-54173-6_18,Impact of AI/Robotics on Human Relations: Co-evolution Through Hybridisation,"Robotics, AI, and Humanity",10.1007/978-3-030-54173-6_18,Springer,2021-01-01,"This chapter examines how the processes of human enhancement that have been brought about by the digital revolution (including AI and robotics, besides ICTs) have given rise to new social identities and relationships. The central question consists in asking how the Digital Technological Matrix, understood as a cultural code that supports artificial intelligence and related technologies, causes a hybridisation between the human and the non-human, and to what extent such hybridisation promotes or puts human dignity at risk. Hybridisation is defined here as entanglements and interchanges between digital machines, their ways of operating, and human elements in social practices. The issue is not whether AI or robots can assume human-like characteristics, but how they interact with humans and affect their social identities and relationships, thereby generating a new kind of society.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54173-6_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-54173-6_1,"AI, Robotics, and Humanity: Opportunities, Risks, and Implications for Ethics and Policy","Robotics, AI, and Humanity",10.1007/978-3-030-54173-6_1,Springer,2021-01-01,"This introduction to the volume gives an overview of foundational issues in AI and robotics, looking into AI’s computational basis, brain–AI comparisons, and conflicting positions on AI and consciousness. AI and robotics are changing the future of society in areas such as work, education, industry, farming, and mobility, as well as services like banking. Another important concern addressed in this volume are the impacts of AI and robotics on poor people and on inequality. These implications are being reviewed, including how to respond to challenges and how to build on the opportunities afforded by AI and robotics. An important area of new risks is robotics and AI implications for militarized conflicts. Throughout this introductory chapter and in the volume, AI/robot-human interactions, as well as the ethical and religious implications, are considered. Approaches for fruitfully managing the coexistence of humans and robots are evaluated. New forms of regulating AI and robotics are called for which serve the public good but also ensure proper data protection and personal privacy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54173-6_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-54173-6_7,AI/Robotics and the Poor,"Robotics, AI, and Humanity",10.1007/978-3-030-54173-6_7,Springer,2021-01-01,"Artificial intelligence and robotics (AI/R) have the potential to greatly change livelihoods. Information on how AI/R may affect the poor is scarce. This chapter aims to address this gap in research. A framework is established that depicts poverty and marginality conditions of health, education, public services, work, small businesses, including farming, as well as the voice and empowerment of the poor. This framework identifies points of entry of AI/R, and is complemented by a more detailed discussion of the way in which changes through AI/R in these areas may relate positively or negatively to the livelihood of the poor. Context will play an important role determining the AI/R consequences for the diverse populations in poverty and marginalized populations at risk. This chapter calls for empirical scenarios and modelling analyses to better understand the different components in the emerging technological and institutional AI/R innovations and to identify how they will shape the livelihoods of poor households and communities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54173-6_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-56433-9_11,The System of Law and Artificial Intelligence in Modern Russia: Goals and Instruments of Digital Modernization,Socio-economic Systems: Paradigms for the Future,10.1007/978-3-030-56433-9_11,Springer,2021-01-01,"Objective : in Chapter the aim is to identify the issues of goal setting, creating a legal regulation of cyber-physical systems, neural systems, created on the basis of artificial intelligence, robots and robotics, the authors believe that such a General goal-setting due to the complex internal and external factors related to the discrepancy of the regulatory framework to new technological conditions and the level of development of science and technology, the emergence of new problems of globalization, the struggle for technological superiority. Design/methodology/approach : the article considers approaches to determining the principles and objectives of the development of artificial intelligence, robots and robotics objects, the most effective development of which should contribute to the implementation of the provisions of the National strategy for the development of artificial intelligence. The methodology of the Chapter consists in the use of methods of interpretation of legal documents and formal and logical tools not only in the system, but also in comparative legal analysis of existing strategic and regulatory legal acts of foreign States that determine their policy in this area. Conclusions : the conclusion is made about the need to strengthen the legal regulation of artificial intelligence, robots and robotics objects. Setting the objectives of legal regulation in the field under study, depends on the formulation of not only General, but also specific goals of improving legislation in the field of artificial intelligent systems and robotics. Originality/value : the solution of these tasks, according to the authors, will contribute to strengthening the digital security of the individual, society and the state; creating economic conditions for the development and introduction of modern technologies based on the use of artificial intelligence, robots and robotics objects; stimulating innovative development with the aim of priority development of Russia.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-56433-9_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-56433-9_10,Ontology of Artificial Intelligence: On the Question of the Dehumanization of Social Regulators,Socio-economic Systems: Paradigms for the Future,10.1007/978-3-030-56433-9_10,Springer,2021-01-01,"Objective : the purpose of this chapter is to analyze ontological approaches to the study of artificial intelligence. Legal ontology of this issue is mandatory for the implementation of the national program of development of artificial intelligence, its legal regulation in order to define artificial intelligence as quasi-objects of law, and robots and objects of robotics—as objects of legal relations. Design/methodology/approach : the article considers approaches to determining the essential features of artificial intelligence, its fundamental differences from other robots and objects of robotics, which is necessary for the most effective implementation of the provisions of the National strategy for the development of artificial intelligence until 2030. The methodology of the Chapter consists in the use of methods of interpretation of legal documents and formal and logical tools not only in the system, but also in the comparative legal analysis of existing strategic and regulatory legal acts of foreign States that determine their policy in this area. Conclusions : it is concluded that there is a need for new approaches to determine the place and role of various objects of robotics, neural systems, artificial intelligence in the system of law and the system of legislation and the possibility of defining artificial intelligence as a quasi-object of law. Originality/value : the solution of these tasks, according to the authors, will contribute to strengthening the digital security of the individual, society and the state; creating economic conditions for the development and implementation of modern technologies based on the use of artificial intelligence, robots and robotic objects; stimulating innovative development for the priority development of Russia.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-56433-9_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-0598-7_5,Design and Development of an Intelligent Robot for Improving Crop Productivity Using Machine Learning,Machine Learning for Robotics Applications,10.1007/978-981-16-0598-7_5,Springer,2021-01-01,"India is the second most populated country in the world, and to fulfil the basic needs of the population, the country needs to have a watch on food, shelter and vesture. AI and machine learning have grabbed their place in many fields, one of those is agriculture. Using the prediction techniques and intelligence, AI and machine learning have contributed a lot in the agricultural domain. In this chapter, we are focusing on an agrobot that analyses the plant’s need by checking the soil moisture and need of water in the plant. It also analyses other needs of the plant and discovers ways to increase the productivity of the plant. The bot has previously stored information of the diseases the plant would get affected from, and the machine is trained and tested to check the same. The main work of the bot is to capture the image with the camera that is attached with Raspberry Pi 4. The agrobot checks the input image by pre-processing the image and squinching the obnoxious raw material. The image acquisition is done, and the image is filtered and enhanced to give the best possible information. Raspberry Pi is trained with CNN algorithm. It does the feature scaling and finds the region of interest. The CNN checks whether the plant is infected or healthy. If the plant is infected, it predicts the disease the plant is suffering from, using the trained data. If a disease is encountered, the agrobot provides the name of the disease. It also checks for the possible medication for it. The cause of the disease is then found, and the suggestion for the prevention of the disease is also provided. It interacts with the farmer and provides adjuration to increase the productivity of the crop thereby meeting the ever increasing demand of food of the increasing population. Using the concepts of machine learning and artificial intelligence, the robot helps the farmer to produce the best quality crop.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-0598-7_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-4909-4_29,Role of Internet of Things and Machine Learning in Finding the Optimal Path for an Autonomous Mobile Robot,"International Conference on Communication, Computing and Electronics Systems",10.1007/978-981-33-4909-4_29,Springer,2021-01-01,"Path planning for the mobile robot is an emerging area in today’s world; the development of autonomous vehicles like driverless cars and mobile robots has tremendously enhanced researchers to work more on path planning strategies using emerging technologies, like the Internet of things and machine learning. These technologies will provide optimal solutions than classical problem-solving algorithms. The article deals with path planning for mobile robots in an unknown environment using deep learning and the Internet of things. These technologies are adopted to work in different strategies like environmental prediction, object detection/ obstacle detection, and finding a path. For this, an innovative model is proposed to detect static and dynamic obstacles from the input data and finding a path from one point to another point.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-4909-4_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85607-6_62,Robotic Emotion Monitoring for Mental Health Applications: Preliminary Outcomes of a Survey,Human-Computer Interaction – INTERACT 2021,10.1007/978-3-030-85607-6_62,Springer,2021-01-01,"Maintaining mental health is crucial for emotional, psychological, and social well-being. Currently, however, societal mental health is at an all-time low. Robots have already proven useful in medicine, and robot assisted mental therapies through emotional monitoring have great potential. This paper reviews 60 recent papers to determine how accurately robots can classify human emotions using the latest sensor technologies. Among 18 different signals, it was determined that EDA sensors are best for this application. Our findings also show that CNN outperforms SVM, SVR, KNN and LDA for classifying EDA data with an average of 79% accuracy. This is further improved with the addition of RGB sensor data.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-85607-6_62,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-70740-8_18,Artificial Intelligence and Robotics Addressing COVID-19 Pandemic’s Challenges,Modelling and Simulation for Autonomous Systems,10.1007/978-3-030-70740-8_18,Springer,2021-01-01,"There is a growing awareness that the unfolding Covid-19 pandemic will deeply change people’s lives, while in the humanitarian system the gap between available resources and need is widening. Authors aim to investigate the ways new technologies can be effective in addressing global challenges. A session has been conducted at the United Nations conference HNPW 2020 where humanitarian experts have recognized the potential for Artificial intelligence (AI) and robotics to support response, decision-making, logistics and health services. In effect, one of the differences between Covid-19 and previous epidemics, consists in the massive deployment of technologies’ applications for monitoring, surveillance, detection, prevention, and mitigation. Areas of concern have been identified in bias, accuracy, protection and use of data, citizens’ privacy and legal gaps. Provided that such issues are addressed in every new project, authors propose to link AI and robotics with the triple nexus concept of the Humanitarian-Development-Peace (HDP) aiming to bridge the divide between humanitarian assistance, development agenda and peacebuilding.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-70740-8_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-52287-2_11,From High-Fidelity Patient Simulators to Robotics and Artificial Intelligence: A Discussion Paper on New Challenges to Enhance Learning in Nursing Education,"Methodologies and Intelligent Systems for Technology Enhanced Learning, 10th International Conference. Workshops",10.1007/978-3-030-52287-2_11,Springer,2021-01-01,"High-fidelity simulation (HFS) is an educational method based on technological mannequins which faithfully reproduces both physiological or physiopathological human body responses to specific clinical conditions and nursing care. When the traditional education is integrated with HFS, improvements in nursing students’ knowledge, performance, self-efficacy, self-confidence, problem solving ability, and critical thinking were reported, as well as relational and empathic skills. The level of realism reached in HFS sessions, defined as the ‘degree to which a simulated experience approaches reality’ demonstrated a positive association with students’ learning outcomes. Most of high-fidelity patient simulators are computer-driven static mannequins which resemble adult or child human body dimensions. However, they show limits that should be overcome to provide a more realistic full-body experience in nursing education. In this regard, robotics and artificial intelligence have a key role for the technological evolution of nursing educational systems and their introduction in the simulation field is opening new perspectives that will produce unavoidably the redefinition of educational standards with beneficial implications for future nursing care. In this perspective, new challenges for nursing education has been discussed in this paper.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-52287-2_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-5879-5_2,An Overlapping Architecture of Large-Size Wide-Body Aircraft Based on Cloud Sea Computing in 5G OGCE,Advances in Wireless Communications and Applications,10.1007/978-981-15-5879-5_2,Springer,2021-01-01,"Based on the fifth generation of mobile communication (5G), 5G open grid computing environment (5G OGCE), in order to avoid the accident of commercial passenger aircraft caused by the engine fire, cloud sea computing (CSC) model, and an overlapping fault-tolerant large-size wide-body (large passenger) aircraft architecture based on CSC are presented in this paper. The new overlapping architecture (or configuration) consists of a coupling robot (CR), a flying wing structure (blended wing body (BWB)) regarded as a load-carrying carrier aircraft (host), and a commercial passenger aircraft with two semi-embedded rear propulsion engines regarded as a passenger cabin. A passenger-cabin passenger plane, a swept-back wing host aircraft, and a coupling robot (CR) combine and form an overlapping fault-tolerant structure’s large passenger aircraft. The CR can tightly couple with the carrier aircraft (host) and the passenger-cabin aircraft (boarding aircraft). The CR consists of a grasping hand type robot (GHTR) and so on. A 5G/6G control cloud of cloud sea computing (CSC) model in 5G OGCE controls the operation of CR and flying and the disassembly of an overlapping fault-tolerant large-size wide-body aircraft. When the engine failure of the load-carrying (carrier) aircraft occurs, passenger-cabin aircraft is launched and ejected from the overlapping fault-tolerant large passenger aircraft (OFTLPA) by the grasping hand of GHTR of CR under the control of the control cloud and the pilot, OFTLPA breaks up. The passenger-cabin aircraft flies away from the load-carrying aircraft and realizes safe flight.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-5879-5_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-77939-9_11,Deep Learning Based Formation Control of Drones,Deep Learning for Unmanned Systems,10.1007/978-3-030-77939-9_11,Springer,2021-01-01,"Robot swarms can accomplish demanding missions fast, efficiently, and accurately. For a robust operation, robot swarms need to be equipped with reliable localization algorithms. Usually, the global positioning system (GPS) and motion capture cameras are employed to provide robot swarms with absolute position data with high precision. However, such infrastructures make the robots dependent on certain areas and hence reduce robustness. Thus, robots should have onboard localization capabilities to demonstrate a swarm behavior in challenging scenarios such as GPS-denied environments. Motivated by the need for a reliable onboard localization framework for robot swarms, we present a distance and vision-based localization algorithm integrated into a distributed formation control framework for three-drone systems. The proposed approach is established upon the bearing angles and the relative distances between the pairs of drones in a cyclic formation where each drone follows its coleader. We equip each drone with a monocular camera sensor and derive the bearing angle between a drone and its coleader with the recently developed deep learning algorithms. The onboard measurements are then relayed back to the formation control algorithm in which every drone computes its control action in its own frame based on its neighbors only, forming a completely distributed architecture. The proposed approach enables three-drone systems to perform in coordination indepen- dent of any external infrastructure. We validate the performance of our approach in a realistic simulation environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77939-9_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89177-0_23,Predicting Artist Drawing Activity via Multi-camera Inputs for Co-creative Drawing,Towards Autonomous Robotic Systems,10.1007/978-3-030-89177-0_23,Springer,2021-01-01,"This paper presents the results of computer vision experiments in the perception of an artist drawing with analog media (pen and paper), with the aim to contribute towards a human-robot co-creative drawing system. Using data gathered from user studies with artists and illustrators, two types of CNN models were designed and evaluated. Both models use multi-camera images of the drawing surface as input. One models predicts an artist’s activity (e.g. are they drawing or not?). The other model predicts the position of the pen on the canvas. Results of different combination of input sources are presented. The overall mean accuracy is 95% (std: 7%) for predicting when the artist is present and 68% (std: 15%) for predicting when the artist is drawing. The model predicts the pen’s position on the drawing canvas with a mean squared error (in normalised units) of 0.0034 (std: 0.0099). These results contribute towards the development of an autonomous robotic system which is aware of an artist at work via camera based input. In addition, this benefits the artist with a more fluid physical to digital workflow for creative content creation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89177-0_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-79357-9_64,Methods for Trajectory Prediction in Table Tennis,Trends in Data Engineering Methods for Intelligent Systems,10.1007/978-3-030-79357-9_64,Springer,2021-01-01,"Training and skill improvement is totally about finding a valuable partner in table tennis. It is difficult to find a partner who has various of good technical skills, teaching capacity to improve your skills, and whose training hours are compatible. Thus, so many researchers improve several methods and systems to solve this deficiency with robot table tennis. This paper provides a review of the common methods and systems then tries to explain how far these methods are from the solution that the professional/semiprofessional table tennis players expected. Some researchers are focused on the whole system, some study on a specific part of the problem. So this review provides a category-based approach to this subject and gives information about the last situation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-79357-9_64,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-8767-2_1,Autonomous Obstacle Avoidance Robot Using Regression,Proceedings of International Conference on Computational Intelligence and Data Engineering,10.1007/978-981-15-8767-2_1,Springer,2021-01-01,"Obstacle avoidance is considered as one of the main features of autonomous intelligent systems. There are various methods for obstacle avoidance. In this paper, obstacle avoidance is achieved by the difference between left wheel velocity and right wheel velocity of differential drive robot. The magnitude of difference between the wheel velocities is used to steer the robot in the correct direction. Data is collected by driving the robot manually. Ultrasonic sensors are used for distance measurement and IR sensors are used to collect the data of wheel velocities. This data is used to build a linear machine learning model which uses sonar data as input features. The model is used to predict the wheel velocities of the differential drive robot. The model built is then programmed into Atmega328 microcontroller using Arduino IDE. This enables the mobile robot to steer itself to avoid the obstacles. Since all the components used for this robot are highly available and cost-effective, the robot is economically affordable.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-8767-2_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-1510-8_27,Improvement of PID Controllers by Recurrent Fuzzy Neural Networks for Delta Robot,"Intelligent Communication, Control and Devices",10.1007/978-981-16-1510-8_27,Springer,2021-01-01,"The objective of this study is to control rotational angles of a 3-degree freedom robot for tracking to the reference trajectories. That is a parallel robot, named Delta, with complex movements in shaping, processing with high efficiency, high load capacity, widely used in industry. The PID controller has been successfully developed for the Delta robot. However, when changing the robot’s parameters such as load, input coupling and friction, the PID controller is difficult to archive control criteria. This article proposes and tests a solution to improve the PID controller by combining it with a recurrent fuzzy neural network (RFNN) controller, so-called RFNN-PID controller. In the proposed solution, the PID controller plays the main role of controlling the Delta robot and the RFNN controller takes charge of a supplemental role to gain with the changes of control conditions. The RFNN-PID and PID controllers will be tested in the same conditions in MATLAB/Simulink. Simulations illustrate that the proposed controller is better than the traditional one, obtaining a response time of about 3.9 ± 0.1 (s) without steady-state error.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-1510-8_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-4443-3_34,Deep Learning for Robot Vision,Intelligent Manufacturing and Energy Sustainability,10.1007/978-981-33-4443-3_34,Springer,2021-01-01,"Deep learning comes under a class of machine learning where we use it for extremely high-level output, like recognition of images, etc. It has been used in pattern recognition over a vast area such as handmade crafts to extract the data from learning procedures. At present, it has gained a great significance in robot vision. In this paper, we show how neural networks play a vital role in robot vision. Image segmentation, which is the initial step, is used to preprocess the images and videos. The multilayered artificial neural networks have a lot more applications. It can be applied in drug detection, military bases, and many more. The main objective of this paper is to review how deep learning algorithms and deep nets can be used in various areas of robot vision. There are some predefined deep learning algorithms that are available in the market, which are used here to perform this comparative study. These will help us to have a clear insight while building vision systems using deep learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-4443-3_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-4355-9_45,Deep Learning-Based Bluetooth-Controlled Robot for Automated Object Classification,Proceedings of International Conference on Sustainable Expert Systems,10.1007/978-981-33-4355-9_45,Springer,2021-01-01,"This paper presents a pick and place robot which can be monitored and controlled remotely through MATLAB within a range of 10 m. Our system is to retrieve predefined displaced items from a known area. The robot can be remotely controlled by an android phone to move through the area of interest. The robot while moving through its path uses an IP camera to stream images of its current surroundings through Wi-Fi to a deep neural network (DNN) created in MATLAB. The DNN determines if an item of interest is present and triggers appropriate control action to retrieve the item. The three main parts of the machine are, pick and place arm, base with 4 wheels attached to individual DC motors, control and communication system using Arduino, L298N motor drivers and HC05 module. The system works using two Arduino Uno-based controllers and four servo motors that move the arm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-4355-9_45,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10163-020-01098-z,Deep learning of grasping detection for a robot used in sorting construction and demolition waste,Journal of Material Cycles and Waste Management,10.1007/s10163-020-01098-z,Springer,2021-01-01,"The traditional construction and demolition waste (CDW) treatment process adopts the method of crushing and screening after mixing and combines the method with manual sorting for resource recycling. However, there is a problem of low recycling purity and low efficiency of manual sorting after mixed screening. This paper proposes a robot for sorting CDW, which is used to finely sort a large number of objects before mixing and crushing. The use of the robot improves the level of resource utilization of CDW. However, under actual working conditions, the adhesion and stacking of CDW on the conveyor belt and the irregularity of the shapes of CDW lead to errors in grasping-information. Thus, a deep learning method for grasping detection is proposed. The method generates some grasping rectangles through a searching algorithm, and inputs the rectangles to the neural network. Then, the network outputs the optimal grasping pose. The experiment demonstrated that the original accuracy of robotic grasping was only 70%. After deep learning for grasping detection, the accuracy was over 90%, which thoroughly meets the requirements of efficiency and accuracy for sorting CDW under actual working conditions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10163-020-01098-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-51064-0_1,Trustworthy Human-Centered Automation Through Explainable AI and High-Fidelity Simulation,Advances in Simulation and Digital Human Modeling,10.1007/978-3-030-51064-0_1,Springer,2021-01-01,"As we become more competent developers of artificially intelligent systems, the level of deployment and associated implicit trust in these systems will increase in kind. While this is an attractive concept, with an already-demonstrated capability to positively disrupt industries around the world, it remains a dangerous premise that demands attention and intentional resource allocation to ensure that these systems’ behaviors match our expectations. Until we can develop explainable AI techniques or high-fidelity simulators to enable us to examine the models’ underlying logic for the situations we intend to utilize them in, it will be irresponsible to place our trust in their ability to act on our behalf. In this work we describe and provide guidelines for ongoing efforts in using novel explainable AI techniques and high-fidelity simulation to help establish shared expectations between autonomous systems and the humans who interact with them, discussing collaborative robotics and cybersecurity domains.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-51064-0_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-77040-2_27,Analysis of Educational Robotics Activities Using a Machine Learning Approach,"Makers at School, Educational Robotics and Innovative Learning Environments",10.1007/978-3-030-77040-2_27,Springer,2021-01-01,"This paper presents the preliminary results of using machine learning techniques to analyze educational robotics activities. An experiment was conducted with 197 secondary school students in Italy: the authors updated Lego Mindstorms EV3 programming blocks to record log files with coding sequences students had designed in teams. The activities were part of a preliminary robotics exercise. We used four machine learning techniques—logistic regression, support-vector machine (SVM), K-nearest neighbors and random forests—to predict the students’ performance, comparing a supervised approach (using twelve indicators extracted from the log files as input for the algorithms) and a mixed approach (applying a k-means algorithm to calculate the machine learning features). The results showed that the mixed approach with SVM outperformed the other techniques, and that three predominant learning styles emerged from the data mining analysis.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77040-2_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-70594-7_13,Deep Convolutional Neural Network Processing of Images for Obstacle Avoidance,Computational Intelligence,10.1007/978-3-030-70594-7_13,Springer,2021-01-01,"Deep Convolutional Neural Networks have been found to be quite successful at processing images and determining their classifications, such as distinguishing dogs from cats in a set of images. With this in mind, we implemented a deep network system for obstacle avoidance of an autonomous robot driving in a real-world lab environment. The network was first trained on the CIFAR10 dataset using a replication of Alex Krizhevsky’s network architecture. The network was then altered by replacing the final fully connected layer with a new fully connected layer with three outputs and random starting weights. The entire network was then fine-tuned using images from the actual environment that were taken by the robot’s camera as it was remotely driven in the lab by a human operator. The network learned the correct responses of left, right, or straight for each of the images with a very low error rate when checked on test images. In addition, ten tests on the actual robot showed that it could successfully and consistently drive through the lab while avoiding obstacles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-70594-7_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85739-4_36,Nego-Bot: A Human-Robot Negotiation System,"Advances in Practical Applications of Agents, Multi-Agent Systems, and Social Good. The PAAMS Collection",10.1007/978-3-030-85739-4_36,Springer,2021-01-01,"In this paper we present a platform composed of a low-cost robot and a multi-agent system that uses deep learning algorithms, whose objective is to establish a negotiation process and persuasively sell items, maximising their price, thus gain. To do this, we have focused on developing an interactive process that is able to interact with humans using a camera, microphone and speaker, to establish all negotiation process without physical contact. This is relevant due to the current COVID-19 situation and arisen issues of human contact. Validation processes with university students have revealed high interest and success in products’ negotiation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-85739-4_36,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-69221-6_12,The Implementation of Artificial Intelligence in Organizations' Systems: Opportunities and Challenges,The Importance of New Technologies and Entrepreneurship in Business Development: In The Context of Economic Diversity in Developing Countries,10.1007/978-3-030-69221-6_12,Springer,2021-01-01,"Nowadays, the revolution of technology plays a major role in organizations' success, Artificial intelligence emerged widely in most of business sectors, and became a crucial part in some businesses. Artificial intelligence (AI), complex algorithms, machine learning and data analytics greatly influence the human live and societies nowadays, even more than before. The benefits of AI applications are wide ranged and it finds it place in various domains and the possibilities are even far-reaching. The AI application is proven in form of unmanned vehicles, medical diagnosis, transport management, air traffic management, environmental sustainability and many more. Thanks to the latest progress in computer hardware, some AI advancements have already gone beyond the human experts’ capacities. The purpose of this research paper is to demonstrate the power of Artificial intelligence in organizations' operations, highlight the current benefits of the AI technology and also gave an insight on the possible challenges and risks associated with this technology. The research is based on previous researches, articles, and specialists’ opinions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-69221-6_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-90525-5_6,From Movement Kinematics to Object Properties: Online Recognition of Human Carefulness,Social Robotics,10.1007/978-3-030-90525-5_6,Springer,2021-01-01,"When manipulating objects, humans finely adapt their motions to the characteristics of what they are handling. Thus, an attentive observer can foresee hidden properties of the manipulated object, such as its weight, temperature, and even whether it requires special care in the manipulation. This study is a step towards endowing a humanoid robot with this last capability. Specifically, we study how a robot can infer online, from vision alone, whether or not the human partner is careful when moving an object. We demonstrated that a humanoid robot could perform this inference with high accuracy (up to 81.3%) even with a low-resolution camera. Only for short movements without obstacles, carefulness recognition did not perform well. The prompt recognition of movement carefulness from observing the partner’s action will allow robots to adapt their actions on the object to show the same degree of care as their human partners.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-90525-5_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-77004-4_12,Metric Localisation for the NAO Robot,Pattern Recognition,10.1007/978-3-030-77004-4_12,Springer,2021-01-01,"We present a metric localisation approach for the NAO robot based on the methodology of depth estimation using optical flow in a frame-to-frame basis. We propose to convert optical flow into a 2-channel image from which images patches of $$60\times 60$$ 60 × 60 are extracted. Each patch is passed as input to a Convolutional Neural Network (CNN) with a regressor in the last layer, thus a depth value is estimated for such patch. A depth image is formed by putting together all the depth estimates obtained for each patch. The depth image is coupled with the RGB image and then passed to the well known ORB-SLAM system in its RGB-D version, this is, a visual simultaneous localisation and mapping approach that uses RGB and depth images to build a 3D map of the scene and use it to localise the camera. When using the depth images, the estimates are recovered with metric. Hence, the NAO’s position can be estimated in metres. Our approach aims at exploiting the walking motion of the robot, which produces image displacements in consecutive frames, and by taking advantage from the fact that the NAO’s walking motion could be programmed to be performed at constant speed. We mount a depth camera on the NAO’s head to produce a training dataset that associates patch RGB images with depth values. Then, a CNN can be trained to learn the patterns in between optical flow vectors and the scene depth. For evaluation, we use one of the in-built NAO’s camera. Our experiments show that this approach is feasible and could be exploited in applications where the NAO requires a localisation systems without depending on additional sensors or external localisation systems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77004-4_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-71356-0_10,Careful with That! Observation of Human Movements to Estimate Objects Properties,Human-Friendly Robotics 2020,10.1007/978-3-030-71356-0_10,Springer,2021-01-01,"Humans are very effective at interpreting subtle properties of the partner’s movement and use this skill to promote smooth interactions. Therefore, robotic platforms that support human partners in daily activities should acquire similar abilities. In this work we focused on the features of human motor actions that communicate insights on the weight of an object and the carefulness required in its manipulation. Our final goal is to enable a robot to autonomously infer the degree of care required in object handling and to discriminate whether the item is light or heavy, just by observing a human manipulation. This preliminary study represents a promising step towards the implementation of those abilities on a robot observing the scene with its camera. Indeed, we succeeded in demonstrating that it is possible to reliably deduct if the human operator is careful when handling an object, through machine learning algorithms relying on the stream of visual acquisition from either a robot camera or from a motion capture system. On the other hand, we observed that the same approach is inadequate to discriminate between light and heavy objects.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-71356-0_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-87358-5_5,Object 6DoF Pose Estimation for Power Grid Manipulating Robots,Image and Graphics,10.1007/978-3-030-87358-5_5,Springer,2021-01-01,"This paper introduces a six degree-of-freedom (6DoF) pose estimation method for manipulating robots to construct a robust machine-vision system. Generally, 2DoF results obtained by traditional object detectors cannot meet the requirements of manipulating operations, where the posture of targets are additionally needed. Meanwhile, due to the sensitivity to light and the limitation to distance, the depth sensor of RGB-D cameras could not always be reliable. To overcome these problems, we study 6DoF pose estimation from a single RGB image. To reduce the complexity and computation, we divide the task into four stages, i.e., data collection and pre-processing, instance segmentation, keypoints prediction, and 2D-to-3D projection. We build the model with deep neural networks, and test it in practical manipulating tasks. The experimental results demonstrate the high accuracy and practicality of our method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-87358-5_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-62579-5_2,Lifelong Object Localization in Robotic Applications,Advances in Physical Agents II,10.1007/978-3-030-62579-5_2,Springer,2021-01-01,"One of the most common tasks in assistive robotics is to find some specific object in a home environment. Usually, this task is tackled by adding the objects of interest to a map of the environment as soon as the objects are detected by the vision system of the robot. However, these maps are usually static, and do not take into account the dynamic nature of a home, where anyone could move an object after the robot has seen it. In this paper, we propose a lifelong system to address this problem. The robot takes into account different possible locations for each object, and chooses the more probable one when it is required. We have designed a probability based system that stores possible locations for each object, and updates the probabilities of past locations based on newer detections.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-62579-5_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-82147-0_21,A Dialogue Contextual Flow Model for Utterance Intent Recognition in Multi-turn Online Conversation,"Knowledge Science, Engineering and Management",10.1007/978-3-030-82147-0_21,Springer,2021-01-01,"There are many intents of dialogues that cannot be recognized due to the contextual features of conversation, resulting in service failure for online chatting robots. Current methods leverage memory networks or machine reading comprehension (MRC) for multi-turn conversation intent recognition. We proposed a novel model for dialogue intent recognition, which leverages the advantages of MRC and memory networks. The model uses a self-attention and co-attention based contextual flow block to aggregate the dialogue utterances for intent recognition. We built a Chinese multi-turn dialogue dataset and designed a multi-task learning method to train the model. The experiment results are exciting, where the proposed model gets 82.75% accuracy and 78.13% F1 score. Those results show promising feasibility to apply our method in online chatting robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-82147-0_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-68449-5_19,A Bengali Voice-Controlled AI Robot for the Physically Challenged,Intelligent Human Computer Interaction,10.1007/978-3-030-68449-5_19,Springer,2021-01-01,"Previously, a number of research is going on in Artificial Intelligence and robotics to make the humans life easier and efficient. Taking motivation form the research works, this paper presents an Artificial intelligence (AI) based smart robot for physically challenged peoples. The model consists of a 4 wheeler car containing a camera and a robotic claw attached to and is operated by Bengali voice commands from the user. At first, the robot will detect the user and parse the voice command to understand its meaning. After that, it will search for the object and then, it will go towards the object to pick it up and finally it will bring the object back to the user. For instance, if for any reason, the object falls from the robotic claw while carrying it towards its destination, this robot has the intelligence to pick it up again and continue its journey to its designated location. For detecting the object, we have used TensorFlow object detection API, and for parsing the voice commands, natural language processing has been used. Additionally, for face detection, we have used Facenet which is a real-time face recognition model based on deep learning consisting of convolutional neural layers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-68449-5_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-53594-0_2,"The Origins of Minimally Invasive and Robotic Surgery and Their Impact on Surgical Practice: A Sociological, Technological History",Robotic Surgery,10.1007/978-3-030-53594-0_2,Springer,2021-01-01,"The origins of these new technologies may, in the broadest sense, have begun in pre-history but definitely appear in antiquity. Their conception and development span more than 2000 years. The period of major development for Minimally Invasive Surgery (MIS) awaited the arrival of the endoscope in the early nineteenth century. The other giant steps along with allied instruments and devices occurred in the late nineteenth and twentieth centuries. Robotic Surgery (RS) appeared far more recently and functionally, that is, in the late twentieth and early twenty-first centuries. Further refinements in both “New Surgeries” are ongoing. The MIS/RS revolution was accompanied by a host of learned activities, special medical meetings, societies, books, and diverse academic pursuits. The Heros, Inventors, and Discoverers from Bozzini, Forlanini, and Semm to the frontiers-shattering Marescaux’s Lindberg Operation and their contributions are recognized. The reader will find The Societies and their role in guiding the new surgery. Their impact on surgical practice and patient care with concomitant emphasis on education and training and research for the new surgery is covered along with the issues of quality and quantity and advantages and disadvantages. For perhaps the first time in medical innovation, there has been an unprecedented interest and acceptance by industry and the public in the new surgery. The controversies, mainly cost issues, and their importance are covered. The future with technology and application refinements as well as the quest for the Ultimate Robot is left in the hands of the old and new practitioners.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-53594-0_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-87034-8_13,New Communicative Strategies for the Affective Robot: F-2 Going Tactile and Complimenting,Creativity in Intelligent Technologies and Data Science,10.1007/978-3-030-87034-8_13,Springer,2021-01-01,"This paper is dedicated to modeling affective reactions in a communicative robot via achieving communicative goals. The effective robot F-2’s software processes multimodal input and facts extracted from input texts. Sentences in Russian are translated with a syntactic-semantic parser into semantic structures that represent sentences meanings and comprise valencies and semantic markers. Basing on the input, the robot changes its emotional state over time, generating effective remarks along with gestures and gazes. The emotional state is modeled via microstates, each represented as a communicative goal, which is further matched to multimodal reactions scenarios from a database. New communicative strategies are introduced. Basing on human features extraction from video, a robot implements strategies of complimenting and making friends; in both cases, it points at the addressee’s look, including clothes and glasses. With tactile sensors, the robot is taught to react to touching; thus the gap in perception is filled which had previously caused the loss of interest by people inclined to tactile communication. Precision is estimated for both methods which are on the basis of new communicative strategies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-87034-8_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-50559-2_5,Electronic Personhood: A Tertium Genus for Smart Autonomous Surgical Robots?,Algorithmic Governance and Governance of Algorithms,10.1007/978-3-030-50559-2_5,Springer,2021-01-01,"Back in 2016, the Committee on Legal Affairs of the European Parliament published a pioneering initiative, the Draft Report with recommendations to the Commission on Civil Law Rules on Robotics (the “Resolution”, or the “EP proposed rules”). The EP proposed rules were intended to bring a common EU solution to the legal challenges posed by, amongst others, smart autonomous robots. This chapter scrutinizes the applicability of one of the solutions proposed by the EP proposed rules: the granting of electronic personhood to such robots by critically evaluating the existence of a legal basis for it.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-50559-2_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-0598-7_8,Digital Transformation in Smart Manufacturing with Industrial Robot Through Predictive Data Analysis,Machine Learning for Robotics Applications,10.1007/978-981-16-0598-7_8,Springer,2021-01-01,"Smart production refers to using advanced predictive data analytics to enhance the physics of improving system performance and decision making. With the wide range of sensor transmissions and Internet of things, there is a growing need to manage large-scale production data characterized by high velocity, high variability, and high volume for industrial robots. In-depth learning provides advanced analytics tools for processing and analyzing large performance data. It usually offers a complete overview of standard learning algorithms and discusses their applications to make production ‘smart.’ The development of in-depth learning technologies and their benefits over traditional machine learning is discussed at the first. Subsequently, competitive approaches based on in-depth learning are specifically developed to improve system performance in manufacturing. Several parameters of smart manufacturing have been analyzed using deep learning models, and corresponding results have been discussed. At the end, the emerging things of research on predictive data analysis of a smart manufacturing system using deep learning are highlighted, and future trends and challenges associated with deep learning for smart manufacturing are summarized.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-0598-7_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-61659-5_1,Recurrence Plot and Convolutional Neural Networks for Terrain Classification Using Energy Consumption of Multi-legged Robots,Recent Advances in Soft Computing and Cybernetics,10.1007/978-3-030-61659-5_1,Springer,2021-01-01,"In this article, we analyze a Machine Learning model for classifying the energy consumption of a multi-legged robots over different terrains. We introduce a system based in three popular techniques: Recurrence Plot (RP), Convolutional Neural Network (CNN), and Dimensionality Reduction. We use RP for transforming the energy consumption of the robots to grayscale 2D images. Due to computational restrictions, we apply a linear dimensionality reduction technique for transforming the images into a smaller feature space. The CNN is applied for classifying the images and to predict the terrain. We present results using several CNN architectures over real-data obtained in six+ types of terrains.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-61659-5_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-77040-2_32,Erwhi Hedgehog: A New Learning Platform for Mobile Robotics,"Makers at School, Educational Robotics and Innovative Learning Environments",10.1007/978-3-030-77040-2_32,Springer,2021-01-01,"Erwhi Hedgehog is one of the smallest mobile robots. It enables mapping and vision analysis, and also displays machine learning features. Behaving like a small, curious animal, eager to explore the surroundings, the robot can be used to test navigation, mapping and localization algorithms, thus allowing the prototyping of new hardware and software for robotics. This application is particularly handy for educational robotics, at both high school and university level. On the one hand, the project is fully open source and open hardware under MIT license and available on Github, so everyone can build his/her own Erwhi Hedgehog robot with the aid of a step-by-step guide. On the other hand, students with more advanced knowledge can use it as a prototyping platform for developing new software programs and features. Erwhi uses Intel RealSense, AAEON UP Squared and Myriad X VPU technologies, with software based on the Robotic Operating System (ROS), and implements SLAM algorithms, such as RTAB-Map. The machine learning aspect is based on the OpenVINO framework and a dedicated ROS wrapper was used. The software package includes all the programs needed to create a Gazebo simulation. In terms of hardware, motor control is based on an STM32 microcontroller and the Arduino software, and the robot works on the differential drive unicycle model. Finally, Erwhi is compatible with AWS RoboMaker tools.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77040-2_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-6014-9_80,The Film Industry Leaps into Artificial Intelligence: Scope and Challenges by the Filmmakers,Rising Threats in Expert Applications and Solutions,10.1007/978-981-15-6014-9_80,Springer,2021-01-01,"Artificial Intelligence (AI) is usually associated with assisting humans with tasks that are either ordinary or can be done better with automation. Since then technology grew, representation of AI and Robotics also evolved in films, especially the robots, which has given surplus roles from the antagonist, protagonist, the romantic, to a deadly weapon capable of machine learning. With the advent of CGI in the 2000s, an AI flareup took place in the world of cinema and came up with worthy concepts of AI-based movies. Today, the AI system can robotically deliver advanced visual effects which makes it easier for performers to act their alternative characters and creatures. Data Analytics and AI technology have already made their debut in films and are going to play a bigger role in the filmmaking process. Till now, films were made on AI. In the future, AI will be writing films, robots will perform, and animation will be done by a deep learning algorithm process. The study aimed to observe the AI technologies used in the film industry. The methods adopted to achieve the goals of the study is the content analysis method. The study will conclude that technology is constantly improving, and AI can become an inescapable force that could renovate the films and take it to the next level.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-6014-9_80,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-81907-1_21,"Robots, Jobs, Taxes, and Responsibilities","Ethics, Governance, and Policies in Artificial Intelligence",10.1007/978-3-030-81907-1_21,Springer,2021-01-01,"In this chapter I argue that the point is not to decide whether robots will qualify someday as a kind of persons, but to realise that we are stuck within the wrong conceptual framework. The digital is forcing us to rethink new solutions for new forms of agency. We must keep in mind that the debate is not about robots but about us, who will have to live with them, and about the kind of infosphere and societies we want to create.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-81907-1_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-80624-8_23,Artificial Intelligence and Tomorrow’s Education,"Advances in Artificial Intelligence, Software and Systems Engineering",10.1007/978-3-030-80624-8_23,Springer,2021-01-01,"Nowadays, there is a rapid technological progress around the world that has enabled realities long ago unimaginable. We live in a technological era that represents new possibilities and challenges for society, and for the educational models in each country [ 1 ]. Research on smart education, which has forced the educational community to rethink on new ways of learning and teaching has been developed globally. Due to the advent of artificial intelligence (AI), the educational model for both, teachers and students will change. Nevertheless, to transform educational systems, it is necessary to update and train students, educators, and administrators effectively [ 2 ]. This research aims to describe the possible applications of AI in education from: 1) the automation of administrative tasks; 2) collection and analysis of information [ 3 ] to create smart content; 3) the implementation of virtual assistants in the teaching-learning process; 4) the potential delivery of lectures by humanoid robots with AI.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-80624-8_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-4795-3_58,Artificial Intelligence-Based Human-Assisted Multipurpose Robot,Current Advances in Mechanical Engineering,10.1007/978-981-33-4795-3_58,Springer,2021-01-01,"This paper explains the most important methods for self-learning systems to develop a self-learning algorithm and a suitable demonstrator for giving an insight in applications and state of the art in self-learning systems. The system described in this task is realized with Q -learning as table method. The agent perceives the environment employing sensors mounted in front. The simulator has been developed in MATLAB to be as close as possible to the physical model. The physical model can either be trained up by reason or benefit itself of finished simulated values. Simulation results show that the table method makes the simulated agent to navigate in an unknown environment, while the physical model only handles static obstacles due to physical limitations and project time scale. An artificial intelligence-based working prototype has been designed to control a robot wirelessly using an Android application. In completing this prototype, wireless software and hardware technologies have been used, such as NodeMCU—ESP8266 wireless module, a dual-channel H-bridge L298N IC for motor driver module, and four electric DC motors connected in parallel are used to move the automobile. The Android application is used by the user to send data wirelessly by connecting to the NodeMCU module using WiFi. This data is an input to the microcontroller system and the microcontroller uses it as the controlling parameter to the underlying hardware. The advantage of using this robot is that it can be used for multiple purposes which include a spy camera as well that can stream the videos to the user over Wi-Fi.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-4795-3_58,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-77040-2_34,European Recommendations on Robotics and Related Issues in Education in Different Countries,"Makers at School, Educational Robotics and Innovative Learning Environments",10.1007/978-3-030-77040-2_34,Springer,2021-01-01,"This short paper describes the preliminary phase in an innovative line of research comparing educational robotics in Italy and other countries, from the perspective of media education, and based on the European Parliament recommendations to the Commission on civil law rules on robotics. More specifically, all decision processes that affect digital citizenship should have the support of children and teenagers. For these reasons, this paper looks at the work of a group of Italian high school students in the fifth year of upper secondary school, who formulated a SWOT analysis to highlight their attitudes to robotics issues in relation to the European Union recommendations. This research started in 2018 and will be repeated this academic year with Italian and Congolese students—from the Institut Supérieur des Techniques Appliquées—with a qualitative analysis to establish student attitudes to robotics issues. Qualitative analysis was selected because the SWOT analysis is already divided into information categories, revealing a variety of concepts that are grouped together from the collected data. These results will be compared with any obtained in future years in Italy and other countries, to find further potential patterns.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77040-2_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-1483-5_28,Autonomous Navigation of Mobile Robot with Obstacle Avoidance: A Review,Futuristic Trends in Network and Communication Technologies,10.1007/978-981-16-1483-5_28,Springer,2021-01-01,"Navigation of mobile robot with obstacle avoidance is a successful research area owing to its comprehensive applications. Secure and smooth mobile robot navigation through different (static and dynamic) environments for single and multiple robot system to attain its goal with following secure path and producing a most fulfilling end result is the principal purpose of navigation. Many techniques are developed for mobile robot navigation. This paper proposes the soft computing techniques used in mobile robot navigation namely fuzzy logic, neural network and neuro-fuzzy. This paper concludes with strength, limitations, efficiency and tabular data of each methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-1483-5_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89134-3_9,A Self-evolution Hybrid Robot for Dental Implant Surgery,Intelligent Robotics and Applications,10.1007/978-3-030-89134-3_9,Springer,2021-01-01,"Dental implant surgery is an effective method for remediating the loss of teeth. A novel custom-built hybrid robot, combining the advantages of serial manipulator and parallel manipulator, was proposed for assisting the dental implant surgery. The hybrid robot is comprised of 3 DOF translation joints, 2 DOF revolute joints and a Stewart manipulator. The translation joints are used for initial position adjustment, making the Stewart manipulator near the target position. The revolute joints are used for assisting the Stewart manipulator in initial orientation adjustment. The procedure of robot-assisted dental implant surgery is designed and described. Considering the limited workspace of Stewart manipulator, we set minimizing the joint displacement of the Stewart manipulator as the optimization objective to find an optimal joint configuration during initial orientation adjustment. In order to find the optimal joint configuration quickly, neural network is used to map the relationship between the target orientation and the optimal joint configuration. In addition, a self-evolution strategy is proposed for optimizing the learning model continuously. And the effectiveness of the strategy is validated in the phantom experiment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89134-3_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-54084-5_1,Artificial Intelligence and Frontline Public Service,The Virtual Public Servant,10.1007/978-3-030-54084-5_1,Springer,2021-01-01,"This chapter opens with an example of a local authority announcing it was hiring Amelia, the world’s first virtual public servant. It quotes press release suggesting Amelia was not only more efficient but also emotionally engaged. The chapter summarises how the national press reacted to the announcement and focused on the idea of Amelia being a robot that would replace the existing workforce. This example sets up a wider question about the role artificial intelligence and related technologies are set to play in frontline public service. The chapter details how AI is currently being used across police and criminal justice, social work and social care, health care, schools and local government. The chapter then considers how the promise of AI is reshaping traditional ideas of face-to-face work and public encounters. The chapter offers an overview of the book and its chapter structure.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54084-5_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-67051-1_15,A Review of Machine Learning Approaches in Clinical Healthcare,Intelligent Healthcare,10.1007/978-3-030-67051-1_15,Springer,2021-01-01,"Healthcare is one of the important real-life applications of machine learning. Machine learning has delivered very powerful automated systems to the humanity such as automated vehicles and voice-enabled personal assistant system. Now in the health domain, digitization of patient data produces a lot of information. This information is used to analyze the health records and predict the future health conditions of the patients. In this chapter, we elaborate various algorithms of machine learning. We analyze the basic understanding of the concept of these algorithms in healthcare domain and working fashion. We discuss the current trends of machine learning in identifying and diagnosing diseases using medical imaging techniques, drug discovery, robotic surgery, and smart fitness equipment. We have elaborated many ML algorithms which are already working in this domain like SVM, logistic regression, random forest, linear regression, etc. In this study, we also talk about the various challenges for the medical care industry and threats. And as the conclusion, we find that algorithms are being optimized for better performance and the selection of an optimal algorithm is a challenging task in AI. And engineers of AI devices should be aware of the possible unintended consequences of their methods and guarantee that the calculations are done in view of the worldwide network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-67051-1_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-77070-9_10,Smart and Intelligent Chatbot Assistance for Future Industry 4.0,Artificial Intelligence for a Sustainable Industry 4.0,10.1007/978-3-030-77070-9_10,Springer,2021-01-01,"Chatbot is an implementation of artificial intelligence (AI) technology that is used to interact with human beings and make them feel like they are talking to the real person, and the chatbot helps them to solve their queries. A chatbot can provide 24 × 7 customer support so that the customer may have a good service experience by any organization. Chatbot helps to resolve the queries and respond to the questions of users. The user is providing the input to the chatbot first, and then, the same input will be processed further; this input can be in the form of text or voice. Therefore, on the basis of the given input and after processing it, the chatbot application will generate the response to the user, and the same response will be the best answer found by the chat application. This response can be in any format like text or a voice output. In this chapter, various approaches of chatbots and how they interact with users are discussed. The proposed approach is also defined using Dialogflow, and it can be accessible through mobile phones, laptops, and portable devices. Chatbots such as Facebook chatbot, WeChat chatbot, Hike chatbot called Natasha, etc. are available in the marker and will respond on the basis of their local databases (DBs). In the proposed method, the focus will be on the scalability, user interactivity, and flexibility of the system, which can be provided by adding both local and Web databases due to which our system will be more fast and accurate. Chatbot uses unification of emerging technologies like machine learning and artificial intelligence. The motive of this chapter is to improve the chatbot system to support and scale businesses and industry domain and maintain relations with customers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77070-9_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-4673-4_21,"Building a Non-ionic, Non-electronic, Non-algorithmic Artificial Brain: Cortex and Connectome Interaction in a Humanoid Bot Subject (HBS)",Proceedings of International Conference on Trends in Computational and Cognitive Engineering,10.1007/978-981-33-4673-4_21,Springer,2021-01-01,"In the 1920s, Brodmann found that the neurons arrange in around 47 distinct patterns in the brain’s topmost thin cortex layer. Each region controls a distinct brain function. Together, the cortex is made of 120,000–200,000 cortical columns, executing all cognitive responses. By filling capillary glass tubes with helical carbon nanotube, we built a corticomorphic device as a replacement of the neuromorphic device and using 10,000 such corticomorphic devices built a cortex replica. Using dielectric and cavity resonators, we built a complex nerve fiber network of the entire brain–body system. It includes connectome, spinal cord, and similar ten major organs. The nerve fiber network takes input from wide ranges of sensors, and the neural paths interact before changing the self-assembly of helical carbon nanotubes, which is read using EEG or laser refraction. The integrated brain–body system is our humanoid bot subject, HBS. One could refill entire cortex region with new synthetic organic materials to test spontaneous, software-free 24 × 7 brain response in EEG and optical vortices. Our extensive theoretical simulations of all brain components were verified with hardware replicas in the optoelectronic HBS. HBS is a universal tool to test a brain hypothesis using AI chips, organic–inorganic materials, etc.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-4673-4_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-68790-8_31,Learning Visual Free Space Detection for Deep-Diving Robots,Pattern Recognition. ICPR International Workshops and Challenges,10.1007/978-3-030-68790-8_31,Springer,2021-01-01,"Since the sunlight only penetrates a few hundred meters into the ocean, deep-diving robots have to bring their own light sources for imaging the deep sea, e.g., to inspect hydrothermal vent fields. Such co-moving light sources mounted not very far from a camera introduce uneven illumination and dynamic patterns on seafloor structures but also illuminate particles in the water column and create scattered light in the illuminated volume in front of the camera. In this scenario, a key challenge for forward-looking robots inspecting vertical structures in complex terrain is to identify free space (water) for navigation. At the same time, visual SLAM and 3D reconstruction algorithms should only map rigid structures, but not get distracted by apparent patterns in the water, which often resulted in very noisy maps or 3D models with many artefacts. Both challenges, free space detection, and clean mapping could benefit from pre-segmenting the images before maneuvering or 3D reconstruction. We derive a training scheme that exploits depth maps of a reconstructed 3D model of a black smoker field in 1400 m water depth, resulting in a carefully selected, ground-truthed data set of 1000 images. Using this set, we compare the advantages and drawbacks of a classical Markov Random Field-based segmentation solution (graph cut) and a deep learning-based scheme (U-Net) to finding free space in forward-looking cameras in the deep ocean.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-68790-8_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86230-5_1,Autonomous Robot Visual-Only Guidance in Agriculture Using Vanishing Point Estimation,Progress in Artificial Intelligence,10.1007/978-3-030-86230-5_1,Springer,2021-01-01,"Autonomous navigation in agriculture is very challenging as it usually takes place outdoors where there is rough terrain, uncontrolled natural lighting, constantly changing organic scenarios and sometimes the absence of a Global Navigation Satellite System (GNSS). In this work, a single camera and a Google coral dev Board Edge Tensor Processing Unit (TPU) setup is proposed to navigate among a woody crop, more specifically a vineyard. The guidance is provided by estimating the vanishing point and observing its position with respect to the central frame, and correcting the steering angle accordingly. The vanishing point is estimated by object detection using Deep Learning (DL) based Neural Networks (NN) to obtain the position of the trunks in the image. The NN’s were trained using Transfer Learning (TL), which requires a smaller dataset than conventional training methods. For this purpose, a dataset with 4221 images was created considering image collection, annotation and augmentation procedures. Results show that our framework can detect the vanishing point with an average of the absolute error of 0.52 $$^\circ $$ ∘ and can be considered for autonomous steering.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-86230-5_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-8395-7_17,Caption Generation of Robot Behaviors Based on Unsupervised Learning of Action Segments,Conversational Dialogue Systems for the Next Decade,10.1007/978-981-15-8395-7_17,Springer,2021-01-01,"Bridging robot action sequences and their natural language captions is an important task to increase explainability of human assisting robots in their recently evolving field. In this paper, we propose a system for generating natural language captions that describe behaviors of human assisting robots. The system describes robot actions by using robot observations; histories from actuator systems and cameras, toward end-to-end bridging between robot actions and natural language captions. Two reasons make it challenging to apply existing sequence-to-sequence models to this mapping: (1) it is hard to prepare a large-scale dataset for any kinds of robots and their environment, and (2) there is a gap between the number of samples obtained from robot action observations and generated word sequences of captions. We introduced unsupervised segmentation based on K-means clustering to unify typical robot observation patterns into a class. This method makes it possible for the network to learn the relationship from a small amount of data. Moreover, we utilized a chunking method based on byte-pair encoding (BPE) to fill in the gap between the number of samples of robot action observations and words in a caption. We also applied an attention mechanism to the segmentation task. Experimental results show that the proposed model based on unsupervised learning can generate better descriptions than other methods. We also show that the attention mechanism did not work well in our low-resource setting.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-8395-7_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-42465-7_41,Artificial Intelligence and Social Responsibility,The Palgrave Handbook of Corporate Social Responsibility,10.1007/978-3-030-42465-7_41,Springer,2021-01-01,"The text introduces basic concepts and problems of artificial intelligence and social responsibility under the perspective of robot ethics and machine ethics. It is composed of two sections. In Sect. 1 concerning the relation of artificial intelligence (further on abbreviated as AI) and social responsibility (further on abbreviated as SR), three things are summarized, namely, basic issues surrounding the topic in Sect. 1.1 , important concepts and their relations in Sect. 1.2 , and a note on the literature in Sect. 1.3 . In Sect. 2 three groups of issues are presented, analyzed, and discussed, namely, AI and fundamental morality and ethics in terms of SR in Sect. 2.1 , AI and general principles of SR in Sect. 2.2 , AI and particular types of SR regarding particular stakeholder groups of AI and particular AI in Sect. 2.3 , and AI and its social implications in Sect. 2.4 .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-42465-7_41,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-74893-7_25,Convolutional Neural Network-Based Local Obstacle Avoidance for a Mobile Robot,"Automation 2021: Recent Achievements in Automation, Robotics and Measurement Techniques",10.1007/978-3-030-74893-7_25,Springer,2021-01-01,"This paper presents collision avoidance and local motion planning modules for a mobile robot equipped with a depth camera. In this paper, we identify some limitations of the existing neural controller, and then we propose the extensions which improve the behavior of the robot. We show that the knowledge about control history is crucial to efficiently avoid collisions with the obstacles if the robot is equipped with a narrow field of view camera. We propose the architecture which utilizes CNN-based neural modules to plan the local motion of the robot. Finally, we provide the results of the experimental verification on the real robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-74893-7_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-4488-0_56,Speech Recognition Using Neural Network for Mobile Robot Navigation,Trends in Mechanical and Biomedical Design,10.1007/978-981-15-4488-0_56,Springer,2021-01-01,"Automatic speech recognition (ASR) has gained a lot of popularity in the mobile robotics, where the commands could be provided to the robot wirelessly to maneuver. A navigation system combined with ASR is a complex system to carry out, because the system has difficulty in recognizing the voice commands when the environment involved already has disturbances like road noise, air conditioner, music, and passengers. The objective of this research is to operate a mobile robot with a single-arm manipulator, where the robot can perceive the speech and it can react to the individual speech commands provided by the operator swiftly and precisely. In order to recognize the speech, mel-frequency cepstral coefficient (MFCC) speech recognition algorithm is chosen and implemented in MATLAB. Various training and testing have been done in MFCC algorithm where it has to carry out the real-time processing of speech data and respond to it. Based on both the training and testing the voice commands collected from the five test subjects both male and female, the speech recognition system achieved 89% efficiency for the test database.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-4488-0_56,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-65661-4_12,Combining Artificial Intelligence with Robotic Process Automation—An Intelligent Automation Approach,Deep Learning and Big Data for Intelligent Transportation,10.1007/978-3-030-65661-4_12,Springer,2021-01-01,"Process Automation has the potential to bring great benefits for businesses and organizations especially in the financial services industry where businesses are information-intensive and experience rich data flows. This was achieved mainly via Robotic Process Automation (RPA), but the increased complexity of the Machine Learning (ML) algorithms increased the possibility of integrating classic RPA with Artificial Intelligence (AI), leading to Robotics 2.0. However, the transition from RPA to Robotics 2.0 embeds a number of challenges. To ensure that the advantages of the modern technologies can be harnessed, these issues need to be tackled. By integrating RPA with cognitive technology such as machine learning, speech recognition, and natural language processing, businesses can automate higher-order tasks with AI assisting that human perceptual and judgment skills were needed in the past. The purpose of this chapter is to identify the set of challenges the companies will face, as well as provide guidance on what preparations to be made before Robotics 2.0 can be implemented in full scale. This also provides the insights about the new intelligent automation approach based on AI integration with RPA in intelligent transportation system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-65661-4_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-58080-3_172-1,Artificial Intelligence in Urology,Artificial Intelligence in Medicine,10.1007/978-3-030-58080-3_172-1,Springer,2021-01-01,"Urology is intertwined with surgical technology. Endoscopic and robotic surgery found early acceptance within the practice of urology. Artificial intelligence research has begun to permeate through the urologic literature. In urologic oncology, AI systems have been developed to diagnose malignancy, guide therapeutics, and predict surgical outcomes. These systems have been shown to grade prostate cancer biopsies more accurately than general pathologists and can accurately predict postoperative length of stay based upon robotic laparoscope kinetics. AI enables accurate prediction of kidney stone passage and stone clearance rates after surgery. Robotic systems using AI have successfully guided renal puncture in early clinical trials. The evaluation and treatment of the infertile male is seeing a paradigm shift as AI systems predict fertility potential and sperm retrieval success. In the future, AI algorithms may inform sperm retrieval for in vitro fertilization optimization. While many of the aforementioned AI systems remain isolated within single-institution research endeavors, published online AI predictors make these analyses accessible to general urologists. In time, AI can be expected to take a larger foothold into modern urologic practice.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58080-3_172-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-58675-1_68-1,Robotics in Industry 4.0,"Handbook of Smart Materials, Technologies, and Devices",10.1007/978-3-030-58675-1_68-1,Springer,2021-01-01,"The advent of robotics in industrial automation has been an integral part of the fourth industrial revolution. Industry 4.0 has various components including robotics, artificial intelligence, machine learning, and internet of things, among various other technologies. The utilization of robots in industries has been on an exponential rise since they increase productivity, efficiency, accuracy, and human safety by a substantial factor. This chapter provides a detailed overview on the different types of robotic technologies that are currently being used in various industries. It also gives an insight of the various control structures and algorithms implemented in an industrial environment to execute targeted tasks with maximum accuracy. It discusses various state estimation and localization techniques as well as motion planning algorithms currently used. Alternatively, this has opened up various opportunities for research, which in turn contributes to industrial automation and optimizes current systems continuously. Applications in various industries and the current challenges faced are also discussed to provide a holistic overview to the role of robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58675-1_68-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-58080-3_177-1,AIM in Rehabilitation,Artificial Intelligence in Medicine,10.1007/978-3-030-58080-3_177-1,Springer,2021-01-01,"Technological advancements in the past decade, especially in the field of Artificial Intelligence (AI), have influenced almost every industry, and the field of medicine is not an exception. From robots taking care of time-consuming, repetitive tasks in hospitals to rapid cancer diagnosis methodologies developing every day, it is visible that AI has potential to help further the medical discipline. AI in rehabilitation has broad usability, such as assisting in the rehabilitation session, evaluating the treatment progress (decision support), and providing prognosis regarding risk of complications or success of the treatment. In this chapter, firstly rehabilitation and its specialties will be explained followed by a thorough explanation of why AI can be helpful in rehabilitation. Furthermore, different applications of AI in this field will be discussed. The chapter also brings some examples from recent studies and state-of-the-art research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58080-3_177-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-80000-0_2,Teaching Robotics with Virtual Reality: Developing Curriculum for the 21st Century Workforce,"Advances in Human Factors in Training, Education, and Learning Sciences",10.1007/978-3-030-80000-0_2,Springer,2021-01-01,"The nature of work is changing. The ongoing shift to automated manufacturing and fabrication in the 21^st Century will require a workforce with a radically different set of skills focused less on manual dexterity for the performance of repetitive tasks and more on interaction with robotic systems. It is expected that both Industrial Manufacturing and the Architecture Engineering and Construction (AEC) sector will begin to adopt more automation technology for the production of manufactured goods as well as the design and construction of the built environment. Teaching the fundamental skills required for 21^st century workers in the Industrial Manufacturing and AEC sectors may no longer be feasible or efficient using on the job training or apprenticeship as a primary educational modality. Virtual Reality (VR) environments offer a possible solution to train workers in an immersive, interactive, and safe environment where they are less likely to be injured, slow down production, or cause unintentional damage to products or projects in construction. Developing curriculum for these workers requires a modular approach to pedagogy that draws on skills and strategies of game design. Assessment tools for evaluating knowledge and skills acquisition can be structured using a reward system drawn from game design and game theory. Pedagogic sequence can thus be more self-directed as a learner explores their developing knowledge, skills, and mastery of specific tasks. The addition of biometric sensors integrated with the VR Headset promises to add a powerful tool for testing curriculum in real time and providing feedback that can influence the duration, sequence, and progression of a learner’s exploration of the learning environment. In this paper we will describe the development of our own AI-powered VR learning environment for teaching fundamentals of robotics, discuss the curriculum and assessment tools we have developed for in-person workshops and VR environment training, and present our aspirations for the further development of this educational tool.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-80000-0_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-51110-4_12,Ethics in AI and Robotics: A Strategic Challenge,An Introduction to Ethics in Robotics and AI,10.1007/978-3-030-51110-4_12,Springer,2021-01-01,"The recent success of AI and robotics has massively increased the international awareness of and the interest in these topics as a factor of economic competitiveness. This concerns not only businesses, but also regional and national governments. There are many claims about the potential for AI to create new service and product innovation. Such claims include the benefits of AI for healthcare such as improved diagnosis or therapy; for transport due to improved efficiency; for energy based on more accurate predictions of energy consumption; or ease of computer use with more natural user interfaces as, for example, in the case of speech understanding, gesture and face recognition and automatic translation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-51110-4_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-5943-0_21,Intelligent Service Robot for High-Speed Railway Passengers,Data Science,10.1007/978-981-16-5943-0_21,Springer,2021-01-01,"With the rapid development of road traffic, the number of high-speed rail passengers is huge, and the flow of people is dense. In epidemic situation, it is prone to intensive infection in high-speed rail carriages, which is not conducive to national prevention and control work. Based on face recognition technology, the intelligent service robot for high-speed rail passengers walks in accordance with the set route and detects the face mask of high-speed rail passengers. The face database of high-speed rail passengers is compared in real time. The passengers who do not wear masks are reminded in time to reduce the risk of infection. Moreover, the robot can accurately remind the passengers of leaving the station in time, and has the functions of automatic selling and student ticket checking. The experimental result is shown to promote the further development of high-speed rail services.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-5943-0_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89098-8_23,Traversability Analysis for Quadruped Robots Navigation in Outdoor Environment,Intelligent Robotics and Applications,10.1007/978-3-030-89098-8_23,Springer,2021-01-01,"In rough and unstructured environment, robots need accuracy environments understanding around them. Especially for legged robots, they need to decide which patch of the terrain to place their legs. This paper proposes a new traversability analysis algorithm for quadruped robots in rough and unstructured terrain. In order to increase accuracy and efficiency of scene understanding, geometric and appearance information of the terrain are all considered in this algorithm. Geometric features (slope, height, roughness) are obtained from point clouds based on Principle Component Analysis (PCA). Visual-based traversability analysis problem is formulated into an image classification task, a Convolutional Neural Network is trained to classify different terrain patches. increase the accuracy and efficiency. Finally, a fused traversability map based on visual features and typical geometric features are built. Simulation experiments show that this algorithm increases the accuracy and efficiency of traversability analysis.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89098-8_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-7834-2_39,Neural Dynamics-based Complete Coverage of Grid Environment by Mobile Robots,Proceedings of International Conference on Frontiers in Computing and Systems,10.1007/978-981-15-7834-2_39,Springer,2021-01-01,"In this work, an algorithm is presented for complete coverage of a grid cell-based environment by mobile robots. The proposed paradigm consists of two biologically inspired neural network models. These allow mobile robots to navigate through collision-free paths and overcome dead-end situations. In this work, inter grid cell diagonal movement is restricted to enhance safety and prevent collision with obstacles. It also ensures inter robot collision-free navigation. The simulation results have shown the effectiveness of the proposed method for a single mobile robot and a multiple mobile robot system. A comparative study is also presented which showcases improvement of the proposed work over the existing literature.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-7834-2_39,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-70740-8_6,Combining Epidemiological and Constructive Simulations for Robotics and Autonomous Systems Supporting Logistic Supply in Infectious Diseases Affected Areas,Modelling and Simulation for Autonomous Systems,10.1007/978-3-030-70740-8_6,Springer,2021-01-01,"It is very likely that the post-Covid-19 world will be significantly different from today. From the experience in fighting the pandemic we can identify lessons on the vulnerability of humans, logistics, and supply chain of vital strategic assets (e.g. medical equipment). This require to think about how to conduct operations in the future, investigate robotics and autonomous systems (RAS) to reduce the exposure while achieving operational improvement, and to assess if current doctrines need to undergo a review. Modelling and simulation play a significant role in analysis and training for scenarios that might include reacting and anticipating the unexpected, challenging our agility and resilience. Available constructive simulations have been designed primarily for training commanders and staff but often lack the ability to exploit the outcomes from predictive systems. The authors propose a novel approach considering the Spatiotemporal Epidemiological Modeler (STEM) for computing the epidemic trend. This tool has been linked with the MASA SWORD constructive simulation. STEM computed data enable the creation in SWORD of highly realistic scenarios in the context of infectious diseases, outbreaks, bioterrorism and biological defence where to model RAS, run the simulation, and analyse doctrine and courses of actions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-70740-8_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-65273-9_15,Instrumentality Versus Awareness: Rethinking the Reverse Side of Artificial Intelligence,Integrated Science,10.1007/978-3-030-65273-9_15,Springer,2021-01-01,"Every epoch with exciting discoveries Discoveries opens up a unique and stunning worldview. Long ago, the attention of archaic man was on Mother Nature. With the utmost amazement and reverence, he prayed for the majesty of nature’s creatures and empowered himself with her magical amulets. Later, man’s attention was attracted to objects in the sky. He worshipped the sun, the moon, and constellations of stars Stars . He ritualized cosmic rhythms and formed the cyclicality of daily life. Later, in ancient Greek tragedy, onto the stage of divine circumstances, suddenly came the man himself—a hero. In the Age of Enlightenment, the man unexpectedly became an infinite potential capable of discovering the whole universe. However, with the advancement of techno-scientific transformations, the focus Focus is changed again. It is no longer on the human, but on technology, the development and training of the instrument. Moreover, again, reverently stunned, but this time adorned with the symbolic amulets of technology instead of flora and fauna, the man looks at the immense scale Scale of technology. He marvels at the growth Growth of “unlimited” possibilities of artificial super-intelligence. The changes brought by artificial Intellect intelligence intelligence Artificial intelligence are claimed to be radically different, and in fact, they are shaping social, economic, and political reality, transforming the entire human world. However, are they radically different? What underpins artificial intelligence Artificial intelligence ? What can it change and what cannot? With the rise of artificial Intellect intelligence intelligence Artificial intelligence , we are witnessing many concerns, but also positive opportunities—new human relations Human human relations with knowledge, and the emergence of a decentralized society, which is focused not solely on consumerism, but also on sharing. [Adopted from https://www.chrismadden.co.uk/cartoon-gallery/turing-test-cartoon-turing-test-being-failed-by-a-human/ , image licensed to the author for free use]. The code of this chapter is 01101110 01101100 01010101 01101001 01100101 01110010 01110110 01100001 01110011 .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-65273-9_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-70296-0_13,Effects of Domain Randomization on Simulation-to-Reality Transfer of Reinforcement Learning Policies for Industrial Robots,Advances in Artificial Intelligence and Applied Cognitive Computing,10.1007/978-3-030-70296-0_13,Springer,2021-01-01,"A requirement for a significant amount of training as well as the exploration of potentially expensive or safety-critical states limits the applicability of reinforcement learning for real-world robotics. One potential solution is given by pretraining models in simulations before transferring them to the real world. In this chapter, we investigate the concept of domain randomization to train robust agents in simulation to control an industrial robot. We examine the effects of different degrees of randomization with respect to the transferability to the real world. In addition, we use attention maps to gain insights into the agents’ decision-making processes. We find that attention maps enable a qualitative assessment for the data-efficiency of a pretrained agent when transferred to the real-world setup.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-70296-0_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89177-0_3,CPG-Actor: Reinforcement Learning for Central Pattern Generators,Towards Autonomous Robotic Systems,10.1007/978-3-030-89177-0_3,Springer,2021-01-01,"Central Pattern Generators (CPGs) have several properties desirable for locomotion: they generate smooth trajectories, are robust to perturbations and are simple to implement. However, they are notoriously difficult to tune and commonly operate in an open-loop manner. This paper proposes a new methodology that allows tuning CPG controllers through gradient-based optimisation in a Reinforcement Learning (RL) setting. In particular, we show how CPGs can directly be integrated as the Actor in an Actor-Critic formulation. Additionally, we demonstrate how this change permits us to integrate highly non-linear feedback directly from sensory perception to reshape the oscillators’ dynamics. Our results on a locomotion task using a single-leg hopper demonstrate that explicitly using the CPG as the Actor rather than as part of the environment results in a significant increase in the reward gained over time (20 $$\times $$ × more) compared with previous approaches. Finally, we demonstrate how our closed-loop CPG progressively improves the hopping behaviour for longer training epochs relying only on basic reward functions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89177-0_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-57802-2_61,Generating 2.5D Photorealistic Synthetic Datasets for Training Machine Vision Algorithms,15th International Conference on Soft Computing Models in Industrial and Environmental Applications (SOCO 2020),10.1007/978-3-030-57802-2_61,Springer,2021-01-01,"The continued success of deep convolution neural networks (CNN) in computer vision can be directly linked to vast amounts of data and tremendous processing resources for training such non-linear models. However, depending on the task, the available amount of data varies significantly. Particularly robotic systems usually rely on small amounts of data, as producing and annotating them is extremely robot and task specific (e.g. grasping) and therefore prohibitive. Recently, in order to address the aforementioned problem of small datasets in robotic vision, a common practice is to reuse features that are already learned by a CNN within a large-scale task and apply them to different small scale ones. This transfer of learning shows some promising results as an alternative, but nevertheless it can not be compared with the performance of a CNN that is specifically trained from the beginning for that specific task. Thus, many researchers turned to synthetic datasets for training, since they can be produced easily and cost effectively. The main issue of such datasets that already exist, is the lack of photorealism both in terms of background and lighting. Herein, we are proposing a framework for the generation of completely synthetic datasets that includes all types of data that state-of-the-art algorithms in object recognition, and tracking need for their training. Thus, we can improve robotic perception without deploying the robot in time-consuming real-world scenarios.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-57802-2_61,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-92635-9_4,Optimal Control and Reinforcement Learning for Robot: A Survey,"Collaborative Computing: Networking, Applications and Worksharing",10.1007/978-3-030-92635-9_4,Springer,2021-01-01,"Along with the development of systems and their applications, conventional control approaches are limited by system complexity and functions. The development of reinforcement learning and optimal control has become an impetus of engineering, which has show large potentials on automation. Currently, the optimization applications on robot are facing challenges caused by model bias, high dimensional systems, and computational complexity. To solve these issues, several researches proposed available data-driven optimization approaches. This survey aims to review the achievements on optimal control and reinforcement learning approaches for robots. This is not a complete and exhaustive survey, but provides some latest and remarkable achievements for optimal control of robots. It introduces the background and facing problem statement at the beginning. The developments of the solutions to existed issues for robot control and some notable control methods in these areas are reviewed briefly. In addition, the survey discusses the future development prospects from four aspects as research directions to achieve improving the efficiency of control, the artificial assistant learning, the applications in extreme environment and related subjects. The interdisciplinary researches are essential for engineering fields based on optimal control methods according to the perspective; which would not only promote engineering equipment to be more intelligent, but extend applications of optimal control approaches.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-92635-9_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-84529-2_50,Research on Path Planning Algorithm for Mobile Robot Based on Improved Reinforcement Learning,Intelligent Computing Theories and Application,10.1007/978-3-030-84529-2_50,Springer,2021-01-01,"This paper proposes an improved Q-learning algorithm to solve the problem that the traditional Q-learning algorithm is applied to the path planning of mobile robot in complex environment, the convergence speed is slow due to large number of iterations, and even the actual reward signal is sparse so that the agent cannot get the optimal path. The improved algorithm reduces the number of iterative runs of the agent in the path planning process to improve the convergence speed by further updating the iterative formula of the Q-value. At the same time, adding sparse reward algorithm leads to finding the optimal path successfully. In order to verify the effectiveness of the algorithm, simulation experiments are carried out in two groups of environments: the simple and the complex. The final simulation results show that the improved algorithm can avoid obstacles effectively and find the optimal path to the target position after less iterations, which proves that the performance of the improved algorithm is better than the traditional Q-learning in the path planning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-84529-2_50,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-3150-4_45,Research on Path Planning of Mobile Robot Based on Deep Reinforcement Learning,Big Data and Security,10.1007/978-981-16-3150-4_45,Springer,2021-01-01,"Reinforcement learning has been widely used in the path planning of mobile robots, and has gradually become the main technology in path planning research. However, in the process of using reinforcement learning, there are problems such as “dimensionality disaster”, slow convergence, and poor generalization. In order to solve these problems, this paper proposes a new learning framework of mobile robots called deep Q learning with experience replay and heuristic knowledge or HDQN in short. In this system, there is a new reward function defined. Then, heuristic knowledge can be designed, which includes knowledge about the target and avoiding obstacles. Finally, experiments can be executed to verify the effect of the HDQN algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-3150-4_45,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-9651-3_18,Analysis of Farm Data Using Artificial Intelligence,Innovative Data Communication Technologies and Application,10.1007/978-981-15-9651-3_18,Springer,2021-01-01,"The population of the world is escalating rapidly, and hence, the necessity of food production is a very serious concern these days. Agricultural productivity can be enhanced by using artificial intelligence. In recent days, many jobs have been replaced by robots, drones and expert systems, but robotics require much more artificial intelligence and advanced programming to replace all the work of farmers. Since the system will not be able to handle the situation effectively as humans, there is less possibility for the system to replace human work completely. Instead of a complete replacement, they can complement each other. The objective of this paper is to discuss some of the problems faced by the farmers, how artificial intelligence is used in the agricultural sector, need for weather predictions and proposed algorithm for irrigation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-9651-3_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89177-0_1,A Study on Dense and Sparse (Visual) Rewards in Robot Policy Learning,Towards Autonomous Robotic Systems,10.1007/978-3-030-89177-0_1,Springer,2021-01-01,"Deep Reinforcement Learning (DRL) is a promising approach for teaching robots new behaviour. However, one of its main limitations is the need for carefully hand-coded reward signals by an expert. We argue that it is crucial to automate the reward learning process so that new skills can be taught to robots by their users. To address such automation, we consider task success classifiers using visual observations to estimate the rewards in terms of task success. In this work, we study the performance of multiple state-of-the-art deep reinforcement learning algorithms under different types of reward: Dense, Sparse, Visual Dense, and Visual Sparse rewards. Our experiments in various simulation tasks (Pendulum, Reacher, Pusher, and Fetch Reach) show that while DRL agents can learn successful behaviours using visual rewards when the goal targets are distinguishable, their performance may decrease if the task goal is not clearly visible. Our results also show that visual dense rewards are more successful than visual sparse rewards and that there is no single best algorithm for all tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89177-0_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-80253-0_11,Learning Robot Arm Controls Using Augmented Random Search in Simulated Environments,Multi-disciplinary Trends in Artificial Intelligence,10.1007/978-3-030-80253-0_11,Springer,2021-01-01,"We investigate the learning of continuous action policy for controlling a six-axes robot arm. Traditional tabular Q-Learning can handle discrete actions well but less so for continuous actions since the tabular approach is constrained by the size of the state-value table. Recent advances in deep reinforcement learning and policy gradient learning abstract the look-up table using function approximators such as artificial neural networks . Artificial neural networks abstract loop-up policy tables as policy networks that can predict discrete actions as well as continuous actions. However, deep reinforcement learning and policy gradient learning were criticized for their complexity. It was reported in recent works that Augmented Random Search (ARS) has a better sample efficiency and a simpler hyper-parameter tuning. This motivates us to apply the technique to our robot-arm reaching tasks. We constructed a custom simulated robot arm environment using Unity Machine Learning Agents game engine, then designed three robot-arm reaching tasks. Twelve models were trained using ARS techniques. Another four models were trained using the state-of-the-art PG learning technique i.e., proximal policy optimization (PPO). Results from models trained using PPO provide a baseline from the policy gradient technique. Empirical results of models trained using ARS and PPO were analyzed and discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-80253-0_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89095-7_30,Open-Loop Motion Control of a Hydraulic Soft Robotic Arm Using Deep Reinforcement Learning,Intelligent Robotics and Applications,10.1007/978-3-030-89095-7_30,Springer,2021-01-01,"Soft robotic arms are of great interests in recent years, but it is challenging to perform effective control due to their strongly nonlinear characteristics. This work develops a model-free open-loop control method for a hydraulic soft robotic arm in spatial motion. A control policy based on reinforcement learning technique is proposed by using Deep Deterministic Policy Gradient. The kinematic model of the soft robotic arm is employed instead of physical prototype to train the control policy. A complete training framework is established through the Reinforcement Learning Toolbox and Deep Learning Toolbox in Matlab software. To make the control policy fast converge and avoid falling into local optimum, the reward is shaped by combining the position error and the action together. A series of simulations are implemented and the results verify the effectiveness of the control policy. It is also shown that the proposed control policy can achieve both of good stability and tracking performance simultaneously.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89095-7_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85906-0_59,Human Aspects in Collaborative Order Picking – What if Robots Learned How to Give Humans a Break?,Advances in Production Management Systems. Artificial Intelligence for Sustainable and Resilient Production Systems,10.1007/978-3-030-85906-0_59,Springer,2021-01-01,"Human aspects in collaboration of humans and robots, as common in warehousing, are considered increasingly important objectives in operations management. In this work, we let robots learn about human stress levels based on sensor data in collaborative order picking of robotic mobile fulfillment systems. To this end, we develop a multi-agent reinforcement (MARL) approach that considers human stress levels and recovery behavior next to traditional performance objectives in the reward function of robotic agents. We assume a human-oriented assignment problem in which the robotic agents assign orders and short breaks to human workers based on their stress/recovery states. We find that the proposed MARL policy reduces the human stress time by up 50% in comparison to the applied benchmark policies and maintains system efficiency at a comparable level. While the results may need to be confirmed in different settings considering different types of humans aspects and efficiency objectives, they also show a practicable pathway to control stress levels and recovery for related problems of human-robot collaboration, inside and outside of warehousing.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-85906-0_59,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89370-5_19,RGB-D Based Visual Navigation Using Direction Estimation Module,PRICAI 2021: Trends in Artificial Intelligence,10.1007/978-3-030-89370-5_19,Springer,2021-01-01,"Target-driven visual navigation without mapping works to solve navigation problems that given a target object, mobile robots can navigate to the target object. Recently, visual navigation has been researched and improved largely by learning-based methods. However, their methods lack depth information and spatial perception, using only single RGB images. To overcome these problems, two methods are presented in this paper. Firstly, we encode visual features of objects by dynamic graph convolutional network and extract 3D spatial features for objects by 3D geometry, a high level visual feature for agent to easily understand object relationship. Secondly, as human beings, they solve this problem in two steps, first exploring a new environment to find the target object and second planning a path to arrive. Inspired by the way of humans navigation, we propose direction estimation module (DEM) based on RGB-D images. DEM provides direction estimation of the target object to our learning model by a wheel odometry. Given a target object, first stage, our agent explores an unseen scene to detect the target object. Second stage, when detected the target object, we can estimate current location of the target object by 3D geometry, after that, each step of the agent, DEM will estimate new location of target object, and give direction information of the target object from a first-view image. It can guide our agent to navigate to the target object. Our experiment results outperforms the result of state of the art method in the artificial environment AI2-Thor.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89370-5_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-90525-5_37,Learning-Based Strategy Design for Robot-Assisted Reminiscence Therapy Based on a Developed Model for People with Dementia,Social Robotics,10.1007/978-3-030-90525-5_37,Springer,2021-01-01,"In this paper, the robot-assisted Reminiscence Therapy (RT) is studied as a psychosocial intervention to persons with dementia (PwDs). We aim at a conversation strategy for the robot by reinforcement learning to stimulate the PwD to talk. Specifically, to characterize the stochastic reactions of a PwD to the robot’s actions, a simulation model of a PwD is developed which features the transition probabilities among different PwD states consisting of the response relevance, emotion levels and confusion conditions. A Q-learning (QL) algorithm is then designed to achieve the best conversation strategy for the robot. The objective is to stimulate the PwD to talk as much as possible while keeping the PwD’s states as positive as possible. In certain conditions, the achieved strategy gives the PwD choices to continue or change the topic, or stop the conversation, so that the PwD has a sense of control to mitigate the conversation stress. To achieve this, the standard QL algorithm is revised to deliberately integrate the impact of PwD’s choices into the Q-value updates. Finally, the simulation results demonstrate the learning convergence and validate the efficacy of the achieved strategy. Tests show that the strategy is capable to duly adjust the difficulty level of prompt according to the PwD’s states, take actions (e.g., repeat or explain the prompt, or comfort) to help the PwD out of bad states, and allow the PwD to control the conversation tendency when bad states continue.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-90525-5_37,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-0598-7_3,Hospital Assistance Robots Control Strategy and Machine Learning Technology,Machine Learning for Robotics Applications,10.1007/978-981-16-0598-7_3,Springer,2021-01-01,"Robotic technology is acquiring more attention now. COVID-19 pandemic brought a large change within short span of time making social distancing among everyone. High safety considerations have to be established everywhere, and in case of hospitals, it is necessary. In order to control a robot, we have to go deep into its control strategies. Control strategy is the major section of robot that makes a robot self-stabilized and helps to control its position and thereby reducing the error. In this chapter, the control strategy and machine learning approach in robot are discussed. Control strategy discussed here helps to ensure the trajectory tracking by back stepping technique and by using sliding mode control (SMC). It helps to achieve the velocity convergence and balancing the robots. In SMC, there is presence of chattering, and other intelligent technique is also discussed to reduce this chattering phenomenon. Those intelligent techniques are adaptive neuro fuzzy interference system (ANFIS) and neuro-sliding mode control scheme. Also, machine learning (ML) which is a part of artificial intelligence (AI) is also discussed here. This chapter mainly focusing on the idea of two-wheeled balancing robot with SMC and back stepping controller along with information about machine learning technology",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-0598-7_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-62784-3_17,Artificial Neural Networks Based Place Categorization,Digital Conversion on the Way to Industry 4.0,10.1007/978-3-030-62784-3_17,Springer,2021-01-01,"Localization using images is a fundamental problem in computer vision for autonomous systems. The information gained enables a high-level understanding of the environment for the mobile robot, which is much more in line with a person’s understanding of their surroundings. It is therefore a critical task for human-robot collaboration and enables robots to find places and identify objects applying this a priori information using semantic maps. Customarily, deep learning models such as convolutional neural networks can be trained for location classification from video streams. However, to achieve acceptable place classification results, previous trained neural nets must be adapted to the specific environment. This work tackles this adaptation of an existing system for place categorization including an extension in terms of possible places. The extension is based on classical machine learning models which were trained based on extracted features of a pre-trained neural network. The developed system outperforms the initial system by correctly classifying 90% of images, including places which were unknown to the neural network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-62784-3_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-71151-1_46,MSL-RAPTOR: A 6DoF Relative Pose Tracker for Onboard Robotic Perception,Experimental Robotics,10.1007/978-3-030-71151-1_46,Springer,2021-01-01,"Determining the relative position and orientation of objects in an environment is a fundamental building block for a wide range of robotics applications. To accomplish this task efficiently in practical settings, a method must be fast, use common sensors, and generalize easily to new objects and environments. We present MSL-RAPTOR, a two-stage algorithm for tracking a rigid body with a monocular camera. The image is first processed by an efficient neural network-based front-end to detect new objects and track 2D bounding boxes between frames. The class label and bounding box is passed to the back-end that updates the object’s pose using an unscented Kalman filter (UKF). The measurement posterior is fed back to the 2D tracker to improve robustness. The object’s class is identified so a class-specific UKF can be used if custom dynamics and constraints are known. Adapting to track the pose of new classes only requires providing a trained 2D object detector or labeled 2D bounding box data, as well as the approximate size of the objects. The performance of MSL-RAPTOR is first verified on the NOCS-REAL275 dataset, achieving results comparable to RGB-D approaches despite not using depth measurements. When tracking a flying drone from onboard another drone, it outperforms the fastest comparable method in speed by a factor of 3, while giving lower translation and rotation median errors by 66% and 23% respectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-71151-1_46,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-90321-3_46,The Redundant Distributed Data Labeling Under Conditions of the Decentralized Training Datasets Storing for the Fog- and Edge-Robotic Environment,Data Science and Intelligent Systems,10.1007/978-3-030-90321-3_46,Springer,2021-01-01,"The process of learning is typical for the most assistive and autonomous robots. Considering the learning as a complex process, the issue of the data labeling is in the focus of this paper, because of the labeling noise effect on the learning results. Distributed redundant labeling is discussed in recent works, yet, no known publications contain the process description in the focus of the distributed decentralized processes, although the manner of distributed implementation of the various areas of the robotics is relevant now in the angle of fog- and edge-robotics. The current paper is devoted to the question of the redundant distributed labeling under the conditions of the decentralized data storing, which is quite relevant in the fog- and edge- robots environments. Two main approaches of the distributed monitoring of the labeling experts groups are considered and compared, as well as some experimental research of the redundant labeling results has been conducted with the results presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-90321-3_46,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-73734-4_7,High-Throughput Phenotyping in Soybean,High-Throughput Crop Phenotyping,10.1007/978-3-030-73734-4_7,Springer,2021-01-01,"Soybean [ Glycine max (L.) Merr.] breeders and geneticists routinely evaluate thousands of plots per year in order to characterize various accessions and breeding Breeding populations for a multitude of traits, for example, morphological, physiological, abiotic and biotic stress Abiotic and biotic stresses , plant organs, and seed composition. Most of these trait evaluations require experienced raters to spend countless hours, recording phenotypes for each genotype in different filial generations. Plant breeders strive to work with increased population sizes, and improved accuracy of selection to increase the response to selection. These requirements have motivated the development of high-throughput phenotyping High-Throughput Phenotyping (HTP) (HTP) methods and associated tools (i.e., hardware) and software solutions. This chapter consists of several topics related to HTP, including sensors Sensors , unmanned aerial systems Unmanned Aerial Systems (UAS) , and ground robots Ground robots , as these are important components of plant phenotyping in the new technological era. The advances in image-based analysis Image-based analysis and machine learning Machine learning methods have accompanied the improvements in phenotyping capabilities, both aerial and ground. This chapter includes the current state of the art State of the art in types of sensors, aerial, and ground-based HTP, in conjunction with machine learning Machine learning -based analytics, particularly for physiological and morphological traits, abiotic and biotic stresses Abiotic and biotic stresses , and root-related traits. Advances in the integration Integration of HTP High-Throughput Phenotyping (HTP) with crop modeling are provided. Finally, the complementary relationship between HTP and genomic studies is explained with pertinent examples.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-73734-4_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-62579-5_22,Reinforcement Learning Experiments and Benchmark for Solving Robotic Reaching Tasks,Advances in Physical Agents II,10.1007/978-3-030-62579-5_22,Springer,2021-01-01,"Reinforcement learning has shown great promise in robotics thanks to its ability to develop efficient robotic control procedures through self-training. In particular, reinforcement learning has been successfully applied to solving the reaching task with robotic arms. In this paper, we define a robust, reproducible and systematic experimental procedure to compare the performance of various model-free algorithms at solving this task. The policies are trained in simulation and are then transferred to a physical robotic manipulator. It is shown that augmenting the reward signal with the Hindsight Experience Replay exploration technique increases the average return of off-policy agents between 7 and 9 folds when the target position is initialised randomly at the beginning of each episode.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-62579-5_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-61659-5_11,Does Lifelong Learning Affect Mobile Robot Evolution?,Recent Advances in Soft Computing and Cybernetics,10.1007/978-3-030-61659-5_11,Springer,2021-01-01,"Evolutionary Algorithms have been applied in robotics over the last quarter of a century to simultaneously evolve robot body morphology and controller. However, the literature shows that in this area, one is still unable to generate robots that perform better than conventional manual designs, even for simple tasks. It is noted that the main hindrance to satisfactory evolution is poor controller generated as a result of the simultaneous variation of the morphology and controller. As the controller is a result of pure evolution, it is not given a chance to improve before fitness is calculated, which is the equivalent of reproducing immediately after birth in biological evolution. Therefore, to improve co-evolution and to bring artificial robot evolution a step closer to biological evolution, this paper introduces Reinforced Co-evolution Algorithm (ReCoAl), which is a hybrid of an Evolutionary and a Reinforcement Learning algorithm. It combines the evolutionary and learning processes found in nature to co-evolve robot morphology and controller. ReCoAl works by allowing a direct policy gradient based RL algorithm to improve the controller of an evolved robot to better utilise the available morphological resources before fitness evaluation. The ReCoAl is tested for evolving mobile robots to perform navigation and obstacle avoidance. The findings indicate that the controller learning process has both positive and negative effects on the progress of evolution, similar to observations in evolutionary biology. It is also shown how, depending on the effectiveness of the learning algorithm, the evolver generates robots with similar fitness in different generations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-61659-5_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-4803-8_6,Model-Based and Model-Free Robot Control: A Review,RiTA 2020,10.1007/978-981-16-4803-8_6,Springer,2021-01-01,"Robot control is one of the key aspects of robotics research. Models are essential tools in robotics, such as robot’s own body dynamics and kinematics models, actuator/motor models, and the models of external controllable objects. In this paper, we review the latest advances in model-based and model-free approaches with a strong focus on robot control. Based on the designed search strategy, several prevailing control approaches are classified and discussed according to their control strategies. An insight into the gripper control is also explored. Then the research problems and applicability of the control methods are discussed by investigating their merits and demerits. Based on the discussion, we summarize the challenges and future research trends of robot control.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-4803-8_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-62579-5_23,Age and Gender Recognition from Speech Using Deep Neural Networks,Advances in Physical Agents II,10.1007/978-3-030-62579-5_23,Springer,2021-01-01,"This paper deals with joint gender identification and age group classification from speech, aimed at improving the functionalities of Interactive Voice Response Systems. Deep Neural Networks are used, because they have recently demonstrated discriminative and representation capabilities over a wide range of applications, among them, speech processing problems based on features extraction and selection. A comparative study of various neural network architectures and sizes is presented to gather knowledge about performance dependence on the network architecture and the number of free parameters. The classification framework was trained and evaluated using Mozilla’s ‘Common Voice’ dataset, an open and crowdsourced speech corpus. The results are promising, with the best systems achieving a gender identification error lower than 2% and an age group classification error lower than 20%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-62579-5_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-90525-5_14,Human vs Robot Lie Detector: Better Working as a Team?,Social Robotics,10.1007/978-3-030-90525-5_14,Springer,2021-01-01,"Human interaction often entails lies. Understanding when a partner is being deceitful is an important social skill, that also robots will need, to properly navigate social exchanges. In this work, we investigate how good are human observers at detecting false claims and which features they base their judgment on. Moreover, we compare their performance with that of an algorithm for lie detection developed for the robot iCub and based uniquely on pupillometry. We ran an online survey asking participants to classify as truthful or deceptive 20 videos of individuals describing complex drawings to iCub, either correctly or untruly. They also had to rate their confidence and provide a written motivation for each classification. Responders achieved an average accuracy of 53.9% with a higher score on detecting lies (55.4%) with respect to true statements (52.8%). Also, they performed better and more confidently on the videos iCub failed to classify than on the ones iCub correctly detected. Interestingly, the human observers listed a wide range of behavioral features as means to decide whether a speaker was lying, while the robot’s judgment was driven by pupil size only. This suggests that an avenue for improving lie detection could be a joint effort between humans and robots, where human sensitivity to subtle behavioral cues could complement the quantitative assessment of physiological signals feasible to the robot. Finally, based on the reported motivations, we speculate and give hints on how the lie detection field should evolve in the future, aiming to portability to real-world interactions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-90525-5_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-0425-6_4,A Leak Detection in Water Pipelines Using Discrete Wavelet Decomposition and Artificial Neural Network,Advances in Signal Processing and Intelligent Recognition Systems,10.1007/978-981-16-0425-6_4,Springer,2021-01-01,"This paper proposes an ANN(Artificial Neuron Network) model to find the location of leakage in water-distribution systems. To detect the water leakage in the systems, a tethered robot with acoustic sensor is used. Leakage signal is captured using tethered acoustics. The captured acoustic signal is pre-processed using DWT (Discrete Wavelet Transform). Then, the pre-processed acoustic signal is modelled by the ANN model to detect the leak. The performance of the proposed algorithm was evaluate in a test bed which consists of a robot, a ground station and a simulated water distribution system. A robot with a hydrophone is used for captured acoustic signal in water pipes. The ground station is designed to control the robot and reports the status of leakage. In addition, the proposed framework discovers the location of the leakage. The experiment results show that the proposed model is effective for detection of water leakage in the system. The evaluation results indicates that the percent of accuracy is 100%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-0425-6_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-75871-4_10,Persons in Banking 5.0,Banking 5.0,10.1007/978-3-030-75871-4_10,Springer,2021-01-01,"This chapter deals with persons. It goes into the details of the new e-competencies or new profiles and of education 5.0. The chapter analyzes in detail the so-called virtual workers, the person-machine integration and their relevance for banking 5.0. Persons are essential in banking 5.0, as in most other organizations. It is necessary to manage talents and cultural modernization with the same attention and in coordination with solution modernization. Banking 5.0 is a successful way to make work more social, vibrant, productive, effective, and efficient. Talent- and culture-related aspects are top challenges when moving to banking 5.0. Banking 5.0 requires new job profiles, such as artificial intelligence and data scientists. Education 5.0 is essential for the new generations of employees and supports the work transformation in the current workforce and management. This chapter presents advanced methodologies to support human–robot-interaction and collaboration, which are characteristics of banking 5.0.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-75871-4_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-54084-5_10,The Virtual Public Servant: Three Futures. A Q-Study,The Virtual Public Servant,10.1007/978-3-030-54084-5_10,Springer,2021-01-01,"This chapter seeks to have meaningful conversation with public servants about a growing role for AI and robotics in frontline work. A previous chapter (Chap. 2 ) develops a set of Q-methodology statements describing a role for AI and related technologies to address problems of control, cost, convenience and connection in public service. In this chapter some 40 public servants in a range of frontline and managerial roles rank-order these statements in a process known as Q-sorting. The Q sorts were subject to a by-person factor analysis and three factors were retained, named and interpreted as shared viewpoints. The viewpoints are: Power of Interaction questions the efficacy of AI to match human empathy, Generation Now is impatient to meet growing expectations and Human + Machine, Choice + Empowerment sees an opportunity to offer seamless services and to reduce digital exclusion. These factors move us on from general utopian-dystopian assessment and methodologically offer a means to engage public servants in meaningful conversation about the future.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54084-5_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-80847-1_1,Ethics and Regulation of Artificial Intelligence,Artificial Intelligence for Knowledge Management,10.1007/978-3-030-80847-1_1,Springer,2021-01-01,"Over the last few years, the world has deliberated and developed numerous ethical principles and frameworks. It is the general opinion that the time has arrived to move from principles and to operationalize on the ethical practice of AI. It is now recognized that principles and standards can play a universal harmonizing role for the development of AI-related legal norms across the globe. However, how do we translate and embrace these articulated values, principles and actions to guide Nation States around the world to formulate their regulatory systems, policies or other legal instruments regarding AI? Our regulatory systems have attempted to keep abreast of new technologies by recalibrating and adapting our regulatory frameworks to provide for new opportunities and risks, to confer rights and duties, safety and liability frameworks, and to ensure legal certainty for businesses. These past adaptations have been reactive and sometimes piecemeal, often with artificial delineation on rights and responsibilities and with unintended flow-on consequences. Previously, technologies have been deployed more like tools, but as autonomy and self-learning capabilities increase, robots and intelligent AI systems will feel less and less like machines and tools. There is now a significant difference, because machine learning AI systems have the ability ‘to learn’, adapt their performances and ‘make decisions’ from data and ‘life experiences’. This paper presented at the International Joint Conference on Artificial Intelligence - Pacific Rim International Conference on Artificial Intelligence in 2021 provides brief insights on some selected topical developments in ethical principles and frameworks, our regulatory systems and the current debates on some of the risks and challenges from the use and actions of AI, autonomous and intelligent systems [ 1 ].",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-80847-1_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-54173-6_12,Applying AI on the Battlefield: The Ethical Debates,"Robotics, AI, and Humanity",10.1007/978-3-030-54173-6_12,Springer,2021-01-01,"Because lethal autonomous weapon systems (LAWS) are designed to make targeting decisions without the direct intervention of human agents (who are “out of the killing loop”), considerable debate has arisen on whether this mode of autonomous targeting should be deemed morally permissible. Surveying the contours of this debate, the authors first present a prominent ethical argument that has been advanced in favor of LAWS, namely, that AI-directed robotic combatants have an advantage over their human counterparts, insofar as the former operate solely on the basis of rational assessment, while the latter are often swayed by emotions that conduce to poor judgment. Several counter arguments are then presented, inter alia, (1) that emotions have a positive influence on moral judgment and are indispensable to it; (2) that it is a violation of human dignity to be killed by a machine, as opposed to being killed by a human being; and (3) that the honor of the military profession hinges on maintaining an equality of risk between combatants, an equality that would be removed if one side delegates its fighting to robots. The chapter concludes with a reflection on the moral challenges posed by human-AI teaming in battlefield settings, and how virtue ethics provides a valuable framework for addressing these challenges.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54173-6_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85867-4_4,AIRPA: An Architecture to Support the Execution and Maintenance of AI-Powered RPA Robots,Business Process Management: Blockchain and Robotic Process Automation Forum,10.1007/978-3-030-85867-4_4,Springer,2021-01-01,"Robotic Process Automation (RPA) has quickly evolved from automating simple rule-based tasks. Nowadays, RPA is required to mimic more sophisticated human tasks, thus implying its combination with Artificial Intelligence (AI) technology, i.e., the so-called intelligent RPA. Putting together RPA with AI leads to a challenging scenario since (1) it involves professionals from both fields who typically have different skills and backgrounds, and (2) AI models tend to degrade over time which affects the performance of the overall solution. This paper describes the AIRPA project, which addresses these challenges by proposing a software architecture that enables (1) the abstraction of the robot development from the AI development and (2) the monitor, control, and maintain intelligent RPA developments to ensure its quality and performance over time. The project has been conducted in the Servinform context, a Spanish consultancy firm, and the proposed prototype has been validated with reality settings. The initial experiences yield promising results in reducing AHT (Average Handle Time) in processes where AIRPA deployed cognitive robots, which encourages exploring the support of intelligent RPA development.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-85867-4_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-84883-5_14,"Socio-technical Issues Concerning theFuture of New Communication Technology, Robots, and AI",Perceiving the Future through New Communication Technologies,10.1007/978-3-030-84883-5_14,Springer,2021-01-01,"Consider which topics are covered by news outlets, where individuals invest their psychological energies, and what our contemporary societies take up as morally significant issues: in all of these, it is natural that the focus is on those issues which are recognized as threatening or troubling. Areas that are smoothly operating, adequately fulfilling needs, or a source of satisfaction tend to be overlooked. That is the case not only in those three areas (news, individual concerns, and social movements and causes) but also when considering the role of communication technologies, robotics, and AI. The attention is less on their successes than it is on their risks and dangers. This imbalance of psychological valences does nothing to lessen the reality of the risks and dangers, but does require us to consider the lenses through which we perceive the future of these technologies. Nonetheless, in full awareness of this bias, it would behoove us to consider what are the major issues facing society in terms of new communication technology, AI, and robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-84883-5_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-64269-3_11,"Shifting the Goalposts: Reconceptualizing Robots, AI, and Humans",Minding the Future,10.1007/978-3-030-64269-3_11,Springer,2021-01-01,"The rapid advancement of AI and autonomous systems is posing some difficult challenges to human beings, and not merely because they can now beat us at our favourite strategy games, like chess and Go Go , at which we used to assume that humans were invincible. AI and robots also pose challenges to humans’ conceptions of ourselves, not just as the “rational animal,” but increasingly in other areas that we used to consider our exclusive domain, pushing humans’ self-conception into more niche, ever-dwindling areas. The abilities of autonomous systems has created, therefore, crises in our understanding of what it means to be “human,” but these crises can be productively directed to challenge the founding mythologies of humanism, forcing us to think re-think what it means to be post-human, and overcoming the idea that “humans” and “machines” are clearly demarcated and in competition with one another.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-64269-3_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-2786-6_11,"Smart Technology Application for COVID-19 Detection, Control, Prediction and Analysis",Impact of AI and Data Science in Response to Coronavirus Pandemic,10.1007/978-981-16-2786-6_11,Springer,2021-01-01,"Artificial intelligence has the potential to be a tool in the fight against COVID-19 and similar pandemics. COVID-19 disease, caused by the SARS-CoV-2 virus, has been declared as a global pandemic by the WHO. AI is a potentially powerful tool in the fight against the COVID-19 pandemic. The applications of AI as well as other data analytic tools can be useful to recognize (diagnose), predict and explain (treat) COVID-19 infections, and help to manage socio-economic impacts. So the main intention of this chapter is to provide corroborative information to researchers, scientists and professionals about how AI can be considered as a tool to fight against this global menace situation. Further, the information in this chapter are planned to be segregated in the form of quality from which the state-of-the-art ways can be analysed to deal with COVID-19 situation with the help of robots and computers. Moreover, the chapter is intended to mainly focus on six areas where AI can contribute to the global fight against COVID-19: (i) early warnings and alerts, (ii) tracking and prediction, (iii) data dashboards, (iv) diagnosis and prognosis, (v) treatments, and cures and (vi) social control. The whole world is now facing a pandemic due to COVID-19. Day-by-day there has been an increase in the number of COVID-19 cases, even though the mortality rate is less but still it is necessary that we come up with a solution to end all this. The only thing that can be done as of now is to help cure the affected patients and find a vaccine for this virus so that no one gets affected by it in the near future. With the increase in the number of patients each day, both severe and non-severe case, there have been a lot of concerns related to shortage of hospital beds, sanitization, less number to ventilator support systems, etc. In order to cope up with these problems, many engineers and innovators along with their companies and start-ups have tried to create inventions to help medical healthcare officials during this dire situation. The main objective of this report is to make everyone aware of the advancements that are being done in the field of health care, about how the technology has been taking part in treating these coronavirus patients. It cannot stop the pandemic all of a sudden but it will definitely help to prevent the spread of virus, educate people and create awareness. So, an analysis has been conducted to determine how technology has been creating an impact during this pandemic. Technology has been helping fight against this pandemic by fighting against misinformation, providing the correct facts about the virus and how to stay safe from it, increasing traceability and transparency by tracking data, finding drugs and helping the locals as well as the healthcare officials.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-2786-6_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-54084-5_9,The Virtual Public Servant Fantasy,The Virtual Public Servant,10.1007/978-3-030-54084-5_9,Springer,2021-01-01,"This chapter asks why it is presently so difficult to develop and implement general-purpose virtual public servants. It opens with a case of a failed attempt to introduce a virtual agent in an English local authority. The experiment had been announced widely and the speculative press coverage stoked up fears that this “robot” would lead to large-scale unemployment. Despite an attempt to refocus the role for the virtual agent, the project was terminated after two years. The chapter discusses the case with a cross-section of frontline public servants across health, education, social care and local government. The chapter reveals a combination of political, technical and emotional barriers to developing such a virtual public servant.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54084-5_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85710-3_26,A Low-Cost Human-Robot Negotiation System,"Highlights in Practical Applications of Agents, Multi-Agent Systems, and Social Good. The PAAMS Collection",10.1007/978-3-030-85710-3_26,Springer,2021-01-01,"In this paper we present a platform composed of a low-cost robot and a multi-agent system that uses deep learning algorithms, whose objective is to establish a negotiation process and persuasively sell items, maximising their price, thus gain. To this, we have focused on developing an interactive process that is able to interact with humans using a camera, microphone and speaker, to establish all negotiation process without physical contact. This is relevant due to the current COVID-19 situation and arisen issues of human contact. Validation processes with university students have revealed high interest and success in products’ negotiation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-85710-3_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-63128-4_15,Autonomous Mobile Robot with AI Based on Jetson Nano,"Proceedings of the Future Technologies Conference (FTC) 2020, Volume 1",10.1007/978-3-030-63128-4_15,Springer,2021-01-01,"This paper describes the autonomous mobile search robot equipped with AI that currently being developed and the results obtained so far during this development process. We describe the theoretical concepts which are utilized as basis of robot system, algorithms used for motion controlling and data processing, implemented hardware and features of software implementation of the applied algorithms. The features of the developed robot are following. At first, it is employment of two lidars, the laser scanning data from which are combined into a single point cloud. Then we used a deep convolutional neural network (DCNN) for certain appropriate objects detection and recognition as well as Dlib tracker for such objects tracking after detection. Besides that, our robot can search for objects under the low light conditions because of usage of IMX219 camera from Sony with additional IR LED system. An NVIDIA Jetson Nano single-board computer was used as the main computational and control unit of the system as well as another board OrangePi PC was utilized for point clouds from two lidars processing. As for the methods for moving control we’ve implemented relatively computationally simple system based on Fuzzy Logic and Google Cartographer system using for SLAM. We have also applied A-star algorithm for better obstacles avoidance. Some functional schemes and additional description are provided in the article for illustration of building blocks of developed ROS based program system for robot location and mapping, moving control and object detection and recognition.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-63128-4_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-81635-3_36,Will Robots Take My Job? Exploring the Effect of Artificial Intelligence in Taiwan’s Labor Market,Knowledge Management in Organizations,10.1007/978-3-030-81635-3_36,Springer,2021-01-01,"The rise of artificial intelligence (AI) and related new technologies have received a lot of attention from the public. In Taiwan, the government and enterprises are also making efforts to develop these technologies. Against this backdrop, and with the massive unemployment that resulted from automation in the third industrial revolution, human workers are anxious about their jobs being replaced by smart robots. On the contrary, many scholars hold a positive view and suggest that technologies augment and enhance human capabilities. Therefore, in order to better understand the present situation in Taiwan, this research was designed to explore the relationship of AI and jobs by adopting a qualitative approach for data collection. Two sessions of focus group discussion were conducted with eight practitioners from different industries, in addition to three in-depth interviews with executive-level managers. All participants have rich knowledge and experience in AI development or implementation. The discussions mainly focused on: (1) examples of the impact of AI and related new technologies on the labor market, (2) the competency of future talents, and (3) suggestions for policymakers. The discussions were recorded with the consent of the participants and transcribed into textual data for further analysis. The research adopted ATLAS.ti version 8 for data analysis. The findings revealed: (1) most practitioners consider AI as a tool; (2) task replacement does happen but workers gain more benefits; (3) new jobs are created as technologies are being developed and utilized. Most participants hold an affirmative attitude toward AI and new technologies. Suggestions for the government and organizations have also been discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-81635-3_36,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-8221-9_114,Autonomous Vehicle Spray Paint and Defect Detection Using Machine Vision,"Advances in Automation, Signal Processing, Instrumentation, and Control",10.1007/978-981-15-8221-9_114,Springer,2021-01-01,"Spray painting after vehicle body inspection is one of the most important aspects of automobile manufacturing and assembling industries. There are many methods available to identify the defects such as dents, scratches or some deformity containing both on a vehicle body using manual labor to closely look and identify the defects and then transfer to spray painting area which may be controlled either manually or semi-autonomously, but this method is not cost- effective as it require more labors and may result in slowing down the speed of manufacturing in a plant leading it to not achieving the target goals set. In this paper, we proposed a defect detection and inspection system using Faster RCNN approach for image processing on a car body to check type of defects apart from the ones which are planned on it and spray painting using a fully autonomous robotic arm having 6 degree of freedom with a sprayer attached to its end effectors and other robotic arm with a camera for inspection. The decision making is provided by classified neural networks through continuous monitoring the vehicle body by the camera. Here the case study takes up the spraying and defect detection in a car body. A similar setup can be used to detect deformity in any other vehicle.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-8221-9_114,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-70400-1_13,Advanced Learning and Classification Techniques for Agricultural and Field Robotics,Fundamentals of Agricultural and Field Robotics,10.1007/978-3-030-70400-1_13,Springer,2021-01-01,"Today, increasingly a large number of growers are utilizing smart agricultural tools as a daily part of their precision agricultural strategy to improve overall crop health and get the most out of their fields while optimizing resource utilization. With the advent of low-cost sensors and internet of things, more data is available within the agricultural industry than ever. Several industries including manufacturing, financial, and service industries have used AI-powered analytics to gain unparalleled edge by extracting valuable information from bigdata to improve product value and sales, boost marketing, and to predict future trends in real time. In recent years, agricultural industries have also started to adopt and apply AI-based solutions for various cumbersome tasks. Advanced learning and classification are some of the fundamental analytical tools used to make decision using large amount of data. This chapter first intends to provide background concepts on the fundamental building blocks of machine learning and deep learning techniques that are in practice today. In addition, the chapter reviews literatures in computer vision and robotics in agriculture highlighting the applications of machine/deep learning techniques described in the chapter. The chapter also discusses the significance and impacts of the advanced learning and classification techniques on agricultural and field robotics compared to the traditional approaches. Finally, current limitations and future directions for research and development in this area have been discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-70400-1_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-49100-0_4,Cloud Computing for Robotics and Surgery,Digital Surgery,10.1007/978-3-030-49100-0_4,Springer,2021-01-01,"This chapter is intended to be an introduction to cloud computing for surgeons and noncomputer scientists. In addition to presenting a modern history of the cloud, it explores theoretical concepts of applying cloud computer systems to next-generation medical robots and operating room infrastructures. It explains how the cloud is suited for high-scale computational tasks necessary for the integration of artificial intelligence and machine learning into tomorrow’s surgical suite and how it will provide a framework for digital surgery. Machine learning via the cloud versus single machine learning is also addressed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-49100-0_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-0598-7_6,Integration of Wireless Sensor Network in Robotics,Machine Learning for Robotics Applications,10.1007/978-981-16-0598-7_6,Springer,2021-01-01,"Presently, robotics is one of the promising fields of science and engineering which is used to build, design and manufacture robot. There is wide range of applications of robot such as automobile industry, manufacturing industry, medical science and smart factory. In Industry 4.0, wireless sensor network should be the promising technology which is being proposed into the manufacturing industry. In smart factory, robotic system plays an important role to operate the factory automatically. Robotic manipulator can be operated through wire or wirelessly. In modern times, wirelessly operated manipulator is one of the rising areas in smart factory. In smart factory, if the radioactive zone exists, so human may encounter some difficulties to operate the factory due to radioactive ray which badly affects the human cells. Therefore, to operate the robotic manipulator wirelessly is one of the key concerns. Therefore, to make wireless operation, wireless sensor networks (WSNs) should be the emerging field in smart factory and incorporation of machine learning (ML) algorithms is able to enhance the WSNs performance in terms of various matrices such as cluster formation, cluster head (CH) selection, data trans-receiving or routing and fault-tolerant scheme by which the life of the sensor network is being enhanced. ML techniques and their learning procedure are also used for localization, incident detection, object tracking in the introduced autonomous system. This chapter primarily centres on the integration of wireless sensor network with robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-0598-7_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-58080-3_56-1,The New Frontiers of AI in Medicine,Artificial Intelligence in Medicine,10.1007/978-3-030-58080-3_56-1,Springer,2021-01-01,"This chapter reflects upon the research and innovation innovation at the forefront of artificial intelligence (AI) from hardware to software and their application to draw the potential future applications of AI that will change how care is delivered irrevocably. Techniques including machine learning machine learning , natural language processing natural language processing , and computer vision will be applied to enable earlier diagnosis, give patient control, and create entirely new categories of diagnostics diagnostics . AI has the potential to not just digitalize what healthcare currently does but provide uniquely different ways forward that will revolutionize care delivery.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58080-3_56-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-71151-1_16,Online Soil Classification Using a UAS Sensor Emplacement System,Experimental Robotics,10.1007/978-3-030-71151-1_16,Springer,2021-01-01,"Deployment of sensors in hard-to-access locations can improve data gathering for scientific studies. We have developed a sensor emplacement system that can be mounted to unmanned aircraft systems with vertical takeoff and landing capabilities to autonomously auger a sensor into the ground. Various techniques can be chosen to enhance the augering process when certain characteristics of the soil are known. Moisture content and compressive strength are the soil characteristics that most impact the augering process, yet directly measuring them would require additional sensors to an already-burdened airframe. We address this through a novel means of predicting these soil characteristics within the first 30 s of an average 85 s augering evolution using onboard sensors and a Gaussian process regression scheme that predicts the soil moisture content and compressive strength with accuracy of 86.53% and 90.53% of the respective measured values.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-71151-1_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-65785-7_7,How Artificial Intelligence Will Change the Future of Tourism Industry: The Practice in China,Information and Communication Technologies in Tourism 2021,10.1007/978-3-030-65785-7_7,Springer,2021-01-01,"In the future, artificial intelligence (AI) is likely to substantially change both the tourism industry and tourist behavior. At present, research on artificial intelligence and tourism is receiving widespread attention, but most of them focus on a certain subject or a specific aspect of the tourism industry. For example, artificial intelligence influences the behavior of tourists and tourism enterprises. The analysis of the impact of artificial intelligence on the tourism industry as a system is still insufficient. Therefore, this research proposes a multi-dimensional framework from an industry perspective based on the existing definition of artificial intelligence. The framework involves three aspects: the level of intelligence, task types, and whether artificial intelligence is embedded in robots. The authors use a large number of Chinese practice cases to investigate how AI affects the tourism industry, then put forward a research agenda to analyze how destination government, tourism enterprises and tourist experience will change in the future. Finally, they highlight important issues related to privacy, prejudice and ethics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-65785-7_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-77431-8_19,Ethical Stance and Evolving Technosexual Culture – A Case for Human-Computer Interaction,Culture and Computing. Design Thinking and Cultural Computing,10.1007/978-3-030-77431-8_19,Springer,2021-01-01,"Issues relating to ethics and how moral principles evolve are imminently engrained in culture. Culture and technology cannot be separated from one another, as both are processes and reflections of social cognition and experience through action and practice. Technology is the embodiment of values and enabler of culture. As technology develops and human relationships to information technology (IT) become ever more intricate and intimate the cultural framework underpinning values and ethics also morphs. The Internet is everywhere and humans are reliant on it for everything from banking to maintaining family relationships. Anything an individual could possibly desire can be found within the masses of information and websites. The Internet has made access to domains that were either rare luxury or forbidden seemingly easy, convenient and free. What was once considered taboo and hedonic indulgence is now not only openly available, but widely accepted within popular Western culture. This paper concentrates on the topic of technosexuality, Internet facilitated sexual encounters, technologically enabled sex, and ideas around ethics and changing moral values. We refer to ‘ethical stance’ as a reflection of the socio-psychological positioning of humans in relation to their moral views and understandings. This is a theoretical paper that draws on contemporary examples from dating Apps and embodied technology (sex robots) in light of current discourse expressed in public online media.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77431-8_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-70569-5_23,Artificial Empathy for Clinical Companion Robots with Privacy-By-Design,Wireless Mobile Communication and Healthcare,10.1007/978-3-030-70569-5_23,Springer,2021-01-01,"We present a prototype whereby we enabled a humanoid robot to be used to assist mental health patients and their families. Our approach removes the need for Cloud-based automatic speech recognition systems to address healthcare privacy expectations. Furthermore, we describe how the robot could be used in a mental health facility by giving directions from patient selection to metrics for evaluation. Our overarching goal is to make the robot interaction as natural as possible to the point where the robot can develop artificial empathy for the human companion through the interpretation of vocals and facial expressions to infer emotions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-70569-5_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-2786-6_14,Computer Vision in COVID-19: A Study,Impact of AI and Data Science in Response to Coronavirus Pandemic,10.1007/978-981-16-2786-6_14,Springer,2021-01-01,"Computer vision is a pioneering sub-field of artificial intelligence that is used in computers for throwing a light on the visual world and better understanding of it. In crucial times like COVID-19, computer vision is used to combat all the challenges that are been faced. In healthcare field, computer vision has been used to enhance the productivity of the various departments and also help in the development of the vaccine. Computer vision tasks include methods for acquiring, processing, analysing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information. Recently all these tasks are put to use in developing a systematic operation to tackle the challenges of COVID-19. Computer vision is used in thermal scanners, along with ML it is used in predicting virus spread, it is also used in AI systems in most of the Lab to help in development of the vaccine and also help in analysing factors like whether people maintaining social distancing or not, wearing masks or not and this analysis helps in decision making for government as well as an individual. Various companies are leveraging computer vision and artificial intelligence to battle COVID-19. From building chatbots to spread awareness to building special robots to maintain social distancing, the concept of computer vision has been proved beneficial to us in every other way. In this chapter, we will learn more on how computer vision is been used in medical imaging to diagnose and properly differentiate between viral fever, COVID-19 and pneumonia. Also how it is helping is faster report analysis of CT scans of lungs and how it is helping in faster detection of infected people. We will further discuss the future development and advancement of computer vision.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-2786-6_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-65233-3_6,"Medicine, Apparatuses, Robots and Intimacy: A Few Ethical and Political Aspects of the Linkage with Machines",Reflections on Medical Ethics,10.1007/978-3-030-65233-3_6,Springer,2021-01-01,"Fortunately, far from J. Ellul and from M. Heidegger, contemporary ethics invoke no more humanism or religious convictions in order to reject technologies, as if they were hostile to man. We have learned and are always learning to live with machines on which, very often, our health and even our very life depends. The existence of men in flesh and blood and the being of machines are intermingled in such a way that it is no longer possible to discern where the one starts and where the other ends. Yet, if this linkage between men and machines is generally recognized, without being rejected, the ethical problems continue to exist as if men had theirs and machines -digital machines and « intelligent » machines- had their own ethics or raised unique ethical concerns. What is quite absurd and opens wide the door to trans-humanist and post-humanist myths that cannot escape the qualification of Schwärmerei following the appellation that Aufklärung gave to such elucubrations. Nevertheless, this is not the issue: ethical questions deal with the indefectible mixed being that any modern man, member of our cultures, makes up with machines. A certain number of political conceptions are disqualified when these linkages with machines are taken into account; we highlight the point with Rousseau’s contractualism. But it may happen that moral positions, even classical, like Kant’s moral law, do not need to be applied to human beings. At least, Kant has fancied the first of the three formulations of his moral law for beings that are not specifically human. The matter is not to substitute Kantian morals to present ethics but to highlight that the ethics we are searching has predecessors and that ethics, when human nature is not imagined to be steeped in laws, cannot avoid dealing with linked or coupled beings.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-65233-3_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-31739-7_122-1,Big Data Robotics and Rights,Encyclopedia of Contemporary Constitutionalism,10.1007/978-3-319-31739-7_122-1,Springer,2021-01-01,"Is the activity of software neutral? Could the set of algorithms and big data which help the framework of an artificial intelligence in recognizing, classifying, or elaborating data be considered truly objective? As a matter of fact, data are never objective. Statistical models modify reality as they represent it. Furthermore, we are living in the era of learning machines: Robots are everyday more intelligent, useful, and independent. As they are implied in a long list of activities, we need to know which rules they do have to respect. Most of all, we need to establish who, and in what terms, could be responsible for their faults. That is why the European Union is elaborating a set of principles and rules on robots and artificial intelligence: New technologies have a great potential for the benefit of humanity, provided that ethics and law do not give up on ruling them.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-31739-7_122-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-73050-5_73,Enhancing Assistive Technology with Biomimicry and Social Robots,Hybrid Intelligent Systems,10.1007/978-3-030-73050-5_73,Springer,2021-01-01,"As the population of the world continues to grow in size and in age; it remains vital to develop streamlined and affordable technologies to address the needs of those most in need of companionship and care. The elderly and visually impaired remain a significant and ever-increasing segment of society, yet due to the cost of at-home health care, many of these individuals are unable to afford full-time caretakers to assist them in everyday tasks. Although the luxury of home care remains elusive to many due to the associated cost, social robots are an important and meaningful way to overcome this issue. The proposed research explores the combination of biomimicry and assistive technology with IoT and artificial intelligence, by proposing an all-in-one robot assistant called the Jet-I-U. This device would mimic the behavioral and physical characteristics of a pet scarlet macaw, to provide information and companionship to visually impaired and elderly individuals. The Jet-I-U would emulate its morphology and movement through laser-cut features and various biomimetic components. The intelligence and behavioral characteristics of the macaw are modeled through the application of the Internet of Things (IoT), Artificial Intelligence (AI), and Machine Learning (ML). By utilizing platforms such as the NVIDIA Jetson Nano and leveraging IoT technologies, the Jet-I-U can assist the visually impaired and older adults in day-to-day tasks. In addition, this paper argues for the need to foster a human and robot pet relationship by not only focusing on essential tasks but also by studying how one can make the service robot more like its living physical counterpart. Such measures would make the pet-like robot assistant more acceptable and provide more meaningful interactions between the robot and its user.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-73050-5_73,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-67871-5_8,Design and Implementation of Walking Control System for Orchard Plant Protection Robot Based on Artificial Intelligence Algorithm,Advanced Hybrid Information Processing,10.1007/978-3-030-67871-5_8,Springer,2021-01-01,"In order to improve the stability of fruit recognition of orchard plant protection robot, the walking control system of orchard plant protection robot was established based on artificial intelligence algorithm. Orchard eppo robot control system design of hardware platform is a rate by machine controller, signal controller, chassis motor drives, cameras and proximity switch of these five parts, is mainly responsible for transferring information to the control system, do matting for software design, on this basis, the set can intelligent power saving communication program and the sensor data acquisition, the recognition data transmission to the robot control system, the implementation is based on artificial intelligence algorithm orchard plant protection design of the control system of walking robot. By combining software and hardware, the research on the walking control system of orchard plant protection robot based on artificial intelligence algorithm is completed. From the results of software and hardware experiments, it can be seen that compared with the traditional robot walking control system, the application of this system for fruit recognition has higher stability and can effectively reduce the workload.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-67871-5_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-82280-4_2,"Sociable Robots for Later Life: Carebots, Friendbots and Sexbots",Sex Robots,10.1007/978-3-030-82280-4_2,Springer,2021-01-01,"This chapter discusses three types of sociable robots for older adults: robotic caregivers (carebots); robotic friends (friendbots); and sex robots (sexbots). The central argument holds that society ought to make reasonable efforts to provide these types of robots and that under certain conditions, omitting such support not only harms older adults but poses threats to their dignity . The argument proceeds stepwise. First, the chapter establishes that assisting care-dependent older adults to perform activities of daily living is integral to respecting dignity. Here, the argument establishes the vital role that carebots-of-the-future might play in aged societies as the supply of working age adults falls shy of demand. Next, the chapter extends this analysis to designing friendbots for socially isolated older adults. The argument holds that reasonable efforts to provide access to friendbots for socially isolated adults is also a future societal responsibility. Finally, the chapter applies similar reasoning to show that societies ought to make reasonable efforts to support sexual capabilities for older adults who want to be sexual but are bereft of sex partners. The argument draws on capability accounts of justice to show that when central human capacities, such as bodily integrity; intimate relationships; and the use of senses, imagination and thought, are at risk of falling below a threshold level, society should intercede.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-82280-4_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-59608-8_27,An Extensible Cloud Based Avatar: Implementation and Evaluation,Recent Advances in Technologies for Inclusive Well-Being,10.1007/978-3-030-59608-8_27,Springer,2021-01-01,"A common issue in human-robot interaction is that a naive user expects an intelligent human-like conversational experience. Recent advances have enabled such experiences through cloud-based infrastructure; however, this is not currently possible on most mobile robots due to the need to access cloud-based (remote) AI technology. Here we describe a toolkit that supports interactive avatars using cloud-based resources for human-robot interaction. The toolkit deals with communication and rendering latency through parallelization and mechanisms that obscure delays. This technology can be used to put an interactive face on a mobile robot. But does an animated face on a robot actually make the interaction more effective or useful? To answer this question, we conducted a user study comparing human-robot interaction using text, audio, a realistic avatar, and a simplistic cartoon avatar. Although response time was longer for both avatar interfaces (due to increased computation and communication), this had no significant effect on participant satisfaction with the avatar-based interfaces. When asked about general preferences, more participants preferred the audio interface over the text interface, the avatar interfaces over the audio interface, and the realistic avatar interface over the cartoon avatar interface. This chapter includes and expands on material previously published [ 1 , 2 ].",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-59608-8_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-74009-2_74,Identifying Positive Socioeconomic Factors of Worker Roles,"Human Interaction, Emerging Technologies and Future Applications IV",10.1007/978-3-030-74009-2_74,Springer,2021-01-01,"Workers incorporating new technologies into their workflow is crucial for organizations. Treating workers as an asset that can be trained to harness the potential of new artificial intelligence (AI) and automation technologies is a middle ground not afforded by most organizations. This study is to aid stakeholders in understanding the positive socioeconomic factors to create solutions to workforce displacement that can incorporate AI technologies. To ensure the creation of effective training solutions, this study is focused on stakeholders immediately affected, workers, and their role. I ask, “what socioeconomic factors should automation and AI technology developers consider for training humans in the workplace?” In answering the research question, the technology developers will be sensitive to socioeconomic factors as potential data points in a training solution. Designing roles incorporating the productivity metrics of job attributes, agency in decisions, and job satisfaction were socioeconomic factors found to have a positive effect on workers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-74009-2_74,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-79997-7_6,Lethal Autonomous Weapon Systems: An Advocacy Paper,"Advances in Human Factors in Robots, Unmanned Systems and Cybersecurity",10.1007/978-3-030-79997-7_6,Springer,2021-01-01,"Some countries, human rights organizations, artificial intelligence experts and academics have expressed doubts about the moral, ethical, and legal development and use of Lethal Autonomous Weapon Systems (LAWS). The United States, United Kingdom, Israel, Russia and many other countries have disagreed with these concerns. This paper will argue that (1) LAWS already exist and are in use by many countries for both defensive and offensive purposes and (2) LAWS cannot be legislated away; the technology is pervasive from smart cars and autonomous ships to military self-protection systems. As long as countries and their respective militaries follow internationally accepted norms when using LAWS such as the Laws of War, principles of war, and have a systematic legal review process, militaries will have the sufficient and necessary controls to address those who criticize and oppose their development and use.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-79997-7_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-2039-3_9,Two Speculations About Language,The Theory of Language Holography,10.1007/978-981-16-2039-3_9,Springer,2021-01-01,"The two speculations about language are the appropriation of the theory of language holography. The appropriation might not be successful, though.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-2039-3_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-8534-0_6,The Role of Internet of Things (IoT) in the Containment and Spread of the Novel COVID-19 Pandemic,"Computational Intelligence Methods in COVID-19: Surveillance, Prevention, Prediction and Diagnosis",10.1007/978-981-15-8534-0_6,Springer,2021-01-01,"The novel COVID-19 pandemic is hitting the strongest economies in an unprecedented manner leading to the crippling of most economic sectors globally. Movement restriction order profoundly affected many industries, including manufacturing, transportation, aviation, education, tourism, and trade and investment, among others. The consequences resulted in people losing their jobs, corporate organizations and the Government experiencing a sharp drop in income and revenue. Similarly, the global crude oil market prices crash to the lowest rate of less than USD30/barrel. In recent times, the world has not witnessed a pandemic that threatened human existence without any sigh of relief as no cure has been found for the disease. The most effective recommended measure in containing the chain of transmitting the virus is through social distancing as a large gathering of people is highly discouraged. Internet of Things (IoT) alongside other related technologies such as artificial intelligence (AI), drones, robotics, Big Data, and e-learning related technologies were found as platforms that can play a critical role in breaking the chain of the virus transmission. This study highlighted the role of IoT related technologies as a measure that enhances human-machine interaction, which supports the social distancing among people.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-8534-0_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-32103-5_28,"Should Machines Write About Death? Questions of Technology, Humanity, and Ethics in the Automation of Journalism",Handbook of Global Media Ethics,10.1007/978-3-319-32103-5_28,Springer,2021-01-01,"This chapter examines ethics regarding the automation of journalism as driven by the integration of algorithms, artificial intelligence, and related technologies, such as news-writing software, into the newsroom. It traces current approaches to journalism ethics that are primarily grounded in existing standards and codes for human journalists and fledgling efforts to address the shift in the role of technology from mediator to “author.” Taking the question, “Should machines write about death?” as provocation, this chapter demonstrates that existing journalism research and codes regarding automated technologies fall short in addressing the complication of machines as communicators in terms of the ontological assumptions underlying journalism theory and ethics. It then advocates for scholars to engage with scholarship within Human-Machine Communication and philosophy of technology to advance journalism ethics in a way that is responsive to the changing function and nature of technology associated with journalism automation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-32103-5_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-54173-6_5,Could a Robot Be Conscious? Some Lessons from Philosophy,"Robotics, AI, and Humanity",10.1007/978-3-030-54173-6_5,Springer,2021-01-01,"In this chapter, the question whether robots could be conscious is evaluated from a philosophical perspective. The position taken is that the human being is the indispensable locus of ethical discovery. Questions concerning what we ought to do as morally equipped agents subject to normative guidance largely depend on our synchronically and diachronically varying answers to the question of “who we are.” It is argued here, that robots are not conscious and could not be conscious, where consciousness is understood as a systemic feature of the animal-environment relationship. It is suggested, that ethical reflection yields the result that we ought not to produce cerebral organoids implanted in a robotic “body.”",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54173-6_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-54173-6_2,Differences Between Natural and Artificial Cognitive Systems,"Robotics, AI, and Humanity",10.1007/978-3-030-54173-6_2,Springer,2021-01-01,"This chapter identifies the differences between natural and artifical cognitive systems. Benchmarking robots against brains may suggest that organisms and robots both need to possess an internal model of the restricted environment in which they act and both need to adjust their actions to the conditions of the respective environment in order to accomplish their tasks. However, computational strategies to cope with these challenges are different for natural and artificial systems. Many of the specific human qualities cannot be deduced from the neuronal functions of individual brains alone but owe their existence to cultural evolution. Social interactions between agents endowed with the cognitive abilities of humans generate immaterial realities, addressed as social or cultural realities. Intentionality, morality, responsibility and certain aspects of consciousness such as the qualia of subjective experience belong to the immaterial dimension of social realities. It is premature to enter discussions as to whether artificial systems can acquire functions that we consider as intentional and conscious or whether artificial agents can be considered as moral agents with responsibility for their actions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54173-6_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-56433-9_23,Robotization in the Economy,Socio-economic Systems: Paradigms for the Future,10.1007/978-3-030-56433-9_23,Springer,2021-01-01,"The aim of this work was the need to show that robotics and artificial intelligence in the modern economy have become not only its integral part, but, without exaggeration, its very foundation. In our world of high speeds and lack of time, the need for intelligent assistants is becoming ever more acute. As you know, demand creates supply, and now processors that only the “chosen ones” saw thirty years ago are firmly registered in our home. Each house has a washing machine, which is based on a processor, which in terms of computing power is many times superior to the processor that stood on the spaceship that delivered the Americans to the moon. Processor technology has become so commonplace that many very original devices can even be created by a group of school-age children under the guidance of a teacher. The methodological basis of this work is a review of the current level of robotics using the example of the Sberbank Robotics Laboratory. The results of the analysis of the situation taking shape at the forefront of the robotics front of the economy are presented. The basis of the development of the robot model is a mathematical analysis of radio engineering signals that transmit information through its “nervous” system. The result of the work is the obtained theoretical analysis of the technological parameters of the robot, the economic feasibility of certain technical solutions adopted in the manufacture of the prototype is weighed and refined. In conclusion, it should be noted that the application of the capabilities of mathematical modeling of the processes of the electronic components of the robot, including the Fourier transform, made it possible to first create a theoretical, and then an operational model of a rather complex and high-tech robot, endowed with a number of very original and practical functions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-56433-9_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-72400-9_18,Merging Education Systems with Humanware,Neuro-Systemic Applications in Learning,10.1007/978-3-030-72400-9_18,Springer,2021-01-01,"People are fascinated with new technological advances in the medical, science, and education disciplines. There are thousands of breakthroughs in each discipline in combination with technology. The famous Moore’s law of technology; that technology advances at a given rate is verified and proved over the past 48-years. This animation can be viewed at Visualizing Moore’s Law in Action (Visualizing Moore’s Law in Action (1971–2019) – https://www.visualcapitalist.com/visualizing-moores-law-in-action-1971-2019/?fbclid=IwAR3BokAmQjdhdBkKjHmLducV3x9Et11i8g05cCJc27mP_lWC4sCtFdt7JIQ ). All advancements have only proven we can develop better systems, while cancer, addictions, suicide, depression, and anxiety loom over society at increasing rates. The reason is simple; we have separated the human heart and being from the advancements. Humanware takes a holistic approach to technological advances and brings the two together for a greater outcome. An article describing the holistic approach can be viewed at https://www.cccu.org/magazine/reflections-that-transform/ . By taking an even high approach, we can see how humans are connected to the world in a rhythmic fashion.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-72400-9_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-66222-6_5,An IoT-Based Autonomous Robot System for Maize Precision Agriculture Operations in Sub-Saharan Africa,Emergence of Cyber Physical System and IoT in Smart Automation and Robotics,10.1007/978-3-030-66222-6_5,Springer,2021-01-01,"The importance of agriculture to the economic growth in sub-Saharan Africa suffers from several challenges. One of the major problems faced by the sector is the lack of suitable technology to optimize yield and profit to reduce the reliance of farmers on manual techniques of farming which is accompanied by drudgery, wastage, and low yields. Precision agriculture has been applied to maximize agricultural outputs while minimizing inputs. This study presents the design of an Internet of things (IoT)-based autonomous robot system that can be used for precision agricultural operations in maize crop production. The robot consists of a camera for remotely monitoring of the environment and a tank incorporated with a liquid level sensor which can be used for irrigation and herbicide application. The real-time feed from the camera as well as the output from the liquid level sensor is accessed from a cloud database via a Web application. This system can be adopted for improved crop production which in turn will increase crop yield, profit, and revenue generated from agriculture.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-66222-6_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-77283-3_7,Human-Autonomy Teaming for the Tactical Edge: The Importance of Humans in Artificial Intelligence Research and Development,Systems Engineering and Artificial Intelligence,10.1007/978-3-030-77283-3_7,Springer,2021-01-01,"The U.S. Army is currently working to integrate artificial intelligence, or AI-enabled systems, into military working teams in the form of both embodied (i.e., robotic) and embedded (i.e., computer or software) intelligent agents with the express purpose of improving performance during all phases of the mission. However, this is largely uncharted territory, making it unclear how to do this integration effectively for human-AI teams. This chapter provides an overview of the Combat Capabilities Development Command (DEVCOM) Army Research Laboratory’s effort to address the human as a critical gap with associated implications on effective teaming. This chapter articulates four major research thrusts critical to integrating AI-enabled systems into military operations, giving examples within these broader thrusts that are currently addressing specific research gaps. The four major research thrusts include: (1) Enabling Soldiers to predict AI; (2) Quantifying Soldier understanding for AI; (3) Soldier-guided AI adaptation; and (4) Characterizing Soldier-AI performance. These research thrusts are the organizing basis for explaining a path toward integration and effective human-autonomy teaming at the tactical edge.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77283-3_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-75789-2_6,Unsupervised Neural Network Based Forward Kinematics for Cable-Driven Parallel Robots with Elastic Cables,Cable-Driven Parallel Robots,10.1007/978-3-030-75789-2_6,Springer,2021-01-01,Forward Kinematic (FK) analysis of under-constrained Cable-Driven Parallel Robots (CDPRs) deals with the inherent coupling between the loop-closure and static equilibrium equations. The non-linearity of the problem is magnified with the addition of the coupling between the cable lengths and their tensions based on the elastic cable model. The paper proposes an unsupervised neural network algorithm to perform fast forward geometrico-static analysis for CDPRs in a suspended configuration with elastic cables. The formulation determines a non-linear function approximation to model the FK and proves to be efficient in solving for consecutive and close waypoints in a path. The methodology is applied on a simulated six-degree-of-freedom (6-DOF) spatial under-constrained suspended cable-driven parallel robot. Specific comparison results to show the effectiveness of the proposed method in tracking a given path are presented against the results obtained from least-square non-linear optimization.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-75789-2_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-77939-9_5,A Cascaded Deep Neural Network for Position Estimation of Industrial Robots,Deep Learning for Unmanned Systems,10.1007/978-3-030-77939-9_5,Springer,2021-01-01,"The estimation of an object’s position and orientation from images plays an important role in the field of industrial robots and visual servo, the performance of the vision control system is deeply dependent on the image processing model and algorithm. Before deep learning is widely used in computer vision, the traditional image processing methods are successful in handling the low dimension information of image features, but the traditional image processing methods always fail in complex images with high dimension feature information. In this research chapter, our main contribution is to propose a cascaded convolution network that could obtain high precision pose estimates. Where Single Shot MultiBox Detector (SSD) is utilized to obtain the bounding box of the object to narrow down the recognition range. And a convolutional neural network is utilized to detect the orientation of the object. The method is designed for industrial detection tasks, so the optimized method can run in real-time and extract weak features of sample images. To verify the effect of the detection method based on deep learning in the industrial system, a hand-eye system is built for detecting Radio Remote Unit. A series of experiments have been carried out on the system with the proposed method and the traditional method. In general, the proposed method has advantages in accuracy and recognition rate compared with the traditional algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77939-9_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-1685-3_35,Terrain Classification Using Neural Network Based on Inertial Sensors for Wheeled Robot,Recent Challenges in Intelligent Information and Database Systems,10.1007/978-981-16-1685-3_35,Springer,2021-01-01,"In the article, a method of terrain recognition for robotic application has been described. The main goal of the research is to support the robot's motor system in recognizing the environment, adjusting the motion parameters to it, and supporting the location system in critical situations. The proposed procedure uses differences between calculated statistics to detect the diverse type and quality of ground on which wheeled robot moves. In the research IMU (Inertial Measurement Unit) has been used as a main source of data, especially 3-axis accelerometer and gyroscope. The experiment involved collecting data with a sensor mounted on a remotely controlled wheeled robot. This data was collected from 4 hand-made platforms that simulated different types of terrain. For terrain recognition, a neural network-based analytical model has been proposed. In this paper authors present results obtained from the application model to experimental data. The paper describes the structure of NN and the whole analytical process in detail. Then, based on a comparison of the obtained results with the results from other methods, the value of the proposed method was shown.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-1685-3_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-65283-8_15,Dynamic Error Reduction via Continuous Robot Control Using the Neural Network Technique,Recent Research in Control Engineering and Decision Making,10.1007/978-3-030-65283-8_15,Springer,2021-01-01,"The article presents an algorithm for planning the trajectory which goes exactly through two given points: the initial and end points. By complicating the structure of the neural network, we can plan the trajectory that will go through a specified number of points with regard to additional conditions. It is obvious that with the increase of the problem complexity, the accuracy of the solution to the problem decreases. The suggested recommendations reduce the possibility of errors in the neural network solutions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-65283-8_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-82562-1_40,PD Controller of a Lower Limb Exoskeleton Robot Based on Sliding Mode RBF Neural Network,Multimedia Technology and Enhanced Learning,10.1007/978-3-030-82562-1_40,Springer,2021-01-01,"The lower limb exoskeleton robot (LLER) is a human-robot interaction device that combines human functions and mechanical characteristics. Due to the complexity and strong coupling of human gait, it is difficult for LLER to be worn comfortably and safely for training. In such a scenario, the paper proposes a kind of proportional-derivative(PD) controller of LLER based on sliding mode RBF neural network(SMRBF-nn). In order to verify the effectiveness of the proposed control scheme, pertinent experiments were carried out. The gait data of the subject was collected through the motion capture system. A simulating model was established, different control methods, like conventional SMRBF-nn controller and PD controller based on SMRBF-nn, have been tested on the LLER. The experimental results show that the control strategy proposed in this paper can not only make LLER track the human body’s gait trajectory, but also output appropriate torque when there is a disturbance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-82562-1_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89134-3_64,Research on Robot Classifiable Grasp Detection Method Based on Convolutional Neural Network,Intelligent Robotics and Applications,10.1007/978-3-030-89134-3_64,Springer,2021-01-01,"Aiming at the problem that FC-GQ-CNNs cannot classify the object of grasp detection, we propose a new method of classifiable grasp detection combining object detection and grasp detection based on FC-GQ-CNNs and YOLOv4. First, using FC-GQ-CNNs to detect various types of parts to obtain the highest quality grasp of the robot (grasp point 3D coordinates and grasp plane angle); secondly, using YOLOv4 trained on the parts dataset detect various types of parts to obtain the classification and positioning bounding boxes; thirdly, by adding Canny edge detection, Sklansky algorithm and other image processing methods, the positioning bounding box have been improved to the minimum bounding rectangle frame; finally, the left-ray method is used to match the grasp point 2D coordinates with the improved positioning bounding box - the minimum bounding rectangle frame, and the classified grasp detection result are obtained according to the minimum bounding rectangle frame that the grasp point coordinates fall into. Experimental results show that the proposed method can identify the classification of the object, and the improved positioning bounding box can solve the problem of classification errors caused by matching the grasp point coordinates to multiple positioning bounding boxes, and improve the accuracy of grasp detection classification rate.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89134-3_64,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-7527-3_59,Tracking Control of Parallel Robot Manipulators Using RBF Neural Network,Research in Intelligent and Computing in Engineering,10.1007/978-981-15-7527-3_59,Springer,2021-01-01,"Since parallel robots are the multibody systems with closed-loop structures, their movement equations usually are in the complex form of redundant coordinates and their dynamics parameters are usually uncertain. The aim of this paper is to improve the control quality for the parallel robot by applying RBF neutron network. Firstly, the movement equations of Rostock Delta robot are established as differential–algebraic systems of equations with redundant generalized coordinates. Then, the stableness of the control method based on sliding mode control law using neural network is proved. Finally, the error in tracking control of a specific Rostock Delta robot is simulated by using this method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-7527-3_59,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-58080-3_323-1,AI in Surgical Robotics,Artificial Intelligence in Medicine,10.1007/978-3-030-58080-3_323-1,Springer,2021-01-01,"The future of surgery is tightly knit with the evolution of artificial intelligence (AI) and its thorough involvement in surgical robotics. Robotics long ago became an integral part of the manufacturing industry. The area of healthcare though adds several more layers of complication. In this chapter we elaborate a broad range of issues to be dealt with when a robotic system enters the surgical theater and interacts with human surgeons – from overcoming the limitations of minimally invasive surgery to the enhancement of performance in open surgery. We present the latest from the fields of cognitive surgical robots, focusing on proprioception, intraoperative decision-making, and, ultimately, autonomy. More specifically, we discuss how AI has advanced the research field of surgical tool tracking, haptic feedback and tissue interaction sensing, advanced intraoperative visualization, robot-assisted task execution, and finally land in the crucial development of context-aware decision support.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58080-3_323-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-54173-6_8,Robotics and AI in Food Security and Innovation: Why They Matter and How to Harness Their Power,"Robotics, AI, and Humanity",10.1007/978-3-030-54173-6_8,Springer,2021-01-01,"From strawberry-picking robots to satellite remote sensing and GIS techniques that forecast crop yields, the integration of robotics and AI in agriculture will play a key role in sustainably meeting the growing food demand of the future. But it also carries the risk of alienating a certain population, such as smallholder farmers and rural households, as digital technologies tend to be biased toward those with higher-level skills. To ensure that digital technologies are inclusive and become a driver for development, countries should make technology affordable and invest in institutions and human capital, so that everyone can participate in the new digital economy. Digital agriculture also represents an opportunity for young people as agriculture value chains can be developed to create new service jobs in rural areas, making agriculture an attractive sector for youth.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54173-6_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-64969-2_11,"Parallels Between the Future for MedTech and Agri-Tech, Perspectives Drawing on the British Experience",Bio#Futures,10.1007/978-3-030-64969-2_11,Springer,2021-01-01,"In this chapter we explore the future for innovation in two related, but distinct, sectors. We consider the linkages between medical technology (MedTech) and agricultural technology (Agri-Tech) innovation in the UK. We ask and discuss questions: Who are the key actors in the innovation systems of MedTech and Agri-Tech in the UK? What are the core technologies driving the current waves of innovation in these two sectors? Can one industry learn from the other? Where is the scope for cooperation and synergies? We notice that both sectors are technologically linked through foundational technologies underpinning the majority of the observed innovation, e.g. big data, AI, IoT and robotics. The outputs of these technologies rely crucially on digital data for insight and decision support. However, Agri-Tech benefits from less complex stakeholder issues regarding data security and privacy. Both sectors are important to the UK going forwards, and both will be exposed to Brexit and consequences of the COVID pandemic. Our discussion on the future for innovation should be of particular interest to start-up leaders, entrepreneurs, investors, managers and policy-makers in MedTech, Agri-Tech and cognate sectors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-64969-2_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-54522-2_11,Research Programs Based on Machine Intelligence Games,Italian Philosophy of Technology,10.1007/978-3-030-54522-2_11,Springer,2021-01-01,"Games have played a significant role throughout the history of artificial intelligence and robotics. Machine intelligence games are examined here from a methodological perspective, focusing on their role as generators of research programs. These research programs are schematized in terms of framework building, subgoaling, and outcome appraisal processes. The latter process is found to involve a rather intricate system of rewards and penalties, which take into account the double allegiance of participating scientists, trading and sharing interchanges which occur in multidisciplinary research environments, in addition to expected industrial payoffs, and a variety of other research benefits in the way of outreach and dissemination of results, recruitment of junior researchers and students’ enrolment. Examples used here to illustrate these various aspects of the outcome appraisal process include RoboCup and computer chess, Go, Poker and video-games. On the whole, a reflection on research programs that are based on machine game playing opens a window on central features of the complex systems of rewards and penalties that come into play to appraise machine intelligence investigations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54522-2_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-69325-1_16,Lessons Learned from Robotics and AI in a Liability Context: A Sustainability Perspective,Sustainability in the Maritime Domain,10.1007/978-3-030-69325-1_16,Springer,2021-01-01,"An important area of application of robotics technologies is unmanned water surface and underwater vehicles, such as in remote exploration work, maritime transportation, repairs of oil rigs and so on. This study evaluates the consequences of these technologies, particularly in a liability context. Taking into account the characteristics of vehicles mentioned above, especially autonomy, it is expected that development of these vehicles, and their increased use in the civil sector, is likely to require a new approach other than the well-established fault-based liability regime. Still, these autonomous vessels are not expected to require amendments to the basic tenets of maritime law as illustrated in, for instance, the 1972 IMO COLREGs Convention. In the light of contemporary applications, it is submitted that most unmanned water surface and underwater vehicles are becoming more and more autonomous, and they are closer to reasonable safety when compared to the ultra-hazardous activity of unmanned aerial vehicles. Safety being the keyword, this chapter argues that the liability regime that applies to unmanned marine vessels should not only conform to the technical characteristics of these vehicles but also balance the social interest in technological progress with the interest of general security and the freedom of commercial enterprise. Indeed, the liability regime to be applied to marine vessels should respond to similar needs with the regime to be applied to robots. A balanced and consistent liability regime is essential for the economic viability of maritime sectors, especially maritime transport, and the economic viability is a prerequisite for sustainability. Moreover, long-term sustainability concerns make it unreasonable to altogether refuse technological innovation, which has many advantages in terms of environmental protection and resource management. To that end, the present study focuses its analysis on the EU law.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-69325-1_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-4299-6_31,A Proposed IoT Architecture for Corals Research Using AI and Robotics,Progress in Advanced Computing and Intelligent Engineering,10.1007/978-981-33-4299-6_31,Springer,2021-01-01,"Aumeer, Wafiik Pooloo, Nabeelah Khoodeeram, Rajeev Coral reefs are one of the most diverse ecosystems on the planet and are vital in providing nursery, spawning, refuge, and nurturing areas for a multitude of different organisms. However, coral reefs are degrading owing to climate change, overfishing, industrial pollution and invasive species. Thereafter, mass coral bleaching events and infectious disease outbreaks take place causing corals to die. This paper aims at contributing in the monitoring of corals in the Mauritian marine ecosystem by utilising a Hybrid Underwater Vehicle (HUV) autonomously for collection of oceanographic data as well as images and videos of surveyed coral reefs sites. Data collected will be transmitted to a base station via Cellular IoT communication for analytics using two methods of Artificial Intelligence (AI) namely Machine Learning and Deep Learning. The conceptual design is thoroughly described together with software applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-4299-6_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-80418-3_32,Towards Visually Intelligent Agents (VIA): A Hybrid Approach,The Semantic Web: ESWC 2021 Satellite Events,10.1007/978-3-030-80418-3_32,Springer,2021-01-01,"Service robots can undertake tasks that are impractical or even dangerous for us - e.g., industrial welding, space exploration, and others. To carry out these tasks reliably, however, they need Visual Intelligence capabilities at least comparable to those of humans. Despite the technological advances enabled by Deep Learning (DL) methods, Machine Visual Intelligence is still vastly inferior to Human Visual Intelligence. Methods which augment DL with Semantic Web technologies, on the other hand, have shown promising results. In the lack of concrete guidelines on which knowledge properties and reasoning capabilities to leverage within this new class of hybrid methods, this PhD work provides a reference framework of epistemic requirements for the development of Visually Intelligent Agents (VIA). Moreover, the proposed framework is used to derive a novel hybrid reasoning architecture, to address real-world robotic scenarios which require Visual Intelligence.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-80418-3_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89092-6_66,Velocity Constraints Based Online Trajectory Planning for High-Speed Parallel Robots,Intelligent Robotics and Applications,10.1007/978-3-030-89092-6_66,Springer,2021-01-01,"Trajectory planning method is important for stable and efficient sorting operations of robots. In this paper, a method for planning the equal-height picking-and-placing trajectory considering velocity constraint is proposed. The velocity constraint in start/end kinematics parameter makes the trajectory more adaptable to complex production line situations. An online trajectory optimization solution is proposed, which simplifies the solution of optimization problem and achieves the real-time nature of the method by BP neural networks. Simulation results on SR4 parallel robots show the effectiveness of the optimization method. The work done in this paper is of great help to the application of high-speed parallel robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89092-6_66,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-0598-7_1,Manipulation of Standard Link Mechanism for Robotic Application Using Artificial Neural Network and PID,Machine Learning for Robotics Applications,10.1007/978-981-16-0598-7_1,Springer,2021-01-01,"The simulation of the position of manipulator requires knowledge of its coordinates in the functional space. The simulation of forward kinematics and inverse kinematics has been implemented on PUMA560 robot having six degrees of freedoms using suitable artificial neural network (ANN) technique. Further, types of forces involved for robotic manipulation are inertia loading, the coupling between joints and gravity effects consisting of position and velocity terms. The nonlinearity of forces and associated uncertainties in modelling necessitates consideration of appropriate tools of the control strategy for simulation. The torque based on a proportional-integral-derivative (PID) controller has been provided to each of the robot joints to achieve the desired position. The methodology is successfully demonstrated on the six degree of freedom system, PUMA560 by achieving the desired trajectory of the end effector.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-0598-7_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89134-3_51,Terrain Attribute Recognition System for CPG-Based Legged Robot,Intelligent Robotics and Applications,10.1007/978-3-030-89134-3_51,Springer,2021-01-01,"In this paper, we develop a terrain attribute recognition system for CPG-based legged robots. First, a low-cost sensing hardware device is designed to be integrated into the robot, including a tactile sensor array and RGB camera. Second, for the tactile modality, a novel terrain attribute recognition framework is proposed. A data generation strategy that adapts to the motion characteristics is presented, which transforms the original tactile signal into a structured representation, and extract meaningful features. Based on unsupervised and supervised machine learning classifiers, the recognition rates reach 94.0% and 95.5%, and the switching time is 1 to 3 steps. Third, for the recognition of terrain attributes in the visual modality, a lightweight real-time mobile attention coding network (MACNet) is proposed as an end-to-end model, which shows an exhibiting an accuracy of 88.5% on the improved GTOS mobile data set, 169FPS inference speed and 6.6 MB model parameter occupancy. Finally, these two methods are simultaneously applied to the AmphiHex-II robot for outdoor experiments. Experimental results show that each modality has its own advantages and disadvantages, and the complementary relationship between multiple modalities plays an irreplaceable role in a broader scene.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89134-3_51,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-89098-8_59,Research on Short Term Power Load Forecasting Combining CNN and LSTM Networks,Intelligent Robotics and Applications,10.1007/978-3-030-89098-8_59,Springer,2021-01-01,"Accurate prediction of power load plays an important role in the optimal scheduling of resources. However, the lack of power data in the traditional automatic acquisition system inevitably affects the subsequent data analysis. With the help of on-site real-time monitoring, the integrity of data collection can be ensured. In this paper, a load forecasting model based on the fusion of Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) is proposed. Through training the historical data collected by the on-duty robot, a complete network model is constructed. The network extracts the effective sequence features of the input data through CNN network, and gets the load prediction results through LSTM network. The experimental results show that the fusion network of CNN and LSTM obtains higher prediction accuracy than present algorithms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-89098-8_59,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7213-2_2,Object Detection of Basketball Robot Based on MobileNet-SSD,"Intelligent Equipment, Robots, and Vehicles",10.1007/978-981-16-7213-2_2,Springer,2021-01-01,"Object detection is one of the research hotspots in the field of computer vision. In this paper, we use the lightweight network MobileNet combined with Single Shot Multibox Detector (SSD) to realize the object detection of the robot. SSD combined with MobileNet can effectively compress the size of the network model and improve the detection rate. The method does automatic extraction on the image features first, and add different size feature maps after the basic network, and then do convolution filtering on the multi dimension feature maps to get the object coordinate value and the object category. In the experiment, compared with the original vision method based on OpenCV, the MobileNet-SSD algorithm was less affected by illumination conditions in the object recognition process, and achieved the rapid and accurate recognition of the basketball robot on the ball.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7213-2_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-79763-8_7,Development of a Neural Network Algorithm to Detect Soldier Load from Environmental Speech,Advances in Simulation and Digital Human Modeling,10.1007/978-3-030-79763-8_7,Springer,2021-01-01,"The objective was to develop a model based on speech input that can identify when team members need adaptive autonomous assistance. Human teams often adjust their behavior to work cohesively and effectively as a team. Similarly, it is beneficial for autonomous agents to be able to adaptively adjust to team needs. We constructed a convolutional recurrent neural network model based on those developed for the recognition of emotion from speech. Audio recordings from a recent field exercise were used to train and validate the model. These data were labeled according to whether the speech occurred during an engagement (engaged, neutral, or no-speech). The model classified more than 99% of the training, validation, and test sets correctly. This information will allow us to design systems in which autonomous agents can prioritize, assist with, and take autonomous control of tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-79763-8_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-70917-4_23,Scalp Massage Therapy According to Symptoms Based on Vietnamese Traditional Medicine,"Advances in Robotics, Automation and Data Analytics",10.1007/978-3-030-70917-4_23,Springer,2021-01-01,"A massive growth in the modernize population, because of disabled people, patients after surgery those whom cannot have ability to move and even wash themselves. Tied on their own bed, has created many problems including the need for massage service and convenient healthcare to help patients body relax and shampoo themselves which reduce medical care staff, otherwise, most of them feel inferior when someone touches their head when they are sick or having dermatological problem. In this paper, on-going projects related to essential technology for reducing work force and overcrowding in Vietnamese hospital are discussed. We propose robotic autonomous scalp massage and shampoo combine with traditional Vietnamese’s acupuncture massage to aid in resolving problems that people suffering from bed sick are experiencing, reports on design, service personalization and deployment of an assistive robot to support elderly people, disabled and patients with scalp care. Levenberg-Marquardt algorithm in artificial neural network are applied to train from collected acupuncture points to give the best trajectories following patient’s symptoms, analyzed for diagnosing and evaluating hairy scalp issues for the neural network input variables associated with body values such as height, weight, age or race which plays an important role in the composition of the multi-layer perceptron. The experimented and analyzed from multi-modal data collection of the first ever longitudinal field trials from patients throughout each experiment, indoor environments demonstrate by people with unmovable needs care. From the experiments, it indicates the ability of combining the mechanical system with 2-DOFs, human scalp massages by water jets with trajectories predicted by machine learning based on physical factors to meet the desired position on human scalp, providing enhanced resilience to being treated patients.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-70917-4_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-74893-7_10,Biologically Inspired Neural Behavioral Control of the Wheeled Mobile Robot,"Automation 2021: Recent Achievements in Automation, Robotics and Measurement Techniques",10.1007/978-3-030-74893-7_10,Springer,2021-01-01,"In this paper, to solve the task of neural behavioral control of a 2-wheeled mobile robot (WMR), a hierarchical structure is used. At higher levels of the hierarchic generate a desired trajectory of mobile robot motion based on the artificial potential field theory. The generated trajectory is a desired trajectory realized by the neural control algorithm, implemented on the lower level of the hierarchy. Correctness of the solution of the desired trajectory generator and the control system of the elementary robot behavior has been confirmed in numerical simulations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-74893-7_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-0771-4_12,Fatwas from Islamweb.Net on Robotics and Artificial Intelligence,Artificial Intelligence in the Gulf,10.1007/978-981-16-0771-4_12,Springer,2021-01-01,"The aim of this chapter is to deal with perceptions perception of robotics and artificial intelligence (AI) from an Islamic Islamic perspective. Since this discourse has not spread much yet, I use the analysis of fatwas fatwa as a starting point. Fatwas are legal opinions expressed by a Muslim scholar or anybody with expertise in Islamic Law ( Arab Arab . mufti). Fatwas give scholars the opportunity to react to innovations (social, legal, technological et cetera) from an Islamic point of view and to judge these according to Islamic Islamic law. The 14 Arabic and English Islamic legal opinions I analysed were all coming from the Qatari Ministry of Awqaf and Islamic Affairs, which is linked to the conservative Wahhabi branch of Islam islam . They were issued between 2002 and 2019 on the web page Islamweb.net. A comparison between the different Islamic Islamic currents is not possible since so far no other fatwas dealing with robotics and/or AI are to be found. The analysis of these Islamic legal opinions is done through the lens of the following questions and by the use of qualitative content analysis: To what extent can Islamic Islamic positions on AI and robotics be found in fatwas? What statements are made by the scholars? How do the attitudes attitude to robotics and AI differ? An analysis of the content and the methods shows that the scholars: (1) have a fairly clear stance on the treatment of robotics but not on AI; (2) are not concerned that these technologies could harm humans or that their creators usurp God’s power to create; and (3), rather tend to avoid dealing with difficult issues such as the impacts of developing strong AI.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-0771-4_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-77820-0_17,What if: Human Rights vs Science – or Both?,"Digital Human Modeling and Applications in Health, Safety, Ergonomics and Risk Management. AI, Product and Service",10.1007/978-3-030-77820-0_17,Springer,2021-01-01,"The author examines the social, economic and political consequences to human rights in terms of modern ICT technologies and biotechnology advances (CRISPR-Cas9) as well as newly developed medical-based rehabilitation techniques. In addition to the benefits of newer technologies, the author offers a recognition and understanding of the hidden risks and their possible long-term consequences when it comes to human rights. The author, who has been a member of the UN CRPD, the human rights committee on the rights of the persons with disabilities for 8 years, puts whether human rights or science and scientific innovation takes precedence. Both artificial intelligence and biotechnology together with invasive solutions (implants) face a number of ethical issues that still remain unanswered. The author also presents the socio-political and legal aspects that arise in connection with the latest developments (see Elon Musk’s brain implant project). Moreover, the author also introduces a new term, homo sapiens conrectus , pointing out that we can speak not only of a correction in relation to modern rehabilitation, but also directly of an upgrade, leading to unpredictable social consequences. This process will also lead us to ‘ post-Renaissance polymaths’ , which will revolutionize the world of work and education.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77820-0_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-69128-8_4,Artificial Intelligence and the Future of Work,Reflections on Artificial Intelligence for Humanity,10.1007/978-3-030-69128-8_4,Springer,2021-01-01,"Digital transformation is underway, particularly shaped by the ever-expanding frontier of Artificial Intelligence (AI) technologies. It is impacting our everyday life, at work, in public space, as well as at home and in the private sphere. We are already strong users and consumers of information, and our dependence on connectivity, shaping the way we make decisions, the way we interact, even more how we feel. This trend seems to be irreversible.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-69128-8_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-58080-3_64-1,AIM in Medical Robotics,Artificial Intelligence in Medicine,10.1007/978-3-030-58080-3_64-1,Springer,2021-01-01,"Medical robotics emerged in the 1980s to improve clinicians’ technical capability and increase safety in clinical procedures. This chapter specifically addresses the topic of surgical robots. Major opportunities for artificial intelligence (AI) here include (i) surgical planning, (ii) intra-operative registration, (iii) surgical execution, and (iv) surgery evaluation/ assessment. This chapter provides an overview of AI methodologies developed so far in these four fields, reporting main limitations and open challenges. Deep learning (DL) models for pre-operative image segmentation, classification, and detection are presented, along with DL architectures for intra-operative registration. In the context of surgical execution, intra-operative image analysis is described, focusing on endoscopic images for tissue and surgical tool segmentation. Considering the rapid evolution of AI applications in the field of surgical robotics, the proposed contribution is aimed at giving to young researchers and surgeons working in the field of surgical robotics a complete overview on the current AI applications proposed in literature.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58080-3_64-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-87725-5_1,Prioritized SIPP for Multi-agent Path Finding with Kinematic Constraints,Interactive Collaborative Robotics,10.1007/978-3-030-87725-5_1,Springer,2021-01-01,"Multi-Agent Path Finding (MAPF) is a long-standing problem in Robotics and Artificial Intelligence in which one needs to find a set of collision-free paths for a group of mobile agents (robots) operating in the shared workspace. Due to its importance, the problem is well-studied and multiple optimal and approximate algorithms are known. However, many of them abstract away from the kinematic constraints and assume that the agents can accelerate/decelerate instantaneously (Fig.  1 ). This complicates the application of the algorithms on the real robots. In this paper, we present a method that mitigates this issue to a certain extent. The suggested solver is essentially, a prioritized planner based on the well-known Safe Interval Path Planning (SIPP) algorithm. Within SIPP we explicitly reason about the speed and the acceleration thus the constructed plans directly take kinematic constraints of agents into account. We suggest a range of heuristic functions for that setting and conduct a thorough empirical evaluation of the suggested algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-87725-5_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-0983-1_14,SkillsFuture: The Roles of Public and Private Sectors in Developing a Learning Society in Singapore,Powering a Learning Society During an Age of Disruption,10.1007/978-981-16-0983-1_14,Springer,2021-01-01,"The future of learning and work, and the development of learning societies, are being disrupted by technological advancements, shifting demographics, extended careers, and more recently, by the coronavirus disease pandemic, with a massive impact on businesses and individuals around the world. Disruptions such as the fourth industrial revolution or Industry 4.0, demographic changes in the labor force, and increases in human life expectancy have accentuated the inadequacies of traditional education and training systems in responding to rapidly evolving skills needs of businesses and individuals. This chapter discusses the need for a new learning architecture for a more flexible and agile system of education and training, where both public and private sectors play significant roles to help companies, workers, and society address skills needs for the future of work and living. The SkillsFuture movement in Singapore is presented to demonstrate how strong multistakeholder partnerships are fostering a more dynamic, holistic, and collaborative learning ecosystem for individuals to acquire new skills and confidently navigate the uncertain future.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-0983-1_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-58740-6_16,The Future of Nursing Informatics in a Digitally-Enabled World,Introduction to Nursing Informatics,10.1007/978-3-030-58740-6_16,Springer,2021-01-01,"The nursing profession has a history of embracing novel technologies that support the delivery of compassionate, person-centred care. The emergence and rapid adoption of ‘intelligent’ technologies that have the ability to act autonomously, but that are often embedded and ‘invisible’ to users, is challenging the nursing profession to reconsider their role in the health system of the future. Using a socio-technical lens the authors examine artificial intelligence and process automation technologies because of their significant potential to become much further embedded into nursing work and disrupt the healthcare system as we know it. Opportunities for nurses to transform their role in the healthcare value chain, will arise from the profession’s proactive reconceptualization of the nursing role in an era where technology is moving from discrete transaction processing and monitoring applications to pervasive computing. But the nurse’s traditional patient and family advocacy role will remain important, as policy, regulatory and ethical challenges arise from the development and use of these emergent digital technologies. The rapidly changing healthcare ecosystem demands nursing involvement in the research, design, adoption and use of emergent digital technologies. The subtle normalization of these technologies into the nursing role will require new nursing knowledge and skills, and different relationships between nurses (i.e., practice, education, research, leadership) and other actors (i.e. patients, physicians, technologies) in the healthcare ecosystem of the future.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58740-6_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-56917-4_11,Advancing Telehealth to Improve Access to Health in Rural America,"Telemedicine, Telehealth and Telepresence",10.1007/978-3-030-56917-4_11,Springer,2021-01-01,"As we begin the second decade of the twenty-first century, there are those Americans who have limited access to medical care and health information. Advancements in technology—computers, sensors, information technology, and communications—provide a remarkable platform for change. Access via broadband communications can provide access to virtual care and educational services. Rural health policy is set by the Federal government but is influenced by many different contributing factors. Several states have been permitted to utilize telehealth, and it has been reimbursable, and as such, a lot of research has been conducted in rural areas. Sometimes events occur that alter the standard approach or the “old way.” Recently, the World Health Organization declared a pandemic due to COVID-19. This has caused the healthcare system to begin to finally embrace telemedicine and telehealth as an ideal tool across the entire landscape. There will always be challenges, and more often than not there are amazing solutions. This chapter provides a review of how telemedicine and telehealth are impacting healthcare in rural America.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-56917-4_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-56917-4_16,Technological Advances Making Telemedicine and Telepresence Possible,"Telemedicine, Telehealth and Telepresence",10.1007/978-3-030-56917-4_16,Springer,2021-01-01,"Imagine a world without technology. What would we do? How would we survive? What would we do without our smartphones? Well, humanity did pretty good for thousands of years, even though there were some significant challenges put in front of our ancestors. Advances in telecommunications, computing power, data storage, and a variety of mechanical devices have helped healthcare, medicine, and public health reach new levels. The integration of these various tools has permitted telemedicine, telehealth, e-health, m-health, and telepresence to become common place and fully entrenched in commerce and all human activity. This chapter presents some of these technological advances at a very high level. A complete or exhaustive list would fill numerous volumes of several compendiums. The important points to remember are that these technological advances continue to amaze us. They become significant and I dare say vital to our way of life and our ability to enable better healthcare.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-56917-4_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-58080-3_334-1,AIM in Nursing Practice,Artificial Intelligence in Medicine,10.1007/978-3-030-58080-3_334-1,Springer,2021-01-01,"Global emergence and exponential growth of artificial intelligence (AI) is becoming seamlessly integrated in our lives. By definition, AI describes a set of advanced technologies enabling machines to perform highly complex tasks effectively otherwise requiring intelligence that can’t be matched if human beings were to perform them. How this reflects on the human mind is certain to continue being an area of ongoing research. This said, science fiction books and the numerous AI-induced apocalyptic scenarios presented to us in films and television series depicting AI gone wrong have cultivated a sense of fear and apprehension. However, to date, the healthcare industry does not evoke Orwellian concerns. Instead, the impact of this technology is particularly evident in the healthcare sector where this innovation promises transformation of the landscape of nursing practice along with the process involved in the delivery of collaborative, compassionate, ethically sound, and evidence-based patient care. In so doing, AI will likely resolve the current problem of global staff shortage and the decline in funding growth driven by an aging baby boomer generation living with multiple complex chronic health conditions. During this transformative time, nurses must reflect on how healthcare technologies can ensure the patient’s experience of care is embedded with understanding and compassion. The loss of these essential characteristics may lead patients to feel that in an AI-driven world their rights become an after-thought in the relentless pursuit of efficiency. To address this, formal and informal educational programs need to be reviewed. Besides enhancing the educators’ AI knowledge, it would be logical to include AI-related professionals to create a truly collaborative approach to training nurses.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58080-3_334-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-66222-6_6,A Concept of Internet of Robotic Things for Smart Automation,Emergence of Cyber Physical System and IoT in Smart Automation and Robotics,10.1007/978-3-030-66222-6_6,Springer,2021-01-01,"A recent evolution in the field of Internet of Things (IoT) is the interdisciplinary domain involving smart automation and robotics implemented by the techniques of Internet of Things (IoT), famously known as Internet of Robotic Things (IoRT). This emerging technology is adopted in various sectors such as health care, manufacturing industries, economic, information technology and several other fields. Persistent sensors and actuators involved in robotics and automation are brought together by the emerging vision of Internet of Robotic Things. The domains of robotics and Internet of Things (IoT) cannot be viewed separately hence integrated together to form the novel domain—Internet of Robotic Things where the technologies of robotics are implemented in the scenarios of IoT. This chapter aims to provide an overview of possible solutions for various issues in smart automation environment and applications of robotics using Internet of Things (IoT). Envisioning dense heterogeneous devices communicating with each other to accomplish various objectives in the field of automation and robotics using Internet of Things (IoT) is the aim of this chapter. This technology can increase efficiency at reduced cost, significantly reducing manual intervention by increasing automation process visioning by SCADA systems. Industrial automation involving Internet of Things (IoT) has the goal of self-configuration, self-organization, self-healing system, scalability with less power consumption compatible to global standards. Involvement of robotics in the field of Internet of Things (IoT) potentially changes the process of production where the operations are performed rapidly in an accurate way leading to tremendous value in the field of automation. These two domains are converged and developed to provide the concept, architecture, involved technologies, challenges and applications and future work in order to cover (Internet of Robotic Things) IoRT comprehensively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-66222-6_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-52067-0_6,"Towards Artificial Intelligence: Concepts, Applications, and Innovations",Enabling AI Applications in Data Science,10.1007/978-3-030-52067-0_6,Springer,2021-01-01,"Artificial intelligence (AI) is a set of theories and techniques implemented in order to achieve solutions capable of simulating intelligence. However, the quick progress in AI raises many questions regarding the benefits and risks of this technology, which can be used in many areas, drawing on advanced software and computers. The AI has also become more popular and especially used for modeling the complex behavior of most life solutions because it shows superior predictive power compared to traditional methods. This document presents the AI technology with a focus on strengths and weaknesses in its various applications to extract a list of the pros and cons of AI technology and reminds of some obstacles that can be faced during the completion of their projects. The contributions presented in this document reveal the high potential of AI methods as tools for predicting and optimizing different applications. In addition, challenges and directions for future research in the area of the use of AI techniques are presented and discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-52067-0_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-54173-6_22,A Human Blueprint for AI Coexistence,"Robotics, AI, and Humanity",10.1007/978-3-030-54173-6_22,Springer,2021-01-01,"The positive coexistence of humans and AI is possible and needs to be designed as a system that provides for all members of society, but one that also uses the wealth generated by AI to build a society that is more compassionate, loving, and ultimately human. It is incumbent on us to use the economic abundance of the AI age to foster the values of volunteers who devote their time and energy toward making their communities more caring. As a practical measure, to protect against AI/robotics’ labor saving and job displacement effects, a “social investment stipend” should be explored. The stipend would be given to those who invest their time and energy in those activities that promote a kind, compassionate, and creative society, i.e., care work, community service, and education. It would put the economic bounty generated by AI to work in building a better society, rather than just numbing the pain of AI-induced job losses.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54173-6_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-66222-6_13,IoT for Smart Automation and Robot,Emergence of Cyber Physical System and IoT in Smart Automation and Robotics,10.1007/978-3-030-66222-6_13,Springer,2021-01-01,"The technology, which is behind this drastically changing world, is the Internet of things (IoT) and Internet of things connected devices. These devices are capable of communicating over the Internet by using various protocols designed for wireless networks. In recent years, IoT devices have flooded the market, and their services to the society and the world infrastructure are becoming vital. The growing demand for automation has accelerated the deployment of IoT devices across the world. Not only the intelligent IoT devices and sensors but the robots also have become the backbone of smart automation systems such as home automation, industrial automation, and city automation (smart cities). The increasing number of these smart devices and growing infrastructure is creating security and privacy challenges, but at the same time, a number of leading companies have extended their support to curb the threat that may be fatal if not taken seriously. Startups have also started working in fields like healthcare, transportation, and delivery of goods via IoT devices across smart cities. Monitoring of streetlights, air quality, noise and traffic of a city, security, and optimal use of home appliances in a home and development of innovative technologies and increasing the production in an industry are some of the IoT and robotic services that the world is already exploiting. This chapter discusses the importance of intelligent IoT devices and robotics today and in future in the domains like home automation, industrial automation, and city automation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-66222-6_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-69415-9_103,The Role of Artificial Intelligence in Professional Legal Sphere: Development Tool or Existential Threat?,Modern Global Economic System: Evolutional Development vs. Revolutionary Leap,10.1007/978-3-030-69415-9_103,Springer,2021-01-01,"In the context of this study, the authors narrow the concept of modern information technologies to artificial intelligence technologies (to a greater extent - strong artificial intelligence) to consider the prospects, threats and risks associated with the introduction of these technologies within the framework of Legal Tech system in legal processes. So the main issue becomes the conclusion that professional legal sphere in future may possibly exist as a combination of technological and human resources. Artificial intelligence is described not a the threat to professional lawyers’ activity but a the great tool for democratization of the whole system of professional legal help and also will minimize the routine component of the work of a particular lawyer, allowing him or her to concentrate on finding non-standard solutions within his or her specialization.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-69415-9_103,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-60188-1_4,"Digital Transformation and Emerging Technologies for COVID-19 Pandemic: Social, Global, and Industry Perspectives",Artificial Intelligence and Machine Learning for COVID-19,10.1007/978-3-030-60188-1_4,Springer,2021-01-01,"COVID-19 disease pandemic is affecting the lives of millions of people in one or another manner. To handle the COVID-19 pandemic situation, technological aspects play a vital role in parallel to medical and healthcare facilities. With the use of existing infrastructure, technologies such as artificial intelligence, neural network, blockchain technology, cloud computing, drone-based monitoring, etc. have given the important observations and awareness to many. It is observed that with the combined efforts of technology and healthcare system, recognition of the outbreak is much faster compared to earlier infections. However, many are working continuously to collect and analyze the available COVID-19-related data and introspect the future. The whole of this work is performed to maximize the use of technology and reduce the risk of a continuous outbreak. This work has discussed the recent work done over the use of technologies in handling the COVID-19 scenario. Here, a comparative analysis of various parameters in each technological aspect is discussed to have an understanding of the preferred approaches in different places. Further, brief surveys are conducted in each technological aspect for a better understanding of technological advantage in handling pandemic.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60188-1_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-71756-8_19,Digital Dimensions of Industry 4.0: Opportunities for Autonomic Computing and Applications,Autonomic Computing in Cloud Resource Management in Industry 4.0,10.1007/978-3-030-71756-8_19,Springer,2021-01-01,"While walking the path through a fourth industrial revolution, the journey of transformation from the time when human intervention was needed, to the current state where the processes are completely automated and are still continuing to a new horizon. A game-changer adoption of the technology of “autonomic computing” supports industrial systems from deep inside and helps sustain with the ever-increasing complexity of systems, helps in customization to a greater extent, helps to manage the maintenance and reliability of the system that is beyond the limits of just human intervention. With this understanding, our work talks about important digital dimensions of smart manufacturing systems. It develops high-level awareness of technologies and ecosystems of smart manufacturing—Industry 4.0. Furthermore, readers would be able to identify tremendous opportunities for applications of computational intelligence referring to the capabilities and aspects of autonomic computing; those are self-healing, self-configuring, self-optimization, and self-protecting; thus pointers for innovation and applied research",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-71756-8_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-70228-1_2,The Fourth Industrial Revolution: A Resilience-Based Coping Strategy for Disruptive Change,Agile Coping in the Digital Workplace,10.1007/978-3-030-70228-1_2,Springer,2021-01-01,"The first, second and third industrial revolutions gave humanity steam power, electricity, internet and connectivity, respectively. The Fourth Industrial Revolution (4IR) is a seismic shift that brings with it a set of radically new technologies. Smart technology, artificial intelligence, robotics, algorithms, the internet of things, 3D printing, bioprinting, gene editing and autonomous vehicles are transforming the world at an incredible speed (Kruger, The Citizen (Gauteng), 2020; Guoping et al., Chin Geogr Sci 27(4):626–637, 2017). The world is marching into a new period characterised by unprecedented developments in digital technology, physical technology and biological technology and the convergence of their applications. As an agent of economic and social change, robotisation has elicited considerable concern about technological unemployment (Pol and Reveley, Psychosociolog Issues Hum Resour Manag 5(2):169–186, 2017). Coping behaviour is shown to be logically compatible with rationality and well suited to dealing with fear of joblessness. It is argued that coping strategies are needed to assist employees in dealing with the threats that robotisation poses to their future job security. The aim of this chapter is to conceptualise a resilience-based coping strategy for disruptive change in the 4IR (Tan, The fourth industrial revolution: coping with disruptive change. Nanyang Technological University, Singapore, 2016; Tan and Wu, Public policy implications of the fourth industrial revolution for Singapore. RSIS, Singapore, 2017). This chapter also suggests possible strategies for both organisations and governments to cope with the disruptive changes brought about by the 4IR.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-70228-1_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-67716-9_11,Application of Modern Technologies on Fighting COVID-19: A Systematic and Bibliometric Analysis,Emerging Technologies During the Era of COVID-19 Pandemic,10.1007/978-3-030-67716-9_11,Springer,2021-01-01,"COVID-19 pandemic drastically increased the demand for essential medical healthcare equipment’s, medicines along with the strict lockdown conditions to prevent disease transmission. As a result it becomes challenging for healthcare professionals to provide In-person treatment. This poses pressure to perform medical practices besides taking care of the spread of the novel coronavirus. Studies have declared that information technologies have the potential to fulfill customized requirements of COVID-19 pandemic. Thinking about advance technologies and its benefits, this study is going to provide a through literature about the application of advance technologies in real-time. The study also highlights that Telemedicine and Telehealth are the most widely used technological term in the COVID-19 research literature. The first aspect of the study is to search the literature that allowed us to understand the series of advance technologies emerging recently and how they are helpful during this pandemic? The second stream of literature focused on classifying the top 12 technologies under different scenarios as an outcome of the current situation. Study mapped the literature by selecting the final 83 articles to understand the benefits and application of these technologies in different areas of healthcare system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-67716-9_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-74009-2_8,Towards a General and Complete Social Assistive Robotic Architecture,"Human Interaction, Emerging Technologies and Future Applications IV",10.1007/978-3-030-74009-2_8,Springer,2021-01-01,"Social and service robots are designed to achieve complex tasks that are increasing daily. Cloud resources enhance service robots with strong computing capabilities and higher data storage centers. One of the major drawbacks of the cloud robotics model is the network latency that edge computing addresses. Considering the capabilities that a service robot must have to achieve somehow human-like capabilities, we propose a hybrid service-oriented fog robotic architecture. The proposed architecture follows the fog robotics approach to distribute the computations through the cloud, edge, and robot in a clear way. Robotic control systems are significantly varied based on the required tasks, environment, robot specifications, user and business needs, or programming tools that were used. The paper introduces several concepts to facilitate the designing or developing process of the robotic system based on the desired robot’s type and functions. Furthermore, automated planning, one of the most important factors to an intelligent and autonomous robot, has been evaluated based on several scenarios. These cases address the computational and the planning aspects through either the Edge or the Cloud server.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-74009-2_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-020-05032-0,A proposed decentralized formation control algorithm for robot swarm based on an optimized potential field method,Neural Computing and Applications,10.1007/s00521-020-05032-0,Springer,2021-01-01,"Lately, robot swarm has widely employed in many applications like search and rescue missions, fire forest detection and navigation in hazard environments. Each robot in a swarm is supposed to move without collision and avoid obstacles while performing the assigned job. Therefore, a formation control is required to achieve the robot swarm three tasks. In this article, we introduce a decentralized formation control algorithm based on the potential field method for robot swarm. Our formation control algorithm is proposed to achieve the three tasks: avoid obstacles in the environment, keep a fixed distance among robots to maintain a formation and perform an assigned task. An artificial neural network is engaged in the online optimization of the parameters of the potential force. Then, real-time experiments are conducted to confirm the reliability and applicability of our proposed decentralized formation control algorithm. The real-time experiment results prove that the proposed decentralized formation control algorithm enables the swarm to avoid obstacles and maintain formation while performing a certain task. The swarm manages to reach a certain goal and tracks a given trajectory. Moreover, the proposed decentralized formation control algorithm enables the swarm to escape from local minima, to pass through two narrow placed obstacles without oscillation near them. From a comparison between the proposed decentralized formation control algorithm and the traditional PFM, we obtained that NN-swarm successes to reach its goal with average accuracy 0.14 m compared to 0.22 m for the T-swarm. The NN-swarm also keeps a fixed distance between robots with a higher swarming error reaches 34.83%, while the T-swarm reaches 23.59%. Also, the NN-swarm is more accurate in tracking a trajectory with a higher tracking error reaches 0.0086 m compared to min. error of T-swarm equals to 0.01 m. Besides, the NN-swarm maintains formation much longer than T-swarm while tracking trajectory reaches 94.31% while the T-swarm reaches 81.07% from the execution time, in environments with different numbers of obstacles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-020-05032-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-92310-5_47,Recurrent Neural Network with Adaptive Gating Timescales Mechanisms for Language and Action Learning,Neural Information Processing,10.1007/978-3-030-92310-5_47,Springer,2021-01-01,"Inspired by the neurons’ differences in membrane time-scales, the multiple timescale recurrent neural network model (MTRNN) adopts the hierarchical architecture with increasing time-scales from bottom to top layers. Based on this idea, the recent adaptive and continuous time recurrent neural networks (ACTRNN) and the gated adaptive continuous time recurrent neural network (GACTRNN) develop the novel learning mechanism on the time-scales. In this paper, we test the performance of GACTRNN using the dataset obtained from a real-world humanoid robot’s object manipulation experiment. By using trainable timescale parameters with the gating mechanism, it can be observed that the GACTRNN can better learn the temporal characteristics of the sequences. Besides, to eliminate the effects of parameters’ overgrowing with a large data-set, we improve the GACTRNN model and propose the MATRNN model. In this model, the sigmoid function is used instead of exponential function. We compare the performances of the CTRNN, GACTRNN and MATRNN models, and find that the GACTRNN and MATRNN models perform better than the CTRNN model with the large-scale dataset. By visualizing the timescales adapting in the training process, we also qualitatively show that the MATRNN model performs better than the GACTRNN model in terms of stability with the dataset.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-92310-5_47,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-88458-1_3,Interactive Collaborative Robotics – New Results and New Problems,Modern Problems of Robotics,10.1007/978-3-030-88458-1_3,Springer,2021-01-01,"A collaborative robotics in the last decade has gained significant popularity due to the fact that it allows to bring robots outside the boundaries of large engineering enterprises. It turned out that there are a significant number of small and medium-sized enterprises in which the robotics implementation was hindered by the two factors only – safety requirements for employees and the complexity of programming and operation. When these limitations were bridged, robotics started to be applied. However, the application of collaborative principles in more complex processes, such as patients’ care in hospitals, prompt assistance to the surgeon during operations, rescue operations and etc. demanded to overcome a new barrier. Collaborative robots had to acquire elements of artificial intelligence in order to assist people in solving intellectual problems, by interacting with them actively. Perhaps, the date of birth of this trend in robotics should be considered the year 2016, when the first international conference on interactive collaborative robotics (Interactive Collaborative Robotics. ICR 2016, Budapest) took place. As the name of the conference implies, a new class of Co-robots involves the active interaction of humans and robots not only at the level of support when performing simple operations, but also some forms of dialogue, including verbal one. The article attempts to determine the current state of the issue and to examine in more detail some problems of fundamental importance, including those that require further research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-88458-1_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-63128-4_47,A Wise Up Visual Robot Driven by a Self-taught Neural Agent,"Proceedings of the Future Technologies Conference (FTC) 2020, Volume 1",10.1007/978-3-030-63128-4_47,Springer,2021-01-01,"This paper presents a biological inspired robot capable of learning by itself high level Tic-Tac-Toe playing policies and then use this knowledge to advantageously compete with humans. The robot comprises a robotic arm, an artificial vision system and a self-motivated neural agent which has the capability to explore in a simulated ambient, new forms of game episodes that conduce toward bigger rewards. During the training phase a three terms reinforcement learning scheme is proposed, where the agent memory resources are sustained by adviser neural sub-networks, noise-balanced trained as to satisfy the look for future conditions in the control optimization predicted by the Bellman equation. In the operating phase the components merge into a wised up robot, with look ahead capacities, that mimic the abilities of ingenious human players. The achieved look ahead robotic intelligence could be useful in other complex robotic mechanisms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-63128-4_47,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-55190-2_51,Grasping Unknown Objects Using Convolutional Neural Networks,Intelligent Systems and Applications,10.1007/978-3-030-55190-2_51,Springer,2021-01-01,"Robotic grasping has been a prevailing problem ever since humans began creating robots to execute human-like tasks. The problems are usually due to the involvement of moving parts and sensors. Inaccuracy in sensor data usually leads to unexpected results. Researchers have used a variety of sensors for improving manipulation tasks in robots. We focus specifically on grasping unknown objects using mobile service robots. An approach using convolutional neural networks to generate grasp points in a scene using RGBD sensor data is proposed. Two convolutional neural networks that perform grasp detection in a top down scenario are evaluated, enhanced and compared in a more general scenario. Experiments are performed in a simulated environment as well as the real world. The results are used to understand how the difference in sensor data can affect grasping and enhancements are made to overcome these effects and to optimize the solution.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-55190-2_51,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-58653-9_68,Control of Bio-Inspired Multi-robots Through Gestures Using Convolutional Neural Networks in Simulated Environment,CONTROLO 2020,10.1007/978-3-030-58653-9_68,Springer,2021-01-01,"In this paper the comparison between three convolutional neural networks, used for the control of bio-inspired multi-robots in a simulated environment, is performed through manual gestures captured in real time by a webcam. The neural networks are: VGG19, GoogLeNet and Alexnet. For the training of networks and control of robots, six gestures were used, each gesture corresponding to one action, collective and individual actions were defined, the simulation contains four bio-inspired robots. In this work the performance of the networks in the classification of gestures to control robots is compared. They proved to be efficient in the classification and control of agents, with Alexnet achieving an accuracy of 98.33%, VGG19 98.06% e Googlelenet 96.94% .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58653-9_68,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-62324-1_18,Muscle-Gesture Robot Hand Control Based on sEMG Signals Utilizing Deep Neural Networks,Computational Intelligence Methods for Green Technology and Sustainable Development,10.1007/978-3-030-62324-1_18,Springer,2021-01-01,"This paper presents a muscle gesture-computer interface (MGCI) system to control a five-fingered robotic hand with a commercial wearable gesture armband MYO employing deep neural networks. Eight channels of surface EMG signals were acquired and segmented. The extracted sEMG raw data for 10 “Taiwanese number” finger gestures was then trained utilizing convolutional neural networks. The average of best overall classification rate during off-line training is found 95.0%. Amongst the accuracy of recognition rates for two finger gestures are perfectly 100%. Accordingly the recognized hand gesture neural network model was implemented to evaluate the performance of the proposed system and experimental results showed that robot can emulate the finger gestures quite well. In addition, IMU (Inertial measurement unit) sensor was employed to calculate the motion of user forearm. Experimental results depict that the robotic manipulator can follow the motion of the user’s arm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-62324-1_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-65283-8_22,Detection of Scenes Features for Path Following on a Local Map of a Mobile Robot Using Neural Networks,Recent Research in Control Engineering and Decision Making,10.1007/978-3-030-65283-8_22,Springer,2021-01-01,"This article describes a software package for analyzing images from the camera of a mobile robot using neural networks. A key feature of the proposed solution is the model that generates recommendations for the robot about the direction of the further movement. This model receives raw video frames from the camera and generates a target rotation angle for the robot relative to the central axis of the robot, which must be followed at the next time in the control loop. Such a control loop is executed with a certain frequency in order to achieve the continuous adjustment of the robot’s driving direction to avoid collision with obstacles. A key feature of the proposed method is the high processing speed of video frames and acceptable quality. These characteristics are achieved due to the simple architecture of the neural network, without reinforcement learning, which is commonly used in robotics. The designed module can be used in addition to the existing navigation systems of a mobile robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-65283-8_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-62579-5_12,Graph Neural Networks for Human-Aware Social Navigation,Advances in Physical Agents II,10.1007/978-3-030-62579-5_12,Springer,2021-01-01,"Autonomous navigation is a key skill for assistive and service robots. To be successful, robots have to comply with social rules, such as avoiding the personal spaces of the people surrounding them, or not getting in the way of human-to-human and human-to-object interactions. This paper suggests using Graph Neural Networks to model how inconvenient the presence of a robot would be in a particular scenario according to learned human conventions so that it can be used by path planning algorithms. To do so, we propose two automated scenario-to-graph transformations and benchmark them with different Graph Neural Networks using the SocNav1 dataset  [ 1 ]. We achieve close-to-human performance in the dataset and argue that, in addition to its promising results, the main advantage of the approach is its scalability in terms of the number of social factors that can be considered and easily embedded in code in comparison with model-based approaches. The code used to train and test the resulting graph neural network is available in a public repository.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-62579-5_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12206-020-1229-6,Optimum design of a parallel robot using neuro-genetic algorithm,Journal of Mechanical Science and Technology,10.1007/s12206-020-1229-6,Springer,2021-01-01,"There are some advantages of parallel robots over serial ones, such as strong structure, big payload ratio with respect to the weight, and good dynamic response. The disadvantages of the parallel robots are the difficulty of solving the forward kinematics and the limited workspace. We apply the advantages of both neural networks and genetic algorithm, for the parallel robot design. With these two methods, we solve the problems of the maximum workspace and the forward kinematics. The design method we proposed in this paper uses the optimum algorithms such that the workspace volume of the robot is maximum. We successfully applied this method to the Stewart platform.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12206-020-1229-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-6318-2_8,Sit-to-Stand Intention Recognition,Advanced Manufacturing and Automation X,10.1007/978-981-33-6318-2_8,Springer,2021-01-01,Sit-to-stand (STS) difficulties are common among elderly because of the decline of their cognitive capabilities and motor functions. The way to help is to encourage them to practice their own functions and to assist only at the point where they need during STS processes. The provision of such support requires the elderly’s intention of standing up to be recognised and the amount of support as well as the moment when the support would be needed to be predicted. The research presented in this paper focuses on intention recognition as it is difficult due to uncertainties existing in STS processes and differences in individual’s biomechanical features. This paper presents fuzzy logic based self-adaptive approach to the recognition of standing up intention from sensor signals that contain the uncertainties.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-6318-2_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-71356-0_5,Balancing Exploration and Exploitation: A Neurally Inspired Mechanism to Learn Sensorimotor Contingencies,Human-Friendly Robotics 2020,10.1007/978-3-030-71356-0_5,Springer,2021-01-01,"The learning of sensorimotor contingencies is essential for the development of early cognition. Here, we investigate how such process takes place on a neural level. We propose a theoretical concept for learning sensorimotor contingencies based on motor babbling with a robotic arm and dynamic neural fields. The robot learns to perform sequences of motor commands in order to perceive visual activation from a baby mobile toy. First, the robot explores the different sensorimotor outcomes, then autonomously decides to utilize (or not) the experience already gathered. Moreover, we introduce a neural mechanism inspired by recent neuroscience research that supports the switch between exploration and exploitation. The complete model relies on dynamic field theory, which consists of a set of interconnected dynamical systems. In time, the robot demonstrates a behavior toward the exploitation of previously learned sensorimotor contingencies and thus selecting actions that induce high visual activation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-71356-0_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-57802-2_17,An Adaptive Cognitive Model to Integrate Machine Learning and Visual Streaming Data,15th International Conference on Soft Computing Models in Industrial and Environmental Applications (SOCO 2020),10.1007/978-3-030-57802-2_17,Springer,2021-01-01,"In this paper, we present our current work towards developing a context aware visual system with capabilities to generate knowledge using an adaptive cognitive model. Our goal is to assist people in their daily routines using the acquired knowledge in combination with a set of machine learning tools to provide prediction and individual routine understanding. This is useful in applications such as assistance to individuals with Alzheimer by helping them to maintain a daily routine based on historical data. The proposed cognitive model is based on simple exponential smoothing technique and provides real time detection of objects and basic relations in the scene. To fulfill these objectives we propose the integration of machine learning tools and memory based knowledge representation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-57802-2_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-68035-0_8,Using HPC as a Competitive Advantage in an International Robotics Challenge,High Performance Computing,10.1007/978-3-030-68035-0_8,Springer,2021-01-01,"Researchers in every knowledge field are moving towards the use of supercomputing facilities because the computing power they can provide is not achievable by individual research groups. The use of supercomputing centers would allow them to reduce costs and time. Additionally, there is a growing trend towards the use of GPUs clusters in HPC centers to accelerate particularly parallel codes as the ones related with the training of artificial neural networks. This paper presents a successful use case of a supercomputing facility, SCAYLE - Centro de Supercomputación de Castilla y León -(Spain) by a group of robotic researchers while participating in an international robotics competition - the ERL Smart CIty RObotic Challenge (SciRoc). The goal of the paper is to show that HPC facilities can be required to provided particular SLAs (Service Level Agreement). In the case described, the HPC services were used to train neural networks for object recognition, that could not be easily trained on-site and that cannot be trained in advanced because of the regulation of the competition.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-68035-0_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-93736-2_26,Embedded Face Recognition for Personalized Services in the Assistive Robotics,Machine Learning and Principles and Practice of Knowledge Discovery in Databases,10.1007/978-3-030-93736-2_26,Springer,2021-01-01,"Recently, the field of assistive robotics has drawn much attention in the health care sector. In combination with modern machine learning-supported person recognition systems, they can deliver highly personalized services. However, common algorithms for person recognition such as convolutional neural networks (CNNs) consume high amounts of power and show low energy efficiency when executed on general-purpose computing platforms. In this paper, we present our hardware architecture and field programmable gate array (FPGA) accelerator to enable on-device person recognition in the context of assistive robotics. Therefore, we optimize a neural network based on the SqueezeNet topology and implement it on an FPGA for a high degree of flexibility and reconfigurability. By pruning redundant filters and quantization of weights and activations, we are able to find a well-fitting neural network that achieves a high identification accuracy of 84%. On a Xilinx Zynq Ultra96v2 , we achieve a power consumption of 4.8 W, a latency of 31 ms and an efficiency of 6.738 FPS/W. Our results outperform the latency by 1.6x compared to recent person recognition systems in assistive robots and energy efficiency by 1.7x for embedded face recognition, respectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-93736-2_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-80568-5_34,Inverse Kinematics via a Network Ensemble and Learning Method,Proceedings of the 22nd Engineering Applications of Neural Networks Conference,10.1007/978-3-030-80568-5_34,Springer,2021-01-01,"A difficult goal in robotics is solving the inverse kinematics for N degree-of-freedom (DOF) robotic arms. Solving for the joint angles for a robot to follow a specified trajectory is a complex task as this requires solving for the solution of an end-effector with respect to its links and base coordinates. Depending on the number of DOFs, finding a closed form solution becomes impossible to find and computationally expensive. An alternative to this consists of function approximations in the form of neural networks (NN). Neural networks have the utility of mapping functions to inherently nonlinear processes such as solving for the trajectories of complicated manipulators through an iterative process of updating weight coefficients based on cost functions, error criteria, and optimization algorithms. In this paper, we propose a method that combines several different NN models along with a method for specifying different batches from the training set based on a set of error criteria with the ultimate goal of improving accuracy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-80568-5_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-62324-1_11,A PD-Folding-Based Controller for a 4DOF Robot,Computational Intelligence Methods for Green Technology and Sustainable Development,10.1007/978-3-030-62324-1_11,Springer,2021-01-01,"In this paper, an intelligent controller is proposed for high-accuracy position tracking control of a 4-degree-of-freedom (4DOF) robot. The control scheme is formatted using a 2-layer neural-network template, in which the first layer is encoded by a proportional-derivative structure, and the second layer is comprised of three different functions. Three ranges of perturbation that affects to the control performance are respectively treated by an offset learning, a folding PD control and high-switching control terms. The gains of the control terms are updated using modified gradient methods. Effectiveness of the proposed control is successfully verified by comparative simulation results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-62324-1_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-020-01262-5,Incremental Learning for Autonomous Navigation of Mobile Robots based on Deep Reinforcement Learning,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01262-5,Springer,2020-12-07,"This paper presents an incremental learning method and system for autonomous robot navigation. The range finder laser sensor and online deep reinforcement learning are utilized for generating the navigation policy, which is effective for avoiding obstacles along the robot’s trajectories as well as for robot’s reaching the destination. An empirical experiment is conducted under simulation and real-world settings. Under the simulation environment, the results show that the proposed method can generate a highly effective navigation policy (more than 90% accuracy) after only 150k training iterations. Moreover, our system has slightly outperformed deep-Q, while having considerably surpassed Proximal Policy Optimization, two recent state-of-the art robot navigation systems. Finally, two experiments are performed to demonstrate the feasibility and effectiveness of our robot’s proposed navigation system in real-time under real-world settings.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-020-01262-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-020-01237-6,A Fuzzy Reinforcement Learning Approach for Continuum Robot Control,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01237-6,Springer,2020-12-01,"Continuum robots (CRs) hold great potential for many medical and industrial applications where compliant interaction within the potentially confined environment is required. However, the navigation of CRs poses several challenges due to their limited actuation channels and the hyper-flexibility of their structure. Environmental uncertainty and characteristic hysteresis in such procedures add to the complexity of their operation. Therefore, the quality of trajectory tracking for continuum robots plays an essential role in the success of the application procedures. While there are a few different actuation configurations available for CRs, the focus of this paper will be placed on tendon-driven manipulators. In this research, a new fuzzy reinforcement learning (FRL) approach is introduced. The proposed FRL-based control parameters are tuned by the Taguchi method and evolutionary genetic algorithm (GA) to provide faster convergence to the Nash Equilibrium. The approach is verified through a comprehensive set of simulations using a Cosserat rod model. The results show a steady and accurate trajectory tracking capability for a CR.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-020-01237-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-020-01235-8,An Unsupervised Neural Network for Loop Detection in Underwater Visual SLAM,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01235-8,Springer,2020-12-01,"Thispaper presents a Neural Network aimed at robust and fast visual loop detection in underwater environments. The proposal is based on an autoencoder architecture, in which the decoder part is being replaced by three fully connected layers. In order to help the proposed network to learn the features that define loop closings, two different global image descriptors to be targeted during training are proposed. Also, a method allowing unsupervised training is presented. The experiments, performed in coastal areas of Mallorca (Spain), show the validity of our proposal and compares it to previously existing methods, based on pre-engineered and learned descriptors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-020-01235-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10676-017-9443-3,From responsible robotics towards a human rights regime oriented to the challenges of robotics and artificial intelligence,Ethics and Information Technology,10.1007/s10676-017-9443-3,Springer,2020-12-01,"As the aim of the responsible robotics initiative is to ensure that responsible practices are inculcated within each stage of design, development and use, this impetus is undergirded by the alignment of ethical and legal considerations towards socially beneficial ends. While every effort should be expended to ensure that issues of responsibility are addressed at each stage of technological progression, irresponsibility (meaning a lack of responsibility) is inherent within the nature of robotics technologies from a theoretical perspective that threatens to thwart the endeavour. This is because the concept of responsibility, despite being treated as such, is not monolithic: rather this seemingly unified concept consists of converging and confluent concepts that shape the idea of what we colloquially call responsibility. From a different perspective, robotics will be simultaneously responsible and irresponsible depending on the particular concept of responsibility that is foregrounded: an observation that cuts against the grain of the drive towards responsible robotics. This problem is further compounded by responsible design and development as contrasted to responsible use. From a different perspective, the difficulty in defining the concept of responsibility in robotics is because human responsibility is the main frame of reference. Robotic systems are increasingly expected to achieve the human-level performance, including the capacities associated with responsibility and other criteria which are necessary to act responsibly. This subsists within a larger phenomenon where the difference between humans and non-humans, be it animals or artificial systems, appears to be increasingly blurred, thereby disrupting orthodox understandings of responsibility. This paper seeks to supplement the responsible robotics impulse by proposing a complementary set of human rights directed specifically against the harms arising from robotic and artificial intelligence (AI) technologies. The relationship between responsibilities of the agent and the rights of the patient suggest that a rights regime is the other side of responsibility coin. The major distinction of this approach is to invert the power relationship: while human agents are perceived to control robotic patients, the prospect for this to become reversed is beginning. As robotic technologies become ever more sophisticated, and even genuinely complex, asserting human rights directly against robotic harms become increasingly important. Such an approach includes not only developing human rights that ‘protect’ humans (in a negative, defensive, sense) but also ‘strengthen’ people against the challenges introduced by robotics and AI (in a positive, empowering, manner) [This distinction parallels Berlin’s negative and positive concepts of liberty (Berlin, in Liberty, Oxford University Press, Oxford, 2002 )], by emphasising the social and reflective character of the notion of humanness as well as the difference between the human and nonhuman. This will allow using the human frame of reference as constitutive of, rather than only subject to, the robotic and AI technologies, where it is human and not technology characteristics that shape the human rights framework in the first place.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10676-017-9443-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-020-00953-9,The rise of artificial intelligence and the crisis of moral passivity,AI & SOCIETY,10.1007/s00146-020-00953-9,Springer,2020-12-01,"In “The rise of the robots and the crisis of moral patiency”, John Danaher argues that the rise of AI and robots will dramatically suppress our moral agency and encourage the expression of moral passivity. This discussion note argues that Danaher needs to strengthen his argument by supporting two key assumptions, that (a) AI will otherwise be friendly or neutral (instead of simply destroying humans), and that (b) humans will largely succumb to the temptation of over-relying upon AI for motivation and decision-making in their personal lives.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-020-00953-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41315-020-00154-z,A recurrent neural network for variable admittance control in human–robot cooperation: simultaneously and online adjustment of the virtual damping and Inertia parameters,International Journal of Intelligent Robotics and Applications,10.1007/s41315-020-00154-z,Springer,2020-12-01,"In this manuscript, a recurrent neural network is proposed for variable admittance control in human–robot cooperation tasks. The virtual damping and the virtual inertia of the designed robot’s admittance controller are adjusted online and simultaneously. A Jordan recurrent neural network is designed and trained for this purpose. The network is indirectly trained using the real-time recurrent learning algorithm and based on the velocity error between the reference velocity of the minimum jerk trajectory model and the actual velocity of the robot. The performance of the proposed variable admittance controller is presented in terms of the human required effort, the task completion time, the achieved accuracy at the target, and the oscillations during the movement. Its generalization ability is evaluated experimentally by conducting cooperative tasks along numerous straight-line segments using the KUKA LWR robot and by ten subjects. Finally, a comparison with previous developed variable admittance controllers, where only the variable damping or only the virtual inertia is adjusted, is presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-020-00154-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-019-01622-6,Robot algorithm based on neural network and intelligent predictive control,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-019-01622-6,Springer,2020-12-01,"With the improvement of industrial control requirements and the development of control theory and computer technology, it is more and more urgent to study the intelligent predictive control algorithm with good control effect, strong robustness and suitable for more complicated industrial processes. This paper proposes a novel intelligent predictive control scheme that uses a neural network intelligent predictive controller to control the force/position of the robot. The controller of this neural network can arbitrarily approach the uncertain object of the industrial robot without knowing the exact structure of the system. At the same time, due to the addition of intelligent predictive control, the system is easy to calculate online and the quality of control is improved. It can be seen from the simulation results of the robot that the traditional PID can not solve the uncertain object well. With the controller designed in this paper, the robustness and rapidity of the system are improved to some extent, and good control accuracy and control effects are achieved.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-019-01622-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-020-01693-w,Adaptive PID control of multi-DOF industrial robot based on neural network,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-020-01693-w,Springer,2020-12-01,"The control system of parallel robot, especially industrial robot, is a very complex multi-modal nonlinear system, which has the characteristics of time-varying, strong coupling and strong nonlinearity. Trajectory tracking control algorithm is a very important part of industrial robot control system. It is required that the algorithm can realize the continuous tracking of each joint of the robot and the processing and tracking of the desired trajectory. However, due to the strong influence of acceleration and speed on the trajectory tracking of industrial robots, the corresponding control difficulty and control accuracy are seriously affected. Based on the core idea of fuzzy neural network algorithm, the functional relationship between control error and arrival degree is established to improve the control quality of industrial robots. At the same time, combining with the PID feedforward control algorithm, the self-adaptive adjustment of PID parameters is realized, and the accuracy of the tracking algorithm is improved. In order to verify the superiority of the proposed trajectory tracking control algorithm over the traditional PID algorithm, the model of industrial robot is established by using the virtual simulation system Adams. At the same time, the model is simulated by joint experiment. Experimental results show that the trajectory control algorithm based on the proposed trajectory control algorithm is effective. This method has good control accuracy and stability.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-020-01693-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-020-01809-2,Adaptive sliding mode control of robot based on fuzzy neural network,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-020-01809-2,Springer,2020-12-01,"The robot is a very complex multi-input multi-output nonlinear system. Due to the inaccuracy of measurement and modeling, coupled with changes in load and the effects of external disturbances, it is virtually impossible to obtain a complete kinetic model. The strong robustness of sliding mode variable structure control makes it particularly suitable for solving the trajectory tracking problem of robots. In this paper, a better real-time adaptive control framework is designed to realize the robust target tracking of mobile robots. Based on the TSK neural network, an efficient control framework combining neural network controller and compensation controller is proposed. Based on the new framework research and improvement of neural network controller, considering the factors of emotional influence decision-making, the existing brain emotional learning neural network is improved and researched, and the brain-emotion learning neural network with radial basis function is proposed. The simulation results show that the trajectory tracking ability, anti-disturbance ability and robustness of the mobile robot are improved to some extent, which verifies the feasibility and efficiency of the proposed control method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-020-01809-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-020-00626-z,Influence of Reaction Time in the Emotional Response of a Companion Robot to a Child’s Aggressive Interaction,International Journal of Social Robotics,10.1007/s12369-020-00626-z,Springer,2020-12-01,"The quality of a companion robot’s reaction is important to make it acceptable to the users and to sustain interactions. Furthermore, the robot’s reaction can be used to train socially acceptable behaviors and to develop certain skills in both normally developing children and children with cognitive disabilities. In this study, we investigate the influence of reaction time in the emotional response of a robot when children display aggressive interactions toward it. Different interactions were considered, namely, pickup, shake, drop and throw. The robot produced responses as audible sounds, which were activated at three different reaction times, namely, 0.5 s, 1.0 s, and 1.5 s. The results for one of the tasks that involved shaking the robotic toys produced a significant difference between the timings tested. This could imply that producing a late response to an action (i.e. greater than 1.0 s) could negatively affect the children’s comprehension of the intended message. Furthermore, the response should be comprehensible to provide a clear message to the user. The results imply that the designers of companion robotic toys need to consider an appropriate timing and clear modality for their robots’ responses.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-020-00626-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-020-01852-z,"Thumbs up, thumbs down: non-verbal human-robot interaction through real-time EMG classification via inductive and supervised transductive transfer learning",Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-020-01852-z,Springer,2020-12-01,"In this study, we present a transfer learning method for gesture classification via an inductive and supervised transductive approach with an electromyographic dataset gathered via the Myo armband. A ternary gesture classification problem is presented by states of ’thumbs up’ , ’thumbs down’ , and ’relax’ in order to communicate in the affirmative or negative in a non-verbal fashion to a machine. Of the nine statistical learning paradigms benchmarked over 10-fold cross validation (with three methods of feature selection), an ensemble of Random Forest and Support Vector Machine through voting achieves the best score of 91.74% with a rule-based feature selection method. When new subjects are considered, this machine learning approach fails to generalise new data, and thus the processes of Inductive and Supervised Transductive Transfer Learning are introduced with a short calibration exercise (15 s). Failure of generalisation shows that 5 s of data per-class is the strongest for classification (versus one through seven seconds) with only an accuracy of 55%, but when a short 5 s per class calibration task is introduced via the suggested transfer method, a Random Forest can then classify unseen data from the calibrated subject at an accuracy of around 97%, outperforming the 83% accuracy boasted by the proprietary Myo system. Finally, a preliminary application is presented through social interaction with a humanoid Pepper robot, where the use of our approach and a most-common-class metaclassifier achieves 100% accuracy for all trials of a ‘20 Questions’ game.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-020-01852-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-020-01815-4,Inverse kinematics solution of Robotics based on neural network algorithms,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-020-01815-4,Springer,2020-12-01,"The rapid development of artificial intelligence technology makes Robotics more intelligent and flexible. In this context, the kinematics inverse algorithm of the Robotics has become the basis and key technology for the further development of the Robotics. The key point of the inverse algorithm of the Robotics is to coordinate the Robotics operation arm with the corresponding action actuator at the end to realize the space attitude control of the Robotics system, and to make a theoretical basis for the motion analysis of the later Robotics. However, the traditional form of Robotics kinematics inverse algorithm avoids a lot of iterative computational solution process, which increases the complexity of the whole algorithm. Therefore, based on the above situation, this paper proposes a Robotics inverse solution algorithm based on improved BP (back propagation) neural network. In this paper, in the application of the actual algorithm, aiming at the convergence problem of the traditional BP neural network algorithm, an improved BP neural network algorithm based on the excitation function is proposed. By selecting the adaptive processing function in each layer of the neural network, the selection is matched with it. The learning rate, thus improving the accuracy of the entire motion inverse algorithm. At the same time, in order to further reduce the calculation of joint quantification, this paper also creatively introduces the algorithm of plane division auxiliary dynamic model construction. The simulation results show that the inverse kinematics algorithm based on improved BP neural network proposed in this paper has obvious advantages in solving the kinematics inverse problem of six-degree-of-freedom Robotics compared with the traditional inverse solution algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-020-01815-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-020-01216-x,A Deep-Learning-based Strategy for Kidnapped Robot Problem in Similar Indoor Environment,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01216-x,Springer,2020-12-01,"We present a deep-learning-based strategy that only uses a 2D LiDAR sensor to solve the kidnapped robot problem in similar indoor environments. First, we converted a set of 2D laser data into an RGB-image and an occupancy grid map and stacked them into a multi-channel image. Then, a neural network structure with five convolutional layers and four fully connected layers was designed to regress the 3-DOF robot pose. Finally, the network was trained using multi-channel images as input. We also improved the network structure to identify the scene where the robot is localized. Extensive experiments have been conducted in practice with a real mobile robot, verifying the effectiveness of the proposed strategy. Our network can obtain approximately 2m and 5^∘ accuracy indoors, and the scene classification accuracy of our network reaches up to 98 % .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-020-01216-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-020-02567-x,Special issue on machine learning for robotics,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-020-02567-x,Springer,2020-12-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-020-02567-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41315-020-00155-y,"Introduction to the focused section on machine learning, estimation and control for intelligent robotics",International Journal of Intelligent Robotics and Applications,10.1007/s41315-020-00155-y,Springer,2020-12-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-020-00155-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-020-02037-4,Multimodal visual image processing of mobile robot in unstructured environment based on semi-supervised multimodal deep network,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-020-02037-4,Springer,2020-12-01,"With the continuous development of computer technology, machine vision and image processing algorithms, people’s research on mobile robots with vision systems is becoming deeper and deeper. This paper studies the related problems of visual image processing of mobile robots in outdoor unstructured environments. In this work, we propose a new approach that integrates heterogeneous features through a well-designed Semi-supervised multimodal deep network (SMMDN). For each modality, there is a multi-layer sub-neural network with a separate structure corresponding to it, which is used to transform features in different modes into the same modal features. At the same time, through a network layer common to all modes above these sub-neural networks, a connection is established between these different modes, and finally a plurality of heterogeneous modes is converted into the same mode and a plurality of them are extracted from fusion characteristics of data modalities. The simulation results prove that SMMDN improves the perception and recognition ability of mobile robots for outdoor complex environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-020-02037-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12541-020-00418-5,A Wearable Soft Robot for Stroke Patients’ Finger Occupational Therapy and Quantitative Measures on the Joint Paralysis,International Journal of Precision Engineering and Manufacturing,10.1007/s12541-020-00418-5,Springer,2020-12-01,"We suggest a wearable soft robot for post-stroke, hemiplegic patients’ finger rehabilitation and quantitative evaluations on the joint paralysis. The device consists of a pair of gloves. One measures finger positions of the normal side, and the other induces symmetric movements on the affected side by pneumatic force. Ten patients at Brunnstrom stage 3 and 4 from a local hospital participated in this study. They performed Rolyan Stacking Cones 10 times with and without the support of the soft robot. We measured subjects’ proximal interphalangeal angles and air pressures in the pneumatic glove during the exercise to monitor grab/release patterns. The soft robot helped open their paralyzed finger joints by more than 50 degrees on average regardless of Brunnstrom stages. We applied pattern recognition methods on the measurement to quantitatively evaluate the subjects. A support vector machine revealed a misclassification rate of 20%, implying that there were a considerable number of overlapping data sets near the boundary between Brunnstrom stages. K-means method with three clusters suggested a new subject group near the support vector machine border. Thus, we conclude that our wearable soft robot not only provides grab/release guides to post-stroke patients but also provides quantitative information on their finger paralysis supplementary to the existing qualitative assessments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12541-020-00418-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13347-020-00415-6,The Whiteness of AI,Philosophy & Technology,10.1007/s13347-020-00415-6,Springer,2020-12-01,"This paper focuses on the fact that AI is predominantly portrayed as white—in colour, ethnicity, or both. We first illustrate the prevalent Whiteness of real and imagined intelligent machines in four categories: humanoid robots, chatbots and virtual assistants, stock images of AI, and portrayals of AI in film and television. We then offer three interpretations of the Whiteness of AI, drawing on critical race theory, particularly the idea of the White racial frame. First, we examine the extent to which this Whiteness might simply reflect the predominantly White milieus from which these artefacts arise. Second, we argue that to imagine machines that are intelligent, professional, or powerful is to imagine White machines because the White racial frame ascribes these attributes predominantly to White people. Third, we argue that AI racialised as White allows for a full erasure of people of colour from the White utopian imaginary. Finally, we examine potential consequences of the racialisation of AI, arguing it could exacerbate bias and misdirect concern.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13347-020-00415-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13164-020-00473-x,Understanding A.I. — Can and Should we Empathize with Robots?,Review of Philosophy and Psychology,10.1007/s13164-020-00473-x,Springer,2020-12-01,"Expanding the debate about empathy with human beings, animals, or fictional characters to include human-robot relationships, this paper proposes two different perspectives from which to assess the scope and limits of empathy with robots: the first is epistemological, while the second is normative. The epistemological approach helps us to clarify whether we can empathize with artificial intelligence or, more precisely, with social robots. The main puzzle here concerns, among other things, exactly what it is that we empathize with if robots do not have emotions or beliefs, since they do not have a consciousness in an elaborate sense. However, by comparing robots with fictional characters, the paper shows that we can still empathize with robots and that many of the existing accounts of empathy and mindreading are compatible with such a view. By so doing, the paper focuses on the significance of perspective-taking and claims that we also ascribe to robots something like a perspectival experience. The normative approach examines the moral impact of empathizing with robots. In this regard, the paper critically discusses three possible responses: strategic, anti-barbarizational, and pragmatist. The latter position is defended by stressing that we are increasingly compelled to interact with robots in a shared world and that to take robots into our moral consideration should be seen as an integral part of our self- and other-understanding.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13164-020-00473-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-020-00982-4,Socially responsive technologies: toward a co-developmental path,AI & SOCIETY,10.1007/s00146-020-00982-4,Springer,2020-12-01,"Robotic and artificially intelligent (AI) systems are becoming prevalent in our day-to-day lives. As human interaction is increasingly replaced by human–computer and human–robot interaction (HCI and HRI), we occasionally speak and act as though we are blaming or praising various technological devices. While such responses may arise naturally, they are still unusual. Indeed, for some authors, it is the programmers or users—and not the system itself—that we properly hold responsible in these cases. Furthermore, some argue that since directing blame or praise at technology itself is unfitting, designing systems in ways that encourage such practices can only exacerbate the problem. On the other hand, there may be good moral reasons to continue engaging in our natural practices, even in cases involving AI systems or robots. In particular, daily interactions with technology may stand to impact the development of our moral practices in human-to-human interactions. In this paper, we put forward an empirically grounded argument in favor of some technologies being designed for social responsiveness. Although our usual practices will likely undergo adjustments in response to innovative technologies, some systems which we encounter can be designed to accommodate our natural moral responses. In short, fostering HCI and HRI that sustains and promotes our natural moral practices calls for a co-developmental process with some AI and robotic technologies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-020-00982-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-020-00977-1,Artificial virtue: the machine question and perceptions of moral character in artificial moral agents,AI & SOCIETY,10.1007/s00146-020-00977-1,Springer,2020-12-01,"Virtue ethics seems to be a promising moral theory for understanding and interpreting the development and behavior of artificial moral agents. Virtuous artificial agents would blur traditional distinctions between different sorts of moral machines and could make a claim to membership in the moral community. Accordingly, we investigate the “machine question” by studying whether virtue or vice can be attributed to artificial intelligence; that is, are people willing to judge machines as possessing moral character? An experiment describes situations where either human or AI agents engage in virtuous or vicious behavior and experiment participants then judge their level of virtue or vice. The scenarios represent different virtue ethics domains of truth, justice, fear, wealth, and honor. Quantitative and qualitative analyses show that moral attributions are weakened for AIs compared to humans, and the reasoning and explanations for the attributions are varied and more complex. On “relational” views of membership in the moral community, virtuous machines would indeed be included, even if they are indeed weakened. Hence, while our moral relationships with artificial agents may be of the same types, they may yet remain substantively different than our relationships to human beings.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-020-00977-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-019-01459-z,Kinematics model identification and motion control of robot based on fast learning neural network,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-019-01459-z,Springer,2020-12-01,"As a static network, the slow learning of back propagation (BP) neural network is an insurmountable disadvantage facing dynamic system identification. In contrast, dynamic neural network provides a potential choice, representing the development direction of neural network modeling, identification and control. Based on dynamic Elman network, a new learning neural network structure, called fast learning neural network, is proposed in this paper. It not only conforms to the basic characteristics of biological neural network, but also has the advantages of simple algorithm, fast learning convergence and high identification accuracy of linear and non-linear systems. Based on the experimental data, this network is applied to the identification of the motion model of modular robots to obtain the non-linear kinematics model of robots. Therefore, this kind of neural network is very suitable for robot kinematics model identification and motion control. The simulation results show that it is appropriate to identify the kinematics model and control the motion of the robot based on fast learning neural network; and the combination of fast learning and ELM network speeds up the training efficiency.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-019-01459-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-020-01242-9,A New Adaptive RISE Feedforward Approach based on Associative Memory Neural Networks for the Control of PKMs,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01242-9,Springer,2020-12-01,"In this paper, a RISE (Robust Integral of the Sign Error) controller with adaptive feedforward compensation terms based on Associative Memory Neural Network (AMNN) type B-Spline is proposed to regulate the positioning of a Delta Parallel Robot (DPR) with three degrees of freedom. Parallel Kinematic Manipulators (PKMs) are highly nonlinear systems, so the design of a suitable control scheme represents a significant challenge given that these kinds of systems are continually dealing with parametric and non-parametric uncertainties and external disturbances. The main contribution of this work is the design of an adaptive feedforward compensation term using B-Spline Neural Networks (BSNNs). They make an on-line approximation of the DPR dynamics and integrates it into the control loop. The BSNNs’ functions are bounded according to the extreme values of the desired joint space trajectories that are the BSNNs’ inputs, and their weights are on-line adjusted by gradient descend rules. In order to evaluate the effectiveness of the proposed control scheme with respect to the standard RISE controller, numerical simulations for different case studies under different scenarios were performed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-020-01242-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-020-01818-w,Light-YOLOv3: fast method for detecting green mangoes in complex scenes using picking robots,Applied Intelligence,10.1007/s10489-020-01818-w,Springer,2020-12-01,"When a robot picks green fruit under natural light, the color of the fruit is similar to the background; uneven lighting and fruit and leaf occlusion often affect the performance of the detection method. We take green mangoes as an experimental object. A lightweight green mangoes detection method based on YOLOv3 is proposed here. To improve the detection speed of the method, we first combine the color, texture, and shape features of green mango to design a lightweight network unit to replace the residual units in YOLOv3. Second, the improved Multiscale context aggregation (MSCA) module is used to concatenate multilayer features and make predictions, solving the problem of insufficient position information and semantic information on the prediction feature map in YOLOv3; this approach effectively improves the detection effect for the green mangoes. To address the overlap of green mangoes, soft non-maximum suppression (Soft-NMS) is used to replace non-maximum suppression (NMS), thereby reducing the missing of predicted boxes due to green mango overlaps. Finally, an auxiliary inspection green mango image enhancement algorithm (CLAHE-Mango) is proposed, is suitable for low-brightness detection environments and improves the accuracy of the green mango detection method. The experimental results show that the F1% of Light-YOLOv3 in the test set is 97.7%. To verify the performance of Light-YOLOv3 under the embedded platform, we embed one-stage methods into the Adreno 640 and Mali-G76 platforms. Compared with YOLOv3, the F1% of Light-YOLOv3 is increased by 4.5%, and the running speed is increased by 5 times, which can meet the real-time running requirements for picking robots. Through three sets of comparative experiments, we could determine that our method has the best detection results in terms of dense, backlit, direct light, night, long distance, and special angle scenes under complex lighting.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-020-01818-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10458-020-09485-4,I2RL: online inverse reinforcement learning under occlusion,Autonomous Agents and Multi-Agent Systems,10.1007/s10458-020-09485-4,Springer,2020-11-05,"Inverse reinforcement learning (IRL) is the problem of learning the preferences of an agent from observing its behavior on a task. It inverts RL which focuses on learning an agent’s behavior on a task based on the reward signals received. IRL is witnessing sustained attention due to promising applications in robotics, computer games, and finance, as well as in other sectors. Methods for IRL have, for the most part, focused on batch settings where the observed agent’s behavioral data has already been collected. However, the related problem of online IRL—where observations are incrementally accrued, yet the real-time demands of the application often prohibit a full rerun of an IRL method—has received significantly less attention. We introduce the first formal framework for online IRL, called incremental IRL (I2RL), which can serve as a common ground for online IRL methods. We demonstrate the usefulness of this framework by casting existing online IRL techniques into this framework. Importantly, we present a new method that advances maximum entropy IRL with hidden variables to the online setting. Our analysis shows that the new method has monotonically improving performance with more demonstration data as well as probabilistically bounded error, both under full and partial observability. Simulated and physical robot experiments in a multi-robot patrolling application situated in varied-sized worlds, which involves learning under high levels of occlusion, show a significantly improved performance of I2RL as compared to both batch IRL and an online imitation learning method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10458-020-09485-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-020-01183-3,Model-Based Reinforcement Learning Variable Impedance Control for Human-Robot Collaboration,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01183-3,Springer,2020-11-01,"Industry 4.0 is taking human-robot collaboration at the center of the production environment. Collaborative robots enhance productivity and flexibility while reducing human’s fatigue and the risk of injuries, exploiting advanced control methodologies. However, there is a lack of real-time model-based controllers accounting for the complex human-robot interaction dynamics. With this aim, this paper proposes a Model-Based Reinforcement Learning (MBRL) variable impedance controller to assist human operators in collaborative tasks. More in details, an ensemble of Artificial Neural Networks (ANNs) is used to learn a human-robot interaction dynamic model, capturing uncertainties. Such a learned model is kept updated during collaborative tasks execution. In addition, the learned model is used by a Model Predictive Controller (MPC) with Cross-Entropy Method (CEM). The aim of the MPC+CEM is to online optimize the stiffness and damping impedance control parameters minimizing the human effort (i.e, minimizing the human-robot interaction forces). The proposed approach has been validated through an experimental procedure. A lifting task has been considered as the reference validation application (weight of the manipulated part: 10 kg unknown to the robot controller). A KUKA LBR iiwa 14 R820 has been used as a test platform. Qualitative performance (i.e, questionnaire on perceived collaboration) have been evaluated. Achieved results have been compared with previous developed offline model-free optimized controllers and with the robot manual guidance controller. The proposed MBRL variable impedance controller shows improved human-robot collaboration. The proposed controller is capable to actively assist the human in the target task, compensating for the unknown part weight. The human-robot interaction dynamic model has been trained with a few initial experiments (30 initial experiments). In addition, the possibility to keep the learning of the human-robot interaction dynamics active allows accounting for the adaptation of human motor system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-020-01183-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-020-01754-9,Content-aware web robot detection,Applied Intelligence,10.1007/s10489-020-01754-9,Springer,2020-11-01,"Web crawlers account for more than a third of the total web traffic and they are threatening the security, privacy and veracity of web applications and their users. Businesses in finance, ticketing, and publishing, as well as websites with rich and unique content are the ones mostly affected by their actions. To deal with this problem, we present a novel web robot detection approach that takes advantage of the content of a website based on the assumption that human web users are interested in specific topics, while web robots crawl the web randomly. Our approach extends the typical user session representation of log-based features with a novel set of features that capture the semantics of the content of the requested resources. In addition, we contribute a new real-world dataset, which we make publicly available, towards alleviating the scarcity of open data in this field. Empirical results on this dataset validate our assumption and show that our approach outranks state-of-the-art methods for web robot detection.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-020-01754-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42235-020-0102-8,Distance-directed Target Searching for a Deep Visual Servo SMA Driven Soft Robot Using Reinforcement Learning,Journal of Bionic Engineering,10.1007/s42235-020-0102-8,Springer,2020-11-01,"Performing complex tasks by soft robots in constrained environment remains an enormous challenge owing to the limitations of flexible mechanisms and control methods. In this paper, a novel biomimetic soft robot driven by Shape Memory Alloy (SMA) with light weight and multi-motion abilities is introduced. We adapt deep learning to perceive irregular targets in an unstructured environment. Aiming at the target searching task, an intelligent visual servo control algorithm based on Q-learning is proposed to generate distance-directed end effector locomotion. In particular, a threshold reward system for the target searching task is proposed to enable a certain degree of tolerance for pointing errors. In addition, the angular velocity and working space of the end effector with load and without load based on the established coupling kinematic model are presented. Our framework enables the trained soft robot to take actions and perform target searching. Realistic experiments under different conditions demonstrate the convergence of the learning process and effectiveness of the proposed algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42235-020-0102-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-020-00642-2,Generating collective foraging behavior for robotic swarm using deep reinforcement learning,Artificial Life and Robotics,10.1007/s10015-020-00642-2,Springer,2020-11-01,"This paper mainly discussed the generation of collective behaviors with raw camera images as the primary information input. The swarm robotic system exhibits considerable advantages when faced with individual-level failure or the lack of global information. Spatial information has always been a necessity in generating collective transport behavior. The rise of deep neural network technology makes it possible for a robot to perceive the environment from its visual input. In this paper, the use of deep reinforcement learning in training a robotic swarm to generate collective foraging behavior is shown. The collective foraging behavior is evaluated in a transportation task, where robots need to learn to process image information while cooperatively transport foods to the nest. We applied a deep Q-Learning algorithm and several improved versions to develop controllers for robotic swarms. The results of computer simulations show that using images as the main information input can successfully generate collective foraging behavior. Besides, we also combine the advantages of several algorithms to improve performance and perform experiments to examine the flexibility of the developed controllers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-020-00642-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10670-020-00331-3,"Robot Ethics 2.0. From Autonomous Cars to Artificial Intelligence—Edited by Patrick Lin, Keith Abney, Ryan Jenkins. New York: Oxford University Press, 2017. Pp xiii + 421",Erkenntnis,10.1007/s10670-020-00331-3,Springer,2020-10-22,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10670-020-00331-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00138-020-01127-9,Learning an end-to-end spatial grasp generation and refinement algorithm from simulation,Machine Vision and Applications,10.1007/s00138-020-01127-9,Springer,2020-10-20,"Novel object grasping is an important technology for robot manipulation in unstructured environments. For most of current works, a grasp sampling process is required to obtain grasp candidates, combined with a local feature extractor using deep learning. However, this pipeline is time–cost, especially when grasp points are sparse such as at the edge of a bowl. To tackle this problem, our algorithm takes the whole sparse point clouds as the input and requires no sampling or search process. Our work is combined with two steps. The first step is to predict poses, categories and scores (qualities) based on a SPH3D-GCN network. The second step is an iterative grasp pose refinement, which is to refine the best grasp generated in the first step. The whole weight sizes for these two steps are only about 0.81M and 0.52M, which takes about 73 ms for a whole prediction process including an iterative grasp pose refinement using a GeForce 840M GPU. Moreover, to generate training data of multi-object scene, a single-object dataset (79 objects from YCB object set, 23.7k grasps) and a multi-object dataset (20k point clouds with annotations and masks) combined with thin structures grasp planning are generated. Our experiment shows our work gets 76.67% success rate and 94.44% completion rate, which performs better than current state-of-the-art works.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00138-020-01127-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40430-020-02652-4,Adaptive trajectory tracking control of a free-flying space robot subject to input nonlinearities,Journal of the Brazilian Society of Mechanical Sciences and Engineering,10.1007/s40430-020-02652-4,Springer,2020-10-14,"The input nonlinearities widely exist in a large range of mechanical systems. Nonetheless, they were relatively less considered in the trajectory tracking control of a space robot in the previous studies. In this paper, an adaptive neural network (NN) control method is proposed for the fast and exact trajectory tracking control of an attitude-controlled free-flying space robot subject to input nonlinearities. The parametric uncertainties and external disturbances are also taken into the consideration. First, a model-based controller is designed to track the desired trajectory of the space robot within a framework of backstepping technique. Then, an adaptive NN controller is designed by using two NNs to compensate for the lumped uncertainties caused by parametric uncertainties and external disturbances and the input nonlinearities, respectively. Rigorous theoretical analysis for the semiglobal uniform ultimate boundedness of the whole closed-loop system is provided. The proposed adaptive NN controller is structurally simple and model-independent, which makes the controller affordable for practical applications. In addition, the proposed adaptive NN controller can guarantee the position and velocity tracking errors converge to the small neighborhoods about zero even in the presence of parametric uncertainties, external disturbances, and input nonlinearities. To the best of the authors’ knowledge, there are really limited existing controllers can achieve such excellent performance in the same conditions. Numerical simulations illustrate the effectiveness and superiority of the proposed control method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40430-020-02652-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-018-3514-1,Control structure for a car-like robot using artificial neural networks and genetic algorithms,Neural Computing and Applications,10.1007/s00521-018-3514-1,Springer,2020-10-01,"The idea of improving human’s life quality by making life more comfortable and easy is nowadays possible using current technologies and techniques to solve complex daily problems. The presented idea in this work proposes a control strategy for autonomous robotic systems, specifically car-like robots. The main objective of this work is the development of a reactive navigation controller by means of obstacles avoidance and position control to reach a desired position in an unknown environment. This research goal was achieved by the integration of potential fields and neuroevolution controllers. The neuro-evolutionary controller was designed using the (NEAT) algorithm “Neuroevolution of Augmented Topologies” and trained using a designed training environment. The methodology used allowed the vehicle to reach a certain level of autonomy, obtaining a stable controller that includes kinematic and dynamic considerations. The obtained results showed significant improvements compared to the comparison work.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-018-3514-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-020-00337-4,A neural network-based approach for variable admittance control in human–robot cooperation: online adjustment of the virtual inertia,Intelligent Service Robotics,10.1007/s11370-020-00337-4,Springer,2020-10-01,"This paper proposes an approach for variable admittance control in human–robot collaboration depending on the online training of neural network. The virtual inertia is an important factor for the system stability, and its tuning is investigated in improving the human–robot cooperation. The design of the variable virtual inertia controller is analyzed, and the choice of the neural network type and their inputs and output is justified. The error backpropagation analysis of the designed system is elaborated since the end-effector velocity error depends indirectly on the multilayer feedforward neural network output. The proposed controller performance is experimentally investigated, and its generalization ability is evaluated by conducting cooperative tasks with the help of multiple subjects using the KUKA LWR manipulator under different conditions and tasks than the ones used for the neural network training. Finally, a comparative study is presented between the proposed method and previous published ones.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-020-00337-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11740-020-00968-7,Reinforcement learning for robotic assembly of fuel cell turbocharger parts with tight tolerances,Production Engineering,10.1007/s11740-020-00968-7,Springer,2020-10-01,"The efficiency of a fuel cell is not only dependent on the stack, but also to a large extent on the turbocharger, which is responsible for providing the required airflow. Since the individual components, especially those of the rotor, are subject to high demands on manufacturing accuracy, it is crucial to ensure a precise and robust assembly. In order to achieve a scalable assembly process, this paper presents a method for a robot-based assembly of the rotationally symmetric components of the rotor. The assembly task has been reduced to the two essential problems: search and insertion. On this basis, a system was developed, which is able to learn the joining process independently and compensate for positioning inaccuracies with the help of reinforcement learning in combination with a position-controlled robot. The applied reinforcement learning strategy is based on the measurement data of a 6-axis force/torque sensor, with which the current contact state can be evaluated and a decision for the next step can be made. The experimental verification shows that an automation of the assembly process is possible with the proposed strategy. The robot is able to perform the search operation successfully, whereas limitations to the achievable accuracies of the insertion process could be found.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11740-020-00968-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11948-020-00238-w,Towards Establishing Criteria for the Ethical Analysis of Artificial Intelligence,Science and Engineering Ethics,10.1007/s11948-020-00238-w,Springer,2020-10-01,"Ethical reflection on Artificial Intelligence (AI) has become a priority. In this article, we propose a methodological model for a comprehensive ethical analysis of some uses of AI, notably as a replacement of human actors in specific activities. We emphasize the need for conceptual clarification of relevant key terms (e.g., intelligence) in order to undertake such reflection. Against that background, we distinguish two levels of ethical analysis, one practical and one theoretical. Focusing on the state of AI at present, we suggest that regardless of the presence of intelligence, the lack of morally relevant features calls for caution when considering the role of AI in some specific human activities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-020-00238-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11948-020-00249-7,Limits of Neural Computation in Humans and Machines,Science and Engineering Ethics,10.1007/s11948-020-00249-7,Springer,2020-10-01,"Aicardi et al. (Ethical and social aspects of neurorobotics, Science and Engineering Ethics, 2020) look to neuroscience to mitigate the limitations of current robotics technology. They propose that robotics technology guided by neuroscience has the capacity to create intelligent robots that function with awareness and capacity for abstraction and reasoning. As neurorobotics extends the capability of robotics technology, it introduces new social and ethical concerns, in particular co-opting civilian applications for military use (dual-use), conflicts between industry and the academy (industry-academy partnerships), and data security (data governance). However, here we argue that empirical evidence has shown that human cognition is faulty; therefore there is not a clear motivation to build intelligent robots on a human model; representation of meaning in the brain is not well-understood; therefore neuro-robotics is limited; and to the extent that intelligent robots become a reality, the ethics of robot rights will be of central concern.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-020-00249-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12204-020-2210-3,Identification and Control of Flexible Joint Robot Using Multi-Time-Scale Neural Network,Journal of Shanghai Jiaotong University (Science),10.1007/s12204-020-2210-3,Springer,2020-10-01,"In this paper, a new identification and control scheme for the flexible joint robotic manipulator is proposed. Firstly, by defining some new state variables, the commonly used dynamic equations of the flexible joint robotic manipulators are transformed into the standard form of a singularly perturbed model. Subsequently, an optimal bounded ellipsoid algorithm based identification scheme using multi-time-scale neural network is proposed to identify the unknown system dynamic equations. Lastly, by using the singular perturbation theory, an indirect adaptive controller based on the identified model is proposed to control the system such that the joint angles can track the given reference signals. The closed-loop stability of the whole system is proved, and the effectiveness of the proposed schemes is verified by simulations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12204-020-2210-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00345-019-03037-6,Artificial intelligence and robotics: a combination that is changing the operating room,World Journal of Urology,10.1007/s00345-019-03037-6,Springer,2020-10-01,"Purpose The aim of the current narrative review was to summarize the available evidence in the literature on artificial intelligence (AI) methods that have been applied during robotic surgery. Methods A narrative review of the literature was performed on MEDLINE/Pubmed and Scopus database on the topics of artificial intelligence, autonomous surgery, machine learning, robotic surgery, and surgical navigation, focusing on articles published between January 2015 and June 2019. All available evidences were analyzed and summarized herein after an interactive peer-review process of the panel. Literature review The preliminary results of the implementation of AI in clinical setting are encouraging. By providing a readout of the full telemetry and a sophisticated viewing console, robot-assisted surgery can be used to study and refine the application of AI in surgical practice. Machine learning approaches strengthen the feedback regarding surgical skills acquisition, efficiency of the surgical process, surgical guidance and prediction of postoperative outcomes. Tension-sensors on the robotic arms and the integration of augmented reality methods can help enhance the surgical experience and monitor organ movements. Conclusions The use of AI in robotic surgery is expected to have a significant impact on future surgical training as well as enhance the surgical experience during a procedure. Both aim to realize precision surgery and thus to increase the quality of the surgical care. Implementation of AI in master–slave robotic surgery may allow for the careful, step-by-step consideration of autonomous robotic surgery.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00345-019-03037-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11948-020-00236-y,Landscape of Machine Implemented Ethics,Science and Engineering Ethics,10.1007/s11948-020-00236-y,Springer,2020-10-01,"This paper surveys the state-of-the-art in machine ethics, that is, considerations of how to implement ethical behaviour in robots, unmanned autonomous vehicles, or software systems. The emphasis is on covering the breadth of ethical theories being considered by implementors, as well as the implementation techniques being used. There is no consensus on which ethical theory is best suited for any particular domain, nor is there any agreement on which technique is best placed to implement a particular theory. Another unresolved problem in these implementations of ethical theories is how to objectively validate the implementations. The paper discusses the dilemmas being used as validating ‘whetstones’ and whether any alternative validation mechanism exists. Finally, it speculates that an intermediate step of creating domain-specific ethics might be a possible stepping stone towards creating machines that exhibit ethical behaviour.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-020-00236-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-020-01202-3,Grasp Pose Detection with Affordance-based Task Constraint Learning in Single-view Point Clouds,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01202-3,Springer,2020-10-01,"Learning to grasp novel objects is a challenging issue for service robots, especially when the robot is performing goal-oriented manipulation or interaction tasks whilst only single-view RGB-D sensor data is available. While some visual approaches focus on grasping that satisfy force-closure standards only, we further link affordances-based task constraints to the grasp pose on object parts, so that both force-closure standard and task constraints can be ensured. In this paper, a new single-view approach is proposed for task-constrained grasp pose detection. We propose to learn a pixel-level affordance detector based on a convolutional neural network. The affordance detector provides a fine grained understanding of the task constraints on objects, which are formulated as a pre-segmentation stage in the grasp pose detection framework. The accuracy and robustness of grasp pose detection are improved by a novel method for calculating local reference frame as well as a position-sensitive fully convolutional neural network for grasp stability classification. Experiments on benchmark datasets have shown that our method outperforms the state-of-the-art methods. We have also validated our method in real-world and task-specific grasping scenes, in which higher success rate for task-oriented grasping is achieved.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-020-01202-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00791-020-00327-0,Parareal with a learned coarse model for robotic manipulation,Computing and Visualization in Science,10.1007/s00791-020-00327-0,Springer,2020-09-23,"A key component of many robotics model-based planning and control algorithms is physics predictions, that is, forecasting a sequence of states given an initial state and a sequence of controls. This process is slow and a major computational bottleneck for robotics planning algorithms. Parallel-in-time integration methods can help to leverage parallel computing to accelerate physics predictions and thus planning. The Parareal algorithm iterates between a coarse serial integrator and a fine parallel integrator. A key challenge is to devise a coarse model that is computationally cheap but accurate enough for Parareal to converge quickly. Here, we investigate the use of a deep neural network physics model as a coarse model for Parareal in the context of robotic manipulation. In simulated experiments using the physics engine Mujoco as fine propagator we show that the learned coarse model leads to faster Parareal convergence than a coarse physics-based model. We further show that the learned coarse model allows to apply Parareal to scenarios with multiple objects, where the physics-based coarse model is not applicable. Finally, we conduct experiments on a real robot and show that Parareal predictions are close to real-world physics predictions for robotic pushing of multiple objects. Code ( https://doi.org/10.5281/zenodo.3779085 ) and videos ( https://youtu.be/wCh2o1rf-gA ) are publicly available.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00791-020-00327-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s40537-020-00341-6,Deep learning-based question answering system for intelligent humanoid robot,Journal of Big Data,10.1186/s40537-020-00341-6,Springer,2020-09-16,"Background The development of Intelligent Humanoid Robot focuses on question answering systems that can interact with people is very limited. In this research, we would like to propose an Intelligent Humanoid Robot with the self-learning capability for accepting and giving responses from people based on Deep Learning and Big Data knowledge base. This kind of robot can be used widely in hotels, universities, and public services. The Humanoid Robot should consider the style of questions and conclude the answer through conversation between robot and user. In our scenario, the robot will detect the user’s face and accept commands from the user to do an action. Findings The question from the user will be processed using deep learning, and the result will be compared to the knowledge base on the system. We proposed our Deep Learning approach, based on Recurrent Neural Network (RNN) encoder, Convolution Neural Network (CNN) encoder, with Bidirectional Attention Flow (BiDAF). Conclusions Our evaluation indicates that using RNN based encoder with BiDAF gives a higher score, than CNN encoder with the BiDAF. Based on our experiment, our model get 82.43% F1 score and the RNN based encoder will give a higher EM/F1 score than using the CNN encoder.",https://www.biomedcentral.com/openurl?doi=10.1186/s40537-020-00341-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s42467-020-00006-3,AI-perspectives: the Turing option,AI Perspectives,10.1186/s42467-020-00006-3,Springer,2020-09-04,This paper presents a perspective on AI that starts with going back to early work on this topic originating in theoretical work of Alan Turing. The argument is made that the core idea - that leads to the title of this paper - of these early thoughts are still relevant today and may actually provide a starting point to make the transition from today functional AI solutions towards integrative or general AI.,http://link.springer.com/openurl/fulltext?id=doi:10.1186/s42467-020-00006-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-020-09915-y,High precision control and deep learning-based corn stand counting algorithms for agricultural robot,Autonomous Robots,10.1007/s10514-020-09915-y,Springer,2020-09-01,"This paper presents high precision control and deep learning-based corn stand counting algorithms for a low-cost, ultra-compact 3D printed and autonomous field robot for agricultural operations. Currently, plant traits, such as emergence rate, biomass, vigor, and stand counting, are measured manually. This is highly labor-intensive and prone to errors. The robot, termed TerraSentia, is designed to automate the measurement of plant traits for efficient phenotyping as an alternative to manual measurements. In this paper, we formulate a Nonlinear Moving Horizon Estimator that identifies key terrain parameters using onboard robot sensors and a learning-based Nonlinear Model Predictive Control that ensures high precision path tracking in the presence of unknown wheel-terrain interaction. Moreover, we develop a machine vision algorithm designed to enable an ultra-compact ground robot to count corn stands by driving through the fields autonomously. The algorithm leverages a deep network to detect corn plants in images, and a visual tracking model to re-identify detected objects at different time steps. We collected data from 53 corn plots in various fields for corn plants around 14 days after emergence (stage V3 - V4). The robot predictions have agreed well with the ground truth with $$C_{robot}=1.02 \times C_{human}-0.86$$ C robot = 1.02 × C human - 0.86 and a correlation coefficient $$R=0.96$$ R = 0.96 . The mean relative error given by the algorithm is $$-3.78\%$$ - 3.78 % , and the standard deviation is $$6.76\%$$ 6.76 % . These results indicate a first and significant step towards autonomous robot-based real-time phenotyping using low-cost, ultra-compact ground robots for corn and potentially other crops.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-020-09915-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-020-03112-3,Teeth infection and fatigue prediction using optimized neural networks and big data analytic tool,Cluster Computing,10.1007/s10586-020-03112-3,Springer,2020-09-01,"Despite the rapid improvement in dental health over the last few decades, a significant portion of our population continue seek dental care every year. Estimates show that 13% of adults seek dental care for dental infection or fatigue within four years. The Social and individual burden of this disease can be reduced by its early detection. However, the symptoms of teeth infection in the early stages are not clear, hence, it would be relatively difficult to predict teeth infections based solely on human skills and experience. Big Data (BD) technologies have a great potential in transforming dental care, as they have revolutionized other industries. In addition to reducing cost, they could save millions of lives and improve patient outcomes. This paper proposes a novel integrated prediction model that extracts hidden knowledge from radiographic datasets containing a large volume of dental X-ray images and utilizes this knowledge to predict dental infections. Initially, preprocessing techniques using morphological skeleton and mean approach is applied to eliminate noise and enhance the images. Next, Multi Scale Segmented Region (MSR) approach, Watershed Approach (WA), Sobel edge Detection (SD), Histogram based Segmentation (HS), Trainable Segmentation (TS), Dual Clustering (DC), and Fuzzy C-Means clustering (FCM) are examined for image segmentation and feature extraction. Among these methods, MSR was selected for feature extraction since it outperformed other methods in terms of accuracy, specificity, precision, recall and F1-score. Then, a set of neural network classifiers are trained to identify patterns in the extracted optimized features and predict dental infections. For this purpose, we have examined Bacterial Optimized Recurrent Neural Networks (BORNN), Deep Learning Neural Networks (DANN), Genetic Optimized Neural Networks (GONN) and Adaptive Neural Networks Algorithm (ADNN). BORNN have shown maximum accuracy and Roc value (98.1% and 0.92 respectively), and minimum error values (MSE = 0.189, MAE = 0.143). The output of the proposed integrated prediction model is fed into a dental robot who proceeds with the treatment process with high accuracy and minimum delay. The proposed prediction model was implemented using a big data analytics tool called Apache SAMOA and experimental results showed its correctness and effectiveness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10586-020-03112-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11548-020-02166-3,Deep learning-based monocular placental pose estimation: towards collaborative robotics in fetoscopy,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-020-02166-3,Springer,2020-09-01,"Purpose Twin-to-twin transfusion syndrome (TTTS) is a placental defect occurring in monochorionic twin pregnancies. It is associated with high risks of fetal loss and perinatal death. Fetoscopic elective laser ablation (ELA) of placental anastomoses has been established as the most effective therapy for TTTS. Current tools and techniques face limitations in case of more complex ELA cases. Visualization of the entire placental surface and vascular equator; maintaining an adequate distance and a close to perpendicular angle between laser fiber and placental surface are central for the effectiveness of laser ablation and procedural success. Robot-assisted technology could address these challenges, offer enhanced dexterity and ultimately improve the safety and effectiveness of the therapeutic procedures. Methods This work proposes a ‘minimal’ robotic TTTS approach whereby rather than deploying a massive and expensive robotic system, a compact instrument is ‘robotised’ and endowed with ‘robotic’ skills so that operators can quickly and efficiently use it. The work reports on automatic placental pose estimation in fetoscopic images. This estimator forms a key building block of a proposed shared-control approach for semi-autonomous fetoscopy. A convolutional neural network (CNN) is trained to predict the relative orientation of the placental surface from a single monocular fetoscope camera image. To overcome the absence of real-life ground-truth placenta pose data, similar to other works in literature (Handa et al. in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2016; Gaidon et al. in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2016; Vercauteren et al. in: Proceedings of the IEEE, 2019) the network is trained with data generated in a simulated environment and an in-silico phantom model. A limited set of coarsely manually labeled samples from real interventions are added to the training dataset to improve domain adaptation. Results The trained network shows promising results on unseen samples from synthetic, phantom and in vivo patient data. The performance of the network for collaborative control purposes was evaluated in a virtual reality simulator in which the virtual flexible distal tip was autonomously controlled by the neural network. Conclusion Improved alignment was established compared to manual operation for this setting, demonstrating the feasibility to incorporate a CNN-based estimator in a real-time shared control scheme for fetoscopic applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-020-02166-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41315-020-00142-3,Real time terrain identification of autonomous robots using machine learning,International Journal of Intelligent Robotics and Applications,10.1007/s41315-020-00142-3,Springer,2020-09-01,"In this project, machine learning based techniques for real time terrain identification of the autonomous robots are investigated. The factors affecting the performance of autonomous robots include nature of trajectories, on-course obstacles, and nature of terrain. The challenges involved in understanding the terrain of autonomous robots are called localization problems. This project investigates a robust classification based machine learning model to identify the terrains of an autonomous robot from a set of input sensor data , which would incorporated as features in the model. The features are selected with respect to the kinematic and dynamic model of differential drive robots. The terrains are classified into 11 classes and the inputs from different sensors are measured and categorized into the respective classes. A total of 49345 readings were taken. Twenty three classification learning methods are evaluated to find the best fitting model that can identify the terrains of robots in real time. Ensemble Subspace KNN classification learning model produced an accuracy of 100 %, observed as the best model for terrain identification. The results are represented using confusion matrix, which shows the relation between original terrains and model predicted terrains , scatter plot that represents the relationship between each features and ROC Curve analyses each sensor input data. The model output can be provided to an intelligent mechanism to control the wheels of robots and improve their performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-020-00142-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10926-020-09888-w,Intelligent Robotics Incorporating Machine Learning Algorithms for Improving Functional Capacity Evaluation and Occupational Rehabilitation,Journal of Occupational Rehabilitation,10.1007/s10926-020-09888-w,Springer,2020-09-01,"Introduction Occupational rehabilitation often involves functional capacity evaluations (FCE) that use simulated work tasks to assess work ability. Currently, there exists no single, streamlined solution to simulate all or a large number of standard work tasks. Such a system would improve FCE and functional rehabilitation through simulating reaching maneuvers and more dexterous functional tasks that are typical of workplace activities. This paper reviews efforts to develop robotic FCE solutions that incorporate machine learning algorithms. Methods We reviewed the literature regarding rehabilitation robotics, with an emphasis on novel techniques incorporating robotics and machine learning into FCE. Results Rehabilitation robotics aims to improve the assessment and rehabilitation of injured workers by providing methods for easily simulating workplace tasks using intelligent robotic systems. Machine learning-based approaches combine the benefits of robotic systems with the expertise and experience of human therapists. These innovations have the potential to improve the quantification of function as well as learn the haptic interactions provided by therapists to assist patients during assessment and rehabilitation. This is done by allowing a robot to learn based on a therapist’s motions (“demonstrations”) what the desired workplace activity (“task”) is and how to recreate it for a worker with an injury (“patient”). Through Telerehabilitation and internet connectivity, these robotic assessment techniques can be used over a distance to reach rural and remote locations. Conclusions While the research is in the early stages, robotics with integrated machine learning algorithms have great potential for improving traditional FCE practice.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10926-020-09888-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42405-020-00254-x,Vision-Based Obstacle Avoidance for UAVs via Imitation Learning with Sequential Neural Networks,International Journal of Aeronautical and Space Sciences,10.1007/s42405-020-00254-x,Springer,2020-09-01,"This paper explores the feasibility of a framework for vision-based obstacle avoidance techniques that can be applied to unmanned aerial vehicles, where such decision-making policies are trained upon supervision of actual human flight data. The neural networks are trained based on aggregated flight data from human experts, learning the implicit policy for visual obstacle avoidance by extracting the necessary features within the image. The images and flight data are collected from a simulated environment provided by Gazebo, and Robot Operating System is used to provide the communication nodes for the framework. The framework is tested and validated in various environments with respect to four types of neural network including fully connected neural networks, two- and three-dimensional convolutional neural networks (CNNs), and recurrent neural networks (RNNs). Among the networks, sequential neural networks (i.e., 3D-CNNs and RNNs) provide the better performance due to its ability to explicitly consider the dynamic nature of the obstacle avoidance problem.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42405-020-00254-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43154-020-00015-4,Human-Robot Interaction in Rehabilitation and Assistance: a Review,Current Robotics Reports,10.1007/s43154-020-00015-4,Springer,2020-09-01,"Purpose of Review Research in assistive and rehabilitation robotics is a growing, promising, and challenging field emerged due to various social and medical needs such as aging populations, neuromuscular, and musculoskeletal disorders. Such robots can be used in various day-to-day scenarios or to support motor functionality, training, and rehabilitation. This paper reflects on the human-robot interaction perspective in rehabilitation and assistive robotics and reports on current issues and developments in the field. Recent Findings The survey on the literature reveals that new efforts are put on utilizing machine learning approaches alongside novel developments in sensing technology to adapt the systems with user routines in terms of activities for assistive systems and exercises for rehabilitation devices to fit each user’s need and maximize their effectiveness. Summary A review of recent research and development efforts on human-robot interaction in assistive and rehabilitation robotics is presented in this paper. First, different subdomains in assistive and rehabilitation robotic research are identified, and accordingly, a survey on the background and trends of such developments is provided.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43154-020-00015-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40998-019-00286-4,Trajectory Tracking Control for Mobile Robots Using Reinforcement Learning and PID,"Iranian Journal of Science and Technology, Transactions of Electrical Engineering",10.1007/s40998-019-00286-4,Springer,2020-09-01,"In this paper, a novel algorithm of trajectory tracking control for mobile robots using the reinforcement learning and PID is proposed. The Q-learning and PID are adopted for tracking the desired trajectory of the mobile robot. The proposed method can reduce the computational complexity of reward function for Q-learning and improve the tracking accuracy of mobile robot. The effectiveness of the proposed algorithm is demonstrated via simulation tests.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40998-019-00286-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43154-020-00013-6,From Humans and Back: a Survey on Using Machine Learning to both Socially Perceive Humans and Explain to Them Robot Behaviours,Current Robotics Reports,10.1007/s43154-020-00013-6,Springer,2020-09-01,"Purpose of Review As intelligent robots enter our daily routine, it is important to be equipped with proper adaptable social perception and explainable behaviours. To do so, machine learning (ML) is often employed. This paper intends to find a trend in the way ML methods are used and applied to model human social perception and produce explainable robot behaviours. Recent Findings The literature has shown a substantial advancement in ML methods with application to social perception and explainable behaviours. There are papers which report models for robots to imitate humans and also for humans to imitate robots. Others use classical methods and propose new and/or improved ones which led to better human-robot interaction performances. Summary This paper reports a review on social perception and explainable behaviours based on ML methods. First, we present literature background on these three research areas and finish with a discussion on limitations and future research venues.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43154-020-00013-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11628-020-00423-8,Impacts of service robots on service quality,Service Business,10.1007/s11628-020-00423-8,Springer,2020-09-01,"With rapid advances in technologies, especially in artificial intelligence, smart sensors, big data analytics, and robotics, the service industry began introducing robots to perform a variety of functions. While the main purpose of deploying robots has been productivity improvement, the current COVID-19 pandemic has brought more urgent purpose, providing contactless service for social distancing. This study explores the service quality provided by robots based on real data in a hotel setting. A sample of 201 guests provided their expected service quality by robots and the actual performance experience after the service. We analyzed this relationship using importance performance analysis (IPA) and the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS). The results revealed that customers’ top priorities for robots’ service quality are assurance and reliability, while tangible and empathy were not as important. Customers were not satisfied with robots’ responsiveness, but this construct was found to be a low priority.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11628-020-00423-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40435-019-00600-2,Adaptive neural network based dynamic surface control for uncertain dual arm robots,International Journal of Dynamics and Control,10.1007/s40435-019-00600-2,Springer,2020-09-01,"The paper discusses an adaptive strategy to effectively control nonlinear manipulation motions of a dual arm robot (DAR) under system uncertainties including parameter variations, actuator nonlinearities and external disturbances. It is proposed that the control scheme is first derived from the dynamic surface control (DSC) method, which allows the robot’s end-effectors to robustly track the desired trajectories. Moreover, since exactly determining the DAR system’s dynamics is impractical due to the system uncertainties, the uncertain system parameters are then proposed to be adaptively estimated by the use of the radial basis function network (RBFN). The adaptation mechanism is derived from the Lyapunov theory, which theoretically guarantees stability of the closed-loop control system. The effectiveness of the proposed RBFN-DSC approach is demonstrated by implementing the algorithm in a synthetic environment with realistic parameters, where the obtained results are highly promising.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40435-019-00600-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-020-04768-z,Distributed fault-tolerant control of modular and reconfigurable robots with consideration of actuator saturation,Neural Computing and Applications,10.1007/s00521-020-04768-z,Springer,2020-09-01,"A novel decomposition-based distributed robust fault-tolerant control method is proposed for modular and reconfigurable robots based on joint torque sensing. The designed robust controller compensates for both model uncertainties and a class of actuator faults. In addition, the proposed scheme does not require a fault detection and diagnosis module, avoiding time delay associated with it. Furthermore, a radial basis function neural network-based compensation scheme is proposed to deal with the actuator saturation problem, which is especially critical when actuator fault has to be tolerated by the control system. Simulation results have shown the effectiveness of the presented method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-020-04768-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-019-0513-7,Adaptive Trajectory Neural Network Tracking Control for Industrial Robot Manipulators with Deadzone Robust Compensator,"International Journal of Control, Automation and Systems",10.1007/s12555-019-0513-7,Springer,2020-09-01,"This paper proposed a novel adaptive tracking neural network with deadzone robust compensator for Industrial Robot Manipulators (IRMs) to achieve the high precision position tracking performance. In order, to deal the uncertainty, the unknown deadzone effect, the unknown dynamics, and disturbances of robot system, the Radial Basis function neural networks (RBFNNs) control is presented to control the joint position and approximate the unknown dynamics of an n-link robot manipulator. The online adaptive control training laws and estimation of the dead-zone are determined by Lyapunov stability and the approximation theory, so that the stability of the entire system and the convergence of the weight adaptation are guaranteed. In this controller, a robust compensator is constructed as an auxiliary controller to guarantee the stability and robustness under various environments such as the mass variation, the external disturbances and modeling uncertainties. The proposed control is the verified on a three-joint robot manipulators via simulations and experiments in comparison with PID and Neural networks (NNs) control.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-019-0513-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41297-020-00109-1,A robot took my job! How STEM education might prepare students for a rapidly changing world,Curriculum Perspectives,10.1007/s41297-020-00109-1,Springer,2020-09-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41297-020-00109-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11548-020-02214-y,Object extraction via deep learning-based marker-free tracking framework of surgical instruments for laparoscope-holder robots,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-020-02214-y,Springer,2020-08-01,"Purpose The surgical instrument tracking framework, especially the marker-free surgical instrument tracking framework, is the key to visual servoing which is applied to achieve active control for laparoscope-holder robots. This paper presented a marker-free surgical instrument tracking framework based on object extraction via deep learning (DL). Methods The surgical instrument joint was defined as the tracking point. Using DL, a segmentation model was trained to extract the end-effector and shaft portions of the surgical instrument in real time. The extracted object was transformed into a distance image by Euclidean Distance Transformation. Next, the points with the maximal pixel value in the two portions were defined as their central points, respectively, and the intersection point of the line connecting the two central points and the plane connecting the two portions was determined as the tracking point. Finally, the object could be fast extracted using the masking method, and the tracking point was fast located frame-by-frame in a laparoscopic video to achieve tracking of surgical instrument. The proposed object extraction via a DL-based marker-free tracking framework was compared with a marker-free tracking-by-detection framework via DL. Results Using seven in vivo laparoscopic videos for experiments, the mean tracking success rate was 100%. The mean tracking accuracy was (3.9 ± 2.4, 4.0 ± 2.5) pixels measured in u and v coordinates of a frame, and the mean tracking speed was 15 fps. Compared to the reported mean tracking accuracy of a marker-free tracking-by-detection framework via DL, the mean tracking accuracy of our proposed tracking framework was improved by 37% and 23%, respectively. Conclusion Accurate and fast tracking of marker-free surgical instruments could be achieved in in vivo laparoscopic videos by using our proposed object extraction via DL-based marker-free tracking framework. This work provided important guiding significance for the application of laparoscope-holder robots in laparoscopic surgeries.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-020-02214-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-019-01106-x,Multi-robot Target Encirclement Control with Collision Avoidance via Deep Reinforcement Learning,Journal of Intelligent & Robotic Systems,10.1007/s10846-019-01106-x,Springer,2020-08-01,"The target encirclement control of multi-robot systems via deep reinforcement learning has been investigated in this paper. Inspired by the encirclement behavior of dolphins to entrap the fishes, the encirclement control is mainly to enforce the robots to achieve a capturing formation pattern around a target, and can be widely applied in many areas such as coverage, patrolling, escorting, etc. Different from traditional methods, we propose a deep reinforcement learning framework for multi-robot target encirclement formation control, combining the advantages of the deep neural network and deterministic policy gradient algorithm, which is free from the complicated work of building the control model and designing the control law. Our method provides a distributed control architecture for each robot in continuous action space, relying only on local teammate information. Besides, the behavioral output at each time step is determined by its own independent network. In addition, both the robots and the moving target can be trained simultaneously. In that way, both cooperation and competition can be contained, and the results validate the effectiveness of the proposed algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-019-01106-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11036-019-01281-z,Artificial Intelligence Clone Generated Content toward Robot Creativity and Machine Mindfulness,Mobile Networks and Applications,10.1007/s11036-019-01281-z,Springer,2020-08-01,"In the project Syntropic Counterpoints, we are using discussions between Artificial Intelligence clones to generate creative content. Nevertheless, our focus is less on content analysis and more on the beauty of creation itself and given context by the machines. We are using a different recurrent neural network (RNN), and collective creativity approaches to support interactions between Artificial Intelligence clones and trigger a humanless creative process which should lead to unsupervised robot creativity. The robots are trained by using the publications of some of the greatest thinkers of their time such as Aristotle, Nietzsche, Machiavelli, SunTzu and confronted with the crucial questions related to humankind such as the understanding of morality, aesthetics, ethnicity, strategy, politics, etc. Throughout this robot-robot interaction model, we are trying to investigate the possibilities and consider limitations of using artificial intelligence in context-based creative processes as well as to raise questions related to potential future phenomena of machine mindfulness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11036-019-01281-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-020-00613-7,Historical and futuristic perspectives of robotics,Artificial Life and Robotics,10.1007/s10015-020-00613-7,Springer,2020-08-01,"According to the progress and applications of robots, we can categorize them into three different generations: industrial robots, autonomous mobile robots, and social robots. At the first section, the significant characteristics, structures, and control methods of industrial robots have been introduced. In the next, autonomous mobile robots, their mobile attributes and the typical navigation methods have been briefly presented. Following that part, we investigate social robots as the third generation of robots. The applications of social robots and their promotion process is also a subject of our study. Finally, try to envisage future trends in the field robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-020-00613-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11684-020-0770-0,Application of artificial intelligence in surgery,Frontiers of Medicine,10.1007/s11684-020-0770-0,Springer,2020-08-01,"Artificial intelligence (AI) is gradually changing the practice of surgery with technological advancements in imaging, navigation, and robotic intervention. In this article, we review the recent successful and influential applications of AI in surgery from preoperative planning and intraoperative guidance to its integration into surgical robots. We conclude this review by summarizing the current state, emerging trends, and major challenges in the future development of AI in surgery.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11684-020-0770-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12195-020-00629-w,"Emerging Technologies for Use in the Study, Diagnosis, and Treatment of Patients with COVID-19",Cellular and Molecular Bioengineering,10.1007/s12195-020-00629-w,Springer,2020-08-01,"Introduction The COVID-19 pandemic has caused an unprecedented health and economic worldwide crisis. Innovative solutions are imperative given limited resources and immediate need for medical supplies, healthcare support and treatments. Aim The purpose of this review is to summarize emerging technologies being implemented in the study, diagnosis, and treatment of COVID-19. Results Key focus areas include the applications of artificial intelligence, the use of Big Data and Internet of Things, the importance of mathematical modeling for predictions, utilization of technology for community screening, the use of nanotechnology for treatment and vaccine development, the utility of telemedicine, the implementation of 3D-printing to manage new demands and the potential of robotics. Conclusion The review concludes by highlighting the need for collaboration in the scientific community with open sharing of knowledge, tools, and expertise.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12195-020-00629-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11684-020-0742-4,Artificial intelligence in gastroenterology: where are we heading?,Frontiers of Medicine,10.1007/s11684-020-0742-4,Springer,2020-08-01,"Artificial intelligence (AI) is coming to medicine in a big wave. From making diagnosis in various medical conditions, following the latest advancements in scientific literature, suggesting appropriate therapies, to predicting prognosis and outcome of diseases and conditions, AI is offering unprecedented possibilities to improve care for patients. Gastroenterology is a field that AI can make a significant impact. This is partly because the diagnosis of gastrointestinal conditions relies a lot on image-based investigations and procedures (endoscopy and radiology). AI-assisted image analysis can make accurate assessment and provide more information than conventional analysis. AI integration of genomic, epigenetic, and metagenomic data may offer new classifications of gastrointestinal cancers and suggest optimal personalized treatments. In managing relapsing and remitting diseases such as inflammatory bowel disease, irritable bowel syndrome, and peptic ulcer bleeding, convoluted neural network may formulate models to predict disease outcome, enhancing treatment efficacy. AI and surgical robots can also assist surgeons in conducting gastrointestinal operations. While the advancement and new opportunities are exciting, the responsibility and liability issues of AI-assisted diagnosis and management need much deliberations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11684-020-0742-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11432-019-2639-6,Learning impedance control of robots with enhanced transient and steady-state control performances,Science China Information Sciences,10.1007/s11432-019-2639-6,Springer,2020-07-24,"This study proposes a learning impedance controller comprising a proportional feedback control term, a composite-learning-based uncertainty estimation term, and a robot-environment interaction control term. The impedance control problem is converted into a particular reference-trajectory tracking problem based on a generated reference trajectory. The proposed controller ensures the exponential convergence of the auxiliary tracking error and the uncertainty estimation error. The interaction control term improves the transient control performance through suppression/encouragement of the incorrect/correct robot movements. The composite-learning update law enhances the transient and steady-state control performances based on the exponential convergence of the uncertainty estimation error and auxiliary tracking error. Finally, the effectiveness and advantages of the proposed impedance controller are validated by theoretical analysis and simulations on a parallel robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11432-019-2639-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-020-00330-x,Correction to: Artificial intelligence with robotics for advanced manufacturing industry using robot-assisted mixed-integer programming model,Intelligent Service Robotics,10.1007/s11370-020-00330-x,Springer,2020-07-20,The original version of this article contains a missing space between the name and middle name of the third author. The correct is: Seifedine Nimer Kadry.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-020-00330-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11548-020-02194-z,Investigating exploration for deep reinforcement learning of concentric tube robot control,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-020-02194-z,Springer,2020-07-01,"Purpose Concentric tube robots are composed of multiple concentric, pre-curved, super-elastic, telescopic tubes that are compliant and have a small diameter suitable for interventions that must be minimally invasive like fetal surgery. Combinations of rotation and extension of the tubes can alter the robot’s shape but the inverse kinematics are complex to model due to the challenge of incorporating friction and other tube interactions or manufacturing imperfections. We propose a model-free reinforcement learning approach to form the inverse kinematics solution and directly obtain a control policy. Method Three exploration strategies are shown for deep deterministic policy gradient with hindsight experience replay for concentric tube robots in simulation environments. The aim is to overcome the joint to Cartesian sampling bias and be scalable with the number of robotic tubes. To compare strategies, evaluation of the trained policy network to selected Cartesian goals and associated errors are analyzed. The learned control policy is demonstrated with trajectory following tasks. Results Separation of extension and rotation joints for Gaussian exploration is required to overcome Cartesian sampling bias. Parameter noise and Ornstein–Uhlenbeck were found to be optimal strategies with less than 1 mm error in all simulation environments. Various trajectories can be followed with the optimal exploration strategy learned policy at high joint extension values. Our inverse kinematics solver in evaluation has 0.44 mm extension and $$0.3^{\circ }$$ 0 . 3 ∘ rotation error. Conclusion We demonstrate the feasibility of effective model-free control for concentric tube robots. Directly using the control policy, arbitrary trajectories can be followed and this is an important step towards overcoming the challenge of concentric tube robot control for clinical use in minimally invasive interventions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-020-02194-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-019-00585-0,Reinforcement Learning Aided Robot-Assisted Navigation: A Utility and RRT Two-Stage Approach,International Journal of Social Robotics,10.1007/s12369-019-00585-0,Springer,2020-07-01,"This work proposes a robot-assisted navigation approach based on user intent adjustment, in the context of robotic walkers. Walkers are prescribed to users with gait disorders so that they can support their body weight on the upper limbs, however, the manipulation of such devices can be cumbersome for some users. Common problems for the users are lack of dexterous upper limb control and visual impairments. These problems can render walkers’ users helpless, making them unable to operate these devices effectively and efficiently. We present a new approach to robot-assisted navigation using a utility decision and safety analysis procedure with user intent adjustments learned by reinforcement learning (RL) and supported on a rapidly-exploring random tree inspired algorithm. The proposed approach offers full control of the assistive platform to the user until obstacles are detected. In dangerous scenarios, corrections are computed in order that the assistive platform avoids collisions and follows social norms, effectively guiding the user through the environment while enforcing safer routes. The experimental validation was carried out in a virtual environment and in a real world scenario using a robotic walker built in our lab (ISR-AIWALKER). Experimental results have shown that the proposed approach provides a reliable solution to the robot-assisted navigation of a robotic walker, in particular the use of utility theory to evaluate candidate motions together with a RL model increases the safety of the user’s navigation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-019-00585-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-019-0197-z,A Neural Network Technique of Compensating for an Inertia Model Error in a Time-delayed Controller for Robot Manipulators,"International Journal of Control, Automation and Systems",10.1007/s12555-019-0197-z,Springer,2020-07-01,"A time-delayed control (TDC) method is known as a simple, robust and non model-based control scheme that requires the fast sampling time, the accurate measurement of joint acceleration signals, and the accuracy of the inertia model of a robot manipulator. Among them, sampling time and acceleration signals are hardware dependent and can be solved. Then a user specified inertia model becomes a key role for the performance of TDC. When the selection of the diagonal element of the inertia matrix of a robot manipulator is used, the ill selection of the constant inertia matrix may lead to the poor tracking performance as well as instability. In addition, an appropriate selection of an inertia matrix for different tasks of the robot is not easy. Therefore, in this paper, an intelligent way of using a neural network is proposed to compensate for the deviation of the constant inertia matrix of a robot manipulator. The role of the neural network is to improve the tracking performance of a robot manipulator by compensating for the deviated error of the inertia matrix while satisfying the stability bound. Simulation studies of a three link robot are presented to confirm the proposal.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-019-0197-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-019-00607-x,A Novel Reinforcement-Based Paradigm for Children to Teach the Humanoid Kaspar Robot,International Journal of Social Robotics,10.1007/s12369-019-00607-x,Springer,2020-07-01,"This paper presents a contribution aiming at testing novel child–robot teaching schemes that could be used in future studies to support the development of social and collaborative skills of children with autism spectrum disorders (ASD). We present a novel experiment where the classical roles are reversed: in this scenario the children are the teachers providing positive or negative reinforcement to the Kaspar robot in order for it to learn arbitrary associations between different toy names and the locations where they are positioned. The objective is to stimulate interaction and collaboration between children while teaching the robot, and also provide them tangible examples to understand that sometimes learning requires several repetitions. To facilitate this game, we developed a reinforcement learning algorithm enabling Kaspar to verbally convey its level of uncertainty during the learning process, so as to better inform the children about the reasons behind its successes and failures. Overall, 30 typically developing (TD) children aged between 7 and 8 (19 girls, 11 boys) and 9 children with ASD performed 25 sessions (16 for TD; 9 for ASD) of the experiment in groups, and managed to teach Kaspar all associations in 2 to 7 trials. During the course of study Kaspar only made rare unexpected associations (2 perseverative errors and 2 win-shifts, within a total of 314 trials), primarily due to exploratory choices, and eventually reached minimal uncertainty. Thus, the robot’s behaviour was clear and consistent for the children, who all expressed enthusiasm in the experiment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-019-00607-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-020-09911-2,Merging of appearance-based place knowledge among multiple robots,Autonomous Robots,10.1007/s10514-020-09911-2,Springer,2020-07-01,"If robots can merge the appearance-based place knowledge of other robots with their own, they can relate to these places even if they have not previously visited them. We have investigated this problem using robots with compatible visual sensing capabilities and with each robot having its individual long-term place memory. Here, each place refers to a spatial region as defined by a collection of appearances and in the place memory, the knowledge is organized in a tree hierarchy. In the proposed merging approach, the hierarchical organization plays a key role—as it corresponds to a nested sequence of hyperspheres in the appearance space. The merging proceeds by considering the extent of overlap of the respective nested hyperspheres—starting with the largest covering hypersphere. Thus, differing from related work, knowledge is merged in as large chunks as possible while the hierarchical structure is preserved accordingly. As such, the merging scales better as the extent of knowledge to be merged increases. This is demonstrated in an extensive set of multirobot experiments where robots share their knowledge and then use their merged knowledge when visiting these places.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-020-09911-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-019-00617-9,A Holistic Approach to Behavior Adaptation for Socially Assistive Robots,International Journal of Social Robotics,10.1007/s12369-019-00617-9,Springer,2020-07-01,"Socially assistive robotics aims at providing users with continuous support and personalized assistance, through appropriate social interactions. The design of robots capable of supporting people in heterogeneous tasks, raises several challenges among which the most relevant are the need to realise intelligent and continuous behaviours, robustness and flexibility of services and, furthermore, the ability to adapt to different contexts and needs. Artificial intelligence plays a key role in realizing cognitive capabilities like e.g., learning, context reasoning or planning that are highly needed in socially assistive robots. The integration of several of such capabilities is an open problem. This paper proposes a novel “cognitive approach” integrating ontology-based knowledge reasoning, automated planning and execution technologies. The core idea is to endow assistive robots with intelligent features in order to reason at different levels of abstraction, understand specific health-related needs and decide how to act in order to perform personalized assistive tasks. The paper presents such a cognitive approach pointing out the contribution of different knowledge contexts and perspectives, presents detailed functioning traces to show adaptation and personalization features, and finally discusses an experimental assessment proving the feasibility of the approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-019-00617-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s40648-020-00174-1,Generalization of movements in quadruped robot locomotion by learning specialized motion data,ROBOMECH Journal,10.1186/s40648-020-00174-1,Springer,2020-06-25,"Machines that are sensitive to environmental fluctuations, such as autonomous and pet robots, are currently in demand, rendering the ability to control huge and complex systems crucial. However, controlling such a system in its entirety using only one control device is difficult; for this purpose, a system must be both diverse and flexible. Herein, we derive and analyze the feature values of robot sensor and actuator data, thereby investigating the role that each feature value plays in robot locomotion. We conduct experiments using a developed quadruped robot from which we acquire multi-point motion information as the movement data; we extract the features of these movement data using an autoencoder. Next, we decompose the movement data into three features and extract various gait patterns. Despite learning only the “walking” movement, the movement patterns of trotting and bounding are also extracted herein, which suggests that movement data obtained via hardware contain various gait patterns. Although the present robot cannot locomote with these movements, this research suggests the possibility of generating unlearned movements.",https://www.biomedcentral.com/openurl?doi=10.1186/s40648-020-00174-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-020-00326-7,Artificial intelligence with robotics for advanced manufacturing industry using robot-assisted mixed-integer programming model,Intelligent Service Robotics,10.1007/s11370-020-00326-7,Springer,2020-06-17,"Digital technologies and artificial intelligence (AI) solutions are growing and changing rapidly and staying at the top are increasingly complicated. Presently, a rapid transformation occurs in advanced manufacturing, the world of innovation, and mass adoption. Robots become even more crucial as now, because they can be connected to the human mind through the machine/brain interface as AI evolves. A significant need to enhance productivity from the manufacturing sector provides the world economy with punishing challenges. The paper addresses the problem in real-world industry applications of the enforcement of an autonomous industrial mobile robot, in all such areas, namely communication, scheduling, mobile robot technology, and planning. The robot-assisted mixed-integer programming model (RA-MIPM) has been proposed for finding the optimal solution for the problem. This paper deals with the issue of the sequence of optimum feeding in a cell with feeders fed by a mobile manipulation arm robot. The efficiency criteria are to reduce the robot’s cumulative travel time in a particular program horizon. Besides, the robot must be designed for production lines to operate within the cell without a lack of feed components.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-020-00326-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-019-01079-x,"Convergence of Machine Learning and Robotics Communication in Collaborative Assembly: Mobility, Connectivity and Future Perspectives",Journal of Intelligent & Robotic Systems,10.1007/s10846-019-01079-x,Springer,2020-06-01,"Collaborative assemblies of robots are promising the next generation of robot applications by ensuring that safe and reliable robots work collectively toward a common goal. To maintain this collaboration and harmony, effective wireless communication technologies are required in order to enable the robots share data and control signals amongst themselves. With the advent of Machine Learning (ML), recent advancements in intelligent techniques for the domain of robot communications have led to improved functionality in robot assemblies, ability to take informed and coordinated decisions, and an overall improvement in efficiency of the entire swarm. This survey is targeted towards a comprehensive study of the convergence of ML and communication for collaborative assemblies of robots operating in the space, on the ground and in underwater environments. We identify the pertinent issues that arise in the case of robot swarms like preventing collisions, keeping connectivity between robots, maintaining the communication quality, and ensuring collaboration between robots. ML techniques that have been applied for improving different criteria such as mobility, connectivity, Quality of Service (QoS) and efficient data collection for energy efficiency are then discussed from the viewpoint of their importance in the case of collaborative robot assemblies. Lastly, the paper also identifies open issues and avenues for future research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-019-01079-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40998-020-00311-x,Correction to: Trajectory Tracking Control for Mobile Robots Using Reinforcement Learning and PID,"Iranian Journal of Science and Technology, Transactions of Electrical Engineering",10.1007/s40998-020-00311-x,Springer,2020-06-01,"In the article “Trajectory Tracking Control for Mobile Robots Using Reinforcement Learning and PID” by Shuti Wang, Xunhe Yin, Peng Li, Mingzhi Zhang and Xin Wang (Iranian Journal of Science and Technology, Transactions of Electrical Engineering. https://doi.org/10.1007/s40998-019-00286-4 ), there is an error in page 5. The erratum is to correct this error.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40998-020-00311-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13748-020-00204-4,Coaching: accelerating reinforcement learning through human-assisted approach,Progress in Artificial Intelligence,10.1007/s13748-020-00204-4,Springer,2020-06-01,"The learning process in reinforcement learning is time-consuming because on early episodes agent relies too much on exploration. The proposed “coaching” approach focused on helping to accelerate learning for the system with a sparse environmental reward setting. This approach works well with linear epsilon-greedy Q-learning with eligibility traces. To coach an agent, an intermediate target is given by a human coach as a sub-goal for the agent to pursue. This sub-goal provides an additional clue that guides the agent toward the actual terminal state. In the coaching phase, the agent pursues an intermediate target with an aggressive policy. The aggressive reward from this intermediate target would not be used to update the state-action value directly but the environmental reward is used. After a small number of coaching episodes, the learning would proceed normally with an $$\epsilon $$ ϵ -greedy policy. In this way, the agent will end up with an optimal policy which is not under influence or supervision of a human coach. The proposed method has been tested on three experimental tasks: mountain car, ball following, and obstacle avoidance. Even with the human coach of various skill levels, the experimental results show that this method could speed up the learning process of an agent in all tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13748-020-00204-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42488-020-00023-1,"AI in operations management: applications, challenges and opportunities","Journal of Data, Information and Management",10.1007/s42488-020-00023-1,Springer,2020-06-01,"We have witnessed unparalleled progress in artificial intelligence (AI) and machine learning (ML) applications in the last two decades. The AI technologies have accelerated advancements in robotics and automation, which have significant implications on almost every aspect of businesses, and especially supply chain operations. Supply chains have widely adopted smart technologies that enable real-time automated data collection, analysis, and prediction. In this study, we review recent applications of AI in operations management (OM) and supply chain management (SCM). Specifically, we consider the innovations in healthcare, manufacturing, and retail operations, since collectively, these three areas represent a majority of the AI innovations in business as well as growing problem areas. We discuss primary challenges and opportunities for utilizing AI in those industries. We also discuss trending research topics with significant value potential in these areas.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42488-020-00023-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-019-00902-1,God-like robots: the semantic overlap between representation of divine and artificial entities,AI & SOCIETY,10.1007/s00146-019-00902-1,Springer,2020-06-01,"Artificial Intelligence and robots share common representations with divine entities (e.g., gods). Artificial Intelligence and robots, similar to divine entities, are conceptualized as non-natural entities with high power over human life. These common representations rely on conceptual semantic proximity at the explicit and implicit level. Artificial intelligence and robots may progressively take a more and more prominent place in our daily environment. Interestingly, in the study of how humans perceive these artificial entities, science has mainly taken an anthropocentric perspective (i.e., how distant from humans are these agents). Considering people’s fears and expectations from robots and artificial intelligence, they tend to be simultaneously afraid and allured to them, much as they would be to the conceptualisations related to the divine entities (e.g., gods). In two experiments, we investigated the proximity of representation between artificial entities (i.e., artificial intelligence and robots), divine entities and natural entities (i.e., humans and other animals) at both an explicit (Study 1) and an implicit level (Study 2). In the first study, participants evaluated these entities explicitly on positive and negative attitudes. Hierarchical clustering analysis showed that participants’ representation of artificial intelligence, robots and divine entities were similar, while the representation of humans tended to be associated with that of animals. In the second study, participants carried out a word/non-word decision task including religious semantic-related words and neutral words after the presentation of a masked prime referring to divine entities, artificial entities and natural entities (or a control prime). Results showed that after divine and artificial entity primes, participants were faster to identify religious words as words compared to neutral words arguing for a semantic activation. We conclude that people make sense of the new entities by relying on already familiar entities and in the case of artificial intelligence and robots, people appear to draw parallels to divine entities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-019-00902-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10710-019-09365-1,Joseph E. Aoun: Robot-proof: higher education at the age of artificial intelligence,Genetic Programming and Evolvable Machines,10.1007/s10710-019-09365-1,Springer,2020-06-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10710-019-09365-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13347-019-00359-6,A Tale of Two Deficits: Causality and Care in Medical AI,Philosophy & Technology,10.1007/s13347-019-00359-6,Springer,2020-06-01,"In this paper, two central questions will be addressed: ought we to implement medical AI technology in the medical domain? If yes, how ought we to implement this technology? I will critically engage with three options that exist with respect to these central questions: the Neo-Luddite option, the Assistive option, and the Substitutive option. I will first address key objections on behalf of the Neo-Luddite option: the Objection from Bias, the Objection from Artificial Autonomy, the Objection from Status Quo, and the Objection from Inscrutability. I will thereafter present the Demographic Trends Argument and the Human Enhancement Argument in support of alternatives to the Neo-Luddite option. In the second half of the paper, I will argue against the Substitutive option and in favour of the Assistive option, given the existence of two chief formal deficits in medical AI technology: the causality deficit and the care deficit.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13347-019-00359-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41315-020-00135-2,A sample efficient model-based deep reinforcement learning algorithm with experience replay for robot manipulation,International Journal of Intelligent Robotics and Applications,10.1007/s41315-020-00135-2,Springer,2020-06-01,"For robot manipulation, reinforcement learning has provided an effective end to end approach in controlling the complicated dynamic system. Model-free reinforcement learning methods ignore the model of system dynamics and are limited to simple behavior control. By contrast, model-based methods can quickly reach optimal trajectory planning by building a dynamic system model. However, it is not easy to build an accurate and efficient system model with high generalization ability, especially when facing complex dynamic system and various manipulation tasks. Furthermore, when the rewards provided by the environment are sparse, the agent will also lose effective guidance and fail to optimize the policy efficiently, which results in considerably decreased sample efficiency. In this paper, a model-based deep reinforcement learning algorithm, in which a deep neural network model is utilized to simulate the system dynamics, is designed for robot manipulation. The proposed deep neural network model is robust enough to deal with complex control tasks and possesses the generalization ability. Moreover, a curiosity-based experience replay method is incorporated to solve the sparse reward problem and improve the sample efficiency in reinforcement learning. The agent who manipulates a robotic hand, will be encouraged to explore optimal trajectories according to the failure experience. Simulation experiment results show great effectiveness of the proposed method. Various manipulation tasks are achieved successfully in such a complex dynamic system and the sample efficiency gets improved even in a sparse reward environment, as the learning time gets reduced considerably.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-020-00135-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-019-01082-2,Towards Skill Transfer via Learning-Based Guidance in Human-Robot Interaction: An Application to Orthopaedic Surgical Drilling Skill,Journal of Intelligent & Robotic Systems,10.1007/s10846-019-01082-2,Springer,2020-06-01,"This paper presents a machine learning-based guidance (LbG) approach for kinesthetic human-robot interaction (HRI) that can be used in virtual training simulations. Demonstrated positional and force skills are learned to both discriminate the skill levels of users and produce LbG forces. Force information is obtained from virtual forces, which developed based on real computed tomography (CT) data, rather than force sensors. A femur bone drilling simulation is developed to provide a practice environment for orthopaedic residents. The residents are provided with haptic feedback that enable them to feel the variable stiffness of bone layers. The X-ray views of the bone are also presented to them for better tracking of a pre-defined path inside the bone. The simulation is capable of planning a drill path, generating X-rays based on user defined orientation, and recording motion data for user assessment and skill modeling. The knowledge of expert surgeons is also incorporated into the simulation to provide LbG forces for improving the unpredictable motions of the residents. To discriminate the skill level of users, machine learning tools are used to develop surgical expert and resident models. In addition, to improve residents performance, the expert HCRF is used to generate adaptive LbG forces regarding the similarities between residents motions and the expert model. Experimental results show that the learning-based approach is able to assess the skill of users and improve residents performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-019-01082-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-019-00891-1,AI and the path to envelopment: knowledge as a first step towards the responsible regulation and use of AI-powered machines,AI & SOCIETY,10.1007/s00146-019-00891-1,Springer,2020-06-01,"With Artificial Intelligence (AI) entering our lives in novel ways—both known and unknown to us—there is both the enhancement of existing ethical issues associated with AI as well as the rise of new ethical issues. There is much focus on opening up the ‘black box’ of modern machine-learning algorithms to understand the reasoning behind their decisions—especially morally salient decisions. However, some applications of AI which are no doubt beneficial to society rely upon these black boxes. Rather than requiring algorithms to be transparent we should focus on constraining AI and those machines powered by AI within microenvironments—both physical and virtual—which allow these machines to realize their function whilst preventing harm to humans. In the field of robotics this is called ‘envelopment’. However, to put an ‘envelope’ around AI-powered machines we need to know some basic things about them which we are often in the dark about. The properties we need to know are the: training data, inputs, functions, outputs, and boundaries. This knowledge is a necessary first step towards the envelopment of AI-powered machines. It is only with this knowledge that we can responsibly regulate, use, and live in a world populated by these machines.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-019-00891-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12124-020-09523-6,The Parasitic Nature of Social AI: Sharing Minds with the Mindless,Integrative Psychological and Behavioral Science,10.1007/s12124-020-09523-6,Springer,2020-06-01,"Can artificial intelligence (AI) develop the potential to be our partner , and will we be as sensitive to its social signals as we are to those of human beings? I examine both of these questions and how cultural psychology might add such questions to its research agenda. There are three areas in which I believe there is a need for both a better understanding and added perspective. First, I will present some important concepts and ideas from the world of AI that might be beneficial for pursuing research topics focused on AI within the cultural psychology research agenda. Second, there are some very interesting questions that must be answered with respect to central notions in cultural psychology as these are tested through human interactions with AI. Third, I claim that social robots are parasitic to deeply ingrained human social behaviour, in the sense that they exploit and feed upon processes and mechanisms that evolved for purposes that were originally completely alien to human-computer interactions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12124-020-09523-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10796-019-09969-z,“Can Computer Based Human-Likeness Endanger Humanness?” – A Philosophical and Ethical Perspective on Digital Assistants Expressing Feelings They Can’t Have”,Information Systems Frontiers,10.1007/s10796-019-09969-z,Springer,2020-06-01,"Digital assistants engage with us with increasingly human-like conversations, including the expression of human emotions with such utterances as “I am sorry…”, “I hope you enjoy…”, “I am grateful…”, or “I regret that… ”. By 2021, digital assistants will outnumber humans. No one seems to stop to ask if creating more digital companions that appear increasingly human is really beneficial to the future of our species. In this essay, we pose the question: “How human should computer-based human-likeness appear?” We rely on the philosophy of humanness and the theory of speech acts to consider the long-term consequences of living with digital creatures that express human-like feelings. We argue that feelings are the very substance of our humanness and therefore are best reserved for human interaction.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10796-019-09969-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11633-019-1206-7,Item Ownership Relationship Semantic Learning Strategy for Personalized Service Robot,International Journal of Automation and Computing,10.1007/s11633-019-1206-7,Springer,2020-06-01,"In order to satisfy the robotic personalized service requirements that can select exclusive items to perform inference and planning according to different service individuals, the service robots need to have the ability to independently obtain the ownership relationship between humans and their carrying items. In this work, we present a novel semantic learning strategy for item ownership. Firstly, a human-carrying-items detection network based on human posture estimation and object detection model is used. Then, the transferred convolutional neural network is used to extract the characteristics of the objects and the back-end classifier to recognize the object instance. At the same time, the face detection and recognition model are used to identify the service individual. Finally, on the basis of the former two, the active learning of ownership items is completed. The experimental results show that the proposed ownership semantic learning strategy can determine the ownership relationship of private goods accurately and efficiently. The solution of this problem can improve the intelligence level of robot life service.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11633-019-1206-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10710-019-09344-6,Genetic programming and evolvable machines at 20,Genetic Programming and Evolvable Machines,10.1007/s10710-019-09344-6,Springer,2020-06-01,"The journal and in particular the resource reviews have been running for 20 years. We summarise the GP literature, including top papers and authors, as seen by users of the genetic programming bibliography. Then revisit our original goals for GPEM book reviews and compare them with what has achieved.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10710-019-09344-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11547-020-01135-9,Artificial intelligence: Who is responsible for the diagnosis?,La radiologia medica,10.1007/s11547-020-01135-9,Springer,2020-06-01,"The aim of the paper is to find an answer to the question “Who or what is responsible for the benefits and harms of using artificial intelligence in radiology?” When human beings make decisions, the action itself is normally connected with a direct responsibility by the agent who generated the action. You have an effect on others, and therefore, you are responsible for what you do and what you decide to do. But if you do not do this yourself, but an artificial intelligence system, it becomes difficult and important to be able to ascribe responsibility when something goes wrong. The manuscript addresses the following statements: (1) using AI, the radiologist is responsible for the diagnosis; (2) radiologists must be trained on the use of AI since they are responsible for the actions of machines; (3) radiologists involved in R&D have the responsibility to guide the respect of rules for a trustworthy AI; (4) radiologist responsibility is at risk of validating the unknown (black box); (5) radiologist decision may be biased by the AI automation; (6)risk of a paradox: increasing AI tools to compensate the lack of radiologists; (7) need of informed consent and quality measures. Future legislation must outline the contours of the professional’s responsibility, with respect to the provision of the service performed autonomously by AI, balancing the professional’s ability to influence and therefore correct the machine, limiting the sphere of autonomy that instead technological evolution would like to recognize to robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11547-020-01135-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-019-01096-w,Visual Positioning of Distant Wall-Climbing Robots Using Convolutional Neural Networks,Journal of Intelligent & Robotic Systems,10.1007/s10846-019-01096-w,Springer,2020-06-01,"Detection of visual markers, such as circular markers or quick response codes, is a commonly used approach to the positioning of wall-climbing robots. However, when the camera is far from the wall-climbing robot (e.g., 20 m), these markers become extremely blurred and difficult to detect. In this paper, a convolutional neural network-based positioning scheme comprised of a global bounding box detector and local wheel detector is proposed. The light-weight local wheel detector can quickly and accurately detect the four wheel points of a distant wall-climbing robot, and the detected wheel points can be used for calculating its position and direction angle. Our wheel detector has a single-frame processing time of 72.2 ms on a CPU and 7.1 ms on a GPU, where the latter meets the real-time positioning requirements of the wall-climbing robot. We also developed an efficient cost function for wheel matching between video frames. Simulation results and multiple test videos confirmed that the proposed cost function can match wheels between video frames perfectly. The high performance of this positioning system indicates that it may be used in a variety of industrial applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-019-01096-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-019-01089-9,A novel Robust Adaptive Control Using RFWNNs and Backstepping for Industrial Robot Manipulators with Dead-Zone,Journal of Intelligent & Robotic Systems,10.1007/s10846-019-01089-9,Springer,2020-06-01,"This paper proposes a novel robust adaptive-backstepping-recurrent-fuzzy-wavelet-neural-networks controller (ABRFWNNs) based on dead zone compensator for Industrial Robot Manipulators (IRMs) in order to improve high correctness of the position tracking control with the presence of the unknown dynamics, and disturbances. To deal on the unknown dynamics of the robot system problems, the proposed controller used recurrent-fuzzy-wavelet-neural-networks (RFWNNs) to approximate the unknown dynamics. The online adaptive control training laws and estimation of the dead-zone are determined by Lyapunov stability theory and the approximation theory. In this method, the robust sliding-mode-control (SMC) is constructed to optimize parameter vectors, solve the approximation error and higher order terms. Therefore, the stability, robustness, and desired tracking performance of ABRFWNNs for IRMs are guaranteed. The simulations and experiments performed on three-link IRMs are provided in comparison with fuzzy-wavelet-neural-networks (FWNNs) and proportional-integral-derivative (PID) to demonstrate the robustness and effectiveness of the ARBFWNNs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-019-01089-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11063-020-10224-9,Task-Independent Spiking Central Pattern Generator: A Learning-Based Approach,Neural Processing Letters,10.1007/s11063-020-10224-9,Springer,2020-06-01,"Legged locomotion is a challenging task in the field of robotics but a rather simple one in nature. This motivates the use of biological methodologies as solutions to this problem. Central pattern generators are neural networks that are thought to be responsible for locomotion in humans and some animal species. As for robotics, many attempts were made to reproduce such systems and use them for a similar goal. One interesting design model is based on spiking neural networks. This model is the main focus of this work, as its contribution is not limited to engineering but also applicable to neuroscience. This paper introduces a new general framework for building central pattern generators that are task-independent, biologically plausible, and rely on learning methods. The abilities and properties of the presented approach are not only evaluated in simulation but also in a robotic experiment. The results are very promising as the used robot was able to perform stable walking at different speeds and to change speed within the same gait cycle.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-020-10224-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-020-00199-8,Real-Time Cloud-Based Load Balance Algorithms and an Analysis,SN Computer Science,10.1007/s42979-020-00199-8,Nature,2020-05-28,"Advancement in communication technologies has also made a positive impact by increase in the computation. Cloud computing is an internet-based computational utility which has reduced the cost of computation and cutting short of larger investments. Cloud is service-oriented architecture with decentralized computation. The SWOT analysis of the cloud computing can be used virtually in every industry to improve the service delivery and improvement; in return, it improves the business. There is a need of a cloud computing system which can use the cloud for the high-performance applications, increased scalability, ability to handle sudden request traffic increase, flexibility to change when applying new topologies, business continuity with complete flexibility, and overall improvement in the cloud system performance. Various load balancing techniques are available in cloud computing which are needed to study for the development of in advent of new emerging technologies like IoT, robotics, and AI.",https://www.nature.com/articles/s42979-020-00199-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10458-020-09459-6,Interactively shaping robot behaviour with unlabeled human instructions,Autonomous Agents and Multi-Agent Systems,10.1007/s10458-020-09459-6,Springer,2020-05-08,"In this paper, we propose a framework that enables a human teacher to shape a robot behaviour by interactively providing it with unlabeled instructions. We ground the meaning of instruction signals in the task-learning process, and use them simultaneously for guiding the latter. We implement our framework as a modular architecture, named TICS (Task-Instruction-Contingency-Shaping) that combines different information sources: a predefined reward function, human evaluative feedback and unlabeled instructions. This approach provides a novel perspective for robotic task learning that lies between Reinforcement Learning and Supervised Learning paradigms. We evaluate our framework both in simulation and with a real robot. The experimental results demonstrate the effectiveness of our framework in accelerating the task-learning process and in reducing the number of required teaching signals.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10458-020-09459-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-019-04306-7,Human–robot collisions detection for safe human–robot interaction using one multi-input–output neural network,Soft Computing,10.1007/s00500-019-04306-7,Springer,2020-05-01,"In this paper, a multilayer feedforward neural network-based approach is proposed for human–robot collision detection taking safety standards into consideration. One multi-output neural network is designed and trained using data from the coupled dynamics of the manipulator with and without external contacts to detect unwanted collisions and to identify the collided link using only the intrinsic joint position and torque sensors of the manipulator. The proposed method is applied to the collaborative robots, which will be very popular in the near future, and is implemented and evaluated in 3D space motion taking into account the effect of the gravity. KUKA LWR manipulator is an example of the collaborative robots, and it is used for doing the experiments. The experimental results prove that the developed system is considerably efficient and very fast in detecting the collisions in the safe region and identifying the collided link along the entire workspace of the three-joint motion of the manipulator. Separate/uncoupled neural networks, one for each joint, are also designed and trained using the same data, and their performance is compared with the coupled one.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-019-04306-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-019-09894-9,On-line object detection: a robotics challenge,Autonomous Robots,10.1007/s10514-019-09894-9,Springer,2020-05-01,"Object detection is a fundamental ability for robots interacting within an environment. While stunningly effective, state-of-the-art deep learning methods require huge amounts of labeled images and hours of training which does not favour such scenarios. This work presents a novel pipeline resulting from integrating (Maiettini et al. in 2017 IEEE-RAS 17th international conference on humanoid robotics (Humanoids), 2017) and (Maiettini et al. in 2018 IEEE/RSJ international conference on intelligent robots and systems (IROS), 2018), which naturally trains a robot to detect novel objects in few seconds. Moreover, we report on an extended empirical evaluation of the learning method, justifying that the proposed hybrid architecture is key in leveraging powerful deep representations while maintaining fast training time of large scale Kernel methods. We validate our approach on the Pascal VOC benchmark (Everingham et al. in Int J Comput Vis 88(2): 303–338, 2010), and on a challenging robotic scenario (iCubWorld Transformations (Pasquale et al. in Rob Auton Syst 112:260–281, 2019). We address real world use-cases and show how to tune the method for different speed/accuracy trades-off. Lastly, we discuss limitations and directions for future development.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-019-09894-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00170-020-05257-2,Grasping pose estimation for SCARA robot based on deep learning of point cloud,The International Journal of Advanced Manufacturing Technology,10.1007/s00170-020-05257-2,Springer,2020-05-01,"With the development of 3D measurement technology, 3D vision sensors and object pose estimation methods have been developed for robotic loading and unloading. In this work, an end-to-end deep learning method on point clouds, PointNetRGPE, is proposed to estimating the grasping pose of SCARA robot. In PointNetRGPE model, the point cloud and class number are fused into a point-class vector, and several PointNet-like networks are used to estimate the robot grasping pose, containing 3D translation and 1D rotation. Considering that rotational symmetry is very common in man-made and industrial environments, a novel architecture is introduced into PointNetRGPE to solve the pose estimation problem with rotational symmetry in the z -axis direction. Additionally, an experimental platform is built containing an industrial robot and a binocular stereo vision system, and a dataset with three subsets is set up. Finally, the PointNetRGPE is tested on the dataset, and the success rates of three subsets are 98.89%, 98.89%, and 94.44% respectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00170-020-05257-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-019-00569-0,Child–Robot Relationship Formation: A Narrative Review of Empirical Research,International Journal of Social Robotics,10.1007/s12369-019-00569-0,Springer,2020-05-01,"This narrative review aimed to elucidate which robot-related characteristics predict relationship formation between typically-developing children and social robots in terms of closeness and trust. Moreover, we wanted to know to what extent relationship formation can be explained by children’s experiential and cognitive states during interaction with a robot. We reviewed 86 journal articles and conference proceedings published between 2000 and 2017. In terms of predictors, robots’ responsiveness and role, as well as strategic and emotional interaction between robot and child, increased closeness between the child and the robot. Findings about whether robot features predict children’s trust in robots were inconsistent. In terms of children’s experiential and cognitive states during interaction with a robot, robot characteristics and interaction styles were associated with two experiential states: engagement and enjoyment/liking. The literature hardly addressed the impact of experiential and cognitive states on closeness and trust. Comparisons of children’s interactions with robots, adults, and objects showed that robots are perceived as neither animate nor inanimate, and that they are entities with whom children will likely form social relationships. Younger children experienced more enjoyment, were less sensitive to a robot’s interaction style, and were more prone to anthropomorphic tendencies and effects than older children. Tailoring a robot’s sex to that of a child mainly appealed to boys.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-019-00569-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11263-019-01239-4,SeDAR: Reading Floorplans Like a Human—Using Deep Learning to Enable Human-Inspired Localisation,International Journal of Computer Vision,10.1007/s11263-019-01239-4,Springer,2020-05-01,"The use of human-level semantic information to aid robotic tasks has recently become an important area for both Computer Vision and Robotics. This has been enabled by advances in Deep Learning that allow consistent and robust semantic understanding. Leveraging this semantic vision of the world has allowed human-level understanding to naturally emerge from many different approaches. Particularly, the use of semantic information to aid in localisation and reconstruction has been at the forefront of both fields. Like robots, humans also require the ability to localise within a structure. To aid this, humans have designed high-level semantic maps of our structures called floorplans. We are extremely good at localising in them, even with limited access to the depth information used by robots. This is because we focus on the distribution of semantic elements, rather than geometric ones. Evidence of this is that humans are normally able to localise in a floorplan that has not been scaled properly. In order to grant this ability to robots, it is necessary to use localisation approaches that leverage the same semantic information humans use. In this paper, we present a novel method for semantically enabled global localisation. Our approach relies on the semantic labels present in the floorplan. Deep Learning is leveraged to extract semantic labels from RGB images, which are compared to the floorplan for localisation. While our approach is able to use range measurements if available, we demonstrate that they are unnecessary as we can achieve results comparable to state-of-the-art without them.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11263-019-01239-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12541-020-00315-x,Robotic Curved Surface Tracking with a Neural Network for Angle Identification and Constant Force Control based on Reinforcement Learning,International Journal of Precision Engineering and Manufacturing,10.1007/s12541-020-00315-x,Springer,2020-05-01,"Aiming to solve the problem that the contact force at a robot end effector when tracking an unknown curved-surface workpiece is difficult to keep constant, a robot force control algorithm based on reinforcement learning is proposed. In this paper, a contact model and force mapping relationship are established for a robot end effector and surface. For the problem that the tangential angle of the workpiece surface is difficult to obtain in the mapping relationship, a neural network is used to identify the tangential angle of the unknown curved-surface workpiece. To keep the normal force of the robot end effector constant, a compensation term is added to a traditional explicit force controller to adapt to the robot constant force tracking scenario. For the problem that the compensation term parameters are difficult to select, the reinforcement learning algorithm A2C (advantage actor critic) is used to find the optimal parameters, and the return function and state values are modified in the A2C algorithm to satisfy the robot tracking scenario. The results show that the neural network algorithm has a good recognition effect on the tangential angle of the curved surface. The force error between the normal force and the expected force is substantially within ± 2 N after 60 iterations of the robot force control algorithm based on A2C; additionally, the variance of the force error decreases by 50.7%, 34.05% and 79.41%, respectively, compared with the force signals obtained by a fuzzy iterative algorithm and an explicit force control with two sets of fixed control parameters.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12541-020-00315-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-019-01083-1,A Robust Model Predictive Control Strategy for Trajectory Tracking of Omni-directional Mobile Robots,Journal of Intelligent & Robotic Systems,10.1007/s10846-019-01083-1,Springer,2020-05-01,"This paper proposes a robust model predictive control (MPC) strategy for the trajectory tracking control of a four-mecanum-wheeled omni-directional mobile robot (FM-OMR) under various constraints. The method proposed in this paper can solve various constraints while implementing trajectory tracking of the FM-OMR. Firstly, a kinematics model with constraint relationship of the FM-OMR is established. On the basis of the kinematics model, the kinematics trajectory tracking error model of the FM-OMR is further formulated. Then, it is transformed into a constrained quadratic programming(QP) problem by the method of MPC. In addition, aiming at the speed deficiencies of conventional neural networks in QP solving, a delayed neural network (DNN) is applied to solve the optimal solution of the QP problem, and compared with the Lagrange programming neural network (LPNN) to show the rapidity of the DNN. Finally, two simulation cases considering bounded random disturbance are provided to verify the robustness and effectiveness of the proposed method. Theoretical analysis and simulation results show that the control strategy is effective and feasible.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-019-01083-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s12984-020-00687-1,Online compensation detecting for real-time reduction of compensatory motions during reaching: a pilot study with stroke survivors,Journal of NeuroEngineering and Rehabilitation,10.1186/s12984-020-00687-1,BioMed Central,2020-04-28,"Background Compensations are commonly observed in patients with stroke when they engage in reaching without supervision; these behaviors may be detrimental to long-term functional improvement. Automatic detection and reduction of compensation cab help patients perform tasks correctly and promote better upper extremity recovery. Objective Our first objective is to verify the feasibility of detecting compensation online using machine learning methods and pressure distribution data. Second objective was to investigate whether compensations of stroke survivors can be reduced by audiovisual or force feedback. The third objective was to compare the effectiveness of audiovisual and force feedback in reducing compensation. Methods Eight patients with stroke performed reaching tasks while pressure distribution data were recorded. Both the offline and online recognition accuracy were investigated to assess the feasibility of applying a support vector machine (SVM) based compensation detection system. During reduction of compensation, audiovisual feedback was delivered using virtual reality technology, and force feedback was delivered through a rehabilitation robot. Results Good classification performance was obtained in online compensation recognition, with an average F1-score of over 0.95. Based on accurate online detection, real-time feedback significantly decreased compensations of patients with stroke in comparison with no-feedback condition ( p  < 0.001). Meanwhile, the difference between audiovisual and force feedback was also significant ( p  < 0.001) and force feedback was more effective in reducing compensation in patients with stroke. Conclusions Accurate online recognition validated the feasibility of monitoring compensations using machine learning algorithms and pressure distribution data. Reliable online detection also paved the way for reducing compensations by providing feedback to patients with stroke. Our findings suggested that real-time feedback could be an effective approach to reducing compensatory patterns and force feedback demonstrated a more enviable potential compared with audiovisual feedback.",https://www.biomedcentral.com/openurl?doi=10.1186/s12984-020-00687-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-020-08684-1,An anomaly detection method using deep convolution neural network for vision image of robot,Multimedia Tools and Applications,10.1007/s11042-020-08684-1,Springer,2020-04-01,"With the acceleration of urbanization, growing number of places are crowded with people, such as banks, shopping malls, schools and hospitals, and the incidence of abnormal events such as assault, fighting, trampling and evacuation is also increasing. Therefore, the need for intelligent detection and identification of abnormal events by security early warning robots is attracting much more attention. Aiming at the problem of anomaly detection for security early warning robots, an anomaly detection method using wireless vision sensor network (WVSN) and deep learning is proposed. Firstly, image collection is carried out by WVSN, and video image information in the monitoring range is transmitted and stored by WVSN. Then, the collected image is preprocessed, and the possible abnormal areas are effectively extracted by region of interest (ROI), image filtering and region segmentation. Finally, the abnormal areas are extracted by WVSN. The slow feature analysis (SFA) is used to solve the problem of insufficient training samples in the deep neural network. Furthermore, the deep convolution neural network (CNN) and the support vector machine (SVM) are used to train and complete the classification respectively. The experimental results on UMN and PETS 2009 database show that the abnormal events can be effectively detected by the proposed method. Compared with several other advanced methods, the proposed method has higher detection accuracy and area under the curve (AUC). Among them, AUC on the experimental data set can reach up to 0.998. Therefore, the proposed method has a good reference value for the application of security early warning robots in densely populated places.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11042-020-08684-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-019-04567-1,Research on motion pattern recognition of exoskeleton robot based on multimodal machine learning model,Neural Computing and Applications,10.1007/s00521-019-04567-1,Springer,2020-04-01,"Exoskeleton as a real-time interaction with the wearer’s intelligent robot, in recent years, becomes a hot topic mouth class research in the field of robotics. Wearable exoskeleton outside the body, combined with the organic body, plays a role in the protection and support. By wearing an exoskeleton robot, it is possible to expand the wearer’s athletic ability, increase muscle endurance, and enable the wearer to complete tasks that he or she cannot perform under natural conditions. Based on the above advantages, the exoskeleton robot in military medical care and rehabilitation has broad application prospects. This paper describes the multimodal model of machine learning research status and research significance of the text on the exoskeleton robot applications, and on the basis of a detailed study of gait. It mainly involves: analysis and planning and obtaining motion information processing, pattern recognition and analysis of gait and the gait conversion process, and the EEG and joint position, foot pressure, such as different modes of data as input to machine learning models to improve the timeliness, accuracy and safety of gait planning. Since the common movement process involves the transformation process of gait, this paper studies the gait transformation process including squatting, walking on the ground and standing.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-019-04567-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40032-019-00539-5,Inverse Kinematics for A 3-R Robot Using Artificial Neural Network and Modified Particle Swarm Optimization,Journal of The Institution of Engineers (India): Series C,10.1007/s40032-019-00539-5,Springer,2020-04-01,"As the calculation of the exact position and orientation of the end effector of robot manipulator is mandatory to obtain inverse kinematics solution, an artificial neural network is used to obtain inverse kinematics as it reduces the computational time as well as complexity associated. The backpropagation algorithm that is generally used for updating weights and biases requires the sensitivity function of the system which is sometimes difficult to obtain. Here, training of neural network means optimizing the parameters of neural network, i.e. weights and biases, for which particle swarm optimization (PSO) is used. PSO is suitable for learning neural network as it does not require the derivative of an objective function. In this work, the parameters of neural networks, i.e. weights and biases, are optimized using three different optimization algorithms, i.e. PSO, segmented particle swarm optimization (SPSO) and modified segmented particle swarm optimization (MSPSO), and their results are then compared. Further, a comparison has been made on the basis of two parameters, i.e. fitness function and regression, and MSPSO is found to perform better than the other two optimization algorithms. Fitness function value obtained using MSPSO is 6.18e−09, using SPSO is 1.1e−05 and using PSO is 2.35e−03.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40032-019-00539-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-019-00300-y,Design of a robust adaptive sliding mode control using recurrent fuzzy wavelet functional link neural networks for industrial robot manipulator with dead zone,Intelligent Service Robotics,10.1007/s11370-019-00300-y,Springer,2020-04-01,"This paper addresses the problem of trajectory tracking control for industrial robot manipulators (IRMs) in the presence of external disturbances and uncertain dynamics. A novel robust adaptive recurrent fuzzy wavelet functional link neural network (RFWFLNN) controller based on dead-zone compensator is proposed in order to improve the position tracking performance. To handle the unknown dynamics of the IRMs, the robust adaptive RFWFLNNs are applied to approximate the unknown dynamics. The online learning laws and estimation of the dead zone are determined by using Lyapunov stability theory and the approximation theory. In addition, the robust SMC is applied to eliminate the estimation errors and disturbances of the IRM control system. Therefore, the RFWFLNN controller for IRMs can guarantee not only the robustness and stability but also the position tracking performance. Some simulations and experiments performed on three-link IRMs are provided to prove the robustness and effectiveness of the RFWFLNNs. The superiority of the RFWFLNN controller is also demonstrated based on comparisons with fuzzy wavelet neural networks and PID controllers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-019-00300-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-019-01072-4,Cleaning Tasks Knowledge Transfer Between Heterogeneous Robots: a Deep Learning Approach,Journal of Intelligent & Robotic Systems,10.1007/s10846-019-01072-4,Springer,2020-04-01,"Nowadays, autonomous service robots are becoming an important topic in robotic research. Differently from typical industrial scenarios, with highly controlled environments, service robots must show an additional robustness to task perturbations and changes in the characteristics of their sensory feedback. In this paper, a robot is taught to perform two different cleaning tasks over a table, using a learning from demonstration paradigm. However, differently from other approaches, a convolutional neural network is used to generalize the demonstrations to different, not yet seen dirt or stain patterns on the same table using only visual feedback, and to perform cleaning movements accordingly. Robustness to robot posture and illumination changes is achieved using data augmentation techniques and camera images transformation. This robustness allows the transfer of knowledge regarding execution of cleaning tasks between heterogeneous robots operating in different environmental settings. To demonstrate the viability of the proposed approach, a network trained in Lisbon to perform cleaning tasks, using the iCub robot, is successfully employed by the DoRo robot in Peccioli, Italy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-019-01072-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-018-3714-8,Decentralized robust optimal control for modular robot manipulators via critic-identifier structure-based adaptive dynamic programming,Neural Computing and Applications,10.1007/s00521-018-3714-8,Springer,2020-04-01,"This paper presents a decentralized robust optimal control method for modular robot manipulators (MRMs) via a critic-identifier structure-based adaptive dynamic programming (ADP) scheme. The robust control problem of MRMs is transformed into an optimal compensation control issue, which consists of model-based compensation control, identifier-based learning control and ADP-based optimal control. The dynamic model of MRMs is deployed for each joint module where the local dynamic information is utilized to design the model compensation controller. A neural network (NN) identifier is established to approximate the interconnected dynamic coupling. Based on ADP and local online policy iteration algorithm, the Hamiltonian–Jacobi–Bellman equation is solved by constructing a critic NN, and then the approximate optimal control policy derivation is possible. The closed-loop robotic system is asymptotic stable by the implementation of a set of developed decentralized control policies. Simulations are presented to demonstrate the effectiveness of the proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-018-3714-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-018-3842-1,Trajectory tracking using artificial neural network for stable human-like gait with upper body motion,Neural Computing and Applications,10.1007/s00521-018-3842-1,Springer,2020-04-01,"This paper presents a trajectory generation algorithm for robots which can walk like human with movable foot and active toe. The proposed algorithm allows smooth transition between walking phases namely, single and double support phases. A neural network approach is used for solving inverse kinematics so that the biped robot follows the ankle and hip trajectories to walk. Zero moment point (ZMP) stability is ensured by taking into account the upper body movements along with the planned motion trajectories. Here, we analyze the effect of lateral upper body motion on ZMP stability. Different types of trajectories for upper body are generated, and the one which ensured the most stable locomotion is identified.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-018-3842-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s13690-020-00409-y,The CARESSES study protocol: testing and evaluating culturally competent socially assistive robots among older adults residing in long term care homes through a controlled experimental trial,Archives of Public Health,10.1186/s13690-020-00409-y,BioMed Central,2020-03-20,"Background This article describes the design of an intervention study that focuses on whether and to what degree culturally competent social robots can improve health and well-being related outcomes among older adults residing long-term care homes. The trial forms the final stage of the international, multidisciplinary CARESSES project aimed at designing, developing and evaluating culturally competent robots that can assist older people according to the culture of the individual they are supporting. The importance of cultural competence has been demonstrated in previous nursing literature to be key towards improving health outcomes among patients. Method This study employed a mixed-method, single-blind, parallel-group controlled before-and-after experimental trial design that took place in England and Japan. It aimed to recruit 45 residents of long-term care homes aged ≥65 years, possess sufficient cognitive and physical health and who self-identify with the English, Indian or Japanese culture ( n  = 15 each). Participants were allocated to either the experimental group, control group 1 or control group 2 (all n = 15). Those allocated to the experimental group or control group 1 received a Pepper robot programmed with the CARESSES culturally competent artificial intelligence (experimental group) or a limited version of this software (control group 1) for 18 h across 2 weeks. Participants in control group 2 did not receive a robot and continued to receive care as usual. Participants could also nominate their informal carer(s) to participate. Quantitative data collection occurred at baseline, after 1 week of use, and after 2 weeks of use with the latter time-point also including qualitative semi-structured interviews that explored their experience and perceptions further. Quantitative outcomes of interest included perceptions of robotic cultural competence, health-related quality of life, loneliness, user satisfaction, attitudes towards robots and caregiver burden. Discussion This trial adds to the current preliminary and limited pool of evidence regarding the benefits of socially assistive robots for older adults which to date indicates considerable potential for improving outcomes. It is the first to assess whether and to what extent cultural competence carries importance in generating improvements to well-being. Trial registration Name of the registry: ClinicalTrials.gov Trial registration number: NCT03756194 . Date of registration: 28 November 2018. URL of trial registry record.",https://www.biomedcentral.com/openurl?doi=10.1186/s13690-020-00409-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41315-019-00114-2,An educational Arduino robot for visual Deep Learning experiments,International Journal of Intelligent Robotics and Applications,10.1007/s41315-019-00114-2,Springer,2020-03-01,"Deep Learning methods are gaining popularity with both academy and industry. We are in dire need of student affordable educational platform that can support doing Deep Learning experiments. In this paper, we present a mobile robot platform based on Arduino for educational experiments in visual Deep Learning. The educational robot uses Arduino open-source hardware and supports various programming interfaces, including C/C++, Python and Matlab. The robot uses an attached android mobile phone to capture images and video streams. Visual Deep Learning models such as DNNs and CNNs can be examined and practiced with the robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-019-00114-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-019-09871-2,Hierarchical reinforcement learning via dynamic subspace search for multi-agent planning,Autonomous Robots,10.1007/s10514-019-09871-2,Springer,2020-03-01,"We consider scenarios where a swarm of unmanned vehicles (UxVs) seek to satisfy a number of diverse, spatially distributed objectives. The UxVs strive to determine an efficient plan to service the objectives while operating in a coordinated fashion. We focus on developing autonomous high-level planning, where low-level controls are leveraged from previous work in distributed motion, target tracking, localization, and communication. We rely on the use of state and action abstractions in a Markov decision processes framework to introduce a hierarchical algorithm, Dynamic Domain Reduction for Multi-Agent Planning , that enables multi-agent planning for large multi-objective environments. Our analysis establishes the correctness of our search procedure within specific subsets of the environments, termed ‘sub-environment’ and characterizes the algorithm performance with respect to the optimal trajectories in single-agent and sequential multi-agent deployment scenarios using tools from submodularity. Simulated results show significant improvement over using a standard Monte Carlo tree search in an environment with large state and action spaces.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-019-09871-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-019-00880-4,Artificial intelligence: consciousness and conscience,AI & SOCIETY,10.1007/s00146-019-00880-4,Springer,2020-03-01,"Our society is in the middle of the AI revolution. We discuss several applications of AI, in particular medical causality, where deep-learning neural networks screen through big data bases, extracting associations between a patient’s condition and possible causes. While beneficial in medicine, several questionable AI trading strategies have emerged in finance. Though advantages in many aspects of our lives, serious threats of AI exist. We suggest several regulatory measures to reduce these threats. We further discuss whether ‘full AI robots’ should be programmed with a virtual consciousness and conscience. While this would reduce AI threats via motivational control, other threats such as the desire for AI—human socioeconomic equality could prove detrimental.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-019-00880-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11002-019-09499-3,Speciesism: an obstacle to AI and robot adoption,Marketing Letters,10.1007/s11002-019-09499-3,Springer,2020-03-01,"Once artificial intelligence (AI) is indistinguishable from human intelligence, and robots are highly similar in appearance and behavior to humans, there should be no reason to treat AI and robots differently from humans. However, even perfect AI and robots may still be subject to a bias (referred to as speciesism in this article ) , which will disadvantage them and be a barrier to their commercial adoption as chatbots, decision and recommendation systems, and staff in retail and service settings. The author calls for future research that determines causes and psychological consequences of speciesism, assesses the effect of speciesism on the adoption of new products and technologies, and identifies ways to overcome it.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11002-019-09499-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41315-020-00116-5,Modelling of a robot-arm for training in fencing sport,International Journal of Intelligent Robotics and Applications,10.1007/s41315-020-00116-5,Springer,2020-03-01,"Robots have several applications in different fields of nowadays life as in sports training-assistance. One of these sports is Fencing that is an individual duel Olympic sport using a bladed weapon. A typical fencer’s training consists of practicing different techniques. This practice is achieved through three training approaches that are not best utilized due to some constraints referred to humans’ nature and capabilities. The aim of this paper is to develop a robot-arm to be used in fencing training to overcome these constraints. This paper introduces a system for modelling fencing robot-arms using a fast and low-cost approach. The system estimates the angles values needed to drive a six degrees-of-freedom robot-arm that mimics a human-arm performing determined fencing movements. A simple and inexpensive system (Kinect) is applied for capturing the motions of the task and an Artificial Neural Networks model is used for transforming the captured motions into robot-arm movements through an inverse kinematics study. The proposed system was verified and validated, while the caused irregularities were referred to the changes in the lengths of the captured arm-segments and to the random error resulting from the depth measurement by Kinect using a single sensing camera.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-020-00116-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00354-019-00084-w,Neuro-SERKET: Development of Integrative Cognitive System Through the Composition of Deep Probabilistic Generative Models,New Generation Computing,10.1007/s00354-019-00084-w,Springer,2020-03-01,"This paper describes a framework for the development of an integrative cognitive system based on probabilistic generative models (PGMs) called Neuro-SERKET. Neuro-SERKET is an extension of SERKET, which can compose elemental PGMs developed in a distributed manner and provide a scheme that allows the composed PGMs to learn throughout the system in an unsupervised way. In addition to the head-to-tail connection supported by SERKET, Neuro-SERKET supports tail-to-tail and head-to-head connections, as well as neural network-based modules, i.e., deep generative models. As an example of a Neuro-SERKET application, an integrative model was developed by composing a variational autoencoder (VAE), a Gaussian mixture model (GMM), latent Dirichlet allocation (LDA), and automatic speech recognition (ASR). The model is called VAE + GMM + LDA + ASR. The performance of VAE + GMM + LDA + ASR and the validity of Neuro-SERKET were demonstrated through a multimodal categorization task using image data and a speech signal of numerical digits.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00354-019-00084-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-019-00879-x,The future of war: could lethal autonomous weapons make conflict more ethical?,AI & SOCIETY,10.1007/s00146-019-00879-x,Springer,2020-03-01,"Lethal Autonomous Weapons (LAWs) are robotic weapon systems, primarily of value to the military, that could engage in offensive or defensive actions without human intervention. This paper assesses and engages the current arguments for and against the use of LAWs through the lens of achieving more ethical warfare. Specific interest is given particularly to ethical LAWs, which are artificially intelligent weapon systems that make decisions within the bounds of their ethics-based code. To ensure that a wide, but not exhaustive, survey of the implications of employing such ethical devices to replace humans in warfare is taken into account, this paper will engage on matters related to current scholarship on the rejection or acceptance of LAWs—including contemporary technological shortcomings of LAWs to differentiate between targets and the behavioral and psychological volatility of humans—and current and proposed regulatory infrastructures for developing and using such devices. After careful consideration of these factors, this paper will conclude that only ethical LAWs should be used to replace human involvement in war, and, by extension of their consistent abilities, should remove humans from war until a more formidable discovery is made in conducting ethical warfare.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-019-00879-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-019-01008-y,Adaptive Neural Network Control of Underwater Robotic Manipulators Tuned by a Genetic Algorithm,Journal of Intelligent & Robotic Systems,10.1007/s10846-019-01008-y,Springer,2020-03-01,"This paper describes a novel approach for the control of underwater robots that can handle uncertainties and disturbance problems, which are commonly met in underwater environments. The considered system is an underwater manipulator with n -degrees of freedom. The approximation capability of an adaptive neural network is exploited to estimate uncertainties in system dynamics. Drag and lift forces are considered as an external disturbance, and a disturbance observer approach which has been proved to be effective with on-land robotic systems, is applied to compensate for it. The objective of the controller designed is to track a desired trajectory. To find the optimal gain parameters of this controller, a classical Genetic Algorithm is employed. Extensive simulation studies carried out on a two degrees of freedom manipulator indicate the efficacy of the proposed approach, proving that the disturbance observer originally developed for on-land systems can also be used effectively for underwater robotic systems. Finally, the performance of the proposed controller, tuned by the Genetic Algorithm is compared with that of a controller, tuned manually. The results show that the reliance on a well-known classic Genetic Algorithm for the tuning of the controller parameters not only saves time, but also provides better values of the parameters.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-019-01008-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-019-00877-z,The role of robotics and AI in technologically mediated human evolution: a constructive proposal,AI & SOCIETY,10.1007/s00146-019-00877-z,Springer,2020-03-01,"This paper proposes that existing computational modeling research programs may be combined into platforms for the information of public policy. The main idea is that computational models at select levels of organization may be integrated in natural terms describing biological cognition, thereby normalizing a platform for predictive simulations able to account for both human and environmental costs associated with different action plans and institutional arrangements over short and long time spans while minimizing computational requirements. Building from established research programs, the proposal aims to take advantage of current momentum in the direction of the integration of the cognitive with social and natural sciences, reduce start-up costs and increase speed of development. These are all important upshots given rising unease over the potential for AI and related technologies to shape the world going forward.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-019-00877-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12083-019-00851-y,Performance evaluation on the accuracy of the semantic map of an autonomous robot equipped with P2P communication module,Peer-to-Peer Networking and Applications,10.1007/s12083-019-00851-y,Springer,2020-03-01,"Semantic mapping plays an important role in the mobile robotic area, helping robots to perform numerous complicated tasks in both industry and daily life. According to the semantic map, the robot can automatically operate some challenging tasks such as path-planning, place localization, and human-robot interaction. Also, the terminologies of a group of homogenous or heterogeneous robots that perform a general purpose to solve a heavy task with resource limitation become more popular in robot society. To build a multi-robot system, the communication protocol is an essential component to cooperate with a team of robots. Therefore, we propose a multi-robot mapping system, which adopts the P2P communication protocol to solve the mapping problem and map segmentation method from the given mapping or floor plan. The P2P network is constructed based on a centralized overlay network to be scalable and broadcast the control command from the base station to all robots. For generating a semantic map, there have been many works to cope with this task; however, they are still lack of performance. Thus, we perform both feature extraction and feature selection from Voronoi node to enhance the performance of map segmentation. Then to support vector machine (SVM) algorithm and artificial neural network (ANN) are adopted for classifying the segmented areas from Voronoi Graph. The experiment of SVM and ANN shows that they accomplish in map segmentation; however, the SVM algorithm has slightly higher accuracy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12083-019-00851-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-019-01030-0,Efficient Hybrid-Supervised Deep Reinforcement Learning for Person Following Robot,Journal of Intelligent & Robotic Systems,10.1007/s10846-019-01030-0,Springer,2020-02-01,"Traditional person following robots usually need hand-crafted features and a well-designed controller to follow the assigned person. Normally it is difficult to be applied in outdoor situations due to variability and complexity of the environment. In this paper, we propose an approach in which an agent is trained by hybrid-supervised deep reinforcement learning (DRL) to perform a person following task in end-to-end manner. The approach enables the robot to learn features autonomously from monocular images and to enhance performance via robot-environment interaction. Experiments show that the proposed approach is adaptive to complex situations with significant illumination variation, object occlusion, target disappearance, pose change, and pedestrian interference. In order to speed up the training process to ensure easy application of DRL to real-world robotic follower controls, we apply an integration method through which the agent receives prior knowledge from a supervised learning (SL) policy network and reinforces its performance with a value-based or policy-based (including actor-critic method) DRL model. We also utilize an efficient data collection approach for supervised learning in the context of person following. Experimental results not only verify the robustness of the proposed DRL-based person following robot system, but also indicate how easily the robot can learn from mistakes and improve performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-019-01030-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11548-019-02098-7,Robot-assisted flexible needle insertion using universal distributional deep reinforcement learning,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-019-02098-7,Springer,2020-02-01,"Purpose Flexible needle insertion is an important minimally invasive surgery approach for biopsy and radio-frequency ablation. This approach can minimize intraoperative trauma and improve postoperative recovery. We propose a new path planning framework using multi-goal deep reinforcement learning to overcome the difficulties in uncertain needle–tissue interactions and enhance the robustness of robot-assisted insertion process. Methods This framework utilizes a new algorithm called universal distributional Q -learning (UDQL) to learn a stable steering policy and perform risk management by visualizing the learned Q -value distribution. To further improve the robustness, universal value function approximation is leveraged in the training process of UDQL to maximize generalization and connect to diagnosis by adapting fast re-planning and transfer learning. Results Computer simulation and phantom experimental results show our proposed framework can securely steer flexible needles with high insertion accuracy and robustness. The framework also improves robustness by providing distribution information to clinicians for diagnosis and decision making during surgery. Conclusions Compared with previous methods, the proposed framework can perform multi-target needle insertion through single insertion point qunder continuous state space model with higher accuracy and robustness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-019-02098-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-019-01031-z,An Intelligent Hybrid Artificial Neural Network-Based Approach for Control of Aerial Robots,Journal of Intelligent & Robotic Systems,10.1007/s10846-019-01031-z,Springer,2020-02-01,"In this work, a learning model-free control method is proposed for accurate trajectory tracking and safe landing of unmanned aerial vehicles (UAVs). A realistic scenario is considered where the UAV commutes between stations at high-speeds, experiences a single motor failure while surveying an area, and thus requires to land safely at a designated secure location. The proposed challenge is viewed solely as a control problem. A hybrid control architecture – an artificial neural network (ANN)-assisted proportional-derivative controller – is able to learn the system dynamics online and compensate for the error generated during different phases of the considered scenario: fast and agile flight, motor failure, and safe landing. Firstly, it deals with unmodelled dynamics and operational uncertainties and demonstrates superior performance compared to a conventional proportional-integral-derivative controller during fast and agile flight. Secondly, it behaves as a fault-tolerant controller for a single motor failure case in a coaxial hexacopter thanks to its proposed sliding mode control theory-based learning architecture. Lastly, it yields reliable performance for a safe landing at a secure location in case of an emergency condition. The tuning of weights is not required as the structure of the ANN controller starts to learn online, each time it is initialised, even when the scenario changes – thus, making it completely model-free. Moreover, the simplicity of the neural network-based controller allows for the implementation on a low-cost low-power onboard computer. Overall, the real-time experiments show that the proposed controller outperforms the conventional controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-019-01031-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-43306-2_28,Vision Sharing Method of Network Robot Based on Deep Learning,Cyber Security Intelligence and Analytics,10.1007/978-3-030-43306-2_28,Springer,2020-01-01,"With the development of science and technology, robots are evolving from scratch, from low-level systems to high-level systems. The future of intelligent robots is towards intelligent and emotional development, and finally to achieve the goal of human-computer coexistence. Network robot is the main direction of future development. It is a robot controlled by computer network. Human-computer interaction technology, visual sharing and remote monitoring technology, data transmission and communication are the focus of their research. Therefore, the purpose of this paper is to explore the research of vision sharing method based on the theory of robotic algorithm, which leads to different thinking about the future development direction of robots. This paper will adopt the research method of concrete analysis of specific problems to make data comparison and draw conclusions. The results of this study show that as a typical representative of advanced manufacturing equipment, the network intelligent robot will have a large industrial development space and broad market prospects. At the same time, the country should draw lessons from the successful practices of foreign advanced robot industry development, formulate the development strategy and related policies of the robot industry, which is the key to the success or failure of China’s robot industry development.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-43306-2_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-15235-2_21,Research on Robot Control Based on Reinforcement Learning,Cyber Security Intelligence and Analytics,10.1007/978-3-030-15235-2_21,Springer,2020-01-01,"This paper reviews the rise and the development of the deep reinforcement learning (DRL). Then, the deep reinforcement learning algorithms for the high-dimensional continuous action space are divided into three categories of the algorithm based on the value function approximation, the algorithm based on the strategy approximation and the algorithm based on other structures. The latest representative algorithms and their characteristics of the deep reinforcement learning are explained in details, and their ideas, advantages and disadvantages are emphasized. Finally, combined with the development direction of the deep reinforcement learning algorithm, the control mechanism of using the deep reinforcement learning method to solve the control mechanism in the robotics problems is prospected.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-15235-2_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-62554-2_14,Reinforcement Learning Applied to Hexapod Robot Locomotion: An Overview,Telematics and Computing,10.1007/978-3-030-62554-2_14,Springer,2020-01-01,"Six-legged robots are very useful in environments with obstacles of a size comparable to its own. However, the locomotion problem of hexapod robots is complex to solve due to the number of degrees of freedom and unknown environments. Nevertheless, the problem definition of Reinforcement Learning fits naturally for solving the robot locomotion problem. Reinforcement Learning has acquired great relevance in the last decade since it has achieved human-level control for specific tasks. This article presents an overview of Reinforcement Learning methods that have been successfully applied to the six-legged robot locomotion problem. First, a description and some achievements of reinforcement learning will be introduced, followed by examples of hexapod robots throughout history focusing on their locomotion systems. Secondly, the locomotion problem for a six-legged hexapod robot will be defined, with special attention to both, the gait and leg motion planning. Thirdly, the classical framework of reinforcement learning will be introduced and the Q-learning algorithm, which is one of the most used Reinforcement Learning algorithms in this context, will be revised. Finally, reinforcement learning methods applied to six-legged robot locomotion will be extensively discussed followed by open questions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-62554-2_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-36918-7_8,The Valuation of Artificial Intelligence,The Valuation of Digital Intangibles,10.1007/978-3-030-36918-7_8,Springer,2020-01-01,"Artificial intelligence allows to think and act humanely and rationally through hardware systems and software programs capable of providing performances that, to an ordinary observer, would seem to be the exclusive domain of natural (human) intelligence. The applications are more and more extensive, thanks also to the big data available today and the ability of self-learning (machine learning) or instead to the synergies with the natural intelligence, which for vision and flexibility remains irreplaceable. The examination of the business models of the companies that base their strategies on artificial intelligence or, more extensively, of the traditional companies using specific applications is preliminary to a framework of the legal problems (still pioneering) and of the profiles of economic evaluation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-36918-7_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-50896-8_25,Developing a Reinforcement Learning Agent for the Game of Checkers,"Advances in Human Factors in Training, Education, and Learning Sciences",10.1007/978-3-030-50896-8_25,Springer,2020-01-01,"The aim of the following paper was to develop, test and evaluate a simple self-learning agent for the game of Checkers based on reinforcement learning and neural networks. The approach followed in this work is rather simple and based on a single deep neural network which is used to evaluate the board states and to choose the next best move for the agent. During the training phases the neural network is trained using a reward system based on different criteria derived from the prior and the current board state that resulted from the last action taken. The neural network takes a state-action pair, consisting of the current state and a possible move option and predicts the total reward that can be expected. This way all possible move options are evaluated and the one with the highest value is chosen as the next move.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-50896-8_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-29513-4_76,Convolutional Neural Network Applied to the Gesticulation Control of an Interactive Social Robot with Humanoid Aspect,Intelligent Systems and Applications,10.1007/978-3-030-29513-4_76,Springer,2020-01-01,"This document presents the enforcement of a facial gesture recognition system through applying a convolutional neural network algorithm for gesticulation of an interactive social robot with humanoid appearance, which was designed in order to accomplish the thematic proposed. Furthermore, it is incorporated into it a hearing communication system for Human-Robot interaction throughout the use of visemes, by coordinating the robot’s mouth movement with the processed audio of the text converted to the robot’s voice (text to speech). The precision achieved by the convolutional neural network incorporated in the social-interactive robot is 61%, while the synchronization system between the robot’s mouth and the robot’s audio-voice differs from 0.1 s. In this manner, it is pretended to endow mechanisms social robots for a more naturally interaction with people, thus facilitating the appliance of them in the fields of children’s teaching-learning, medical therapies and as entertainment means.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-29513-4_76,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-13-9217-7_3,A Computer Vision System for Visual Perception in Unknown Environments,Machine Learning-based Natural Scene Recognition for Mobile Robot Localization in An Unknown Environment,10.1007/978-981-13-9217-7_3,Springer,2020-01-01,"The goal of machine learning research is to equip robots with human-like perception capabilities so that they can sense its working environment, understand the collected data, take appropriate actions, and learn from its experience so as to enhance future performance. As a result, the acquisition of knowledge about its environment is one of the most important tasks of an autonomous system of any kind. This is done by taking measurements using various sensors and then extracting meaningful information from those measurements. In this chapter, we will present a vision based machine perception model from the perspective of a system design domain and discuss strategies for extracting information acquired from vision sensors for mobile robot localization tasks. More specifically, we aim to apply several important machine learning techniques to vision-based mobile robot navigation applications by discussing three issues, namely, information acquisition, environmental representation, and reasoning, leading to a general high-level model of the problem. The model is intended to be generic enough to allow a wide variety of tasks to be performed using a single set of sensory data. It is argued that the model has a direct correspondence with some recent biological evidences and can be applied to solving real-world problems specifically for an autonomous system operating in outdoor unknown environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-9217-7_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-44267-5_25,Continuous Control in Deep Reinforcement Learning with Direct Policy Derivation from Q Network,"Human Interaction, Emerging Technologies and Future Applications II",10.1007/978-3-030-44267-5_25,Springer,2020-01-01,"The reinforcement learning approach allows learning desired control policy in different environments without explicitly providing system dynamics. A model-free deep Q-learning algorithm is proven to be efficient on a large set of discrete-action tasks. Extension of this method to the continuous control task usually solved with actor-critic methods which approximate a policy function with additional actor network and uses Q function to speed up policy network training. Another approach is to discretize action space which will not give a smooth policy and is not applicable for large action spaces. A direct continuous policy derivation from the Q network leads to optimization of action on each inference and training step which is not efficient but provides optimal and continuous action. Time-efficient Q function input optimization is required in order to apply this method in practice. In this work, we implement efficient action derivation method which allows using Q-learning in real-time continuous control tasks. In addition, we test our algorithm on robotics control tasks from robotics gym environments and compare this method with modern continuous RL methods. The results have shown that in some cases proposed approach learns smooth continuous policy keeping the implementation simplicity of the original discreet action space Q-learning algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-44267-5_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-63955-6_21,Simulation Training Remote Control System of Industrial Robot Based on Deep Learning,"e-Learning, e-Education, and Online Training",10.1007/978-3-030-63955-6_21,Springer,2020-01-01,"In order to improve the remote control performance of industrial robot simulation training, deep learning algorithm is used to optimize the design of traditional remote control system. On the basis of traditional remote control system, the configuration of hardware system is modified, and the database of control system is established. With the support of hardware system and database, the remote control of two training items of industrial robot simulation mobile training and simulation picking training are realized respectively. Through the system test experiment, the conclusion is drawn: compared with the traditional industrial robot remote control system, the control function of the design control system is improved, and the system can save about 12.5 s response time in the control process.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-63955-6_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-61377-8_17,Assessing Deep Learning Models for Human-Robot Collaboration Collision Detection in Industrial Environments,Intelligent Systems,10.1007/978-3-030-61377-8_17,Springer,2020-01-01,"The increasing adoption of industrial robots to boost production efficiency is turning human-robot collaborative scenarios much more frequent. In this context, technical factory workers need to be safe at all times from collisions and prepare for emergencies and potential accidents. Another trend in industrial automation is the usage of machine learning techniques - specifically, deep learning algorithms - for image classification. Following these tendencies, this work evaluates the application of deep learning models to detect physical collision in human-robot interactions. Security camera images are used as the primary information source for intelligent collision detection. Unlike other proposed approaches in the literature that apply sensors like Light Detection And Ranging (LIDAR), Laser Range Finder (LRF), or torque sensors from robots, this work does not consider extra sensors, using only 2D cameras. Results show more than 99% of accuracy in the evaluated scenarios, revealing that approaches adopting deep learning algorithms could be promising for human-robot collision avoidance in industrial scenarios. The proposed models may support safety in industrial environments and reduce the impact of collision accidents.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-61377-8_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-29513-4_69,Autonomous Robot Navigation with Signaling Based on Objects Detection Techniques and Deep Learning Networks,Intelligent Systems and Applications,10.1007/978-3-030-29513-4_69,Springer,2020-01-01,"The autonomous navigation of robots is one of the main problems of robots due to its complexity and level of dynamics, as it depends on environmental conditions and the environment. Deep learning has become an interesting line of research in the area of robotics and computer vision. In this work, we have proposed the application of neural networks with deep learning applying the Single Shot Detector algorithm that provides robustness in speed and precision that mainly allows the detection of persons, objects through the use of the neural network trained for autonomous navigation of robots. The objective of this research is to achieve that a robot is able to make a route in an unknown environment and that by means of the parameterization of a signal at the moment of the detection of an object to have a visible mark in the map, allowing this way the acquisition of information that will help in the future explorations of the robot in the same environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-29513-4_69,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-15235-2_67,Application of Deep Learning Algorithm Based on Multimodal Regularization in Detection Robot Grasping,Cyber Security Intelligence and Analytics,10.1007/978-3-030-15235-2_67,Springer,2020-01-01,"This paper uses the depth learning method to settle the question of robot detection and capture in the RGB-D view of the sight comprising the object. A large number of candidates can be evaluated by using a two-step cascade system, which is faster and more effective than manual design. There are two deep-step cascade system network, a top value of the first detection system is reappraised by the second system. The first meshwork runs faster because of its fewer functions and can prune a large number of candidate fetches effectively. The second network is more powerful, so the speed is relatively slow, and the top-level detection value of the first system can be re-evaluated. To deal with multimodal input effectively, e propose a weighted structure regularization method in view of multichannel group regularization. The experimental results indicate the depth learning arithmetic can effectively improve the performance of RGBD robot grasping data sets, And the new objects can also be captured successfully.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-15235-2_67,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-46817-0_19,Reinforcement Learning Based Human-Prosthetic Robot Interaction Control in Movement Therapy,"New Technologies, Development and Application III",10.1007/978-3-030-46817-0_19,Springer,2020-01-01,"A human–robot interactive control is proposed to control a lower limb prosthetic robot for amputee patients in the movement therapy training. The developed rehabilitation prosthetic robot is driven by the hydraulic system and has two rotational degrees of freedom. An adaptive admittance model is adopted considering its suitability for human–robot interaction. The combined effects of flexibility of linear hydraulic actuators and compliance provided by the controller should contribute to the training comfort, safety, and therapeutic outcome in the gait rehabilitation. In this paper, we present the human-robot interaction admittance model where individual admittance parameters suitable for patients are obtained by reinforcement learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-46817-0_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-32022-5_18,A ConvNet-Based Approach Applied to the Gesticulation Control of a Social Robot,Advances in Emerging Trends and Technologies,10.1007/978-3-030-32022-5_18,Springer,2020-01-01,"This document presents the enforcement of a facial gesture recognition system through applying a Convolutional Neural Network (CNN) algorithm for gesticulation of an interactive social robot with humanoid appearance, which was designed in order to accomplish the thematic proposed. Furthermore, it is incorporated into it a hearing communication system for Human-Robot interaction throughout the use of visemes, by coordinating the robots mouth movement with the processed audio of the text converted to the robot’s voice (text to speech). The precision achieved by the CNN incorporated in the social-interactive robot is 61%, while the synchronization system between the robot’s mouth and the robot’s audio-voice differs from 0.1 s. In this way, it is pretended to endow mechanisms social robots for a naturally interaction with people, thus facilitating the appliance of them in the fields of childrens teaching-learning, medical therapies and as entertainment means.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-32022-5_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-66412-1_14,Integrated Commonsense Reasoning and Deep Learning for Transparent Decision Making in Robotics,Multi-Agent Systems and Agreement Technologies,10.1007/978-3-030-66412-1_14,Springer,2020-01-01,"A robot’s ability to provide explanatory descriptions of its decisions and beliefs promotes effective collaboration with humans. Providing such transparency in decision making is particularly challenging in integrated robot systems that include knowledge-based reasoning methods and data-driven learning algorithms. Towards addressing this challenge, our architecture couples the complementary strengths of non-monotonic logical reasoning with incomplete commonsense domain knowledge, deep learning, and inductive learning. During reasoning and learning, the architecture enables a robot to provide on-demand explanations of its decisions, beliefs, and the outcomes of hypothetical actions, in the form of relational descriptions of relevant domain objects, attributes, and actions. The architecture’s capabilities are illustrated and evaluated in the context of scene understanding tasks and planning tasks performed using simulated images and images from a physical robot manipulating tabletop objects. Experimental results indicate the ability to reliably acquire and merge new information about the domain in the form of constraints, and to provide accurate explanations in the presence of noisy sensing and actuation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-66412-1_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-30425-6_25,Application of Deep Neural Network for the Vision System of Mobile Service Robot,"Advances in Neural Computation, Machine Learning, and Cognitive Research III",10.1007/978-3-030-30425-6_25,Springer,2020-01-01,"The solution of object detection task is valuable in many fields of robotics. However, application of neural networks for mobile robots requires the use of high – performance architectures with low power consumption. In search of suitable model, a comparative analysis of the YOLO and SqueezeDet architectures was conducted. The task of detecting wooden cubes by mobile robot with the camera with the aim of collecting them was solved. A specific dataset was constructed for the training purposes. Applied SqueezeDet neural network has reached precision 89% and recall 82% for IOU ≥ 0.5.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30425-6_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-34983-7_54,Neural Network Compensation of Dynamic Errors in a Robot Manipulator Programmed Control System,Cyber-Physical Systems and Control,10.1007/978-3-030-34983-7_54,Springer,2020-01-01,The subject of consideration in this paper is a programmed control system of a robot manipulator. Mathematical description of the control system was presented taking into account the nonlinear dynamics of the robot mechanism. Synthesis of multivariable compensators of dynamic errors for a prototype control system was carried out. Computer models of the control system with synthesized compensators were developed using MATLAB package. The results of teaching of neural network compensators are given for a programmed trajectory of the robot gripper. Comparative analysis of dynamic errors in the prototype system and the system with neural network compensators was conducted.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-34983-7_54,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-59506-7_14,A Review of Self-balancing Robot Reinforcement Learning Algorithms,Information and Software Technologies,10.1007/978-3-030-59506-7_14,Springer,2020-01-01,"We analyse reinforcement learning algorithms for self balancing robot problem. This is the inverted pendulum principle of balancing robots. Various algorithms and their training methods are briefly described and a virtual robot is created in the simulation environment. The simulation-generated robot seeks to maintain the balance using a variety of incentive training methods that use non-model-based algorithms. The goal is for the robot to learn the balancing strategies itself and successfully maintain its balance in a controlled position. We discuss how different algorithms learn to balance the robot, how the results depend on the learning strategy and the number of steps. We conclude that different algorithms result in different performance and different strategies of keeping the robot balanced. The results also depend on the model training policy. Some of the balancing methods can be difficult to implement in real world.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-59506-7_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-7297-5_9,Robot Theatre and AI Films,"Pop with Gods, Shakespeare, and AI",10.1007/978-981-15-7297-5_9,Springer,2020-01-01,"This chapter explores Robot Theatre La Métamorphose Version Androïde (2015 Taipei), Three Sisters: Android Version (2012 Taipei), and the 11 AI films. Japanese Playwright and Theater Director Oriza Hirata collaborates with Professor Hiroshi Ishiguro to bring in robots into theatre performances. The first script is adapted from Franz Kafka’s novel The Metamorphosis . The drastic change is the protagonist Gregor Samsa wakes up one morning to find that he transform into, not a huge insect, but a robot. The second robot theatre case is adapted from Russian playwright Anton Chekhov’s Three Sisters . As Shakespeare in As You Like It writes: “All the world’s a stage,” robot theatre and AI films reflect the tendency that the world goes toward the era where humans co-exist with AI robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-7297-5_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-6113-9_56,The Ideas of Robot Design and Application from the First-Year Undergraduate Students,Cognitive Cities,10.1007/978-981-15-6113-9_56,Springer,2020-01-01,"The purpose of this research was to understand college students’ perspectives of robot design and robot application. This study invited 53 first-year college students to participate. Participants were invited to draw the robots which they want to design, and to describe the ideotype, target group, and the function of the robot. All information of robot characteristics was coded and analyzed. In the results, four robot ideotypes were presented, including: humanoid style, android style, pet/animal style, and others. The five target populations were baby and children, college students and young people, family and all people, elderly or single person, and others. Ten categories of robot functions were suggested, including: accompanying and chatting, personal assistant, educational function, babysitter, dance and exercise, pet function, elder care, housework, entertaining, and other specific functions. More relationships between robot characteristics were discussed in the study. The results can help the instructors to develop artificial intelligence and robot courses to establish better knowledge and competencies for students in the college of social sciences. This information may also help the robot designers to think human needs from different perspectives and to develop robots with more friendly functions for improving user’s experiences and life quality in future.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-6113-9_56,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-19648-6_12,Shared Impedance Control Based on Reinforcement Learning in a Human-Robot Collaboration Task,Advances in Service and Industrial Robotics,10.1007/978-3-030-19648-6_12,Springer,2020-01-01,"In this work a shared impedance control scheme for a hybrid human-robot team is designed for transporting a rigid workpiece to a desired position. Within the scope of proposed control structure, both human and robot are regarded as mechanical impedance and their parameters are adapted continuously in real-time. Reinforcement learning is used to find an impedance parameter set for the whole team to optimize a task-orient cost function. Then the learned parameters are further adjusted by taking human’s disagreement into consideration. The proposed method is aimed to reduce human’s control effort during collaboration and be flexible to variation of the task or environment. Experimental results are presented to illustrate the performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-19648-6_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-13-9267-2_44,Robot Navigation System in Stochastic Environment Based on Reinforcement Learning on Lidar Data,Proceedings of 14th International Conference on Electromechanics and Robotics “Zavalishin's Readings”,10.1007/978-981-13-9267-2_44,Springer,2020-01-01,"In this paper, we present an approach ensuring efficient pathfinding by a robotic platform among static and dynamic objects in a stochastic environment. The approach utilizes data from two-dimensional laser scanner (lidar) that are fed to the neural network for reinforcement learning. The network is trained based on a three-dimensional room model that contains static objects such as walls, floor, stairs, and random dynamic objects, moving in this space along paths. The output data of the trained network represent the next move of the robotic vehicle on its way to the destination point in the room. The presented approach enables the robotic platform to reach the destination point, accounting for special features of the obstacle in the path using data that is taken from the two-dimensional lidar within a certain timeframe.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-9267-2_44,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-36150-1_18,Effects of a Social Force Model Reward in Robot Navigation Based on Deep Reinforcement Learning,Robot 2019: Fourth Iberian Robotics Conference,10.1007/978-3-030-36150-1_18,Springer,2020-01-01,"In this paper is proposed an inclusion of the Social Force Model (SFM) into a concrete Deep Reinforcement Learning (RL) framework for robot navigation. These types of techniques have demonstrated to be useful to deal with different types of environments to achieve a goal. In Deep RL, a description of the world to describe the states and a reward adapted to the environment are crucial elements to get the desire behaviour and achieve a high performance. For this reason, this work adds a dense reward function based on SFM and uses the forces in the states like an additional description. Furthermore, obstacles are added to improve the behaviour of works that only consider moving agents. This SFM inclusion can offer a better description of the obstacles for the navigation. Several simulations have been done to check the effects of these modifications in the average performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-36150-1_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-35314-8_5,Digitalisation,Modern Facility and Workplace Management,10.1007/978-3-030-35314-8_5,Springer,2020-01-01,"After the introduction of the meaning of digitalisation and its goals, this chapter presents the most important emerging technologies in the area of RE/FM/FS. It analyses which services are mainly affected by these technologies and goes into details about these changes, using examples of the FS “maintenance and operation”, “energy”, “logistic”, “security” and “safety”. It must be emphasised that digitalisation does not only mean the use of emerging technologies but also the development of new, human-centric services and products, of disruptive change in the service provision, of customised services and of new partnerships – only to name some of the most important “opportunities” due to digitalisation!",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-35314-8_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-50801-2_5,Robotics and AI: How Technology May Change the Way We Shape Our Bodies and What This Does to the Mind,21st Century Sports,10.1007/978-3-030-50801-2_5,Springer,2020-01-01,"In this chapter, Kirchner explores some of the exciting recent developments in robotics and artificial intelligence (AI) and the barriers to control complex mechanisms. He also offers a solution that he terms “the hybrid AI approach.” Kirchner goes on to argue for using robots and learning as a way to achieve AI, an idea first touted by Alan Turing, and offers example cases of robots and AI in sports. Finally, he looks to the future and explores the possibilities and possible effects on the human body and mind of extensive physical interaction with intelligent machines.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-50801-2_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-12719-0_8,Applying Blockchain and Artificial Intelligence to Digital Health,Digital Health Entrepreneurship,10.1007/978-3-030-12719-0_8,Springer,2020-01-01,"During recent years, healthcare informatics has become synonymous with big data and interoperability challenges. Skilled digital health entrepreneurs, however, can turn these issues into profitable opportunities for unlocking greater value out of healthcare and adjacent industries, including pharma or insurance. Recent technology breakthroughs such as blockchain and artificial intelligence hold great promise in helping entrepreneurs tackle major healthcare challenges, such as breaking data out of silos while keeping it secure, moving data quickly through the whole value stream, and analyzing and getting insights out of huge data sets quickly and reliably. This chapter provides a brief introduction to how both blockchain and artificial intelligence work, some key use cases in healthcare where they can be leveraged, as well as critical challenges that must be overcome for the technologies to be adopted and deployed at scale.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-12719-0_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-31635-8_192,Toward a Neural-Symbolic Framework for Automated Workflow Analysis in Surgery,XV Mediterranean Conference on Medical and Biological Engineering and Computing – MEDICON 2019,10.1007/978-3-030-31635-8_192,Springer,2020-01-01,"Learning production rules from continuous data streams, e.g. surgical videos, is a challenging problem. To learn production rules, we present a novel framework consisting of deep learning models and inductive logic programming (ILP) system for learning surgical workflow entities that are needed in subsequent surgical tasks, e.g. “what kind of instruments will be needed in the next step?” As a prototypical scenario, we analyzed the Robot-Assisted Partial Nephrectomy (RAPN) workflow. To verify our framework, first consistent and complete rules were learnt from the video annotations which can classify RAPN surgical workflow and temporal sequence at high-granularity e.g. steps. After we found that RAPN workflow is hierarchical, we used combination of learned predicates, presenting workflow hierarchy, to predict the information on the next step followed by a classification of step sequences with deep learning models. The predicted rules on the RAPN workflow was verified by an expert urologist and conforms with the standard workflow of RAPN.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-31635-8_192,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-4291-6_3,"Artificial Intelligence in Disaster Management: Rescue Robotics, Aerial Mapping and Information Sourcing",AI and Robotics in Disaster Studies,10.1007/978-981-15-4291-6_3,Springer,2020-01-01,"Rescue robotics, aerial mapping, and information sourcing systems are a few of the many advancements in disaster management that have been developed using AI. AI has provided rescue crews access to disaster-stricken zones without any risks of injury or fatigue. In this chapter we will discuss how AI is modernizing disaster management, and review successful applications of robotics and machine learning in supporting recovery operations during recent disasters. We will also review various companies and products that are commercially available today and how they can easily be adopted to modernize a country’s disaster management infrastructure. The latter section of this chapter also discusses the use of machine learning in predicting disasters and highlights advantages in terms of accuracy, implementation, and cost. Lastly this chapter discusses how AI can get biased and provides some recommendations to be considered with adopting AI in disaster management.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-4291-6_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-51005-3_29,Robot Creativity: Humanlike Behaviour in the Robot-Robot Interaction,Science and Technologies for Smart Cities,10.1007/978-3-030-51005-3_29,Springer,2020-01-01,"Artificial Intelligence development is mainly directed toward imitating human reasoning and performing different tasks. For that purpose, related software and program solution where artificial intelligence is used have mostly thinking abilities. However, there are many questions to answer in ongoing AI research, especially when we come to the point which is addressing humanlike behaviour and reasoning triggered by emotions. In this paper, we are presenting an interactive installation Botorikko: Machine Create State, which is part of the Syntropic Counterpoints art/research project. We are exposing AI cyber clones to some of the fundamental questions for humankind and challenge their creativity. The robots are trained by using the publications Machiavelli and Sun Tzu and confronted to the crucial questions related to moral, ethic, strategy, politics, diplomacy, war etc. We are using a recurrent neural network (RNN) and robot-robot interaction to trigger unsupervised robot creativity and humanlike behaviour on generated machine-made content.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-51005-3_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-36150-1_31,Machine Learning Methods for Radar-Based People Detection and Tracking by Mobile Robots,Robot 2019: Fourth Iberian Robotics Conference,10.1007/978-3-030-36150-1_31,Springer,2020-01-01,"This paper reports a machine learning approach for people detection and tracking in indoor environments using a compact radar system deployed by a mobile robot. The set-up described in the paper includes a series of experiments carried out in an indoor scenario involving walking people and dummies representative of other moving objects. In these experiments, distinct learning models (a neural network and a random forest) were explored with different combinations of radar features to achieve person versus non-person classification.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-36150-1_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27015-5_64,Subject Structure of the Offense in Artificial Intelligence (AI) and Robotics,"Digital Age: Chances, Challenges and Future",10.1007/978-3-030-27015-5_64,Springer,2020-01-01,"Digitalization and digital technologies are a source of revolutionary changes affecting all aspects of human activity without any exception. Adaptation of society to digitalization is not only a technological, economic, socio-psychological, but particularly a legal problem. No one doubts that in the period of the fourth technical revolution, the regulatory framework should be aimed at providing a fertile and healthy ground for the progressive development of various technological innovations, preventing offenses. The development of robotics and artificial intelligence (AI) and their widespread use in all areas of the economy suggests the need to revise the traditional views on legal personality and offense. Without determining the legal status of work technicians and AI, the resolution of the question of their responsibility for the offenses committed and the damages caused, the further qualitative development of this area is impossible. Modern research in the field of law pays great attention to particular issues of the legal responsibility of robots and AI. In this regard, a number of questions arise directly related to the general theoretical concept of “offense”, namely, can robots and AI be recognized as subjects of an offense and, as a result, bear legal responsibility, if so, what are the scope and consequences of this responsibility? The results of this study can be used in the practice of legislative bodies of the Russian Federation and international organizations. The theoretical conclusions of the study can be used in research and development institutes, in higher educational institutions for teaching not only legal but also economic disciplines.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27015-5_64,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-05324-6_110-1,"Impact of Artificial Intelligence in Travel, Tourism, and Hospitality",Handbook of e-Tourism,10.1007/978-3-030-05324-6_110-1,Springer,2020-01-01,"Artificial intelligence (AI) is currently present in almost every area of travel and tourism, appearing in different types of applications such as personalization and recommender systems, robots, conversational systems, smart travel agents, prediction and forecasting systems, language translation applications, and voice recognition and natural language processing systems. Recent improvements in big data, algorithms, and computing power have enabled significant enhancements in AI. In this chapter, we review how AI has changed and is changing the main processes in the tourism industry. We start with the IT foundations of AI that are relevant for travel and tourism and then address the AI systems and applications available in the sector. We then examine hospitality in detail, as a sector in which most of these systems are being implemented. We conclude with the challenges that AI faces in the tourism sector, a research agenda, and draw a scenario of the future of AI in tourism.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-05324-6_110-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-3242-9_21,Sapling Health Monitoring System,Advanced Computing Technologies and Applications,10.1007/978-981-15-3242-9_21,Springer,2020-01-01,"Aim is to create a system that helps in time to time analysis of field to collect real-time data of field crops about moisture, soil pH, etc. System also helps in detecting diseases if any in crops by collecting their leaf snaps. The paper briefly explains the system and its architecture which is implemented on a rover equipped to collect data and is further processed using deep learning concepts. The paper discusses the real-world implementation of this device and its work cycle.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-3242-9_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-0630-7_49,Pedestrian Activity Recognition Using 2-D Pose Estimation for Autonomous Vehicles,ICT Analysis and Applications,10.1007/978-981-15-0630-7_49,Springer,2020-01-01,"Human activity recognition is the task of recognizing activities of any given subject in a scene, from a set of observation over time, taking into consideration the environmental and behavioral factors. It has application in a lot of fields including surveillance, assistance system, threat identification. Human activity recognition plays a vital role in human computer interaction, as it is very important that a computer correctly identifies human activity to really understand the human behavior and learn what the human is trying to convey through their action as more than 50% of communication humans do is through body language. In this paper, we propose a system for identifying activities of pedestrians on road using pose estimation to give the autonomous vehicles a better understanding of the humans’ actions and get better at driving and also provide a safer environment for the humans.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-0630-7_49,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-44267-5_27,Traffic Sign Classification Using Embedding Learning Approach for Self-driving Cars,"Human Interaction, Emerging Technologies and Future Applications II",10.1007/978-3-030-44267-5_27,Springer,2020-01-01,"Image classification is one of the most popular and important problems in computer vision. In self-driving cars image classification is used to classify detected traffic signs. Modern state-of-the-art algorithms based on deep neural networks use softmax function to interpret the output of the network as the probability that the input data belongs to a certain class. This approach works well, however it has several disadvantages. More precisely, it is necessary to know the number of classes in advance, and if one wants to add a new class, then it is necessary to retrain the network. Moreover, a large number of images of each class are required. In the case of road signs, datasets may contain only the most frequent signs while ignoring rarely used ones. Thus, the traffic signs recognition module in autonomous cars will not recognize traffic signs not included into training dataset, which can lead to accidents. In this paper we put forward another approach that does not have disadvantages of networks with softmax. The approach is based on learning image embeddings in which models are trained to bring closer objects of one class and to move away objects of other classes in embeddings space. Therefore, having even a small number of images of rare classes it becomes possible to create a working classification system. In this work, we test the applicability of these algorithms in the traffic signs classification problem, and also compare its accuracy with neural networks with softmax and with networks pre-trained on softmax. We developed publicly available toolbox for training and testing embedding networks with different loss functions, backbone models, training strategies and other configuration parameters and embedding space visualization tools. All our experiments were carried out on the russian road signs dataset. To simplify the process of conducting training experiments, a framework for embedding learning based neural networks making was created. The framework can be found at https://github.com/RocketFlash/EmbeddingNet .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-44267-5_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-32-9690-9_30,Android App Controlled Multi-purpose Robot Using 8051 Microcontroller,Smart Intelligent Computing and Applications,10.1007/978-981-32-9690-9_30,Springer,2020-01-01,"Robotics and artificial intelligence have become an indispensible part of our lives. From Turing’s test to deep learning we have seen their presence and evolution. The rate at which robotics is currently proceeding is so fast that soon we would live in a world where intelligent systems would have seeped into the most common applications. It would thus be suitable to get acquainted with the technology as it advances and grows. It would be much better if people could learn to do it at a young age, especially children. Hence we decided to create a robot that could be operated and controlled by children. The aim of our project is to create a robot using 8051 microcontroller interfaced with Bluetooth and Android App. This is how the robot works: the Bluetooth module of the robot interacts with the Android App to control the application of three different robots: Line Follower, Button controlled and voice controlled robots via exchange of numeric data. The interface has been designed in a user-friendly manner that would be easy for kids to operate. This can ultimately be used to introduce children to the world of robotics and would give them an insight as to how things work. The future is moving towards a state where technology would be pervasive and knowledge would be preferable.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-32-9690-9_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-33846-6_98,Competitions of Multi-agent Systems for Teaching Artificial Intelligence,Inventive Computation Technologies,10.1007/978-3-030-33846-6_98,Springer,2020-01-01,"This paper presents an approach based on competitions of multi-agent systems as the basis for teaching advanced topics in Artificial Intelligence. The method was applied in the Cognitive Robotics course with students of the 5th-year in Computer Science from the University of Mumbai in India, in the domain of Soccer. The championships are played between different teams to allow students to assess and compare the results. The motivation that is reached is fundamental for creating interest in the study of Artificial Intelligence techniques and in research. The developed experiences are described, as well as an analysis of the method and its impact for the academy and the research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-33846-6_98,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-18141-3_14,"Flexible Techniques for Fast Developing and Remotely Controlling DIY Robots, with AI Flavor",Educational Robotics in the Context of the Maker Movement,10.1007/978-3-030-18141-3_14,Springer,2020-01-01,"During the last years we are witnessing a very successful osmosis between innovative and cost-effective credit card - sized computers and education. These computers, equipped with low cost sensors or actuators, can be the “heart” of various DIY robotic artefacts. This environment allows for a mixture of thinking and making activities that can be very meaningful in terms of pedagogy and science. Indeed, similar practices, usually referred as STEM or STEAM activities, are applied in many educational institutions, from primary schools up to universities, with most of the effort to focus on secondary school students. The overall process, although promising at the beginning, is not always straightforward to keep up with. More specifically, as students get more experience, they develop a hunger for more complicated scenarios that usually demand features like remote interaction with simple Artificial Intelligence – A.I. capabilities or sophisticated control of their robotic artefacts. At this moment, trainers should be able to propose simple and stable techniques to their students for implementing such features in their constructions. This paper proposes flexible methods for this to be done by exploiting the very popular MIT App Inventor and Snap! visual programming environments, in conjunction with a modified tiny web server module, written in Python, that runs on a Raspberry Pi credit card - sized computer. Furthermore, this paper reports on simple techniques being used to make robust enough robots by low cost everyday/recyclable materials like cardboard, wood, plastic bottles or broken toys.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-18141-3_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-29516-5_60,Anticipating Next Goal for Robot Plan Prediction,Intelligent Systems and Applications,10.1007/978-3-030-29516-5_60,Springer,2020-01-01,"Goal reasoning is a main objective for robot task execution. Here we propose a deep model for learning to infer a next goal, while performing an activity. Because predicting the next goal state requires a robot language, not comparable to sentences, we introduce a specific metric for optimization, which is related to the representation the robot has of the scene. Experiments of the proposed idea and method have been done at a warehouse with a humanoid robot performing tasks assisting a maintenance technician working at a production line.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-29516-5_60,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-38778-5_38,The Robot in the Classroom: A Review of a Robot Role,Emerging Technologies for Education,10.1007/978-3-030-38778-5_38,Springer,2020-01-01,"The 20th-century was the age of computers and information communication technology; at the beginning of the 21st-century researchers are exploring the use of robots in the classroom. Our review investigates the implementation of copresent social robots with teaching purposes in a classroom setting in areas other than the teaching of subjects that are closely related to the field of Robotics. We are interested in anthropomorphic robots, with an active role in the classroom and capable of human-like activity. With a search of the WOS database and a subsequent manual search in 19 journals we identified 24 relevant articles which have been included in the analysis. Studies mostly include small number of participating learners. In all studies special conditions are established for the robot intervention in a classroom. Most often robots appear in roles as teacher, teacher assistant and Care-Receiving Robot. Robots interventions were conducted by NAO, Saya, RoboThespian, Bioloid, BAXTER, Darwin, NIMA-Robocop, Robosapien, TIRO. Social robots diverge from the computer-mediated communication technologies, as they are not mediating interaction but are partner in interaction. ITSs and ILEs assist teachers in teaching, while the teacher and a robot have a shared presence in the classroom. The copresent social robots perform a social role by interacting with students. Robotic activities are aimed at delivering learning materials and not primarily for individualised teaching, which encompasses the delivery of feedback and the tailoring learning activities for individual learner’s needs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-38778-5_38,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-32523-7_14,Human-Augmented Robotic Intelligence (HARI) for Human-Robot Interaction,Proceedings of the Future Technologies Conference (FTC) 2019,10.1007/978-3-030-32523-7_14,Springer,2020-01-01,"This paper provides a system design framework for a human-robot interaction system. The design introduces a human-augmented robotic intelligence embedded in a human-robot interaction system. The motivations behind the system design are spoken dialogue systems, Wizard-of-OZ framework, and existing HRI designs for socially intelligent robots. In this work, we explain how artificial intelligence of human-robot interaction system is enhanced by human intelligence through collaboration. The collaborative artificial intelligence enables the system to learn from demonstration. The main objective and the gradual progression from this paper is to build an iterative interactive system that is capable of achieving human-robot interaction similar to the nuances of human-human interaction.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-32523-7_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-49778-1_43,Understandable Teams of Pepper Robots,"Advances in Practical Applications of Agents, Multi-Agent Systems, and Trustworthiness. The PAAMS Collection",10.1007/978-3-030-49778-1_43,Springer,2020-01-01,"The term understandable robots refers to robots making their actions and intentions understandable (or explainable) to humans. To support understandability of a team of collaborating robots we use natural language to let the robots verbalize what they do and plan to do. Our solution is based on Cooperating Distributed Grammar Systems for plan derivation and a Multi-agent algorithm for coordination of robot actions. We implemented and evaluated our solution on a team of three Pepper robots that work collaboratively to move an object on a table, thereby coordinating their capabilities and actions and verbalizing their actions and intentions. In a series of experiments, our solution not only successful demonstrated collaboration and task fulfilment, but also considerable variation, both regarding actions and generated natural language utterances.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-49778-1_43,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-61218-4_1,Cloud Robotics for Industry 4.0 - A Literature Review,"Cloud Computing, Big Data & Emerging Topics",10.1007/978-3-030-61218-4_1,Springer,2020-01-01,"Robots in the industry have been used for decades, much before the so-called Fourth Industrial Revolution. They have been incorporated into industrial processes in various ways, for example, with mechanic arms, in assembly processes, welding, and painting, among others. Industrial robots are located in restricted access sites and their space is delimited by means of physical barriers and security measures. In recent years, Industry 4.0 proposes the use robots, able to collaborate with persons, known as collaborative robots or “cobots”. Cobots are characterized by cooperating with human work, sharing the same workspace, and able to respond to simple human-machine interactions. In addition, given the benefits of applying cloud computing in Industry 4.0, research has been conducted in applying such technologies to robots. The approach is known as “cloud robotics” and appears as an emerging topic. The objective of this work is to carry out a systematic literature review of cloud robotics for Industry 4.0, in an attempt to present the state of the art in this field and identify opportunities for future research. From the analysis of the results, we observe an emerging interest in this area, and we identify main technologies applied, research themes, and application areas, as well as a special interest on security and safety aspects.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-61218-4_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-62803-1_12,Assessing the Japanese Turn in AI and Robot Ethics: Extracting Meaningful Principles Between Exoticism and Empiricism in the Case of AIBO,Human-Centric Computing in a Data-Driven Society,10.1007/978-3-030-62803-1_12,Springer,2020-01-01,"The present paper critically examines a recent recurrent pattern of Western scholarship of importing sets of Japanese ethics in artificial intelligence/data/robot ethics contexts without a deeper examination of their meaning and value. The paper’s outline is unfolded as such: (1) We draw on material stemming from an ethnographic participant-observer study that followed a debate between Western and Japanese people confronting the robotic AI pet AIBO. (2) We demarcate how many of the proposed Japanese values are practically relevant to the examination of human-robot interaction and how this feeds into existing questions about privacy and safety, in the context of a global overwhelming AI hype and narrative bias. (3) Finally, we discuss how a long history of Western enthusiasm and occasional misunderstandings of Japanese values comes full circle with the recent trend, and we conclude with a set of open questions that require more dedicated empirical research in order to reach more proper and practical value system in the future design of technology.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-62803-1_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-58799-4_54,AISRA: Anthropomorphic Robotic Hand for Small-Scale Industrial Applications,Computational Science and Its Applications – ICCSA 2020,10.1007/978-3-030-58799-4_54,Springer,2020-01-01,"We describe the design of the multi-finger anthropomorphic robotic hand for small-scale industrial applications, called AISRA (Anthropomorphic Interface for Stimulus Robust Applications), which can feel and sense the object that it is holding. The robotic hand was printed using the 3D printer and includes the servo bed for finger movement. The data for object recognition was collected using Leap Motion controller, and Naïve Bayes classifier was used for training and classification. We have trained the robotic hand on several monotonous objects used in daily life using supervised machine learning techniques and the gesture data obtained from the Leap Motion controller. The mean accuracy of object recognition achieved is 92.1%. The Naïve Bayes algorithm is suitable for using with the robotic hand to predict the shape objects in its hands based on the angular position of its figures. Leap Motion controller provides accurate results and helps to create a dataset of object examples in various forms for the AISRA robotic hand, and can be used to help developing and training 3D-printed anthropomorphic robotic hands. The experiments in object grasping experiments demonstrated that the AISRA robotic hand can grasp objects with different size and shape, and verified the feasibility of robot hand design using low-cost 3D printing technology. The implementation can be used for small-scale industrial applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58799-4_54,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-33491-8_19,Experiments with Neural Net Object Detection System YOLO on Small Training Datasets for Intelligent Robotics,Advanced Technologies in Robotics and Intelligent Systems,10.1007/978-3-030-33491-8_19,Springer,2020-01-01,"In this paper we’ve conducted multiple experiments with modern object detection system YOLO. Object detection systems are fundamental to many robotics tasks. Recognition algorithms involving object detection are often part of various intelligence systems for robots. Training object detection systems usually requires waste amounts of training data which can be expensive and time-consuming. In this paper we’ve conducted several experiments with YOLO on small training datasets investigating YOLO’s capacity to train on small number of examples. We measured accuracy metrics for object detector depending on the size of training dataset, compared training process of full and smaller versions of YOLO and their speed. Gathered information will be used for creating visual factographic intelligence system for robots. YOLO (You Only Look Once) is a special intelligent technology for computer vision techniques. Our results are useful for industry professionals and students from a broad range of disciplines related to robotics, intelligent technologies and other fields.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-33491-8_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-35990-4_42,Artificial Intelligence Teaching Through Embedded Systems: A Smartphone-Based Robot Approach,Robot 2019: Fourth Iberian Robotics Conference,10.1007/978-3-030-35990-4_42,Springer,2020-01-01,"Following the recommendations of the European Commission, with the aim of positioning the EU as a leader in the technological revolution that is yet to come, Artificial Intelligence (AI) teaching at University degrees should be updated. Current AI subjects should move from theoretical and virtual applications towards what is called “specific AI”, focused on real embedded devices, using data from real sensors and interacting with their environment to solve problems in the real world. These real devices must have the computing power to process all the information that comes from their sensors and also full network connectivity, to allow the connection with other intelligent devices. This work belongs to an Erasmus Plus proposal in such direction, called TAIREMA, which aims to provide a set of tools to include low-cost embedded devices at classes to support AI teaching. One of these tools is a smartphone-based robot called Robobo, which is the main topic of this paper. We will present its main features, mainly in software aspects, and we will describe some specific teaching units that have been developed in classes during the last year in AI subjects.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-35990-4_42,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-60128-7_21,Producing an Immersive Experience Using Human-Robot Interaction Stimuli,"HCI International 2020 – Late Breaking Papers: Cognition, Learning and Games",10.1007/978-3-030-60128-7_21,Springer,2020-01-01,"Human-Robot Interaction (HRI) is an emerging topic within contemporary science and this topic spans the literatures between engineering, psychology, computer science, artificial intelligence, machine learning and robotics. The study of HRI requires scenarios and other affordances from which to contextualize the HRI to study the factors that shape human attitudes, behaviors, and biases as they relate to robots. The current paper details the rationale, software/hardware, and contextual considerations associated with the creation of HRI stimuli used in experiments, specifically the creation of a set of video stimuli. These stimuli centered on the concept of an autonomous security robot (ASR) and provided a scenario wherein humans (research confederates) would interact with the ASR in a realistic scenario. A video was created to foster a realistic visual and auditory representation of the HRI encounter from a dynamic perspective – meaning shifting perspectives between a first-person experiential vantage point to a birds-eye-view of the broader situation. The scenario used involved a security context where the confederates sought access to a secure facility. The ASR’s role was to examine visitor access credentials and determine if the visitor was authorized or not. The robot’s behaviors, while scripted, were depicted as autonomous in the video and included verbal interactions/instructions as well as physical limb motions, gestures, and instructions. Several important features of the stimuli were considered in its creation, namely: realism, immersive experience, and simulated vulnerability of the human to the robot. The current paper walks through each of these considerations with details provided in our approach. To date, the HRI stimuli have been used in multiple experiments and have demonstrated flexibility in addressing multiple research questions in the domain of HRI.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60128-7_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-55789-8_6,Push Recovery and Active Balancing for Inexpensive Humanoid Robots Using RL and DRL,Trends in Artificial Intelligence Theory and Applications. Artificial Intelligence Practices,10.1007/978-3-030-55789-8_6,Springer,2020-01-01,"Push recovery of a humanoid robot is a challenging task because of many different levels of control and behaviour, from walking gait to dynamic balancing. This research focuses on the active balancing and push recovery problems that allow inexpensive humanoid robots to balance while standing and walking, and to compensate for external forces. In this research, we have proposed a push recovery mechanism that employs two machine learning techniques, Reinforcement Learning and Deep Reinforcement Learning, to learn recovery step trajectories during push recovery using a closed-loop feedback control. We have implemented a 3D model using the Robot Operating System and Gazebo. To reduce wear and tear on the real robot, we used this model for learning the recovery steps for different impact strengths and directions. We evaluated our approach in both in the real world and in simulation. All the real world experiments are performed by Polaris, a teen-sized humanoid robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-55789-8_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-41099-5_3,Research on Human-Computer Cooperative Teaching Supported by Artificial Intelligence Robot Assistant,Artificial Intelligence Supported Educational Technologies,10.1007/978-3-030-41099-5_3,Springer,2020-01-01,"The artificial intelligence robot assistant is the physical embodiment of the educational application of artificial intelligence. It is different from the online virtual robot assistant experience to the robot psychological and habit experience, and the robot application of educational situation relies on the design and implementation of human-computer cooperation mechanism. Human-computer collaborative gives full parts to the advantages of teachers and artificial intelligence and promotes the personalized educational development of learners. How to promote the collaborative teaching of teachers and artificial intelligence robot assistant in the smart learning environment is a topic worth to study. Therefore, based on the application scenario of the artificial intelligence robot assistant, this chapter analyzes key technologies of artificial intelligence supported by the artificial intelligence robot assistant, constructs the collaborative teaching environment supported by the artificial intelligence robot assistant under the framework of online platform foundation and fog computing environment, analyzes the collaborative teaching process and application supported by the artificial intelligence robot assistant, and designs the collaborative teaching environment. At last, we summarize the application effect and related discussion of the application of artificial intelligence robot assistant in the classroom. Artificial intelligence robot assistant is an integrated and concrete classroom embodiment of artificial intelligence technology. The artificial intelligence robot assistant can be used as a teacher assistant in the classroom, which can form a new human-computer cooperative teaching mode.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-41099-5_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-33491-8_20,Robot-Doctor: What Can It Be?,Advanced Technologies in Robotics and Intelligent Systems,10.1007/978-3-030-33491-8_20,Springer,2020-01-01,"The ethical issues of application of artificial intelligence methods in medicine are discussed and the assumption is made that the methods of artificial intelligence will solve the main ethical problem of medicine—the appointment of drugs, courses of treatment and prevention of diseases will stop without preliminary computer modeling of their consequences and optimization of given prescriptions and recommendations. The methods of creation of dynamic intellectual systems capable not only to make current diagnoses of diseases, but also to model development of diseases in time are briefly described. The latter allows you to optimize the prescribed courses of prevention and treatment of diseases. It is reported about the experience of creating a robot-doctor who performs diagnosis of diseases of the cardiovascular system, predicting the development of diseases, giving recommendations for optimizing the lifestyle and taking some medications. An example of the work of a robot-doctor is given. The robot-doctor diagnoses and predicts the development of cardiovascular diseases for three patients who differ, differing in age and sex characteristics, way of life and history. As follows from the forecasts, the same recommendations can have a different effect for each individual patient. It is noted that the robot-doctor when issuing forecasts and recommendations, takes into account the characteristics of the patient’s body, which is not always able to do a natural doctor.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-33491-8_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-23132-3_47,Training a Four Legged Robot via Deep Reinforcement Learning and Multibody Simulation,Multibody Dynamics 2019,10.1007/978-3-030-23132-3_47,Springer,2020-01-01,"In this paper we use the Proximal Policy Optimization (PPO) deep reinforcement learning algorithm to train a Neural Network to control a four-legged robot in simulation. Reinforcement learning in general can learn complex behavior policies from simple state-reward tuples datasets and PPO in particular has proved its effectiveness in solving complex tasks with continuous states and actions. Moreover, since it is model-free, it is general and can adapt to changes in the environment or in the robot itself. The virtual environment used to train the agent was modeled using our physics engine Project Chrono . Chrono can handle non smooth dynamics simulation allowing us to introduce stiff leg-ground contacts and using its Python interface Pychrono it can be interfaced with the Machine Leaning framework TensorFlow with ease. We trained the Neural Network until it learned to control the motor torques, then various policy Neural Network input state choices have been compared.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-23132-3_47,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-50729-9_22,A Robot Agent that Learns Group Interaction Through a Team-Based Virtual Reality Game Using Affective Reward Reinforcement Learning,HCI International 2020 - Posters,10.1007/978-3-030-50729-9_22,Springer,2020-01-01,"In the near future, robots are expected to be integrated into people’s lives, interacting with them. To develop better robotics and artificial intelligence, this research focuses on the concept of teamwork. A robot agent was implemented in a virtual reality(VR) game to play the sport roundnet, a team-based sport similar to table tennis and volleyball [ 2 ]. The agent is trained with reinforcement learning with EDA skin sensor data [ 6 ] of players. The system is evaluated using a questionnaire on the player’s feeling during the experiment and compared with agents not trained with affective data. The system is implemented in Unity3D’s ML-Agents Toolkit.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-50729-9_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-08277-2_8,"Robotics, Artificial Intelligence, and the Evolving Nature of Work",Digital Transformation in Business and Society,10.1007/978-3-030-08277-2_8,Springer,2020-01-01,"Most people in the future will not need to work, at least in the ways in which we continue to think about work/human labour. In this chapter, we discuss the role of humans in the future economy. We begin with a discussion of the evolution of the integration of robots into the economy. Then, we turn our attention to the economics of robotics and artificial intelligence, showing how these technological changes alter the economy and how markets and political responses may unfold. Then we discuss how humans can remain competitive in the new economy, developing skills that are needed, and how educational institutions will have to change to address the new economic reality. Finally, we conclude, showing that humans will have to see their relationship to the job market differently and there will have to be an appropriate political response to the new economic landscape with changes in taxation and new ways of ensuring economic and political stability.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-08277-2_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-48791-1_22,Semantic Segmentation of Vineyard Images Using Convolutional Neural Networks,Proceedings of the 21st EANN (Engineering Applications of Neural Networks) 2020 Conference,10.1007/978-3-030-48791-1_22,Springer,2020-01-01,"This paper aims to study the segmentation demands of vineyard images using Convolutional Neural Networks (CNNs). To this end, eleven CNN models able to provide semantic segmented images are examined as part of the sensing subsystem of an autonomous agricultural robot. The task is challenging due to the similar color between grapes, leaves and image’s background. Moreover, the lack of controlled lighting conditions results in varying color representation of grapes and leaves. The studied CNN model architectures combine three different feature learning sub-networks, with five meta-architectures for segmentation purposes. Investigation on three different datasets consisting of vineyard images of grape clusters and leaves, provided segmentation results, by mean pixel intersection over union (IU) performance index, of up to 87.89% for grape clusters and 83.45% for leaves, for the case of ResNet50_FRRN and MobileNetV2_PSPNet model, respectively. Comparative results reveal the efficacy of CNNs to separate grape clusters and leaves from image’s background. Thus, the proposed models can be used for in-field applications for real-time localization of grapes and leaves, towards automation of harvest, green harvest and defoliation agricultural activities by an autonomous robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-48791-1_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-63955-6_13,Research on Multi-agent Robot Behavior Learning Based on Fuzzy Neural Network,"e-Learning, e-Education, and Online Training",10.1007/978-3-030-63955-6_13,Springer,2020-01-01,"Human behavior or motion is diverse and complex. In order to design a robot with better sensitivity and better performance, it is necessary to set up multiple control nodes to facilitate the control robot to imitate the trajectory of human motion. However, due to the traditional robot behavior learning method, the control nodes are relatively single, and there is no clear behavior target node for the reference object, which leads to a large deviation in the robot behavior learning trajectory. Therefore, a fuzzy neural network-based Multi-agent robot behavior learning method. This method is based on the fuzzy neural network to control the behavior of robot. By optimizing the learning parameters of robot behavior, it can enhance the search program of behavior learning. According to the multi-level robot behavior learning model, it can identify the master-slave target of reference object and realize a more accurate multi-agent robot behavior learning method. The test results show that compared with the traditional method, the behavior trajectory of the proposed method is basically consistent with the behavior trajectory of the reference object. It can be seen that the method has better performance and meets the research requirements at the current stage.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-63955-6_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-32-9682-4_40,Neural Network Based Adaptive Backstepping Control of Uncertain Flexible Joint Robot Systems,Proceedings of 2019 Chinese Intelligent Systems Conference,10.1007/978-981-32-9682-4_40,Springer,2020-01-01,"For flexible joint (FJ) robotic systems with uncertainties, a command filter based backstepping control is proposed in this paper. Through the control scheme, an adaptive controller is constructed to track desired position. In order to overcome complex computation problem in backstepping technology, a command filter is used, and the filtering error compensation is further defined. To deal with the uncertain dynamics of flexible joint robot system, the neural network approximation technology is adopted. The simulation results of FJ robot are given to show the effectiveness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-32-9682-4_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-019-0155-1,Adaptive Neural Network Fast Fractional Sliding Mode Control of a 7-DOF Exoskeleton Robot,"International Journal of Control, Automation and Systems",10.1007/s12555-019-0155-1,Springer,2020-01-01,"To rehabilitate individuals with impaired upper limb (UL) functions due to neurological disorders, this research focuses on trajectory tracking control (representing passive rehabilitation exercise) of a 7 DOFs exoskeleton robot named ETS-MARSE. It is a redundant type of robotic manipulator having a very complex structure which is designed based on human UL joint articulations. The exoskeleton is constantly encountered with external disturbances and unknown dynamics such as friction forces, and backlash which is hard to model. Moreover, this type of robot needs to deal with the unknown dynamics of a wide range of subjects with different degrees of UL impairments. Therefore, to deal with this modeling uncertainty, in this paper we propose a novel adaptive neural network fast fractional integral terminal sliding mode control (ANFFITSMC) approach to maneuver the ETS-MARSE to provide passive arm movement therapy. To address the chattering phenomena which are observed in the fast fractional integral terminal sliding mode control (FFITSMC), a new adaptive radial basis function neural network (ARBFN) is incorporated with the FFITSMC. The Lyapunov theory is used in order to prove the stability of the proposed controller. Simulation results validated the efficient performance of the ANFFITSMC in terms of chattering reduction and trajectory tracking.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-019-0155-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-51005-3_5,Intelligent Playful Environments in New Urban Social Landscape,Science and Technologies for Smart Cities,10.1007/978-3-030-51005-3_5,Springer,2020-01-01,"The concept of Smart Cities are giving lots of opportunities for using technology to make citizens heathier and happier in the future cities. Recent development of artificial intelligence and its capacity to support people in creative and learning processes can be crucial factor in changing social landscape and lead to novel social innovations. In this paper, we are presenting art/research projects, and design experiments of interactive designer Predrag K. Nikolic exposed in various public spaces within the period of last ten years. The conceptual idea behind the projects has been to affect human behavior through novel interactions within playful mix realities and lastly in artificial reality (AIR) as new user experience phenomena in a new urban social landscape.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-51005-3_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-36150-1_35,Using a Collaborative Robot to the Upper Limb Rehabilitation,Robot 2019: Fourth Iberian Robotics Conference,10.1007/978-3-030-36150-1_35,Springer,2020-01-01,"Rehabilitation is a relevant process for the recovery from dysfunctions and improves the realization of patient’s Activities of Daily Living (ADLs). Robotic systems are considered an important field within the development of physical rehabilitation, thus allowing the collection of several data, besides performing exercises with intensity and repeatedly. This paper addresses the use of a collaborative robot applied in the rehabilitation field to help the physiotherapy of upper limb of patients, specifically shoulder. To perform the movements with any patient the system must learn to behave to each of them. In this sense, the Reinforcement Learning (RL) algorithm makes the system robust and independent of the path of motion. To test this approach, it is proposed a simulation with a UR3 robot implemented in V-REP platform. The main control variable is the resistance force that the robot is able to do against the movement performed by the human arm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-36150-1_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-63955-6_5,Evaluation Model of Aquaculture Robot Technology Research Project Based on Machine Learning,"e-Learning, e-Education, and Online Training",10.1007/978-3-030-63955-6_5,Springer,2020-01-01,"With the increase of research projects of aquaculture robot technology, how to evaluate the research projects of aquaculture robot technology effectively has become the primary task in the research process. However, in the use of the original evaluation model, the problem of improper selection of the index range often occurred. Therefore, the evaluation model of aquaculture robot technology research project based on machine learning is designed. Obtain the evaluation index of aquaculture robot technology project, calculate the index weight to build the evaluation index system, use machine learning algorithm to complete the collection of evaluation samples, and use the above settings to build the evaluation model of aquaculture robot technology research project. At this point, the evaluation model of the aquaculture robot technology research project based on machine learning has been designed. In order to verify the effect of the design model in this article, design a comparison experiment, evaluate the design model and the original model on a project. It can be seen through comparative experiments, it is known from experimental comparison that this model is better than the original model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-63955-6_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-50334-5_27,Social Dynamics in Human-Robot Groups – Possible Consequences of Unequal Adaptation to Group Members Through Machine Learning in Human-Robot Groups,Artificial Intelligence in HCI,10.1007/978-3-030-50334-5_27,Springer,2020-01-01,"Social robots designed to live and work with humans will have to recognize, learn from, and adapt to multiple users, since humans live and organize themselves in groups. Social robots must consider the social dynamics that arise when humans interact in groups as well as the social consequences of their own behaviour in these groups. When trying to automatically adapt to its users, a robot might unintentionally favour one human group member. For instance, when in a work setting, a robot’s implemented goal is to maximize team performance, it might decide to distribute more resources to those team members who are identified as high performers in the task, thereby discriminating low performers. Algorithm-based learning and decision-making can result in unequal treatment, intergroup bias and social exclusion of team members with severe negative outcomes for the emotional state of the individual and the social dynamics in the group. In this paper, we advocate for systematically investigating ingroup identification and intergroup bias in human-robot group interactions and their possible negative effects for individuals such as feelings of rejection, social exclusion, and ostracism. We review theories from social psychology on groups and outline future research lines to investigate social dynamics in human-robot mixed teams from the perspectives of psychology and computer science.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-50334-5_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-08277-2_13,Artificial Intelligence and Robotics Technology in the Hospitality Industry: Current Applications and Future Trends,Digital Transformation in Business and Society,10.1007/978-3-030-08277-2_13,Springer,2020-01-01,"This study explores the application of artificial intelligence (AI) and robotics technology in the hospitality industry. After reviewing and evaluating research and articles, currently, robotics technology has been broadly applied into hotel, food and beverage, and meeting and convention; these are the three major segments in the hospitality industry. The impacts of AI and robotics technology on workforce, customers, and corporations are examined. Further, the authors explore the potential use of artificial intelligence (AI) and robotics technology. In the end of this literature review, the factors and the risks of robot industry are discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-08277-2_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-14544-6_9,Robotics and Industry 4.0,"A Roadmap to Industry 4.0: Smart Production, Sharp Business and Sustainable Development",10.1007/978-3-030-14544-6_9,Springer,2020-01-01,"Industry 4.0 also known as fourth revolution is a new era in which industry will deal with technologies like Robotics, Automation, Artificial Intelligence (AI), and many more. The adoption of robots in Industries worldwide is on the high rise. Robots and human both have their own strengths and limitations. Working together in safe manner both will provide better quality product with high accuracy in less time. The main aim of Robotics and Industry 4.0 is to improve productivity, produce high quality product at low price and meet customer expectation. In this chapter we have discussed role of Robotics and Automation in Industry 4.0, pros and Cons of Robotics in Industry 4.0, various challenges and its applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-14544-6_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-60337-3_8,Collision Detection in the Work of Collaborative Robots Using an Intelligent System,Interactive Collaborative Robotics,10.1007/978-3-030-60337-3_8,Springer,2020-01-01,"This paper describes an approach to applying the JSM method for automatic recognition of collision situations when working with collaborative robots. The approach uses the description of situations in the form of a set of primitives that determine the position of a person in the work space and allow you to distinguish a person from surrounding objects. An intelligent JSM system requires training that can be realized in real time. In the course of experiments, the efficiency of the proposed approach was confirmed and estimates of the collision detection time were made.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60337-3_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-13-9217-7_14,A Developmental Robotic Paradigm for Mobile Robot Navigation in an Indoor Environment,Machine Learning-based Natural Scene Recognition for Mobile Robot Localization in An Unknown Environment,10.1007/978-981-13-9217-7_14,Springer,2020-01-01,"In general, traditional machine learning algorithms typically employ task-specific methods and only the parameters pre-determined by the human programmer are updated. These methods often fail to respond to the dynamically changing states of the uncontrolled environments. Additionally, such methods may not represent a developmental entity, such as a human mind. In contrast, an open-ended developmental robot system can learn simple behaviors and buildup more complex behaviors by utilizing the previously learned behaviors. In this chapter, we propose a basic framework for visual learning tasks that integrates a perceptual system into a biologically inspired working memory system. A main objective of this research is to provide a general framework for developmental learning and to investigate how well a neuro-computational PFC working memory model performs on a robotic platform in a real-world environment with complex tasks. Experiments conducted show impressive results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-9217-7_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-63486-5_33,An Incremental Learning Approach for Physical Human-Robot Collaboration,Towards Autonomous Robotic Systems,10.1007/978-3-030-63486-5_33,Springer,2020-01-01,"Physical Human-Robot Collaboration requires humans and robots to perform joint tasks in a shared workspace. Since robot’s characteristic strengths are to cope well with high payloads, they are utilized to assist human operators during heavy pulling or pushing activities. A widely used sensor to detect human muscle fatigue and thus, to trigger an assistance request, is an Electromyography (EMG). Many previous approaches to process EMG data are based on training Machine Learning models offline or include a large degree of manual fine tuning. However, due to recent advances in Machine Learning such as incremental learning, there is an opportunity to apply online learning which reduces programming effort and also copes well with subject specific characteristics of EMG signals. Initial results show promising potential, yet, unveil a conflict between convergence time and classification accuracy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-63486-5_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-46828-6_2,AI-Based Farm Survey Technique for Efficient Fruit Harvesting,Security with Intelligent Computing and Big-Data Services 2019,10.1007/978-3-030-46828-6_2,Springer,2020-01-01,"Strawberry farming is labor intensive and time critical. Farmers need to harvest ripe fruit within 2–3 days, and the size of their farms makes it extremely difficult to accurately survey the farm and determine the optimal harvest time for strawberries. As a result, farmers employ fixed labor and pick their crop three times a week, often incurring losses due to this inefficient system. Image recognition service and machine learning can be used to solve this problem by analyzing the farm and more accurately determining the optimal time and labor requirements for an efficient harvest. However, off-the shelf image recognition models [ 1 , 2 ] perform poorly with low accuracy and recall scores when identifying strawberries, as they have not been trained with datasets that reflect farm conditions such as daylight or terrain. The solution proposed here identifies strawberries through a custom Convolutional Neural Network (CNN) trained with images of an actual strawberry farm. The proposed solution provides farmers more information about the state of the farm and can be used in conjunction with a drone or robot to more effectively survey and analyze the farm to plan the harvest procedures. Future work includes using this solution with a fruit-picking robot to further decrease labor costs and increase efficiency.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-46828-6_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-41913-4_12,Learning Patterns for Complex Event Detection in Robot Sensor Data,Optimization and Learning,10.1007/978-3-030-41913-4_12,Springer,2020-01-01,"We present an approach for learning patterns for Complex Event Processing (CEP) in robot sensor data. While the robot executes a certain task, sensor data is recorded. The sensor data recordings are classified in terms of events or outcomes that characterize the task. These classified recordings are then used to learn simple rules that describe the events using a simple, domain specific language, in a human-readable and interpretable way.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-41913-4_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-36674-2_23,Design of a Mini Robot for the Automation of 3D Winding Machines Axes and Self-correction by Artificial Vision Using Deep Learning,Advanced Intelligent Systems for Sustainable Development (AI2SD’2019),10.1007/978-3-030-36674-2_23,Springer,2020-01-01,"Object recognition is among the most important subjects in computer vision, it has undergone a huge evolution during these last decades, but in the last years artificial intelligence has seen the appearance of Deep Learning, and through the efforts of researchers, Deep Learning is having great success, its applications have touched on different fields, such as robotics, industry, automotive. In this context, in collaboration with an Automotive components manufacturer and FST faculty of sciences and technologies of tangier (UAE University) they have taken the initiative to develop an object recognition and self-correction system for a winding machine that requires a good accuracy of location of the needle using the Deep Learning which is the purpose of this paper. This report summarizes the work done within this Company concerning the development and implementation of a system for automating and self-correcting the location of the needles of winding machines using artificial vision with Deep learning. The convolutional neural networks have become advanced methods for classification and detection of objects over the last five years. At present, they work better than conventional image processing method set, on many image classification data sets. Most of these datasets are based on the notion of concrete classes. In this paper, we present a new set of image classification data as well as object detection data, which should be easy for humans to solve, but its variations are difficult for CNN. The classification performance of popular CNN architectures is evaluated on this dataset and variations of this dataset may be of interest for future research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-36674-2_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-58920-2_14,Model-Based Error Detection for Industrial Automation Systems Using LSTM Networks,Model-Based Safety and Assessment,10.1007/978-3-030-58920-2_14,Springer,2020-01-01,"The increasing complexity of modern automation systems leads to inevitable faults. At the same time, structural variability and untrivial interaction of the sophisticated components makes it harder and harder to apply traditional fault detection methods. Consequently, the popularity of Deep Learning (DL) fault detection methods grows. Model-based system design tools such as Simulink allow the development of executable system models. Besides the design flexibility, these models can provide the training data for DL-based error detectors. This paper describes the application of an LSTM-based error detector for a system of two industrial robotic manipulators. A detailed Simulink model provides the training data for an LSTM predictor. Error detection is achieved via intelligent processing of the residual between the original signal and the LSTM prediction using two methods. The first method is based on the non-parametric dynamic thresholding. The second method exploits the Gaussian distribution of the residual. The paper presents the results of extensive model-based fault injection experiments that allow the comparison of these methods and the evaluation of the error detection performance for varying error magnitude.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58920-2_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-11292-9_20,Object Detection and 6D Pose Estimation for Precise Robotic Manipulation in Unstructured Environments,"Informatics in Control, Automation and Robotics",10.1007/978-3-030-11292-9_20,Springer,2020-01-01,"In this paper we present an algorithm for the robust 6D pose estimation with an RGB-D camera in harsh and unstructured environments using object detection. While the pose estimation uses clustering and segmentation to find a robust point in multiple frames to track changes in the position of the camera, its functionality is enhanced with Faster-RCNN for classification and detection, providing the operator with information about the object of interest. This work further facilitates the goal of increasing the robot’s autonomy and helping operators to recover 3D reconstructions of the objects to be manipulated with the robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-11292-9_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-48989-2_26,A Boosted Decision Tree Approach for a Safe Human-Robot Collaboration in Quasi-static Impact Situations,Advances in Service and Industrial Robotics,10.1007/978-3-030-48989-2_26,Springer,2020-01-01,"According to the ISO/TS 15066, human safety in quasi-static impact situations in human-robot collaboration is assessed first by identifying all high-risk impact situations and then by measuring maximal and steady-state values the impact force and pressure at these possibly critical situations. This means that if something is changed in a collaborative application, the ISO/TS 15066 requires that the risk analysis and the force measurements must be redone, which severely limits the flexibility of a robotic system. In this paper, a physics guided boosted decision tree is proposed as a tool to assess human safety. The basic hypothesis is that a physics guided boosted decision tree can be trained to estimates the peak impact force for a given impact velocity, robot configuration, an impact point on the robot and a human body part. Based on experimental measurements done with the Universal Robots UR10e and on a simple mathematical model of an impact between a point on a robot and a point on a human body part, a feature vector is generated as an input to the boosted decision tree. After the training using Matlab’s Least-squares boosting algorithm, the boosted decision tree can predict the measured peak impact force with a relative error of less than 9% thus supporting the basic hypothesis. However, the predictions of the trained boosted decision tree are valid only for the case of a quasi-static impact in a vertical direction between a robot’s end-effector and a back of human’s non-dominant hand.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-48989-2_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-05324-6_112-1,Robotics in Tourism and Hospitality,Handbook of e-Tourism,10.1007/978-3-030-05324-6_112-1,Springer,2020-01-01,"This chapter provides a comprehensive review of robotics in tourism and hospitality, including the technical foundations of robotics, synthesis of academic literature, and current and potential applications. Robots may be defined as programmable, intelligent devices, with a certain degree of autonomy, mobility, and sensory capabilities, designed to perform a certain task. Distinguishing between industrial and service robots, the chapter focuses on the category of service robots that perform useful tasks for humans in the tourism and hospitality industry. The chapter begins with the review of relevant studies and addresses both engineering and social sciences perspectives. The latter is evaluated deeper by looking at conceptual and empirical research. The chapter presents applications of robots across different segments of the tourism and hospitality industry, including hotels (e.g., front desk agents, concierges, delivery robots, porters, and housekeepers), restaurants (e.g., cook assistants, hosts, wait staff, food runners, bartenders, and robots delivering food), events (e.g., guest entertainment and physical presence for virtual attendees), attractions (e.g., museums), and travel (e.g., airports, autonomous vehicles). This book chapter investigates the issues related to robot adoption by tourism and hospitality companies from two perspectives: the supply- and the demand-side. From the supply-side perspective, the chapter evaluates the economics of robotics in tourism and hospitality, presents analysis of financial and non-financial costs and benefits, discusses employee resistance towards robotic labor, and outlines considerations for designing robot-friendly facilities. From a demand-side perspective, the chapter elaborates on customer attitudes towards the use of robots by tourism and hospitality companies, human-robot interaction, and customer willingness to pay for robot-delivered services. The chapter concludes by looking at future opportunities for robotization and research directions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-05324-6_112-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-24074-5_6,"AI, Robots and IPRs – An Approach to Ownership",Inclusive Robotics for a Better Society,10.1007/978-3-030-24074-5_6,Springer,2020-01-01,"Nowadays, Artificial Intelligence (AI) is tangible and not just the imaginings of a Sci-fi novelist.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-24074-5_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-51999-5_3,Towards the Edge Intelligence: Robot Assistant for the Detection and Classification of Human Emotions,"Highlights in Practical Applications of Agents, Multi-Agent Systems, and Trust-worthiness. The PAAMS Collection",10.1007/978-3-030-51999-5_3,Springer,2020-01-01,"Deep learning is being introduced more and more in our society. Nowadays, there are very few applications that do not use deep learning as a classification tool. One of the main application areas is focused on improving people’s life quality, allowing to create personal assistants with canned benefits. More recently, with the proliferation of mobile computing and the emergence of the Internet of Things (IoT), billions of mobile and IoT devices are connected to the Internet. This allows the generation of millions of bytes of information about sensors, images, sounds, etc. Driven by this trend, there is an urgent need to push the IoT frontiers to the edge of the network, in order to decrease this massive sending of information to large exchanges for analysis. As a result of this trend, a new discipline has emerged: edge intelligence or edge AI, a widely recognised and promising solution that attracts with special interest to the community of researchers in artificial intelligence. We adapted edge AI to classify human emotions. Results show how edge AI-based emotion classification can greatly benefit in the field of cognitive assistants for the elderly or people living alone.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-51999-5_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-7297-5_10,Conclusion,"Pop with Gods, Shakespeare, and AI",10.1007/978-981-15-7297-5_10,Springer,2020-01-01,"This monograph applies the theories to interpreting (musical) theatre, films, and TV drama. Chapter 2 interprets Shakespeare’s Romeo & Juliet in films and pop music. Chapter 3 analyzes Habitus and Spectacle in Korean Film Along with the Gods by cinematic 3D special effects and CGI. Chapter 4 explores myth imagination by Levi-Strauss’ anthropology on Taiwan musical Classic of Mountain and Sea and Chinese Film The Monkey King . Chapter 5 on face, race, identity, etc. in Yellow Face , Cats , The Lion King , War Paint , and Jekyll & Hyde & So On . Chapter 6 women’s revenge in Chicago and The Visit . Chapter 7 explores Chinese TV drama Story of Yanxi Palace . Chapter 8 explores “play-within-the-play” in Hakka Theater Roseki . Chapter 9 on Robot Theatre and AI Films.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-7297-5_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-36150-1_51,A Review of Segmentation Methods for 3D Semantic Mapping,Robot 2019: Fourth Iberian Robotics Conference,10.1007/978-3-030-36150-1_51,Springer,2020-01-01,"A 3D semantic map can be defined as a grid-based representation of the environment, where each bin stores a probability distribution over the possible elements to be found in it. This probability distribution can be obtained with any state-of-the-art image classifier, while the 3D position depends on the localization accuracy of the robot, the sensitivity of its RGB-D sensor, and the segmentation of the input image. In this paper, we focus on this last factor, to explore different options for image segmentation that might improve 3D maps. We will compare various approaches based on the use of 2D and 3D information to find relevant clusters of information. They will be evaluated to assess their suitability for real-time applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-36150-1_51,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-63823-8_79,Adaptive Neural Control for Efficient Rhythmic Movement Generation and Online Frequency Adaptation of a Compliant Robot Arm,Neural Information Processing,10.1007/978-3-030-63823-8_79,Springer,2020-01-01,"In this paper, we propose an adaptive and simple neural control approach for a robot arm with soft/compliant materials, called GummiArm. The control approach is based on a minimal two-neuron oscillator network (acting as a central pattern generator) and an error-based dual integral learning (DIL) method for efficient rhythmic movement generation and frequency adaptation, respectively. By using this approach, we can precisely generate rhythmic motion for GummiArm and allow it to quickly adapt its motion to handle physical and environmental changes as well as interacting with a human safely. Experimental results for GummiArm in different scenarios (e.g., dealing with different joint stiffnesses, working against elastic loads, and interacting with a human) are provided to illustrate the effectiveness of the proposed adaptive neural control approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-63823-8_79,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-49183-3_11,A Framework for Human-Autonomy Team Research,Engineering Psychology and Cognitive Ergonomics. Cognition and Design,10.1007/978-3-030-49183-3_11,Springer,2020-01-01,"On a team, autonomy must be able to work alongside human counterparts and carry out the fundamentals of teamwork and taskwork. In this paper we refer to these machine teammates as autonomy. These Human-Autonomy Teams (HATs) need to be assembled to have the appropriate roles and responsibilities and to interact in an interdependent manner. One challenge in assembling an effective Human-Autonomy Team involves doing research on human-autonomy teaming that can provide input to autonomy development BEFORE the autonomy is developed. We propose here a five-step process to doing HAT research and provide four examples of the application of this process. The five steps involve 1) knowledge elicitation to determine the essential aspects of HAT in a given domain, 2) development of a synthetic task environment with Wizard of Oz capability, 3) development of measurement strategies, 4) human subject experimentation, and 5) translation to the developers of artificial intelligence and robots that will serve as teammates.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-49183-3_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-39165-2_24,Special Session: Rise of the Service Robots: Exploring Consumer Acceptance: An Abstract,Marketing Opportunities and Challenges in a Changing Global Marketplace,10.1007/978-3-030-39165-2_24,Springer,2020-01-01,"Due to rapid developments of service robots, artificial intelligence and other new technologies (including big data, analytics, speech recognition, biometrics, mobile and cloud technologies, and geo-tagging) the service sector is facing a new wave of digitalization, including at the customer interface. Service robots, defined as system-based autonomous and adaptable interfaces that interact, communicate and deliver service to an organization’s customers (Wirtz et al. 2018), will bring opportunities for a wide range of service innovations that will dramatically impact the customer experience, service quality, and productivity all at the same time (e.g., many hotel, restaurant and hair stylist services are likely to be robot-delivered in the future), lower cost will make high-end services available to the broad consumer base (e.g., personal concierge services, image consulting, and high-end personal tuition), while potentially offering new services we have not thought of yet (Wirtz and Lovelock 2016). This study explores how consumers perceive and respond to service robots. Based on conceptual and empirical data, we fine-tune and further develop an integrated framework: the service robot acceptance model (sRAM) and present a future research agenda (Wirtz et al. 2018). In the second part, we highlight that as service robotics are likely to impact all strata of society, important ethical and societal implications have to be considered. The purpose of ethics is the improvement of the general well-being of all participants in society. It especially focuses on protecting and improving personal integrity and human dignity, makes sure that the rights of the weakest in society are protected and aims at limiting possible inequalities caused by the advancement of service robotics. Our presentation will discuss crucial challenges at the micro (customers), meso (markets and organizations), and macro (society) level of analysis. Seeing the pervasiveness of service robots in the future, we also draw a number of potential approaches for these challenges from the literature and apply them to the service robotics context to provide several thought-provoking recommendations for the way forward.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-39165-2_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-1286-5_35,Cognitive Services Applied as Student Support Service Chatbot for Educational Institution,International Conference on Innovative Computing and Communications,10.1007/978-981-15-1286-5_35,Springer,2020-01-01,"Many software companies try to build at least simple FAQ/Q&A based chatbot recently. Recent works shows that it is really easy to build a bot while to build intelligent one could be an extremely hard. Domain specific bots like AI driven Support Center Automation Bots should consider to be interoperable on many levels and with every new level, level of complexity grows exponentially. In recent years, messaging apps overtaken social networks and become the dominant platforms on smart phones. That enormous potential should be considered to solve one of the issues that any organization larger than 10 participants has. Combining various existing and external data sources company already have access to, most of the first-and second-line helpdesk questions could be resolved before they came to support service staff. Robotic Process Automation (RPA) is one of hottest topics among business process experts while one of the fastest growing fields of RPA is Knowledge Mining which is especially applicable in Educational (EDU) environment like any kind of EDU Support System. This paper cover experience in building Chatbot as the effective interface for student support.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-1286-5_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-33950-0_5,Understanding and Transfer of Human Skills in Robotics Using Deep Learning and Musculoskeletal Modeling,Proceedings of the 2018 International Symposium on Experimental Robotics,10.1007/978-3-030-33950-0_5,Springer,2020-01-01,"With the application of deep learning, prosthetic rehabilitation can be carried out in a manner that not only emulates human manipulation skills and performance, but can also work more efficiently. In this study, we introduced computer vision capability for a rehabilitation robot using a convolutional neural network (CNN). The human skill of scooping was studied by dividing it into four motion primitives or sub-tasks. For each primitive, optimum human posture was identified in terms of muscular effort. Human motion skills were analyzed in terms of physiological parameters, including wrist pronation-supination angle, elbow flexion angle, shoulder rotation/abduction/flexion angles, and hand accelerations by three dimensional musculoskeletal modeling. This analysis identified how humans execute the same activity for eight different materials. Optimum human motion for each material was mapped to a robotic arm with six degrees-of-freedom (DOFs), which was equipped with a camera. The success ratio while examining the scooping motion over all trials was found to be 85%. Consequently, the activity can be performed efficiently based on human intuition in a dynamic environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-33950-0_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-64313-3_18,From Models of Cognition to Robot Control and Back Using Spiking Neural Networks,Biomimetic and Biohybrid Systems,10.1007/978-3-030-64313-3_18,Springer,2020-01-01,"With the recent advent of neuromorphic hardware there has been a corresponding rise in interest in spiking neural network models for the control of real-world artificial agents such as robots. Although models of cognitive mechanisms instantiated in spiking neural networks are nothing new, very few of them are translated onto real robot platforms. In this paper, we attempt such a translation: we implement an existing, biologically plausible model of reaching (the REACH model) demonstrated in 2D simulation on a UR5e robot arm. We are interested in particular in how well such a translation works since this has implications for similar exercises with a vast library of existing models of cognition. In this particular case, after extensions to operations in 3D and for the particular hardware used, we do find that the model is able to learn on the real platform as it did in the original simulation, albeit without reaching the same levels of performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-64313-3_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-23946-6_5,Predicting the Error of a Robot’s Positioning Repeatability with Artificial Neural Networks,"Distributed Computing and Artificial Intelligence, 16th International Conference, Special Sessions",10.1007/978-3-030-23946-6_5,Springer,2020-01-01,"Industrial robots are an integral part of modern manufacturing systems. In order to fully use their potential, the information related to the robot’s accuracy should be known first of all. In most cases, the information considering robot’s errors, provided in a technical specification, is scarce. That’s why, this paper presents the issues of determining the error of industrial robots positioning repeatability. A neural mathematical model that allows for predicting its value with the error less than 5% was designed. The obtained results were compared to a classical mathematical model. It was revealed that a well-trained neural network enables the prediction of the error of positioning repeatability with the doubled accuracy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-23946-6_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-19648-6_18,Neural Adaptive Control of a Robot Joint Using Secondary Encoders,Advances in Service and Industrial Robotics,10.1007/978-3-030-19648-6_18,Springer,2020-01-01,"This paper aims to reduce gearbox errors on industrial robots with a feed forward, neural adaptive control. The algorithm combines two networks, one for control and one for system identification. In order to achieve a high precision and generality on untrained data, a Runge-Kutta Neural Network is used for black-box identification of a nonlinear robot joint. Secondary encoders as additional angle sensors measure the gearbox error and are used for supervised learning. The presented algorithm is capable of online application and reduces gearbox errors in a nonlinear simulation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-19648-6_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-60117-1_16,A Sociable Robotic Platform to Make Career Advices for Undergraduates,HCI International 2020 - Late Breaking Papers: Multimodality and Intelligence,10.1007/978-3-030-60117-1_16,Springer,2020-01-01,"Most of the undergraduates couldn’t figure out a proper direction for their future careers since advising depends on the person and students show aversion in revealing their information to other humans. This research focused on creating a social robotic platform to interact with undergraduates in the field of computer science to realize possible career paths, as recent researches show social companion robots tend to form a stronger bond, which helps the addressee to share their information easily. The robot was created as a tabletop robot employing minimalistic design with a friendly view attached with speech synthesis for communicating purposes. Data was collected from 202 persons, who followed a degree in computer science. Data contains their experience, qualifications, and skills. Thereafter an artificial neural network was created using supervised learning to predict the career path with 95% performance accuracy. The experiment was performed by engaging 15 students from the final year who are a doing degree in computer science and they were asked to provide feedback on the interactions with the robot. The gathered responses highlighted robot animacy, interaction, technology and usefulness. Therefore, from the results it can be concluded that a majority of the students accepted the robot, interacted without hesitation and had friendly conversations with the robot where they valued the generated output from the robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60117-1_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-5959-4_101,Control Method of Bionic Robot,Innovative Computing,10.1007/978-981-15-5959-4_101,Springer,2020-01-01,"With the rapid development of computer technology, biological engineering and artificial intelligence, robot technology has made a significant breakthrough. Bionic robots have made great progress. Robot technology includes computer, artificial intelligence, machinery, electronics and sensors. The application field of robot expands continuously after years of development. In this paper, the robot technology is introduced, the research status of the robot platform is explained, the control method of the robot is studied and the application prospect of the bionic robot is analyzed. Finally, it is pointed out that the motion control method and control theory of the bionic robot need to be studied more and more, so as to further improve the theoretical research basis and make greater breakthroughs in the realization of technology and motion control method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-5959-4_101,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-3867-4_35,Exploring the Formalization of Brain Cognition in the Age of Artificial Intelligence,"Advances in 3D Image and Graphics Representation, Analysis, Computing and Information Technology",10.1007/978-981-15-3867-4_35,Springer,2020-01-01,"In the contemporary society where the Internet has almost reached its peak, artificial intelligence has gradually become an important proposition for the development of science and technology. From the traditional perspective, people’s cognition of the brain is limited to the human point of view, but in the era of artificial intelligence, due to the large number of robots, people will deal with artificial intelligence in a wide range of daily life. In this context, it is clear that the current human cognition of the brain will gradually be eliminated and replaced with the breakthrough of artificial intelligence technology. The problem of brain cognition was widely recognized and heatedly discussed by scientists as early as 1956. In the modern era, with the maturity of science and technology, the problem of the formalization of brain cognition will also be redefined with the advent of the artificial intelligence era. This article starts the relevant discussion and hopes to contribute to the in-depth discussion of the problem of formal cognition of brain cognition in China.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-3867-4_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-39319-9_7,Robotization in the Area of Labor and Employment: On the Verge of the Fourth Industrial Revolution,Artificial Intelligence: Anthropogenic Nature vs. Social Origin,10.1007/978-3-030-39319-9_7,Springer,2020-01-01,"Purpose : The particular aspects of the upcoming transformation in the area of labor and employment within the context of the new technological revolution are being examined in the article. Design/Methodology/Approach : This article with the use of available social, scientifically-educative and economic statistics, as well as on the basis of systematic and “look-ahead” methods covers the directions of transformation of social relations in the area of labor in the context of automation and robotization of manufacturing within the technological shift of the new age – the Fourth Industrial Revolution. Findings: The major conclusions formulated as the outcome of the conducted research can be structured in the following way: the anticipated result of the digital development of the economy in the upcoming years (before 2025) will be the widespread robotization (from manufacturing to agriculture, from retail sales to the service sector); this will require establishing additional arrangements for minimizing social risks related to the transformation of the area of labor (global labor market polarization leading to the ultimate displacement of the standard form of employment with its untypical forms like remote work, outsourcing, work in the “online platforms”, “cloud” etc.; high technological unemployment related to rejection of human resources in favor of intelligent robots and further decline of the salary level for remaining human workers etc.); mass robotization of manufacturing and services sector, including creation and introduction of artificial intelligence, over time will require solving the problems of necessity of introducing the status of electronic personality to intelligent robots, defining their legal capacity in the civil, labor and others fields of law which will lead to either the rejection of previously formulated principles of the legal regulations or their fundamental conversion; exponential paces of development of the new technological revolution will require the relevant legal formalization (legalization) newly originated public relations – including relations in the area of labor, employment, and social security – definition of their core, conceptual framework, and focused targeting. This process will be followed by increasing harmonization and integration of legal systems and the system of common values that will turn the Fourth Industrial Revolution into the new opportunities for all members of society. Originality/Value : The purpose of the study is to analyze the restructure of the labor market and the employment due to the widespread introduction of smart robots and artificial intelligence. Such analysis helped to develop a number of original ideas aimed at maintaining stable employment and preventing technological unemployment in the world and in the Russian Federation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-39319-9_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-36150-1_49,A Story-Telling Social Robot with Emotion Recognition Capabilities for the Intellectually Challenged,Robot 2019: Fourth Iberian Robotics Conference,10.1007/978-3-030-36150-1_49,Springer,2020-01-01,"In this paper, a story-telling social robot is proposed. The robot is able to modify the evolution of the story considering the emotions the audience is feeling. To do that, the robot uses the user’s emotion from his/her face. We have used a deep learning-based model to identify the emotion. This model was trained and tested on state of the art dataset. We also demonstrate that involving generated, realistic samples in the training process as a way of data augmentation does not benefit the model at all. The mentioned samples are generated by a state of the art GAN, which is able to translate neutral faces to a range of emotions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-36150-1_49,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-22438-7_41-1,Artificial Intelligence and Social Responsibility,The Palgrave Handbook of Corporate Social Responsibility,10.1007/978-3-030-22438-7_41-1,Springer,2020-01-01,"The text introduces basic concepts and problems of artificial intelligence and social responsibility under the perspective of robot ethics and machine ethics. It is composed of two sections. In sect. 1 concerning the relation of artificial intelligence (further on abbreviated as AI) and social responsibility (further on abbreviated as SR), three things are summarized, namely, basic issues surrounding the topic in sect. 1.1 , important concepts and their relations in sect. 1.2 , and a note on the literature in sect. 1.3 . In the sect. 2 three groups of issues are presented, analyzed, and discussed, namely, AI and fundamental morality and ethics in terms of SR in sect. 2.1 , AI and general principles of SR in sect. 2.2 , AI and particular types of SR regarding particular stakeholder groups of AI and particular AI in sect. 2.3 , and AI and its social implications in sect. 2.4 .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-22438-7_41-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-50722-0_22,Spine Tumors: Technological Advances,Surgical Spinal Oncology,10.1007/978-3-030-50722-0_22,Springer,2020-01-01,"The technological advances in spine surgery serve to support the surgeon through the preservation of the functionality of the spine during tumor resection. Numerous avenues of technology help achieve this goal. Three-dimensional printing allows for improved surgical planning of patient-specific complex anatomy and customized implants. There has been tremendous growth in the application of robotics in spine surgery. They aid surgeons by increasing the precision of instrumentation and navigation. In the realm of data analysis, machine learning has come to the forefront. Machine learning allows for complex analysis of big data to predict models such as patient survival following metastatic spine disease or risk factors for postoperative complications. Neural mapping technologies such as motor-evoked potentials assist spine surgeons by ensuring safe resection of tumors while maintaining nerve function. Intraoperative assistive technology includes augmented reality and fluorescence surgery, both of which allow for improved navigation and identification of complex anatomy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-50722-0_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-52060-1_4,Techno Service Worlds? Digitization of Service Businesses,Service Management,10.1007/978-3-030-52060-1_4,Springer,2020-01-01,"In this chapter, the focus is on exploring the role that technological innovation—including big data, robotics, artificial intelligence, online platforms and algorithms—has played in the emergence of new service business models and in new forms of service business and work. The emphasis is on the digitization of service operational processes and their impacts. This is a tension between the role service workers play in creating and delivering service experiences through face-to-face encounters versus the substitution of service workers by technology. On the one hand, service customization and the quality of a service experience is still founded around interactions between service producers and service consumers. On the other hand, there is the emergence of service encounters in which service workers are a hidden rather than a visible part of the service experience. Reading and managing service businesses must include an appreciation of the ways in which technological innovation is transforming the management of service businesses.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-52060-1_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-24074-5_5,Inclusive Robotics and AI – Some Urgent Ethical and Societal Issues,Inclusive Robotics for a Better Society,10.1007/978-3-030-24074-5_5,Springer,2020-01-01,"Many discussions about robotics and Artificial Intelligence (AI) focus on far future scenarios such as superintelligence, but for the near future ethics of robotics AI it is necessary to think about more concrete ethical issues that pervade the daily use of the technologies. This talks gives a very brief overview of ethical and societal issues raised by robotics and AI, with a focus on inclusive robotics. It also offers some remarks on robot and AI policy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-24074-5_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-6572-4_8,COVID-19: Loose Ends,Intelligent Systems and Methods to Combat Covid-19,10.1007/978-981-15-6572-4_8,Springer,2020-01-01,"The sudden outburst of the COVID-19 has hit the world badly. Avoid, control, and monitor (ACM) is the need of time! With limited expert manpower in COVID-19, the technologies like artificial intelligence (AI), robotics (R), and IOT (I), i.e., (ARI) would help in avoidance of further spread and control of disease transmission. Prediction and analysis tools are effectively implemented only when sufficient data is available. Though an early stage of any pandemic has to deal with the scarcity of data, an early detection and prediction are equally important steps to fight COVID-19. But a complete solution to the pandemic is impossible because of the loose ends like availability of data and “dependent” development of ARI technology. Since December 2019, there has been a continuous up-scaling in analysis and prediction algorithms because of more data getting available in terms of features and more number of the cases across the world. This chapter will discuss the role of ARI and loose ends in their implementation. It is focused on three major aspects: AI algorithms in analysis and prediction, the use of robotics in control and prevention of the pandemic and the role of IOT for the patient monitoring system (PMS). This discussion will provide an evolutionary path of the algorithms. The accuracy rate for diagnosis and prediction has been increased because of the various novel approaches by researchers. They are trying to overcome the loopholes and are tying the loose ends with the advent of more and more data!",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-6572-4_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-13-9267-2_43,Sound Source Localization Based on the Simple Cross-correlation Method and Probabilistic Neural Networks,Proceedings of 14th International Conference on Electromechanics and Robotics “Zavalishin's Readings”,10.1007/978-981-13-9267-2_43,Springer,2020-01-01,"In this paper, we present an improved method for estimating the distance to a sound source and localizing a sound source in three-dimensional space, based on a simple correlation approach with training of a neural network. This new algorithm provides an estimate of azimuth and elevation of angles in free space using four microphones. The proposed method is tested using simulation and compared with the method of simple cross-correlation. It allows to localize sound sources in free space with an accuracy of up to 93%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-9267-2_43,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-61616-8_41,"Adaptive, Neural Robot Control – Path Planning on 3D Spiking Neural Networks",Artificial Neural Networks and Machine Learning – ICANN 2020,10.1007/978-3-030-61616-8_41,Springer,2020-01-01,"Safe, yet efficient, Human-robot interaction requires real-time-capable and flexible algorithms for robot control including the human as a dynamic obstacle. Even today, methods for collision-free motion planning are often computationally expensive, preventing real-time control. This leads to unnecessary standstills due to safety requirements. As nature solves navigation and motion control sophisticatedly, biologically motivated techniques based on the Wavefront algorithm have been previously applied successfully to path planning problems in 2D. In this work, we present an extension thereof using Spiking Neural Networks. The proposed network equals a topologically organized map of the work space, allowing an execution in 3D space. We tested our work on simulated environments with increasing complexity in 2D with different connection types. Subsequently, the application is extended to 3D spaces and the effectiveness and efficiency of the used approach are attested by simulations and comparison studies. Thereby, a foundation is set to control a robot arm flexibly in a workspace with a human co-worker. In combination with neuromorphic hardware this method will likely achieve real-time capability.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-61616-8_41,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-13-9406-5_15,Capsule Network-Based Facial Expression Recognition Method for a Humanoid Robot,"Recent Trends in Intelligent Computing, Communication and Devices",10.1007/978-981-13-9406-5_15,Springer,2020-01-01,"Compared to the classical convolutional neural network (CNN), the capsule net Hinton put forward can use fewer network layers to achieve the classification tasks very well and arrive at the convergence with a faster speed. The principle of the capsule net is based on the CNN, and it is just that the neuron form is converted from the scalar to the vector, which is a capsule, and then chooses the suitable capsule for the final output through the dynamic routing method (Sabour in Dynamic routing between capsules, [ 1 ]). In this paper, on the basis of the capsule net, use deconvolution to restore images and optimize the error between original images and restored images. The classical facial emotions database named Cohn-Kanade Database Plus (CK+) that is processed through Data Augmentation is used to conduct experiments. Lately, the classification results are combined with the NAO robot. The NAO robot is able to visualize the emotion by changing its eyes colors and speaking the results, achieving the purpose of combining theory with practice.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-9406-5_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-1420-3_35,Microcontroller Based ANN for Pick and Place Robot Coordinate Monitoring System,ICDSMLA 2019,10.1007/978-981-15-1420-3_35,Springer,2020-01-01,"Industrial Robots have captivated the manufacturing process of a product in the present assembly lines. The pick and place robot plays a vital role in this process for handling the products. But sometimes it may deviate from its desired position due to vibrations in the motors or due to external factors such as the impact on the robotic arm by the nearby robotic arm in an assembly line, resulting in aberrant gripping of the product. The resulting product either becomes unusable or gets damaged. As a solution to this a microcontroller- based machine learning coordinate monitoring design is proposed. A Feed-Forward neural network is used to determine whether the robot can pick the product or not. Before the robot picks the product the position of the robot arm is tracked by the three-axis angle sensor. The simple design of the system makes it easier to implement. The output of the feed forward neural network in microcontroller will determine whether the robot arm can grip the product. The network is trained through an iterative process with the training data which consists of both accepted and rejected values. The performance of the network is tested by exposing the outputs of the sensor (i.e. test data) to the network. The accuracy and the performance of the network are achieved by modeling the network architecture with the required number of neurons in the hidden layers. The accuracy of the neural network designed is observed to be around 98% from the respective accuracy graphs at different training process. The simple design procedure makes this system compact and reprogrammable.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-1420-3_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-60337-3_29,A Modular Deep Learning Architecture for Anomaly Detection in HRI,Interactive Collaborative Robotics,10.1007/978-3-030-60337-3_29,Springer,2020-01-01,"Considering humans as a non-deterministic factor makes anomaly detection in Human-Robot Interaction scenarios rather a challenging problem. Anomalous events like unexpected user interaction or unforeseen environment changes are unknown before they happen. On the other hand, the work process or user intentions could evolve in time. To address this issue, a modular deep learning approach is presented that is able to learn normal behavior patterns in an unsupervised manner. We combined the unsupervised feature extraction learning ability of an autoencoder with a sequence modeling neural network. Both models were firstly evaluated on benchmark video datasets, revealing adequate performance comparable to the state-of-the-art methods. For HRI application, a continuous training approach for real-time anomaly detection was developed and evaluated in an HRI-experiment with a collaborative robot, ToF camera, and proximity sensors. In the user study with 10 subjects irregular interactions and misplaced objects were the most common anomalies, which system was able to detect reliably.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60337-3_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-3290-0_21,EEG-Induced Error Correction in Path Planning by a Mobile Robot Using Learning Automata,Soft Computing for Problem Solving 2019,10.1007/978-981-15-3290-0_21,Springer,2020-01-01,"The paper makes an honest attempt to amalgamate two interesting open issues of path planning of mobile robots, such as learning automata-based planning and human in a loop using brain–computer interfaces. The learning automaton is employed to demarcate better actions at a state using a reward/penalty mechanism, whereas the brain–computer interface is used to identify the wrong actions taken by the robot at a given state and assist the robot to update the effect of penalty in its space of learning automaton. After convergence of the learning automaton, the robot utilizes it for determination of the next states from its current state by selection of the action with the highest reward function stored in the automaton. The proposed technique yields faster convergence than the one obtained by only learning automata-based system without any provisions for subjective feedback for error corrections. The choice of incremental reward/penalty value is also optimized with respect to minimum steps required to reach the goal during the planning phase.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-3290-0_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-0474-7_63,Reinforcement Learning on Robot with Variational Auto-Encoder,"Proceedings of the 11th International Conference on Modelling, Identification and Control (ICMIC2019)",10.1007/978-981-15-0474-7_63,Springer,2020-01-01,"Reinforcement learning Chen, Yiwen  enables robot to learn plentiful skills through training. Yang, Chenguang  The control based on end-to-end reinforcement learning output Feng, Ying  joint angle to the robot with image as input. However, using the deep network for end-to-end reinforcement learning makes it hard to converge and need much training time. And it’s also difficult to expand to other tasks because of custom-designed network. In this paper, we propose a reinforcement learning structure with variational auto-encoder that can be applied to different goals and reduce training time. Firstly the auto-encoder is trained with images that capture random robot actions. Then the reinforcement learning network is trained with the latent space vectors from auto-encoder instead of raw image. After finish training, the robot can reach a state similar to the state in expected image that we input.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-0474-7_63,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-019-0351-7,Model-free Optimal Tracking Control for an Aircraft Skin Inspection Robot with Constrained-input and Input Time-delay via Integral Reinforcement Learning,"International Journal of Control, Automation and Systems",10.1007/s12555-019-0351-7,Springer,2020-01-01,"This paper presents a model-free optimal tracking control algorithm for an aircraft skin inspection robot with constrained-input and input time-delay. To tackle the input time-delay problem, the original system is transformed into a delay-free system with constrained-input and unknown input coupling term. In order to overcome the optimal control problem subject to constrained-input, a discounted value function is employed. In general, it is known that the HJB equation does not admit a classical smooth solution. Moreover, since the input coupling term of the delay-free system is unknown, a model-free integral reinforcement learning(IRL) algorithm which only requires the system sampling data generated by arbitrary different control inputs and external disturbances is proposed. The model-free IRL method is implemented on an actor-critic neural network (NN) structure. A system sampling data set is utilized to learn the value function and control policy. Finally, the simulation verifies the effectiveness of the proposed algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-019-0351-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-43089-4_43,SWIRL: A SequentialWindowed Inverse Reinforcement Learning Algorithm for Robot Tasks With Delayed Rewards,Algorithmic Foundations of Robotics XII,10.1007/978-3-030-43089-4_43,Springer,2020-01-01,"Inverse Reinforcement Learning (IRL) allows a robot to generalize from demonstrations to previously unseen scenarios by learning the demonstrator’s reward function. However, in multi-step tasks, the learned rewards might be delayed and hard to directly optimize. We present Sequential Windowed Inverse Reinforcement Learning (SWIRL), a three-phase algorithm that partitions a complex task into shorter-horizon subtasks based on linear dynamics transitions that occur consistently across demonstrations. SWIRL then learns a sequence of local reward functions that describe the motion between transitions. Once these reward functions are learned, SWIRL applies Q-learning to compute a policy that maximizes the rewards. We compare SWIRL (demonstrations to segments to rewards) with Supervised Policy Learning (SPL - demonstrations to policies) and Maximum Entropy IRL (MaxEnt-IRL demonstrations to rewards) on standard Reinforcement Learning benchmarks: Parallel Parking with noisy dynamics, Two-Link acrobot, and a 2D GridWorld. We find that SWIRL converges to a policy with similar success rates (60%) in 3x fewer time-steps than MaxEnt-IRL, and requires 5x fewer demonstrations than SPL. In physical experiments using the da Vinci surgical robot, we evaluate the extent to which SWIRL generalizes from linear cutting demonstrations to cutting sequences of curved paths.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-43089-4_43,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-13-9217-7_13,Reinforcement Learning for Mobile Robot Perceptual Learning,Machine Learning-based Natural Scene Recognition for Mobile Robot Localization in An Unknown Environment,10.1007/978-981-13-9217-7_13,Springer,2020-01-01,"With the development of a computer vision system, the autonomous robots possess the ability to detect target objects from image sequences to build a model for an unknown environment. The next step in mobile robot autonomous navigation is for it to acquire control by some kind of learning. Reinforcement learning is of great interest because of the large number of practical applications that it can be used to address, ranging from problems in artificial intelligence to control engineering. Unlike supervised learning, in reinforcement learning, only partial feedback is given to the learner about its predictions which may have long term effects through influencing the future states of the controlled system and the goal of reinforcement learning is concerned with learning to control a system so as to maximize a numerical performance measure that expresses a long-term objective. In this chapter, we will provide an overview of the field of reinforcement learning in general and concepts that are relevant to the proposed work in specific. We begin with a review of the fundamental concepts of reinforcement learning considered from the artificial intelligence or computer science perspective on solving sequential decision-making problems. This introduction is followed by a brief introduction to one of the fundamental reinforcement learning method, the temporal difference learning algorithm, and its implementation based on a psychological model of its, working memory, to represent the learned knowledge.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-9217-7_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-4032-5_71,Recent Development of AI and IoT in the field of Agriculture Industries: A Review,Soft Computing: Theories and Applications,10.1007/978-981-15-4032-5_71,Springer,2020-01-01,"In this, paper presents the new technology which in turn increases the area of application for the technology, amongst that, one of them is the agricultural application such as the adding artificial intelligence (AI) and Internet of things (IoT) in the machinery is to make it a smart device which will be capable of making decision-making capacity based on the past experiences and learning, it is the system that includes IoT (Internet of things) where automated machine learning of the process can be done, and the AI involves many logics and methods for the problem-solving process. This technology is used for the application of agricultural system, and it overcomes the various problems in the agriculture such as the crop disease infestations, lack of storage management, pesticide control, weed management, and lack of irrigation and drainage facilities, and the technology uses wireless networks for the monitoring and controlling. The main aim of this study is to explore the present and future aspects of the AI and IoT in the agriculture industries that make the agriculture systems easy, effective, and minimize the human efforts.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-4032-5_71,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-12719-0_16,Future Entrepreneurship in Digital Health,Digital Health Entrepreneurship,10.1007/978-3-030-12719-0_16,Springer,2020-01-01,"Digital health through artificial Intelligence, telemedicine, genomics, robotics and many other innovative technologies, is already changing in many ways how medicine is being practiced around the world. Physicians entrepreneurs are adapting to this new reality with growth mindsets, creating innovative value propositions which are very differentiated from present ones. Additionally, a new subset of medical professionals will arise, and physicians and entrepreneurs who do not adopt innovative digital health technologies will be replaced, not by the technologies themselves, but by some others who would adopt them. This chapter will describe in detail these new paradigms in medicine and in entrepreneurship in healthcare.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-12719-0_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-50334-5_24,Prediction-Based Uncertainty Estimation for Adaptive Crowd Navigation,Artificial Intelligence in HCI,10.1007/978-3-030-50334-5_24,Springer,2020-01-01,"Fast, collision-free motion through human environments remains a challenging problem for robotic systems. In these situations, the robot’s ability to reason about its future motion and other agents is often severely limited. By contrast, biological systems routinely make decisions by taking into consideration what might exist in the future based on prior experience. In this paper, we present an approach that provides robotic systems the ability to make future predictions of the environment. We evaluate several deep network architectures, including purely generative and adversarial models for map prediction. We further extend this approach to predict future pedestrian motion. We show that prediction plays a key role in enabling an adaptive, risk-sensitive control policy. Our algorithms are able to generate future maps with a structural similarity index metric up to 0.899 compared to the ground truth map. Further, our adaptive crowd navigation algorithm is able to reduce the number of collisions by 43% in the presence of novel pedestrian motion not seen during training.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-50334-5_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-4095-0_16,Robot Learning in Simulation,Deep Reinforcement Learning,10.1007/978-981-15-4095-0_16,Springer,2020-01-01,"This chapter introduces a hands-on project for robot learning in simulation, including the process of setting up a task with a robot arm for objects grasping in CoppeliaSim and the deep reinforcement learning solution with soft actor-critic algorithm. The effects of different reward functions are also shown in the experimental sections, which testifies the importance of auxiliary dense rewards for solving a hard-to-explore task like the robot grasping ones. Brief discussions on robot learning applications, sim-to-real transfer, other robot learning projects and simulators are also provided at the end of this chapter.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-4095-0_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00170-019-04614-0,Robotic constant-force grinding control with a press-and-release model and model-based reinforcement learning,The International Journal of Advanced Manufacturing Technology,10.1007/s00170-019-04614-0,Springer,2020-01-01,"When a workpiece is ground by a robot, the issue often arises that the grinding force signal can easily suffer overshoot during the impact stage and instability during the processing stage. In this paper, a force control algorithm for use in the impact and processing stages of robotic constant-force grinding is proposed based on a press-and-release model and model-based reinforcement learning. For the impact stage, a press-and-release model for compensating for the robot deformation is established to enable the indirect control of the magnitude of the force signal by regulating the ratio of the pressing and release times to prevent overshoot. In the processing stage, model-based reinforcement learning is applied to quickly obtain the optimal processing parameters. Through iterative experiments, model-based reinforcement learning is used to update the model and then continue to search for the optimal processing parameters until the normal force reaches the desired state. Experimental results show that force control based on the proposed algorithm converges fast; in the impact and processing stages, the normal force converges to the set range after 4 and 3 iterations, respectively. The normal force is more stable than it is under position control. Moreover, the surface roughness Ra of the workpiece is reduced by 30.68%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00170-019-04614-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-66645-3_12,Towards Safe and Socially Compliant Map-Less Navigation by Leveraging Prior Demonstrations,Intelligent Robotics and Applications,10.1007/978-3-030-66645-3_12,Springer,2020-01-01,"This paper presents a learning-based approach for safe and socially compliant map-less navigation in dynamic environments. Our approach maps directly 2D-laser range findings and other measurements to motion commands, and a combination of imitation learning and reinforcement learning is deployed. We show that, by leveraging prior demonstrations, the training time for RL can be reduced by 60% and its performance is greatly improved. We use Constrained Policy Optimization (CPO) and specially designed rewards so that a safe and socially compliant behavior is achieved. Experiment results prove that the obtained navigation policy is capable of generalizing to unseen dynamic scenarios.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-66645-3_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-48989-2_56,"Crashing to Learn, Learning to Survive: Planning in Dynamic Environments via Domain Randomization",Advances in Service and Industrial Robotics,10.1007/978-3-030-48989-2_56,Springer,2020-01-01,"Autonomous robots in the real world should avert collisions with pedestrians and react quickly to sudden changes in the environment. Most local planners rely on static environment maps that cannot capture such critical elements of uncertainty. Learning based methods for end-to-end navigation have become popular recently, but it is still unclear how to incorporate collision avoidance in a simple, safe and quick manner. We propose a reinforcement learning curriculum based on domain randomization to train a high performing policy entirely in simulation. The policy is first trained in a simple obstacle-free environment to quickly learn point to point navigation. The learned policy is transferred to a dynamic environment to learn collision avoidance. The key idea is to randomize the obstacle dynamics to obtain a robust planner that can be directly deployed to the real world. The resultant policy outperforms conventional planners in dynamic real world environments, even when the robot is intentionally obstructed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-48989-2_56,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-4929-2_3,A Novel Optimization Approach Oriented to Auxiliary Transfer Based on Improved Reinforcement Learning,Robotics and Rehabilitation Intelligence,10.1007/978-981-33-4929-2_3,Springer,2020-01-01,"Aiming to provide an adaptive transfer method for people with weak motion capability, a novel optimization approach oriented to auxiliary transfer based on improved reinforcement learning is proposed. Firstly, the function of excretory support robot and the limitation of daily autonomous behavior are discussed. To obtain the transfer point of the user groups with different mobility, a two-link model of human body during sitting down is proposed and the mapping relationship of human body position and sitting point is established. According to the difference of human sitting posture, a fuzzy-reinforcement learning algorithm is proposed to calculate the appropriate transfer point. Integrating fuzzy reasoning method into the reward mechanism of reinforcement learning, the mapping relationship is continuously optimized and the appropriate sitting point is obtained in multiple transfer process. Finally, the transfer experiments and simulation are carried out. Experiments show that the transfer optimization method based on improved fuzzy-reinforcement learning proposed in this paper effectively obtains the optimal transfer point according to different motion capability and different transfer postures of users during the transfer process. The approach has strong popularization characteristics, which has the potential to be applied to nursing homes, hospitals and other rehabilitation sites.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-4929-2_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-61616-8_32,Social Navigation with Human Empowerment Driven Deep Reinforcement Learning,Artificial Neural Networks and Machine Learning – ICANN 2020,10.1007/978-3-030-61616-8_32,Springer,2020-01-01,"Mobile robot navigation has seen extensive research in the last decades. The aspect of collaboration with robots and humans sharing workspaces will become increasingly important in the future. Therefore, the next generation of mobile robots needs to be socially-compliant to be accepted by their human collaborators. However, a formal definition of compliance is not straightforward. On the other hand, empowerment has been used by artificial agents to learn complicated and generalized actions and also has been shown to be a good model for biological behaviors. In this paper, we go beyond the approach of classical Reinforcement Learning (RL) and provide our agent with intrinsic motivation using empowerment. In contrast to self-empowerment, a robot employing our approach strives for the empowerment of people in its environment, so they are not disturbed by the robot’s presence and motion. In our experiments, we show that our approach has a positive influence on humans, as it minimizes its distance to humans and thus decreases human travel time while moving efficiently towards its own goal. An interactive user-study shows that our method is considered more social than other state-of-the-art approaches by the participants.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-61616-8_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-60887-3_40,Mobile Robotic Navigation System With Improved Autonomy Under Diverse Scenarios,Advances in Computational Intelligence,10.1007/978-3-030-60887-3_40,Springer,2020-01-01,"Mobile robots integrate a combination of physical robotic elements for locomotion and artificial intelligence algorithms to move and explore the environment. They have the ability to react and make decisions based on the perception they receive from the environment to fulfill the assigned navigation tasks. A crucial issue in mobile robots is to address the energy consumption in the robot design strategy for prolonged autonomous operation. Therefore, the battery charge level is an input variable that is commonly monitored and evaluated at all times, in this type of robots, in order to influence the decision-making with the least user intervention, during the navigation phase. Hence, the robot is capable to complete its tasks successfully. To achieve this, a navigation approach based on a fuzzy Q-Learning architecture for decision-making in combination with a module of artificial potential fields for path planning is introduced. The exhibited behavior of a six-legged robot obtained under this approach, demonstrates the robot’s ability of moving from a starting point to a destination point, considering the need to go to the charging station or to remain static, if necessary.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60887-3_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-58147-3_51,Attention-Based Robot Learning of Haptic Interaction,"Haptics: Science, Technology, Applications",10.1007/978-3-030-58147-3_51,Springer,2020-01-01,"Haptic interaction involved in almost any physical interaction with the environment performed by humans is a highly sophisticated and to a large extent a computationally unmodelled process. Unlike humans, who seamlessly handle a complex mixture of haptic features and profit from their integration over space and time, even the most advanced robots are strongly constrained in performing contact-rich interaction tasks. In this work we approach the described problem by demonstrating the success of our online haptic interaction learning approach on an example task: haptic identification of four unknown objects. Building upon our previous work performed with a floating haptic sensor array, here we show functionality of our approach within a fully-fledged robot simulation. To this end, we utilize the haptic attention model (HAM), a meta-controller neural network architecture trained with reinforcement learning. HAM is able to learn to optimally parameterize a sequence of so-called haptic glances, primitive actions of haptic control derived from elementary human haptic interaction. By coupling a simulated KUKA robot arm with the haptic attention model, we pursue to mimic the functionality of a finger. Our modeling strategy allowed us to arrive at a tactile reinforcement learning architecture and characterize some of its advantages. Owing to a rudimentary experimental setting and an easy acquisition of simulated data, we believe our approach to be particularly useful for both time-efficient robot training and a flexible algorithm prototyping.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58147-3_51,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-66645-3_14,A Guided Evaluation Method for Robot Dynamic Manipulation,Intelligent Robotics and Applications,10.1007/978-3-030-66645-3_14,Springer,2020-01-01,"It is challenging for reinforcement learning (RL) to solve the dynamic goal tasks of robot in sparse reward setting. Dynamic Hindsight Experience Replay (DHER) is a method to solve such problems. However, the learned policy DHER is easy to degrade, and the success rate is low, especially in complex environment. In order to help agents learn purposefully in dynamic goal tasks, avoid blind exploration, and improve the stability and robustness of policy, we propose a guided evaluation method named GEDHER, which assists the agent to learn under the guidance of evaluated expert demonstrations based on the DHER. In addition, We add the Gaussian noise in action sampling to balance the exploration and exploitation, preventing from falling into local optimal policy. Experiment results show that our method outperforms original DHER method in terms of both stability and success rate.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-66645-3_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-41586-0_20,"Rocks, Rivers, and Robots: Reading Crisis with Teilhard de Chardin",Back to the ‘30s?,10.1007/978-3-030-41586-0_20,Springer,2020-01-01,"Teilhard de Chardin, known by early twentieth-century anthropologists for his contributions in paleontology, wrote The Phenomenon of Man during the 1930s. Having been exiled to China for his unorthodox views reconciling Christianity with scientific theory, this ultra-anthropological treatise on human evolution described a world undergoing “cosmogenesis,” developing in complexity and consciousness. Tracing this process through geological and then biological evolution, Teilhard suggested that a layer of human thought and its products would soon encircle the world and a single mind would emerge. These ideas have fueled art, literature, and theoretical speculation about the post-human. This chapter calls upon Teilhard to help us make sense of crises of nationalism, labor, and personhood in an era of globalizing artificial intelligence. I examine what the sustainable “us” looks like under these terms, with special attention paid to the implications for individuals tethered to—or detached from—an increasingly virtual state and economy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-41586-0_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-49186-4_6,Deepbots: A Webots-Based Deep Reinforcement Learning Framework for Robotics,Artificial Intelligence Applications and Innovations,10.1007/978-3-030-49186-4_6,Springer,2020-01-01,"Deep Reinforcement Learning (DRL) is increasingly used to train robots to perform complex and delicate tasks, while the development of realistic simulators contributes to the acceleration of research on DRL for robotics. However, it is still not straightforward to employ such simulators in the typical DRL pipeline, since their steep learning curve and the enormous amount of development required to interface with DRL methods significantly restrict their use by researchers. To overcome these limitations, in this work we present an open-source framework that combines an established interface used by DRL researchers, the OpenAI Gym interface, with the state-of-the-art Webots robot simulator in order to provide a standardized way to employ DRL in various robotics scenarios. Deepbots aims to enable researchers to easily develop DRL methods in Webots by handling all the low-level details and reducing the required development effort. The effectiveness of the proposed framework is demonstrated through code examples, as well as using three use cases of varying difficulty.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-49186-4_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-60337-3_24,Indoor vs. Outdoor Scene Classification for Mobile Robots,Interactive Collaborative Robotics,10.1007/978-3-030-60337-3_24,Springer,2020-01-01,"This paper deals with the task of automatic indoor vs. outdoor classification from image data with respect to future usage in mobile robotics. For the requirements of this research, we utilize the Miniplaces dataset. We compare a large number of classic machine learning approaches such as Support Vector Machine, k-Nearest Neighbor, Decision Tree, or Naive Bayes using various color and texture description methods on a single dataset. Moreover, we employ some of the most important neural network-based approaches from the last four years. The best tested approach reaches 96.17% classification accuracy. To our best knowledge, this paper presents the most extensive comparison of classification approaches in the task of indoor vs. outdoor classification ever done on a single dataset. We also address the processing time problem, and we discuss using the applied methods in real-time robotic tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60337-3_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-54407-2_17,Robot-Assisted Composite Manufacturing Based on Machine Learning Applied to Multi-view Computer Vision,Smart Multimedia,10.1007/978-3-030-54407-2_17,Springer,2020-01-01,"This paper introduces an automated wrinkle detection method on semi-finished fiber products in the aerospace manufacturing industry. Machine learning, computer vision techniques, and evidential reasoning are combined to detect wrinkles during the draping process of fibre-reinforced materials with an industrial robot. A well-performing Deep Convolutional Neural Network (DCNN) was developed based on a preliminary, hand-labelled dataset captured on a functioning robotic system used in a composite manufacturing facility. Generalization of this model to different, unlearned wrinkle features naturally compromises detection accuracy. To alleviate this problem, the proposed method employs computer vision techniques and belief functions to enhance defect detection accuracy. Co-temporal views of the same fabric are extracted, and individual detection results obtained from the DCNN are fused using the Dempster-Shafer Theory (DST). By the application of the DST rule of combination, the overall wrinkle detection accuracy for the generalized case is greatly improved in this composite manufacturing facility.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54407-2_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-43089-4_47,Persistent Surveillance of Events with Unknown Rate Statistics,Algorithmic Foundations of Robotics XII,10.1007/978-3-030-43089-4_47,Springer,2020-01-01,"We present a novel algorithm for persistent monitoring of stochastic events that occur at discrete locations in the environment with unknown event rates. Prior research on persistent monitoring assumes knowledge of event rates, which is often not the case in robotics applications. We consider the multi-objective optimization of maximizing the total number of events observed in a balanced manner subject to real-world autonomous system constraints. We formulate an algorithm that quantifies and leverages uncertainty over events’ statistics to greedily generate adaptive policies that simultaneously consider learning and monitoring objectives. We analyze the favorable properties of our algorithm as a function of monitoring cycles and provide simulation results demonstrating our method’s effectiveness in real-world inspired monitoring applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-43089-4_47,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-20040-4_8,Epistemic Debt: A Concept and Measure of Technical Ignorance in Smart Manufacturing,Advances in Human Factors and Systems Interaction,10.1007/978-3-030-20040-4_8,Springer,2020-01-01,"This paper introduces the notion of epistemic debt as an analytical tool for understanding and managing the effects of technical ignorance in smart manufacturing. Drawing on the concepts of technical and social debt from software engineering, the metaphor of epistemic debt refers to the implied long-term costs of rework (e.g., redesign, replacement, reconfiguration or systems and/or organizational structures) caused by a lack of understanding and/or means of knowing the internals of complex software-based manufacturing systems essential to the value chain and core business of an organization. After defining the concept, we identify three of its sources and propose strategies for coping with epistemic debt in manufacturing.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-20040-4_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-44051-0_11,Learning Stabilizable Dynamical Systems via Control Contraction Metrics,Algorithmic Foundations of Robotics XIII,10.1007/978-3-030-44051-0_11,Springer,2020-01-01,"We propose a novel framework for learning stabilizable nonlinear dynamical systems for continuous control tasks in robotics. The key idea is to develop a new control-theoretic regularizer for dynamics fitting rooted in the notion of stabilizability , which guarantees that the learned system can be accompanied by a robust controller capable of stabilizing any open-loop trajectory that the system may generate. By leveraging tools from contraction theory, statistical learning, and convex optimization, we provide a general and tractable semi-supervised algorithm to learn stabilizable dynamics, which can be applied to complex underactuated systems. We validated the proposed algorithm on a simulated planar quadrotor system and observed notably improved trajectory generation and tracking performance with the control-theoretic regularized model over models learned using traditional regression techniques, especially when using a small number of demonstration examples. The results presented illustrate the need to infuse standard model-based reinforcement learning algorithms with concepts drawn from nonlinear control theory for improved reliability.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-44051-0_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-28619-4_60,Stochastic Motion Planning for Hopping Rovers on Small Solar System Bodies,Robotics Research,10.1007/978-3-030-28619-4_60,Springer,2020-01-01,"Hopping rovers have emerged as a promising platform for the future surface exploration of small Solar System bodies, such as asteroids and comets. However, hopping dynamics are governed by nonlinear gravity fields and stochastic bouncing on highly irregular surfaces, which pose several challenges for traditional motion planning methods. This paper presents the first ever discussion of motion planning for hopping rovers that explicitly accounts for various sources of uncertainty. We first address the problem of planning a single hopping trajectory by developing (1) an algorithm for robustly solving Lambert’s orbital boundary value problems in irregular gravity fields, and (2) a method for computing landing distributions by propagating control and model uncertainties—from which, a time/energy-optimal hop can be selected using a (myopic) policy gradient. We then cast the sequential planning problem as a Markov decision process and apply a sample-efficient, off-line, off-policy reinforcement learning algorithm—namely, a variant of least squares policy iteration (LSPI)—to derive approximately optimal control policies that are safe, efficient, and amenable to real-time implementation on computationally-constrained rover hardware. These policies are demonstrated in simulation to be robust to modelling errors and outperform previous heuristics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-28619-4_60,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-30036-4_26,Learning Emotion Recognition and Response Generation for a Service Robot,Robotics and Mechatronics,10.1007/978-3-030-30036-4_26,Springer,2020-01-01,"Building dialoguing services for robots to provide natural human-robot interactions and to enhance user experiences is now advocated. With this type of services, a robot can work as a consultant and provide domain-specific knowledge to end users. In this study, we adopt a service-oriented framework to develop emotion-aware dialogues for a service robot. Our work includes several unique features: it trains classifiers to recognize users’ emotions in conversation, learns a deep neural model to generate answers in response to users’ questions, and uses the emotional information to determine the answer sentences produced by the dialoguing model. A series of experiments are conducted for performance evaluation. The results are compared with other machine learning methods, and they show the promise and potential of the presented approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30036-4_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-44051-0_52,Operation and Imitation Under Safety-Aware Shared Control,Algorithmic Foundations of Robotics XIII,10.1007/978-3-030-44051-0_52,Springer,2020-01-01,"We describe a shared control methodology that can, without knowledge of the task, be used to improve a human’s control of a dynamic system, be used as a training mechanism, and be used in conjunction with Imitation Learning to generate autonomous policies that recreate novel behaviors. Our algorithm introduces autonomy that assists the human partner by enforcing safety and stability constraints. The autonomous agent has no a priori knowledge of the desired task and therefore only adds control information when there is concern for the safety of the system. We evaluate the efficacy of our approach with a human subjects study consisting of 20 participants. We find that our shared control algorithm significantly improves the rate at which users are able to successfully execute novel behaviors. Experimental results suggest that the benefits of our safety-aware shared control algorithm also extend to the human partner’s understanding of the system and their control skill. Finally, we demonstrate how a combination of our safety-aware shared control algorithm and Imitation Learning can be used to autonomously recreate the demonstrated behaviors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-44051-0_52,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-63486-5_25,An Experiment on Human-Robot Interaction in a Simulated Agricultural Task,Towards Autonomous Robotic Systems,10.1007/978-3-030-63486-5_25,Springer,2020-01-01,"On the farm of the future, a human agriculturist collaborates with both human and automated labourers in order to perform a wide range of tasks. Today, changes in traditional farming practices motivate robotics researchers to consider ways in which automated devices and intelligent systems can work with farmers to address diverse needs of farming. Because farming tasks can be highly specialised, though often repetitive, a human-robot approach is a natural choice. The work presented here investigates a collaborative task in which a human and robot share decision making about the readiness of strawberries for harvesting, based on visual inspection. Two different robot behaviours are compared: one in which the robot provides decisions with more false positives and one in which the robot provides decisions with more false negatives. Preliminary experimental results conducted with human subjects are presented and show that the robot behaviour with more false positives is preferred in completing this task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-63486-5_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-019-00551-w,A Robot for Test Bed Aimed at Improving Telepresence System and Evasion from Discomfort Stimuli by Online Learning,International Journal of Social Robotics,10.1007/s12369-019-00551-w,Springer,2020-01-01,"This study contributes to improving the comfort of telepresence communication by adaptations to people. We developed a handheld telepresence robot comprised of a binaural microphone and a head mounted display as a test bed and conducted surveys on unpleasantness caused by special devices in use. We found that numerous people experienced an increase in unpleasant sound when the binaural microphone was being used. It was also found that types of unpleasant stimuli differed from person to person. Furthermore, we propose an automatic unpleasant stimuli avoidance system using online machine learning architecture constructed from echo state networks (ESNs) and Accumulator Based Arbitration Models (ABAMs) that can also flexibly adapt to remote users. Because the handheld telepresence robot can avoid unpleasant stimuli before remote users experience these stimuli, it provides them with a more comfortable communication environment while notifying people around the robot that uncomfortable stimulation is being avoided.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-019-00551-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-60337-3_13,Gesture-Based Intelligent User Interface for Control of an Assistive Mobile Information Robot,Interactive Collaborative Robotics,10.1007/978-3-030-60337-3_13,Springer,2020-01-01,"This article presents a gesture-based user interface for a robotic shopping trolley. The trolley is designed as a mobile robotic platform helping customers in shops and supermarkets. Among the main functions are: navigating through the store, providing information on availability and location, and transporting the items bought. One of important features of the developed interface is the gestural modality, or, more precisely, Russian sign language elements recognition system. The notion of the interface design, as well as interaction strategy, are presented in flowcharts, it was made an attempt to demonstrate the gestural modality as a natural part of an assistive information robot. Besides, a short overview of mobile robots is given in the paper, and CNN-based technique of gesture recognition is provided. The Russian sign language recognition option is of high importance due to a relatively large number of native speakers (signers).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60337-3_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-61705-9_8,Clustering and Regression to Impute Missing Values of Robot Performance,Hybrid Artificial Intelligent Systems,10.1007/978-3-030-61705-9_8,Springer,2020-01-01,"It is widely claimed that a major challenge in Robotics is to get reliable systems while both response and down times are minimized. In keeping with this idea, present paper proposes the application of a Hybrid Artificial Intelligence System (HAIS) to preprocess data with the aim of improving the detection of performance anomalies. One of the main problems when analyzing real-life data is the presence of missing values. It is usually solved by removing incomplete data, what causes a loss of information that may be critical in some domains. As an alternative, present paper proposes the application of regression models to impute those missing values. Prediction is optimized by generating personalized models on previously clustered data. Experiments are run on a public and up-to-date dataset that contains information about anomalies affecting the component-based software of a robot. The obtained results validate the proposed HAIS, as it successfully imputes missing values from the different features in the original dataset.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-61705-9_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-40971-5_24,Improving Positioning Accuracy of an Articulated Robot Using Deep Q-Learning Algorithms,Automation 2020: Towards Industry of the Future,10.1007/978-3-030-40971-5_24,Springer,2020-01-01,"Positioning accuracy of articulated robots decreases significantly when they are fully loaded and operated at maximum speeds due to increased inertia. Hard-coding correction algorithms using traditional methods is extremely difficult. A system, which could automatically detect patterns in deviations and offer possible corrections at every motion cycle would be preferable. This work explores the possibility to use deep q-learning algorithms to achieve this. Around forty experiments of various lengths were conducted. They were divided into three experimental groups, each of which had various parameters values and elements of algorithms. While algorithms in two experimental groups were unsuccessful in achieving improved accuracy, one offered comparable accuracy, while resulting in more stable and predictable deviations compared to uncorrected positioning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-40971-5_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-64246-4_4,The Laws and Regulation of AI and Autonomous Systems,Unimagined Futures – ICT Opportunities and Challenges,10.1007/978-3-030-64246-4_4,Springer,2020-01-01,"Our regulatory systems have attempted to keep abreast of new technologies by recalibrating and adapting our regulatory frameworks to provide for new opportunities and risks, to confer rights and duties, safety and liability frameworks, and to ensure legal certainty for businesses. These adaptations have been reactive and sometimes piecemeal, often with artificial delineation on rights and responsibilities and with unintended flow-on consequences. Previously, technologies have been deployed more like tools, but as autonomy and self-learning capabilities increase, robots and intelligent AI systems will feel less and less like machines and tools. There is now a significant difference, because machine learning AI systems have the ability to learn, adapt their performances and ‘make decisions’ from data and ‘life experiences’. This chapter provides brief insights on some of the topical developments in our regulatory systems and the current debates on some of the risks and challenges from the use and actions of AI, autonomous and intelligent systems [ 1 ].",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-64246-4_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-7066-7_4,The Robots Are Here,Contemporary Applications of Actor Network Theory,10.1007/978-981-15-7066-7_4,Springer,2020-01-01,"This chapter makes an argument for a shift in focus from the bias of human centricity to that of technology centricity in the analysis of technology driven actor networks. The ‘4 moments of translation’ is used as a reference model to explain the emergence of technology as a focal actor in contemporary actor networks. The implications of technology centric actor networks on the 4 moments of translations and the sociology of Translation are discussed in the chapter. The chapter posits that the current approach toward analyzing Sociology of Translation, using the 4 moments of translation might not sufficient to explain translations led by Super AI in future.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-7066-7_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-53644-2_5,What Can Get Wrong?,Judgement-Proof Robots and Artificial Intelligence,10.1007/978-3-030-53644-2_5,Springer,2020-01-01,"The newest generation of super-intelligent AI agents learn to gang up and cooperate against humans, without communicating or being told to do so. Sophisticated autonomous AI agents even collude to raise prices instead of competing to create better deals and they do decide to gouge their customers and humans. This chapter shows that super-intelligent AI systems might be used toward undesirable ends, the use of AI systems might result in a loss of accountability and the ultimate, unregulated success of AI might mean the end of the human race. Moreover, this chapter also suggests that the main issue related to the super-intelligent AI is not their consciousness but rather their competence to cause harm and hazards.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-53644-2_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-61295-5_2,TRIZ Driven Identification of AI Application to Improve Navigation of Mobile Autonomous Robots,Systematic Complex Problem Solving in the Age of Digitalization and Open Innovation,10.1007/978-3-030-61295-5_2,Springer,2020-01-01,"Increase of effectiveness of navigation in the case of autonomous mobile robots with limited sensory systems integrated that operate in different types of production facilities is considered in this research work. The challenge is to define a reliable solution in a cost-effective design. The research methodology integrates TRIZ within the framework of voice-of-use-table-performance function deployment (VOUT-PFD) design planning framework. The key user requirements and engineering specifications defined with VOUT-PFD have been analyzed in terms of correlations. For the identified sets of negative correlations, TRIZ Contradiction Matrix has been considered to formulate the generic areas for inventive problem-solving. Using the method of weighted analysis of interdependencies (AIDA), the compatible TRIZ vectors have been selected for guiding the design of the artificial intelligence (AI) algorithm. These vectors have been introduced in the framework of Complex System Design Technique (CSDT) in relation with generic modules of the AI system (algorithm, related inputs from the sensors and mechanical limitations of the robotic system) in order to design the navigation solution. In this article eight areas of possible improvements using AI algorithms have been found and the first area of research, which represents the robot construction is further detailed. The major result of this paper is that it shows a structured way in which inventive problem-solving thinking can lead to possible improvement areas regarding navigation of autonomous mobile robots (AMRs) in industrial environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-61295-5_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-62056-1_45,Using AI-Enhanced Social Robots to Improve Children’s Healthcare Experiences,Social Robotics,10.1007/978-3-030-62056-1_45,Springer,2020-01-01,"This paper describes a new research project that aims to develop an autonomous and responsive social robot designed to help children cope with painful procedures in hospital emergency departments. While this is an application domain where psychological interventions have been previously demonstrated to be effective at reducing pain and distress using a variety of devices and techniques, in recent years, social robots have been trialled in this area with promising initial results. However, until now, the social robots that have been tested have generally been teleoperated, which has limited their flexibility and robustness, as well as the potential to offer personalized, adaptive procedural support. Using co-design techniques, this project plans to define and validate the necessary robot behaviour together with participant groups that include children, parents and caregivers, and healthcare professionals. Identified behaviours will be deployed on a robot platform, incorporating AI reasoning techniques that will enable the robot to adapt autonomously to the child’s behaviour. The final robot system will be evaluated through a two-site clinical trial. Throughout the project, we will also monitor and analyse the ethical and social implications of robotics and AI in paediatric healthcare.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-62056-1_45,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-60117-1_39,Why Did the Robot Cross the Road?,HCI International 2020 - Late Breaking Papers: Multimodality and Intelligence,10.1007/978-3-030-60117-1_39,Springer,2020-01-01,"This work documents a pilot user study evaluating the effectiveness of contrastive, causal and example explanations in supporting human understanding of AI in a hypothetical commonplace human-robot interaction (HRI) scenario. In doing so, this work situates “explainable AI” (XAI) in the context of the social sciences and suggests that HRI explanations are improved when informed by the social sciences.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60117-1_39,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-32150-5_73,Explore and Rescue Using Humanoid Water Rescuer Robot with AI Technologies,Emerging Trends in Computing and Expert Technology,10.1007/978-3-030-32150-5_73,Springer,2020-01-01,"In the present era, there is no requirement for humans to work in risky jobs. Technology has developed to an extreme to replace for humans. The most perfect technology to replace humans in risky jobs is Robotics with Artificial Intelligence. In this paper, we are going to design “Humanoid Water Rescuer”. This is worth and new to the job as it supports both rescuing human life and existing aquatic organisms from environment situation. One of the mobile robots is rescuer robots which is portable and small. As it traverses the source to destination and sense the organism and to save the life. With sending information to robots it will diagnosis and treat or given the first aid and it is used as carrier robots to carry the humans to the source. Thus it used in all water rescuing situations and treat life according to the command of the master.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-32150-5_73,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-32161-1_32,Social and Emotional Robots: Useful Artificial Intelligence in the Absence of Consciousness,Healthcare and Artificial Intelligence,10.1007/978-3-030-32161-1_32,Springer,2020-01-01,"Artificial intelligence and robotics are opening up important opportunities in the field of health diagnosis and treatment support with aims like better patient follow-up. A social and emotional robot is an artificially intelligent machine that owes its existence to computer models designed by humans. If it has been programmed to engage in dialogue, detect and recognize emotional and conversational cues, adapt to humans, or even simulate humor, such a machine may on the surface seem friendly. However, such emotional simulation must not hide the fact that the machine has no consciousness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-32161-1_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-51005-3_33,Should We Share Rights and Obligations with Artificial Intelligence Robots?,Science and Technologies for Smart Cities,10.1007/978-3-030-51005-3_33,Springer,2020-01-01,"Technology could have impact on the public safety of humans it is not enough to simply presume it works. The social structures are already revolutionized by the introduction of artificial intelligence in the industry and society and the legal framework is not yet prepared to absorb the impact. This is why we consider that robots should have a distinctive legal status, separate from their users and owners. The role of this special issue is to define the contents of the status of the artificially intelligent agents (liability, rights, tax duties and so on) for a minimum certainty not only related to eventual damages, but also to the public safety and data protection.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-51005-3_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-31635-8_205,Multi-view Robust Gesture Recognition for Assistive Interfaces,XV Mediterranean Conference on Medical and Biological Engineering and Computing – MEDICON 2019,10.1007/978-3-030-31635-8_205,Springer,2020-01-01,"In this paper, we propose a gesture recognition approach using a multi-view setup for assistive device applications. As smart assistances become a reality, the need to interact with them in a natural fashion, as we do with other humans, becomes crucial. Gestures are a fundamental modality of human interaction, being natural and intuitive. We propose a gesture recognition approach relying on upper-body joints’ motions, so that individuals suffering from motor dysfunctions, that need to use wheelchairs or cannot stand, can as well interact with their smart assistive devices. To achieve this goal, we propose a robust multi-view skeleton fusion through a Kalman filtering technique, followed by an upper-body handcrafted feature extraction process. Gestures are classified using a support vector machine (SVM) classifier. Experiments with our captured dataset revealed a strong generalization from our method, and an increased performance of our multi-view fusion over the individual views.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-31635-8_205,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-53644-2_4,Introduction to the Autonomous Artificial Intelligence Systems,Judgement-Proof Robots and Artificial Intelligence,10.1007/978-3-030-53644-2_4,Springer,2020-01-01,"This chapter attempts to explain the main concepts, definitions, and developments of the field of artificial intelligence. It addresses the issues of logic, probability, perception, learning, and action. This chapter examines the current “state of the art” of the artificial intelligence systems and its recent developments. Moreover, this chapter presents the artificial intelligence’s conceptual foundations and discusses the issues of machine learning, uncertainty, reasoning, learning, and robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-53644-2_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-38724-2_13,Service Robots in the Hospitality Industry: An Exploratory Literature Review,Exploring Service Science,10.1007/978-3-030-38724-2_13,Springer,2020-01-01,"The service sector is changing drastically due the use of robotics and other technologies, such as Artificial Intelligence (AI), Internet of things (IoT), Big Data and Biometrics. Consequently, further research opportunities in the service industry domain are also expected. In light of the above, the purpose of this paper is to explore the potentialities and limitations of service robots in the hospitality industry. To this end, this paper uses a conceptual approach based on a literature review. As a result, we found that in contexts of high customer contact, service robots should be considered to perform standardized tasks due to social/emotional and cognitive/analytical complexity. The hospitality industry is therefore considered closely related to empathic intelligence, as the integration of service robots has not yet reached the desired stage of service delivery. In a seemingly far-fetched context of our reality, organizations will have to decide whether the AI will allow the complete replacement of humans with robots capable of performing the necessary cognitive and emotional tasks. Or investing in balanced capacities by integrating robot-human systems that seems a reasonable option these days.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-38724-2_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-30131-6_4,Technological Transformation,Disrupted Development and the Future of Inequality in the Age of Automation,10.1007/978-3-030-30131-6_4,Springer,2020-01-01,"Most research on the economic implications of automation has so far focused on advanced industrialized economies where the cost of labor is high and manufacturing shows a high degree of mechanization and productivity. Yet, the developing world is likely to be both affected by automation trends in high-income countries (HICs) and is itself catching up in terms of automation. “Late developers” are facing the digital revolution earlier and under different conditions than today’s advanced economies. There is an increasing worry that any low-cost labor advantage of developing countries in international trade is eroding. Beyond the alarmist threat of “technological unemployment,” there are broader questions to be asked about how automation and digitization influence global economic development, employment growth, and structural transformation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30131-6_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-97134-6_14-1,Twilight Zone as Philosophy 101,The Palgrave Handbook of Popular Culture as Philosophy,10.1007/978-3-319-97134-6_14-1,Springer,2020-01-01,"This is a threefold introduction to philosophy, to The Twilight Zone , and to the rest of the book. This chapter begins with a discussion of the advantages of using examples, salient features, and an immersive approach when introducing new subject matter. This is then followed, first, by an examination of some of the salient features of philosophy, particularly those features that are also features of The Twilight Zone , and, second, by a detailed discussion of the philosophical content of specific episodes of The Twilight Zone , particularly those topics that are also addressed in other chapters of this book. This immerses the reader in the process of doing exactly what philosophers often do, which is engaging with philosophical texts.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-97134-6_14-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-40974-6_1,Introduction,Milestones in Analog and Digital Computing,10.1007/978-3-030-40974-6_1,Springer,2020-01-01,"The chapter “Introduction” describes the goal of the book and the period of time covered by the presentations. It conveys an overview of new and exciting findings of objects (above all calculating machines) and documents and provides insight into their origins. The book focuses on the history predating the emergence of analog and digital computer technology and the early history of their development, automaton construction (automaton figures and musical automatons), and selected scientific instruments from the areas of astronomy, surveying, and measurement of time. Special attention is given to the non-English-speaking countries. It is not the intention of the book to present the entire history without interruption. Instead, the emphasis is on the highlights and the most significant achievements. Overviews in the form of tables facilitate the study of the material. Lines of development depict coherent relationships. Instead of a treatment of the most recent era in computer science, the subjects of digital transformation and artificial intelligence are discussed at length. Numerous step-by-step operating instructions for analog and digital calculating devices round out the volume.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-40974-6_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11747-019-00696-0,How artificial intelligence will change the future of marketing,Journal of the Academy of Marketing Science,10.1007/s11747-019-00696-0,Springer,2020-01-01,"In the future, artificial intelligence (AI) is likely to substantially change both marketing strategies and customer behaviors. Building from not only extant research but also extensive interactions with practice, the authors propose a multidimensional framework for understanding the impact of AI involving intelligence levels, task types, and whether AI is embedded in a robot. Prior research typically addresses a subset of these dimensions; this paper integrates all three into a single framework. Next, the authors propose a research agenda that addresses not only how marketing strategies and customer behaviors will change in the future, but also highlights important policy questions relating to privacy, bias and ethics. Finally, the authors suggest AI will be more effective if it augments (rather than replaces) human managers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11747-019-00696-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-74336-3_636-1,Autonomous Weapon Systems (AWS),The Palgrave Encyclopedia of Global Security Studies,10.1007/978-3-319-74336-3_636-1,Springer,2020-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-74336-3_636-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-50726-8_82,The Development Dilemma and Countermeasures of Strong Artificial Intelligence in Meeting Human Emotional Needs,HCI International 2020 - Posters,10.1007/978-3-030-50726-8_82,Springer,2020-01-01,"Artificial intelligence, as a new technological science involving cognitive level, is gradually entering our daily life, and it is developing faster than imagined. In the long process of human evolution, society has long been deeply imprinted in genes as a natural attribute. But people’s socialization with machines has just begun, and they are full of expectations for communication with AI and even emotional dialogue. However, when the artificial intelligence robot without life-span concept appears in our life, the AI with simulation emotion and excellent ability also brings the ethical problems of life and death concept, controllability, emotionalization, social concept, specificity, authenticity and man-machine boundary. Just as Asimov’s three laws of robots, human society should guide and restrict the development direction of artificial intelligence according to the applicable objects, and avoid possible out of control situations, which requires some relatively specific guiding principles to lead. We hope to see the glory of technology and wisdom embodied by AI, but at the same time, we should be more alert to the huge dilemma of AI development brought by robots once they enter the reverse lane of human emotional needs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-50726-8_82,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-44289-7_3,Experimental Modeling of Hexapod Robot Using Artificial Intelligence,Proceedings of the International Conference on Artificial Intelligence and Computer Vision (AICV2020),10.1007/978-3-030-44289-7_3,Springer,2020-01-01,"Hexapod Robots gave us the opportunity to study walking robots without facing problems such as stability and expensive custom made hardware. It has a great deal of flexibility in moving over different terrains even if some legs become malfunctioned or facing some difficulties in movement. In this study the kinematic analysis of CH3-R 18DOF Hexapod Robot is discussed where each leg contains three revolute joints in order to mimic the structure of a spider. To develop the overall kinematic model of CH3-R robot, direct and inverse kinematic analyses for each leg have been considered where the Denavit-Hartenberg (D-H) conventions will be used to perform the forward kinematic analysis of the six-legged robot while the inverse kinematics are obtained by simplifying the architecture of the robot into 7 modules, a hexagon trunk and 6 limbs between the trunk and the ground. A neural network (NN) model was employed in order to compare and decide the angles prediction, training time and overall performance with the ones obtained from the analytical solution of the inverse kinematics. The data points used for training the two models and testing their performance was acquired from giving the robot an initial and final position and recording the change in the coordinates and time by using an IMU sensor.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-44289-7_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-15160-7_137,Research of the Best Practices of Artificial Intelligence in the Formation and Development of Personnel,"Growth Poles of the Global Economy: Emergence, Changes and Future Perspectives",10.1007/978-3-030-15160-7_137,Springer,2020-01-01,"The article deals with topical issues of application of technologies based on artificial intelligence models in the field of human resources management. The purpose of this research is to analyze the practice of introduction of artificial intelligence in the process of personnel management of organizations, as well as to determine the prospects and potential dangers of this phenomenon. The basis of the research methodology is mainly based on the methods of processing large amounts of information: content analysis, systematization, generalization and structuring of information. This enabled the authors to explore a significant array of data from different companies on the practice of artificial intelligence application, in the field of HR-management. The article gives examples of the use of special programs on work with personnel at different stages of the personnel cycle, from search and attraction of candidates to training and consulting of employees of the organization. According to various personnel agencies, the research devoted to the evaluation of the effectiveness of the introduction of information technologies in the sphere of work with human resources in Russian organizations. In the conclusions of the article the key directions of application of artificial intelligence technologies in the management of human resources, as well as the key risks and dangers that await specialists on personnel management in this area.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-15160-7_137,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-36315-4_2,From Data Journalism to Robotic Journalism: The Automation of News Processing,Journalistic Metamorphosis,10.1007/978-3-030-36315-4_2,Springer,2020-01-01,"The 21st century is a reaffirmation of automation and through big data and data journalism begins to speak of the ‘robot journalism’, the ‘automated journalism’ and the weight of ‘cognitive journalism’. This article refers to how Artificial Intelligence (AI) is beginning to occupy a field traditionally dominated by the human factor in the management of information relations between organizations, the media and society by the application of data mining to generate algorithms that make it possible to automate the management and derive it to the work of bots in the elaboration of news. It also addresses how the journalistic profession lives apparently oblivious to the robotization of the newsrooms, although the origin of mass automation dates back to 2014 when Associated Press with Automated Insights and Zacks Investment Research generated 3000 news about ‘corporate profits’.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-36315-4_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00542-019-04554-5,Position error prediction using hybrid recurrent neural network algorithm for improvement of pose accuracy of cable driven parallel robots,Microsystem Technologies,10.1007/s00542-019-04554-5,Springer,2020-01-01,"Because cable-driven parallel robots (CDPRs) have lightweight moving parts, CDPRs have been used in various industrial applications requiring high speeds and accelerations. Especially, CDPRs with polymer cables can achieve higher accelerations and speeds compared to those with steel cables. However, they also have some disadvantages, such as a nonlinear creep, a hysteresis, and a short- and long-term recovery. Because these nonlinear characteristics, the accuracy of CDPRs gets worse and worse. In this study, we proposed a hybrid recurrent neural network (H-RNN) to predict nonlinear characteristics of the cable elongation and to solve the problems associated with CDPRs and apply the real-time control. In the algorithm, the long short-term memory (LSTM) algorithm was used to learn the characteristics of the low-frequency data, and the basic RNN learned the features of the high-frequency data. We also confirmed that the cut-off frequency was determined based on the non-operating frequency related to rest time. Also, it yielded more accurate results because the LSTM has a wider effective frequency range. Finally, the learning process was completed by combining these two algorithms. These results made it possible to predict position errors of CDPRs with high accuracy, in which error varies under both while operating and no operation conditions. The H-RNN had a lower root mean square error than both the optimal RNN and the optimal LSTM, so it was effective for controlling systems that have errors across a range of frequencies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00542-019-04554-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-2133-1_16,Design and Comparison of Two Evolutionary and Hybrid Neural Network Algorithms in Obtaining Dynamic Balance for Two-Legged Robots,Frontier Applications of Nature Inspired Computation,10.1007/978-981-15-2133-1_16,Springer,2020-01-01,"In a closed-loop control scheme, the proportional–integral–derivative (PID) controllers are mainly used to diminish the error between the desired setpoint and the actual measured value. It is significant to note that some kind of tuning procedure is essential to acquire the optimal values for the gains of the controller to reach the desired setpoint. In this chapter, to tune the gains of the PID controller, the authors are made to develop an adaptive neural network algorithm. Further, the authors of this manuscript proposed a metaheuristic optimization algorithm, that is, modified chaotic invasive weed optimization (MCIWO) algorithm to train the weights of the neural network (NN). Moreover, the well-established optimization algorithm, that is, particle swarm optimization (PSO) algorithm has also been separately used to optimize the structure of NN. Once the controllers are developed, the required torque to move every joint of the two-legged robot on the said terrain will be predicted. In addition to the above parameters, the zero moment point (ZMP) of the foot and dynamic balance margin (DBM) of the gait have also been calculated and considered as a measure to compare the performances of the developed approaches. Further, the neural network-based PID controller tuned with MCIWO algorithm is seen to produce more dynamically balanced gaits than that of the PSO trained NN. Finally, the optimal gaits obtained through the MCIWO-NN algorithm have been confirmed on an actual two-legged robot in our laboratory.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-2133-1_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-32-9686-2_60,An Efficient Loop Closure Detection Based on Convolutional Autoencoder Neural Network for Autonomous Robots,Proceedings of 2019 Chinese Intelligent Systems Conference,10.1007/978-981-32-9686-2_60,Springer,2020-01-01,"Loop closure detection is the core part of the visual simultaneous localization and mapping (VSLAM) for autonomous robots. In the dynamic environments, loop closure detection turns to be a very difficult problem compared to the static scenario. This paper proposes a novel approach based on convolutional autoencoder neural network (CAENN) architecture for extracting images features, and then uses Euclidean loss for minimizing the difference between the extracted feature and the gist feature which has the ability of scene recognition. In order to improve the accuracy and recall rate for loop closure detection in the dynamic scenario, the perspective transformation and dynamic object are applied in the process of the construction of the training set. And by calculating the Manhattan distance between the two image feature vectors, the loop closure is accepted when the distance is smaller than the threshold. The experimental results demonstrate that the proposed method obtains better accuracy and recall rate compared to the commonly used gist feature method and has a lower cost on time and space compared to the BOW method and AlexNet method in loop closure detection.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-32-9686-2_60,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-57365-6_12-2,AI and Robotics Innovation,"Handbook of Labor, Human Resources and Population Economics",10.1007/978-3-319-57365-6_12-2,Springer,2020-01-01,"Economic activities based on the invention, production, and distribution of artificial intelligence (AI) technologies have recently emerged worldwide. Yet, little is known about the innovative activities, location, and growth performance of AI innovators. This chapter aims to map and analyze the global innovative landscape of AI by exploring 155,000 patents identified as AI-related by means of text-mining techniques. It highlights the emergence and evolution of AI technologies and identifies AI hotspots across the world. It explores the scale and pervasiveness of AI activities across sectors and evaluates the economic performance of AI innovators using firm accounting information. Finally, it assesses recent trends in venture capital investments towards AI as financial support to promising AI startups. Findings of this chapter reveal a tremendous increase in AI patenting activities since 2013 with a significant boom in 2015–2016. While most of AI patenting activities remain concentrated in the sectors of software programming and manufacturing of electronic equipment and machinery, there are clear signs of cross-fertilization towards (nontech) sectors. The market of AI patenting firms is very vibrant and characterized by a large increase of new and small players with economic performances above industry average. This trend is also reflected by the recent increase in venture capital towards AI startups.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-57365-6_12-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-29135-8_3,The AI Driving Olympics at NeurIPS 2018,The NeurIPS '18 Competition,10.1007/978-3-030-29135-8_3,Springer,2020-01-01,"Despite recent breakthroughs, the ability of deep learning and reinforcement learning to outperform traditional approaches to control physically embodied robotic agents remains largely unproven. To help bridge this gap, we present the “AI Driving Olympics” (AI-DO), a competition with the objective of evaluating the state of the art in machine learning and artificial intelligence for mobile robotics. Based on the simple and well-specified autonomous driving and navigation environment called “Duckietown,” the AI-DO includes a series of tasks of increasing complexity—from simple lane-following to fleet management. For each task, we provide tools for competitors to use in the form of simulators, logs, code templates, baseline implementations and low-cost access to robotic hardware. We evaluate submissions in simulation online, on standardized hardware environments, and finally at the competition event. The first AI-DO, AI-DO 1, occurred at the Neural Information Processing Systems (NeurIPS) conference in December 2018. In this paper we will describe the AI-DO 1 including the motivation and design objections, the challenges, the provided infrastructure, an overview of the approaches of the top submissions, and a frank assessment of what worked well as well as what needs improvement. The results of AI-DO 1 highlight the need for better benchmarks, which are lacking in robotics, as well as improved mechanisms to bridge the gap between simulation and reality.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-29135-8_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-57365-6_12-1,AI and Robotics Innovation,"Handbook of Labor, Human Resources and Population Economics",10.1007/978-3-319-57365-6_12-1,Springer,2020-01-01,"Economic activities based on the invention, production, and distribution of artificial intelligence (AI) technologies have recently emerged worldwide. Yet, little is known about the innovative activities, location, and growth performance of AI innovators. This chapter aims to map and analyze the global innovative landscape of AI by exploring 155,000 patents identified as AI-related by means of text-mining techniques. It highlights the emergence and evolution of AI technologies and identifies AI hotspots across the world. It explores the scale and pervasiveness of AI activities across sectors and evaluates the economic performance of AI innovators using firm accounting information. Finally, it assesses recent trends in venture capital investments towards AI as financial support to promising AI startups. Findings of this chapter reveal a tremendous increase in AI patenting activities since 2013 with a significant boom in 2015–2016. While most of AI patenting activities remain concentrated in the sectors of software programming and manufacturing of electronic equipment and machinery, there are clear signs of cross-fertilization towards (nontech) sectors. The market of AI patenting firms is very vibrant and characterized by a large increase of new and small players with economic performances above industry average. This trend is also reflected by the recent increase in venture capital towards AI startups.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-57365-6_12-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-50426-7_25,Autonomous Guided Vehicles for Smart Industries – The State-of-the-Art and Research Challenges,Computational Science – ICCS 2020,10.1007/978-3-030-50426-7_25,Springer,2020-01-01,"Autonomous Guided Vehicles (AGVs) are considered to be one of the critical enabling technologies for smart manufacturing. This paper focus on the application of AGVs in new generations of manufacturing systems including: (i) the fusion between AGVs and collaborative robots; (ii) the application of machine to machine communication for integrating AGVs with the production environment and (iii) AI-driven analytics that is focused on the data that is produced and consumed by AGV. This work aims to evoke discussion and elucidate the current research opportunities, highlight the relationship between different subareas and suggest possible courses of action.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-50426-7_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-2696-1_54,Navigational Control Analysis of Mobile Robot in Cluttered Unknown Environment Using Novel Neural-GSA Technique,Innovative Product Design and Intelligent Manufacturing Systems,10.1007/978-981-15-2696-1_54,Springer,2020-01-01,"A unique hybridized neural-GSA artificial intelligence strategy has been proposed in this current paper for the steerage of a wheeled mobile robot in an obstacle prone environment. In this work, a seven-layered back propagation neural network has been hybridized with GSA to synthesize a controller for the wheeled mobile robot. The inputs to the neural-GSA approach are front obstacle distance, left obstacle distance, right obstacle distance and target angle. The output from the neural network is intermediate steering angle. The inputs to the GSA system in neural-GSA technique are front obstacle distance, left obstacle distance, right obstacle distance and intermediate steering angle. The output from the GSA controller is final steering angle. During the research, several simulations are carried out. Using the proposed neural-GSA strategy as well as theoretical results, it has been found out that the robot can successfully navigate in an obstacle prone environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-2696-1_54,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-42058-1_32,Soft Computing-Based Control System of Intelligent Robot Navigation,Intelligent Information and Database Systems,10.1007/978-3-030-42058-1_32,Springer,2020-01-01,"This paper focuses on the study of intelligent navigation techniques which are capable of navigating a mobile robot autonomously in unknown environments in real-time. We primarily focused on a soft computing-based control system of autonomous robot behaviour. The soft computing methods included artificial neural networks and fuzzy logic. Using them, it was possible to control autonomous robot behaviour. Based on defined behaviour, this device was able to deduce a corresponding reaction to an unknown situation. Real robotic equipment was represented by a Lego Mindstorms EV3 robot. The outcomes of all experiments were analysed in the conclusion.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-42058-1_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-32-9990-0_5,Autonomous Robot Navigation Using Moth-Flame-Based Neuroevolution,Evolutionary Machine Learning Techniques,10.1007/978-981-32-9990-0_5,Springer,2020-01-01,"Determining the best set of weights and biases for training neural networks (NN) using gradient descent techniques is a computationally challenging task. On the other hand, training of gradient descent algorithms suffers from being trapped in local optima and slow convergence speed in the last iterations. The moth-flame optimization (MFO) is a novel evolutionary method based on navigation paths of moths in nature. This algorithm showed its effectiveness in many real-world optimization problems. In this chapter, MFO is employed for training multilayer perceptron (MLP) to overcome the problems of gradient descent algorithms. This algorithm also investigates the application of the MFO for tackling the navigation of autonomous mobile robots. The results are compared with four powerful evolutionary algorithms including gray wolf optimizer (GWO), cuckoo search (CS), multiverse optimizer algorithm (MVO), and particle swarm optimization (PSO). Moreover, the results are compared to two gradient-based training MLP algorithms including Levenberg–Marquardt (LM) and back-propagation (BP). The evaluation metrics used in this book chapter are accuracy and area under the curve (AUC). The experimental results show that MFO-based MLP algorithm outperforms other algorithms and showed its capabilities effectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-32-9990-0_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-20135-7_8,How Can Robotics Be Integrated into the Field of Care and Acceptance by the Population for the Use of Artificial Intelligence Be Strengthened?,"Advances in Human Factors in Training, Education, and Learning Sciences",10.1007/978-3-030-20135-7_8,Springer,2020-01-01,"The interviews with experts from the field of nursing science and robotics, which were conducted as part of a project study, were intended to provide an overview of the current status of the use of AI, especially with focus on acceptance research. It was found that there is a change towards a service society. During this change, acceptance would have to be created partly trough participation and education, in addition to the focus on transparency in action. The focus here is on the degree of autonomy of the robots and the overcoming of technical knowledge barriers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-20135-7_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-06170-8_12,Robotics and Artificial Intelligence,A Guided Tour of Artificial Intelligence Research,10.1007/978-3-030-06170-8_12,Springer,2020-01-01,"Robotics is an interdisciplinary research field leveraging on control theory, mechanical engineering, electronic engineering and computer science. It aims at designing machines able to perceive, move around and interact with their environment in order to perform useful tasks. Artificial Intelligence (AI) is an area of computer science, overlapping with, but significantly distinct from robotics. Its purpose includes the development of computational models of intelligence, as well as the design and experiment with systems which implement these models. There is a significant convergence between Robotics and AI. Their intersection is critical for both areas. Robots implement a “ perception - decision - action ” loop. The decision making part is central in that loop for tackling variable environments and tasks. On the other hand, AI is broadening an initial focus on abstract tasks, as in mathematics and board games, to addressing embodied intelligence. This chapter covers some of the research topics and approaches in the intersection of robotics and AI. It surveys the state of the art in key issues such as planning and acting deliberately on the basis of tasks and world models, learning these models, and organizing the sensory-motor and cognitive functions of a robot into resilient and scalable architectures.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-06170-8_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-39512-4_38,"Caterina, Alexa and the Others",Intelligent Human Systems Integration 2020,10.1007/978-3-030-39512-4_38,Springer,2020-01-01,"What will the future identity of design be? Perhaps that of making man-machine communication even more fluid through the development of more intuitive interfaces and objects that prolong us, capable of inducing the emotion of non-reality or on the contrary will tend to restore strength to the material, to the tangible aspects and to the real emotions? Artificial intelligence is meaningless, it cannot therefore give sense or meaning to what it learns, so the strategic vision of design will remain a human responsibility just as creativity will always belong to that side of the human, that artificial intelligence cannot understand and undermine. We can therefore conclude that yes, probably in future, many works will be carried out by robots, but still instructed by man.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-39512-4_38,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-50801-2_17,Impossible Sports,21st Century Sports,10.1007/978-3-030-50801-2_17,Springer,2020-01-01,"To illustrate how future technologies will shape future sports, Subirana and Laguarta explore an imaginary future—following a fictional character and her family through a day in their lives. They highlight potential applications of technologies in the fields of the Internet of things, robotics and automation, information processing, communications, and legal programming in new sports. The chapter also explores potential sports that, beyond entertainment, could solve real-life problems or otherwise improve society with examples like improved human relationships with animals, increased safety from environmental dangers, and more efficient smart cities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-50801-2_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-40271-6_27,Background of the Revision of the Secondary School Engineering Curriculum in the Context of the Society 4.0,The Impact of the 4th Industrial Revolution on Engineering Education,10.1007/978-3-030-40271-6_27,Springer,2020-01-01,"The study responds to the characteristics of Society 4.0, which links industry, services, science, research, innovation and new digital technologies. Education 4.0 must ensure the preparation for the digital age and the expansion of digital skills across generations while increasing the use of digital technology in school and in-service training. Digitization, robotics and the potency of artificial intelligence also significantly influence engineering production, which requires a different qualification of workers. European Qualifications Frameworks are a suitable tool for revising engineering study. The revision must be based on trends in engineering, analysis of the educational needs of this sector, current educational concept and knowledge of the specifics of the current young generation. The revised curriculum should integrate professional competences with key competences and transversal (cross-curricular) skills, allowing school leavers to enter the production or production practice and excellent students a higher level of engineering education. The authors of the study deal with the research grant of the Technological Agency of the Czech Republic entitled “Education in engineering fields and its optimisation for the labour market”, which will be one of the research starting points for the commenced review of the curriculum. Research uses a number of empirical methods to identify unnecessary parts of the curriculum and to identify new components in terms of learning goals and learning outcomes in both the vocational and general education fields. Research findings will be compared with foreign results and discussed with engineering companies as purchasers of graduates and educators at secondary engineering schools to meet the needs of the emerging Industry 4.0 and the real educational potential of schools. The study presents the results of analyses of trends in the engineering industry, its human resources needs and requirements for the professional profile of workers in this sector, especially in the Czech Republic as an industrialized country.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-40271-6_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-50801-2_4,"Robotics, Automation, and the Future of Sports",21st Century Sports,10.1007/978-3-030-50801-2_4,Springer,2020-01-01,"This chapter explores the growing influence of robotics and automation on sports and potential resultant future states. In this chapter, Siegel and Morris describe advances leading to broader deployment of robotics and automation and envision how these technologies may lead to new models for spectator experience by increasing engagement and interactivity. Next, they consider how robotics and automation create opportunities for improved athlete training and detail how robotics and automation have augmented sports by allowing new athletes to compete, creating new sports, and providing a playing field for intellectual athletes. Finally, they envision possible future evolutions of sports leveraging robotic advances and present a case study on how robotics might impact motorsport, closing by considering potential non-technical challenges and risks in inviting robots into sport.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-50801-2_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-37841-7_4,Control and Ergonomic Problems of Collaborative Robotics,Robotics: Industry 4.0 Issues & New Intelligent Control Paradigms,10.1007/978-3-030-37841-7_4,Springer,2020-01-01,Together with the development of information technology and artificial intelligence robotics intended to enlighten the more and more area of human life and work. It results in a change of the method of communication between human and “intelligence robot” capable of autonomous behavior—from control to collaboration. The new branch of robotics has been formed nowadays as collaborative robotics. The new ways of application of robotics create the new problems of communication of human and “intelligent” robot which are not only technical but also of a psychological kind because human-operator now becomes a part of the human-robot system. The new problems demand the development of new methods in the field of cognitive ergonomics. Some of the problems are under discussion below.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-37841-7_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-43890-6_27,AI-Powered Lethal Autonomous Weapon Systems in Defence Transformation. Impact and Challenges,Modelling and Simulation for Autonomous Systems,10.1007/978-3-030-43890-6_27,Springer,2020-01-01,"Robotics and artificial intelligence (AI) are changing business, and transforming defense and warfare. In particular, the paper addresses the challenges from the easy availability of AI resources to be applied to drones that are already an asymmetric threat, and the issues concerning the Lethal Autonomous Weapons Systems (LAWS) that promise military advantages like the reduction of deployed soldiers, loss of civilians, damage of infrastructures, and the rapid support to decision-making. Autonomous systems can also help in disaster and humanitarian operations. However, the deployment of systems that are more and more autonomous from humans poses multidimensional challenges for their certification, compliance with ethics and international humanitarian law and present risks to security. Mechanisms for the mitigation of their proliferation to malicious non-state actors and a meaningful human control should be implemented. War gaming in a theoretical, risk-safe environment can assess the threats and impact of robotic weapons on future defense planning and operations. From the example of the lessons learned in the automotive industry, simulation can be applied to digital twin models of the AI system and the environment to train and test under unexpected and extreme conditions, unanticipated hardware and software failure situations and in complex dynamic operational contexts including interaction with civilian entities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-43890-6_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-39319-9_45,Features of Artificial Intelligence Simulation Models and Risks When Using Them,Artificial Intelligence: Anthropogenic Nature vs. Social Origin,10.1007/978-3-030-39319-9_45,Springer,2020-01-01,"This paper is aimed at emphasizing that ample opportunities in robotics have made their appearance at the current stage of development of computer technologies. Modern computer technologies make it possible to analyze an enormous number of input and output actions on the management systems. Ample opportunities in robotics make their appearance, making it possible to create and commission machines with Artificial Intelligence. The authors of the paper give consideration to the problem of creation of Artificial Intelligence which is capable of carrying out operation an infinite aggregate of operations. The management processes can be implemented using the Artificial Intelligence simulation modeling. The simulation modeling is able to provide feedback and to achieve the evolution of the capabilities of human intelligence through the use of the “method of successive approximations”. The methodological foundation of this paper consists in the economics and statistics analysis of the most common probability theory distributions: normal, exponential and uniform. The authors analyze difficulties on the way toward the selection of methods and algorithms able to solve the problem of creation of Artificial Intelligence. The result of work consists in the assessment of managerial decision-making risk functions in every distribution of random variables under consideration. In addition, the generalization of risk functions in the multidimensional stochastic process – a multiplicative model with functional shift – has been constructed. We note finally : using the capabilities of the simulation modeling and modern computer technologies will allow making the best choice in the creation and control of machines endowed with Artificial Intelligence.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-39319-9_45,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-24513-9_2,Challenges and Solutions of Using the Social Internet of Things in Healthcare and Medical Solutions—A Survey,"Toward Social Internet of Things (SIoT): Enabling Technologies, Architectures and Applications",10.1007/978-3-030-24513-9_2,Springer,2020-01-01,"Social Internet of Things (SIoT) is considered as one of the most attractive topics in the last centuries of researches. It introduces a lot of technologies in different fields based on the new intelligent things of era internet. Furthermore, it plays an important role to update new technologies of healthcare and medical Robotics. In this chapter, we introduce some of the challenges of using the SIoT in healthcare and medical applications. The different methods and solutions utilize big data in different fields. After giving a survey about these challenges and solutions, we introduce two recent applications of our own in healthcare solutions. The first application is for heart diseases diagnosis and the second is for brain tumor diagnosis. The results of the two applications prove the importance of SIoT in healthcare solutions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-24513-9_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-30271-9_6,Soft Computing in Robotics: A Decade Perspective,Applications of Robotics in Industry Using Advanced Mechanisms,10.1007/978-3-030-30271-9_6,Springer,2020-01-01,"As soft computing deals with development of approximate models in finding solutions to real world problems, it is considered as one of the emerging area of research in all fields of engineering and sciences. Because of rapid development in mechanization, vast research has also been carried out by the researchers in the field of robotics for the development of robots in various applications such as industry, medical, rehabilitation, agriculture, military etc. to assist human being. In this paper, a comprehensive analytical perspective of soft computing techniques and their application in robotics has been illustrated. Further, the analysis is a witness of the fact that problems emerging in the robotics can be solved aptly using soft computing techniques. Also, this paper sheds light on various issues and challenges of the discussed research area to demonstrate the dominance of soft computing techniques in the development of various applications in robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30271-9_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-31635-8_238,Feedback-Error Learning Control for Powered Assistive Devices,XV Mediterranean Conference on Medical and Biological Engineering and Computing – MEDICON 2019,10.1007/978-3-030-31635-8_238,Springer,2020-01-01,"Active orthoses (AOs) are becoming relevant for user-oriented training in gait rehabilitation. This implies efficient responses of AO’s low-level controllers with short time modeling for medical applications. This thesis investigates, in an innovative way, the performance of Feedback-Error Learning (FEL) control to time-effectively adapt the AOs’ responses to user-oriented trajectories and changes in the dynamics due to the interaction with the user. FEL control comprises a feedback PID controller and a neural network feedforward controller to promptly learn the inverse dynamics of two AOs. It was carried out experiments with able-bodied subjects walking on a treadmill and considering external disturbances to user-AO interaction. Results showed that the FEL control effectively tracked the user-oriented trajectory with position errors between 5% to 7%, and with a mean delay lower than 25 ms. Compared to a single PID control, the FEL control decreased by 16.5% and 90.7% the position error and delay, respectively. Moreover, the feedforward controller was able to learn the inverse dynamics of the two AOs and adapt to variations in the user-oriented trajectories, such as speed and angular range, while the feedback controller compensated for random disturbances. FEL demonstrated to be an efficient low-level controller for controlling AOs during gait rehabilitation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-31635-8_238,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-58817-5_72,Detection of Obstacle Features Using Neural Networks with Attention in the Task of Autonomous Navigation of Mobile Robots,Computational Science and Its Applications – ICCSA 2020,10.1007/978-3-030-58817-5_72,Springer,2020-01-01,"This article describes the design process of a software package for image recognition of a mobile robot camera using neural networks with attention, which allows to identify the probability of a robot colliding with obstacles standing in its way. A key feature of this software is using a dataset that is prepared without manual labeling of all obstacles and the probability of a collision. Currently, an important task in mobile robotics is the need to use numerous heuristics and deterministic algorithms in control programs along with neural networks. The use of a single neural network that solves all the tasks of scene analysis (the so-called “end-to-end” solution) is impossible for several reasons: the high complexity of the training samples due to the large parameter space of the environment of the robot and the insufficient formalization of these parameters, as well as the computational complexity of machine learning algorithms, which is critical for mobile robots with strict energy requirements. Therefore, the development of a universal algorithm (end-to-end) is a laborious process. The article describes a method that allows to use weakly formalized parameters of the robot environment for training convolutional neural networks with attention using the obstacle recognition task. At the same time, weak formalization reduces the time-consuming process of manual data labeling due to automatically generated datasets in the NVIDIA Isaac environment, and the attention mechanism allows increasing the interpretability of the analysis results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58817-5_72,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-55789-8_5,Path Planning of Mobile Robot Group Based on Neural Networks,Trends in Artificial Intelligence Theory and Applications. Artificial Intelligence Practices,10.1007/978-3-030-55789-8_5,Springer,2020-01-01,"This article is devoted to development of a neural control system for group of drones. The control system estimates the environmental complexity, selects the best path planning algorithm, and plans the path of the copters. Algorithm of the complexity estimation is a logical classification of the environmental state. The complexity depends of obstacle’s location in the environment. Selection of the best path planning algorithm is a neural classification of the environment. The neural network selects the best path planning algorithm from two algorithms. The first one is the shortest path planning algorithm, and the second one is the safest path planning algorithm. A hybrid learning algorithm is proposed for the neural classifier of the environment. This learning algorithm consists of a supervised and an unsupervised unit. Evaluation of the neural classifier is performed by the multi criterion including the motion time, the path length, and the minimal distance from the path to the obstacles. The path planning algorithms are implemented by neural networks also. These networks are trained by supervised algorithms. The neural planner output is the next desired location of the drone, but not whole path to the target point. This approach allows the group of drones to operate in a dynamical environment without recalculating the whole path. Also this research proposes algorithms of drone’s formation in an uncertain unmapped 3-D environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-55789-8_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-48791-1_1,A Compact Sequence Encoding Scheme for Online Human Activity Recognition in HRI Applications,Proceedings of the 21st EANN (Engineering Applications of Neural Networks) 2020 Conference,10.1007/978-3-030-48791-1_1,Springer,2020-01-01,"Human activity recognition and analysis has always been one of the most active areas of pattern recognition and machine intelligence, with applications in various fields, including but not limited to exertion games, surveillance, sports analytics and healthcare. Especially in Human-Robot Interaction, human activity understanding plays a crucial role as household robotic assistants are a trend of the near future. However, state-of-the-art infrastructures that can support complex machine intelligence tasks are not always available, and may not be for the average consumer, as robotic hardware is expensive. In this paper we propose a novel action sequence encoding scheme which efficiently transforms spatio-temporal action sequences into compact representations, using Mahalanobis distance-based shape features and the Radon transform. This representation can be used as input for a lightweight convolutional neural network. Experiments show that the proposed pipeline, when based on state-of-the-art human pose estimation techniques, can provide a robust end-to-end online action recognition scheme, deployable on hardware lacking extreme computing capabilities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-48791-1_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-4932-2_14,Tire Defect Detection Based on Faster R-CNN,Robotics and Rehabilitation Intelligence,10.1007/978-981-33-4932-2_14,Springer,2020-01-01,"The tire defect detection method can help the rehabilitation robot to achieve autonomous positioning function and improve the accuracy of the robot system behavior. Defects such as foreign matter sidewall, foreign matter tread, and sidewall bubbles will appear in the process of tire production, which will directly or indirectly affect the service life of the tire. Therefore, a novel and efficient tire defect detection method was proposed based on Faster R-CNN. At preprocessing stage, the Laplace operator and the homomorphic filter were used to sharpen and enhance the data set, the gray values of the image target and the background were significantly different, which improved the detection accuracy. Moreover, data expansion was used to increase the number of images and improve the robustness of the algorithm. To promote the accuracy of the position detection and identification, the proposed method combined the convolution features of the third layer and the convolution features of the fifth layer in the ZF network (a kind of convolution neural network). Then, the improved ZF network was used to extract deep characteristics as inputs for Faster R-CNN. From the experiment, the proposed faster R-CNN defect detection method can accurately classify and locate the tire X-ray image defects, and the average test recognition rate is up to 95.4%. Moreover, if there are additional types of defects that need to be detected, then a new detection model can be obtained by fine-tuning the network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-4932-2_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-019-03969-6,Neural collision avoidance system for biomimetic autonomous underwater vehicle,Soft Computing,10.1007/s00500-019-03969-6,Springer,2020-01-01,"Autonomous underwater vehicles (AUVs) are underwater robots which are able to perform certain tasks without the help of a human operator. The key skill of each AUV is the capability to avoid collisions. To this end, appropriate devices and software are necessary with the potential to detect obstacles and to take proper decisions from the point of view of both the task and safety of the vehicle. The paper presents a neural collision avoidance system (NCAS) designed for the biomimetic autonomous underwater vehicle (BAUV). The NCAS is a component of the path following and collision avoidance system (PFCAS), which as the name implies is responsible for safely leading the vehicle along a desired path with collision avoidance. The task of NCAS is to make decisions regarding vehicle maneuvers in the horizontal plane, but only in the close proximity of the obstacles. It is implemented as an evolutionary artificial neural network designed by means of a neuro-evolutionary technique called assembler encoding with evolvable operations (AEEO). The paper outlines operation and construction of the BAUV as well as the PFCAS, the role of the NCAS in the entire system, and briefly presents AEEO as well as reporting on the experiments performed in simulation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-019-03969-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-39225-3_41,Automation in Foundry Industry: Modern Information and Cyber-Physical Systems,Advances in Automation,10.1007/978-3-030-39225-3_41,Springer,2020-01-01,"The automation of the foundry industry in the framework of the forthcoming sixth technological system evolves through the introduction of: cyber-physical systems, industry internet, IoT industry, smart production, 4.0 industry, cloud calculations and neural networks. Currently, in the area of the foundry industry the manual labour still prevails at the stages of materials finishing processing. Cyber-physical systems based on manipulation robots are very efficient in solving tasks of grinding parts after casting. The positioning problem solution for precise approach of a part to the surface of a processing tool with addition of force control makes the system more complicated. The equipment of the manipulation robot with a control system on the basis of a neural network controller is considered assuring the solution to the inverse kinematics problem taking into account the force of processed part interaction with a grinding disc of the abrasive tool. The comparison of analytical and experimental solutions has shown that the precision of the abrasive machining is approximately uniform in the limits of normative values. In this case the complexity of the development of the control algorithm is significantly lower if the neural network control method is used.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-39225-3_41,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-50794-7_11,Object Recognition Using Neural Networks for Robotics Precision Application,"Advances in Design, Simulation and Manufacturing III",10.1007/978-3-030-50794-7_11,Springer,2020-01-01,"The fourth industrial revolution is based on the fusion of different technologies and, in particular, between machines and information, and encourages companies to integrate new tools in their production processes to improve working conditions and increase productivity and production quality of companies. The future of production, therefore, depends on increasingly intelligent machinery through the use of digital systems. Intelligent machines and systems are the key elements for future integrated infrastructures based on human-machine interaction and information sharing. This sharing requires the implementation of shared languages that allow different systems to dialogue in a simple way. With this in mind, the ability of machines or systems to learn new operations through the use of algorithms based on neural networks allows us to have increasingly flexible machines capable of replicating the learning processes of human beings. Such self-learning techniques will allow developing a new class of machines capable of revolutionizing our companies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-50794-7_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-25719-4_71,Closed Loop Control of a Compliant Quadruped with Spiking Neural Networks,Biologically Inspired Cognitive Architectures 2019,10.1007/978-3-030-25719-4_71,Springer,2020-01-01,"Compliant robots can be more versatile than traditional robots, but their control is more complex. The dynamics of compliant bodies can however be turned into an advantage using the physical reservoir computing framework. By feeding sensor signals to the reservoir and extracting motor signals from the reservoir, closed loop robot control is possible. Here, we present a novel framework for implementing central pattern generators with spiking neural networks to obtain closed loop robot control. Using the FORCE learning paradigm, we train a reservoir of spiking neuron populations to act as a central pattern generator. We demonstrate the learning of predefined gait patterns, speed control and gait transition on a simulated model of a compliant quadrupedal robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-25719-4_71,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-61401-0_18,6D Pose Estimation of Texture-Less Objects on RGB Images Using CNNs,Artificial Intelligence and Soft Computing,10.1007/978-3-030-61401-0_18,Springer,2020-01-01,"In this paper, we present a convolutional neural network-based approach to 6D pose estimation on RGB images segmented in advance. We designed and trained two neural networks to achieve reliable 6D object pose estimation on such images. The first neural network detects fiducial points of objects, which are then fed to a PnP algorithm responsible for pose estimation. The second one is an rotation regression network delivering at the output the quaternion. The neural networks were trained on our datasets containing both real images as well as photo-realistic images, which have been rendered on the basis of our 3D models. The performance of neural networks for object segmentation and 6D pose estimation was evaluated using both real and synthesized images. Experimental results demonstrate a high potential of our approach to pose estimation of texture-less objects observed by RGB camera and mounted on arm of the Franka-Emika robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-61401-0_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-12082-5_46,Problems of Intelligent Automation of Unmanned Underground Coal Mining,Advances in Artificial Systems for Medicine and Education II,10.1007/978-3-030-12082-5_46,Springer,2020-01-01,"The article deals with the field of artificial intelligence in two aspects: (1) in the broad sense, the interaction between man and machine, the automation of processes, intellectual automation are considered; (2) specifically it treats neural networks applications, in particular for the recognition of echolocation signals. The possibilities for underground coal mining without the permanent presence of workers in areas of working faces (the so-called technology of unmanned coal mining) are studied, in this respect advantages of plow cutter technology for thin seams being shown as well as needs of its perfection. Main objectives for automation of technological and logistical operations during underground coal excavation are analyzed; in particular, to achieve greater maneuverability of extraction units by controlling their positions on the bottoms of coal seams. The paper also notes that the main of controlling positions of machines that result from non-parallelism of the drifts, assume the use of technique of neural networks being proposed as the means of adjusting these positions. It is shown that the dynamism of the operation mode of the electric drive when mining thin seams demands application of tensioning devices for plow chain to reduce dynamic loads in the electromechanical system in question. As for the operation system of unmanned coal mining as a whole, intelligent control with the possibility of creating self-organizing systems is discussed and proposed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-12082-5_46,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s12910-019-0437-z,Ethical concerns with the use of intelligent assistive technology: findings from a qualitative study with professional stakeholders,BMC Medical Ethics,10.1186/s12910-019-0437-z,BioMed Central,2019-12-19,"Background Advances in artificial intelligence (AI), robotics and wearable computing are creating novel technological opportunities for mitigating the global burden of population ageing and improving the quality of care for older adults with dementia and/or age-related disability. Intelligent assistive technology (IAT) is the umbrella term defining this ever-evolving spectrum of intelligent applications for the older and disabled population. However, the implementation of IATs has been observed to be sub-optimal due to a number of barriers in the translation of novel applications from the designing labs to the bedside. Furthermore, since these technologies are designed to be used by vulnerable individuals with age- and multi-morbidity-related frailty and cognitive disability, they are perceived to raise important ethical challenges, especially when they involve machine intelligence, collect sensitive data or operate in close proximity to the human body. Thus, the goal of this paper is to explore and assess the ethical issues that professional stakeholders perceive in the development and use of IATs in elderly and dementia care. Methods We conducted a multi-site study involving semi-structured qualitative interviews with researchers and health professionals. We analyzed the interview data using a descriptive thematic analysis to inductively explore relevant ethical challenges. Results Our findings indicate that professional stakeholders find issues of patient autonomy and informed consent, quality of data management, distributive justice and human contact as ethical priorities. Divergences emerged in relation to how these ethical issues are interpreted, how conflicts between different ethical principles are resolved and what solutions should be implemented to overcome current challenges. Conclusions Our findings indicate a general agreement among professional stakeholders on the ethical promises and challenges raised by the use of IATs among older and disabled users. Yet, notable divergences persist regarding how these ethical challenges can be overcome and what strategies should be implemented for the safe and effective implementation of IATs. These findings provide technology developers with useful information about unmet ethical needs. Study results may guide policy makers with firsthand information from relevant stakeholders about possible solutions for ethically-aligned technology governance.",https://www.biomedcentral.com/openurl?doi=10.1186/s12910-019-0437-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s40942-019-0202-y,"Artificial intelligence, robotics and eye surgery: are we overfitted?",International Journal of Retina and Vitreous,10.1186/s40942-019-0202-y,BioMed Central,2019-12-16,"Eye surgery, specifically retinal micro-surgery involves sensory and motor skill that approaches human boundaries and physiological limits for steadiness, accuracy, and the ability to detect the small forces involved. Despite assumptions as to the benefit of robots in surgery and also despite great development effort, numerous challenges to the full development and adoption of robotic assistance in surgical ophthalmology, remain. Historically, the first in-human–robot-assisted retinal surgery occurred nearly 30 years after the first experimental papers on the subject. Similarly, artificial intelligence emerged decades ago and it is only now being more fully realized in ophthalmology. The delay between conception and application has in part been due to the necessary technological advances required to implement new processing strategies. Chief among these has been the better matched processing power of specialty graphics processing units for machine learning. Transcending the classic concept of robots performing repetitive tasks, artificial intelligence and machine learning are related concepts that has proven their abilities to design concepts and solve problems. The implication of such abilities being that future machines may further intrude on the domain of heretofore “human-reserved” tasks. Although the potential of artificial intelligence/machine learning is profound, present marketing promises and hype exceeds its stage of development, analogous to the seventieth century mathematical “boom” with algebra. Nevertheless robotic systems augmented by machine learning may eventually improve robot-assisted retinal surgery and could potentially transform the discipline. This commentary analyzes advances in retinal robotic surgery, its current drawbacks and limitations, and the potential role of artificial intelligence in robotic retinal surgery.",https://www.biomedcentral.com/openurl?doi=10.1186/s40942-019-0202-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-019-00989-0,Evolutionary Robotics Applied to Hexapod Locomotion: a Comparative Study of Simulation Techniques,Journal of Intelligent & Robotic Systems,10.1007/s10846-019-00989-0,Springer,2019-12-15,"The Evolutionary Robotics (ER) process has been applied extensively to developing control programs to achieve locomotion in legged robots, as an automated alternative to the arduous task of manually creating control programs for such robots. The evolution of such controllers is typically performed in simulation by making use of a physics engine-based robotic simulator. Making use of such physics-based simulators does, however, have certain challenges associated with it, such as these simulators’ computational inefficiency, potential issues with lack of accuracy and the human effort required to construct such simulators. The current study therefore proposed and investigated an alternative method of simulation for a hexapod (six-legged) robot in the ER process, and directly compared this newly-proposed simulation method to traditional physics-based simulation. This alternative robotic simulator was built based solely on experimental data acquired directly from observing the behaviour of the robot. This data was used to construct a simulator for the robot based on Artificial Neural Networks (ANNs). To compare this novel simulation method to traditional physics simulation, the ANN-based simulators were used to evolve simple open-loop locomotion controllers for the robot in simulation. The real-world performance of these controllers was compared to that of controllers evolved in a more traditional physics-based simulator. The obtained results indicated that the use of ANN-based simulators produced controllers which could successfully perform the required locomotion task on the real-world robot. In addition, the controllers evolved using the ANN-based simulators allowed the real-world robot to move further than those evolved in the physics-based simulator and the ANN-based simulators were vastly more computationally efficient than the physics-based simulator. This study thus decisively indicated that ANN-based simulators offer a superior alternative to widely-used physics simulators in ER for the locomotion task considered.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-019-00989-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.3103/S1068798X19120256,Control of Collaborative Robot Systems and Flexible Production Cells on the Basis of Deep Learning,Russian Engineering Research,10.3103/S1068798X19120256,Springer,2019-12-01,"Abstract A system for contact-free control of a robot system is based on a three-dimensional biomechanical model of the human skeleton for gesture recognition, by means of deep learning. Preliminary data analysis by calculating saliency maps permits more efficient classification of gestural commands and thus improves the performance of all control systems in the collaborative robot system.",http://link.springer.com/openurl/fulltext?id=doi:10.3103/S1068798X19120256,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-019-00617-x,Weed Management of the Future,KI - Künstliche Intelligenz,10.1007/s13218-019-00617-x,Springer,2019-12-01,"The methods used to protect agricultural products currently undergo drastic changes. Artificial Intelligence is a prime candidate to overcome two challenges faced by farmers around the world: The increasing cost and decreasing availability of human labor for weed control, and the growing global restriction of herbicides. Deep Learning is one of the most prominent approaches for applying AI to all kinds of use cases in industrial applications, entertainment, and security. Its latest field of application is plant classification that enables automated weed control and precise spot spraying of herbicides. While cheap, powerful platforms for deploying classification mechanisms are widely available, this comes at the cost of expensive and effort rich classifier training. This effectively makes Deep Learning-based approaches unavailable for the majority of the agricultural sector. Deepfield Robotics presents a systematic approach for deploying AI onto fields at large, including the learnings that led to their self-contained AI driven plant classification modules that relieve individuals from having to deploy their own AI solution. The same technology acts as enabler for more agricultural domains, such as targeted fertilization, nano irrigation, and automated phenotyping. This article documents Deepfield Robotics’ findings and vision on how AI can be the workhorse for agricultural weeding labor.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-019-00617-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-019-01510-8,Student-t policy in reinforcement learning to acquire global optimum of robot control,Applied Intelligence,10.1007/s10489-019-01510-8,Springer,2019-12-01,"This paper proposes an actor-critic algorithm with a policy parameterized by student-t distribution, named student-t policy, to enhance learning performance, mainly in terms of reachability on global optimum for tasks to be learned. The actor-critic algorithm is one of the policy-gradient methods in reinforcement learning, and is proved to learn the policy converging on one of the local optima. To avoid the local optima, an exploration ability to escape it and a conservative learning not to be trapped in it are deemed to be empirically effective. The conventional policy parameterized by a normal distribution, however, fundamentally lacks these abilities. The state-of-the-art methods can somewhat but not perfectly compensate for them. Conversely, heavy-tailed distribution, including student-t distribution, possesses an excellent exploration ability, which is called Lévy flight for modeling efficient feed detection of animals. Another property of the heavy tail is its robustness to outliers. Namely, conservative learning is performed to not be trapped in the local optima even when it takes extreme actions. These desired properties of the student-t policy enhance the possibility of the agents reaching the global optimum. Indeed, the student-t policy outperforms the conventional policy in four types of simulations, two of which are difficult to learn faster without sufficient exploration and the others have the local optima.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-019-01510-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-018-0834-8,The HeartMath coherence model: implications and challenges for artificial intelligence and robotics,AI & SOCIETY,10.1007/s00146-018-0834-8,Springer,2019-12-01,"HeartMath is a contemporary, scientific, coherent model of heart intelligence. The aim of this paper is to review this coherence model with special reference to its implications for artificial intelligence (AI) and robotics. Various conceptual issues, implications and challenges for AI and robotics are discussed. In view of seemingly infinite human capacity for creative, destructive and incoherent behaviour, it is highly recommended that designers and operators be persons of heart intelligence, optimal moral integrity, vision and mission. This implies that AI and robotic design and production should be continuously optimized through vigilant and appropriate human and material quality control procedures. Evidence is provided for some value and effectiveness of the HeartMath coherence model in this context.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-018-0834-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-019-00619-9,Benchmarking Functionalities of Domestic Service Robots Through Scientific Competitions,KI - Künstliche Intelligenz,10.1007/s13218-019-00619-9,Springer,2019-12-01,"Benchmarking via carefully designed competitions makes it possible to provide a common framework for the rigorous comparison of intelligent and autonomous systems; competitions may play the role of scientific experiments while being appealing both to researchers and to the general public thus promoting critical analysis of systems outside the labs. This paper describes our approach to benchmarking domestic service robots through organizing recurrent competitions under the European Robotics League. It details the tools and benchmarks designed to evaluate the performance of robots at task and functionality levels. In particular, the functionality benchmarks for object perception and navigation are described and an overview of the new benchmarks to appear in the league is presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-019-00619-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00170-019-03806-y,A collaborative robot for the factory of the future: BAZAR,The International Journal of Advanced Manufacturing Technology,10.1007/s00170-019-03806-y,Springer,2019-12-01,"This paper introduces BAZAR, a collaborative robot that integrates the most advanced sensing and actuating devices in a unique system designed for the Industry 4.0. We present BAZAR’s three main features, which are all paramount in the factory of the future. These features are: mobility for navigating in dynamic environments, interaction for operating side-by-side with human workers, and dual-arm manipulation for transporting and assembling bulky objects.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00170-019-03806-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-019-00622-0,Volvo Group Collaborative Robot Systems Laboratory: A Collaborative Way for Academia and Industry to be at the Forefront of Artificial Intelligence,KI - Künstliche Intelligenz,10.1007/s13218-019-00622-0,Springer,2019-12-01,"With the clear aim of being on the forefront in the area of collaborative robots (cobots), the Volvo Group Truck Operations has created a collaboration arena where academia, industry, and start-up companies can share visions and needs and jointly create research and/or technology development projects. The arena has been active for about 5 years and is highly appreciated and beneficial for all involved parties. Advanced prototypes of robots and novel control methods for the usage of collaborative robots in an environment where human operators and robots are acting and collaborating on “equal terms” have been developed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-019-00622-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10734-019-00387-3,Joseph E. Aoun: Robot-proof: higher education in the age of artificial intelligence,Higher Education,10.1007/s10734-019-00387-3,Springer,2019-12-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10734-019-00387-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-019-00625-x,Special Issue on Reintegrating Artificial Intelligence and Robotics,KI - Künstliche Intelligenz,10.1007/s13218-019-00625-x,Springer,2019-12-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-019-00625-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-019-09852-5,Real-time robot path planning from simple to complex obstacle patterns via transfer learning of options,Autonomous Robots,10.1007/s10514-019-09852-5,Springer,2019-12-01,"We consider the problem of path planning in an initially unknown environment where a robot does not have an a priori map of its environment but has access to prior information accumulated by itself from navigation in similar but not identical environments. To address the navigation problem, we propose a novel, machine learning-based algorithm called Semi-Markov Decision Process with Unawareness and Transfer (SMDPU-T) where a robot records a sequence of its actions around obstacles as action sequences called options which are then reused by it within a framework called Markov Decision Process with unawareness (MDPU) to learn suitable, collision-free maneuvers around more complex obstacles in future. We have analytically derived the cost bounds of the selected option by SMDPU-T and the worst case time complexity of our algorithm. Our experimental results on simulated robots within Webots simulator illustrate that SMDPU-T takes $$24\%$$ 24 % planning time and $$39\%$$ 39 % total time to solve same navigation tasks while, our hardware results on a Turtlebot robot indicate that SMDPU-T on average takes $$53\%$$ 53 % planning time and $$60\%$$ 60 % total time as compared to a recent, sampling-based path planner.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-019-09852-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10710-019-09357-1,A covariance matrix adaptation evolution strategy in reproducing kernel Hilbert space,Genetic Programming and Evolvable Machines,10.1007/s10710-019-09357-1,Springer,2019-12-01,"The covariance matrix adaptation evolution strategy (CMA-ES) is an efficient derivative-free optimization algorithm. It optimizes a black-box objective function over a well-defined parameter space in which feature functions are often defined manually. Therefore, the performance of those techniques strongly depends on the quality of the chosen features or the underlying parametric function space. Hence, enabling CMA-ES to optimize on a more complex and general function class has long been desired. In this paper, we consider modeling the input spaces in black-box optimization non-parametrically in reproducing kernel Hilbert spaces (RKHS). This modeling leads to a functional optimisation problem whose domain is a RKHS function space that enables optimisation in a very rich function class. We propose CMA-ES-RKHS, a generalized CMA-ES framework that is able to carry out black-box functional optimisation in RKHS. A search distribution on non-parametric function spaces, represented as a Gaussian process, is adapted by updating both its mean function and covariance operator. Adaptive and sparse representation of the mean function and the covariance operator can be retained for efficient computation in the updates and evaluations of CMA-ES-RKHS by resorting to sparsification. We will also show how to apply our new black-box framework to search for an optimum policy in reinforcement learning in which policies are represented as functions in a RKHS. CMA-ES-RKHS is evaluated on two functional optimization problems and two bench-marking reinforcement learning domains.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10710-019-09357-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00170-019-03940-7,"Modeling, planning, and scheduling of shop-floor assembly process with dynamic cyber-physical interactions: a case study for CPS-based smart industrial robot production",The International Journal of Advanced Manufacturing Technology,10.1007/s00170-019-03940-7,Springer,2019-12-01,"In recent years, the applications of industrial robots are expanding rapidly due to Industry 4.0 oriented evolutions, ranging from automobile industry to almost all manufacturing domains. As demands with rapid product iterations become increasingly fluctuant and customized, the assembly process of industrial robots faces new challenges including dynamic reorganization and reconfiguration, ubiquitous sensing, and communication with time constraints, etc. This paper studies the industrial robot assembly process modeling, planning, and scheduling based on real-time data acquisition and fusion under the framework of advanced shop-floor communication and computing technologies such as wireless sensor, actuator network, and edge computing. Taking the assembly of industrial robots as the specific object, the multi-agent model of industrial robot assemble process is established. Then, the encapsulation, communication, and interaction of agents with real-time data acquisition and fusion are studied. Based on multi-agent reinforcement learning approach, an intelligent planning and scheduling algorithm for industrial robot assembly is proposed, and a simulation case is presented to demonstrate the proposed model and algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00170-019-03940-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-019-00618-w,SocRob@Home,KI - Künstliche Intelligenz,10.1007/s13218-019-00618-w,Springer,2019-12-01,"This paper describes the SocRob@Home robot system, consisting of a mobile robot (MBOT) equipped with several sensors and actuators, including a manipulator arm, and several software modules that provide the skills and capability to perform domestic tasks while interacting with humans in a domestic environment. We describe the whole system holistically, explaining how it integrates the contributing modules, and then we focus on the most relevant sub-systems, pointing out the original contributions of our research and development on the system in the last 5 years. The robot system includes metric and semantic mapping, several navigation modes (way-point navigation, person following and multi-sensor obstacle detection and avoidance), vision-based object detection, recognition, servoing and grasping, speech understanding, task planning and task execution. The robot system is mostly activated by speech commands from a human, and these commands, after being interpreted, are executed by the robot sub-systems, coordinated by a task executor. Lessons learned during the development and use of this system, which are useful as guidelines for the development of similar robot systems, are provided. MBOT’s performance is assessed using the task benchmarks scoring system of the European Robotics League competitions on Consumer Service robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-019-00618-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11841-017-0628-3,Robotic Bodies and the Kairos of Humanoid Theologies,Sophia,10.1007/s11841-017-0628-3,Springer,2019-12-01,"In the not-too-distant future, robots will populate the walks of everyday life, from the manufacturing floor to corporate offices, and from battlefields to the home. While most work on the social implications of robotics focuses on such moral issues as the economic impact on human workers or the ethics of lethal machines, scant attention is paid to the effect of the advent of the robotic age on religion. Robots will likely become commonplace in the home by the end of the twenty-first century as nannies and caretakers, particularly for young children. As a consequence, parents will want to be assured that robots will instruct their children in their values, based upon the moral teachings of their religious tradition. Consequently, parents will need robots programmed with appropriate religious software, installed by corporations but approved by their religious communities, e.g., Catholic robots, Muslim robots, and Lutheran robots. If, as expected, robots will acquire the capacity to engage in independent reasoning, believers will want to incorporate their robots within their religious communities to influence the evolution of robotic religious views. The Robotic Age will therefore present basic theological challenges. If robots simulate human personalities, desires, and fears, can religious communities tailor their doctrine, rituals, and institutions to accommodate these new “converts”? In short, can religion generate “soulless” theologies for the non-human? The Robotic Age promises a challenge unlike any other in the history of religious traditions. Biofundamentalists will undoubtedly resist revolutionary changes in theology, but for many people of faith, it will be difficult to resist appealing to those who appear and act strikingly like human beings. This paper poses questions and entertains speculation about those theological challenges, particularly in Christianity, which believers will face, e.g., concepts of the soul, blood sacrifice and redemption, marriage, and death.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11841-017-0628-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41315-019-00107-1,A computer vision and artificial intelligence based cost-effective object sensing robot,International Journal of Intelligent Robotics and Applications,10.1007/s41315-019-00107-1,Springer,2019-12-01,"In this research, we intend to present an enhanced object detection system incorporating a few well-known computer vision techniques, machine learning algorithms, as well as smart sensors in a more organized way. In essence, a computer vision based system in cooperation with machine learning approach has been employed to detect objects in parallel with a hardware-based ultrasonic sensor unit. The units can not only operate independently but also can cooperate in terms of detection result and hence, this type of approach can be termed as a cooperative object sensing system. Moreover, another key point is the prototype can determine free path to ensure smooth traversing which makes it effective in case of unforeseen scenario. By the same token, this prototype is also able to detect the type of object which is another compelling evidence of its novelty. With this intention in mind, we conducted a field test and evaluated its performance which justified the features specified above.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-019-00107-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-019-09868-x,ART neural network-based integration of episodic memory and semantic memory for task planning for robots,Autonomous Robots,10.1007/s10514-019-09868-x,Springer,2019-12-01,"Automated task planning for robots faces great challenges in that the sequences of events needed for a particular task are mostly required to be hard-coded. This can be a cumbersome process, especially, when the user wants a robot to learn a large number of similar tasks with different objects that are semantically related. We propose a novel approach of user preference-based integrated multi-memory model (pMM-ART). This approach focuses on exploiting a semantic hierarchy of objects alongside an episodic memory for enhancing the behavior of an autonomous agent. We analyze the functioning principle of the proposed model by teaching it a few distinct domestic tasks and observe that it is able to carry out a large number of similar tasks based on the semantic similarities between learned objects. We also demonstrate, via experiments using Mybot, our ability to reach those goals that are not possible without the integration of semantic knowledge with episodic memory.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-019-09868-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-019-00621-1,A Philosophically Motivated View on AI and Robotics,KI - Künstliche Intelligenz,10.1007/s13218-019-00621-1,Springer,2019-12-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-019-00621-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-019-00626-w,Shakey Ever After? Questioning Tacit Assumptions in Robotics and Artificial Intelligence,KI - Künstliche Intelligenz,10.1007/s13218-019-00626-w,Springer,2019-12-01,Shakey the robot was a milestone of autonomous robots and artificial intelligence. Its design principles have dominated research until now. Tacit philosophical and architectural assumptions have impoverished the space of research topics and methods. I point out ways to overcome this impasse with sideglances to other scientific fields.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-019-00626-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41027-019-00191-8,A Critique of Economic Literature on Technology and Fourth Industrial Revolution: Employment and the Nature of Jobs,The Indian Journal of Labour Economics,10.1007/s41027-019-00191-8,Springer,2019-12-01,"Technology has come to the centre stage of the capitalist framework after the advent of the Fourth Industrial Revolution. Almost all schools of economic thought have realised the importance of technology in the production process. For the classical economists, technology is a tool to increase the output of the economy, ultimately leading to an increase in employment. However, Ricardo of the classical school differs in his approach from others. Despite being optimistic about the adoption of technology, he contends that labour will be worse off with the onset of technology. The issue of jobs remained the same for Marx and Keynes. For Marx, technology represents a duality which is both advantageous and disadvantageous for labour. For Keynes, it is a root for unemployment and a structural change in society and nature of work. Schumpeter, Veblen and other economists also address the issue of technology. Despite the focus, technology is not central to the theory of development or labour. However, with the Fourth Industrial Revolution, there needs to be more emphasis on the role of technology. By refining the existing literature and using anecdotal and subjective evidence, an attempt is made to put forth a modified idea of technology.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41027-019-00191-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-019-00591-2,On-the-Fly Detection of User Engagement Decrease in Spontaneous Human–Robot Interaction Using Recurrent and Deep Neural Networks,International Journal of Social Robotics,10.1007/s12369-019-00591-2,Springer,2019-12-01,"In this paper we consider the detection of a decrease of engagement by users spontaneously interacting with a socially assistive robot in a public space. We first describe the UE-HRI dataset that collects spontaneous human–robot interactions following the guidelines provided by the affective computing research community to collect data “in-the-wild”. We then analyze the users’ behaviors, focusing on proxemics, gaze, head motion, facial expressions and speech during interactions with the robot. Finally, we investigate the use of deep leaning techniques (recurrent and deep neural networks) to detect user engagement decrease in real-time. The results of this work highlight, in particular, the relevance of taking into account the temporal dynamics of a user’s behavior. Allowing 1–2 s as buffer delay improves the performance of taking a decision on user engagement.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-019-00591-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s40648-019-0141-2,An automated fruit harvesting robot by using deep learning,ROBOMECH Journal,10.1186/s40648-019-0141-2,Springer,2019-11-01,"Automation and labor saving in agriculture have been required recently. However, mechanization and robots for growing fruits have not been advanced. This study proposes a method of detecting fruits and automated harvesting using a robot arm. A highly fast and accurate method with a Single Shot MultiBox Detector is used herein to detect the position of fruit, and a stereo camera is used to detect the three-dimensional position. After calculating the angles of the joints at the detected position by inverse kinematics, the robot arm is moved to the target fruit’s position. The robot then harvests the fruit by twisting the hand axis. The experimental results showed that more than 90% of the fruits were detected. Moreover, the robot could harvest a fruit in 16 s.",https://www.biomedcentral.com/openurl?doi=10.1186/s40648-019-0141-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11235-019-00561-z,Survey on artificial intelligence based techniques for emerging robotic communication,Telecommunication Systems,10.1007/s11235-019-00561-z,Springer,2019-11-01,"This paper reviews the current development of artificial intelligence (AI) techniques for the application area of robot communication. The research of the control and operation of multiple robots collaboratively toward a common goal is fast growing. Communication among members of a robot team and even including humans is becoming essential in many real-world applications. The survey focuses on the AI techniques for robot communication to enhance the communication capability of the multi-robot team, making more complex activities, taking an appreciated decision, taking coordinated action, and performing their tasks efficiently. We present a comprehensive review of the intelligent solutions for robot communication which have been proposed in the literature in recent years. This survey contributes to a better understanding of the AI techniques for enhancing robot communication and sheds new lights on future research direction in the subject area.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11235-019-00561-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-018-3520-3,Recurrent fuzzy wavelet neural networks based on robust adaptive sliding mode control for industrial robot manipulators,Neural Computing and Applications,10.1007/s00521-018-3520-3,Springer,2019-11-01,"A robust adaptive control method is proposed in this paper based on recurrent fuzzy wavelet neural networks (RFWNNs) system for industrial robot manipulators (IRMs) to improve high accuracy of the tracking control. The RFWNNs consist of four layers, and second layer has the feedback connections. Wavelet basis function is used as fuzzy membership function. In general, it is not easy to adopt a model-based method to achieve this control object due to the uncertainties of the IRM, such as unknown dynamic, disturbances and parameter variations. To solve this problem, all the parameters of the RFWNNs system are tuned online by an adaptive learning algorithm, and online adaptive control laws are determined by Lyapunov stability theorem. In addition, the robust controller is designed to deal with the approximation error, optimal parameter vectors and higher-order terms in Taylor series. Therefore, with the proposed control, the desired tracking performance, stability and robustness of the closed-loop manipulators system are guaranteed. The simulations and experimental performed on a three-link IRMs are provided in comparison with fuzzy wavelet neural network and robust neural fuzzy network to demonstrate the effectiveness and robustness of the proposed RFWNNs methodology.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-018-3520-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-019-01439-y,A recurrent TSK interval type-2 fuzzy neural networks control with online structure and parameter learning for mobile robot trajectory tracking,Applied Intelligence,10.1007/s10489-019-01439-y,Springer,2019-11-01,"This paper focuses on the design of a recurrent Takagi-Sugeno-Kang interval type-2 fuzzy neural network RTSKIT2FNN for mobile robot trajectory tracking problem. The RTSKIT2FNN is incorporating the recurrent frame of internal-feedback loops into interval type-2 fuzzy neural network which uses simple interval type-2 fuzzy sets in the antecedent part and the Takagi-Sugeno-Kang (TSK) type in the consequent part of the fuzzy rule. The antecedent part forms a local internal feedback loop by feeding the membership function of each node in the fuzzification layer to itself. Initially, the rule base in the RTSKIT2FNN is empty, after that, all rules are generated by online structure learning, and all the parameters of the RTSKIT2FNN are updated online using gradient descent algorithm with varied learning rates VLR. Through experimental results, we demonstrate the effectiveness of the proposed RTSKIT2FNN for mobile robot control.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-019-01439-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11548-019-01953-x,Segmenting and classifying activities in robot-assisted surgery with recurrent neural networks,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-019-01953-x,Springer,2019-11-01,"Purpose Automatically segmenting and classifying surgical activities is an important prerequisite to providing automated, targeted assessment and feedback during surgical training. Prior work has focused almost exclusively on recognizing gestures, or short, atomic units of activity such as pushing needle through tissue , whereas we also focus on recognizing higher-level maneuvers, such as suture throw . Maneuvers exhibit more complexity and variability than the gestures from which they are composed, however working at this granularity has the benefit of being consistent with existing training curricula. Methods Prior work has focused on hidden Markov model and conditional-random-field-based methods, which typically leverage unary terms that are local in time and linear in model parameters. Because maneuvers are governed by long-term, nonlinear dynamics, we argue that the more expressive unary terms offered by recurrent neural networks (RNNs) are better suited for this task. Four RNN architectures are compared for recognizing activities from kinematics: simple RNNs, long short-term memory, gated recurrent units, and mixed history RNNs. We report performance in terms of error rate and edit distance, and we use a functional analysis-of-variance framework to assess hyperparameter sensitivity for each architecture. Results We obtain state-of-the-art performance for both maneuver recognition from kinematics (4 maneuvers; error rate of $$8.6 \pm 3.4\%$$ 8.6 ± 3.4 % ; normalized edit distance of $$9.3 \pm 4.3\%$$ 9.3 ± 4.3 % ) and gesture recognition from kinematics (10 gestures; error rate of $$15.2 \pm 6.0\%$$ 15.2 ± 6.0 % ; normalized edit distance of $$8.4 \pm 6.3\%$$ 8.4 ± 6.3 % ). Conclusions Automated maneuver recognition is feasible with RNNs, an exciting result which offers the opportunity to provide targeted assessment and feedback at a higher level of granularity. In addition, we show that multiple hyperparameters are important for achieving good performance, and our hyperparameter analysis serves to aid future work in RNN-based activity recognition.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-019-01953-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-018-00975-y,Robot-Assisted Autism Spectrum Disorder Diagnostic Based on Artificial Reasoning,Journal of Intelligent & Robotic Systems,10.1007/s10846-018-00975-y,Springer,2019-11-01,"Autism spectrum disorder (ASD) is a neurodevelopmental disorder that affects people from birth, whose symptoms are found in the early developmental period. The ASD diagnosis is usually performed through several sessions of behavioral observation, exhaustive screening, and manual coding behavior. The early detection of ASD signs in naturalistic behavioral observation may be improved through Child-Robot Interaction (CRI) and technological-based tools for automated behavior assessment. Robot-assisted tools using CRI theories have been of interest in intervention for children with Autism Spectrum Disorder (CwASD), elucidating faster and more significant gains from the diagnosis and therapeutic intervention when compared to classical methods. Additionally, using computer vision to analyze child’s behaviors and automated video coding to summarize the responses would help clinicians to reduce the delay of ASD diagnosis. In this article, a CRI to enhance the traditional tools for ASD diagnosis is proposed. The system relies on computer vision and an unstructured and scalable network of RGBD sensors built upon Robot Operating System (ROS) and machine learning algorithms for automated face analysis. Also, a proof of concept is presented, with participation of three typically developing (TD) children and three children in risk of suffering from ASD.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-018-00975-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-018-09821-4,Deep learning of structured environments for robot search,Autonomous Robots,10.1007/s10514-018-09821-4,Springer,2019-10-15,"Robots often operate in built environments containing underlying structure that can be exploited to help predict future observations. In this work, we present a framework based on convolutional neural networks to predict point of interest locations in structured environments. The proposed technique exploits the inherent structure of the environment to train a convolutional neural network that is leveraged to facilitate robotic search. We start by investigating environments where the full environmental structure is known, and then we extend the work to unknown environments. Experimental results show the proposed framework provides a reliable method for increasing the efficiency of current search methods across multiple domains. Finally, we demonstrate the proposed framework increases the search efficiency of a mobile robot in a real-world office environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-018-09821-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/d41586-019-02939-0,"Raging robots, hapless humans: the AI dystopia",Nature,10.1038/d41586-019-02939-0,Nature,2019-10-03,Stuart Russell’s latest book examines how artificial intelligence could spin out of control. David Leslie critiques it. Stuart Russell’s latest book examines how artificial intelligence could spin out of control. David Leslie critiques it.,https://www.nature.com/articles/d41586-019-02939-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42438-019-00046-x,Critical Imaginaries and Reflections on Artificial Intelligence and Robots in Postdigital K-12 Education,Postdigital Science and Education,10.1007/s42438-019-00046-x,Springer,2019-10-01,"It is commonly suggested that emerging technologies will revolutionize education. In this paper, two such emerging technologies, artificial intelligence (AI) and educational robots (ER), are in focus. The aim of the paper is to explore how teachers, researchers and pedagogical developers critically imagine and reflect upon how AI and robots could be used in education. The empirical data were collected from discussion groups that were part of a symposium. For both AI and ERs, the need for more knowledge about these technologies, how they could preferably be used, and how the emergence of these technologies might affect the role of the teacher and the relationship between teachers and students, were outlined. Many participants saw more potential to use AI for individualization as compared with ERs. However, there were also more concerns, such as ethical issues and economic interests, when discussing AI. While the researchers/developers to a greater extent imagined ideal future technology-rich educational practices, the practitioners were more focused on imaginaries grounded in current practice.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42438-019-00046-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11432-019-9932-3,Accelerating DNN-based 3D point cloud processing for mobile computing,Science China Information Sciences,10.1007/s11432-019-9932-3,Springer,2019-09-19,"3D point cloud data, which are produced by various 3D sensors such as LIDAR and stereo cameras, have been widely deployed by industry leaders such as Google, Uber, Tesla, and Mobileye, for mobile robotic applications such as autonomous driving and humanoid robots. Point cloud data, which are composed of reliable depth information, can provide accurate location and shape characteristics for scene understanding, such as object recognition and semantic segmentation. However, deep neural networks (DNNs), which directly consume point cloud data, are particularly computation-intensive because they have to not only perform multiplication-and-accumulation (MAC) operations but also search neighbors from the irregular 3D point cloud data. Such a task goes beyond the capabilities of general-purpose processors in realtime to figure out the solution as the scales of both point cloud data and DNNs increase from application to application. We present the first accelerator architecture that dynamically configures the hardware on-the-fly to match the computation of both neighbor point search and MAC computation for point-based DNNs. To facilitate the process of neighbor point search and reduce the computation costs, a grid-based algorithm is introduced to search neighbor points from a local region of grids. Evaluation results based on the scene recognition and segmentation tasks show that the proposed design harvests 16.4 × higher performance and saves 99.95% of energy than an NVIDIA Tesla K40 GPU baseline in point cloud scene understanding applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11432-019-9932-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-017-0758-8,Comparative legal study on privacy and personal data protection for robots equipped with artificial intelligence: looking at functional and technological aspects,AI & SOCIETY,10.1007/s00146-017-0758-8,Springer,2019-09-01,"This paper undertakes a comparative legal study to analyze the challenges of privacy and personal data protection posed by Artificial Intelligence (“AI”) embedded in Robots, and to offer policy suggestions. After identifying the benefits from various AI usages and the risks posed by AI-related technologies, I then analyze legal frameworks and relevant discussions in the EU, USA, Canada, and Japan, and further consider the efforts of Privacy by Design (“PbD”) originating in Ontario, Canada. While various AI usages provide great convenience, many issues, including profiling, discriminatory decisions, lack of transparency, and impeding consent, have emerged. The unpredictability arising from the AI machine learning function poses further difficulties, which have only been partially addressed by legal frameworks in the aforementioned jurisdictions. However, analyzing the relevant discussions yielded several suggestions. The first priority is adopting PbD as the most flexible, soft-legal, and preferable approach toward AI-oriented issues. Implementing PbD will protect individual privacy and personal data without specific efforts, and achieve both the development of AI and the advancement of privacy and personal data protection. Technical measures that can adapt to an individual’s dynamic choices according to the “context” should be further developed. Furthermore, alternative technical measures, including those to solve the “algorithmic black box” or achieve differential privacy, warrant thorough examination. If AI surpasses human intelligence, a terminating function, such as a “kill switch” will be the last resort to preserve individual choice. Despite numerous difficulties, we must prepare for the coming AI-prevalent society by taking a flexible approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-017-0758-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-019-00525-1,"Artificial intelligence, ethics and human values: the cases of military drones and companion robots",Artificial Life and Robotics,10.1007/s10015-019-00525-1,Springer,2019-09-01,"Can artificial intelligence (AI) be more ethical than human intelligence? Can it respect human values better than a human? This article examines some issues raised by the AI with respect to ethics. The utilitarian approach can be a solution, especially the one that uses agent-based theory. We have chosen two extreme cases: combat drones, vectors of death, and life supporting companion robots. The ethics of AI and unmanned aerial vehicles (UAV) must be studied on the basis of military ethics and human values when fighting. Despite the fact that they are not programmed to hurt humans or harm their dignity, companion robots can potentially endanger their social, moral as well as their physical integrity. An important ethical condition is that companion robots help the nursing staff to take better care of patients while not replacing them.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-019-00525-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-018-03986-w,Discrete-time neural network with two classes of bias noises for solving time-variant matrix inversion and application to robot tracking,Neural Computing and Applications,10.1007/s00521-018-03986-w,Springer,2019-09-01,"It is well known that noise is inevitable in real world, especially in the case of solving time-variant matrix inversion. Therefore, it is more necessary to study the algorithm with bias noises to solve time-variant matrix inversion. This paper investigates discrete-time neural network with two classes of bias noises for solving time-variant matrix inversion, and its application to robot tracking based on the property of second-order differential equation. Firstly, the model is presented and some indispensable propaedeutics are given. Then, continuous-time and discrete-time neural network with two classes of bias noises is designed, respectively. Their convergence and finite-time stability are also theoretically analyzed. Finally, the proposed models are applied to a five-link robot tracking. Numerical simulations demonstrate the superiority and effectiveness of our method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-018-03986-w,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41315-019-00101-7,Transferring optimal contact skills to flexible manipulators by reinforcement learning,International Journal of Intelligent Robotics and Applications,10.1007/s41315-019-00101-7,Springer,2019-09-01,"Flexible/soft manipulators have the potential to maneuver in confined space and reach deeply-seated targets via curvy trajectories, thus enjoy increasing popularity in minimally invasive surgery (MIS) community. We aim to automate palpation movement for this type of robots, an important procedure for disease diagnosis, where multiple force and pose requirements are to be achieved simultaneously. It’s challenging to obtain accurate models due to the system’s inherent nonlinearities and actuation hysteresis. Moreover, unknown contact transitions and high-dimensionality specific to the palpation task, pose great challenges to deriving optimal task policies. We employ the model-free reinforcement learning method for learning palpation skills through deterministic policy gradient, whose reward function was carefully shaped to accommodate all the task objectives. In addition, we design a safety check routine to avoid undesirable collisions and a dedicated initialization process for generalization to various environment conditions. We demonstrate successful implementation of the learning framework in simulation and real world. The trained policy succeeds in automating the designed tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-019-00101-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11517-019-02002-0,A CNN-based prototype method of unstructured surgical state perception and navigation for an endovascular surgery robot,Medical & Biological Engineering & Computing,10.1007/s11517-019-02002-0,Springer,2019-09-01,"Performance of robot-assisted endovascular surgery (ES) remains highly dependent on an individual surgeon’s skills, due to common adoption of master-slave robotic structure. Surgeons’ skill modeling and unstructured surgical state perception pose prohibitive challenges for an autonomous ES robot. In this paper, a novel convolutional neural network (CNN)-based framework is proposed to address these challenges for navigation of an ES robot based on surgeons’ skill learning. An operating action probability estimator is proposed by integrating a two-dimensional CNN, with which the features of a surgical state image are extracted and then directly mapped to the action probability. A one-dimensional CNN with multi-input is developed to recognize the guide wire operating force condition. An eye-hand collaborative servoing algorithm is proposed to combine the outputs of these two networks and to control the robot under a closed-loop architecture. A real-world ES robot is employed for data collection and task performance evaluation in laboratory condition. Compared with the state of the art, the CNN-based method shows its capability of adapting to different situations and achieves similar success rate and average operating time. Robotic operation performs similar operating trajectory and maintains similar level of operating force with manual operation. The CNN-based method can be easily extended to many other surgical robots. Graphical abstract A surgeon’s guide wire operating skills in endovascular surgery (ES) is learned by the proposed CNN-based method. Then, the learned model is used for autonomous control of a ES robot with surgical state input (images and operating force).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11517-019-02002-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11548-019-02048-3,Force classification during robotic interventions through simulation-trained neural networks,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-019-02048-3,Springer,2019-09-01,"Purpose Intravitreal injection is among the most frequent treatment strategies for chronic ophthalmic diseases. The last decade has seen a serious increase in the number of intravitreal injections, and with it, adverse effects and drawbacks. To tackle these problems, medical assistive devices for robotized injections have been suggested and are projected to enhance delivery mechanisms for a new generation of pharmacological solutions. In this paper, we present a method aimed at improving the safety characteristics of upcoming robotic systems. Our vision-based method uses a combination of 2D OCT data, numerical simulation and machine learning to classify the range of the force applied by an injection needle on the sclera. Methods We design a neural network to classify force ranges from optical coherence tomography (OCT) images of the sclera directly. To avoid the need for large real data sets, the network is trained on images of simulated deformed sclera. This simulation is based on a finite element method, and the model is parameterized using a Bayesian filter applied to observations of the deformation in OCT images. Results We validate our approach on real OCT data collected on five ex vivo porcine eyes using a robotically guided needle. The thorough parameterization of the simulations leads to a very good agreement between the virtually generated samples used to train the network and the real OCT acquisitions. Results show that the applied force range on real data can be predicted with 93% accuracy. Conclusions Through a simulation-trained neural network, our approach estimates the force range applied by a robotically guided needle on the sclera based solely on a single OCT slice of the deformed sclera. Being real-time, this solution can be integrated in the control loop of the system, permitting the prompt withdrawal of the needle for safety reasons.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-019-02048-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-018-0898-1,A Fully-Autonomous Aerial Robot for Search and Rescue Applications in Indoor Environments using Learning-Based Techniques,Journal of Intelligent & Robotic Systems,10.1007/s10846-018-0898-1,Springer,2019-08-15,"Search and Rescue (SAR) missions represent an important challenge in the robotics research field as they usually involve exceedingly variable-nature scenarios which require a high-level of autonomy and versatile decision-making capabilities. This challenge becomes even more relevant in the case of aerial robotic platforms owing to their limited payload and computational capabilities. In this paper, we present a fully-autonomous aerial robotic solution, for executing complex SAR missions in unstructured indoor environments. The proposed system is based on the combination of a complete hardware configuration and a flexible system architecture which allows the execution of high-level missions in a fully unsupervised manner (i.e. without human intervention). In order to obtain flexible and versatile behaviors from the proposed aerial robot, several learning-based capabilities have been integrated for target recognition and interaction. The target recognition capability includes a supervised learning classifier based on a computationally-efficient Convolutional Neural Network (CNN) model trained for target/background classification, while the capability to interact with the target for rescue operations introduces a novel Image-Based Visual Servoing (IBVS) algorithm which integrates a recent deep reinforcement learning method named Deep Deterministic Policy Gradients (DDPG). In order to train the aerial robot for performing IBVS tasks, a reinforcement learning framework has been developed, which integrates a deep reinforcement learning agent (e.g. DDPG) with a Gazebo-based simulator for aerial robotics. The proposed system has been validated in a wide range of simulation flights, using Gazebo and PX4 Software-In-The-Loop, and real flights in cluttered indoor environments, demonstrating the versatility of the proposed system in complex SAR missions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-018-0898-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40313-019-00472-z,Adaptive Neural Network-Based Backstepping Sliding Mode Control Approach for Dual-Arm Robots,"Journal of Control, Automation and Electrical Systems",10.1007/s40313-019-00472-z,Springer,2019-08-15,"The paper introduces an adaptive strategy to effectively control a nonlinear dual-arm robot under external disturbances and uncertainties. By the use of the backstepping sliding mode control (BSSMC) method, the proposed algorithm first allows the manipulators to be able to robustly track the desired trajectories. Furthermore, due to the nonlinear, uncertain and unmodeled dynamics of the dual-arm robot, it is proposed to employ the radial basis function network (RBFN) to adaptively estimate the robot’s dynamic model. Though the estimation of the dynamics is approximate, the adaptation law is derived from the Lyapunov theory, which provides the controller with ability to guarantee stability of the whole system in spite of its nonlinearities, parameter uncertainties and external load variations. The effectiveness of the proposed RBFN–BSSMC approach is demonstrated by implementation in a simulation environment with realistic parameters, where the obtained results are highly promising.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40313-019-00472-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-019-01417-4,A novel multi-step reinforcement learning method for solving reward hacking,Applied Intelligence,10.1007/s10489-019-01417-4,Springer,2019-08-15,"Reinforcement learning with appropriately designed reward signal could be used to solve many sequential learning problems. However, in practice, the reinforcement learning algorithms could be broken in unexpected, counterintuitive ways. One of the failure modes is reward hacking which usually happens when a reward function makes the agent obtain high return in an unexpected way. This unexpected way may subvert the designer’s intentions and lead to accidents during training. In this paper, a new multi-step state-action value algorithm is proposed to solve the problem of reward hacking . Unlike traditional algorithms, the proposed method uses a new return function, which alters the discount of future rewards and no longer stresses the immediate reward as the main influence when selecting the current state action. The performance of the proposed method is evaluated on two games, Mappy and Mountain Car. The empirical results demonstrate that the proposed method can alleviate the negative impact of reward hacking and greatly improve the performance of reinforcement learning algorithm. Moreover, the results illustrate that the proposed method could also be applied to the continuous state space problem successfully.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-019-01417-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-018-9810-x,Advancing multi-vehicle deployments in oceanographic field experiments,Autonomous Robots,10.1007/s10514-018-9810-x,Springer,2019-08-15,"Our research concerns the coordination and control of robotic vehicles for upper water-column oceanographic observations. In such an environment, operating multiple vehicles to observe dynamic oceanographic phenomena, such as ocean processes and marine life, from fronts to cetaceans, has required that we design, implement and operate software, methods and processes which can support opportunistic needs in real-world settings with substantial constraints. In this work, an approach for coordinated measurements using such platforms, which relate directly to task outcomes, is presented. We show the use and operational value of a new Artificial Intelligence based mixed-initiative system for handling multiple platforms along with the networked infrastructure support needed to conduct such operations in the open sea. We articulate the need and use of a range of middleware architectures, critical for such deployments and ground this in the context of a field experiment in open waters of the mid-Atlantic in the summer of 2015.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-018-9810-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00170-019-03851-7,Machine learning for in-process end-point detection in robot-assisted polishing using multiple sensor monitoring,The International Journal of Advanced Manufacturing Technology,10.1007/s00170-019-03851-7,Springer,2019-08-01,"The decision on polishing operation stopping time when employing a robot-assisted polishing machine is a critical issue for the full automation of the polishing process. In this paper, a machining learning approach based on artificial neural networks was developed using multiple sensor monitoring data to realize an intelligent system capable to determine the state of the polishing process in terms of target surface roughness achievement. During the experimental tests, surface roughness measurements were performed on each polished workpiece and the acquired sensor signals were analyzed and processed by applying two kinds of feature extraction procedures: statistical features extraction and principal component analysis. By feeding diverse types of feature pattern vectors to artificial neural networks, a highly accurate classification of the polishing process state was obtained using the principal component feature pattern vectors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00170-019-03851-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10677-019-10029-3,What’s Wrong with Designing People to Serve?,Ethical Theory and Moral Practice,10.1007/s10677-019-10029-3,Springer,2019-08-01,"In this paper I argue, contrary to recent literature, that it is unethical to create artificial agents possessing human-level intelligence that are programmed to be human beings’ obedient servants. In developing the argument, I concede that there are possible scenarios in which building such artificial servants is, on net, beneficial. I also concede that, on some conceptions of autonomy, it is possible to build human-level AI servants that will enjoy full-blown autonomy. Nonetheless, the main thrust of my argument is that, in building such artificial agents, their creators cannot help but evince an objectionable attitude akin to the Aristotelian vice of manipulativeness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10677-019-10029-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s10033-019-0373-3,Neural Network-Based Adaptive Motion Control for a Mobile Robot with Unknown Longitudinal Slipping,Chinese Journal of Mechanical Engineering,10.1186/s10033-019-0373-3,Springer,2019-07-17,"When the mobile robot performs certain motion tasks in complex environment, wheel slipping inevitably occurs due to the wet or icy road and other reasons, thus directly influences the motion control accuracy. To address unknown wheel longitudinal slipping problem for mobile robot, a RBF neural network approach based on whole model approximation is presented. The real-time data acquisition of inertial measure unit (IMU), encoders and other sensors is employed to get the mobile robot’s position and orientation in the movement, which is applied to compensate the unknown bounds of the longitudinal slipping using the adaptive technique. Both the simulation and experimental results prove that the control scheme possesses good practical performance and realize the motion control with unknown longitudinal slipping.",http://link.springer.com/openurl/fulltext?id=doi:10.1186/s10033-019-0373-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-018-0781-0,Neural Network Based Adaptive Actuator Fault Detection Algorithm for Robot Manipulators,Journal of Intelligent & Robotic Systems,10.1007/s10846-018-0781-0,Springer,2019-07-15,"In order to improve the reliability of robotic systems, various fault detection and isolation (FDI) algorithms have been proposed. However, most of these algorithms are model-based and thus, an accurate model of the robot is required although it is hard to obtain and often time-varying. Acceleration estimation is an additional challenge in dynamic model-based algorithms as it is hard to measure accurately in practice. In this study, a neural network based fault detection algorithm that does not require the use of physical robot model and acceleration is proposed. By utilizing neural network, the fault torque can be estimated, which allows effective fault detection and diagnosis. The feasibility of the proposed fault detection algorithm is validated through various simulations and experiments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-018-0781-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10734-018-0326-2,Joseph E. Aoun: robot-proof—higher education in the age of artificial intelligence,Higher Education,10.1007/s10734-018-0326-2,Springer,2019-07-15,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10734-018-0326-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-018-0835-3,"Optimization of Vehicle Mounting Motions and Its Application to Full-Sized Humanoid, DRC-Hubo",Journal of Intelligent & Robotic Systems,10.1007/s10846-018-0835-3,Springer,2019-07-15,"This paper describes optimization of humanoid’s whole body motion for vehicle mounting task. To accomplish the goal, a trajectory optimization framework based on the reinforcement learning agent is used in this study. The guideline input trajectory is planned and optimized as regards various dynamic and kinematic limitations of humanoid in the framework. In previous studies, the authors demonstrated test-and-evaluation process of the framework using a full-sized humanoid, Hubo+. Experimental testing however presented several problems like overheating and self-collisions. To resolve those issues and to validate the trajectory optimization approach, another humanoid, called DRC-Hubo, is newly designed. Keeping a main structure of the optimization framework, the cost value functions are revised to meet dynamic and kinematic changes. Experimental test and verification process using a simulation model and a physical prototype is demonstrated to confirm the efficacy of the trajectory optimization approach. For both processes, two different types of ground vehicle are used. Last, analytical comparisons with other techniques are also conducted for validation of the proposed framework.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-018-0835-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-019-00280-z,Trajectory-based gait pattern shift detection for assistive robotics applications,Intelligent Service Robotics,10.1007/s11370-019-00280-z,Springer,2019-07-01,"In the medical field, rehabilitation of the lower limbs is a slow and continuous process, where healthcare professionals have to follow each patient over long periods of time. In conventional rehabilitation, the progression of a patient is assessed by a professional, who analyzes visual tracking data. This assessment is dependent on each professional’s own experience. In this paper, we propose an approach to analyze tracking data, captured by our robotic walker’s gait tracking system, to detect shifts in the gait pattern over time automatically. For this purpose, the system takes in gait tracking data and segments it into gait cycles (heel strike to heel strike). Then, our approach handles each gait cycle considering it as a group of gait parameters that define trajectories in that time frame. From each gait parameter within the cycle, spatiotemporal features are extracted and similarity rates are computed using autoencoders. These spatiotemporal features and similarity rates are fused in a feature space which is fed to a one-class support vector machine that constructs a model of the observable gait cycle. Each posterior observed gait cycle is checked for shifts, using a set of proposed novelty detection techniques. Experimental tests using a dataset captured using our robotic walker platform revealed a promising performance when detecting if a gait cycle is ‘reference’ or ‘novel’ when compared to a previously trained model of a unique ‘reference’ gait pattern.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-019-00280-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/s41586-019-1218-z,Author Correction: Controlling an organic synthesis robot with machine learning to search for new reactivity,Nature,10.1038/s41586-019-1218-z,Nature,2019-06-27,"Change history: Owing to the misidentification of compound 22 in the original Letter, changes have been made to Fig. 5, Extended Data Fig. 2 and the main text; see accompanying Amendment.",https://www.nature.com/articles/s41586-019-1218-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00170-018-03263-z,Observations on developing reliability information utilization in a manufacturing environment with case study: robotic arm manipulators,The International Journal of Advanced Manufacturing Technology,10.1007/s00170-018-03263-z,Springer,2019-06-19,"Manufacturing environments face many unique challenges with regard to balancing high standards of both product quality and production efficiency. Proper diagnostic health assessment is essential for maximizing uptime and maintaining product and process quality. Information for diagnostic assessments, and reliability information in general, can come from a myriad of sources that can be processed and managed through numerous algorithms that range from simplistic to hypercomplex. One area that typifies the assortment of information sources in a modern manufacturing setting is found with the use of industrial robotics and automated manipulators. Although several monitoring methods and technologies have been previously proposed for this and other assets, adoption has been sporadic with returns on investment not always meeting expectations. Practical concerns regarding data limitations, variability of setup, and scarcity of ground truth points of validation from active industrial sites have contributed to this. This paper seeks to provide an overview of barriers and offer a feasible action plan for developing a practical condition monitoring information utilization program, matching available capabilities and assets to maximize knowledge gain. Observations are made on a real-world case study involving industrial 6 degrees of freedom (DOF) robots actively deployed in a manufacturing facility with a variety of operational tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00170-018-03263-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-018-9793-7,Sensorimotor input as a language generalisation tool: a neurorobotics model for generation and generalisation of noun-verb combinations with sensorimotor inputs,Autonomous Robots,10.1007/s10514-018-9793-7,Springer,2019-06-15,"The paper presents a neurorobotics cognitive model explaining the understanding and generalisation of nouns and verbs combinations when a vocal command consisting of a verb-noun sentence is provided to a humanoid robot. The dataset used for training was obtained from object manipulation tasks with a humanoid robot platform; it includes 9 motor actions and 9 objects placing placed in 6 different locations), which enables the robot to learn to handle real-world objects and actions. Based on the multiple time-scale recurrent neural networks, this study demonstrates its generalisation capability using a large data-set, with which the robot was able to generalise semantic representation of novel combinations of noun-verb sentences, and therefore produce the corresponding motor behaviours. This generalisation process is done via the grounding process: different objects are being interacted, and associated, with different motor behaviours, following a learning approach inspired by developmental language acquisition in infants. Further analyses of the learned network dynamics and representations also demonstrate how the generalisation is possible via the exploitation of this functional hierarchical recurrent network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-018-9793-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40435-018-0487-y,Intelligent controller for hybrid force and position control of robot manipulators using RBF neural network,International Journal of Dynamics and Control,10.1007/s40435-018-0487-y,Springer,2019-06-01,"In this paper, an intelligent controller is developed for hybrid force and position control of robot manipulators in the presence of external disturbances and the model uncertainties. The proposed controller consists of a model based controller and neural network based model free controller with an adaptive bound part. A non linear function of model dynamics is identified by employing a radial basis function neural network. The role of adaptive bound part is to estimate the bounds on model disturbances, friction term and neural network reconstruction error. The Lyapunov function candidate is used to prove the stability of the proposed controller and to show that the errors are asymptotically convergent. Finally numerical simulation results are presented for two link robot manipulator to show excellent performance of the proposed controller in comparison to other control schemes such as model based computed torque control and neural network based model free controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40435-018-0487-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11548-019-01947-9,Preliminary study of an RNN-based active interventional robotic system (AIRS) in retinal microsurgery,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-019-01947-9,Springer,2019-06-01,"Purpose Retinal microsurgery requires highly dexterous and precise maneuvering of instruments inserted into the eyeball through the sclerotomy port. During such procedures, the sclera can potentially be injured from extreme tool-to-sclera contact force caused by surgeon’s unintentional misoperations. Methods We present an active interventional robotic system to prevent such iatrogenic accidents by enabling the robotic system to actively counteract the surgeon’s possible unsafe operations in advance of their occurrence. Relying on a novel force sensing tool to measure and collect scleral forces, we construct a recurrent neural network with long short-term memory unit to oversee surgeon’s operation and predict possible unsafe scleral forces up to the next 200 ms. We then apply a linear admittance control to actuate the robot to reduce the undesired scleral force. The system is implemented using an existing “steady hand” eye robot platform. The proposed method is evaluated on an artificial eye phantom by performing a “vessel following” mock retinal surgery operation. Results Empirical validation over multiple trials indicates that the proposed active interventional robotic system could help to reduce the number of unsafe manipulation events. Conclusions We develop an active interventional robotic system to actively prevent surgeon’s unsafe operations in retinal surgery. The result of the evaluation experiments shows that the proposed system can improve the surgeon’s performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-019-01947-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41315-019-00082-7,Real-time path planning for a robot to track a fast moving target based on improved Glasius bio-inspired neural networks,International Journal of Intelligent Robotics and Applications,10.1007/s41315-019-00082-7,Springer,2019-06-01,"Path planning from the initial location to reach the target location has received considerable attentions. There are still some challenges in real-time path planning for tracking a fast moving target. In the application of tracking a fast moving target, the robot must move rapidly and correctly to follow the target. It requires an algorithm that enables real-time path planning in the fast changing environment. The Glasius Bio-inspired Neural Network (GBNN) model has been reported inefficient for the real-time path planning in the fast changing environments because its dynamic performance lags behind the fast environmental changes. This study puts forward several improvements for the GBNN model to improve its dynamic performance. An alternate weight function for GBNN model is also studied. It shows that all the proposed GBNN models can be parameter-fixed when applied in a specific case. Through theoretical analysis and comparative simulations, the improved models are stable and feasible in the real-time path planning in a rapidly changing environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-019-00082-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s41469-019-0050-0,Primer on artificial intelligence and robotics,Journal of Organization Design,10.1186/s41469-019-0050-0,Springer,2019-05-29,"This article provides an introduction to artificial intelligence, robotics, and research streams that examine the economic and organizational consequences of these and related technologies. We describe the nascent research on artificial intelligence and robotics in the economics and management literature and summarize the dominant approaches taken by scholars in this area. We discuss the implications of artificial intelligence, robotics, and automation for organizational design and firm strategy, argue for greater engagement with these topics by organizational and strategy researchers, and outline directions for future research.",https://www.biomedcentral.com/openurl?doi=10.1186/s41469-019-0050-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-018-0777-4,Optimal path-planning for mobile robots to find a hidden target in an unknown environment based on machine learning,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-018-0777-4,Springer,2019-05-01,"Using mobile robots in disaster areas can reduce risks and the search time in urban search and rescue operations. Optimal path-planning for mobile robotics can play a key role in the reduction of the search time for rescuing victims. In order to minimize the search time, the shortest path to the target should be determined. In this paper, a new integrated Reinforcement Learning—based method is proposed to search and find a hidden target in an unknown environment in the minimum time. The proposed algorithm is developed in two main phases. Depending on whether or not the mobile robot receives the signal from the hidden target, phases I or II of the proposed algorithm can be carried out. Then, the proposed algorithm is implemented on an e-puck robot in an urban environment which is simulated within Webots software. Finally, to demonstrate the efficiency of the proposed method and to verify it, the computational results from the proposed method are compared with three conventional methods from the literature.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-018-0777-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-017-1538-4,Trajectory tracking control of robot manipulator based on RBF neural network and fuzzy sliding mode,Cluster Computing,10.1007/s10586-017-1538-4,Springer,2019-05-01,"Aimed at the nonlinearity and uncertainty of the manipulator system, a RBF (radial basis function) neural network-based fuzzy sliding-mode control method was proposed in this paper, in order to make the manipulator track the given trajectory at an ideal dynamic quality. In this method, the equivalent part of the sliding-mode control is approximated by the RBF neural network, in which no model information is required. Meanwhile, a fuzzy controller is developed to make adaptive adjustment of the sliding-mode control’s switching gains according to the distance between the current motor point and the sliding-mode surface, thus effectively the problem of chattering is solved. This method has, to some extent, improved the performance of response and tracking, and reduced the time of adjustment and chattering of input control. The system stability is verified by Lyapunov’s theorem. The simulation result suggests that the algorithm designed for the three-degree-of-freedom (3DOF) manipulator system is effective.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10586-017-1538-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42438-018-0005-8,Review of Joseph E. Aoun (2017). Robot Proof: Higher Education in the Age of Artificial Intelligence,Postdigital Science and Education,10.1007/s42438-018-0005-8,Springer,2019-04-15,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42438-018-0005-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10734-018-0289-3,Joseph E. Aoun: Robot-proof: higher education in the age of artificial intelligence,Higher Education,10.1007/s10734-018-0289-3,Springer,2019-04-15,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10734-018-0289-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-018-0796-6,Modeling the Static Friction in a Robot Joint by Genetically Optimized BP Neural Network,Journal of Intelligent & Robotic Systems,10.1007/s10846-018-0796-6,Springer,2019-04-15,"This paper aims to present a method for improving the modeling precision of static friction. To some extent, as the traditional static friction models available can’t be unified to characterize all the friction situations, a back propagation neural network (BPNN) was proposed to weaken the requirements of traditional static friction models. In details, relative speed of interacting surfaces and joint load are typically considered as the inputs of BPNN, whose output is the predicted static friction. Furthermore, to speed up the convergence and improve the global generalization capability of BPNN, we use genetic algorithm (GA) to optimize the initial values of weights and thresholds. All the training samples follow with reciprocating constant-speed experiments of friction under the changes of joint speed and load. Three comparative experiments indicate that using GA to optimize the initial values of weights and thresholds benefit to improve the convergence rate of network and prediction accuracy, and comparing with the traditional model of static friction, the BPNN model has a higher prediction precision and excellent generalization capability.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-018-0796-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00542-018-4084-y,Underwater autonomous motion control of a small-scaled spherical robot with neural networks,Microsystem Technologies,10.1007/s00542-018-4084-y,Springer,2019-04-04,"Considering the complex and variability of the operating environment of underwater spherical robot, usually it is difficult to solve the control problem when the robot changes its motion state or it is subject to waves and ocean currents, in those cases wherein robots are subject to continuous parametric changes or external disturbances, online gains tuning is a desirable choice. In this paper, with the goal of supporting some autonomous tasks of our small-scaled spherical robot, such as ecological observations and intelligent surveillance, a neural network-based auto-tuning control system was designed and implemented, which has a great advantage of processing online for the robot due to their nonlinear dynamics. The neural network plays the role of automatically estimating the suitable set of control gains that achieves the stability of the system. Simulation results are presented for the underwater swimming, in terms of the motion performance, stability, and velocity of the robot. Finally, the effectiveness of the proposed method was demonstrated by showing that the underwater horizontal and desired triangular trajectory motion were stable, and the design presented in this paper is able to meet future demands of underwater robots in biological monitoring and multi-robot cooperation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00542-018-4084-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-018-0140-8,Multi-layer Feed-forward Neural Network Deep Learning Control with Hybrid Position and Virtual-force Algorithm for Mobile Robot Obstacle Avoidance,"International Journal of Control, Automation and Systems",10.1007/s12555-018-0140-8,Springer,2019-04-01,"This paper addresses the trajectory tracking and obstacle avoidance control problems for a class of mobile robot systems. Two classes of controllers are designed for the mobile robot system in the free motion, respectively. A new hybrid position virtual-force controller is designed to adjust the distance between the mobile robot and the obstacles. Since the uncertainties between the mobile robot dynamics model and obstacles degrade the performance of the obstacle avoidance system, a multi-layer feed-forward neural networks (NNs) deep learning method with hybrid position and virtual-force is proposed, such that the distance between the mobile robot and the obstacles converges to an adjustable bounded region. It is shown that the proposed controller in this paper is smooth, effective, and only uses the system output. The control design conditions are relaxed because of the developed multi-layer feed-forward NNs deep learning compensator. The simulation results and obstacle avoidance cases are performed to show the effectiveness of the proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-018-0140-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11548-018-1882-8,“Deep-Onto” network for surgical workflow and context recognition,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-018-1882-8,Springer,2019-04-01,"Purpose Surgical workflow recognition and context-aware systems could allow better decision making and surgical planning by providing the focused information, which may eventually enhance surgical outcomes. While current developments in computer-assisted surgical systems are mostly focused on recognizing surgical phases, they lack recognition of surgical workflow sequence and other contextual element, e.g., “Instruments.” Our study proposes a hybrid approach, i.e., using deep learning and knowledge representation, to facilitate recognition of the surgical workflow. Methods We implemented “Deep-Onto” network, which is an ensemble of deep learning models and knowledge management tools, ontology and production rules. As a prototypical scenario, we chose robot-assisted partial nephrectomy (RAPN). We annotated RAPN videos with surgical entities, e.g., “Step” and so forth. We performed different experiments, including the inter-subject variability, to recognize surgical steps. The corresponding subsequent steps along with other surgical contexts, i.e., “Actions,” “Phase” and “Instruments,” were also recognized. Results The system was able to recognize 10 RAPN steps with the prevalence-weighted macro-average (PWMA) recall of 0.83, PWMA precision of 0.74, PWMA F1 score of 0.76, and the accuracy of 74.29% on 9 videos of RAPN. Conclusion We found that the combined use of deep learning and knowledge representation techniques is a promising approach for the multi-level recognition of RAPN surgical workflow.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-018-1882-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10609-018-9360-0,Guilty Robots? – Rethinking the Nature of Culpability and Legal Personhood in an Age of Artificial Intelligence,Criminal Law Forum,10.1007/s10609-018-9360-0,Springer,2019-03-15,"Robots and Artificial Intelligence are conquering our world. Just as any progress, this development is expected to have a relevant impact on law in general as well as on criminal law in particular. It involves the potential of transforming our conception of criminal responsibility, as notions of personhood, capacity and culpability will not stay unaffected. This article aims at giving an overview of the potential conversion criminal law is facing due to the increased importance of robotics and of artificial intelligence in our everyday lives. The discussion starts with an overview of different scenarios of criminal liability in the context of robotics. While some of them can be faced with existing doctrines, others demand a more far reaching assessment of the question if robots could ever gain legal personhood and therefore be originally called to account. While the picture of robots as liable perpetrators seems implausible at first sight, the present analysis reveals that blameworthiness is inherently socially constructed. However, it is not randomly constituted and follows social interaction and social meaning in fulfilling a certain function. Enabling the possibility of robots’ criminal liability therefore would require that robots are regarded as a suitable agent of responsibility. The article lights up the conditions for such social and legal change in rethinking the very nature of culpability having the overall function of criminal law in mind. It can be concluded that the on-going technological progress definitely has the potential of testing the theory of criminal responsibility while more clearly unveiling its foundations and its sociological implications. A guilty robot, however, as fictional as that appears today, may be nothing unrealistic nor unlikely in the future.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10609-018-9360-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11047-016-9582-1,Challenges in cooperative coevolution of physically heterogeneous robot teams,Natural Computing,10.1007/s11047-016-9582-1,Springer,2019-03-15,"Heterogeneous multirobot systems have shown significant potential in many applications. Cooperative coevolutionary algorithms (CCEAs) represent a promising approach to synthesise controllers for such systems, as they can evolve multiple co-adapted components. Although CCEAs allow for an arbitrary level of team heterogeneity, in previous works heterogeneity is typically only addressed at the behavioural level. In this paper, we study the use of CCEAs to evolve control for a heterogeneous multirobot system where the robots have disparate morphologies and capabilities. Our experiments rely on a simulated task where a simple ground robot must cooperate with a complex aerial robot to find and collect items. We first show that CCEAs can evolve successful controllers for physically heterogeneous teams, but find that differences in the complexity of the skills the robots need to learn can impair CCEAs’ effectiveness. We then study how different populations can use different evolutionary algorithms and parameters tuned to the agents’ complexity. Finally, we demonstrate how CCEAs’ effectiveness can be improved using incremental evolution or novelty-driven coevolution. Our study shows that, despite its limitations, coevolution is a viable approach for synthesising control for morphologically heterogeneous systems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11047-016-9582-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-017-0703-x,Rethinking the I-You relation through dialogical philosophy in the Ethics of AI and robotics,AI & SOCIETY,10.1007/s00146-017-0703-x,Springer,2019-03-14,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-017-0703-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-017-0695-6,Primacy of I–you connectedness revisited: some implications for AI and robotics,AI & SOCIETY,10.1007/s00146-017-0695-6,Springer,2019-03-14,"In this essay, I challenge the egocentric tradition which privileges the standpoint of an isolated individual, and propose a speech-based dialogical approach as an alternative. Considering that the egocentric tradition can be deciphered in part by analyzing the distortions undergone by pronominal discourse in the language of classical philosophy, I reexamine the pragmatics of ordinary language featuring the pronoun I in an effort to recover a more relational understanding of persons. I develop such an analysis of the deep grammar of pronominal discourse under the heading of ‘I–you connectedness’. I–you connectedness emphasizes the communicative structure of experience, in particular the phenomenological importance of the addressee, the inseparability of ‘I’ and ‘You’, and the nature of the alternation between them. I–you connectedness is the best thematized within living speech, which is invariably oriented towards an interlocutor, and animated by mutual address. Yet, I–you connectedness extends beyond living speech to other modalities of meaning, notably thinking and writing, where one notes a similar orientation to a living, imagined, or virtual addressee. I–you connectedness extends, therefore, beyond discursive experience, and captures the deep dialogic dimension of meaning in pre-linguistic and extra-linguistic life. I briefly consider its implications for theoretical and practical issues within robotics and AI.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-017-0695-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-017-0694-7,I in an other’s eye,AI & SOCIETY,10.1007/s00146-017-0694-7,Springer,2019-03-14,"This paper presents a model of how the fundamental cognitive machinery of self emerges as an accident of sociality, reflecting Buber’s assertion of the primacy of I–Thou relationships. This stands in contrast with the standard ‘I first’ model of theory of mind, which suggests that we understand others’ thought processes by imagining ourselves in their heads. However, this standard model tacitly assumes that understanding oneself is in some way easy, counter to experience in knowledge elicitation, where experts find it hard to reflect on and externalise tacit thought processes. Furthermore, it is hard to create convincing evolutionary accounts for the spontaneous emergence of self. The paper argues that the reflexive understanding of self is both more plausible phylogenically as an evolutionary development and fully consonant ontogenically with research on childhood cognitive development. This reflexive understanding has practical implications for efforts to create artificial agents or robots that are in some sense conscious, and may also inform discussions of the ethical and spiritual implications of advances in artificial intelligence.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-017-0694-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-017-0748-x,The synthetization of human voices,AI & SOCIETY,10.1007/s00146-017-0748-x,Springer,2019-03-14,"The synthetization of voices, or speech synthesis, has been an object of interest for centuries. It is mostly realized with a text-to-speech system, an automaton that interprets and reads aloud. This system refers to text available for instance on a website or in a book, or entered via popup menu on the website. Today, just a few minutes of samples are enough to be able to imitate a speaker convincingly in all kinds of statements. This article abstracts from actual products and actual technological realization. Rather, after a short historical outline of the synthetization of voices, exemplary applications of this kind of technology are gathered for promoting the development, and potential applications are discussed critically to be able to limit them if necessary. The ethical and legal challenges should not be underestimated, in particular with regard to informational and personal autonomy and the trustworthiness of media.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-017-0748-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-017-0773-9,The rise of the robots and the crisis of moral patiency,AI & SOCIETY,10.1007/s00146-017-0773-9,Springer,2019-03-14,"This paper adds another argument to the rising tide of panic about robots and AI. The argument is intended to have broad civilization-level significance, but to involve less fanciful speculation about the likely future intelligence of machines than is common among many AI-doomsayers. The argument claims that the rise of the robots will create a crisis of moral patiency. That is to say, it will reduce the ability and willingness of humans to act in the world as responsible moral agents, and thereby reduce them to moral patients. Since that ability and willingness is central to the value system in modern liberal democratic states, the crisis of moral patiency has a broad civilization-level significance: it threatens something that is foundational to and presupposed in much contemporary moral and political discourse. I defend this argument in three parts. I start with a brief analysis of an analogous argument made (or implied) in pop culture. Though those arguments turn out to be hyperbolic and satirical, they do prove instructive as they illustrates a way in which the rise of robots could impact upon civilization, even when the robots themselves are neither malicious nor powerful enough to bring about our doom. I then introduce the argument from the crisis of moral patiency, defend its main premises and address objections.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-017-0773-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-018-0210-y,Robust Adaptive Sliding Mode Neural Networks Control for Industrial Robot Manipulators,"International Journal of Control, Automation and Systems",10.1007/s12555-018-0210-y,Springer,2019-03-01,"This paper proposes an original robust adaptive controller by using Radial Basis Function Neural networks (RBFNNs) for industrial robot manipulators (IRMs) in uncertain dynamical environments. This suggested control structure combines sliding mode technique, RBFNNs approximation and adaptive technique to improve the high accuracy of the tracking control. The proposed RBFNNs can deal the small problems successful because of its simple structure, faster training update laws and better approximation for the unknown dynamic of IRMs. All the parameters of the proposed control system are determined by Lyapunov stability theorem, and tuned online by an adaptive learning algorithm. Therefore, the stability, robustness and desired tracking performance of RBFNNs for IRMs are guaranteed. The simulations and experimental performed on a three-link IRMs are proposed in comparison with proportional integral differential (PID) and adaptive Fuzzy (AF) control to prove the robustness and efficiency of the RBFNNs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-018-0210-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-018-9771-0,Enabling robots to communicate their objectives,Autonomous Robots,10.1007/s10514-018-9771-0,Springer,2019-02-15,"The overarching goal of this work is to efficiently enable end-users to correctly anticipate a robot’s behavior in novel situations. And since a robot’s behavior is often a direct result of its underlying objective function, our insight is that end-users need to have an accurate mental model of this objective function in order to understand and predict what the robot will do. While people naturally develop such a mental model over time through observing the robot act, this familiarization process may be lengthy. Our approach reduces this time by having the robot model how people infer objectives from observed behavior, in order to then show those behaviors that are maximally informative. We introduce two factors to define candidate models of human inference, and show that certain models indeed produce example robot behaviors that better enable users to anticipate what it will do in novel situations. Our results also reveal that choosing the appropriate model is key, and suggest that our candidate models do not fully capture how humans extrapolate from examples of robot behavior. We leverage these findings to propose a stronger model of human learning in this setting, and conclude by analyzing the impact of different ways in which the assumed model of human learning may be incorrect.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-018-9771-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00138-018-0966-3,A hybrid image dataset toward bridging the gap between real and simulation environments for robotics,Machine Vision and Applications,10.1007/s00138-018-0966-3,Springer,2019-02-13,"The primary motivation of computer vision in the robotics field is to obtain a perception level that is as close as possible to human visual system. To achieve this, the inclusion of large datasets is necessary, sometimes involving less-frequent and seemingly irrelevant data to increase the system robustness. To minimize the effort and time in forming such extensive datasets from real world, the preferred method is to utilize simulation environments, replicating real-world conditions as much as possible. Following this solution path, the machine vision problems in robotics (i.e., object detection, recognition, and manipulation) often employ synthetic images in datasets and, however, do not mix them with real-world images. When the systems are trained only using the synthetic images and tested within the simulated world, the tasks requiring object recognition in robotics can be accomplished. However, the systems trained using this procedure cannot be directly used in the real-world experiments or end-user products due to the inconsistencies between real and simulation environments. Therefore, we propose a hybrid image dataset including annotated desktop objects from real and synthetic worlds (ADORESet). This hybrid dataset provides purposeful object categories with a sufficient number of real and synthetic images. ADORESet is composed of colored images with the dimension of $$300\times 300$$ 300 × 300 pixels within 30 categories. Each class has 2500 real-world images acquired from the wild web and 750 synthetic images that are generated within Gazebo simulation environment. This hybrid dataset enables researchers to implement their own algorithms for both real-world and simulation environment conditions. ADORESet is composed of fully annotated object images. The limits of objects are manually specified, and the bounding box coordinates are provided. The successor objects are also labeled to give statistical information and the likelihood about the relations of the objects within the dataset. To further demonstrate the benefits of this dataset, it is tested in object recognition tasks by fine-tuning the state-of-the-art deep convolutional neural networks such as VGGNet, InceptionV3, ResNet, and Xception. The possible combinations regarding the data types for these models are compared in terms of time, accuracy, and loss values. As a result of the conducted object recognition experiments, training with all-real images yields approximately $$49\%$$ 49 % validation accuracy for simulation images. When the training is performed with all-synthetic images and validated using all-real images, the accuracy becomes lower than $$10\%$$ 10 % . If the complete ADORESet is employed for training and validation, the hybrid dataset validation accuracy reaches approximately to $$95\%$$ 95 % . This result proves further that including the real and synthetic images together in the training and validation sessions increases the overall system accuracy and reliability.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00138-018-0966-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/s41928-019-0213-6,Ethical standards in robotics and AI,Nature Electronics,10.1038/s41928-019-0213-6,Nature,2019-02-01,"A new generation of ethical standards in robotics and artificial intelligence is emerging as a direct response to a growing awareness of the ethical, legal and societal impacts of the fields. But what exactly are these ethical standards and how do they differ from conventional standards?",https://www.nature.com/articles/s41928-019-0213-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-018-0260-2,Neural network-based approaches for mobile robot navigation in static and moving obstacles environments,Intelligent Service Robotics,10.1007/s11370-018-0260-2,Springer,2019-01-24,"Mobile robots can travel by acquiring the information using sensor-actuator control techniques from surrounding and perform several tasks. Due to the ability of traversing, mobile robots are used in different application for different places. In the field of robotic research, robot navigation is the fundamental problem and it is easier in static environment than dynamic environment. This paper presents a new method for generating a collision-free, near-optimal path and speed for a mobile robot in a dynamic environment containing moving and static obstacles using artificial neural network. For each robot motion, the workspace is divided into five equal segments. The multilayer perceptron (MLP) neural network is used to choose a collision-free segment and also controls the speed of the robot for each motion. Simulation results show that the method is efficient and gives near-optimal path reaching the target position of the mobile robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-018-0260-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40430-019-1585-2,Lower gamma band in the classification of left and right elbow movement in real and imaginary tasks,Journal of the Brazilian Society of Mechanical Sciences and Engineering,10.1007/s40430-019-1585-2,Springer,2019-01-23,"In this article, the activity of lower gamma band was used to classify right and left elbow movements performed from real and imaginary tasks in two different cognitive states: the preparation and the movement execution. Discriminability maps were used both to generalize the signal behavior of all the volunteers and to select time intervals of high discrimination among classes. The features extracted from chosen intervals were tested in eight different classification algorithms. To improve classes discrimination, LDA was used for dimensional reduction. Algorithms were tested using a fivefold cross-validation. The results showed similar signal activity for both real and imaginary actions, obtaining closer classification responses among all volunteers. The tested algorithm gave a mean classification success up to 70%, with minor differences between the type of task and the cognitive state.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40430-019-1585-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11548-018-1866-8,Conditions for reliable grip force and jaw angle estimation of da Vinci surgical tools,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-018-1866-8,Springer,2019-01-17,"Purpose This work presents an estimation technique as well as corresponding conditions which are necessary to produce an accurate estimate of grip force and jaw angle on a da Vinci surgical tool using back-end sensors alone. Methods This work utilizes an artificial neural network as the regression estimator on a dataset acquired from custom hardware on the proximal and distal ends. Through a series of experiments, we test the effect of estimation accuracy due to change in operating frequency, using the opposite jaw, and using different tools. A case study is then presented comparing our estimation technique with direct measurements of material response curves on two synthetic tissue surrogates. Results We establish the following criteria as necessary to produce an accurate estimate: operate within training frequency bounds, use the same side jaw, and use the same tool. Under these criteria, an average root mean square error of 1.04 mN m in grip force and 0.17 degrees in jaw angle is achieved. Additionally, applying these criteria in the case study resulted in direct measurements which fell within the 95% confidence bands of our estimation technique. Conclusion Our estimation technique, along with important training criteria, is presented herein to further improve the literature pertaining to grip force estimation. We propose the training criteria to begin establishing bounds on the applicability of estimation techniques used for grip force estimation for eventual translation into clinical practice.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-018-1866-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10916-018-1151-y,A Machine Learning Approach to Predicting Case Duration for Robot-Assisted Surgery,Journal of Medical Systems,10.1007/s10916-018-1151-y,Springer,2019-01-05,"Robot-assisted surgery (RAS) requires a large capital investment by healthcare organizations. The cost of a robotic unit is fixed, so institutions must maximize use of each unit by utilizing all available operating room block time. One way to increase utilization is to accurately predict case durations. In this study, we sought to use machine learning to develop an accurate predictive model for RAS case duration. We analyzed a random sample of robotic cases at our institution from January 2014 to June 2017. We compared the machine learning models to the baseline model, which is the scheduled case duration (determined by previous case duration averages and surgeon adjustments). Specifically, we used: 1) multivariable linear regression, 2) ridge regression, 3) lasso regression, 4) random forest, 5) boosted regression tree, and 6) neural network. We found that all machine learning models decreased the average root-mean-squared error (RMSE) as compared to the baseline model. The average RMSE was lowest with the boosted regression tree (80.2 min, 95% CI 74.0–86.4), which was significantly lower than the baseline model (100.4 min, 95% CI 90.5–110.3). Using boosted regression tree, we can increase the number of accurately booked cases from 148 to 219 (34.9% to 51.7%, p  < 0.001). This study shows that using various machine learning approaches can improve the accuracy of RAS case length predictions, which will increase utilization of this limited resource. Further work is needed to operationalize these findings.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10916-018-1151-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-34995-0_51,Real-Time Gestural Control of Robot Manipulator Through Deep Learning Human-Pose Inference,Computer Vision Systems,10.1007/978-3-030-34995-0_51,Springer,2019-01-01,"With the raise of collaborative robots, human-robot interaction needs to be as natural as possible. In this work, we present a framework for real-time continuous motion control of a real collaborative robot (cobot) from gestures captured by an RGB camera. Through deep learning existing techniques, we obtain human skeletal pose information both in 2D and 3D. We use it to design a controller that makes the robot mirror in real-time the movements of a human arm or hand.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-34995-0_51,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-23712-7_52,Humanoid Robot Control Based on Deep Learning,E-Learning and Games,10.1007/978-3-030-23712-7_52,Springer,2019-01-01,"The direct control of humanoid robot by human motion is an important aspect of current research. Most of these methods are based on additional equipments, such as Kinect, which are usually not equipped on robot. In order to avoid using these external equipments, we explored a robot controlling method only using the low-resolution camera on robot. Firstly, a stacked hourglass network is employed to obtain the accurate 2D heatmap containing positions of human joints from RGB image captured by camera on robot. Then, 3D human poses including coordinates of human body joints are estimated from 2D heatmaps by a method aiming to reconstruct 3D human poses from 2D poses. Finally, the rotation angles of robot are computed according to these 3D coordinates and are transmitted to the robot to reconstruct the original human pose. Using the NAO robot as an example, the experimental results show that the humanoid robot can imitate motions of different human actors in different scenes well while applying our method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-23712-7_52,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-14984-0_29,Visual Data Simulation for Deep Learning in Robot Manipulation Tasks,Modelling and Simulation for Autonomous Systems,10.1007/978-3-030-14984-0_29,Springer,2019-01-01,"This paper introduces the usage of simulated images for training convolutional neural networks for object recognition and localization in the task of random bin picking. For machine learning applications, a limited amount of real world image data that can be captured and labeled for training and testing purposes is a big issue. In this paper, we focus on the use of realistic simulation of image data for training convolutional neural networks to be able to estimate the pose of an object. We can systematically generate varying camera viewpoint datasets with a various pose of an object and lighting conditions. After successful training and testing the neural network, we compare the performance of network trained on simulated images and images from a real camera capturing the physical object. The usage of the simulated data can speed up the complex and time-consuming task of gathering training data as well as increase robustness of object recognition by generating a bigger amount of data.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-14984-0_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-03748-2_40,Reinforcement Learning-Based Two-Wheel Robot Control,Recent Advances in Intelligent Information Hiding and Multimedia Signal Processing,10.1007/978-3-030-03748-2_40,Springer,2019-01-01,"In this paper, reinforcement learning (RL) with PID control is used to design the balance and self-control system to verify the feasibility of RL technology in this field. We can use straight line command and turn command via WiFi interface to control the robot. Thus the robot acts according to the received command. The system is divided into three parts: sensing module, learning control module and motor drive module. A Q-Learning algorithm is implemented by learning control module using ARM A8 embedded platform. The sensing module contains an accelerometer (ADXL345) and a gyroscope (L3G4200D) that senses the current tilt angle and angular velocity of robot. Rely on the Q-learning algorithm which based on the input data from sensing module, an optimal response control is derived in motor driving control. The realization results shown that the two-wheel robot can back to balance within 2 ms once it goes to unbalance state.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-03748-2_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-662-58485-9_7,Which deep artifical neural network architecture to use for anomaly detection in Mobile Robots kinematic data?,Machine Learning for Cyber Physical Systems,10.1007/978-3-662-58485-9_7,Springer,2019-01-01,"Small humps on the floor go beyond the detectable scope of laser scanners and are therefore not integrated into SLAM based maps of mobile robots. However, even such small irregularities can have a tremendous effect on the robot’s stability and the path quality. As a basis to develop anomaly detection algorithms, kinematics data is collected exemplarily for an overrun of a cable channel and a bulb plate. A recurrent neuronal network (RNN), based on the autoencoder principle, could be trained successfully with this data. The described RNN architecture looks promising to be used for realtime anomaly detection and also to quantify path quality.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-662-58485-9_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-26118-4_31,Emergency-Response Locomotion of Hexapod Robot with Heuristic Reinforcement Learning Using Q-Learning,Interactive Collaborative Robotics,10.1007/978-3-030-26118-4_31,Springer,2019-01-01,"The locomotion of legged robot is often controlled by predefined gaits, and this approach works well when all joints and motors are operating normally. However, walking legged robots usually have high risk of being damaged during operation, causing the breakdown of the robotic joints. In this paper, we introduce a reinforcement learning based approach for the legged robot to generate real-time locomotion response to the emergence of locomotion breakdown. Our approach detects the functionality of the available joints, substitutes the pre-defined gaits with proper gait function accordingly, and upgrades the gait-generation function by Q-Learning for the proper locomotion.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-26118-4_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-01370-7_9,Unsupervised Hump Detection for Mobile Robots Based On Kinematic Measurements and Deep-Learning Based Autoencoder,Intelligent Autonomous Systems 15,10.1007/978-3-030-01370-7_9,Springer,2019-01-01,"Small humps on the floor go beyond the detectable scope of laser scanners and are therefore not integrated into SLAM based maps of mobile robots. However, even such small irregularities can have a tremendous effect on the robot’s stability and the path quality. As a basis to develop anomaly detection algorithms, example kinematics data is collected for an overrun of a cable channel and a bulb plate. A recurrent neuronal network (RNN), based on the autoencoder principle, could be trained successfully with this data. The described RNN architecture looks promising to be used for realtime anomaly detection and also to quantify path quality.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-01370-7_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27538-9_54,Towards Deep Learning Based Robot Automatic Choreography System,Intelligent Robotics and Applications,10.1007/978-3-030-27538-9_54,Springer,2019-01-01,"It is a challenge task to enable a robot to dance according to different types of music. However, two problems have not been well resolved yet: (1) how to assign a dance to a certain type of music, and (2) how to ensure a dancing robot to keep in balance. To tackle these challenges, a robot automatic choreography system based on the deep learning technology is introduced in this paper. First, two deep learning neural network models are built to convert local and global features of music to corresponding features of dance, respectively. Then, an action graph is built based on the collected dance segments; the main function of the action graph is to generate a complete dance sequence based on the dance features generated by the two deep learning models. Finally, the generated dance sequence is performed by a humanoid robot. The experimental results shows that, according to the input music, the proposed model can successfully generate dance sequences that match the input music; also, the robot can maintain its balance while it is dancing. In addition, compared with the dance sequences in the training dataset, the dance sequences generated by the model has reached the level of artificial choreography in both diversity and innovation. Therefore, this method provides a promising solution for robotic choreography automation and design assistance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27538-9_54,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27538-9_46,3D Pose Estimation of Robot Arm with RGB Images Based on Deep Learning,Intelligent Robotics and Applications,10.1007/978-3-030-27538-9_46,Springer,2019-01-01,"In the field of human-robot interaction, robot collision avoidance with the human in a shared workspace remains a challenge. Many researchers use visual methods to detect the collision between robots and obstacles on the assumption that the robot pose is known because the information about the robot is obtained from the controller and hand-eye calibration is conducted. Therefore, they focus on the motion prediction of obstacles. In this paper, a real-time method based on deep learning is proposed to directly estimate the 3D pose of the robot arm using a color image. The method aims to remove the hand-eye calibration when the system needs to be reconfigured and increase the flexibility of the system by eliminating the requirement that the camera fixed relative to the robot. Our approach has two main contributions. One is that the method estimates the 3D position of the robot base and the relative 3D positions of the predefined key points of the robot to the robot base separately different from other deep learning methods considering the limitations of the dataset. The other is that some datasets are collected through another trained network to avoid tedious calibration process, and the trained network will be reused in the pose estimation task. Finally, the experiments are conducted. The results show that a fully trained system provides an accurate 3D pose estimation for the robot arm in the camera coordinate system. The average errors of the 3D positions of the robot base and the predefined key points are 2.35 cm and 1.99 cm respectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27538-9_46,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-35699-6_1,Learning to Run Faster in a Humanoid Robot Soccer Environment Through Reinforcement Learning,RoboCup 2019: Robot World Cup XXIII,10.1007/978-3-030-35699-6_1,Springer,2019-01-01,"Reinforcement learning techniques bring a new perspective to enduring problems. Developing skills from scratch is not only appealing due to the artificial creation of knowledge. It can also replace years of work and refinement in a matter of hours. From all the developed skills in the RoboCup 3D Soccer Simulation League, running is still considerably relevant to determine the winner of any match. However, current approaches do not make full use of the robotic soccer agents’ potential. To narrow this gap, we propose a way of leveraging the Proximal Policy Optimization using the information provided by the simulator for official RoboCup matches. To do this, our algorithm uses a mix of raw, computed and internally generated data. The final result is a sprinting and a stopping behavior that work in tandem to bring the agent from point a to point b in a very short time. The sprinting speed stabilizes at around 2.5 m/s, which is a great improvement over current solutions. Both the sprinting and stopping behaviors are remarkably stable.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-35699-6_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-00232-9_52,A Reinforcement Learning Based Algorithm for Robot Action Planning,Advances in Service and Industrial Robotics,10.1007/978-3-030-00232-9_52,Springer,2019-01-01,"The learning process that arises in response to the visual perception of the environment is the starting point for numerous research in the field of applied and cognitive robotics. In this research, we propose a reinforcement learning based action planning algorithm for the assembly of spatial structures with an autonomous robot in an unstructured environment. We have developed an algorithm based on temporal difference learning using linear base functions for the approximation of the state-value-function because of a large number of discrete states that the autonomous robot can encounter. The aim is to find the optimal sequence of actions that the agent (robot) needs to take in order to move objects in a 2D environment until they reach the predefined target state. The algorithm is divided into two parts. In the first part, the goal is to learn the parameters in order to properly approximate the Q function. In the second part of the algorithm, the obtained parameters are used to define the sequence of actions for a UR3 robot arm. We present a preliminary validation of the algorithm in an experimental laboratory scenario.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-00232-9_52,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-96722-6_11,Artificial Intelligence in Human-Robot Interaction,Emotional Design in Human-Robot Interaction,10.1007/978-3-319-96722-6_11,Springer,2019-01-01,"Human-Robot Interaction challenges the field of research on Artificial Intelligence in many ways, especially regarding the complexity of the physical world. While physical interactions require Artificial Intelligence techniques to handle dynamic, nondeterministic, and partially unknown environments, the communication with humans requires socially acceptable responses and common-sense knowledge to handle a broad variety of situations with complex semantics to interpret and understand. In the context of emotional design, different Artificial Intelligence techniques are necessary to allow robots to express, understand, and induce emotions as part of the interaction process. This chapter explores Human-Robot Interaction from the Artificial Intelligence point of view, presenting the main challenges, techniques, and our particular vision for future developments in this research area.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-96722-6_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-19823-7_52,Using Shallow Neural Network Fitting Technique to Improve Calibration Accuracy of Modeless Robots,Artificial Intelligence Applications and Innovations,10.1007/978-3-030-19823-7_52,Springer,2019-01-01,"This paper describes a technique for the position error estimations and compensations of the modeless robots and manipulators calibration process based on a shallow neural network fitting function method. Unlike traditional model-based robots calibrations, the modeless robots calibrations do not need to perform any modeling and identification processes. Only two processes, measurements and compensations, are necessary for this kind of robots calibrations. By using the shallow neural network fitting technique, the accuracy of the position error compensation can be greatly improved, which is confirmed by the simulation results given in this paper. Also the comparisons among the popular traditional interpolation methods, such as bilinear and fuzzy interpolations, and this shallow neural network technique, are made via simulation studies. The simulation results show that more accurate compensation result can be achieved using the shallow neural network fitting technique compared with the bilinear and fuzzy interpolation methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-19823-7_52,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-1078-6_11,Robot Arm Control Method of Moving Below Object Based on Deep Reinforcement Learning,Methods and Applications for Modeling and Simulation of Complex Systems,10.1007/978-981-15-1078-6_11,Springer,2019-01-01,"The existing robot arm control system has long commissioning time and the control system has poor scope of application. In this paper, the Deep Deterministic Policy Gradient (DDPG) algorithm has been adopted and adapted to control the robot arm to move below the object at any position, thereby enhancing the flexibility of the control algorithm and shortening the adjusting time. In addition, to address the problem that physical production line cannot be utilized directly or provide sufficient data for training deep reinforcement learning agent, this paper constructs a virtual model containing both the robot arm and the object as training environment for the agent. Simulation experiment has been performed with state variables and reward properly designed. As is shown by the results, the control agent trained in this paper show good performance in controlling the robot arm, which in turn confirms the effectiveness of the training algorithm with effective data support of the constructed simulation environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-1078-6_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-98020-1_42,Solving Inverse Kinematics of a Planar Dual-Backbone Continuum Robot Using Neural Network,EuCoMeS 2018,10.1007/978-3-319-98020-1_42,Springer,2019-01-01,"The inverse kinematics of multiple-backbone continuum robots is a highly non-linear problem. Traditional methods for solving such kinds of problems include the inverse transformation, geometric approach, etc., which are relatively complex and have multiple solutions. On the other hand, the pseudo-rigid-body model (PRBM) is one simple approach for solving the forward kinematics of multiple-backbone continuum robots, but currently, it is still not applicable for solving the inverse kinematics problem. In this paper, we present a strategy for solving the inverse kinematics problem of a dual-backbone continuum robot using PRBM and the Artificial Neural Network (ANN). The strategy firstly computes the forward kinematic solutions of the dual-backbone robot via the PRBM approach. The obtained solutions are then used to build up an ANN model for solving the inverse kinematics of the dual-backbone continuum robot. Based on the Bayesian Regularization training algorithm, the accuracy of the ANN results after linear regression is 99.99%. Finally, we compared the errors between the inputs of the forwards kinematics problem and the output (solutions) of the inverse kinematics problem solved by the ANN model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-98020-1_42,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-94120-2_35,Current Research Trends in Robot Grasping and Bin Picking,International Joint Conference SOCO’18-CISIS’18-ICEUTE’18,10.1007/978-3-319-94120-2_35,Springer,2019-01-01,"We provide a view of current research issues in Robotic Grasping and Bin Picking focused on the perception aspects of the problem, mainly related to computer vision algorithms. After recalling the evolution of the topics in the last decades, we focus on the modern use of Deep Learning Algorithms. Two main trends are followed in the approaches to innovative grasping techniques. First, Convolutional Neural Networks are used for grasping perceptual aspects. We discuss the different degrees of success of several published approaches. Second, Deep Reinforcement Learning is being extensively tested in order to develop integrated eye-hand coordination systems not requiring delicate calibration. We provide also a discussion of possible future lines of research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-94120-2_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-13-7983-3_48,Robot Simulation and Reinforcement Learning Training Platform Based on Distributed Architecture,Cognitive Systems and Signal Processing,10.1007/978-981-13-7983-3_48,Springer,2019-01-01,"In recent years, reinforcement learning, which enables robots to learn previously missing abilities, plays an increasingly important role in robotics, such as learning hard-to-code behaviors or optimizing problems without an accepted closed solution. The main problem of RL in robotics is that it is expensive and takes a long time to learn and operate. Another problem: advanced robot simulators like Gazebo are inefficient and time-consuming. In order to cope with these problems, a hybrid computing platform based on traditional robot simulation architecture and distributed architecture (hereinafter referred to as RDTP) is proposed in this paper, which helps to save cost, shorten time and speed up simulation and training. Additionally, the platform is optimized to a certain extent in terms of ease of use and compatibility.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-7983-3_48,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-04792-4_6,A Comparison of Various Approaches to Reinforcement Learning Algorithms for Multi-robot Box Pushing,Advances in Engineering Research and Application,10.1007/978-3-030-04792-4_6,Springer,2019-01-01,"In this paper, a comparison of reinforcement learning algorithms and their performance on a robot box pushing task is provided. The robot box pushing problem is structured as both a single agent problem and also a multi-agent problem. A Q-learning algorithm is applied to the single-agent box pushing problem, and three different Q-learning algorithms are applied to the multi-agent box pushing problem. Both sets of algorithms are applied on a dynamic environment that is comprised of static objects, a static goal location, a dynamic box location, and dynamic agent positions. A simulation environment is developed to test the four algorithms, and their performance is compared through graphical explanations of test results. The comparison shows that the newly applied reinforcement algorithm out-performs the previously applied algorithms on the robot box pushing problem in a dynamic environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-04792-4_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-662-60417-5_48,Experimental validation of smoothed machine learning-based parameterization of local support in robot-based incremental sheet forming,Production at the leading edge of technology,10.1007/978-3-662-60417-5_48,Springer,2019-01-01,"In robot-based incremental sheet forming the part is shaped solely by the movement of a typically hemispherical forming tool. A local supporting tool can be moved directly opposed to the forming tool on the other side of the sheet to locally form an accuracy improving die. The two major process parameters of the local support are the support angle and the support force. Although their influence on the forming process is proven, concrete calculation methods for process planning based on the part’s geometry are still missing. To improve the process planning and therefore the geometric accuracy of the formed part, the authors present a novel approach where the parameterization of the local support is done by machine learning. Specifically, various artificial neural networks are trained with a process database gathered in a preceding experimental survey. Their performance to predict the resulting geometric deviation of every toolpath point is compared under different aspects. The most precise artificial neural network is used to predict the combination of support force and support angle that minimizes the geometric deviation. Afterwards, a laplacian smoothing function is presented to prevent rapid changes of the process parameters and to keep the forming process controllable. In the end, the approach is experimentally validated with the part used to build up the process database and an additional part to demonstrate the transferability of the approach. In der roboterbasierten inkrementellen Blechumformung wird das Bauteil nur durch die Bewegung eines typischerweise halbkugelförmigen Umformwerkzeugs ausgeformt. Ein lokales Gegenhaltewerkzeug kann, gegenüber dem Umformwerkzeug, auf der anderen Blechseite bewegt werden und bildet lokal eine Patrize nach, um die geometrische Genauigkeit zu steigern. Die zwei Hauptprozessparameter des lokalen Gegenhaltewerkzeugs sind der Nacheilwinkel und die Gegenhaltekraft. Obwohl deren Einfluss auf den Umformprozess nachgewiesen ist, fehlt es an konkreten Berechnungsmethoden zur Prozessplanung, die auf der Bauteilgeometrie basieren. Um die Prozessplanung und dementsprechend die geometrische Genauigkeit des umgeformten Bauteils zu verbessern, stellen die Autoren einen neuartigen Ansatz vor, in dem der lokale Gegenhalter mittels maschinellen Lernens parametriert wird. Konkret werden verschiedene künstliche neuronale Netze mit einer Prozessdatenbank, die in einer vorangegangenen Versuchsreihe aufgebaut wurde, trainiert. Deren Leistungsfähigkeit zur Vorhersage der geometrischen Abweichung eines jeden Werkzeugbahnpunktes wird unter verschiedenen Aspekten verglichen. Das präziseste, künstliche neuronale Netz wird genutzt, um die Kombination von Nacheilwinkel und Gegenhaltekraft mit der geringsten geometrischen Abweichung vorauszusagen. Nachfolgend wird eine laplacesche Glättungsfunktion vorgestellt, die genutzt wird, um Sprünge der Prozessparameter zu verhindern und die Regelbarkeit des Umformprozesses zu bewahren. Abschließend wird der Ansatz sowohl anhand des Bauteils, mit dem die Prozessdatenbank aufgebaut wurde, experimentell validiert als auch dessen Übertragbarkeit unter Zuhilfenahme eines weiteren Bauteils demonstriert.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-662-60417-5_48,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-33274-7_11,Toward Faster Reinforcement Learning for Robotics: Using Gaussian Processes,Artificial Intelligence,10.1007/978-3-030-33274-7_11,Springer,2019-01-01,"Standard robotic control works perfectly in case of ordinary conditions, but in the case of a change in the conditions (e.g. damaging of one of the motors), the robot won’t achieve its task anymore. We need an algorithm that provide the robot with the ability of adaption to unforeseen situations. Reinforcement learning provide a framework corresponds with that requirements, but it needs big data sets to learn robotic tasks, which is impractical. We discuss using Gaussian processes to improve the efficiency of the Reinforcement learning, where a Gaussian Process will learn a state transition model using data from the robot (interaction) phase, and after that use the learned GP model to simulate trajectories and optimize the robot’s controller in a (simulation) phase. PILCO algorithm considered as the most data efficient RL algorithm. It gives promising results in Cart-pole task, where a working controller was learned after seconds of (interaction) on the real robot, but the whole training time, considering the training in the (simulation) was longer. In this work, we will try to leverage the abilities of the computational graphs to produce a ROS friendly python implementation of PILCO, and discuss a case study of a real world robotic task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-33274-7_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-22964-1_7,Robot Intelligent Perception Based on Deep Learning,"Proceedings of the 1st International Conference on Smart Innovation, Ergonomics and Applied Human Factors (SEAHF)",10.1007/978-3-030-22964-1_7,Springer,2019-01-01,"Robotic and automation field is continuously in expansion. Robotic systems are now operating in unknown and dynamic environments. Therefore, they must not only classify sensory pattern but also determine the decision and action to be made. The well making decision of robot will depend on its efficiency when processing raw sensor data. In this work, we propose an innovative approach for robot intelligent perception and decision making process. We investigate the ability of deep learning methods to be brought to bear on robotic system decision making and control. Our challenging researches consist on providing robots the ability to autonomously recognize obstacle without a pre-programming need. For this purpose, we design a deep learning based framework to compute a high-quality convolutional Neural Network (CNN) model for image classification. The designed approach is labeled Enhanced Elite CNN Propagation Method. Simulations demonstrate the effectiveness of robot decision making when exploring its environment based on our approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-22964-1_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-13-1675-3_4,The Enterprise Technology Landscape,Business Innovation and ICT Strategies,10.1007/978-981-13-1675-3_4,Springer,2019-01-01,"This chapter explores the broad technological themes in the evolving enterprise landscape, including the key ICT technologies that will gain force, for example, cloud, AI/ML, IoT, drones, blockchain, and so on. The evolving role of the CTO/CIO is examined and the future demands of the role are discussed. Finally the current (indicative) ICT spend and its breakup in any organization were described.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-1675-3_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-22999-3_60,Using Particle Filter and Machine Learning for Accuracy Estimation of Robot Localization,Advances and Trends in Artificial Intelligence. From Theory to Practice,10.1007/978-3-030-22999-3_60,Springer,2019-01-01,"Robot localization is a fundamental capability of all mobile robots. Because of uncertainties in acting and sensing and environmental factors such as people flocking around robots there is always the risk that a robot loses its localization. Very often behaviors of robots rely on a valid position estimation. Thus, for dependability of robot systems it is of great interest for the system to know the state of its localization component. In this paper we present an approach that allows a robot to asses if the localization is still valid. The approach assumes that the underlying localization approach is based on a particle filter. We use deep learning to identify temporal patterns in the particles in the case of losing/lost localization in combination with weak classifiers from the particle set and perception for boosted learning of a localization monitor. The approach is evaluated in a simulated transport robot environment where a degraded localization is provoked by disturbances cased by dynamic obstacles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-22999-3_60,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27526-6_51,Improvement of Mask-RCNN Object Segmentation Algorithm,Intelligent Robotics and Applications,10.1007/978-3-030-27526-6_51,Springer,2019-01-01,"Semantic maps play a key role in tasks such as navigation of mobile robots. However, the visual SLAM algorithm based on multi-objective geometry does not make full use of the rich semantic information in space. The map point information retained in the map is just a spatial geometric point without semantics. Since the algorithm based on convolutional neural network has achieved breakthroughs in the field of target detection, the target segmentation algorithm MASK-RCNN is combined with the SLAM algorithm to construct the semantic map. However, the MASK-RCNN algorithm easily treats part of the background in the image as foreground, which results in inaccuracy of target segmentation. Moreover, Grubcut segmentation algorithm is time-consuming, but it’s easy to take foreground as background, which leads to the excessive edge segmentation. Based on these, our paper proposes a novel algorithm which combines MASK-RCNN and Grubcut segmentation. By comparing the experimental results of MASK-Rcnn, Grubcut and the improved algorithm on the data set, it is obvious that the improved algorithm has the best segmentation effect and the accuracy of image target segmentation is significantly improved. These phenomenons demonstrate the effectiveness our proposed algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27526-6_51,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-10-8944-2_49,A Deep Learning-Based Robotic Grasp Detection Method,"Recent Developments in Intelligent Computing, Communication and Devices",10.1007/978-981-10-8944-2_49,Springer,2019-01-01,"Deep learning makes a great breakthrough in the field of artificial intelligence. The performance of robots on the uncertainty task can be enhanced using the deep learning. Due to the accumulative errors of the servomotors, the robot’s end-of-arm tooling (EOAT) could not grasp objects in proper position. It is worth to study robotic grasping detection with the deep learning while there has already been some successes practice in the robotics research. We propose a novel method for the robotic grasp detection that gives the grasp position of a parallel-plate robotic gripper based on the deep learning model with the RGBD image of the scene. The best model of our method archived an accuracy of 87.49% with an acceptable time speed. Our method introduces another way to solve the robotic grasping problem.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-8944-2_49,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-10898-4_4,"Toying with the Singularity: AI, Automata and Imagination in Play with Robots and Virtual Pets",The Internet of Toys,10.1007/978-3-030-10898-4_4,Springer,2019-01-01,"To grasp the emerging possibilities of new developments in the Internet of Toys, paying critical attention to the layered relationships of material technology and intangible imagination is needed. This chapter explores children’s imaginative and playful engagement with toys that demonstrate AI or autonomous behaviour (here robots and virtual pets). It takes a workshop on the design of a new robotic gaming platform as a central case study. Paying close descriptive and analytical attention to moments of interaction with such toys is essential to fully grasp the complex relationships between global technological imaginaries—in this case of AI and artificial life—and the material and embodied workings of imagination in play.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-10898-4_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-32388-2_57,Robustness Analysis on Natural Language Processing Based AI Q&A Robots,Machine Learning and Intelligent Communications,10.1007/978-3-030-32388-2_57,Springer,2019-01-01,"Recently, the natural language processing (NLP) based intelligent question and answering (Q&A) robots have been used in a wide range of applications, such as smart assistant, smart customer service, government business. However, the robustness and security issues of these NLP based artificial intelligence (AI) Q&A robots have not been studied yet. In this paper, we analyze the robustness problems in current Q&A robots, which include four aspects: (1) semantic slot settings are incomplete; (2) sensitive words are not filtered efficiently and completely; (3) Q&A robots return the search results directly; (4) unsatisfactory matching algorithms and inappropriate matching threshold settings. Then, we design and implement two types of evaluation tests, bad language and user’s typos, to evaluate the robustness of several state-of-the-art Q&A robots. Experiment results show that these common inputs (bad language and user’s typos) can successfully make these Q&A robots malfunction, denial of service, or speaking dirty words. Besides, we also propose possible countermeasures to enhance the robustness of these Q&A robots. To the best of the authors’ knowledge, this is the first work on analyzing the robustness and security problems of intelligent Q&A robots. This work can hopefully help provide guidelines to design robust and secure Q&A robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-32388-2_57,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-36711-4_49,Achieving Human–Robot Collaboration with Dynamic Goal Inference by Gradient Descent,Neural Information Processing,10.1007/978-3-030-36711-4_49,Springer,2019-01-01,"Collaboration with a human partner is a challenging task expected of intelligent robots. To realize this, robots need the ability to share a particular goal with a human and dynamically infer whether the goal state is changed by the human. In this paper, we propose a neural network-based computational framework with a gradient-based optimization of the goal state that enables robots to achieve this ability. The proposed framework consists of convolutional variational autoencoders (ConvVAEs) and a recurrent neural network (RNN) with a long short-term memory (LSTM) architecture that learns to map a given goal image for collaboration to visuomotor predictions. More specifically, visual and goal feature states are first extracted by the encoder of the respective ConvVAEs. Visual feature and motor predictions are then generated by the LSTM based on their current state and are conditioned according to the extracted goal feature state. During collaboration after the learning process, the goal feature state is optimized by gradient descent to minimize errors between the predicted and actual visual feature states. This enables the robot to dynamically infer situational (goal) changes of the human partner from visual observations alone. The proposed framework is evaluated by conducting experiments on a human–robot collaboration task involving object assembly. Experimental results demonstrate that a robot equipped with the proposed framework can collaborate with a human partner through dynamic goal inference even when the situation is ambiguous.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-36711-4_49,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-15857-6_30,Autonomous Robot Control System for Automation of Manipulations,Mechatronics 2017 - Ideas for Industrial Applications,10.1007/978-3-030-15857-6_30,Springer,2019-01-01,"The aim of the research is to analyze the possibilities of creating a robot control system allowing automatic replication of manual actions. Functioning of the system would be based on the detection and identification of manipulations and environment changes related to a particular task. For the purpose, 3D machine vision is required in order to monitor people and objects around a robot. Acquired information would be used by an artificial intelligence system for creating relations between manipulation motions and events in a working area. This would allow the automation of a huge range of manual actions by showing the controller how a robot should perform them. In combination with motion path optimization and collision prevention, the presented solution could be an intelligent tool in the human-machine collaboration and machine learning. The article concerns the main concept of the autonomous robot control system, including techniques planned to be applied, and the plan of the research leading to the definition of principles allowing the creation of the system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-15857-6_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-94878-2_18,Does Future Society Need Legal Personhood for Robots and AI?,Artificial Intelligence in Medical Imaging,10.1007/978-3-319-94878-2_18,Springer,2019-01-01,"If artificial entities as autonomous robots will be sentient beings, will it be necessary to give robots and AI entities some legal capacity comparable with legal personhood in a society that will be interacting with robotics and AI appliances? Must they have an understanding of legal consequences of their actions? In this chapter, this question is considered by analyzing the future capacities and functions of robots and AI systems and the rights and duties of existing legal subjects, natural persons, and (artificial) legal persons such as corporations and states. The question is posed if AI will have a capacity to be sentient as natural persons and—maybe— other living beings or will AI always be comparable with the subject in the Chinese room experiment? Therefore the relevance of free will, intelligence, and consciousness of natural persons to acquire legal personhood are analyzed and compared with other beings, animals, and future sentient AI entities. The hesitance to give legal personhood to AI is also influenced by the human conviction that this would increase the risk to lose control and a “robot uprising.” Man, as always, is afraid of technology getting out of hand and is convinced of their own superiority and therefore always wants to stay in control. Question is if there always has to be a natural person in the loop. In that light the need for a certain legal personhood in a future legal framework, considering civil liability and even criminal liability, is discussed as it is also subjected to considerations as proposed by a resolution of the European Parliament, eventually leading to proposals in European policy and law.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-94878-2_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-16447-8_1,Syntropic Counterpoints: Philosophical Content Generated Between Two Artificial Intelligence Clones,Intelligent Technologies for Interactive Entertainment,10.1007/978-3-030-16447-8_1,Springer,2019-01-01,"In the project Syntropic Counterpoints, we are using discussions between Artificial Intelligence clones to generate creative content. Nevertheless, our focus is less on content analysis and more on the beauty of creation itself and given context by the machines. We are using a different recurrent neural network (RNN), and collective creativity approaches to support interactions between Artificial Intelligence clones and trigger a humanless creative process which should lead to unsupervised robot creativity. The robots are trained by using the publications of some of the greatest thinkers of their time such as Aristotle, Nietzsche, Machiavelli, Sun Tzu and confronted to the crucial questions related to humankind such as understanding of moral, aesthetic, ethic, strategy, politics, etc. Throughout this robot-robot interaction model, we are trying to investigate the possibilities and consider limitations of using artificial intelligence in context-based creative processes as well as to raise questions related to potential future phenomena of machines mindfulness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-16447-8_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-91334-6_6,Building a Behaviour Architecture: An Approach for Promoting Human-Robot Interaction,"Innovation, Engineering and Entrepreneurship",10.1007/978-3-319-91334-6_6,Springer,2019-01-01,"Human distraction behaviour is a paramount subject to take into account. Several woks in the literature try to tackle this topic mostly in the automotive industry. Following this trend, the present work proposes a system to detect the patterns of distraction/attention during an interaction activity between a human and a robot. The goal is to analyse selected patterns of distraction, such as eye gaze, head pose, blinking rate, among others, and adapting the robot behaviour, consequently promoting a more fluid interaction. A behavioural state machine that takes into account the engagement and the performance of the user in the activity is proposed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-91334-6_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-21814-0_9,SHAUN—A Companion Robot for Children Based on Artificial Intelligence,Learning and Collaboration Technologies. Designing Learning Experiences,10.1007/978-3-030-21814-0_9,Springer,2019-01-01,"This article is aimed at providing a design principle for companion robot based on Artificial Intelligence. Taking children at 0–6 years old as target users and their parents as target customers, the author applied methods of investigation and observation to understand their income level, life routine, habit, pain points, consumption capacity and aesthetic level. With these previous researches and some utilization of ergonomics, this paper defined the function, size, material of Companion Robot for children. This paper explores and summarizes the user orientation of Companion Robot for children, its functional definition, material definition and man-machine definition, and shows the design practice under its guidance. This study will provide guidance for future design of companion robots and make the design location clearer by putting forward design concepts and guidelines.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-21814-0_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-13397-9_34,Regarding the Issue of the Essence of Legal Treatment and the Possibility of Granting Legal Status to a Robot in Civil Law,Ubiquitous Computing and the Internet of Things: Prerequisites for the Development of ICT,10.1007/978-3-030-13397-9_34,Springer,2019-01-01,"Active development of digital economy in Russia and across the world stimulates the usage of the robotic devices in many different areas of society. Thus arises the necessity to study the issue of the legal treatment of robots and how it corresponds to the legal status if the subjects of civil law. In this paper the possibility of granting robots the status of the subjects of the law is researched. As the robots are essentially technical devises it makes sense to view them as objects of law with specific technical specifications. Next some possibilities of robots making specific actions and thus having some characteristics of the subject of law are studied. We found out that robots (with AI or some parts of it) do possess such characteristics. However it should be noted, that despite having some characteristics of the subject of civil circulation, robots cannot be the subjects of the law as they don’t possess their own free will and thus cannot express their mental attitude towards their actions. There’s no real basis to make robots a part of civil circulation as independent and standalone subject of the law, based on the case with the legal persons. The purpose of legal persons for existing is always clear and justified by the necessity of capital aggregation or by the joint venture of physical persons. Also the legal persons take part in civil circulation via its official bodies, which may be represented by a physical person or several of them who possess their own free will and intelligence. Robots with their abilities to independently carry out some physical acts without human interference may perform specific functions as a part of the system of property relations. But despite that fact robots cannot be recognized as independent subjects of law, as their actions are always defined by their human owners who actually possess legal capacity, active capacity and delictual dispositive capacity. The methods of general scientific research (dialectic, inductive, deductive, analytic, synthetic) and specific scientific research (legalistic, interpretative) are used in this research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-13397-9_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27538-9_31,A Hybrid Deep Reinforcement Learning Algorithm for Intelligent Manipulation,Intelligent Robotics and Applications,10.1007/978-3-030-27538-9_31,Springer,2019-01-01,"Conventional collaborative robots can solve complex problems through programming approaches. But the current tasks are different and nonrepetitive, many problems cannot be solved by conventional programming methods. Deep reinforcement learning provides a framework for solving robotic control tasks using machine learning techniques. However, the existing model-free deep reinforcement learning algorithms lack unified framework for comparing sample efficiency with final performance. In this paper, a hybrid deep reinforcement learning framework and its application in robot control are proposed based on the existing model-free deep reinforcement learning algorithms. In the acting process, the distributed actors acting with the environment are used to acquire the data, while prior actors are used to solve the cold boot problem of the algorithm. In the learning process, prioritized experience replay and multi-step learning are designed for the improvement on the final performance. Simulations are represented to show the practicality and potential of the proposed algorithm. Results show that the hybrid deep reinforcement learning algorithm in this paper has a significant improvement on the final performance and sample efficiency while it can ensure the stability and convergence.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27538-9_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-20915-5_55,Enhancing Cognitive Virtual Maps for Domestic Service Robots by Adapting the User’s Perception on Uncertain Information Based on the Robot Experience: A Neural Network Approach,Artificial Intelligence and Soft Computing,10.1007/978-3-030-20915-5_55,Springer,2019-01-01,Assistive robots possess the competency to provide companionship to the human beings. Navigation is an essential factor of the robot. The robot should have the capability to virtually imagine the description of an unknown environment to prove that it possesses a better navigation skill. Subsequently they should improve the capability in relevance to the imagining with its experience. Therefore this paper proposes a method to improve the virtual imagining capability of a service robot while understanding the uncertain information about an object size using the artificial neural network. The proposed method possesses the capability to create a virtual map of an environment and enhances it using the actual sensory data. The Virtual Map Modeler (VOM) has been introduced in order to create the improved virtual maps. The capabilities of the robots have been demonstrated and evaluated for the performance.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-20915-5_55,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-26354-6_1,Multi-robot Cooperation Strategy in a Partially Observable Markov Game Using Enhanced Deep Deterministic Policy Gradient,Advances in Swarm Intelligence,10.1007/978-3-030-26354-6_1,Springer,2019-01-01,"Deep reinforcement learning (DRL) has been applied to solve challenging problems in robotic domains. However, since non-stationary of the environment and the difficulty of long-term interaction between robots, traditional DRL is poorly suitable for multi-robot. Thus, an enhanced deep deterministic policy gradient algorithm is proposed in this study to explore the application of DRL in multi-robot domains. The algorithm ensures a cooperation strategy for multi-robot, which merely uses partially observed state of each robot, named a partially observable Markov game, realize global optimality in executing process. It is achieved by eliminating non-stationary of the environment in training process and a centralized critic for decentralized multi-robot. Simulations with increasingly complex environments are performed to validate the effectiveness of the proposed algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-26354-6_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-99316-4_37,An Intrinsically Motivated Robot Explores Non-reward Environments with Output Arbitration,Biologically Inspired Cognitive Architectures 2018,10.1007/978-3-319-99316-4_37,Springer,2019-01-01,"In real worlds, rewards are easily sparse because the state space is huge. Reinforcement learning agents have to achieve exploration skills to get rewards in such an environment. In that case, curiosity defined as internally generated rewards for state prediction error can encourage agents to explore environments. However, when a robot learns its policy by reinforcement learning, changing outputs of the policy cause jerking because of inertia. Jerking prevents state prediction from convergence, which would make the policy learning unstable. In this paper, we propose Arbitrable Intrinsically Motivated Exploration (AIME), which enables robots to stably learn curiosity-based exploration. AIME uses Accumulator Based Arbitration Model (ABAM) that we previously proposed as an ensemble learning method inspired by prefrontal cortex. ABAM adjusts motor controls to improve stability of reward generation and reinforcement learning. In experiments, we show that a robot can explore a non-reward simulated environment with AIME.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-99316-4_37,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-25332-5_42,Towards Generating Simulated Walking Motion Using Position Based Deep Reinforcement Learning,Towards Autonomous Robotic Systems,10.1007/978-3-030-25332-5_42,Springer,2019-01-01,"Much of robotics research aims to develop control solutions that exploit the machine’s dynamics in order to achieve an extraordinarily agile behaviour [ 1 ]. This, however, is limited by the use of traditional model-based control techniques such as model predictive control and quadratic programming. These solutions are often based on simplified mechanical models which result in mechanically constrained and inefficient behaviour, thereby limiting the agility of the robotic system in development [ 2 ]. Treating the control of robotic systems as a reinforcement learning (RL) problem enables the use of model-free algorithms that attempt to learn a policy which maximizes the expected future (discounted) reward without inferring the effects of an executed action on the environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-25332-5_42,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-33749-0_48,A Fast and Robust Deep Learning Approach for Hand Object Grasping Confirmation,Advances in Soft Computing,10.1007/978-3-030-33749-0_48,Springer,2019-01-01,"One of the most important skills for service robots is object manipulation, which is still a challenging task. Since object manipulation is a hard task, it is relevant to know if an object was successfully grasped, avoiding future wrong decisions. Object grasp confirmation is commonly solved by using robotic sensors (infrared, pressure, etc.), but, in many cases, these sensors are not available for all robots. In contrast, depth and RGB sensor are present in almost all service robots. In this work a novel computer vision based method oriented to hand object grasp confirmation is proposed, which uses a deep learning network trained with depth maps. In order to measure the performance of the proposed method, experiments were performed using a single-arm manipulator service robot for both known and unknown objects. Experimental results show that the proposed approach correctly identifies 99% of both classes (object grasped or not grasped) with known objects and $$92\%$$ with unknown objects. The grasping confirmation method was added to the Storing Groceries task, for RoboCup@Home competition, improving its time performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-33749-0_48,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27544-0_10,Playing Soccer Without Colors in the SPL: A Convolutional Neural Network Approach,RoboCup 2018: Robot World Cup XXII,10.1007/978-3-030-27544-0_10,Springer,2019-01-01,"The goal of this paper is to propose a vision system for humanoid robotic soccer that does not use any color information. The main features of this system are: (i) real-time operation in the NAO robot, and (ii) the ability to detect the ball, the robots, their orientations, the lines and key field features robustly. Our ball detector, robot detector, and robot’s orientation detector obtain the highest reported detection rates. The proposed vision system is tested in a SPL field with several NAO robots under realistic and highly demanding conditions. The obtained results are: robot detection rate of 94.90%, ball detection rate of 97.10%, and a completely perceived orientation rate of 99.88% when the observed robot is static, and 95.52% when the observed robot is moving.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27544-0_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27538-9_33,Virtual Force Senor Based on PSO-BP Neural Network for Legged Robots in Planetary Exploration,Intelligent Robotics and Applications,10.1007/978-3-030-27538-9_33,Springer,2019-01-01,"The foot force of the legged robot plays a decisive role in the balance of the fuselage. Especially when walking on the irregular road surface and the less rigid road surface, the change of the foot end support force will change the attitude of the robot body, which will affect the stability. In addition, the change of foot force is also closely related to the flexibility of the movement of the leg of the robot. When the movement of the foot end has a transition from free space to constrained space, only the position control will not meet the requirements of the leg for the flexibility of the movement. This paper addresses the design of virtual sensors for terrain adaptation developed with the aims of simplifying the hardware of the legged robot or increasing the reliability of the sensorial information available. The virtual force sensor (VFS) is developed based on particle swarm optimization (PSO) BP neural network and can estimate the forces exerted by the feet from data extracted from joint-position, joint-velocity, and joint-torque, which are mandatory in all robotic systems. The force estimates are used to detect foot/ground contact. Several simulations carried out with the hexapod robot are reported to prove the efficacy of this method. This method simplifies the hardware of the robot, reduces design, construction and maintenance costs while enhancing the robustness of the robot and the reliability of its behavior.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27538-9_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27544-0_7,Learning Skills for Small Size League RoboCup,RoboCup 2018: Robot World Cup XXII,10.1007/978-3-030-27544-0_7,Springer,2019-01-01,"In this work, we show how modern deep reinforcement learning (RL) techniques can be incorporated into an existing Skills, Tactics, and Plays (STP) architecture. STP divides the robot behavior into a hand-coded hierarchy of plays, which coordinate multiple robots, tactics, which encode high level behavior of individual robots, and skills, which encode low-level control of pieces of a tactic. The CMDragons successfully used an STP architecture to win the 2015 RoboCup competition. The skills in their code were a combination of classical robotics algorithms and human designed policies. In this work, we use modern deep RL, specifically the Deep Deterministic Policy Gradient (DDPG) algorithm, to learn skills. We compare learned skills to existing skills in the CMDragons’ architecture using a physically realistic simulator. We then show how RL can be leveraged to learn simple skills that can be combined by humans into high level tactics that allow an agent to navigate to a ball, aim and shoot on a goal.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27544-0_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-26766-7_15,Full-Order Sliding Mode Control Algorithm for Robot Manipulators Using an Adaptive Radial Basis Function Neural Network,Intelligent Computing Methodologies,10.1007/978-3-030-26766-7_15,Springer,2019-01-01,"In this paper, a full-order sliding mode tracking control system is developed for industrial robots. First, to dismiss the effects of perturbations and uncertainties, while to improve faster response time and to eliminate the singularity, a full-order sliding function is selected. Next, to reach the prescribed tracking path and to remove the chattering, a control method is designed for robot manipulators by using a combination of full-order sliding function and a continuous adaptive control term. Additionally, the unknown dynamic model of the robot is estimated by adopting a radial basis function neural network. Due to the combination of these methodologies, the proposed controller can run free of exact robot dynamics. The suggested controller provides strong properties of high tracking accuracy and quick response with minimum tracking errors. In simulation analysis, the simulated performances verify high effectiveness of the proposed controller in trajectory tracking control of a 3-DOF robot manipulator.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-26766-7_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-24741-6_20,Design of a Canine Inspired Quadruped Robot as a Platform for Synthetic Neural Network Control,Biomimetic and Biohybrid Systems,10.1007/978-3-030-24741-6_20,Springer,2019-01-01,"Legged locomotion is a feat ubiquitous throughout the animal kingdom, but modern robots still fall far short of similar achievements. This paper presents the design of a canine-inspired quadruped robot named DoggyDeux as a platform for synthetic neural network (SNN) research that may be one avenue for robots to attain animal-like agility and adaptability. DoggyDeux features a fully 3D printed frame, 24 braided pneumatic actuators (BPAs) that drive four 3-DOF limbs in antagonistic extensor-flexor pairs, and an electrical system that allows it to respond to commands from a SNN comprised of central pattern generators (CPGs). Compared to the previous version of this robot, DoggyDeux eliminates out-of-plane bending moments on the legs, has biologically realistic joint range of motion for walking, and eliminates buckling of the BPAs by utilizing a biologically inspired muscle attachment approach. A simple SNN comprised of a single isolated CPG for each joint is used to control the front left leg on DoggyDeux and joint angle data from this leg is collected to verify that the robot responds correctly to inputs from its SNN. Future design work on DoggyDeux will involve further improving the muscle attachment mechanism, while future SNN research will include expanding the robot’s SNN to achieve coordinated locomotion with all four legs utilizing sensory feedback.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-24741-6_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-22577-3_26,Inferring Human Feelings and Desires for Human-Robot Trust Promotion,"Cross-Cultural Design. Methods, Tools and User Experience",10.1007/978-3-030-22577-3_26,Springer,2019-01-01,"Trust is a key component in developing successful interpersonal relationships. In this paper, we posit that the same is true for Human-Robot Interaction (HRI), since human trust toward robots can facilitate HRI in terms of comfort and usability. We investigated the ability of a socially assistive robot to promote trust in the social relationship with its user by inducing self-disclosure of the user’s negative experiences and offering coping mechanisms to deal with these. To achieve this purpose, our system is equipped with deep learning techniques to detect the user’s negative facial expressions, which in turn can be used as cues for the robot to proactively induce self-disclosure. Once triggered, using a conversational model, the robot engages the user to determine the cause of their negative mood. Then, it infers the user’s internal feelings by applying Markov Chain Monte Carlo (MCMC) inference over a Bayesian Network on the user’s utterance. Combining the information gathered from the concept inferencing process and the self-disclosure content, the system is able to estimate a set of desires from the Bayesian Network. Experiments show that our proposed work can correctly infer the user’s feelings and desires from their utterances, as well as generate an appropriate response, resulting in the improvement of human’s trust toward the robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-22577-3_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-29743-5_23,Solving the Inverse Kinematics of Robotic Arm Using Autoencoders,Creativity in Intelligent Technologies and Data Science,10.1007/978-3-030-29743-5_23,Springer,2019-01-01,"In the modern era, robotics is an attractive field for many researchers since robots are involved in many aspects of everyday life due to the conveniences and solutions that they provide in various daily difficulties. For this reason, the inverse kinematics of robotic arms is a challenging problem that seems more appealing to researchers as years pass by. In this paper, a novel approach to solve this problem is assessed, which is based on autoencoders. In our implementation the goal is not only to find one random (of the infinite solutions) of this problem, but to determine the one that minimizes both the position error between the actual and desired position of the end-effector of the robotic arm and the joint movement. For the training of the Neural Network of the autoencoder, four different types of the loss function and their corresponding results are examined. A robotic arm with three Degrees of Freedom is used for the evaluation of our implementation and the accurate results demonstrate the efficiency and effectiveness of our proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-29743-5_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-01370-7_70,Triggering Robot Hand Reflexes with Human EMG Data Using Spiking Neurons,Intelligent Autonomous Systems 15,10.1007/978-3-030-01370-7_70,Springer,2019-01-01,"The interaction of humans and robots (HRI) is of great relevance for the field of neurorobotics as it can provide insights on motor control and sensor processing mechanisms in humans that can be applied to robotics. We propose a spiking neural network (SNN) to trigger motion reflexes on a robotic hand based on human EMG data. The first part of the network takes EMG signals to measure muscle activity, then classify the data to detect which finger is active in the human hand. The second part triggers single finger reflexes using the classification output. The finger reflexes are modeled with motion primitives activated with an oscillator and mapped to the robot kinematic. We evaluated the SNN by having users wear a non-invasive EMG sensor, record a training dataset, and then flex different fingers, one at a time. The muscle activity was recorded using a Myo sensor with eight channels. EMG signals were successfully encoded into spikes as input for the SNN. The classification could detect the active finger to trigger motion generation of finger reflexes. The SNN was able to control a real Schunk SVH robotic hand. Being able to map myo-electric activity to functions of motor control for a task, can provide an interesting interface for robotic applications, and also to study brain functioning. SNN provide a challenging but interesting framework to interact with human data. In future work the approach will be extended to control a robot arm at the same time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-01370-7_70,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27544-0_19,RoboCupSimData: Software and Data for Machine Learning from RoboCup Simulation League,RoboCup 2018: Robot World Cup XXII,10.1007/978-3-030-27544-0_19,Springer,2019-01-01,"The main goal of this work is to facilitate machine learning research for multi-robot systems as they occur in RoboCup, an international scientific robot competition. We describe our software (a simulator patch and scripts) and a larger research dataset from games of some of the top teams from 2016 and 2017 in Soccer Simulation League (2D), where teams of 11 agents compete against each other, recorded by this software. We used 10 different teams to play each other, resulting in 45 unique pairings. For each pairing, we ran 25 matches, leading to 1125 matches or more than 180 h of game play. The generated CSV files are 17 GB of data (zipped), or 229 GB (unzipped). The dataset is unique in the sense that it contains local, incomplete and noisy percepts (as sent to each player), in addition to the ground truth logfile that the simulator creates (global, complete, noise-free information of all objects on the field). These data are made available as CSV files, as well as in the original soccer simulator formats.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27544-0_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-24741-6_42,Learning in Growing Robots: Knowledge Transfer from Tadpole to Frog Robot,Biomimetic and Biohybrid Systems,10.1007/978-3-030-24741-6_42,Springer,2019-01-01,"Inspired by natural growing processes, we investigate how morphological changes can potentially help to lead and facilitate the task of learning to control a robot. We use the model of a tadpole that grows in four discrete stages into a frog. The control task to learn is to locomote to food positions that occur at random positions. We employ reinforcement learning, which is able to find a tail-driven swimming strategy for the tadpole stage that transitions into a leg-driven strategy for the frog. Furthermore, by using knowledge transferred from one growing stage to the next one, we were able to show that growing can benefit from guiding the controller optimization through morphological changes. The results suggest that learning time can be reduced compared to the cases when learning each stage individually from scratch.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-24741-6_42,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-01057-7_85,Application of Deep Reinforcement Learning to UAV Fleet Control,Intelligent Systems and Applications,10.1007/978-3-030-01057-7_85,Springer,2019-01-01,"The increasing presence of robots and unmanned systems as a result of technological breakthroughs and falling costs has increased the demand for robust and scalable multi-agent control systems. We developed a multi-UAV fleet control system based on recent findings in the deep reinforcement learning literature. A deep convolutional neural network with a linear output layer is chosen as control policy, due to its wide spread applicability, and is trained, in simulation, for two tasks: aerial surveillance and base defense, with five UAVs. The generalization power of the architecture with respect to different fleet sizes was evaluated. For both tasks, at test time, we varied the number of UAVs from one to ten and we found that for all settings the policy was able to accomplish both tasks robustly. We deployed the control policy on a fleet of five DJI Mavic Pro drones and found that it performed well.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-01057-7_85,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-99885-5_6,Adaptation of the Difficulty Level in an Infant-Robot Movement Contingency Study,Advances in Physical Agents,10.1007/978-3-319-99885-5_6,Springer,2019-01-01,"This paper presents a personalized contingency feedback adaptation system that aims to encourage infants aged 6 to 8 months to gradually increase the peak acceleration of their leg movements. The ultimate challenge is to determine if a socially assistive humanoid robot can guide infant learning using contingent rewards, where the reward threshold is personalized for each infant using a reinforcement learning algorithm. The model learned from the data captured by wearable inertial sensors measuring infant leg movement accelerations in an earlier study. Each infant generated a unique model that determined the behavior of the robot. The presented results were obtained from the distributions of the participants’ acceleration peaks and demonstrate that the resulting model is sensitive to the degree of differentiation among the participants; each participant (infant) should have his/her own learned policy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-99885-5_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-16184-2_47,Nonlinear Identification of a Robotic Arm Using Machine Learning Techniques,New Knowledge in Information Systems and Technologies,10.1007/978-3-030-16184-2_47,Springer,2019-01-01,"With the advancement of intelligent algorithms more and more robots perform human tasks, be they due to dangerousness or simply by reducing human costs, for that to happen requires precision. This work has the objective of making an identification of a robotic arm with three phase induction motor through machine learning techniques to obtain a better model that represents the plant. The techniques used were Artificial Neural Network (ANNs): MLP, RBF and MLP + PSO. The techniques obtained a good performance, and they were evaluated through the multi-correlation coefficient (R^2) for a comparative analysis.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-16184-2_47,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-22649-7_26,Estimating Timing of Head Movements Based on the Volume and Pitch of Speech,Human Interface and the Management of Information. Information in Intelligent Systems,10.1007/978-3-030-22649-7_26,Springer,2019-01-01,"Our research aims to create two friendly communication robots to talk with elderly people in nursing facilities. If the robots synchronize their head movements in response to the elderly person, the elderly person may react favorably to the robot. Then, the elderly person can enjoy talking with these two robots. In this paper, we investigated whether the volume and pitch of the speech are useful data for estimating the timing of head movements. Because the robots need to move their heads in real time, when one of the robots or the person is talking, we focus on the volume and pitch of the speech, not the content. Moreover, it was cleared which machine learning method creates suitable classifier models for estimating the timing of head movements. The experimental results showed that Random Forest classifier was the most suitable method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-22649-7_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-22338-0_26,Humanoid Robots as Interviewers for Automated Credibility Assessment,"HCI in Business, Government and Organizations. Information Systems and Analytics",10.1007/978-3-030-22338-0_26,Springer,2019-01-01,"Humans are poor at detecting deception under the best conditions. The need for having a decision support system that can be a baseline for data-driven decision making is obvious. Such a system is not biased like humans are, and these often subconscious human biases can impair people’s judgment. A system for helping people at border security (CBP) is the AVATAR. The AVATAR, an Embodied Conversational agent (ECA), is implemented as a self-service kiosk. Our research uses this AVATAR as the baseline and we plan to augment the automated credibility assessment task that the AVATAR performs using a Humanoid robot. We will be taking advantage of humanoid robots’ capability of realistic dialogue and nonverbal gesturing. We are also capturing data from various sensors like microphones, cameras and an eye tracker that will help in model building and testing for the task of deception detection. We plan to carry out an experiment where we compare the results of an interview with the AVATAR and an interview with a humanoid robot. Such a comparative analysis has never been done before, hence we are very eager to conduct such a social experiment. This research paper deals with the design and implementation plan for such an experiment. We also want to highlight what the considerations are while designing such a social experiment. It will help us understand how people perceive robot agent interactions in contrast to the more traditional ECA agents on screen. For example, does the physical presence of a robot encourage greater perceptions of likability, expertise, or dominance? Moreover, this research will address the question on which interaction model (ECA or robot) elicits the most diagnostic cues to detecting deception. This study may also prove very useful to researchers and organizations that want to use robots in increasing social roles and need to understand its societal and personal implications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-22338-0_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-19734-6_10,Intimate Relationships with Humanoid Robots: Exploring Human Sexuality in the Twenty-First Century,AI Love You,10.1007/978-3-030-19734-6_10,Springer,2019-01-01,"Sex robots are humanoid robots with artificial intelligence, designed to interact sexually with humans. They have received much attention in recent discussions about technology, human relationships and the future of human sexuality. Based on available evidence so far, this outlook aims to give tentative answers to two fundamental questions surrounding the topic of human–robot intimate relationships. First, whether intelligent humanoid robots are technologically ready to be our intimate partners. Second, whether humans are ready to accept the idea of developing intimate relationships with robots, and how far we have engaged and will engage in such activity. We highlight the importance of a scientific transdisciplinary approach to the study of human sexuality in the twenty-first century.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-19734-6_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-78452-6_10,Intelligent Smart Glass for Visually Impaired Using Deep Learning Machine Vision Techniques and Robot Operating System (ROS),Robot Intelligence Technology and Applications 5,10.1007/978-3-319-78452-6_10,Springer,2019-01-01,"The Smart Glass represents potential aid for people who are visually impaired that might lead to improvements in the quality of life. The smart glass is for the people who need to navigate independently and feel socially convenient and secure while they do so. It is based on the simple idea that blind people do not want to stand out while using tools for help. This paper focuses on the significant work done in the field of wearable electronics and the features which comes as add-ons. The Smart glass consists of ultrasonic sensors to detect the object ahead in real-time and feeds the Raspberry for analysis of the object whether it is an obstacle or a person. It can also assist the person on whether the object is closing in very fast and if so, provides a warning through vibrations in the recognized direction. It has an added feature of GSM, which can assist the person to make a call during an emergency situation. The software framework management of the whole system is controlled using Robot Operating System (ROS). It is developed using ROS catkin workspace with necessary packages and nodes. The ROS was loaded on to Raspberry Pi with Ubuntu Mate.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-78452-6_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-99885-5_11,Person Following Robot Behavior Using Deep Learning,Advances in Physical Agents,10.1007/978-3-319-99885-5_11,Springer,2019-01-01,"Human-robot interaction (HRI) is a field with growing impact as robot applications are entering into homes, supermarkets and general human environments. Person following is an interesting capability in HRI. This paper presents a new system for a robust person following behavior inside a robot. Its perception module addresses the person detection on images using a pretrained TensorFlow SSD Convolutional Neural Network which provides robustness even on tough lighting conditions. It also includes a face detector and a FaceNet CNN to reidentify the target person. Care has been put to allow real-time operation. The control module implements two PID controllers for a reactive smooth response, moving the robot towards the target person without distracting with other people around. The entire system has been experimentally validated on a real TurtleBot2 robot, with an Asus Xtion RGBD camera.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-99885-5_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-20131-9_240,Adaptive cognitive robot using dynamic perception with fast deep-learning and adaptive on-line predictive control,Advances in Mechanism and Machine Science,10.1007/978-3-030-20131-9_240,Springer,2019-01-01,"This paper presents a novel adaptive cognitive robot control architecture able to adapt the robot actions and motions to the dynamics of both environment and human involving an “ expressive states ” in a cognitive model that adapts directly the robot optimal control. We developed an integrated system that performs dynamic perception with fast deep-learning algorithms, cognition models based on affects, and adaptive generalized predictive controllers (AGPC). The adaptation works with the perceptive states, which is transformed in cognitive data to use as the main requirement in the control design. The perception level detects and tracks to react to the environment in order to create personalized actions. The cognition is created using PAD model which defines different robot states related with the robot actions/tasks, it is created by KNN algorithm. The adaptation is commanded by an AGPC that is changed according to the cognitive states. The AGPC cost functions are calculated with the PAD values. Results showed the ability to perform robot tasks with expressive and personalized behaviours continuously.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-20131-9_240,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-99885-5_1,Semantic Localization of a Robot in a Real Home,Advances in Physical Agents,10.1007/978-3-319-99885-5_1,Springer,2019-01-01,"In social robotics, it is important that a mobile robot knows where it is because it provides a starting point for other activities such as moving from one room to another. As a contribution to solving this problem in the field of the semantic location of the mobile robot, we pro- pose to implement a methodology of recognition and scene learning in a real domestic environment. For this purpose, we used images from five different residences to create a dataset with which the base model was trained. The effectiveness of the implemented base model is evaluated in different scenarios. When the accuracy of the site identification decreases, the user provides feedback to the robot so that it can process the information collected from the new environment and re-identify the current location. The results obtained reinforce the need to acquire more knowledge when the environment is not recognizable by the pre-trained model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-99885-5_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27202-9_23,Vision-Based Target Objects Recognition and Segmentation for Unmanned Systems Task Allocation,Image Analysis and Recognition,10.1007/978-3-030-27202-9_23,Springer,2019-01-01,"This paper investigates the potential of deep learning methods to detect and segment objects from vision sensors mounted on autonomous robots to support task allocation in unmanned systems. An object instance segmentation framework, Mask R-CNN, is experimentally evaluated and compared with previous architecture, Faster R-CNN. The former model adds an object mask prediction branch in parallel with the existing branches for target objects location and class recognition, which represents a significant benefit for autonomous robots navigation. A comparison of performance between the two architectures is carried over scenes of varying complexity. While both networks perform well on recognition and bounding box estimation, experimental results show that Mask R-CNN generally outperforms Faster R-CNN, particularly because of the accurate mask prediction generated by this network. These results support well the requirements imposed by an automated task allocation mechanism for a group of unmanned vehicles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27202-9_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-78452-6_1,Artificial Intelligence Approach to the Trajectory Generation and Dynamics of a Soft Robotic Swallowing Simulator,Robot Intelligence Technology and Applications 5,10.1007/978-3-319-78452-6_1,Springer,2019-01-01,"Soft robotics is an area where the robots are designed by using soft and compliant modules which provide them with infinite degrees of freedom. The intrinsic movements and deformation of such robots are complex, continuous and highly compliant because of which the current modelling techniques are unable to predict and capture their dynamics. This paper describes a machine learning based actuation and system identification technique to discover the governing dynamics of a soft bodied swallowing robot. A neural based generator designed by using Matsuoka’s oscillator has been implemented to actuate the robot so that it can deliver its maximum potential. The parameters of the oscillator were found by defining and optimising a quadratic objective function. By using optical motion tracking, time-series data was captured and stored. Further, the data were processed and utilised to model the dynamics of the robot by assuming that few significant non-linearities are governing it. It has also been shown that the method can generalise the surface deformation of the time-varying actuation of the robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-78452-6_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-19913-5_1,Beyond Coding: Back to the Future with Education Robots,Smart Learning with Educational Robotics,10.1007/978-3-030-19913-5_1,Springer,2019-01-01,"Jeannette Wing’s 2013 call for education to make coding a key skill coincided with a boom in new education robots. Not surprisingly most of these new robots focus on developing student’s computational thinking abilities and programming know-how. Is that all robots can offer? To find the answer I’ll explore the history of education robots: specifically the ideas of Seymour Papert. What we’ll find is something with far more potential than providing learners with a way of developing their coding skills. And against accepted wisdom, I’ll suggest that as technology develops the need for coders will (in the long term) dwindle but the power of robots to help educate children for the future will increase.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-19913-5_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1631/FITEE.1800587,Autonomous flying blimp interaction with human in an indoor space,Frontiers of Information Technology & Electronic Engineering,10.1631/FITEE.1800587,Springer,2019-01-01,"We present the Georgia Tech Miniature Autonomous Blimp (GT-MAB), which is designed to support human-robot interaction experiments in an indoor space for up to two hours. GT-MAB is safe while flying in close proximity to humans. It is able to detect the face of a human subject, follow the human, and recognize hand gestures. GT-MAB employs a deep neural network based on the single shot multibox detector to jointly detect a human user’s face and hands in a real-time video stream collected by the onboard camera. A human-robot interaction procedure is designed and tested with various human users. The learning algorithms recognize two hand waving gestures. The human user does not need to wear any additional tracking device when interacting with the flying blimp. Vision-based feedback controllers are designed to control the blimp to follow the human and fly in one of two distinguishable patterns in response to each of the two hand gestures. The blimp communicates its intentions to the human user by displaying visual symbols. The collected experimental data show that the visual feedback from the blimp in reaction to the human user significantly improves the interactive experience between blimp and human. The demonstrated success of this procedure indicates that GT-MAB could serve as a flying robot that is able to collect human data safely in an indoor environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1631/FITEE.1800587,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27526-6_48,Deep Learning Based Gesture Recognition and Its Application in Interactive Control of Intelligent Wheelchair,Intelligent Robotics and Applications,10.1007/978-3-030-27526-6_48,Springer,2019-01-01,"With the development of robotics technology, new human-robot interaction technology has gradually received more and more attention. Bioelectric-based gesture recognition, which is to be studied in this article, has become a frontier subject of new human-robot interaction because of its natural and intuitive information representation function and it is not restricted from complex background conditions. A deep neural network model based on the Alexnet-based network structure is used for gesture recognition based on sEMG (surface electromyography) and inertial information. The data is collected by the sliding window method, the recognition thread loads the trained model and performs online recognition in real time. Moreover, in order to improve the robustness of the algorithm to the input data, a verification model based on the twin neural network is used to verify whether the input data belongs to the identification type. And the human-robot interaction method proposed is verified on the omnidirectional intelligent wheelchair, and the obvious control effect is obtained.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27526-6_48,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-01370-7_48,Deep Learning Waterline Detection for Low-Cost Autonomous Boats,Intelligent Autonomous Systems 15,10.1007/978-3-030-01370-7_48,Springer,2019-01-01,"Waterline detection in images captured from a moving camera mounted on an autonomous boat is a complex task, due the presence of reflections, illumination changes, camera jitter, and waves. The pose of the boat and the presence of obstacles in front of it can be inferred by extracting the waterline. In this work, we present a supervised method for waterline detection, which can be used for low-cost autonomous boats. The method is based on a Fully Convolutional Neural Network for obtaining a pixel-wise image segmentation. Experiments have been carried out on a publicly available data set of images and videos, containing data coming from a challenging scenario where multiple floating obstacles are present (buoys, sailing and motor boats). Quantitative results show the effectiveness of the proposed approach, with 0.97 accuracy at a speed of 9 fps.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-01370-7_48,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-017-0068-4,An ANFIS-based Optimized Fuzzy-multilayer Decision Approach for a Mobile Robotic System in Ever-changing Environment,"International Journal of Control, Automation and Systems",10.1007/s12555-017-0068-4,Springer,2019-01-01,"In robotics, resolution of several difficult issues requires process intelligence. In many applications, the environment of a robot changes with time in a manner that has not been foreseen by its designer. Additionally, information on the environment is commonly inaccurate and incomplete, which is attributed to the restricted sensory activity of sensors. A new online sensor-based motion planning algorithm, which employs a fuzzy multilayer decision controller, is proposed in this study to enhance the quality of the next position in terms of safety and optimality. Fuzzy logic controller (FLC) utilizes the prediction and priority rules of multilayer approach for an effective and intelligent proposed method. Moreover, an adaptive neuro-fuzzy inference system (ANFIS) is designed, which constructs and optimizes an FLC using a given dataset of input/output variables. The ANFIS shortens the high runtime of fuzzy system, optimizes the parameters of the membership functions of inputs and outputs of the fuzzy-multilayer decision controller, and rearranges the rules to enhance the efficiency of the overall approach. The simulation and comparison results indicate the superiority of the proposed path planning algorithm from other well-known algorithms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-017-0068-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-13-7983-3_39,AI in Locomotion: Quadruped Bionic Mobile Robot,Cognitive Systems and Signal Processing,10.1007/978-981-13-7983-3_39,Springer,2019-01-01,"The report begins with the requirements of quadruped robots and discusses the advantages of quadruped robots in overcoming unstructured problems. Secondly, from the main domestic and foreign research on quadruped robot, the technical status of quadruped robot is expounded; thirdly, the development process and key technologies of “Running” quadruped robot are reported; finally, the trend of 4S performance which quadruped robot urgently needs to improve is discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-7983-3_39,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-10898-4_2,Asking Today the Crucial Questions of Tomorrow: Social Robots and the Internet of Toys,The Internet of Toys,10.1007/978-3-030-10898-4_2,Springer,2019-01-01,"Social robots and the Internet of Toys represent key technologies in children’s future lives. Based on Winfield (Robotics: A Very Short Introduction. Oxford University Press, Oxford, 2012), we conceptualize the relationship between social robots and smart/connected toys with six characteristics: interactivity, energy, sensors, software control, movement and embodiment. These characteristics, in turn, help to classify social robots and smart/connected toys along three dimensions (i.e. horizontal, vertical and spatial integration), which suggests that the difference between social robots and smart/connected is rather subtle. We identify three common theoretical (absence or heterogeneity of theory, lacking developmental perspective, insufficient attention to intercultural differences) and three methodological issues (lack of standardized measures, study design issues, dominance of cross-sectional studies) that research on both social robots and the Internet of Toys needs to address.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-10898-4_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-35888-4_32,Playing Rock-Paper-Scissors with RASA: A Case Study on Intention Prediction in Human-Robot Interactive Games,Social Robotics,10.1007/978-3-030-35888-4_32,Springer,2019-01-01,"Interaction quality improvement in a social robotic platform can be achieved through intention detection/prediction of the user. In this research, we tried to study the effect of intention prediction during a human-robot game scenario. We used our humanoid robotic platform, RASA. Rock-Paper-Scissors was chosen as our game scenario. In the first step, a Leap Motion sensor and a Multilayer Perceptron Neural Network is used to detect the hand gesture of the human-player. On the next level, in order to study the intention prediction’s effect on our human-robot gaming platform, we implemented two different playing strategies for RASA. One of the strategies was to play randomly, while the other one used Markov Chain model, to predict the next move. Then 32 players with the ages between 20 to 35 were asked to play Rock-Paper-Scissors with RASA for 20 rounds in each strategy mode. Participants did not know about the difference in the robot’s decision-making strategy in each mode and the intelligence of each strategy modes as well as the Acceptance/Attractiveness of the robotic gaming platform were assessed quantitatively through a questionnaire. Finally, paired T-tests indicated a significant difference between the random playing strategy and the other strategy predicting players’ intention during the game.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-35888-4_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-13-0923-6_22,Machine Learning for Beach Litter Detection,Machine Intelligence and Signal Analysis,10.1007/978-981-13-0923-6_22,Springer,2019-01-01,"People from economically weaker sections find consolation in doing unskilled tasks which are easily available, though a few of them are certainly not for humans. They have to be replaced with robots since these jobs fall into the categories of dull, dirty, difficult, and dangerous jobs. Exclusion of human involvement in the demeaning tasks and provision of hygienic environments around the beach areas would contribute to a better opportunity for a country’s tourism. The task of implementation of beach cleaning with robots throws many technical challenges, a few of which are addressed in this research work. Machine learning has influenced the progress and outcomes for various domains of engineering and science including statistics. Even in social domains the impact of advent of Machine learning has been felt by not just the end users, but also the researchers. In this work, different methods for classifications of beach litter are proposed and evaluated. A dataset is collected and the classifiers are evaluated based on various metrics. An appropriate classifier is then selected based on these metrics, and the system is used on a beach cleaning robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-0923-6_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-99316-4_36,An Approach to Hierarchical Deep Reinforcement Learning for a Decentralized Walking Control Architecture,Biologically Inspired Cognitive Architectures 2018,10.1007/978-3-319-99316-4_36,Springer,2019-01-01,"Locomotion in animals is characterized as a stable, rhythmic behavior which at the same time is flexible and extremely adaptive. Many motor control approaches have taken considerable steps taking insights from biology. As one example, the Walknet approach for six-legged robots realizes a decentralized and modular structure that reflects insights from walking in stick insects. While this approach can deal with a variety of disturbances during locomotion, it is still limited dealing with novel and particular challenging walking situations. This has lead to a cognitive expansion that allows to test behaviors outside their original context and search for a solution in a form of internal simulation. What is still missing in this approach is the variation of lower level motor primitives themselves to cope with difficult situation and any form of learning. Here, we propose how this biologically-inspired approach can be extended in order to include a form of trial-and-error learning. The realization is currently underway and is based on a more broad formulation as a hierarchical reinforcement learning problem. Importantly, the structure of the hierarchy follows the decentralized organization taken from insects.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-99316-4_36,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-29022-1_20,"Astrovirology, Astrobiology, Artificial Intelligence: Extra-Solar System Investigations",Global Virology III: Virology in the 21st Century,10.1007/978-3-030-29022-1_20,Springer,2019-01-01,"This chapter attempts to encompass and tackle a large problem in Astrovirology and Astrobiology. There is a huge anthropomorphic prejudice that although life is unlikely, the just-right Goldilocks terrestrial conditions mean that the just-right balance of minerals and basic small molecules inevitably result in life as we know it throughout our solar system, galaxy, and the rest of the universe. Moreover, when such conditions on planets such as ours may not be quite right for the origin of life, it is popularly opined that asteroids and comets magically produce life or at the very least, the important, if not crucial components of terrestrial life so that life then blooms, when their fragments cruise the solar system, stars, and galaxies, and plummet onto appropriately bedecked planets and moons. It is no longer extraordinary to detect extraterrestrial solar systems. Moreover, since extra-solar system space exploration has commenced, this provides the problem of detecting life with enhanced achievability. Small organisms, which replicate outside of a living cell or host, would not be catalogued as viruses. How about viruses that cohabit with life? On the Earth, viruses are a major, if underestimated, condition of life – will that be the case elsewhere? Detection of extra-solar system viruses, if they exist, requires finding life, since viruses necessitate life to replicate. (It should be noted, though, that viruses could be detected through various types of portable ultra-microscopes, including Electron Microscopes (EM) (scanning and transmission) as well as Atomic Force Microscopes (AFM) Atomic Force Microscopes (AFM) .) However, extra-solar system detection of life does not oblige that viruses exist ubiquitously. Viruses are important potential components of biospheres because of their multiple interactions and influence on evolution, although viruses are small and obligatory parasitic. In addition, nanotechnology – living or replicating nano-synthetic machine organisms might also be present out there, and require consideration as well. An imposing caveat is that, if found, could some extraterrestrial viruses and synthetic nanotechnological microorganisms infect humans? Possibly, intelligence and cognition may at times be contemporaneous with life. Concomitantly, life and viruses that may be detected, could well be impacted upon by intelligences existing on such exoplanets (and vice versa ). Coming to an understanding of the plurality of extraterrestrial intelligence is an optimal objective, in order to avoid causing harm on exoplanets, as well as avoiding conflict and possible human devastation. This is especially the case if we encounter greatly advanced galactic-level civilizations, compared to terrestrial civilizations. Their machine and bionic technologies on the Dyson engineering civilization scale may be prominently superior to ours; their biological expertise may be similarly critically radical. For example, they may use viruses for purposes for which we are barely aware, and which could be utterly deadly for humans. A series of steps is being taken in space exploration. Scientists hypothesize and claim that types of life may be near the Earth, in the solar system, and outside the solar system, similar to ours in the sense that only such conditions, Goldilocks conditions, are key sine qua non requirements, based on our terrestrial chemistry and biochemistry. If detected within the solar system, will life or its remnants resemble terrestrial life? Outside the solar system a similar chauvinism exists, although the likelihood for life, in any event, remains probably low, according to more cautious approaches to the problem. The study of our solar system includes planets, asteroids, comets, and other planetesimals that have been in overall contiguity during several billion years; anthropomorphisms claims life consequently has been developing along terrestrial-type mechanisms. However, a non-anthropomorphic view would surmise, probably not, especially for extra-solar system locales. The prime warning and admonition in all these deliberations is the contamination and damage, which current and past practice and procedures has caused and continues, due to insufficient biocontainment concepts and technology to date. Advances in the development of robotics, artificial intelligence (AI), and high capacity ultrafast quantum computers (QC) greatly enhance the sophisticated control and logical development of extra-solar system studies. Consequently, future long-range manned space exploration seems unwarranted. Clearly, reduced dangers to human health and safety, will result from the use of intelligent machine-based investigations and besides, with increased cost-effectiveness. Space exploration comes at great cost to humanity as a whole and utilizes global resources. Consequently, appropriate organizational measures and planning/cooperation need to be in place. Moreover, the bottom line is that despite all the slogans and claims, there have been next to no financial benefits to our planet as a whole. Such financial and heedless difficulties need to be addressed, the sooner the better. In addition, prior to exposure to exoplanetary life, deep understanding of the problems of infectious diseases and immune dysfunction risks are needed. In addition, global efforts should avoid serendipity and stochasticity as this work should be directed with long-term organization, commitment, scientific, and technological methodology. This chapter briefly reviews such questions assuming a new paradigm for oversight of extrasolar system viral investigations including intelligence and life. Finances are included as an essential adjunct.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-29022-1_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-34255-5_21,A Flexible and Scalable Architecture for Human-Robot Interaction,Ambient Intelligence,10.1007/978-3-030-34255-5_21,Springer,2019-01-01,"Recent developments and advancements in several areas of Computer Science such as Semantic Web, Natural Language Understanding, Knowledge Representation, and more in general Artificial Intelligence have enabled to develop automatic and smart systems able to address various challenges and tasks. In this paper, we present a scalable and flexible humanoid robot architecture which employs artificial intelligent technologies and developed on top of the programmable humanoid robot called Zora. The framework is composed by three different modules which enable the interaction between Zora and a human for tasks such as Sentiment Understanding, Question-Answering, and automatic Object Recognition. The framework is flexible and extensible, and can be augmented by other modules. Moreover, the embedded modules we present are general, in the sense that they can be easily enriched by adding training resources for the presented sub-components. The design of each module consists of two components (i) a front-end system which is responsible for the interaction with humans, and (ii) a back-end component which resides on server side and performs the heavy computation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-34255-5_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-29911-8_35,Deep Global-Relative Networks for End-to-End 6-DoF Visual Localization and Odometry,PRICAI 2019: Trends in Artificial Intelligence,10.1007/978-3-030-29911-8_35,Springer,2019-01-01,"Although a wide variety of deep neural networks for robust Visual Odometry (VO) can be found in the literature, they are still unable to solve the drift problem in long-term robot navigation. Thus, this paper aims to propose novel deep end-to-end networks for long-term 6-DoF VO task. It mainly fuses relative and global networks based on Recurrent Convolutional Neural Networks (RCNNs) to improve the monocular localization accuracy. Indeed, the relative sub-networks are implemented to smooth the VO trajectory, while global sub-networks are designed to avoid drift problem. All the parameters are jointly optimized using Cross Transformation Constraints (CTC), which represents temporal geometric consistency of the consecutive frames, and Mean Square Error (MSE) between the predicted pose and ground truth. The experimental results on both indoor and outdoor datasets show that our method outperforms other state-of-the-art learning-based VO methods in terms of pose accuracy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-29911-8_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-29891-3_31,A Challenging Voice Dataset for Robotic Applications in Noisy Environments,Computer Analysis of Images and Patterns,10.1007/978-3-030-29891-3_31,Springer,2019-01-01,"Artificial Intelligence plays a fundamental role in the speech-based interaction between humans and machines in cognitive robotic systems. This is particularly true when dealing with very crowded environments, such as museums or fairs, where cognitive systems could be profitably used. The existing datasets “in the wild” are not sufficiently representative for this purposes, thus there is a growing need to make publicly available a more complex dataset for speaker recognition in extremely noisy conditions. In this paper, we propose the Speaker Recognition dataset in the Wild (SpReW), a novel and more challenging Italian audio database for speaker recognition tasks. Moreover, we report a quantitative evaluation of a novel CNN architecture for Speaker Identification tasks called SincNet, on the proposed dataset. SincNet has been chosen as a baseline architecture since it has obtained impressive results on widely used controlled datasets. Experimental results demonstrate the difficulties when dealing with very noisy test sets and few clearly acquired samples for training.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-29891-3_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27544-0_29,Deep Learning for Semantic Segmentation on Minimal Hardware,RoboCup 2018: Robot World Cup XXII,10.1007/978-3-030-27544-0_29,Springer,2019-01-01,"Deep learning has revolutionised many fields, but it is still challenging to transfer its success to small mobile robots with minimal hardware. Specifically, some work has been done to this effect in the RoboCup humanoid football domain, but results that are performant and efficient and still generally applicable outside of this domain are lacking. We propose an approach conceptually different from those taken previously. It is based on semantic segmentation and does achieve these desired properties. In detail, it is being able to process full VGA images in real-time on a low-power mobile processor. It can further handle multiple image dimensions without retraining, it does not require specific domain knowledge to achieve a high frame rate and it is applicable on a minimal mobile hardware.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27544-0_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27529-7_1,Research on Optimization of Control Parameters of Coal Sampling Robot Based on Model and Neural Network Algorithm,Intelligent Robotics and Applications,10.1007/978-3-030-27529-7_1,Springer,2019-01-01,"This paper takes the single joint (big arm joint) servo control system of coal sampling robot as the research object, analyzes the structure of servo control system, establishes the model of single joint servo control system to study the method of tuning and optimizing the control parameters of the servo system. The combination of model-based control parameter tuning and improved BP neural network control parameter optimization is adopted to improve the system’s ability to adapt to the load and improve the performance of system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27529-7_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-36802-9_38,LoRa Indoor Localization Based on Improved Neural Network for Firefighting Robot,Neural Information Processing,10.1007/978-3-030-36802-9_38,Springer,2019-01-01,"Trapped occupants’ safety is a critical problem in the fireground and a major issue is the lack of reliable indoor localization decision-making system for firefighting. State of the art methods have failed to provide an automatic, accurate and reliable solution that can facilitate the decision-making of incident commanders. This paper aims to develop a novel smart firefighting robot to achieve this goal, by combining artificial neural network with received signal strength indication of the new wireless communication approach named Long Range (LoRa). Our solution includes a new indoor localization algorithm that contains a process for optimizing the initial weights and thresholds of BP neural networks. The solution can improve the location accuracy of trapped occupants in fire. We fully implement the algorithm in a complete indoor localization system and conduct experiments in the space of 25 m  $$\times $$  25 m  $$\times $$  5 m that involved a firefighting robot and some trapped occupants. The localization results demonstrate that our solution greatly shortens the convergence time and reduces the average and minimum location error to 0.7 m and 0.2 m respectively in a 20 m  $$\times $$  15 m testing area.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-36802-9_38,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-77252-3_5,"The New CxO Gang: Data, AI, and Robotics",Applied Artificial Intelligence: Where AI Can Be Used In Business,10.1007/978-3-319-77252-3_5,Springer,2019-01-01,"This chapter explains and identifies the emergence of new relevant figures in the data ecosystem space, namely the chief data officer, the chief AI officer, and the chief robotics officer. It will show the differences between them and highlight where they are needed and how they can be used efficiently.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-77252-3_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-13-7986-4_11,RBF Network Imitation Posture Judgment Algorithm Based on Improved PSO,Cognitive Systems and Signal Processing,10.1007/978-981-13-7986-4_11,Springer,2019-01-01,"In this paper, because the robot is easy to fall during the imitation process, a novel Radical Basis Function (RBF) neural network algorithm based on heuristic simulated annealing adaptive particle swarm optimization Particle Swarm Optimization (PSO) algorithm is proposed to judge the mimic posture of the robot. In order to solve the problem of poor convergence speed and low accuracy of traditional RBF neural network, the PSO algorithm is used to optimize it. At the same time, in order to solve the problem that the classical PSO algorithm is easy to fall into the local optimal value, heuristic simulated annealing adaptive PSO algorithm is proposed. Experiment shows that the proposed algorithm has higher convergence speed and accuracy than BP neural network, Support Vector Machines (SVM) and traditional RBF neural network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-7986-4_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-02348-5_5,"Leadership, Growth, and the Future",Effective and Creative Leadership in Diverse Workforces,10.1007/978-3-030-02348-5_5,Springer,2019-01-01,"Taylor, Santiago, Hauer, Hynes, and Mickahail provide a much-needed discussion on ways innovative leaders are preparing for the future. Effective leadership styles, including relevant examples and self-reflective exercises, make up the discussion of building an innovative, diverse organizational culture. Possible future technology challenges and opportunities demonstrate the practice of flexibility and risk taking, with real-life examples of organizations coping with change. A short history of the Industrial Revolutions helps the reader to understand the effect of technology on society as well as businesses when looking toward the future. The discussion of the Fourth Revolution includes Artificial Intelligence, robotics, Machine Learning, and workforce disruption.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-02348-5_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-35699-6_11,Collision Avoidance for Indoor Service Robots Through Multimodal Deep Reinforcement Learning,RoboCup 2019: Robot World Cup XXIII,10.1007/978-3-030-35699-6_11,Springer,2019-01-01,"In this paper, we propose an end-to-end approach to endow indoor service robots with the ability to avoid collisions using Deep Reinforcement Learning (DRL). The proposed method allows a controller to derive continuous velocity commands for an omnidirectional mobile robot using depth images, laser measurements, and odometry based speed estimations. The controller is parameterized by a deep neural network, and trained using DDPG. To improve the limited perceptual range of most indoor robots, a method to exploit range measurements through sensor integration and feature extraction is developed. Additionally, to alleviate the reality gap problem due to training in simulations, a simple processing pipeline for depth images is proposed. As a case study we consider indoor collision avoidance using the Pepper robot. Through simulated testing we show that our approach is able to learn a proficient collision avoidance policy from scratch. Furthermore, we show empirically the generalization capabilities of the trained policy by testing it in challenging real-world environments. Videos showing the behavior of agents trained using the proposed method can be found at https://youtu.be/ypC39m4BlSk .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-35699-6_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-30487-4_53,CPG Driven RBF Network Control with Reinforcement Learning for Gait Optimization of a Dung Beetle-Like Robot,Artificial Neural Networks and Machine Learning – ICANN 2019: Theoretical Neural Computation,10.1007/978-3-030-30487-4_53,Springer,2019-01-01,"In this paper, we employ a central pattern generator (CPG) driven radial basis function network (RBFN) based controller to learn optimized locomotion for a complex dung beetle-like robot using reinforcement learning approach called “Policy Improvement with Path Integrals (PI $$^2$$ )”. Our CPG driven RBFN controller is inspired by rhythmic dynamic movement primitives (DMPs). The controller can be also seen as an extension to a traditional CPG controller, which usually controls only the frequency of the motor patterns but not the shape. Our controller uses the CPG to control the frequency while the RBFN takes care of the shape of the motor patterns. In this paper, we only focus on the shape of the motor patterns and optimize those with respect to walking speed and energy efficiency. As a result, the robot can travel faster and consume less power than using only the CPG controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30487-4_53,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27529-7_32,Control of Nameplate Pasting Robot for Sand Mold Based on Deep Reinforcement Learning,Intelligent Robotics and Applications,10.1007/978-3-030-27529-7_32,Springer,2019-01-01,"In order to solve the problem of low-efficiency in the manual operation process of nameplate pasting for sand mold, an intelligent simulation system based on visual sensing and industrial robot is designed to paste nameplate on sand molds, and a deep reinforcement learning control method is proposed. The simulation system including the robot, visual sensor and sand mold is established in ROS combined with the physical simulation engine Gazebo. Then the task of nameplate pasting for sand molds is expressed as a markov process and the robot is trained by DQN method to learn a strategy to complete the task of pasting the nameplate of sand mold. A multi-level reward function algorithm based on multi-distances and collision information is proposed to improve the train success rate. Finally, the method is verified in the simulation system. The results show that the nameplate can be quickly attached to the sand mold cavity by the industrial robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27529-7_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-05816-6_3,Distributed Reinforcement Learning for Multi-robot Decentralized Collective Construction,Distributed Autonomous Robotic Systems,10.1007/978-3-030-05816-6_3,Springer,2019-01-01,"Inspired by recent advances in single agent reinforcement learning, this paper extends the single-agent asynchronous advantage actor-critic (A3C) algorithm to enable multiple agents to learn a homogeneous, distributed policy, where agents work together toward a common goal without explicitly interacting. Our approach relies on centralized policy and critic learning, but decentralized policy execution, in a fully-observable system. We show that the sum of experience of all agents can be leveraged to quickly train a collaborative policy that naturally scales to smaller and larger swarms. We demonstrate the applicability of our method on a multi-robot construction problem, where agents need to arrange simple block elements to build a user-specified structure. We present simulation results where swarms of various sizes successfully construct different test structures without the need for additional training.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-05816-6_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-1922-2_19,Robot Path Planning in Dynamic Environments Based on Deep Reinforcement Learning,"Cyberspace Data and Intelligence, and Cyber-Living, Syndrome, and Health",10.1007/978-981-15-1922-2_19,Springer,2019-01-01,"Path planning in dynamic environment has been the hot research direction. This paper considers a new dynamic environment—the obstacles are randomly distributed in the environment, and all of the obstacles will be distributed randomly again after robot’s movements. In the new dynamic environment, traditional path planning methods have some shortcomings when facing the dynamic environments. The traditional path planning algorithms need to re-calculate the path once the environments change, which is a very time consuming process. The deep reinforcement learning (DRL) model is a single-step algorithm, so the dynamic environments will not affect its running time consumption, which is superior to the traditional path planning algorithms in terms of running time consumption. However, the DRL model will face the problem of sparse rewards in the path planning problem due to the large state space of the environments. This paper uses DRL to solve the shortcomings of traditional path planning algorithms in dynamic environments and we propose a new framework to solve the problem of sparse reward in robot path planning. The framework uses a new strategy searching algorithm and a new shaped reward function. The improved framework can effectively solve the convergence problem in path planning. According to the simulation results, in the stochastic dynamic environments, the running time consumption of the new framework is less than the traditional path planning algorithm, and the new framework is better the classic DRL model in training results and planning results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-1922-2_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27529-7_30,Robot Intelligent Trajectory Planning Based on PCM Guided Reinforcement Learning,Intelligent Robotics and Applications,10.1007/978-3-030-27529-7_30,Springer,2019-01-01,"Reinforcement Learning (RL) was successfully applied in multi-degree-of-freedoms robot to acquire motor skills, however, it hardly ever consider each joints’ relationship, or just think about the linear relationship between them. In order to find the nonlinear relationship between each degrees of freedom (DOFs), we propose a Pseudo Covariance Matrix (PCM) to guide reinforcement learning for motor skill acquisition. Specifically it combined Path Integral Policy Improvement ( $$\mathrm{PI}^2$$ ) with Kernel Canonical Correlation Analysis (KCCA), where KCCA is used to obtain the PCM in high dimensional space and record it as the heuristic information to search an optimal/sub-optimal strategy. The experiments based on robots (SCARA and UR5) demonstrate the new method is feasible and effective.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27529-7_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-29852-4_24,Method of Improving the Cyber Resilience for Industry 4.0. Digital Platforms,Software Technology: Methods and Tools,10.1007/978-3-030-29852-4_24,Springer,2019-01-01,"Cyber resilience is the most important feature of any cyber system, especially during the transition to the sixth technological stage, and related Industry 4.0 technologies: Artificial Intelligence (AI), Cloud and foggy computing, 5G +, IoT/IIoT, Big Data and ETL, Q-computing, Block chain, VR/AR, etc. We should even consider the cyber resilience as primary one, because the mentioned systems cannot exist without it. Indeed, without the sustainable formation, made of the interconnected components of the critical information infrastructure, it does not make sense to discuss the existence of 4.0 Industry cyber-systems. In case when the cyber security of these systems is mainly focused on assessment of the incidents’ probability and prevention of possible security threats, the cyber security is mainly aimed at preserving the targeted behavior and cyber systems’ performance under the conditions of known (about 45%) as well as unknown (the remaining 55%) cyber-attacks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-29852-4_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-03577-8_63,Matchstick Games: On Removing a Matchstick Without Disturbing the Others,Information Systems and Technologies to Support Learning,10.1007/978-3-030-03577-8_63,Springer,2019-01-01,"It is shown that given any configuration of n ≥ 3 line segments (matchsticks) in the plane, there exist at least three segments that can each be translated to infinity, without colliding with the other n − 1 segments. In addition, if n ≥ 4, and the line segments are restricted to be parallel to the axes, at least four segments can be moved without disturbing the others. Furthermore, both lower bounds are best possible. The proofs are elementary and suitable for teaching in lower-level undergraduate courses on discrete mathematics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-03577-8_63,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-30763-9_4,Hierarchical Control Architecture for a Learning Robot Based on Heterogenic Behaviors,Artificial Intelligence,10.1007/978-3-030-30763-9_4,Springer,2019-01-01,"The paper describes a hierarchical control architecture for robotic systems with learning that allows combining various goal-directed algorithms. A top-level control algorithm is proposed that switches control between base algorithms: Q-learning, random walk and a rule-based planning. The algorithm is implemented as a software module and is verified by the example of the task of finding a given door in a building of complex planning. The task is considered as a reinforcement learning problem in two distinct cases: with a goal fixed between the episodes and the goal changing from episode to episode. The simulation showed that the proposed method is more stable for different variants of the task than each of the basic ones separately, although it does not give the best result for each individual case.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30763-9_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-24202-2_9,Evolutionary Multi-objective Optimization for Evolving Soft Robots in Different Environments,Bio-inspired Information and Communication Technologies,10.1007/978-3-030-24202-2_9,Springer,2019-01-01,"Evolutionary robotics is an approach for optimizing a robotic control system and structure based on the bio-inspired mechanism of adaptiogenesis. Conventional evolutionary robotics assigns a task and an evaluation to a virtual robot and acquires an optimal control system. In many cases, however, the robot is composed of a few rigid primitives and the morphology imitates that of real animals, insects, and artifacts. This paper proposes a novel approach to evolutionary robotics combining morphological evolution and soft robotics to optimize the control system of a soft robot. Our method calculates the relational dynamics among morphological changes and autonomous behavior for neuro-evolution (NE) with the development of a complex soft-bodied robot and the accomplishment of multiple tasks. We develop a soft-bodied robot composed of heterogeneous materials in two stages: a development stage and a locomotion stage, and we optimize these robotic structures by combining an artificial neural network (ANN) and age-fitness pareto optimization (AFP). These body structures of the robot are determined depending on three genetic rules and some voxels for evolving the ANN. In terms of our experimental results, our approach enabled us to develop some adaptive structural robots that simultaneously acquire behavior for crawling both on the ground and underwater. Subsequently, we discovered an unintentional morphology and behavior (e.g., walking, swimming, and crawling) of the soft robot through the evolutionary process. Some of the robots have high generalization ability with the ability to crawl to any target in any direction by only learning a one-directional crawling task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-24202-2_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-35430-5_2,Robots’ Vision Humanization Through Machine-Learning Based Artificial Visual Attention,Pattern Recognition and Information Processing,10.1007/978-3-030-35430-5_2,Springer,2019-01-01,"If the main challenge of robotics during the industrial air of 19^th century has consisted of automating repetitive tasks and the sophistication of these machines through digitization of these robots throughout the 20^th century, the challenge of robotics in the current century will be to make cohabit humans and robots in the same living space. However, robots would not succeed in seamlessly integrate the humans’ universe without developing the ability of perceiving similarly to humans the environment that they are supposed to share with them. In such a context, fitting the skills of the natural vision is an appealing perspective for autonomous robotics dealing with and prospecting Human-Robot interaction. The main goal of the present article is to debate the plausibility and the reality of humanizing the robots behavior focusing the perception of the surrounding environment. An implementation of the developed concept on a real humanoid robot nourishes the presented results and the related discussions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-35430-5_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-43011-9_71,"Automation, Artificial Intelligence and Innovations in the Future of IVF",In Vitro Fertilization,10.1007/978-3-319-43011-9_71,Springer,2019-01-01,"By in vitro fertilization (IVF), more than 5 million babies have been born worldwide till now and the number is increasing. Many developments took place – among others – in the embryology laboratory in the last few decades. IVF lab deals with the precious human life – the gametes and embryos which are destined to become 100–200 trillion cells adult human being. The culture systems currently being used in IVF lab is borrowed from tissue culture discipline. Unlike other field of biomedicine, the technical jump in innovation is rather slow, with regard to automation in IVF lab. There is a huge scope of robotics or automation in IVF lab systems. The process is very complex and needs high level of accuracy and errors close to zero, along with proper documentation. Embryo manipulations/intracytoplasmic sperm injection, cryopreservation, culture systems, etc. can be automated when right minds come together from embryology, automation engineering, and IT professionals. The artificial neural network (ANN) system in the near future can act as a routine information technology platform for the IVF unit and capable of recalling and evaluating a vast amount of information in a rapid and automated manner to provide an objective indication on the outcome of an IVF cycle. ANNs are an exceptional candidate in providing the fertility specialist with numerical estimates to promote personalization of healthcare and adaptation of the course of treatment according to the indications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-43011-9_71,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-92294-2_1,Image Classification for Robotic Plastering with Convolutional Neural Network,"Robotic Fabrication in Architecture, Art and Design 2018",10.1007/978-3-319-92294-2_1,Springer,2019-01-01,"Inspecting robotically fabricated objects to detect and classify discrepancies between virtual target models and as-built realities is one of the challenges that faces robotic fabrication. Industrial-grade computer vision methods have been widely used to detect manufacturing flaws in mass production lines. However, in mass-customization, a versatile and robust method should be flexible enough to ignore construction tolerances while detecting specified flaws in varied parts. This study aims to leverage recent developments in machine learning and convolutional neural networks to improve the resiliency and accuracy of surface inspections in architectural robotics. Under a supervised learning scenario, the authors compared two approaches: (1) transfer learning on a general purpose Convolutional Neural Network (CNN) image classifier, and (2) design and train a CNN from scratch to detect and categorize flaws in a robotic plastering workflow. Both CNNs were combined with conventional search methods to improve the accuracy and efficiency of the system. A web-based graphical user interface and a real-time video projection method were also developed to facilitate user interactions and control over the workflow.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-92294-2_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-662-57277-1_15,Overview of Computational Intelligence (CI) Techniques for Powered Exoskeletons,Computational Intelligence in Sensor Networks,10.1007/978-3-662-57277-1_15,Springer,2019-01-01,"There is an emerging need to synchronise wearable function with user intention as many exoskeletons reported in current literature have limited capability to predict user intention. In order to achieve good synchronization, closed loop feedback is required. Overcoming these limitations necessitates an architecture composed of networked sensors and actuators with smart control algorithms to fuse sensor data and create smooth actuation. This review chapter discusses the growing need to deploy computational intelligence (CI) techniques as well as machine learning (ML) algorithms so that exoskeletons are able to predict the user intentions and consequently operate in parallel with human intention. A comprehensive review of major portable, active exoskeletons are provided for both upper and lower limbs with a focus on the need for smart algorithms integration to drive them. The application areas include rehabilitation and human performance augmentation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-662-57277-1_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-30241-2_30,Intelligent Control of an Exoskeleton for Rehabilitation Purposes Using a ROS-Based Software Architecture,Progress in Artificial Intelligence,10.1007/978-3-030-30241-2_30,Springer,2019-01-01,"This paper describes an open-source software architecture that allows an exoskeleton to be remotely used for rehabilitation purposes. The exoskeleton can be controlled through a Natural User Interface (NUI), which directly records the therapist’s legs motion, from which, the input references that should be sent to the exoskeleton are calculated. The proposed architecture consists of a set of interconnected components, running independently, which use a middleware for transparently sharing information. In particular, a set of software components, executed as ROS nodes, solve the problems related to hardware issues and control strategies. An early prototype of the system has been tested and results are shown in this paper, together with a discussion about the advantages and disadvantages of the system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30241-2_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-36211-9_9,DCGAN Model Used to Generate Body Gestures on a Human-Humanoid Interaction System,Applications of Computational Intelligence,10.1007/978-3-030-36211-9_9,Springer,2019-01-01,"The current availability of the humanoid robots opens up a wide range of applications, for instance, in the domain of hospitality the humanoids can be programmed to behave autonomous ways to provide help to people. The aspect of the humanoids and the humanness of interaction are key components of success. We developed a system to endow the humanoid robot Pepper, from SoftBank Robotics, with the capability of both: identify the emotion state of the humans and exhibiting emotional states via gestures and postures generated using a DCGAN model to learn from the human body language and to create originals body expressions to exhibit like-human movements.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-36211-9_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-31332-6_34,Collision Anticipation via Deep Reinforcement Learning for Visual Navigation,Pattern Recognition and Image Analysis,10.1007/978-3-030-31332-6_34,Springer,2019-01-01,"Visual navigation is the ability of an autonomous agent to find its way in a large and complex environment based on visual information. It is indeed a fundamental problem in computer vision and robotics. In this paper, we propose a deep reinforcement learning approach which is able to learn to navigate a scene to reach a given visual target, but anticipating the possible collisions with the environment. Technically, we propose a map-less-based model, which follows an actor-critic reinforcement learning method where the reward function has been designed to be collision aware. We offer a thorough experimental evaluation of our solution in the AI2-THOR virtual environment, where the results show that our proposed method: (1) improves the state of the art in terms of number of steps and collisions; (2) is able to converge faster than a model which does not care about the collisions, simply searching for the shortest paths; and (3) offers an interesting generalization capability to reach visual targets that have never been seen during training.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-31332-6_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-22999-3_56,A Model-Based Reinforcement Learning Approach to Time-Optimal Control Problems,Advances and Trends in Artificial Intelligence. From Theory to Practice,10.1007/978-3-030-22999-3_56,Springer,2019-01-01,"Reinforcement Learning has achieved an exceptional performance in the last decade, yet its application to robotics and control remains a field for deeper investigation due to potential challenges. These include high-dimensional continuous state and action spaces, as well as complicated system dynamics and constraints in robotic settings. In this paper, we demonstrate a pioneering experiment in applying an existing model-based RL framework, PILCO, to the problem of time-optimal control. At first, the algorithm models the system dynamics with Gaussian Processes, successfully reducing the effect of model biases. Then, policy evaluation is done through iterated prediction with Gaussian posteriors and deterministic approximate inference. Finally, analytic gradients are used for policy improvement. A simulation and an experiment of an autonomous car completing a rest-to-rest linear locomotion is documented. Time-optimality and data efficiency of the task are shown in the simulation results, and learning under real-world circumstances is proved possible with our methodology.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-22999-3_56,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-30487-4_51,Scaffolding Haptic Attention with Controller Gating,Artificial Neural Networks and Machine Learning – ICANN 2019: Theoretical Neural Computation,10.1007/978-3-030-30487-4_51,Springer,2019-01-01,"A powerful concept that emerged within the field of educational psychology is scaffolding. Characterizing favourable expert-learner interaction, it can be defined as a temporal support that provides a novice an adaptable guidance to either learn tasks that would usually be beyond own capabilities or to speed up and refine the learning of manageable problems. In this work we apply the above-mentioned concept to implement a novel multi-strategy haptic exploration controller that is able to perform object identification using a robot. In our previous work we have proposed a reinforcement learner that acquires haptic exploration capabilities for a goal-directed task by optimizing motor control in a strongly restricted attentional framework, called the haptic attention model (HAM). The resulting policy however was not characterized by a smooth energy-efficient exploration suitable for execution on a robot. In this work, we scaffold the designed learning architecture by imposing the so-called controller gating that is trained to switch between orientation and position control. Integrated in the same reinforcement learning setting as the HAM, controller gating guides and monitors the data acquisition. Inspired by the human expert scaffolding, it analyzes the HAM internal data representation, modulates the HAM weight update process, and forces data acquisition that achieves efficient and successful completion of the goal. Our computational scaffold adapts to the learner model, while it masters the skill. The evaluation demonstrated that it is more likely for the trained model to change either location or orientation than simultaneously change both, which significantly improves the smoothness and the energy-efficiency of the resulting exploration.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30487-4_51,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-99010-1_9,Classification Techniques for Wall-Following Robot Navigation: A Comparative Study,Proceedings of the International Conference on Advanced Intelligent Systems and Informatics 2018,10.1007/978-3-319-99010-1_9,Springer,2019-01-01,"Autonomous navigation is an important feature that allows the robot to move independently from a point to another without a teleoperator. In this paper, an investigation related to mobile robot navigation is presented. A group of supervised classification algorithms are tested and validated using the same dataset. Then focus will shift especially towards the k-Nearest Neighbors (KNN) algorithm. In order to improve the performance of KNN, an existing work related to genetic algorithms, local search, and Condensed Nearest Neighbors termed Memetic Controlled Local Search algorithm (MCLS) is applied to overcome the high running time of KNN. The results indicate that KNN is a competing algorithm especially after decreasing the running time significantly and combining that with existing algorithm features.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-99010-1_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-32423-0_7,EEG-Based Workload Index as a Taxonomic Tool to Evaluate the Similarity of Different Robot-Assisted Surgery Systems,Human Mental Workload: Models and Applications,10.1007/978-3-030-32423-0_7,Springer,2019-01-01,"In operational fields, there is a growing use of simulators during training protocols because of their versatility, the possibility of limiting costs and increasing efficiency. This work aimed at proposing an EEG-based neurometric of mental workload, previously validated in other contexts, as a taxonomic tool to evaluate the similarity, in terms of cognitive demands, of two different systems: the da Vinci surgical system, leader in the field of robotic surgery, and the Actaeon Console by BBZ, basically a cheaper simulator aimed to train students to use the da Vinci system. Such a neurophysiologic evaluation of the workload demand was also integrated by information derived by the task performance and self-reports. The results validated the proposed EEG-based workload index and indicated the potentially fruitful use of simulators because of their high similarity in terms of cognitive demands.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-32423-0_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-658-17483-5_17,Learning How to Behave,Handbuch Maschinenethik,10.1007/978-3-658-17483-5_17,Springer,2019-01-01,"We describe a theoretical framework and recent research on one key aspect of robot ethics: the development and implementation of a robot’s moral competence. As autonomous machines take on increasingly social roles in human communities, these machines need to have some level of moral competence to ensure safety, acceptance, and justified trust. We review the extensive and complex elements of human moral competence and ask how analogous competences could be implemented in a robot. We propose that moral competence consists of five elements, two constituents (moral norms and moral vocabulary) and three activities (moral judgment, moral action, and moral communication). A robot’s computational representations of social and moral norms is a prerequisite for all three moral activities. However, merely programming in advance the vast network of human norms is impossible, so new computational learning algorithms are needed that allow robots to acquire and update the context-specific and graded norms relevant to their domain of deployment. Moral vocabulary is needed primarily for moral communication, which expresses moral judgments of others’ violations and explains one’s own moral violations – to justify them, apologize, or declare intentions to do better. Current robots have at best rudimentary moral competence, but with improved learning and reasoning they may begin to show the kinds of capacities that humans will expect of future social robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-658-17483-5_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-30645-8_47,Gaze-Based Human-Robot Interaction by the Brunswick Model,Image Analysis and Processing – ICIAP 2019,10.1007/978-3-030-30645-8_47,Springer,2019-01-01,"We present a new paradigm for human-robot interaction based on social signal processing, and in particular on the Brunswick model. Originally, the Brunswick model copes with face-to-face dyadic interaction, assuming that the interactants are communicating through a continuous exchange of non verbal social signals, in addition to the spoken messages. Social signals have to be interpreted, thanks to a proper recognition phase that considers visual and audio information. The Brunswick model allows to quantitatively evaluate the quality of the interaction using statistical tools which measure how effective is the recognition phase. In this paper we cast this theory when one of the interactants is a robot; in this case, the recognition phase performed by the robot and the human have to be revised w.r.t. the original model. The model is applied to Berrick , a recent open-source low-cost robotic head platform, where the gazing is the social signal to be considered.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30645-8_47,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-97490-3_46,Technical Diagnostics at the Department of Automation and Production Systems,Intelligent Systems in Production Engineering and Maintenance,10.1007/978-3-319-97490-3_46,Springer,2019-01-01,"The article contains a summary of recent development in field of technical diagnostics at the Department of Automation and Production Systems, Faculty of Mechanical Engineering, University of Zilina. It covers diagnostics and monitoring of CNC machine tools, industrial robots, and production lines. Each part contains a description of basic approaches, methods, measurement tools and their implementation. In case of machine tool and industrial robot diagnostics, it is mainly laser interferometry and double Ballbar method. It also describes usage of the internet of things and machine learning as a tools to implement multiparametric diagnostics and monitoring on production lines.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-97490-3_46,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-90893-9_25,Acoustic Diagnostics of Lever Mechanisms with Subsequent Processing of Data on Neural Networks,"New Technologies, Development and Application",10.1007/978-3-319-90893-9_25,Springer,2019-01-01,"The technique of acoustic diagnostics for machine tools - robots is developed. A neural network reference model has been constructed that allows to diagnose the current characteristics of the state of objects under different conditions, namely, the configuration of the mechanism, the geometric parameters of the mechanism with the motor-spindle running, the dynamics of the movement of the nodes of the experimental stand mechanism with variable speed and load on the drive, and the temperature of the object. Experiments have been carried out to investigate the relationship between the parameters of the spectrum of an acoustic signal with a given discreteness, excited by a perturbing effect in the form of “white noise.” The possibility of using the proposed approach to the management of complex technological machines, such as machines with mechanisms based on parallel kinematics, is shown to improve the accuracy of the positioning of the actuators, to ensure their dynamic tuning and to optimize the trajectories of the movements of the working organs of the equipment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-90893-9_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-13-7780-8_12,Effective Indoor Robot Localization by Stacked Bidirectional LSTM Using Beacon-Based Range Measurements,Robot Intelligence Technology and Applications,10.1007/978-981-13-7780-8_12,Springer,2019-01-01,"In this paper, we propose a stacked bidirectional Long Short-Term Memory (stacked Bi-LSTM) for accurate localization of a robot. Using deep learning, the proposed structure directly maps range measurements from beacons into robot position. This operation non-linearly maps the relationship not only considering the long-range dependence of sequential distance data but also using the correlation of the backward information and the forward information of the sequence of each time step by virtue of its bidirectional architecture. Our stacked bidirectional LSTM structure exhibits better estimates of robot positions than other RNN structure units on the simulated environment. In addition, experiments suggest that even if the robot position is not included in the training dataset, our method is able to predict robot positions with small errors through sequential distance data.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-7780-8_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-23207-8_40,AI Meets Austen: Towards Human-Robot Discussions of Literary Metaphor,Artificial Intelligence in Education,10.1007/978-3-030-23207-8_40,Springer,2019-01-01,"Artificial intelligence is revolutionizing formal education, fueled by innovations in learning assessment, content generation, and instructional delivery. Informal, lifelong learning settings have been the subject of less attention. We provide a proof-of-concept for an embodied book discussion companion, designed to stimulate conversations with readers about particularly creative metaphors in fiction literature. We collect ratings from 26 participants, each of whom discuss Jane Austen’s Pride and Prejudice with the robot across one or more sessions, and find that participants rate their interactions highly. This suggests that companion robots could be an interesting entryway for the promotion of lifelong learning and cognitive exercise in future applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-23207-8_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-22335-9_24,User Experience Study: The Service Expectation of Hotel Guests to the Utilization of AI-Based Service Robot in Full-Service Hotels,"HCI in Business, Government and Organizations. eCommerce and Consumer Behavior",10.1007/978-3-030-22335-9_24,Springer,2019-01-01,"With the dramatic development of AI technology, the concept of robotic hotel is entering the public’s awareness. Although AI application brings in high efficiency, low labor cost and novelty, practical operation of robotic hotels still faces with challenges. This quantitative research aims at understanding the current user expectation level of AI robotic hotel and robot appliance. Based on that, it tries to make the user classification by demographic, behavioral and attitude factors. By using the refined SERVQUAL model, it gathers the expectation from five dimensions involving tangibles, reliability, responsiveness, assurance and empathy. These research objectives were realized by using survey-designed questionnaires and distributed by a snowball sampling method conducted in Beijing. After validity and reliability test, data collected from the field were analyzed by a variety of inspections. It is found that education, attitude and income level have a significant effect on the expectation to stay in the robotic hotel, which provided the basis of market position for robotic hotel operators. Through regression analysis, the model was established to identify what factors played an important part and how they worked. It is found that tangibles and responsiveness expectation significantly and positively contributed to increases in general user expectation to robotic hotels. This thesis drew up several conclusions, which would help industry players including hoteliers, AI robot suppliers better understand details of the user group in their decision-making process, as well as academic side to formulate a tailored model to evaluate the interaction between AI robots and hotel guests.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-22335-9_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-21836-2_5,Visions of Swarming Robots: Artificial Intelligence and Stupidity in the Military-Industrial Projection of the Future of Warfare,Cyborg Futures,10.1007/978-3-030-21836-2_5,Springer,2019-01-01,"This chapter brings a philosophical perspective to a critical engagement with the analysis, speculation, and recommendations for the future development and deployment of lethal autonomous robotic systems such as they appear in reports, studies, and presentations emanating from the US military-industrial complex. In particular, Bernard Stiegler’s philosophy of technology and how it relates to human cultural and political endeavors—including in the domain of military conflict—is brought to bear on projections of the development of artificially intelligent swarming in future war. The discussion focuses on the Center for a New American Security’s “Future of Warfare” research initiative because of its consolidation of the theoretical and logistical arguments for the adoption of swarming robotic elements in the application of military force. A critique of these efforts is made which argues that a problematic, voluntary stupidity animates these efforts to clear the way toward a much greater delegation of the exercise of lethal force to automated robotic systems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-21836-2_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-476-04967-4_2,Technology Games/Gender Games. From Wittgenstein’s Toolbox and Language Games to Gendered Robots and Biased Artificial Intelligence,Feminist Philosophy of Technology,10.1007/978-3-476-04967-4_2,Springer,2019-01-01,"Responding to postphenomenology, going beyond postmodern obsessions with text and discourse, and using Wittgenstein, this chapter proposes a conceptual framework for addressing gender issues raised by technologies such as robotics and artificial intelligence. It is shown that technologies, through their use, are always connected to wider social and cultural meanings. These “technology games” include “gender games”. This notion enables us to reveal, analyze, and critically discuss the gender meanings linked to material artefacts and other technologies. It thus provides a way to conceptualize why and how technologies such as robots and artificial intelligence can be gendered. This approach, which is not necessarily feminist but certainly critical and compatible with Wajcman’s work and with posthumanist questioning, can also inform and help to shape more ethical design of new technologies that takes into account gender issues.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-476-04967-4_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-05532-5_45,Inductive Machine Learning with Image Processing for Objects Detection of a Robotic Arm with Raspberry PI,Technology Trends,10.1007/978-3-030-05532-5_45,Springer,2019-01-01,"Goals. The present study was designed to build a prototyping and develop algorithms that allow the detection, classification, and movement of objects of a robotic arm of 4 DOF with the following technologies: ArmUno arm structure, Raspberry Pi 3 B+, PiCam 2.1, driver PCA9685 for servomotors, Opencv3, and python. Another goal was to measure the effectiveness of prediction and classification of objects photographed by the robotic arm, using machine learning with the KNN classifier method. Methodology. The generation of a dataset of 800 photographic images was proposed, in 4 categories: volumetric geometric shapes conformed by 200 images each one of them. With this, processing techniques were applied to the image captured by the camera to detect the object in the image: Grayscale filtering, Gaussian filtering, and threshold. Then, the characteristics of the object were obtained through the first two invariant moments of HU, and finally, the machine learning method KNN was applied to predict, that the image captured by the robotic arm belongs or not to a certain category. In this way, the robotic arm decides to move the object or not. Results. According to the plot of the obtained data described in the results section; the level of correct answers increases markedly by using the techniques described above. The prediction and classification using KNN were remarkable, For all the tests carried out The average effectiveness of KNN method was 95.42%. Once the scripts were integrated, the operation of the robotic arm was satisfactory.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-05532-5_45,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-29888-3_2,MIVIABot: A Cognitive Robot for Smart Museum,Computer Analysis of Images and Patterns,10.1007/978-3-030-29888-3_2,Springer,2019-01-01,"Cognitive robots are robots provided with artificial intelligence capabilities, able to properly interact with people and with the objects in an a priori unknown environment, using advanced artificial intelligence algorithms. For instance, a humanoid robot can be perceived as a plausible tourist guide in a museum. Within this context, in this work we present how the latest findings in the field of machine learning and pattern recognition can be applied to equip a robot with sufficiently advanced perception capabilities in order to successfully guide visitors through the halls and the attraction in a museum. The challenge of running all those algorithms on a mobile, embedded platform in real time is tackled on an architectural level, where all the artificial intelligence features are tuned to run with a low computational burden and a Neural Network accelerator is included in the hardware setup. Improved robustness and predictable latency is obtained avoiding the use of cloud services in the system. Our robot, that we call MIVIABot, is able to decode and understand speech as well as extract soft biometrics from its interlocutor such as age, gender and emotional status. The robot can integrate all those elements in a dialog, using basic Natural Language Processing capabilities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-29888-3_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-30241-2_10,Vineyard Segmentation from Satellite Imagery Using Machine Learning,Progress in Artificial Intelligence,10.1007/978-3-030-30241-2_10,Springer,2019-01-01,"Steep slope vineyards are a complex scenario for the development of ground robots due to the harsh terrain conditions and unstable localization systems. Automate vineyard tasks (like monitoring, pruning, spraying, and harvesting) requires advanced robotic path planning approaches. These approaches usually resort to Simultaneous Localization and Mapping (SLAM) techniques to acquire environment information, which requires previous navigation of the robot through the entire vineyard. The analysis of satellite or aerial images could represent an alternative to SLAM techniques, to build the first version of occupation grid map (needed by robots). The state of the art for aerial vineyard images analysis is limited to flat vineyards with straight vine’s row. This work considers a machine learning based approach (SVM classifier with Local Binary Pattern (LBP) based descriptor) to perform the vineyard segmentation from public satellite imagery. In the experiments with a dataset of satellite images from vineyards of Douro region, the proposed method achieved accuracy over 90%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30241-2_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-23560-4_8,Universal Access: The Challenges Ahead,"Universal Access in Human-Computer Interaction. Theory, Methods and Tools",10.1007/978-3-030-23560-4_8,Springer,2019-01-01,It is approaching 20 years since the first issue of the International Journal on Universal Access was published and also that the first International Conference on Universal Access in Human-Computer Interaction was held. This paper reflects on how the field of Universal Access has evolved over the intervening period and proposes new areas of research challenges that have either emerged following recent advances in technology or still remain comparatively poorly addressed. The proposed challenges have been derived from a examining Maslow’s Hierarchy of Needs along with technological development trends.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-23560-4_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-22871-2_24,"Machine Autonomy: Definition, Approaches, Challenges and Research Gaps",Intelligent Computing,10.1007/978-3-030-22871-2_24,Springer,2019-01-01,"The processes that constitute the designs and implementations of AI systems such as self-driving cars, factory robots and so on have been mostly hand-engineered in the sense that the designers aim at giving the robots adequate knowledge of its world. This approach is not always efficient especially when the agent’s environment is unknown or too complex to be represented algorithmically. A truly autonomous agent can develop skills to enable it to succeed in such environments without giving it the ontological knowledge of the environment a priori . This paper seeks to review different notions of machine autonomy and presents a definition of autonomy and its attributes. The attributes of autonomy as presented in this paper are categorised into low-level and high-level attributes. The low-level attributes are the basic attributes that serve as the separating line between autonomous and other automated systems while the high-level attributes can serve as a taxonomic framework for ranking the degrees of autonomy of any system that has passed the low-level autonomy. The paper reviews some AI techniques as well as popular AI projects that focus on autonomous agent designs in order to identify the challenges of achieving a true autonomous system and suggest possible research directions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-22871-2_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-97418-7_13,"‘New Technologies’: Questions of Agency, Responsibility, and Luck",Technologies of International Relations,10.1007/978-3-319-97418-7_13,Springer,2019-01-01,"In this wide-ranging conversation Professor Erskine details the emergence of her interest in new technologies and their impact on international ethics and politics. She explains how a research interest in the early stages of her career in the ethics and norms of war led via work on institutional moral agency to her current research on artificial intelligence. She outlines the key questions animating her work in the context of AI, robots and moral agency and moral standing. She goes on to explain how technology has become increasingly foregrounded in her work and discusses the impact of technology on International Relations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-97418-7_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-658-26212-9_13,Sex Machines as Mediatized Sexualities: Ethical and Social Implications,Responsibility and Resistance,10.1007/978-3-658-26212-9_13,Springer,2019-01-01,"Sex machines are also communication practices. This chapter considers sexual interactions with technological devices as mediatized sexualities. Media are integrated in the definition of most of the contexts of human life—and the combination of the mediatization perspective with an Actor-Network Theory enables an organic cross-disciplinary discussion about technologies across specific socio-cultural fields. Sex machines, hybrids of fundamental humanness and either or both artificiality and artifactuality, push the boundaries and raise social and ethical discussions about the limits of the integrated circuit involving society, individuals, culture, values, interactivity and intercourse. Therefore, a consideration of sex machines enriches media discussions on technologies, communicative, social and cultural practices and ethical debates. This chapter starts with a discussion on how sex machines belong to the world of mediatized sexualities. After an introductory section on mediatization, ethics and sex machines, the argument builds on a typology of sex machines (similarity, extension, substitution, sublimation, sensuality and creativity) to provide a discussion on ethical issues. The debates consider, amongst others, robots, surveillance, psychological, sociological and body-related concerns, which are also relevant for media and communication studies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-658-26212-9_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-35664-4_9,Energy Industry Perspective on the Definition of Autonomy for Mobile Robots,Nordic Artificial Intelligence Research and Development,10.1007/978-3-030-35664-4_9,Springer,2019-01-01,"Autonomy refers to a system that decides and performs actions motivated by some intended objectives, and those actions are justifiable by sound reasoning with respect to these objectives. Artificial intelligence (AI) is here intended as the technology that enables autonomy. Artificially intelligent autonomous robots are predicted to play an increasingly important role in the energy industry capability to address the society demand for energy. The development of such advanced systems needs to start with defining AI and autonomy for asset owners in the energy industry. In general, different applications will require different engineering definitions of AI and different levels of autonomy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-35664-4_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-11051-2_43,Adaptive Learning for Robots in Public Spaces,Intelligent Human Systems Integration 2019,10.1007/978-3-030-11051-2_43,Springer,2019-01-01,"Proper functioning of robots deployed in public spaces often require extensive knowledge of its environment of use, which is completely unknown prior to deployment. The methods for acquiring and utilizing such knowledge also varies depending on the nature of the public space and the tasks the robot needs to perform. This calls for development and application of adaptive learning methods specifically designed to take into consideration the nature and key properties of various public spaces and robotic tasks. In this paper, we study typical types of public spaces for deployment of robots, and analyze robotic tasks required in each type of space to derive common capabilities that the robots need to have. We then consider three adaptive learning methods: (1) autonomous learning, (2) unsupervised learning from real-time on-site data, and (3) guided learning. Applicability of the methods to improve each common capability and possible means of application are further discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-11051-2_43,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-90659-1_18,A Task in Education: Towards a Community of Difference for Learning to Live Together,Learning To Live Together: Promoting Social Harmony,10.1007/978-3-319-90659-1_18,Springer,2019-01-01,"In 2016, the world was stunned by two unforeseen events. In June, the UK voted to leave the European Union, and in November, Donald Trump was elected as the president of the United States. The polls then showed that the chances of voting against Brexit were high, and the chances of Trump being elected were unlikely. The results were unexpected. The British people voted to break away from the EU and the Americans elected President Trump.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-90659-1_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-02242-6_23,The Responsibilities of Knowledge,"EAI International Conference on Technology, Innovation, Entrepreneurship and Education",10.1007/978-3-030-02242-6_23,Springer,2019-01-01,"Knowledge and technology in the future will hold out almost limitless possibilities, but will also bring challenges and responsibilities relating to how they are used. This paper uses a story about space exploration in the future where Holodecks, advanced brain–computer and brain–brain interfaces, and other technologies, will enable exciting possibilities, but also create deep ethical dilemmas which have to be dealt with.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-02242-6_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27541-9_11,Intelligent Robot Arm: Vision-Based Dynamic Measurement System for Industrial Applications,Intelligent Robotics and Applications,10.1007/978-3-030-27541-9_11,Springer,2019-01-01,"Current industrial robot arms are not satisfied in flexibility and intelligence due to the lack of visual perception. The production efficiency also runs into a bottleneck because most parts must be completely fixed when assembling and welding. We propose a vision-based intelligent robot arm, which can dynamically sense the environment and perform appropriate operations. The measurement system consists of operator face authentication, gesture remote control, abnormal entry detection and moving target tracking. The capabilities of human-machine interaction and dynamic measurement meet the needs of high-performance robot arm in intelligent manufacturing, with the characteristics of intelligence, safety, efficiency and flexibility. Various functions of the intelligent robot arm are verified through a large number of experiments in laboratory.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27541-9_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-30391-4_4,Explaining Sympathetic Actions of Rational Agents,"Explainable, Transparent Autonomous Agents and Multi-Agent Systems",10.1007/978-3-030-30391-4_4,Springer,2019-01-01,"Typically, humans do not act purely rationally in the sense of classic economic theory. Different patterns of human actions have been identified that are not aligned with the traditional view of human actors as rational agents that act to maximize their own utility function. For instance, humans often act sympathetically – i.e., they choose actions that serve others in disregard of their egoistic preferences. Even if there is no immediate benefit resulting from a sympathetic action, it can be beneficial for the executing individual in the long run. This paper builds upon the premise that it can be beneficial to design autonomous agents that employ sympathetic actions in a similar manner as humans do. We create a taxonomy of sympathetic actions, that reflects different goal types an agent can have to act sympathetically. To ensure that the sympathetic actions are recognized as such, we propose different explanation approaches autonomous agents may use. In this context, we focus on human-agent interaction scenarios. As a first step towards an empirical evaluation, we conduct a preliminary human-robot interaction study that investigates the effect of explanations of (somewhat) sympathetic robot actions on the human participants of human-robot ultimatum games. While the study does not provide statistically significant findings (but notable differences), it can inform future in-depth empirical evaluations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30391-4_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27538-9_10,Improved Neural Network 3D Space Obstacle Avoidance Algorithm for Mobile Robot,Intelligent Robotics and Applications,10.1007/978-3-030-27538-9_10,Springer,2019-01-01,"Path planning problems are classical optimization problems in many fields, such as computers, mathematics, transportation, robots, etc., which can be described as an optimization problem in mathematics. In this paper, the mathematical model of obstacle environment is established. The characteristics of neural network algorithm, simulated annealing algorithm and adaptive variable stepsize via linear reinforcement are studied respectively. A new neural network 3D space obstacle avoidance algorithm for mobile robot is proposed, which solves the problem of the computational duration and minimum distance of the traditional neural network obstacle avoidance algorithm in solving the optimal path. According to the characteristics of the improved neural network algorithm, it is fused with a variety of algorithms to obtain the optimal path algorithm that achieves the shortest path distance and meets the requirements of obstacle avoidance security. The simulation experiment of the algorithm is simulated by Matlab. The results show that the improved neural network spatial obstacle avoidance algorithm based on the multiple algorithms proposed in this paper can effectively accelerate the convergence speed of path planning, realize the minimum path distance, and achieve very good path planning effect.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27538-9_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-26118-4_28,Application of Convolutional Neural Network to Organize the Work of Collaborative Robot as a Surgeon Assistant,Interactive Collaborative Robotics,10.1007/978-3-030-26118-4_28,Springer,2019-01-01,"Medicine is a perspective area for collaborative robotics. The paper presents the collaborative robot as a surgeon’s assistant, accompanying the operation, submitting the necessary tools and performing other auxiliary actions. Such a robot must be mobile, have a manipulator, means of visual communication, an autonomous navigation system in the operating room, and an interactive system for interaction with the surgeon. The last task is considered in the paper. At the voice request of the surgeon, the robot have to find the necessary medical tool on the desktop and transmit it to the surgeon. This operation involves three steps: firstly, at the voice request, the robot must determine which tool is required by the surgeon; on the second step- to find the right tool on the desktop and take it; and on the third – to hand the tool to the surgeon. In the paper the neural networks technology is proposed to solve the recognition problems aroused at two first stages.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-26118-4_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27538-9_20,Haptic Feedback with a Reservoir Computing-Based Recurrent Neural Network for Multiple Terrain Classification of a Walking Robot,Intelligent Robotics and Applications,10.1007/978-3-030-27538-9_20,Springer,2019-01-01,"Terrain classification is an important feature for walking robots because it allows the robots to stably move and operate on the terrain. Different terrain classification techniques have been developed. The techniques include the use of different exteroceptive and proprioceptive sensors with different classification methods. Whereas these techniques have been widely used to classify flat, hard, and rough terrains, their application to soft terrains has not been fully addressed. Achieving soft-terrain classification will expand the operational range of walking robots. Thus, in this study, we propose a new technique to classify various terrains including soft ones. The technique exploits haptic feedback (expressed only through ground contact force measurement of a legged robot) and neurodynamics with the temporal memory of a reservoir computing-based recurrent neural network. We used six different terrains to evaluate the performance of the proposed technique. The terrains include sand (loose ground), foams with different softness levels (soft ground), and floor (hard ground). The experimental results show that we can successfully classify all terrains with an accuracy of above 70%. Furthermore, owing to the temporal memory of the network, if the haptic feedback is transiently missing, the network will be still be able to classify the terrain considerably well.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27538-9_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-24305-0_57,The Architecture of the Robot-Finder Based on SLAM and Neural Network,Computational Science and Its Applications – ICCSA 2019,10.1007/978-3-030-24305-0_57,Springer,2019-01-01,"The task of this paper is to find lost or frozen people in the wood. That takes accurate exploration of a large space with a minimum time duration. This work is dedicated to the architecture part of the assigned task. We give an architecture for robot-finder capable to find a human being in the wood or in the snow area. For us, the robot is blending of two elements, which we can develop independently. That are a wheeled platform and an operating module. In this task, we look at the second one. During that way we assume that the first one is developed, therefore the robot is driving upon the airbag or wheeled platform. Our solution to this task is architecture and algorithm. These two are made for and directed to learn robot follow the map and detect human being alongside. We use computer vision, neural network and GPS technologies. In the end, we have a theoretical basis for developing robot-finder.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-24305-0_57,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-22999-3_16,Neural Network Control System of Motion of the Robot in the Environment with Obstacles,Advances and Trends in Artificial Intelligence. From Theory to Practice,10.1007/978-3-030-22999-3_16,Springer,2019-01-01,"The article deals with the combined motion control system which provides an autonomous movement of the robot in an uncertain environment. The motion planning level is implemented on a cascade neural network of deep learning. The proposed structure of the network allows decomposing the task of planning a path to the task of deciding whether to maneuver and the task of selecting a direction to bypass an obstacle. The motion control level is implemented in the form of a hybrid system that includes the neural network correction of the path, and the algorithm for avoiding collisions, built on the basis of unstable modes. The control system was modeled and as the result of modeling the quality of control system was obtained. The results of experiments confirming the performance of the control system are presented. It is proposed to classify the environment of operation of the robot according to the complexity of the current situation, depending on the need for maneuver. The environment is classified into complexity classes, the number of which depends on the number of active network cascades.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-22999-3_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-20131-9_182,Artificial Neural Network Based Kinematics: Case Study on Robotic Surgery,Advances in Mechanism and Machine Science,10.1007/978-3-030-20131-9_182,Springer,2019-01-01,This study presents a novel controller design for robot-assisted surgery based on Artificial Neural Network (ANN) architecture. The motion of surgical robot is constrained by the kinematics of remote center of motion (RCM). A new ANN design for inverse kinematics of RCM is proposed. ANN compared with classical ANN design. The input pattern of new ANN has included feedback of previous joint angles of robotic arm as well as the position and orientation of the tool tip. A six DOF robotic arm with a tool prototype used to demonstrate a surgical robot. The experimental results proved applicability and efficiency of NN in robotics assisted minimally invasive surgery (RAMIS).,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-20131-9_182,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-28180-9_2,"Smart Technology, Artificial Intelligence, Robotics and Algorithms (STARA): Employees’ Perceptions and Wellbeing in Future Workplaces","Theory, Research and Dynamics of Career Wellbeing",10.1007/978-3-030-28180-9_2,Springer,2019-01-01,"Futurists predict that a third of jobs that exist today could be replaced by smart technology Smart technology , artificial intelligence Artificial intelligence , robotics Robotics and algorithms Algorithms ( STARA Smart Technology, Artificial Intelligence, Robotics and Algorithms (STARA) ). Robots will handle 52% of current work tasks by 2025, almost twice as many as in 2019. Rapid changes in machines Machines and algorithms Algorithms or computer processes could create 133 million new roles in place of 75 million that will be displaced between 2019 and 2022 (World Economic Forum, The Citizen, 2018 ). The objective of the chapter was to present a critical review of how employees Employees perceive technological innovations (STARA Smart Technology, Artificial Intelligence, Robotics and Algorithms (STARA) ) with regard to their own jobs and careers Careers , and their wellbeing in future workplaces Future workplace . STARA Smart Technology, Artificial Intelligence, Robotics and Algorithms (STARA) awareness is a measure that encapsulates the extent to which employees Employees feel their career Careers could be replaced by these modes of technology Technology . Age Age as a moderator of STARA Smart Technology, Artificial Intelligence, Robotics and Algorithms (STARA) also plays a role due to career Careers development and technology Technology expertise associated with age Age . STARA Smart Technology, Artificial Intelligence, Robotics and Algorithms (STARA) awareness will not only effect job outcomes, but also wellbeing outcomes. The way employees Employees construct their identity with their career Careers and evaluate their own career Careers achievement can have an impression on their financial and psychological wellbeing Psychological wellbeing (Mirvis & Hall, Journal of Organizational Behavior , 15 (4), 237–255, 1996 ; Wiese, Freund, & Baltes, Journal of Vocational Behavior , 60 (3), 321–335, 2002 ). Brougham and Haar, Journal of Management & Organization, 24 (2), 239–257 ( 2018 ) state that, in their research, greater STARA Smart Technology, Artificial Intelligence, Robotics and Algorithms (STARA) awareness was negatively correlated to organisational commitment Organisational commitment and career satisfaction Career satisfaction , and positively correlated to turnover intentions Turnover intention , cynicism and depression.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-28180-9_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-21836-2_7,"Fiction Meets Science: Ex Machina, Artificial Intelligence, and the Robotics Industry",Cyborg Futures,10.1007/978-3-030-21836-2_7,Springer,2019-01-01,"This chapter challenges the pronouncements that fiction is coming true that are so prevalent in the media and in the robotics and artificial intelligence (AI) industry. While this oft-repeated slogan fuels the corporate fantasy that there is no difference between machines and humans, I want to restore the gap between science and fiction by critiquing the metaphors and the circular logic at work in the industry and by considering how science and fiction differently imagine robots and AI. Resisting the reading of Ex Machina as a film that predicts the future of robotics/AI, I suggest it explores the shifting ground of what it is to be human in the early decades of the tech- and porn-fueled twenty-first century.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-21836-2_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-21836-2_6,"The Business of Ethics, Robotics, and Artificial Intelligence",Cyborg Futures,10.1007/978-3-030-21836-2_6,Springer,2019-01-01,"This chapter explores the rise of ethics as the discipline to address issues in robotics and artificial intelligence (AI). But why single out the discipline of “ethics”? I show how ethics is not a homogeneous, or unitary, body of knowledge, and that we have to pay attention to narratives in ethics that reproduce class and sex biases. In this sense, I focus on the theme of corporate and academic interest in the ethics of robots and AI, which, as I argue, is motivated by a metaphysical project to redefine the human as equivalent to a machine (robot) and to algorithmic programs (AI). I argue that the rejection of humans as distinct from machines represents the failure of mainstream philosophy to assimilate perspectives of class and sex into ethics as a body of knowledge that is capable of solving human crises. Rather than see ethics as neutral, I show a connection between corporate interest in ethics of robots and AI on the one hand, and the redefinition of the human on the other. I propose we should question ethical paradigms and ensure that feminist and class analyses are integrated into contemporary narratives of ethics of robots and AI.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-21836-2_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-01054-6_58,Our New Handshake with the Robot,Intelligent Systems and Applications,10.1007/978-3-030-01054-6_58,Springer,2019-01-01,"Very few topics in today’s digital conversations are more en vogue than Artificial Intelligence and Robotics. However, all too often, debate is centred on the machine and not the human side of this rapidly evolving handshake. This paper introduces a framework that structures the relationship from demystifying through to designing and adopting the handshake, and explores impact on enterprises and provides a future outlook.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-01054-6_58,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-29852-4_23,Cyber-Resilience Concept for Industry 4.0 Digital Platforms in the Face of Growing Cybersecurity Threats,Software Technology: Methods and Tools,10.1007/978-3-030-29852-4_23,Springer,2019-01-01,"Modern cyber systems acquire the more emergent system properties, as far as their complexity is being increased: cyber resilience, controllability, self-organization, proactive cyber security and adaptability. Each of the listed properties is the subject of the cybernetics research (comes from Greek κυβερνητική (kybernētikḗ) - the art of the governance) and each subsequent feature makes sense only if there is a previous one. This article presents a valuable experience and the exploratory study practical results of the Innopolis University Information Security Center on the scientific problem of the cyber-resilient critical information infrastructure organization under the conditions of previously unknown heterogeneous mass cyber attacks of intruders, based on similarity invariants. It is essential that the obtained results significantly complement the well-known practices and recommendations of ISO 22301 ( https://www.iso.org ), MITRE PR 15-1334 ( www.mitre.org ) and NIST SP 800-160 ( www.nist.gov ) in terms of developing the quantitative metrics and cyber resistance measures. This makes it possible for the first time to discover and formally present the ultimate efficiency law of the cyber resilience of modern Industry 4.0 systems under increasing security threats.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-29852-4_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-33229-7_15,Artificial Intelligence as a Competitive Advantage in the Manufacturing Area,Telematics and Computing,10.1007/978-3-030-33229-7_15,Springer,2019-01-01,"Since the beginning of the industrial revolution, manufacturing has gone through different stages: the 1st technological islands, 2nd the mass production, 3rd the lean manufacturing and the 4th IIoT (for the year 2025); we must keep in mind the leadership in the production of goods today what the Eastern countries have (and are using stage 3), so that the current guidelines have the necessary meaning, which establishes a new way of producing more as the potential of technologies that are in the process of maturation such as: Artificial Intelligence, Big Data, 3D Printing and Robotics; find original solutions to the problems of productivity, customization, just in time and services. Artificial Intelligence is taking a leading role in solving manufacturing problems, with the purpose of eliminating all those areas that are blindly worked, and that therefore it is not possible to improve by suffering from data to: analyze them, obtain information, establish controls and improve. The above is achieved by establishing disruptive technologies that take control in real time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-33229-7_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-97085-1_3,RobotCraft: The First International Collective Internship for Advanced Robotics Training,Robotics in Education,10.1007/978-3-319-97085-1_3,Springer,2019-01-01,"This paper describes a two-month summer collective internship conceived to provide a unique hands-on experience in robotics. The objective of the Robotics Craftsmanship International Academy, or RobotCraft for short, is to introduce higher education students in the full design cycle of a mobile robotic platform, providing training in computer-aided design (CAD), mechatronics, low-level programming of embedded systems, high-level development using the Robot Operating System (ROS), and artificial intelligence. This non-academic teaching, which successfully completed its second edition, already encompassed around 150 students and 100 universities, being evaluated by participants as challenging, engaging, and beneficial not only to their overall understanding of robotics, but also guiding them through their future academic and professional endeavors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-97085-1_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-22216-1_22,OSH and the Future of Work: Benefits and Risks of Artificial Intelligence Tools in Workplaces,"Digital Human Modeling and Applications in Health, Safety, Ergonomics and Risk Management. Human Body and Motion",10.1007/978-3-030-22216-1_22,Springer,2019-01-01,"There are significant possibilities for workplace progress and growth in productivity with the integration of artificial intelligence (AI) applications and tools in workplaces. However, there are also important occupational safety and health (OSH)-related questions arising as AI is integrated into workplaces. Stress, discrimination, heightened precariousness, musculoskeletal disorders, and the possibilities of work intensification and job losses have already been shown to pose psychosocial risks, including physical violence in digitalised workplaces. These risks are exacerbated when AI augments already existing technological tools or are newly introduced for workplace management and design. Indeed, AI exaggerates OSH risks in digitalised workplaces, because it can allow increased monitoring and tracking and thus may lead to micro-management, which a prime cause of stress and anxiety. AI stresses the imperative of giving more credibility and potentially authority to prediction machines, robotics and algorithmic processes at work. But it is worth stressing that it is not technology in isolation that creates OSH benefits or risks. It is instead the implementation of technologies that creates negative or positive conditions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-22216-1_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-94223-0_26,From Cognitive Modeling to Robotics: How Research on Human Cognition and Computational Cognitive Architectures can be Applied to Robotics Problems,Advances in Human Factors in Simulation and Modeling,10.1007/978-3-319-94223-0_26,Springer,2019-01-01,"Cognitive psychology and Artificial Intelligence (AI) have long been intertwined in the study of problem solving, learning, and perception. The early pioneers of AI, Herbert Simon and Allen Newell, drew as inspiration chess masters and from their study developed computer programs to mimic the problem solving abilities identified in chess masters. The understanding of chess strategies relied heavily upon characterizing the problem space as a combination of symbolic inference and statistical pattern matching, which allowed for a quick understanding of the environment by computer systems. Recently, robotics has emerged as an AI domain, and the problem space has proven a difficult one due to the sub-symbolic nature of the knowledge. As robotics has emerged as a field in AI, cognitive architecture researchers have continued to refine their understanding of cognition in new ways that allow for the duplication of human problem solving with limited resources. The goal of this manuscript is to inform the AI world of the successes cognitive architectures have produced with the hope that this knowledge can be transferred to AI, and more specifically, robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-94223-0_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-17649-5_20,The Frontiers of Neurosurgery,Fundamentals of Neurosurgery,10.1007/978-3-030-17649-5_20,Springer,2019-01-01,"Neurological surgery is a rapidly evolving medical field. Although relatively new, this medical specialty has experienced an unprecedented technological development. As we live the so-called fourth industrial revolution, neurosurgery seems to be following this revolution closely. It consists of robotics, artificial intelligence, nanotechnology, extensive study of epigenetics, tridimensional printing, big computer data, and automated machines, among others. This fascinating era has been reviewed in light of the fourth human revolution. The chapter is divided into various topics corresponding to different neurosurgical fields. Many recent advancements are presented, as well as what might be expected for doctors and patients. This chapter is based on current medical and technical literature, as we present today’s developments. Some topics allow us to predict what may be expected for us in the near future, since knowledge and technology have never developed so quickly.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-17649-5_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27544-0_18,From Commands to Goal-Based Dialogs: A Roadmap to Achieve Natural Language Interaction in RoboCup@Home,RoboCup 2018: Robot World Cup XXII,10.1007/978-3-030-27544-0_18,Springer,2019-01-01,"On the one hand, speech is a key aspect to people’s communication. On the other, it is widely acknowledged that language proficiency is related to intelligence. Therefore, intelligent robots should be able to understand, at least, people’s orders within their application domain. These insights are not new in RoboCup@Home, but we lack of a long-term plan to evaluate this approach. In this paper we conduct a brief review of the achievements on automated speech recognition and natural language understanding in RoboCup@Home. Furthermore, we discuss main challenges to tackle in spoken human-robot interaction within the scope of this competition. Finally, we contribute by presenting a pipelined road map to engender research in the area of natural language understanding applied to domestic service robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-27544-0_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-05921-7_14,Will Robin Ever Help “Nonna Lea” Using Artificial Intelligence?,Ambient Assisted Living,10.1007/978-3-030-05921-7_14,Springer,2019-01-01,"A new generation of Intelligent Robots are entering our working and living environments, Cesta, Amedeo taking care of human-level tasks. Such robotic systems are becoming more and more important also in healthcare assistance for elderly. Cortellessa, Gabriella Indeed, recent advancements in Artificial Intelligence and Robotics are fostering the diffusion of robotic agents with the capabilities needed to support both older adults and their caregivers in a variety of situations (e.g., in their homes, in hospitals, etc.). The capability of representing and reasoning about diverse kind of knowledge is crucial for allowing robotic assistants to understand the needs of the older persons as well as the status of the working environment. This paper presents a recent research initiative which aims at endowing autonomous robots with the capabilities needed to represent and reason on sensor data and to autonomously make decisions according Orlandini, Andrea to the inferred knowledge. The complete approach ends out being a cognitive control architecture, called Knowledge-based cOntinuous Loop (KOaLa) whose main aspect are described in this paper. Umbrico, Alessandro The application of KOaLa to our Robin telepresence robot is also exemplified to enhance the services of older people assistance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-05921-7_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-36211-9_8,A Computational Model for Distance Perception Based on Visual Attention Redeployment in Locomotor Infants,Applications of Computational Intelligence,10.1007/978-3-030-36211-9_8,Springer,2019-01-01,"Self-locomotion experience of infants has been argued to improve perception of distance, as visual attention is drawn to previously undetected or ignored depth specifying information. We present a computational model to evaluate how does self-locomotion experience influences the estimation of distance in infants. The model assigns an estimated distance label to salient objects in the scene, through a Binocular Neural Network (BNN) that computes binocular disparities. Emphasizing on key aspects of locomotion experience, two BNN are trained, one for non-locomotor infants and one for locomotor infants. The validation and test stages of the process show a significant improvement on the distance estimation task for the BNN trained with locomotor experience. This result is added to previous evidence which supports that locomotion in infants is an important step in cognitive development.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-36211-9_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-32281-6_13,Catheter Synthesis in X-Ray Fluoroscopy with Generative Adversarial Networks,Predictive Intelligence in Medicine,10.1007/978-3-030-32281-6_13,Springer,2019-01-01,"Accurate localization of catheters or guidewires in fluoroscopy images is important to improve the stability of intervention procedures as well as the development of surgical navigation systems. Recently, deep learning methods have been proposed to improve performance, however these techniques require extensive pixel-wise annotations. Moreover, the human annotation effort is equally expensive. In this study, we mitigate this labeling effort using generative adversarial networks (cycleGAN) wherein we synthesize realistic catheters in flouroscopy from localized guidewires in camera images whose annotations are cheaper to acquire. Our approach is motivated by the fact that catheters are tubular structures with varying profiles, thus given a guidewire in a camera image, we can obtain the centerline that follows the profile of a catheter in an X-ray image and create plausible X-ray images composited with such a centerline. In order to generate an image similar to the actual X-ray image, we propose a loss term that includes perceptual loss alongside the standard cycle loss. Experimental results show that the proposed method has better performance than the conventional GAN and generates images with consistent quality. Further, we provide evidence to the development of methods that leverage such synthetic composite images in supervised settings.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-32281-6_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-35699-6_25,A Real-Time Ball Detection Approach Using Convolutional Neural Networks,RoboCup 2019: Robot World Cup XXIII,10.1007/978-3-030-35699-6_25,Springer,2019-01-01,"Ball detection is one of the most important tasks in the context of soccer-playing robots. The ball is a small moving object which can be blurred and occluded in many situations. Several neural network based methods with different architectures are proposed to deal with the ball detection. However, they are either neglecting to consider the computationally low resources of humanoid robots or highly depend on manually-tuned heuristic methods to extract the ball candidates. In this paper, we propose a new ball detection method for low-cost humanoid robots that can detect most soccer balls with a high accuracy rate of up to 97.17%. The proposed method is divided into two steps. First, some coarse regions that may contain a full ball are extracted using an iterative method employing an efficient integral image based feature. Then they are fed to a light-weight convolutional neural network to finalize the bounding box of a ball. We have evaluated the proposed approach using a comprehensive dataset and the experimental results show the efficiency of our method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-35699-6_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-24741-6_4,Automatic Calibration of Artificial Neural Networks for Zebrafish Collective Behaviours Using a Quality Diversity Algorithm,Biomimetic and Biohybrid Systems,10.1007/978-3-030-24741-6_4,Springer,2019-01-01,"During the last two decades, various models have been proposed for fish collective motion. These models are mainly developed to decipher the biological mechanisms of social interaction between animals. They consider very simple homogeneous unbounded environments and it is not clear that they can simulate accurately the collective trajectories. Moreover when the models are more accurate, the question of their scalability to either larger groups or more elaborate environments remains open. This study deals with learning how to simulate realistic collective motion of collective of zebrafish, using real-world tracking data. The objective is to devise an agent-based model that can be implemented on an artificial robotic fish that can blend into a collective of real fish. We present a novel approach that uses Quality Diversity algorithms, a class of algorithms that emphasise exploration over pure optimisation. In particular, we use CVT-MAP-Elites [ 32 ], a variant of the state-of-the-art MAP-Elites algorithm [ 25 ] for high dimensional search space. Results show that Quality Diversity algorithms not only outperform classic evolutionary reinforcement learning methods at the macroscopic level (i.e. group behaviour), but are also able to generate more realistic biomimetic behaviours at the microscopic level (i.e. individual behaviour).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-24741-6_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-35166-3_28,Capturing Frame-Like Object Descriptors in Human Augmented Mapping,AI*IA 2019 – Advances in Artificial Intelligence,10.1007/978-3-030-35166-3_28,Springer,2019-01-01,"The model of an environment plays a crucial role in autonomous mobile robots, by providing them with the necessary task-relevant information. As robots become more intelligent, they need a richer and more expressive environment model. This model is a map that contains a structured description of the environment that can be used as the robot’s knowledge for several tasks, such as planning and reasoning. In this work, we propose a framework that allows to capture important environment descriptors, such as functionality and ownership of the robot’s surrounding objects, through verbal interaction. Specifically, we propose a corpus of verbal descriptions annotated with frame-like structures. We use the proposed dataset to train two multi-task neural architectures. We compare the two architectures through an experimental evaluation, discussing the design choices. Finally, we describe the creation of a simple interactive interface with our system, implemented through the trained model. The novelties of this work are: (i) the definition of a new problem, i.e., addressing different object descriptors, that plays a crucial role for the robot’s tasks accomplishment; (ii) a specialized corpus to support the creation of rich Semantic Maps; (iii) the design of different neural architectures, and their experimental evaluation over the proposed dataset; (iv) a simple interface for the actual usage of the proposed resources.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-35166-3_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-19591-5_18,Real-Time Emotional Recognition for Sociable Robotics Based on Deep Neural Networks Ensemble,Understanding the Brain Function and Emotions,10.1007/978-3-030-19591-5_18,Springer,2019-01-01,"Recognizing emotions in controlled conditions, based on facial expressions, has achieved high accuracies in the past years. This is still a challenging task for robots working in real-world scenarios due to different factors such as illumination, pose variation or occlusions. One of the next barriers of science is to give sociable robots the ability to fully engage in emotional interactions with users. In this paper a real-time emotion recognition system using a YOLO-based facial detection system and an ensemble CNN for sociable robots, is proposed. Experiments have been carried out on the most challenging database, FER 2013, giving a performance of 72.47% on test sets, achieving current standards.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-19591-5_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-10-8797-4_41,Application of Swarm Intelligence in Autonomous Cars for Obstacle Avoidance,"Integrated Intelligent Computing, Communication and Security",10.1007/978-981-10-8797-4_41,Springer,2019-01-01,"Obstacle detection is a major challenge which must be addressed for optimal implementation of self-driving cars. Various approaches have been postulated regarding the same. However, the acquisition of data by the various sensors in a car is shortsighted and constrained due the physical limitations in the scope of the sensors. In this chapter, we propose a model for obstacle avoidance in self-driving cars by integrating swarm intelligence with pre-existing conventional technologies. By establishing bi-directional communication of sensory data between the various cars which may form a network we can overcome the limitations faced by the receptors of a self-driving car.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-8797-4_41,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s41018-018-0045-4,Search and rescue with autonomous flying robots through behavior-based cooperative intelligence,Journal of International Humanitarian Action,10.1186/s41018-018-0045-4,Springer,2018-12-05,"A swarm of autonomous flying robots is implemented in simulation to cooperatively gather situational awareness data during the first few hours after a major natural disaster. In computer simulations, the swarm is successful in locating over 90% of survivors in less than an hour. The swarm is controlled by new sets of reactive behaviors which are presented and evaluated. The reactive behaviors integrate collision avoidance, battery recharge, formation control, altitude maintenance, and a variety of search methods to optimize the coverage area of camera and heart-beat locator sensors mounted on the robots. The behaviors are implemented in simulation on swarms of sizes from 1 to 20 robots. The simulation uses actual location data, including post-disaster satellite imagery, real locations of damaged and inundated buildings, and realistic victim locations based on personal interviews and accounts. The results demonstrate the value of using behavior-based swarming algorithms to control autonomous unmanned aerial vehicles for post-disaster search and assessment. Three examples of algorithms that have been effective in simulation are presented .",https://www.biomedcentral.com/openurl?doi=10.1186/s41018-018-0045-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s13640-018-0355-x,Research on multi-robot scheduling algorithms based on machine vision,EURASIP Journal on Image and Video Processing,10.1186/s13640-018-0355-x,Springer,2018-12-04,"In the multi-robot system, how to achieve effective and reasonable task coordination between multi-robots is an important problem;, multi-robot task scheduling is the term used for the coordination of the key technologies. Therefore, in this paper we combined the pilot scheduling method with the following method and the behavior method of the robot based on task scheduling, and we then studied how to improve the traditional robot scheduling effect, which is a deep-learning algorithm that is applied to multi-robot scheduling to formulate an action selection strategy. We thus proved the effectiveness of this idea experimentally. Based on the above research foundation, this paper continues to build a simple simulation experiment platform, which simply sets up three obstacles and completes the task of robot scheduling on the platform.",https://www.biomedcentral.com/openurl?doi=10.1186/s13640-018-0355-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11548-018-1860-1,Deep learning with convolutional neural network for objective skill evaluation in robot-assisted surgery,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-018-1860-1,Springer,2018-12-01,"Purpose With the advent of robot-assisted surgery, the role of data-driven approaches to integrate statistics and machine learning is growing rapidly with prominent interests in objective surgical skill assessment. However, most existing work requires translating robot motion kinematics into intermediate features or gesture segments that are expensive to extract, lack efficiency, and require significant domain-specific knowledge. Methods We propose an analytical deep learning framework for skill assessment in surgical training. A deep convolutional neural network is implemented to map multivariate time series data of the motion kinematics to individual skill levels. Results We perform experiments on the public minimally invasive surgical robotic dataset, JHU-ISI Gesture and Skill Assessment Working Set (JIGSAWS). Our proposed learning model achieved competitive accuracies of 92.5%, 95.4%, and 91.3%, in the standard training tasks: Suturing , Needle-passing , and Knot-tying , respectively. Without the need of engineered features or carefully tuned gesture segmentation, our model can successfully decode skill information from raw motion profiles via end-to-end learning. Meanwhile, the proposed model is able to reliably interpret skills within a 1–3 second window, without needing an observation of entire training trial. Conclusion This study highlights the potential of deep architectures for efficient online skill assessment in modern surgical training.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-018-1860-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13369-018-3267-2,Mobile Robot Navigation Using MLP-BP Approaches in Dynamic Environments,Arabian Journal for Science and Engineering,10.1007/s13369-018-3267-2,Springer,2018-12-01,"To find an optimal path for robots in an environment that is only partially known and continuously changing is a difficult problem. This paper presents a new method for generating a collision-free near-optimal path and speed for a mobile robot in a dynamic environment containing moving and static obstacles using artificial neural network. For each robot motion, the workspace is divided into five equal segments. The multilayer perceptron neural network is used to choose a collision-free segment and also controls the speed of the robot for each motion. Experimental results show that the method is efficient and gives near-optimal path reaching the target position of the mobile robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13369-018-3267-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40314-017-0538-6,Adaptive robust control strategy for rhombus-type lunar exploration wheeled mobile robot using wavelet transform and probabilistic neural network,Computational and Applied Mathematics,10.1007/s40314-017-0538-6,Springer,2018-12-01,"In this paper, we propose a stable tracking control rule for rhombus-type lunar exploration wheeled mobile robot (RLEWMR) with completely unknown dynamics and unmodeled disturbance. The control system adopts a wavelet transform and probabilistic neural network (WTPNN) with accurate approximation capability to represent the unknown dynamics of the RLEWMR, and it also uses an adaptive robust compensator to confront the inevitable approximation errors due to the finite number of wavelet bases functions and to disturbances. Adaptive learning algorithms are proposed to learn the parameters of WTPNN weight and robust compensator on line. Based on the Lyapunov stability theorem, the tracking stability of the closed-loop system, the convergence of the WTPNN weight-updating process, and boundedness of WTPNN weight estimation errors are all guaranteed. The effectiveness and efficiency of the proposed controller is demonstrated by simulation and experiment studies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40314-017-0538-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11036-018-1110-3,Telesurgery Robot Based on 5G Tactile Internet,Mobile Networks and Applications,10.1007/s11036-018-1110-3,Springer,2018-12-01,"With the development of modern medical technology, the emerging 5G, tactile Internet, robot, and artificial intelligence technology have enabled the interdisciplinary innovations facilitating the development of the surgical treatment technology, and enhancing the treatment efficiency of various diseases. In the medical field, the introduction of robot technology has contributed to the telesurgery. Moreover, the telesurgery robot allocated with the 5G tactile Internet as infrastructure, and AI technology as core competitiveness can promote the audio, visual and tactile perceptions of a doctor during the surgery process and solve the problems of resource scheduling; accordingly, it has become the research hotspot. Therefore, this paper introduces a telesurgery robot based on the 5G tactile Internet and artificial intelligence technology. The architecture, composition, characteristics, and advantages of telesurgery are explained in detail from two aspects, the intelligent tactile feedback, and human-machine interaction data. On this basis, a human-machine interaction optimization scheme during the telesurgery process is presented from four aspects, i.e., Edge-Cloud Integration, network slice, and intelligent edge-cloud. Finally, this paper discusses the open issues of the presented telesurgery system regarding the ultra-high reliability, AI-enabled surgery robot, communication, and security, to provide the reference for the promotion of the telesurgery robot performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11036-018-1110-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-018-0182-y,View-point Invariant 3D Classification for Mobile Robots Using a Convolutional Neural Network,"International Journal of Control, Automation and Systems",10.1007/s12555-018-0182-y,Springer,2018-12-01,"3D object classification is an important component in semantic scene understanding for mobile robots. However, many current systems do not consider the practical issues such as object representation from different viewing positions of mobile robots. A novel 3D object representation is introduced using cylindrical occupancy grid and 3D convolutional neural network with row-wise max pooling layer. Due to the rotationally invariant characteristics of this method, robots can successfully classify 3D objects regardless of starting positions of object modelling. Experimental results on publicly available benchmark dataset show the significantly improved performance compared with other conventional algorithms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-018-0182-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-018-0456-8,A dung beetle-inspired robotic model and its distributed sensor-driven control for walking and ball rolling,Artificial Life and Robotics,10.1007/s10015-018-0456-8,Springer,2018-12-01,"A typical approach when designing a bio-inspired robot is to simplify an animal model and to enhance the functionality of interest. For hexapod robots, this often leads to a need of supplementary mechanics to become multifunctional. However, a preferable solution is to employ the embodied multifunctional capabilities of the animal as inspiration for robot design. Using this approach, we present a method for translating the kinematic chain of a dung beetle from which an accurate kinematic model and a simplified one were simulated and compared. The beetle was selected due to its multifunctional locomotory capabilities including walking as well as standing on and rolling a ball. For testing the models, we developed a distributed sensor-driven controller that can generate walking and ball-rolling behaviors. A comparison of the two modeling approaches shows a similar performance with regards to walking stability and accuracy, but differences when it comes to speed and multifunctionality. This is because the accurate model is able to use its legs to walk faster and roll a ball, which the simplified one is not. In conclusion, the accurate model of a dung beetle-inspired robot is advantageous as it, together with our novel control mechanism, is able to elicit behaviors comparable to those of the real dung beetle (i.e., walking and rolling a dung ball).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-018-0456-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13369-018-3295-y,An Asymptotically Stable Control Scheme for Space Robot System,Arabian Journal for Science and Engineering,10.1007/s13369-018-3295-y,Springer,2018-12-01,"In this manuscript, an asymptotically stable control scheme is designed for space robot system. The space robot systems are highly uncertain systems and face structured/unstructured uncertainties, unbounded disturbances and unpredictable environment interference. The inability of model-based control schemes for such uncertain systems is improved by combining with neural network-based model-free scheme together with an adaptive bound. The proposed controller achieves the desired trajectory tracking adequately. The unknown dynamics of the system is approximated with RBF neural network without the requirement of offline learning. To recompense the effect of approximation error and unknown bound on uncertainties, the adaptive bound part of the controller is utilized. In the proposed approach, we do not need joint acceleration measurements. The Lyapunov function approach is utilized to show that the proposed controller is stable and the errors are asymptotically convergent. Finally, the numerical simulation studies are performed to validate the proposed approach and the effectiveness is shown in a comparative manner with various existing controllers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13369-018-3295-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-018-0558-4,Unsupervised Human Activity Analysis for Intelligent Mobile Robot,KI - Künstliche Intelligenz,10.1007/s13218-018-0558-4,Springer,2018-11-01,"The success of intelligent mobile robots operating and collaborating with humans in daily living environments depends on their ability to generalise and learn human movements, and obtain a shared understanding of an observed scene. In this thesis we aim to understand human activities being performed in real-world environments from long-term observation from an autonomous mobile robot. A number of qualitative spatial–temporal representations are used to capture different aspects of the relations between human subjects and their environment. Analogous to information retrieval on text corpora, a generative probabilistic technique is used to recover latent, semantically-meaningful concepts in the encoded observations in an unsupervised manner. The small number of concepts discovered are considered as human activity classes, granting the robot a low-dimensional understanding of visually observed complex scenes. Finally, variational inference is used to facilitate incremental updating of such concepts allowing for efficient learning and updating of human activity models over time, resulting in efficient life-long learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-018-0558-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-018-0553-9,AI and Robotics for the Human Brain Project II,KI - Künstliche Intelligenz,10.1007/s13218-018-0553-9,Springer,2018-11-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-018-0553-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11548-018-1833-4,Modular force approximating soft robotic pneumatic actuator,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-018-1833-4,Springer,2018-11-01,"Purpose Soft robots are highly flexible and adaptable instruments that have proven extremely useful, especially in the surgical environment where compliance allows for improved maneuverability throughout the body. Endoscopic devices are a primary example of an instrument that physicians use to navigate to difficult-to-reach areas inside the body. This paper presents a modular soft robotic pneumatic actuator as a proof of concept for a compliant endoscopic device. Methods The actuator is 3D printed using an FDM printer. Maximum bending angle is measured using image processing in MATLAB at a gauge pressure level of 35 psi. End-effector displacement is measured using electromagnetic tracking as gauge pressure ranges from 10 to 35 psi, and uniaxial tensile loading ranges from 0 to 120 g. Results The actuator achieves a maximum bending angle of 145°. Fourth-order polynomial regression is used to model the actuator displacement upon inflation and tensile loading with an average coefficient of correlation value of 0.998. We also develop a feedforward neural network as a robust computer-assisted method for controlling the actuator that achieves a coefficient of correlation value of 0.996. Conclusion We propose a novel modular soft robotic pneumatic actuator that is developed via rapid prototyping and evaluated using image processing and machine learning models. The curled resting shape allows for simple manufacturing and achieves a greater range of bending than other actuators of its kind. A feedforward neural network provides accurate prediction of end-effector displacement upon inflation and loading to deliver precise manipulation and control.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-018-1833-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/s41586-018-0412-8,Publisher Correction: Controlling an organic synthesis robot with machine learning to search for new reactivity,Nature,10.1038/s41586-018-0412-8,Nature,2018-10-25,The chemical structure formatting in Fig. 5 has been corrected online.,https://www.nature.com/articles/s41586-018-0412-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00779-018-1154-1,Deep learning over IoT big data-based ubiquitous parking guidance robot for parking near destination especially hospital,Personal and Ubiquitous Computing,10.1007/s00779-018-1154-1,Springer,2018-10-01,"This paper offered a ubiquitous parking guidance robot system used for assisting drivers in selection of parking lots near their destination locations and recommending the parking lot with optimum conditions based on the forecast results by deep learning the big data of parking lots obtained through Internet of Things, which not only decreased the cost and the required time of parking, but also reduced the parking failure by a relatively accurate guidance way, and is important for drivers to save time on parking when drivers hurry to their destination locations such as hospital. The ubiquitous parking guidance robot system can be implemented as parking guidance apps or parking guidance plugins of navigation apps installed in drivers’ mobile phones. Drivers can independently set their filtering criteria of guidance, and then the parking lot with the optimum conditions such as shortest distance, largest number of parking spaces and best environment will be recommended.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00779-018-1154-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12206-018-0941-y,A study on the optimal route design considering time of mobile robot using recurrent neural network and reinforcement learning,Journal of Mechanical Science and Technology,10.1007/s12206-018-0941-y,Springer,2018-10-01,"Recently, the robots market is growing rapidly, and robots are being applied in various industrial fields. In the future, robots will work in more complex and diverse environments. For example, a robot can perform one or more tasks and collaborate with people or other robots. In this situation, the path planning for the robots to perform their tasks efficiently is an important issue. In this study, we assume that the mobile robot performs one or more tasks, moves various places freely, and works with other robots. In this situation, if the path of the mobile robot is planned with the shortest path algorithm, waiting time may occur because the planned path is blocked by other robots. Sometimes it is possible to complete a task in a shorter time than returning or performing another task first. That is, the shortest path and the shortest path do not coincide with each other. The purpose of this study is to construct a network in which the mobile robot designs the shortest path planning considering shortest time by judging itself based on environment information and path planning information of other robots. For this purpose, a network is constructed using a recurrent neural network and reinforcement learning is used. We established the environment for network learning using the robot simulation program, V-Rep. We compare the effects of various network structures and select network models that meet the purpose. In the future work, we will try to prove the effect of network by comparing existing algorithm and network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12206-018-0941-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11633-018-1130-2,Software for Small-scale Robotics: A Review,International Journal of Automation and Computing,10.1007/s11633-018-1130-2,Springer,2018-10-01,"In recent years, a large number of relatively advanced and often ready-to-use robotic hardware components and systems have been developed for small-scale use. As these tools are mature, there is now a shift towards advanced applications. These often require automation and demand reliability, efficiency and decisional autonomy. New software tools and algorithms for artificial intelligence (AI) and machine learning (ML) can help here. However, since there are many software-based control approaches for small-scale robotics, it is rather unclear how these can be integrated and which approach may be used as a starting point. Therefore, this paper attempts to shed light on existing approaches with their advantages and disadvantages compared to established requirements. For this purpose, a survey was conducted in the target group. The software categories presented include vendor-provided software, robotic software frameworks (RSF), scientific software and in-house developed software (IHDS). Typical representatives for each category are described in detail, including SmarAct precision tool commander, MathWorks Matlab and national instruments LabVIEW, as well as the robot operating system (ROS). The identified software categories and their representatives are rated for end user satisfaction based on functional and non-functional requirements, recommendations and learning curves. The paper concludes with a recommendation of ROS as a basis for future work.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11633-018-1130-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00422-018-0775-9,Application of chaos in a recurrent neural network to control in ill-posed problems: a novel autonomous robot arm,Biological Cybernetics,10.1007/s00422-018-0775-9,Springer,2018-10-01,"Inspired by a viewpoint that complex/chaotic dynamics would play an important role in biological systems including the brain, chaotic dynamics introduced in a recurrent neural network was applied to robot control in ill-posed situations. By computer experiments we show that a model robot arm without an advanced visual processing function can catch a target object and bring it to a set position under ill-posed situations (e.g., in the presence of unknown obstacles). The key idea in these works is adaptive switching of a system parameter (connectivity) between a chaos regime and attractor regime in a neural network model, which generates, depending on environmental circumstances, either chaotic motions or definite motions corresponding to embedded attractors. The adaptive switching results in useful functional motions of the robot arm. These successful experiments indicate that chaotic dynamics is potentially useful for practical engineering control applications. In addition, this novel autonomous arm system is implemented in a hardware robot arm that can avoid obstacles and reach for a target in a situation where the robot can get only rough target information, including uncertainty, by means of a few sensors, as indicated in the appendix, A1 and A2 .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00422-018-0775-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41649-018-0061-0,The “Use” of Sex Robots: A Bioethical Issue,Asian Bioethics Review,10.1007/s41649-018-0061-0,Springer,2018-10-01,"The manufacture of humanoid robots with embedded artificial intelligence and for sexual purposes has generated some debates within bioethics, in which diverse competing views have been presented. Themes such as sexuality and its deviations, the objectification of women, the relational problems of contemporary life, loneliness, and even the reproductive future of the species constitute the arguments which have emerged in relation to this subject. Based on these themes, this article presents the current state of the use of female sex robots, the bioethical problems that arise, and how bioethics could serve as a medium for both thinking about and resolving some of these challenges.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41649-018-0061-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-018-0258-9,Common sounds in bedrooms (CSIBE) corpora for sound event recognition of domestic robots,Intelligent Service Robotics,10.1007/s11370-018-0258-9,Springer,2018-10-01,"Although sound event recognition attracted much attention in the scientific community, applications in the robotics domain have not been in the focus. A new database was published in this paper and classifiers were evaluated with this dataset to guide the future practical developments of domestic robots. A corpus (CSIBE-RAW) was collected from the internet to build acoustic models to recognize 13 sound events and omit ambient sounds. As a case study, CSIBE-RAW was rerecorded in four room settings (CSIBE-AIBO) to create reverberation-tolerant classifiers for a Sony ERS-7. After eight classifiers were reviewed, the convolutional neural network achieved the best accuracy (95.07%) after multi-conditional learning and it was suitable for real-time classification on the robot. The effects of lossy audio codecs were studied, lossy encoder-tolerant audio statistics were specified for the feature vector and the Ogg Vorbis encoder with 128 kbit VBR was found superior to store big data and avoid any significant accuracy loss with the compression ratio 1:8.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-018-0258-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-017-0743-y,Wall-following and Navigation Control of Mobile Robot Using Reinforcement Learning Based on Dynamic Group Artificial Bee Colony,Journal of Intelligent & Robotic Systems,10.1007/s10846-017-0743-y,Springer,2018-10-01,"This study proposes an efficient wall-following and navigation control model that includes three control modes, namely w all- f ollowing (WF), t oward- g oal (TG), and b ehavior m anager (BM). To achieve an adaptive controller for WF mode, an efficient r ecurrent f uzzy c erebellar m odel a rticulation c ontroller (RFCMAC) based on d ynamic g roup a rtificial b ee c olony (DGABC) is proposed for implementing reinforcement learning process. The fitness function includes four assessment factors which are defined as follows: (1) maintaining safe distance between the mobile robot and the wall; (2) ensuring successfully running a cycle; (3) avoiding mobile robot collisions; (4) mobile robot running at a maximum speed. Moreover, the BM is used to switch WF mode and TG mode, and is employed as an escape mechanism based on the relationship between the robot and the environment. The experimental results show that the proposed DGABC is more effective than the traditional ABC in WF mode. The proposed control method also obtains a better navigation control than other methods in unknown environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-017-0743-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11633-018-1128-9,Learning to Transform Service Instructions into Actions with Reinforcement Learning and Knowledge Base,International Journal of Automation and Computing,10.1007/s11633-018-1128-9,Springer,2018-10-01,"In order to improve the learning ability of robots, we present a reinforcement learning approach with a knowledge base for mapping natural language instructions to executable action sequences. A simulated platform with physical engine is built as interactive environment. Based on the knowledge base, a reward function with immediate rewards and delayed rewards is designed to handle sparse reward problems. Also, a list of object states is produced by retrieving the knowledge base, as a standard to define the quality of action sequences. Experimental results demonstrate that our approach yields good performance on accuracy of action sequences production.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11633-018-1128-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-017-9608-9,Extension of grounding mechanism for abstract words: computational methods insights,Artificial Intelligence Review,10.1007/s10462-017-9608-9,Springer,2018-10-01,"The attempts to model cognitive phenomena effectively have split the research community in two paradigms: symbolic and connectionist. The extension of grounding phenomenon for abstract words is very important for social interactions of cognitive robots in real scenarios. This paper reviews the strength of symbolic and connectionist methods to address the abstract word grounding problem in cognitive robots. In particular, the presented work is focused on designing and simulating cognitive robotics model to achieve a grounding mechanism for abstract words by using the semantic network approach, as well as examining the utility of connectionist computation for the same problem. Two neuro-robotics models based on feed forward neural network and recurrent neural network are presented to see the pros and cons of connectionist approach. The simulation results and review of attributes of these methods reveal that the proposed symbolic model offers the solution to the problem of grounding abstract words with attributes like high data storage capacity with recall accuracy, structural integrity and temporal sequence handling. Whereas, connectionist computation based solutions give more natural solution to this problem with some shortcomings that include combinatorial ambiguity, low storage capacity and structural rigidity. The presented results are not only important for the advancement in communication system of cognitive robot, also provide evidence for embodied nature of abstract language.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10462-017-9608-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11948-017-9975-2,The Ugly Truth About Ourselves and Our Robot Creations: The Problem of Bias and Social Inequity,Science and Engineering Ethics,10.1007/s11948-017-9975-2,Springer,2018-10-01,"Recently, there has been an upsurge of attention focused on bias and its impact on specialized artificial intelligence (AI) applications. Allegations of racism and sexism have permeated the conversation as stories surface about search engines delivering job postings for well-paying technical jobs to men and not women, or providing arrest mugshots when keywords such as “black teenagers” are entered. Learning algorithms are evolving; they are often created from parsing through large datasets of online information while having truth labels bestowed on them by crowd-sourced masses. These specialized AI algorithms have been liberated from the minds of researchers and startups, and released onto the public. Yet intelligent though they may be, these algorithms maintain some of the same biases that permeate society. They find patterns within datasets that reflect implicit biases and, in so doing, emphasize and reinforce these biases as global truth. This paper describes specific examples of how bias has infused itself into current AI and robotic systems, and how it may affect the future design of such systems. More specifically, we draw attention to how bias may affect the functioning of (1) a robot peacekeeper, (2) a self-driving car, and (3) a medical robot. We conclude with an overview of measures that could be taken to mitigate or halt bias from permeating robotic technology.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-017-9975-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11633-018-1139-6,A Selective Attention Guided Initiative Semantic Cognition Algorithm for Service Robot,International Journal of Automation and Computing,10.1007/s11633-018-1139-6,Springer,2018-10-01,"With the development of artificial intelligence and robotics, the study on service robot has made a significant progress in recent years. Service robot is required to perceive users and environment in unstructured domestic environment. Based on the perception, service robot should be capable of understanding the situation and discover service task. So robot can assist humans for home service or health care more accurately and with initiative. Human can focus on the salient things from the mass observation information. Humans are capable of utilizing semantic knowledge to make some plans based on their understanding of the environment. Through intelligent space platform, we are trying to apply this process to service robot. A selective attention guided initiatively semantic cognition algorithm in intelligent space is proposed in this paper. It is specifically designed to provide robots with the cognition needed for performing service tasks. At first, an attention selection model is built based on saliency computing and key area. The area which is highly relevant to service task could be located and referred as focus of attention (FOA). Second, a recognition algorithm for FOA is proposed based on a neural network. Some common objects and user behavior are recognized in this step. At last, a unified semantic knowledge base and corresponding reasoning engine is proposed using recognition result. Related experiments in a real life scenario demonstrated that our approach is able to mimic the recognition process in humans, make robots understand the environment and discover service task based on its own cognition. In this way, service robots can act smarter and achieve better service efficiency in their daily work.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11633-018-1139-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/s41598-018-32757-9,A soft artificial muscle driven robot with reinforcement learning,Scientific Reports,10.1038/s41598-018-32757-9,Nature,2018-09-28,"Soft robots driven by stimuli-responsive materials have their own unique advantages over traditional rigid robots such as large actuation, light weight, good flexibility and biocompatibility. However, the large actuation of soft robots inherently co-exists with difficulty in control with high precision. This article presents a soft artificial muscle driven robot mimicking cuttlefish with a fully integrated on-board system including power supply and wireless communication system. Without any motors, the movements of the cuttlefish robot are solely actuated by dielectric elastomer which exhibits muscle-like properties including large deformation and high energy density. Reinforcement learning is used to optimize the control strategy of the cuttlefish robot instead of manual adjustment. From scratch, the swimming speed of the robot is enhanced by 91% with reinforcement learning, reaching to 21 mm/s (0.38 body length per second). The design principle behind the structure and the control of the robot can be potentially useful in guiding device designs for demanding applications such as flexible devices and soft robots.",https://www.nature.com/articles/s41598-018-32757-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s40648-018-0118-6,Detection of object arrangement patterns using images for robot picking,ROBOMECH Journal,10.1186/s40648-018-0118-6,Springer,2018-09-10,"This paper focuses on robot picking of objects in warehouses and stores. Objects are often regularly stacked or aligned in specific arrangement patterns to increase storage efficiency. There are typical patterns in arrangement patterns. A specific picking strategy set is often linked to specific arrangement patterns. By linking the arrangement patterns of various object categories to picking strategy sets, the picking performance of a robot is expected to improve. In this paper, we propose a method in which groups of regularly arranged objects are detected from an image, and the arrangement pattern of each group is identified. In this paper, we describe the effectiveness of the proposed method based on experiment results for “book” as the target.",https://www.biomedcentral.com/openurl?doi=10.1186/s40648-018-0118-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.3103/S0146411618050024,Integration of Computervision and Artificial Intelligence Subsystems with Robot Operating System Based Motion Planning for Industrial Robots,Automatic Control and Computer Sciences,10.3103/S0146411618050024,Springer,2018-09-01,"Abstract The paper proposes flexible system that is based on Robot Operating System framework for integration of 3D computer vision and artificial intelligence algorithms with industrial robots for automation of industrial tasks. The system provides flexibility of 3D computer vision hardware and industrial robot components, allowing to test different hardware with small software changes. The experimental system consisting of Kinect V2 RGB+Depth camera and Universal Robots UR5 robot was set up. In experimental setup the pick and place task was implemented where randomly organized two types of objects (tubes and cans) where picked from the container and sorted in two separate containers. Average full cycle time for the task was measured to be 19.675 s.",http://link.springer.com/openurl/fulltext?id=doi:10.3103/S0146411618050024,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-017-0445-4,The More the Merrier? Effects of Humanlike Learning Abilities on Humans’ Perception and Evaluation of a Robot,International Journal of Social Robotics,10.1007/s12369-017-0445-4,Springer,2018-09-01,"In this paper, we present three experimental studies in which subjects trained a robot to do a card game via reinforcement learning. In the first two studies participants interacted with the robot either without any learning ability (control group) or with one out of three versions of a learning algorithm implementing gradually aspects of more humanlike learning abilities. Results show that the implementation of a learning algorithm had positive effects regarding the evaluation of the robot, its learning abilities and the interaction. We found that more humanlike learning abilities do not always lead to better performance and evaluation and that results were to some extend influenced by longer or shorter interaction times. In a third study, we additionally explored the influence of other behavioral variations such as low or high verbal skills and interaction modalities in perceived intelligence of the robot irrespective of the implemented learning algorithm, but did not find significant effects. Results are discussed with regard to the socialness of future interaction scenarios.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-017-0445-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11277-018-5247-y,A Minimal Dataset Construction Method Based on Similar Training for Capture Position Recognition of Space Robot,Wireless Personal Communications,10.1007/s11277-018-5247-y,Springer,2018-09-01,"Recognizing capture position for non-cooperative targets is an important component of on-orbit service. Traditional machine learning works could not satisfy the requirements of space mission, which demands universality, accuracy and real-time performance. To meet those requirements, an innovative job based on deep learning called Faster Region-based Convolutional Neural Network (Faster RCNN) is introduced for space robot capture position recognizing. Based on the principle of similar training, a minimal dataset construction trick is proposed in order to solve the problem of fewer training samples in space environment. Firstly, the Deep Neural Network is pre-trained through ImageNet training set. Then, using the trained weights as the initial weight of the network, the network is fine-tuned by 1000 training samples in space environment. Finally, a simulation experiment is designed, and the experimental results indicate that the similar training principle can solve the problem of capture position recognition of non-cooperative targets.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11277-018-5247-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-018-0445-y,Neural networks IC controlled multi-legged walking MEMS robot with independent leg mechanism,Artificial Life and Robotics,10.1007/s10015-018-0445-y,Springer,2018-09-01,"In this paper, we will compare the walking behavior of quadruped and hexapod walking MEMS robots. These robots are fabricated by connecting same modules, which are composed of a couple of independent leg mechanisms. Independent leg mechanisms can actuate the single leg by a single artificial muscle wire. The neural networks IC that mimics real living organisms controls the mechanical systems. The length and weight of the quadruped MEMS robot were 7.2 mm and 95.8 mg, respectively. The quadruped robot showed the walking speed of 24.6 mm/min. The robot tended to lose its balance and the weight balance is quite important for the moving quadruped. On the other hand, the length and weight of the hexapod MEMS robot were 9.0 mm and 162 mg, respectively. The hexapod robot showed stable walking. The speed was 27.0 mm/min.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-018-0445-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.3103/S1068798X18090150,Drone-Based Autonomous Robot Diagnostic System for Gas and Oil Pipelines in the Arctic and Far North,Russian Engineering Research,10.3103/S1068798X18090150,Springer,2018-09-01,A drone-based autonomous robot diagnostic system for gas and oil pipelines in the Arctic and Far North has been developed.,http://link.springer.com/openurl/fulltext?id=doi:10.3103/S1068798X18090150,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10151-018-1847-5,"Robotics, artificial intelligence and distributed ledgers in surgery: data is key!",Techniques in Coloproctology,10.1007/s10151-018-1847-5,Springer,2018-09-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10151-018-1847-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11263-018-1102-6,Virtual Training for a Real Application: Accurate Object-Robot Relative Localization Without Calibration,International Journal of Computer Vision,10.1007/s11263-018-1102-6,Springer,2018-09-01,"Localizing an object accurately with respect to a robot is a key step for autonomous robotic manipulation. In this work, we propose to tackle this task knowing only 3D models of the robot and object in the particular case where the scene is viewed from uncalibrated cameras—a situation which would be typical in an uncontrolled environment, e.g., on a construction site. We demonstrate that this localization can be performed very accurately, with millimetric errors, without using a single real image for training, a strong advantage since acquiring representative training data is a long and expensive process. Our approach relies on a classification Convolutional Neural Network trained using hundreds of thousands of synthetically rendered scenes with randomized parameters. To evaluate our approach quantitatively and make it comparable to alternative approaches, we build a new rich dataset of real robot images with accurately localized blocks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11263-018-1102-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-017-0731-2,Heuristically Accelerated Reinforcement Learning by Means of Case-Based Reasoning and Transfer Learning,Journal of Intelligent & Robotic Systems,10.1007/s10846-017-0731-2,Springer,2018-08-01,"Reinforcement Learning (RL) is a well-known technique for learning the solutions of control problems from the interactions of an agent in its domain. However, RL is known to be inefficient in problems of the real-world where the state space and the set of actions grow up fast. Recently, heuristics, case-based reasoning (CBR) and transfer learning have been used as tools to accelerate the RL process. This paper investigates a class of algorithms called Transfer Learning Heuristically Accelerated Reinforcement Learning (TLHARL) that uses CBR as heuristics within a transfer learning setting to accelerate RL. The main contributions of this work are the proposal of a new TLHARL algorithm based on the traditional RL algorithm Q ( λ ) and the application of TLHARL on two distinct real-robot domains: a robot soccer with small-scale robots and the humanoid-robot stability learning. Experimental results show that our proposed method led to a significant improvement of the learning rate in both domains.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-017-0731-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11948-017-9932-0,Why We Should Create Artificial Offspring: Meaning and the Collective Afterlife,Science and Engineering Ethics,10.1007/s11948-017-9932-0,Springer,2018-08-01,"This article argues that the creation of artificial offspring could make our lives more meaningful (i.e. satisfy more meaning-relevant conditions of value). By ‘artificial offspring’ I mean beings that we construct, with a mix of human and non-human-like qualities. Robotic artificial intelligences are paradigmatic examples of the form. There are two reasons for thinking that the creation of such beings could make our lives more meaningful and valuable. The first is that the existence of a collective afterlife—i.e. a set of human-like lives that continue after we die—is likely to be an important source and sustainer of meaning in our present lives (Scheffler in Death and the afterlife, OUP, Oxford, 2013 ). The second is that the creation of artificial offspring provides a plausible and potentially better pathway to a collective afterlife than the traditional biological pathway (i.e. there are reasons to favour this pathway and there are no good defeaters to trying it out). Both of these arguments are defended from a variety of objections and misunderstandings.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-017-9932-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-017-0727-y,Dimitri: an Open-Source Humanoid Robot with Compliant Joint,Journal of Intelligent & Robotic Systems,10.1007/s10846-017-0727-y,Springer,2018-08-01,"We introduce Dimitri, an open-software & open-hardware humanoid robot with 31 DOFs, fitted with cost-effective modular compliant joints and parallel link legs, designed for advanced human-robot interaction research, force-informed object handling and intelligent environment discovery. Our main innovation is in the design of a robust full-body biped humanoid robot equipped with very low-cost polyurethane torsional spring fixed to traditional servo motors and a circuit to measure angular displacement, transforming the system into a series elastic actuator (SEA). In order to illustrate the robot’s qualities in the field of machine learning applied to robotics and manipulation, a multiple timescale recurrent neural network (MTRNN) is implemented, allowing the robot to replicate combined movement sequences earlier taught via interactive demonstration.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-017-0727-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00422-018-0758-x,Modeling and analysis of a new locomotion control neural networks,Biological Cybernetics,10.1007/s00422-018-0758-x,Springer,2018-08-01,"Experimental data have shown that inherent bursting of the neuron plays an important role in the generation of rhythmic movements in spinal networks. Based on the mechanism that the spinal neurons of a lamprey generate this inherent bursting, this paper builds a simplified inherent bursting neuron model. A new locomotion control neural network is built that takes advantage of this neuron model and its performance is analyzed mathematically and by numerical simulation. From these analyses, it is found that the new control networks have no restriction on their topological structure for generating the oscillatory outputs. If a network is used to control the motion of bionic robots or build the model of the vertebrate spinal circuitry, its topological structure can be constructed using the unit burst generator model proposed by Grillner. The networks can also be easily switched between oscillatory and non-oscillatory output. Additionally, inactivity and saturation properties of the new networks can also be developed, which will be helpful to increase the motor flexibility and environmental adaptability of bionic robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00422-018-0758-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/s41586-018-0307-8,Controlling an organic synthesis robot with machine learning to search for new reactivity,Nature,10.1038/s41586-018-0307-8,Nature,2018-07-19,"A robot instructed by a machine learning algorithm and coupled with real-time spectroscopic systems provides fast and accurate reaction outcome predictions and reactivity assessments, leading to the discovery of new reactions. The discovery of chemical reactions is an inherently unpredictable and time-consuming process^ 1 . An attractive alternative is to predict reactivity, although relevant approaches, such as computer-aided reaction design, are still in their infancy^ 2 . Reaction prediction based on high-level quantum chemical methods is complex^ 3 , even for simple molecules. Although machine learning is powerful for data analysis^ 4 , 5 , its applications in chemistry are still being developed^ 6 . Inspired by strategies based on chemists’ intuition^ 7 , we propose that a reaction system controlled by a machine learning algorithm may be able to explore the space of chemical reactions quickly, especially if trained by an expert^ 8 . Here we present an organic synthesis robot that can perform chemical reactions and analysis faster than they can be performed manually, as well as predict the reactivity of possible reagent combinations after conducting a small number of experiments, thus effectively navigating chemical reaction space. By using machine learning for decision making, enabled by binary encoding of the chemical inputs, the reactions can be assessed in real time using nuclear magnetic resonance and infrared spectroscopy. The machine learning system was able to predict the reactivity of about 1,000 reaction combinations with accuracy greater than 80 per cent after considering the outcomes of slightly over 10 per cent of the dataset. This approach was also used to calculate the reactivity of published datasets. Further, by using real-time data from our robot, these predictions were followed up manually by a chemist, leading to the discovery of four reactions.",https://www.nature.com/articles/s41586-018-0307-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/d41586-018-05776-9,Listen: AI robot mixes chemicals to discover reactions,Nature,10.1038/d41586-018-05776-9,Nature,2018-07-18,"Automated machine conducts, assesses and learns from experiments with random reagents. Automated machine conducts, assesses and learns from experiments with random reagents.",https://www.nature.com/articles/d41586-018-05776-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10677-018-9909-3,"Lin, P., Abney, K., & Jenkins, R. (Eds.): Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence",Ethical Theory and Moral Practice,10.1007/s10677-018-9909-3,Springer,2018-06-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10677-018-9909-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-017-9670-9,Early prediction for physical human robot collaboration in the operating room,Autonomous Robots,10.1007/s10514-017-9670-9,Springer,2018-06-01,"To enable a natural and fluent human robot collaboration flow, it is critical for a robot to comprehend their human peers’ on-going actions, predict their behaviors in the near future, and plan its actions correspondingly. Specifically, the capability of making early predictions is important, so that the robot can foresee the precise timing of a turn-taking event and start motion planning and execution early enough to smooth the turn-taking transition. Such proactive behavior would reduce human’s waiting time, increase efficiency and enhance naturalness in collaborative task. To that end, this paper presents the design and implementation of an early turn-taking prediction algorithm, catered for physical human robot collaboration scenarios. Specifically, a robotic scrub nurse system which can comprehend surgeon’s multimodal communication cues and perform turn-taking prediction is presented. The developed algorithm was tested on a collected data set of simulated surgical procedures in a surgeon–nurse tandem. The proposed turn-taking prediction algorithm is found to be significantly superior to its algorithmic counterparts, and is more accurate than human baseline when little partial input is given (less than 30% of full action). After observing more information, the algorithm can achieve comparable performances as humans with a F1 score of 0.90.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-017-9670-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11432-017-9363-y,Cooperative deterministic learning control for a group of homogeneous nonlinear uncertain robot manipulators,Science China Information Sciences,10.1007/s11432-017-9363-y,Springer,2018-05-23,"This paper addresses the learning control problem for a group of robot manipulators with homogeneous nonlinear uncertain dynamics, where all the robots have an identical system structure but the reference signals to be tracked differ. The control objective is twofold: to track on reference trajectories and to learn/identify uncertain dynamics. For this purpose, deterministic learning theory is combined with consensus theory to find a common neural network (NN) approximation of the nonlinear uncertain dynamics for a multi-robot system. Specifically, we first present a control scheme called cooperative deterministic learning using adaptive NNs to enable the robotic agents to track their respective reference trajectories on one hand and to exchange their estimated NN weights online through networked communication on the other. As a result, a consensus about one common NN approximation for the nonlinear uncertain dynamics is achieved for all the agents. Thus, the trained distributed NNs have a better generalization capability than those obtained by existing techniques. By virtue of the convergence of partial NN weights to their ideal values under the proposed scheme, the cooperatively learned knowledge can be stored/represented by NNs with constant/converged weights, so that it can be used to improve the tracking control performance without re-adaptation. Numerical simulations of a team of two-degree-of-freedom robot manipulators were conducted to demonstrate the effectiveness of the proposed approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11432-017-9363-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-017-4872-x,Human segmentation of infrared image for mobile robot search,Multimedia Tools and Applications,10.1007/s11042-017-4872-x,Springer,2018-05-01,"In the search robotics field, human target segmentation method plays a basic preprocessing step in the visual guidance. However, with the wide application of the infrared sensor on robot vision, traditional segmentation methods are facing more challenges of low-contrast, overlapping and blurring targets, and complex background. This paper introduces an infrared human segmentation approach that integrates the improved pulse coupled neural network (PCNN), the curvature gravity gradient tensor (CGGT) and the mathematical morphology to address these above problems. This approach starts with an improved PCNN segmentation model. Local dynamic synapse weights are designed to enhance the synchronous pulsing ability of the improved PCNN model with similar inputs, and a reformed threshold is conducted to guide the process of segmentation. Moreover, eigenvalues of CGGT are guaranteed in this model as linking coefficients, in order to capture the edges and details of human target more exactly in segmentation. Lastly, the segmentation result is repaired by morphology operators, to ensure the integrity of the target region and the independent noise removal. Experiments on 200 real infrared images captured by the mobile robot CQSearcher I, demonstrate that our method is superior over the other classic segmentation methods in both the subjective visual performance and the objective indicators of misclassification error and f-measure.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11042-017-4872-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10339-017-0818-5,Intuitive control of mobile robots: an architecture for autonomous adaptive dynamic behaviour integration,Cognitive Processing,10.1007/s10339-017-0818-5,Springer,2018-05-01,"In this paper, we present a novel approach to human–robot control. Taking inspiration from behaviour-based robotics and self-organisation principles, we present an interfacing mechanism, with the ability to adapt both towards the user and the robotic morphology. The aim is for a transparent mechanism connecting user and robot, allowing for a seamless integration of control signals and robot behaviours. Instead of the user adapting to the interface and control paradigm, the proposed architecture allows the user to shape the control motifs in their way of preference, moving away from the case where the user has to read and understand an operation manual, or it has to learn to operate a specific device. Starting from a tabula rasa basis, the architecture is able to identify control patterns (behaviours) for the given robotic morphology and successfully merge them with control signals from the user, regardless of the input device used. The structural components of the interface are presented and assessed both individually and as a whole. Inherent properties of the architecture are presented and explained. At the same time, emergent properties are presented and investigated. As a whole, this paradigm of control is found to highlight the potential for a change in the paradigm of robotic control, and a new level in the taxonomy of human in the loop systems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10339-017-0818-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-018-3358-8,A hybrid deep learning neural approach for emotion recognition from facial expressions for socially assistive robots,Neural Computing and Applications,10.1007/s00521-018-3358-8,Springer,2018-04-01,"We have recently seen significant advancements in the development of robotic machines that are designed to assist people with their daily lives. Socially assistive robots are now able to perform a number of tasks autonomously and without human supervision. However, if these robots are to be accepted by human users, there is a need to focus on the form of human–robot interaction that is seen as acceptable by such users. In this paper, we extend our previous work, originally presented in Ruiz-Garcia et al. (in: Engineering applications of neural networks: 17th international conference, EANN 2016, Aberdeen, UK, September 2–5, 2016, proceedings, pp 79–93, 2016 . https://doi.org/10.1007/978-3-319-44188-7_6 ), to provide emotion recognition from human facial expressions for application on a real-time robot. We expand on previous work by presenting a new hybrid deep learning emotion recognition model and preliminary results using this model on real-time emotion recognition performed by our humanoid robot. The hybrid emotion recognition model combines a Deep Convolutional Neural Network (CNN) for self-learnt feature extraction and a Support Vector Machine (SVM) for emotion classification. Compared to more complex approaches that use more layers in the convolutional model, this hybrid deep learning model produces state-of-the-art classification rate of $$96.26\%$$ 96.26 % , when tested on the Karolinska Directed Emotional Faces dataset (Lundqvist et al. in The Karolinska Directed Emotional Faces—KDEF, 1998 ), and offers similar performance on unseen data when tested on the Extended Cohn–Kanade dataset (Lucey et al. in: Proceedings of the third international workshop on CVPR for human communicative behaviour analysis (CVPR4HB 2010), San Francisco, USA, pp 94–101, 2010 ). This architecture also takes advantage of batch normalisation (Ioffe and Szegedy in Batch normalization: accelerating deep network training by reducing internal covariate shift. http://arxiv.org/abs/1502.03167 , 2015 ) for fast learning from a smaller number of training samples. A comparison between Gabor filters and CNN for feature extraction, and between SVM and multilayer perceptron for classification is also provided.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-018-3358-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-017-0186-z,Improvement of Tracking Control of a Sliding Mode Controller for Robot Manipulators by a Neural Network,"International Journal of Control, Automation and Systems",10.1007/s12555-017-0186-z,Springer,2018-04-01,"This article presents a neural network control technique to improve the tracking performance of a robot manipulator controlled by the sliding mode control method in a non-model-based framework. The sliding mode controller is a typical nonlinear controller that has been well developed in theory and used in many applications due to its simplicity and practicality. Selection of the gain of the nonlinear function plays an important role in performance as well as stability. When the sliding mode controller is used for the non model-based configuration in robot control, the nonlinear gain should be selected large enough to guarantee the stability. Since the appropriate selection of the gain value is essential and difficult in the sliding mode control framework, a neural network compensator is introduced at the trajectory level to help the fixed gain deal with the stability and performance more intelligently. Stability of the proposed control scheme is analyzed. Simulation studies of following the Cartesian trajectory for a three-link rotary robot manipulator are conducted to confirm the control improvement by the neural network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-017-0186-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12559-017-9526-9,Semantic Scene Mapping with Spatio-temporal Deep Neural Network for Robotic Applications,Cognitive Computation,10.1007/s12559-017-9526-9,Springer,2018-04-01,"Semantic scene mapping is a challenge and significant task for robotic application, such as autonomous navigation and robot-environment interaction. In this paper, we propose a semantic pixel-wise mapping system for potential robotic applications. The system includes a novel spatio-temporal deep neural network for semantic segmentation and a Simultaneous Localisation and Mapping (SLAM) algorithm for 3D point cloud map. Their combination yields a 3D semantic pixel-wise map. The proposed network consists of Convolutional Neural Networks (CNNs) with two streams: spatial stream with images as the input and temporal stream with image differences as the input. Due to the use of both spatial and temporal information, it is called spatio-temporal deep neural network, which shows a better performance in both accuracy and robustness in semantic segmentation. Further, only keyframes are selected for semantic segmentation in order to reduce the computational burden for video streams and improve the real-time performance. Based on the result of semantic segmentation, a 3D semantic map is built up by using the 3D point cloud map from a SLAM algorithm. The proposed spatio-temporal neural network is evaluated on both Cityscapes benchmark (a public dataset) and Essex Indoor benchmark (a dataset we labelled ourselves manually). Compared with the state-of-the-art spatial only neural networks, the proposed network achieves better performances in both pixel-wise accuracy and Intersection over Union (IoU) for scene segmentation. The constructed 3D semantic map with our methods is accurate and meaningful for robotic applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12559-017-9526-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-017-0055-9,Application of the Fuzzy Logic for the Development of Automnomous Robot with Obstacles Deviation,"International Journal of Control, Automation and Systems",10.1007/s12555-017-0055-9,Springer,2018-04-01,"This paper proposed to elaborate a navigation system for an autonomous mobile robot, able to deviate from obstacles, from the study and application of Fuzzy Logic. With the algorithm in operation, it was verified that the Fuzzy logic offers a smoother transition in the movements. In order to validate the efficiency of the navigation system created, simulations were performed with the robot according to the rules inserted in the Fuzzy controller, where the input values of the sensors and the output values in the PWM of the board were analyzed. The results obtained were consistent with the responses given by the simulation in MatLab, following the same trend of behavior. With the realization of this project, it was concluded that the Fuzzy methodology presents a solution to the problems of navigation in real environments, allowing to implement a controller for an autonomous robot that can deflect obstacles avoiding their collision. One of the problems encountered is the angle of actuation of the ultrasonic sensors. This type of sensor works with an angle of actuation of 15◦, which leaves the robot with a low vision area in the use of three sensors. As a result, there may be no reading on objects entering zones without detection, leading to a collision with these obstacles. The responses were satisfactory, following the same trend behavior of the simulations of the Fuzzy controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-017-0055-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12115-018-0221-6,Society and the Second Age of Machines: Algorithms Versus Ethics,Society,10.1007/s12115-018-0221-6,Springer,2018-04-01,"The term “Second Machine Age” was used by Erik Brynjolfsson and Andrew McAfee in their book of the same name as an indication of the impact of AI technology on people, society, and the economy. The term seeks to analyse the age we actually live in, its hidden patterns, which jobs and fields of study have a perspective, and which do not. It is about the second industrial revolution that is going on right now, and it changes the world no less radically than the first one, driven by the steam locomotive. Exponential growth of digital technologies, digitization of everything and recombinant innovation is a driving engine and fuel of the Second Machine Age. However, the ethical issues of this change remain unaddressed. Artificial intelligence is currently being dealt with by a great many scientists and philosophers who ask many questions. The most important questions are whether the machines can think, whether we will give them the copyright, which the animals do not have until now, and the question whether AI can has its own ethics. The study focuses on these issues, and uses concrete examples to show our unpreparedness for these topics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12115-018-0221-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42235-018-0026-8,Multi-Layered CPG for Adaptive Walking of Quadruped Robots,Journal of Bionic Engineering,10.1007/s42235-018-0026-8,Springer,2018-03-01,"This work concerns biped adaptive walking control on slope terrains with online trajectory generation. In terms of the lack of satisfactory performances of the traditional simplified single-layered Central Pattern Generator (CPG) model in engineering applications where robots face unknown environments and access feedback, this paper presents a Multi-Layered CPG (ML-CPG) model based on a half-center CPG model. The proposed ML-CPG model is used as the underlying low-level controller for a quadruped robot to generate adaptive walking patterns. Rhythm-generation and pattern formation interneurons are modeled to promptly generate motion rhythm and patterns for motion sequence control, while motoneurons are modeled to control the output strength of the joint in real time according to feedback. Referring to the motion control mechanisms of animals, a control structure is built for a quadruped robot. Multi-sensor models abstracted from the neural reflexes of animals are involved in all the layers of neurons through various feedback paths to achieve adaptability as well as the coordinated motion control of a robot’s limbs. The simulation experiments verify the effectiveness of the presented ML-CPG and multi-layered reflexes strategy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42235-018-0026-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12541-018-0041-z,Synchronization Controller for a 3-RRR Parallel Manipulator,International Journal of Precision Engineering and Manufacturing,10.1007/s12541-018-0041-z,Springer,2018-03-01,"A 3-RRR parallel manipulator has been well-known as a closed-loop kinematic chain mechanism in which the end-effector generally a moving platform is connected to the base by several independent actuators. Performance of the robot is decided by performances of the component actuators which are independently driven by tracking controllers without acknowledging information from each other. The platform performance is degraded if any actuator could not be driven well. Therefore, this paper aims to develop an advanced synchronization (SYNC) controller for position tracking of a 3-RRR parallel robot using three DC motor-driven actuators. The proposed control scheme consists of three sliding mode controllers (SMC) to drive the actuators and a supervisory controller named PID-neural network controller (PIDNNC) to compensate the synchronization errors due to system nonlinearities, uncertainties and external disturbances. A Lyapunov stability condition is added to the PIDNNC training mechanism to ensure the robust tracking performance of the manipulator. Numerical simulations have been performed under different working conditions to demonstrate the effectiveness of the suggested control approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12541-018-0041-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-016-2536-9,STMVO: biologically inspired monocular visual odometry,Neural Computing and Applications,10.1007/s00521-016-2536-9,Springer,2018-03-01,"Visual odometry (VO) is a fundamental and challenging problem in both the computer vision community and the robotics community. VO refers the process of recovering the relative movements of a camera by analyzing the associated image sequence. While VO is generally formulated as descriptors-based feature tracking with outliers rejection and global optimization, these algorithms are not only computationally expensive but also lack robustness. In the paper, a biologically inspired solution to the monocular visual odometry problem was presented, which was named as shunting short-term memory monocular visual odometry. The proposed method is simple and concise in both concept and implementation. To be more specific, it utilizes the shunting short-term memory to represent the key frames and the latest observations and also to adapt to uncertainties and ambiguities. And scan matching scheme is adopted to search the movement that best explained the difference between the latest observation and the key frame. Because of the dynamic properties of the neural network, the proposed method requires neither explicit extraction of features and descriptors, nor outliers detection and bundle optimization. Theoretical analysis in the paper showed that the proposed method has Lyapunov stability and constant computational complexity. The proposed method was also compared with the classical monocular VO algorithm in real indoor environments, and the experimental results proved that the proposed method outperforms the classical method on both effectiveness and robustness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-016-2536-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10994-017-5666-0,Emotion in reinforcement learning agents and robots: a survey,Machine Learning,10.1007/s10994-017-5666-0,Springer,2018-02-01,"This article provides the first survey of computational models of emotion in reinforcement learning (RL) agents. The survey focuses on agent/robot emotions, and mostly ignores human user emotions. Emotions are recognized as functional in decision-making by influencing motivation and action selection. Therefore, computational emotion models are usually grounded in the agent’s decision making architecture, of which RL is an important subclass. Studying emotions in RL-based agents is useful for three research fields. For machine learning (ML) researchers, emotion models may improve learning efficiency. For the interactive ML and human–robot interaction community, emotions can communicate state and enhance user investment. Lastly, it allows affective modelling researchers to investigate their emotion theories in a successful AI agent class. This survey provides background on emotion theory and RL. It systematically addresses (1) from what underlying dimensions (e.g. homeostasis, appraisal) emotions can be derived and how these can be modelled in RL-agents, (2) what types of emotions have been derived from these dimensions, and (3) how these emotions may either influence the learning efficiency of the agent or be useful as social signals. We also systematically compare evaluation criteria, and draw connections to important RL sub-domains like (intrinsic) motivation and model-based RL. In short, this survey provides both a practical overview for engineers wanting to implement emotions in their RL agents, and identifies challenges and directions for future emotion-RL research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10994-017-5666-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40926-017-0059-9,Can Merging a Capability Approach with Effectual Processes Help Us Define a Permissible Action Range for AI Robotics Entrepreneurship?,Philosophy of Management,10.1007/s40926-017-0059-9,Springer,2018-02-01,"In this paper, we first enumerate the problems that humans might face with a new type of technology such as robots with artificial intelligence (AI robots). Robotics entrepreneurs are calling for discussions about goals and values because AI robots, which are potentially more intelligent than humans, can no longer be fully understood and controlled by humans. AI robots could even develop into ethically “bad” agents and become very harmful. We consider these discussions as part of a process of developing responsible innovations in AI robotics in order to prevent catastrophic risks on a global scale. To deal with these issues, we propose the capability-effectual approach , drawing on two bodies of research: the capability approach from ethics, and the effectual process model from entrepreneurship research. The capability approach provides central human capabilities, guiding the effectual process through individual goals and aspirations in the collaborative design process of stakeholders. More precisely, by assuming and understanding correspondences between goals, purposes, desires, and aspirations in the languages of different disciplines, the capability-effectual approach clarifies both how a capability list working globally could affect the aspirations and end-goals of individuals, and how local aspirations and end-goals could either energise or limit effectual processes. Theoretically, the capability-effectual approach links the collaboration of stakeholders and the design process in responsible innovation research. Practically, this approach could potentially contribute to the robust development of AI robots by providing robotics entrepreneurs with a tool for establishing a permissible action range within which to develop AI robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40926-017-0059-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-98192-5_3,Deep Learning and Sentiment Analysis for Human-Robot Interaction,The Semantic Web: ESWC 2018 Satellite Events,10.1007/978-3-319-98192-5_3,Springer,2018-01-01,"In this paper we present an ongoing work showing to what extent semantic technologies, deep learning and natural language processing can be applied within the field of Human-Robot Interaction. The project has been developed for Zora, a completely programmable and autonomous humanoid robot, and it aims at allowing Zora to interact with humans using natural language. The robot is capable of talking to the user and understanding sentiments by leveraging our external services, such as a Sentiment Analysis engine and a Generative Conversational Agent, which is responsible for generating Zora’s answers to open-dialog natural language utterances.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-98192-5_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-00308-1_28,Humanoid Robot Detection Using Deep Learning: A Speed-Accuracy Tradeoff,RoboCup 2017: Robot World Cup XXI,10.1007/978-3-030-00308-1_28,Springer,2018-01-01,"Recent advances in computer vision have made the detection of landmarks on the soccer field easier for teams. However, the detection of other robots is also a critical capability that has not garnered much attention in the RoboCup community so far. This problem is well represented in different RoboCup Soccer and Rescue Robot Leagues. In this paper, we compare several two-stage detection systems based on various Convolutional Neural Networks (CNN) and highlight their speed-accuracy trade off. The approach performs edge based image segmentation in order to reduce the search space and then a CNN validates the detection in the second stage. We use images of different humanoid robots to train and test three different CNN architectures. A part of these images was gathered by our team and will be publicly available. Our experiments demonstrate the strong adaptability of deeper CNNs. These models, trained on a limited set of robots, are able to successfully distinguish an unseen kind of humanoid robot from non-robot regions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-00308-1_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-62875-2_29,An Open Robotics Environment Motivates Students to Learn the Key Concepts of Artificial Neural Networks and Reinforcement Learning,Robotics in Education,10.1007/978-3-319-62875-2_29,Springer,2018-01-01,"Educational robotics is a widely recognized tool to motivate students and concretize abstract and complex topics, such as artificial intelligence in computing education curricula. Lego Mindstorms series is one of the most popular robotics platform due to its flexibility and relatively cheap price. We used Lego Mindstorms EV3 robots with a novel Open Learning Environment for Artificial Intelligence (OLE-AI) to teach concepts of reinforcement learning and artificial neural networks (ANNs) to computer science students. OLE-AI uses a white box approach to expose internal structures of an ANN to students. Results from the pilot study with OLE-AI indicate that the participating students were able to deepend their knowledge about AI topics through a practical and open exercise that involved them in controlling EV3 robots by manipulating the ANN and Q-Learning algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-62875-2_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-04239-4_11,Comparing Computing Platforms for Deep Learning on a Humanoid Robot,Neural Information Processing,10.1007/978-3-030-04239-4_11,Springer,2018-01-01,The goal of this study is to test two different computing platforms with respect to their suitability for running deep networks as part of a humanoid robot software system. One of the platforms is the CPU-centered Intel® NUC7i7BNH and the other is a NVIDIA® Jetson TX2 system that puts more emphasis on GPU processing. The experiments addressed a number of benchmarking tasks including pedestrian detection using deep neural networks. Some of the results were unexpected but demonstrate that platforms exhibit both advantages and disadvantages when taking computational performance and electrical power requirements of such a system into account.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-04239-4_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-00308-1_2,Using Convolutional Neural Networks in Robots with Limited Computational Resources: Detecting NAO Robots While Playing Soccer,RoboCup 2017: Robot World Cup XXI,10.1007/978-3-030-00308-1_2,Springer,2018-01-01,"The main goal of this paper is to analyze the general problem of using Convolutional Neural Networks (CNNs) in robots with limited computational capabilities, and to propose general design guidelines for their use. In addition, two different CNN based NAO robot detectors that are able to run in real-time while playing soccer are proposed. One of the detectors is based on the XNOR-Net and the other on the SqueezeNet. Each detector is able to process a robot object-proposal in ~1 ms, with an average number of 1.5 proposals per frame obtained by the upper camera of the NAO. The obtained detection rate is ~97%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-00308-1_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-60702-3_16,Design of Artificial Neural Network Predictor for Trajectory Planning of an Experimental 6 DOF Robot Manipulator,"Mechanisms, Transmissions and Applications",10.1007/978-3-319-60702-3_16,Springer,2018-01-01,"Nowadays, the use of robots is continuously increasing in industry. Especially, robotic Gas metal arc (GMA) welding is widespread used as manufacturing process. Because of this increase in the use of robots in the industry, there is a need to study on a number of improvements. This paper presents an experimental research on the robot manipulator, using image processing to detect location of welding seam for the planning optimal trajectory. This new study provides the weld seam trajectory to be created without being affected by manufacture faults. Firstly, communication interface between the robot and the computer is developed by using previous related software library. Then, the weld seam trajectory are automatically generated using image processing via Matlab and reference points are determined on the trajectory for tracking of the manipulator. The values of this points are sent to the robots for calculation of the joint angles by the software on the robot side. Furthermore, the related parameters are tested with neural network predictor to predict optimal trajectory on resulting image using image processing. The results show that this approach improved that neural network predictor can increase trajectory accuracy for quality welding process.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-60702-3_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-13-1702-6_26,Fall Detection System Based on Mobile Robot,Image and Graphics Technologies and Applications,10.1007/978-981-13-1702-6_26,Springer,2018-01-01,"This paper proposed an accurate fall detection algorithm based on the feature of whole human body. The feature is extracted from convolutional neural network. The implementation of algorithm is integrated into a hardware system based on a visual mobile robot platform. To ensure the robustness and flexibility of algorithm in actual situation, a set of systemic strategies was applied on mobile robot. Finally, sufficient experiments on public dataset were conduct on our algorithm. Moreover, in a real indoor scene, experiment results proved the efficiency and precision of the designed fall detection system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-1702-6_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-04239-4_30,A Neural Network Compensation Technique for an Inertia Estimation Error of a Time-Delayed Controller for a Robot Manipulator,Neural Information Processing,10.1007/978-3-030-04239-4_30,Springer,2018-01-01,"In this paper, a neural network is added to compensate for the deviation error of an estimated inertia matrix of the time-delayed controller for a robot manipulator. The time-delayed control (TDC) method is known as a simple and practical control method for controlling robot manipulators. The previously sampled information is used to cancel uncertainties for the current control using a time- delay. One of the problems of TDC is the constant inertia selected for simplicity and how to deal with the error of the inertia model estimation. In this paper, a neural network is used to compensate for the deviated inertia error. Simulation studies of position tracking control performances of a three link rotary robot are presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-04239-4_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-00825-3_6,Emotion-Aware Teaching Robot: Learning to Adjust to User’s Emotional State,ICT Innovations 2018. Engineering and Life Sciences,10.1007/978-3-030-00825-3_6,Springer,2018-01-01,"Robots today are taking more and more complex roles thus they are getting smarter and more human-like. One complex function, specific to social robots, is the role of robots in human-robot interaction. They are helpful in the process of social human-robot interaction while performing a specific task like teaching, assisting, entertaining, etc. The ability to recognize emotions has a significant role for social robots. A robot that can understand emotions could be able to interact according to that emotion. In this paper, we propose a model for robotic behavior adapting to the user’s emotions. The humanoid robot Nao is used in the role of emotion-aware teacher for teaching math. Its main purpose is to teach and entertain the user while adapting its behavior to the user’s emotional state derived from the facial expression. The robot uses reinforcement learning to learn which action to perform in a specific emotional state. It employs the Q-learning algorithm, maximizing the next action’s award - a value that depends on the current emotional state of the user. An experimental study with a selected group of subjects is conducted to assess the proposed behavior. We evaluated the robot’s ability to recognize emotions and the subjects’ experience of interacting with the robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-00825-3_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-89629-8_14,Improved Deep Neural Network Object Tracking System for Applications in Home Robotics,Computational Intelligence for Pattern Recognition,10.1007/978-3-319-89629-8_14,Springer,2018-01-01,"Robotic navigation in GPS-denied environments GPS denied environment requires case specific approaches for controlling a mobile robot to any desired destinations. In general, a nominal path is created in an environment described by a set of distinct objects, in other words such obstacles and landmarks. Intelligent voice Voice assistants or digital assistance devices are increasing their importance in today’s smart home. Especially, by the help of fast-growing Internet of Things (IoT) applications. These devices are amassing an ever-growing list of features such as controlling states of connected smart devices, recording tasks, and responding to queries. Assistive robots are the perfect complement to smart voice assistants for providing physical manipulation. A request made by a person can be assigned to the assistive robot by the voice Voice assistant. In this chapter, a new approach for autonomous navigation Autonomous navigation is presented using pattern recognition Pattern recognition and machine learning Machine learning techniques such as Convolutional Neural Networks to identify markers or objects from images and videos. Computational intelligence Computational intelligence techniques are implemented along with Robot Operating System and object positioning to navigate towards these objects and markers by using RGB-depth camera Depth camera . Multiple potential matching objects detected by the robot with deep neural network Neural network object detectors will be displayed on a screen installed on the assistive robot to improve and evaluate Human-Robot Interaction (HRI).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-89629-8_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-60384-1_33,VR Environment for the Study of Collocated Interaction Between Small UAVs and Humans,Advances in Human Factors in Robots and Unmanned Systems,10.1007/978-3-319-60384-1_33,Springer,2018-01-01,"Two issues that are crucial to the integration of flying robotic systems into human populated environments include: how humans perceive autonomous flying robots, and how to design and control flying robots to improve the level of comfort and perceived safety for collocated others. This work represents a comprehensive virtual reality test environment to explore scripted and unscripted interactions with flying robots. We employ a multimethod approach by incorporating behavioral measures, self-report questionnaires, and physiological data to characterize human arousal during a variety of predetermined and real-time scenarios in both indoor and outdoor environments. By combining complementary methodological techniques, we can converge on a data-driven model of social etiquette for flying robots; this model can then be reparametrized in terms of planning and control solutions to govern the robot’s behavior in a real-world context.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-60384-1_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-04239-4_27,Multi-feature Fusion for Deep Reinforcement Learning: Sequential Control of Mobile Robots,Neural Information Processing,10.1007/978-3-030-04239-4_27,Springer,2018-01-01,"Compared with traditional motion planners, deep reinforcement learning has been applied more and more widely to achieving sequential behaviours control of mobile robots in indoor environment. However, the state of robot in deep reinforcement learning is commonly obtained through single sensor, which lacks accuracy and stability. In this paper, we propose a novel approach called multi-feature fusion framework. The multi-feature fusion framework utilizes multiple sensors to gather different scene images around the robot. Once environment information is gathered, a well-trained autoencoder achieves the fusion and extraction of multiple visual features. With more accurate and stable states extracted from the autoencoder, we train the mobile robot to patrol and navigate in 3D simulation environment with an asynchronous deep reinforcement learning algorithm. Extensive simulation experiments demonstrate that the proposed multi-feature fusion framework improves not only the convergence rate of training phase but also the testing performance of the mobile robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-04239-4_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-97586-3_17,Deep Reinforcement Learning Based Collision Avoidance Algorithm for Differential Drive Robot,Intelligent Robotics and Applications,10.1007/978-3-319-97586-3_17,Springer,2018-01-01,"In this paper, collision avoidance problem is investigated for differential drive robot running in pedestrian environment, which requires for natural and safe interaction between robot and human. Based on deep reinforcement learning, a human-aware collision avoidance algorithm is proposed to find a smooth and collision-free path. A well designed reward function ensures the robot navigates without collision and obeys right-pass norm simultaneously. The slow convergence problem during training is addressed by pre-training the neural network using supervised learning. The simulation results show that the proposed algorithm can find a feasible and norm-obeyed path which achieves a natural human-robot interaction compared with traditional method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-97586-3_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-96133-0_20,Reinforcement Learning for Computer Vision and Robot Navigation,Machine Learning and Data Mining in Pattern Recognition,10.1007/978-3-319-96133-0_20,Springer,2018-01-01,"Nowadays, machine learning has become one of the basic technologies used in solving various computer vision tasks such as feature detection, image segmentation, object recognition and tracking. In many applications, various complex systems such as robots are equipped with visual sensors from which they learn the state of a surrounding environment by solving corresponding computer vision tasks. Solutions of these tasks are used for making decisions about possible future actions. Reinforcement learning is one of the modern machine learning technologies in which learning is carried out through interaction with the environment. In recent years, reinforcement learning has been used both for solving robotic computer vision problems such as object detection, visual tracking and action recognition as well as robot navigation. The paper describes shortly the reinforcement learning technology and its use for computer vision and robot navigation problems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-96133-0_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-97304-3_34,Reinforcement Learning for Mobile Robot Obstacle Avoidance Under Dynamic Environments,PRICAI 2018: Trends in Artificial Intelligence,10.1007/978-3-319-97304-3_34,Springer,2018-01-01,"Collision avoidance under dynamic environments is a challenging problem for mobile robots. Navigating the robot safely to the target is extremely significant especially in the dynamic environments. In this paper, a new approach based on reinforcement learning is proposed to navigate the robot from the start location to the target location without collisions with static and dynamic obstacles. In the proposed method, we improve the original Q-learning algorithm in environment modeling, reward function, and the adapted policy to make the robot stay away from obstacles, reduce the probability of collisions, and reach the target as fast as possible. Finally, simulations of some test scenarios and the comparisons between the original Q-learning and improved Q-learning are respectively conducted to validate that the proposed approach has high efficiency and adaptability in solving dynamic obstacle avoidance problem.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-97304-3_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-98998-3_2,Optimized Artificial Neural Network System to Select an Exploration Algorithm for Robots on Bi-dimensional Grids,Advances in Computing,10.1007/978-3-319-98998-3_2,Springer,2018-01-01,"This article shows how Machine learning techniques are tested to predict the performance of different exploration algorithms: Random Walk, Random Walk WSB and Q Learning, for robots moving on a bi-dimensional grid. The overall objective is to create a tool to help select the best performing exploration algorithm according to a configurable testing scenario, without the need to perform new experiments, either physical or simulated. The work presented here focuses on optimizing the topology of an Artificial Neural Network (ANN) to improve prediction results versus a previously proposed approach. The Hill Climbing algorithm is tested as optimization method, compared with manual trial and error optimization. The ANN was selected because it has the best performance indicators in terms of Relative Absolute Error and Pearson Correlation Coefficient compared with Random Forest and Decision Trees. The metric used to measure the performance of the exploration algorithms is Maximum Number of Steps to target.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-98998-3_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-99582-3_29,Hybrid Force/Position Control of a Collaborative Parallel Robot Using Adaptive Neural Network,Interactive Collaborative Robotics,10.1007/978-3-319-99582-3_29,Springer,2018-01-01,"In this paper, a new stable adaptive neural network control scheme has been presented for hybrid position and force control of the Delta parallel robot. Force control is an important technique in programming and safety for collaborative robots. The hybrid control scheme is introduced to tackle the interaction problem between the robot and its environment such that the robot follows the position trajectory and desired force, which is applied in a certain position. The goal of the control is applying desired force trajectory in a certain position in which there is a constraint for movement. Fewer parameter settings, adaptive algorithm, and efficient control input signals are the advantages of the proposed controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-99582-3_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-04221-9_35,Deep Learning for Real Time Facial Expression Recognition in Social Robots,Neural Information Processing,10.1007/978-3-030-04221-9_35,Springer,2018-01-01,"Human robot interaction is a rapidly growing topic of interest in today’s society. The development of real time emotion recognition will further improve the relationship between humans and social robots. However, contemporary real time emotion recognition in unconstrained environments has yet to reach the accuracy levels achieved on controlled static datasets. In this work, we propose a Deep Convolutional Neural Network (CNN), pre-trained as a Stacked Convolutional Autoencoder (SCAE) in a greedy layer-wise unsupervised manner, for emotion recognition from facial expression images taken by a NAO robot. The SCAE model is trained to learn an illumination invariant down-sampled feature vector. The weights of the encoder element are then used to initialize the CNN model, which is fine-tuned for classification. We train the model on a corpus composed of gamma corrected versions of the CK+ , JAFFE, FEEDTUM and KDEF datasets. The emotion recognition model produces a state-of-the-art accuracy rate of 99.14% on this corpus. We also show that the proposed training approach significantly improves the CNN’s generalisation ability by over 30% on nonuniform data collected with the NAO robot in unconstrained environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-04221-9_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-91244-8_31,Using Convolutional Neural Networks for Assembly Activity Recognition in Robot Assisted Manual Production,Human-Computer Interaction. Interaction in Context,10.1007/978-3-319-91244-8_31,Springer,2018-01-01,"Due to ever-shortening product life cycles and multi variant products the demand for flexible production systems that include human-robot collaboration (HRC) rises. One key factor in HRC is stress that occurs because of the unfamiliar work with the robot. To reduce stress induced strain for assembly tasks we propose an adjustment of cycle times to the human’s performance, so that the stress that is exerted on the working person by a waiting robot is minimized. For an autonomous adaptation of the cycle time, the production system should be aware of the human’s actions and assembly progress without the need to inform the system manually. Therefore, we propose an activity recognition in assembly based on a machine learning technique. A convolutional neural network is used to distinguish between different activities during the assembly by analyzing motion data of the hands of the working person. The results show that the network is suitable for distinguishing between nine different assembly activities like screwing with a screwdriver, screwing with a hexagon wrench or general assembly and further activities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-91244-8_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-13-1396-7_1,Computer-Aided Orthopaedic Surgery: State-of-the-Art and Future Perspectives,Intelligent Orthopaedics,10.1007/978-981-13-1396-7_1,Springer,2018-01-01,"Introduced more than two decades ago, computer-aided orthopaedic surgery (CAOS) has emerged as a new and independent area, due to the importance of treatment of musculoskeletal diseases in orthopaedics and traumatology, increasing availability of different imaging modalities and advances in analytics and navigation tools. The aim of this chapter is to present the basic elements of CAOS devices and to review state-of-the-art examples of different imaging modalities used to create the virtual representations, of different position tracking devices for navigation systems, of different surgical robots, of different methods for registration and referencing, and of CAOS modules that have been realized for different surgical procedures. Future perspectives will be outlined. It is expected that the recent advancement on smart instrumentation, medical robotics, artificial intelligence, machine learning, and deep learning techniques, in combination with big data analytics, may lead to smart CAOS systems and intelligent orthopaedics in the near future.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-1396-7_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-00308-1_9,A Machine Learning System for Controlling a Rescue Robot,RoboCup 2017: Robot World Cup XXI,10.1007/978-3-030-00308-1_9,Springer,2018-01-01,"Many rescue robots are reconfigurable, having subtracks (or flippers) that can be adjusted to help the robot traverse different types of terrain. Knowing how to adjust them requires skill on the part of the operator. If the robot is intended to run autonomously, the control system must have an understanding of how the flippers affect the robot’s interaction with the ground. We describe a system that first learns the effects of a robot’s actions and then uses this knowledge to plan how to reconfigure the robot’s tracks so that it can overcome different types of obstacles. The system is a hybrid of qualitative symbolic learning and reinforcement learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-00308-1_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-13-2874-9_1,The Rise of Robotics & AI: Technological Advances & Normative Dilemmas,"Robotics, AI and the Future of Law",10.1007/978-981-13-2874-9_1,Springer,2018-01-01,"Computer science, robotics Robotics and AI Artificial Intelligence (AI) have Innovation all Law developed rapidly in recent years, bringing profound changes to all aspects of human life. However, the emergence Emergence and proliferation of these new technologies has not occurred within the bounds of traditional organizational, ethical and regulatory systems. We have reached an inflection point, where we need to pursue new business models and normative frameworks to underpin these fast-developing technologies. This introductory chapter briefly maps the evolution of these different technologies and argues for a new, more forward-oriented approach to the business and normative challenges that are created. The discussion ends with a review of the chapters that comprise this volume.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-2874-9_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-06091-0_12-1,Media in Knowledge Democracy and Cyber-Democracy,"Handbook of Cyber-Development, Cyber-Democracy, and Cyber-Defense",10.1007/978-3-319-06091-0_12-1,Springer,2018-01-01,"Media, particularly in combination with the Internet and advanced IT (information technology), can produce a major impact on politics. Elections, campaigning, governance, and policy-making in advanced democracies, but also in emerging democracies, do of course refer to media. It is also being said, and at least being discussed, that or if the media and new media were playing a triggering role for the events of the Arab Spring. New media and the New Social Media are also acting that invasive, because they can easily operate beyond and transcend national borders, and they allow the “cost-efficient” bypassing of more traditional media forms that are very cost intensive. This poses dangers for democracy. But this also poses opportunities for democracy and knowledge democracy, in the sense of offering a broader spectrum of available and accessible information. In addition, the analysis here also emphasizes and refers to this interesting interdisciplinary, transdisciplinary, and inter-sectoral overlap of media, knowledge democracy, and innovation systems. Media, new media, and New Social Media impact politics, but they may also enhance innovation and innovation system. The theories and concepts of the Quadruple and Quintuple Helix innovation systems are explicit about the role of media for knowledge and innovation (“media-based and culture-based public”). Media allow and support the integration of knowledge creation, knowledge production, and knowledge application across diverse national, regional, and global innovation systems. In that sense, media may also be an element and a force for the advancement of AI (artificial intelligence) and AI systems. Already existing examples here are robot journalism, robot writers, and robot writing. The media are interlinking and building networks between political processes in media democracy and innovation processes in innovation systems. Between the sectors of the political system and of the innovation systems, new forms of cross-connectedness are emerging, facilitated also by the media.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-06091-0_12-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-09069-6_12,Media in Knowledge Democracy and Cyber-Democracy,"Handbook of Cyber-Development, Cyber-Democracy, and Cyber-Defense",10.1007/978-3-319-09069-6_12,Springer,2018-01-01,"Media, particularly in combination with the Internet and advanced IT (information technology), can produce a major impact on politics. Elections, campaigning, governance, and policy-making in advanced democracies, but also in emerging democracies, do of course refer to media. It is also being said, and at least being discussed, that or if the media and new media were playing a triggering role for the events of the Arab Spring. New media and the New Social Media are also acting that invasive, because they can easily operate beyond and transcend national borders, and they allow the “cost-efficient” bypassing of more traditional media forms that are very cost intensive. This poses dangers for democracy. But this also poses opportunities for democracy and knowledge democracy, in the sense of offering a broader spectrum of available and accessible information. In addition, the analysis here also emphasizes and refers to this interesting interdisciplinary, transdisciplinary, and inter-sectoral overlap of media, knowledge democracy, and innovation systems. Media, new media, and New Social Media impact politics, but they may also enhance innovation and innovation system. The theories and concepts of the Quadruple and Quintuple Helix innovation systems are explicit about the role of media for knowledge and innovation (“media-based and culture-based public”). Media allow and support the integration of knowledge creation, knowledge production, and knowledge application across diverse national, regional, and global innovation systems. In that sense, media may also be an element and a force for the advancement of AI (artificial intelligence) and AI systems. Already existing examples here are robot journalism, robot writers, and robot writing. The media are interlinking and building networks between political processes in media democracy and innovation processes in innovation systems. Between the sectors of the political system and of the innovation systems, new forms of cross-connectedness are emerging, facilitated also by the media.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-09069-6_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-04239-4_4,Learning to Cooperate in Decentralized Multi-robot Exploration of Dynamic Environments,Neural Information Processing,10.1007/978-3-030-04239-4_4,Springer,2018-01-01,"This paper presents an approach to train a decentralized multi-robot system to learn cooperation strategy in the exploration of dynamic environments. The traditional approaches to multi-robot exploration problem are all based on the “pre-designed” cooperation strategy. However, many real-world settings are too complex for humans to “design” effective strategies. Besides, “pre-designed” strategy does not possess the ability to adapt to different task environment features, which also limits its application in real-world practices. Inspired by the superiority of deep reinforcement learning technique on complex individual behavior design, we apply the same technology to the cooperative learning process on the robot collective level. Our approach has been evaluated in a simulated multi-robot Disaster Exploration scenario and the results show that it could be applied in more complicated scenarios in contrast with two traditional “human-designed” methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-04239-4_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-73751-5_1,"Artificial Intelligence, Autonomous Systems and Robotics: Legal Innovations",Service Orientation in Holonic and Multi-Agent Manufacturing,10.1007/978-3-319-73751-5_1,Springer,2018-01-01,"Ethical, societal and legal issues are rising jointly with the development of autonomous robotic systems immersed into human society. This work focuses on legal aspects and intends to raise the awareness of engineers and researchers in the fields of robotics and artificial intelligence with applications to embedded autonomous systems, cyber-physical systems and self-organizing systems. The paper discusses in detail some recent legal innovations in these fields. Two questions are specifically addressed: how does the lawyer apprehend artificial intelligence and robotics? Which are the existing rules and the necessary legal innovations coming in the next years?",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-73751-5_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-77770-2_12,Cognitive Robotics: The New Challenges in Artificial Intelligence,"Advanced Topics on Computer Vision, Control and Robotics in Mechatronics",10.1007/978-3-319-77770-2_12,Springer,2018-01-01,"Recent technological advances have provided the manufacturing industry with precise and robust machines that perform better than their human counterparts in tiresome and tedious jobs. Likewise, robots can perform high precision tasks including in hazardous environments. However, a new area of research in robotics has emerged in the last decades, namely cognitive robotics. The main interest in this area is the study of cognitive processes in humans and their implementation and modeling in artificial agents. In cognitive robotics, the use of robots as platforms, in the study of cognition, is the best-suited mechanism as they naturally interact with their environment and learn through this interaction. Following these ideas, in these works, two low-level cognitive tasks are modeled and implemented in an artificial agent. Based on the ecological framework of perception, in the first experiment, an agent learns its body map. In the second experiment, the agent acquires a distance-to-obstacles concept. The agent is let to interact with its environment and allowed to build multimodal representations of its surroundings, known as affordances. Internal models are proposed as a conceptual mechanism which performs associations between different modalities. The results presented here provide the basis for further research on the capabilities of internal models as a constituent cognitive base for higher capabilities in artificial agents.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-77770-2_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-10-7037-2_4,Neural Networks for Robot Arm Cooperation with a Full Distributed Control Topology,Neural Networks for Cooperative Control of Multiple Robot Arms,10.1007/978-981-10-7037-2_4,Springer,2018-01-01,"This chapter considers cooperative kinematic control of multiple robot arms with a full distributed control topology by using distributed recurrent neural networks. The problem is formulated as a constrained game, where energy consumptions for each robot arm, saturations of control input, and the topological constraints imposed by the communication graph are taken into account. An implicit form of the Nash equilibrium for the game is obtained by converting the problem into its dual space. Then, a distributed dynamic controller based on recurrent neural networks is devised to drive the system towards the desired Nash equilibrium to seek the optimal solution of the cooperative control. Global stability and solution optimality of the neural networks are proved in theory. Simulations demonstrate the effectiveness of the method presented in this chapter.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-7037-2_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-63940-6_28,“Re:ROS”: Prototyping of Reinforcement Learning Environment for Asynchronous Cognitive Architecture,Biologically Inspired Cognitive Architectures (BICA) for Young Scientists,10.1007/978-3-319-63940-6_28,Springer,2018-01-01,"Reinforcement learning (RL), which is a field of machine learning, is effective for behavior acquisition in robots. Asynchronous cognitive architecture, which is a method to model human intelligence, is also effective for behavior acquisition. Accordingly, the combination of RL and asynchronous cognitive architecture is expected to be effective. However, early work on the RL toolkit cannot apply asynchronous cognitive architecture because it cannot solve the difference between the asynchrony, which the asynchronous cognitive architecture has, and the synchrony, which RL modules have. In this study, we propose an RL environment for robots that can apply the asynchronous cognitive architecture by applying asynchronous systems to RL modules. We prototyped the RL environment named “Re:ROS.”",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-63940-6_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-01836-8_22,Space-Game: Domestication of Humanoid Robots and AI by Generating a Cultural Space Model of Intra-action Between Human and Robot,Developing Support Technologies,10.1007/978-3-030-01836-8_22,Springer,2018-01-01,"Technical perception systems exhibit essential differences in comparison with human perception systems. Technical perception systems comprise geometry, numbers, and images. But humans can define only a very small portion of space by means of technically abstract values. Far more important are topologies of personal meanings rooted in cultural meanings. This leads to several problems. Humanoid robots are endowed with complex technical perception systems, unfolding a paradox: They are being developed for the most intimate areas of human existence, but they cannot participate in the human sphere of perception. Therefore, we have developed an approach that connects robotic and human perception systems. Humanoid robots are then understood as “ companions ”. The object of our approach is to develop a cultural model of space, involving robots, AI, and humans within the same context of meaning . Interaction design",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-01836-8_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-13-2874-9_2,Do We Need New Legal Personhood in the Age of Robots and AI?,"Robotics, AI and the Future of Law",10.1007/978-981-13-2874-9_2,Springer,2018-01-01,"Do we need to give robots Robot(s) and AI Artificial Intelligence (AI) entities a kind of legal personhood Legal personhood in a robotized society where activities with legal effect are increasingly performed by AI Artificial Intelligence (AI) systems and autonomous robots Robot(s) ? In this chapter, this question is considered by comparing the requirements of existing legal subjects, natural persons and (artificial) legal persons such as corporations and states. The relevance of free will, intelligence and consciousness of natural persons to acquire legal personhood Legal personhood are analysed and compared with other beings, animals Animal(s) and future AI Artificial Intelligence (AI) entities. To give legal personhood Legal personhood to AI Artificial Intelligence (AI) is also influenced by the human conviction that this would increase the risk to lose control and a “robot uprising.” Man, as always is afraid of technology getting out of hand and is convinced of their own superiority and therefore always wants to stay in control. In that context, the need for a certain legal personhood Legal personhood in a future legal framework, considering civil liability Civil liability and even criminal liability Liability is discussed as it is also subjected to considerations by the European Parliament, eventually leading to proposals in European law Law .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-2874-9_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-70836-2_14,Tactile Sensing and Machine Learning for Human and Object Recognition in Disaster Scenarios,ROBOT 2017: Third Iberian Robotics Conference,10.1007/978-3-319-70836-2_14,Springer,2018-01-01,"This paper presents the application of machine learning to tactile sensing for rescue robotics. Disaster situations often exhibit low-visibility scenarios where haptic feedback provides a valuable information for the search of potential victims. To extract haptic information from the environment, a tactile sensor attached to a lightweight robotic arm is used. Then, methods based on the SURF descriptor, support vector machines (SVM), Deep Convolutional Neural Networks (DCNN) and transfer learning are implemented to classify the data. Besides, experiments have been carried out, to compare those procedures, using different contact elements, such as human parts and objects that could be found in catastrophe scenarios. The best achieved accuracy of $$92.22\%$$ , results from the application of the transfer learning procedure using a pre-trained DCNN and fine-tuning the classification layer of the network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-70836-2_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-77770-2_6,Learning in Biologically Inspired Neural Networks for Robot Control,"Advanced Topics on Computer Vision, Control and Robotics in Mechatronics",10.1007/978-3-319-77770-2_6,Springer,2018-01-01,"Cognitive robotics has focused its attention on the design and construction of artificial agents that are able to perform some cognitive task autonomously through the interaction of the agent with its environment. A central issue in these fields is the process of learning. In its attempt to imitate cognition in artificial agents, cognitive robotics has implemented models of cognitive processes proposed in areas such as biology, psychology, and neurosciences. A novel methodology for the control of autonomous artificial agents is the paradigm that has been called neuro-robotics or embedded neural cultures, which aims to embody cultures of biological neurons in artificial agents. The present work is framed in this paradigm. In this chapter, simulations of an autonomous learning process of an artificial agent controlled by artificial action potential neural networks during an obstacle avoidance task were carried out. The implemented neural model was introduced by Izhikevich ( 2003 ); this model is capable of reproducing abrupt changes in the membrane potential of biological neurons, known as action potentials. The learning strategy is based on a multimodal association process where the synaptic weights of the networks are modified using a Hebbian rule. Despite the growing interest generated by artificial action potential neural networks, there is little research that implements these models for learning and the control of autonomous agents. The present work aims to fill this gap in the literature and at the same time, serve as a guideline for the design of further experiments for in vitro experiments where neural cultures are used for robot control.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-77770-2_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-68321-8_1,Synergetic Artificial Intelligence and Social Robotics,Proceedings of the Second International Scientific Conference “Intelligent Information Technologies for Industry” (IITI’17),10.1007/978-3-319-68321-8_1,Springer,2018-01-01,"The fundamentals of synergetic artificial intelligence and its relationships with swarm intelligence are considered. Basic classifications of agents and multi-agent systems are presented, the comparison between intelligent and reactive agents is made. Different synergy sources for conventional group intelligence and swarm intelligence are elicited. The concepts of swarms, swarm intelligence and swarm robotics are discussed. The principles and models of swarm tasks distribution via local interactions are formulated. The results of experimental investigation of pack-hunting task are analyzed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-68321-8_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-70833-1_48,Robust Hand Pose Regression Using Convolutional Neural Networks,ROBOT 2017: Third Iberian Robotics Conference,10.1007/978-3-319-70833-1_48,Springer,2018-01-01,"Hand pose estimation is useful for several human-computer interaction applications, like sign language recognition, the identification of more complex behaviors such as hand gestures and interaction in virtual reality applications. In this work, we propose a system which is able to predict the 2D hand joints using a monocular color camera. To do that, we propose to use a 3D hand tracking sensor for collecting ground truth information that is projected to the camera image plane. We present a novel pipeline that leverages deep learning techniques for hand pose estimation. The proposed Convolutional Neural Networks (CNN) is able to infer the joints of the hand from an image without the need of any additional sensor.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-70833-1_48,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-95972-6_10,Evolutionary Optimisation of Neural Network Models for Fish Collective Behaviours in Mixed Groups of Robots and Zebrafish,Biomimetic and Biohybrid Systems,10.1007/978-3-319-95972-6_10,Springer,2018-01-01,"Animal and robot social interactions are interesting both for ethological studies and robotics. On the one hand, the robots can be tools and models to analyse animal collective behaviours, on the other hand the robots and their artificial intelligence are directly confronted and compared to the natural animal collective intelligence. The first step is to design robots and their behavioural controllers that are capable of socially interact with animals. Designing such behavioural bio-mimetic controllers remains an important challenge as they have to reproduce the animal behaviours and have to be calibrated on experimental data. Most animal collective behavioural models are designed by modellers based on experimental data. This process is long and costly because it is difficult to identify the relevant behavioural features that are then used as a priori knowledge in model building. Here, we want to model the fish individual and collective behaviours in order to develop robot controllers. We explore the use of optimised black-box models based on artificial neural networks (ANN) to model fish behaviours. While the ANN may not be biomimetic but rather bio-inspired, they can be used to link perception to motor responses. These models are designed to be implementable as robot controllers to form mixed-groups of fish and robots, using few a priori knowledge of the fish behaviours. We present a methodology with multilayer perceptron or echo state networks that are optimised through evolutionary algorithms to model accurately the fish individual and collective behaviours in a bounded rectangular arena. We assess the biomimetism of the generated models and compare them to the fish experimental behaviours.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-95972-6_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-69814-4_58,Online Training the Radial Basis Function Neural Network Based on Quasi-Newton Algorithm for Omni-directional Mobile Robot Control,AETA 2017 - Recent Advances in Electrical Engineering and Related Sciences: Theory and Application,10.1007/978-3-319-69814-4_58,Springer,2018-01-01,"A radial basis function neural network (RBFNN) is a branch of neural network which performs good to control the dynamics system. Several researchers have proposed many approaches to train RBFNN such as Gradient Descent (GD), Newton’s method, Conjugate Gradient, Quasi-Newton, Levenberg Marquardt. This paper presents the Quasi-Newton method with Broyden – Fletcher – Grodfarb – Shanno (BFGS) for online training the RBFNN. The Quasi-Newton method was studied as one of the most effect optimization algorithms based on the gradient descent. After being trained, the RBFNN is applied to control Omni-directional mobile robot based on sliding mode controller. The RBFNN is considered as an adaptive controller. The simulation results in MATLAB Simulink show that the proposed algorithm is efficient, the response of adaptive sliding mode controller with Quasi-Newton algorithm converge to reach the trajectory.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-69814-4_58,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-10-5699-4_3,Virtual Experimental Analysis of Redundant Robot Manipulators Using Neural Networks,Soft Computing: Theories and Applications,10.1007/978-981-10-5699-4_3,Springer,2018-01-01,"This study presents a theoretical–experimental scheme to control a redundant robot manipulator in the presence of unmodeled dynamics and discontinuous friction. The proposed control scheme does not require a priori knowledge of upper bounds, robot’s parameters, and external disturbance. The advantage of a feed-forward neural network (FFNN) controller is its robustness and ability to handle the model uncertainties. The virtual experimental results are carried out for a three-link planar redundant manipulator to show the effectiveness of the controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-5699-4_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-00937-3_32,Surgical Activity Recognition in Robot-Assisted Radical Prostatectomy Using Deep Learning,Medical Image Computing and Computer Assisted Intervention – MICCAI 2018,10.1007/978-3-030-00937-3_32,Springer,2018-01-01,"Adverse surgical outcomes are costly to patients and hospitals. Approaches to benchmark surgical care are often limited to gross measures across the entire procedure despite the performance of particular tasks being largely responsible for undesirable outcomes. In order to produce metrics from tasks as opposed to the whole procedure, methods to recognize automatically individual surgical tasks are needed. In this paper, we propose several approaches to recognize surgical activities in robot-assisted minimally invasive surgery using deep learning. We collected a clinical dataset of 100 robot-assisted radical prostatectomies (RARP) with 12 tasks each and propose ‘RP-Net’ , a modified version of InceptionV3 model, for image based surgical activity recognition. We achieve an average precision of 80.9% and average recall of 76.7% across all tasks using RP-Net which out-performs all other RNN and CNN based models explored in this paper. Our results suggest that automatic surgical activity recognition during RARP is feasible and can be the foundation for advanced analytics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-00937-3_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-76947-9_14,Temporal Difference (TD) Based Critic-Actor Adaptive Control for a Fine Hand Motion Rehabilitation Robot,Mechatronics and Machine Vision in Practice 3,10.1007/978-3-319-76947-9_14,Springer,2018-01-01,"Robot assisted post-stroke rehabilitation training is an effective approach in delivering the highly intensive repetitive training, aiming to retrain the neural pathways in the brain thus to restore and improve the affected mobility skills. The adaptive control of robotic devices, especially assist-as-needed control providing exact assistive force intensity along the intended motion trajectory for fine motion, can be a complex but effective method. A temporal difference based critic-actor reinforcement learning control method is explored in this study. The effectiveness of the method is verified through Matlab simulation and implemented on a hand rehabilitation robotic device. Results suggest that the control system can fulfil the control task with high performance and reliability, thus holding the promise of improving the fine hand motion rehabilitation training efficiency.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-76947-9_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-70833-1_49,3D Semantic Maps for Scene Segmentation,ROBOT 2017: Third Iberian Robotics Conference,10.1007/978-3-319-70833-1_49,Springer,2018-01-01,"The semantic segmentation problem has been widely studied in the computer vision community. However, state-of-the-art solutions based on deep learning are only available for 2D images. The lack of large annotated datasets makes more difficult the training of models with 3D images. In this work we propose to use the already available 2D deep learning based solutions to semantically segment the 3D environment for robotic applications. Concretely, deep learning applications provide the semantic labeling, and the geometrical information from RGB-D cameras along with the robot pose provides the 3D position.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-70833-1_49,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-00308-1_13,Follow Me: Real-Time in the Wild Person Tracking Application for Autonomous Robotics,RoboCup 2017: Robot World Cup XXI,10.1007/978-3-030-00308-1_13,Springer,2018-01-01,"In the last 20 years there have been major advances in autonomous robotics. In IoT (Industry 4.0), mobile robots require more intuitive interaction possibilities with humans in order to expand its field of applications. This paper describes a user-friendly setup, which enables a person to lead the robot in an unknown environment. The environment has to be perceived by means of sensory input. For realizing a cost and resource efficient Follow Me application we use a single monocular camera as low-cost sensor. For efficient scaling of our Simultaneous Localization and Mapping (SLAM) algorithm, we integrate an inertial measurement unit (IMU) sensor. With the camera input we detect and track a person. We propose combining state of the art deep learning with Convolutional Neural Network (CNN) and SLAM algorithms functionality on the same input camera image. Based on the output robot navigation is possible. This work presents the specification, workflow for an efficient development of the Follow Me application. Our application’s delivered point clouds are also used for surface construction. For demonstration, we use our platform SCITOS G5 equipped with the afore mentioned sensors. Preliminary tests show the system works robustly in the wild (This work is partially supported by a grant of the BMBF FHprofUnt program, no. 03FH049PX5).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-00308-1_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-76369-9_1,SSML for Sex Robots,Love and Sex with Robots,10.1007/978-3-319-76369-9_1,Springer,2018-01-01,"In love and sex, the voice is a decisive factor. It not only matters what is said, but also how it is said. Pitch, volume and personal expression are important to attract and retain potential partners. The same goes for sex robots and love dolls, and is true for chatbots and virtual assistants with sexual orientation as well. If you are not working with ordinary recordings, they all need artificial voices (if you decide to use voices at all). The synthetization of voices, or speech synthesis, has been an object of interest for centuries. Today, it is mostly realized with a text-to-speech system (TTS), an automaton that interprets and reads aloud. This system refers to text which is available for instance in a knowledge base or on a website. Different procedures have been established to adjust the artificial voice. This article examines how the Speech Synthesis Markup Language (SSML) can be used for sex robots and love servants. Existing tags, attributes and values are categorized in the present context and new ones are proposed to support the purpose of the special machines. In addition, a short ethical discussion takes place.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-76369-9_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-97586-3_15,Hand Detection and Location Based on Improved SSD for Space Human-Robot Interaction,Intelligent Robotics and Applications,10.1007/978-3-319-97586-3_15,Springer,2018-01-01,"In the astronaut-space robot interaction based on hand gestures, the detection and location of hands are the premise and basis of vision-based hand gesture recognition and hand tracking. In this paper, the SSD (Single Shot Multibox Detector) which is a kind of deep learning model is utilized to detect and locate astronaut’s hands for space human-robot interaction (SHRI) based on hand gestures. First of all, in order to meet the needs of hand detection and location, an improved SSD model is designed to detect hands when they are shown as small targets in images. Then, a platform for SHRI is built and a set of hand gestures for SHRI are designed. Finally, the proposed SSD model is validated experimentally on a homemade hand gesture database for proving the superiority of this improved SSD model to small target hands detection.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-97586-3_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-04239-4_21,Adaptive Modeling and Control of an Upper-Limb Rehabilitation Robot Using RBF Neural Networks,Neural Information Processing,10.1007/978-3-030-04239-4_21,Springer,2018-01-01,"Robot-assisted rehabilitation following neurological injury is most successful when subject participation is maximized in the training tasks. Developing control strategies that can provide subject-specific assistance is accordingly an active area of research. For robot-assisted rehabilitation training, it is challenging to adapt the robotic assistance to each patient’s impairment, and model-based control methods in previous studies are difficult to implement because of the computational complexity of human-robot interaction dynamics and changes of human active efforts during rehabilitation exercises. This study implements adaptive modeling and control for an two-DOF upper-limb rehabilitation robot by combining an RBF-based feedforward controller with a feedback impedance controller. Simulation and experiment results show that, the RBF neural network is able to adaptively establish the human-robot dynamics as well as estimating the human efforts, and the impedance controller guarantees compliant human-robot interaction and regulates the maximal tolerated tracking error. Besides, the proposed controller is defined in the robot workspace, thus is easy to be generalized to be used for multi-DOFs exoskeleton-type rehabilitation robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-04239-4_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-89743-1_49,Facial Expressions Recognition: Development and Application to HMI,Computational Intelligence and Its Applications,10.1007/978-3-319-89743-1_49,Springer,2018-01-01,"We present in this paper, a facial expressions recognition system to command a mobile robot (Pionner-3DX). The proposed system mainly consists of two modules: facial expression recognition and robot command. The first module aims to recognize the facial expressions like happiness, sadness, surprise, anger, fear, disgust and neutral using Gradient Vector Flow (GVF) snake to find ROI (Region Of Interest like: mouth, eyes, eyebrow) segmentation from FEEDTUM database (video file). While the second module, analyses the segmented ROI to recognize with Euclidian distance calculation (compatible with the MPEG-4 description of the six universal emotions) and Time Delay Neural Network classifier. Finally, the recognized facial expressions were used as control commands for the mobile robot displacement (forward; backward; turn left; turn right) in ROS (Robot Operating System).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-89743-1_49,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-63429-6_1,The Development of Robotic Surgery: Evolution or Revolution?,Textbook of Gynecologic Robotic Surgery,10.1007/978-3-319-63429-6_1,Springer,2018-01-01,"The history of mechanical automatons can be traced back to the ancient world with the development of the earliest mechanical machinery. During the fourth century BC, the Greek mathematician Archytas designed a mechanical bird, ‘the pigeon’ driven by steam. In 320 BC Aristotle postulated that automatons would replace human slavery. He quoted Greek mythology in which Hephaestus, the Greek god of craftsmen, created three-legged tables that could action under their own power.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-63429-6_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-91253-0_17,Motivated Reinforcement Learning Using Self-Developed Knowledge in Autonomous Cognitive Agent,Artificial Intelligence and Soft Computing,10.1007/978-3-319-91253-0_17,Springer,2018-01-01,"This paper describes the development of a cognitive agent using motivated reinforcement learning. The conducted research was based on the example of a virtual robot, that placed in an unknown maze, was learned to reach a given goal optimally. The robot should expand knowledge about the surroundings and learn how to move in it to achieve a given target. The built-in motivation factors allow it to focus initially on collecting experiences instead of reaching the goal. In this way, the robot gradually broadens its knowledge with the advancement of exploration of its surroundings. The correctly formed knowledge is used for effective controlling the reinforcement learning routine to reach the target by the robot. In such a way, the motivation factors allow the robot to adapt and control its motivated reinforcement learning routine automatically and autonomously.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-91253-0_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-65978-7_82,A New Behavior Recognition Method of Nursing-Care Robots for Elderly People,Recent Developments in Mechatronics and Intelligent Robotics,10.1007/978-3-319-65978-7_82,Springer,2018-01-01,"Based on the optical flow technology, a convolutioal neural network (CNN) is proposed for nursing-care robots to perform the behavior recognition task, which considered both static and dynamic information during human motions, thus it is more accurate than the traditional CNN. Firstly, a behavior processing method, combining with Lucas-Kanade optical flow technology, is elaborately designed and tested. In this method, the limitation of static processing method existed in CNN is solved well, then the method is applied to a CNN model for behavior recognition task. Simulation experiment has been carried out, indicating that this method can achieve a higher recognition accuracy and obtain a good recognition effect successfully.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-65978-7_82,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-99582-3_8,Sign Language Numeral Gestures Recognition Using Convolutional Neural Network,Interactive Collaborative Robotics,10.1007/978-3-319-99582-3_8,Springer,2018-01-01,"This paper presents usage of convolutional neural network for classification of sign language numeral gestures. For requirements of this research, we created a new dataset of these gestures. The dataset was recorded via Kinect v2 device and it consists of recordings of 18 different people. Only depth data-stream was used in our research. For a classification task, there was utilized classic VGG16 architecture and its results were compared with chosen baseline method and other tested architectures. Our experiment on classification showed the great potential of neural networks for this task. We reached recognition accuracy 86.45%, which is by more than 34% better result than chosen baseline method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-99582-3_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-63940-6_25,Realization of the Gesture Interface by Multifingered Robot Hand,Biologically Inspired Cognitive Architectures (BICA) for Young Scientists,10.1007/978-3-319-63940-6_25,Springer,2018-01-01,"The paper considers theoretical mechanical model of a multifingered arm with 21 degrees of freedom. The main objective of the work is the creation of gesture interface. Gesture interface includes the set of gestures, the synthesis of finger control schemes for 26 gestures, as well as gesture recognition task with the help of convolutional neural network training. As the demonstration we propose to observe the results of 26 gestures recognition with the help of constructed convolutional network. For 26 classes 15600 images at different distance and at different angles were created. As a result of convolutional neural network training the accuracy of a test set classification is 76%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-63940-6_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-04497-8_24,An Adaptive Robotic Assistance Platform for Neurorehabilitation Therapy of Upper Limb,Advances in Computational Intelligence,10.1007/978-3-030-04497-8_24,Springer,2018-01-01,"There are many human-robot physical interaction methods for physical therapy in patients of upper limbs disabilities. The use of haptic devices for this purpose is abundant, as are the different proposals for motion control in haptic guidance, as part of a clinical protocol with the patient in the loop. A conclusive result of these interaction platforms is the need to modify elements of the control strategy and the motion planning, this for each patient. In this paper, we propose a new approach to the control of human-robot physical interaction systems. To guarantee the bilateral energy flow between the robotic system and the patient under stable conditions and, without modifying the interaction platform; we propose an adaptive control structure, free of the dynamic model. The control scheme is called PID Wavenet, and identifies the dynamics using a radial basis neural network with daughter RASP1 wavelets activation function; its output is in cascaded with an infinite impulse response (IIR) filter toprune irrelevant signals and nodes as well as to recover a canonical form. Then, online adaptive of a discrete PID regulator is proposed, whose closed-loop guarantees global regulation for nonlinear dynamical plants, in our case a haptic device with the human in the loop. Effectiveness of the proposed method is verified by the real-time experiments on a Geomagic Touch haptic interface.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-04497-8_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-97676-1_4,Associative Memory: An Spiking Neural Network Robotic Implementation,Artificial General Intelligence,10.1007/978-3-319-97676-1_4,Springer,2018-01-01,"This article proposes a novel minimalist bio-inspired associative memory (AM) mechanism based on a spiking neural network acting as a controller in simple virtual and physical robots. As such, several main features of a general AM concept were reproduced. Using the strength of temporal coding at the single spike resolution level, this study approaches the AM phenomenon with basic examples in the visual modality. Specifically, the AM include varying time delays in synaptic links and asymmetry in the spike-timing dependent plasticity learning rules to solve visual tasks of pattern-matching, pattern-completion and noise-tolerance for autoassociative and heteroassociative memories. This preliminary work could serve as a step toward future comparative analysis with traditional artificial neural networks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-97676-1_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-04497-8_23,Design and Equilibrium Control of a Force-Balanced One-Leg Mechanism,Advances in Computational Intelligence,10.1007/978-3-030-04497-8_23,Springer,2018-01-01,"The problem of equilibrium is critical for planning, control, and analysis of legged robot. Control algorithms for legged robots use the equilibrium criteria to avoid falls. The computational efficiency of the equilibrium tests is critical. To comply with this it is necessary to calculate the horizontal momentum rotation for every moment. For arbitrary contact geometries, more complex and computationally-expensive techniques are required. On the other hand designing equilibrium controllers for legged robots is a challenging problem. Nonlinear or more complex control systems have to be designed, complicating the computational cost and demanding robust actuators. In this paper, we propose a force-balanced mechanism as a building element for the synthesis of legged robots that can be easily balance controlled. The mechanism has two degrees of freedom, in opposition to the more traditional one degree of freedom linkages generally used as legs in robotics. This facilitates the efficient use of the “projection of the center of mass” criterion with the aid of a counter rotating inertia, reducing the number of calculations required by the control algorithm. Different experiments to balance the mechanism and to track unstable set-point positions have been done. Proportional error controllers with different strategies as well as learning approaches, based on an artificial intelligence method namely artificial hydrocarbon networks, have been used. Dynamic simulations results are reported. Videos of experiments will be available at: https://sites.google.com/up.edu.mx/smart-robotic-legs/ .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-04497-8_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-00308-1_8,Toward Real-Time Decentralized Reinforcement Learning Using Finite Support Basis Functions,RoboCup 2017: Robot World Cup XXI,10.1007/978-3-030-00308-1_8,Springer,2018-01-01,"This paper addresses the design and implementation of complex Reinforcement Learning (RL) behaviors where multi-dimensional action spaces are involved, as well as the need to execute the behaviors in real-time using robotic platforms with limited computational resources and training times. For this purpose, we propose the use of decentralized RL, in combination with finite support basis functions as alternatives to Gaussian RBF, in order to alleviate the effects of the curse of dimensionality on the action and state spaces respectively, and to reduce the computation time. As testbed, a RL based controller for the in-walk kick in NAO robots, a challenging and critical problem for soccer robotics, is used. The reported experiments show empirically that our solution saves up to 99.94% of execution time and 98.82% of memory consumption during execution, without diminishing performance compared to classical approaches.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-00308-1_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-00308-1_30,Interactive Machine Learning Applied to Dribble a Ball in Soccer with Biped Robots,RoboCup 2017: Robot World Cup XXI,10.1007/978-3-030-00308-1_30,Springer,2018-01-01,"An Interactive Machine Learning (IML) approach for training a dribbling engine for humanoid biped robots in RoboCup competitions (Standard Platform League) is presented. The proposed dribbling approach solves two decision problems: the determination of the dribbling direction and the calculation of the walking velocities required for pushing the ball toward the desired direction. Moreover, the prediction of the position of moving balls is used for improving the dribbling performance, when it is needed to intercept a moving ball. A combination of batch and incremental learning is used for shaping the policies of the dribbling controller. Results obtained from previous RoboCup competitions, and also from specific experiments, validate the proposed methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-00308-1_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-96978-7_18,Machine Learning and ‘The Cloud’ for Natural Resource Applications: Autonomous Online Robots Driving Sustainable Conservation Management Worldwide?,Machine Learning for Ecology and Sustainable Natural Resource Management,10.1007/978-3-319-96978-7_18,Springer,2018-01-01,"The advent of the internet was arguably the most important development in modern society. It has altered nearly every aspect of modern social behavior and therefore represents one of the (if not ‘THE’) biggest changes humankind has ever experienced. The internet has shifted paradigms in thinking, particularly in science and natural resource management, as we are now able to store and deliver data faster than ever. However, the internet also played a major role in moving us further into the Anthropocene due to its role in globalization, related climate change, wilderness degradation and ongoing over-population. Despite the implications for the natural world, the dramatic increase in internet accessibility has yet to be studied with regards to ethical considerations in ecology. In this chapter, we take an approach reflective of human optimism and focus on one of the ‘pros’ of the internet by examining how the cloud can be used with machine learning algorithms to explore aspects and sustainability of natural resource management. We present an overview of several ecological applications which take advantage of cloud computing and machine learning that have already left a global impact. Secondly, we show how machine learning in the cloud is likely to be employed in the near future for natural resource management. Lastly, we conclude with a holistic perspective on governance of global sustainability that takes the carbon and energy footprint of the cloud into account. While technology is increasingly driving global decision making, we argue that ecological and associated ethical considerations and their global constraints must be fully considered to ensure a truly sustainable society.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-96978-7_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-3453-2_6,Reinforcement Learning and Robotics,Introduction to Deep Learning Business Applications for Developers,10.1007/978-1-4842-3453-2_6,Springer,2018-01-01,"Because of the recent achievements of deep learning [GBC16] benefiting from big data, powerful computation, and new algorithmic techniques, you have been witnessing the renaissance of reinforcement learning, especially the combination of reinforcement learning and deep neural networks such as deep reinforcement learning (deep RL). Deep Q-networks (DQNs) have ignited the field of deep RL [MKS+15] by allowing machines to achieve superhuman performance in Atari games and the very hard board game of Go.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4842-3453-2_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-76261-6_4,Methodology for Learning Multimodal Instructions in the Context of Human-Robot Interaction Using Machine Learning,Intelligent Computing Systems,10.1007/978-3-319-76261-6_4,Springer,2018-01-01,"This work shows the design, implementation and evaluation of a human-robot interaction system where a robot is capable of learning multimodal instructions through gestures and voice issued by a human user. The learning procedure can be performed in two ways: an instruction learning phase, where the human aims at teaching one instruction to the robot by performing several repetitions and an instruction receiving phase where the robot reacts to the instructions given by the human and possibly asks for feedback from the user to strengthen the instruction’s model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-76261-6_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-72926-8_26,Estimating Dynamics of Honeybee Population Densities with Machine Learning Algorithms,"Machine Learning, Optimization, and Big Data",10.1007/978-3-319-72926-8_26,Springer,2018-01-01,"The estimation of the density of a population of behaviourally diverse agents based on limited sensor data is a challenging task. We employed different machine learning algorithms and assessed their suitability for solving the task of finding the approximate number of honeybees in a circular arena based on data from an autonomous stationary robot’s short range proximity sensors that can only detect a small proportion of a group of bees at any given time. We investigate the application of different machine learning algorithms to classify datasets of pre-processed, highly variable sensor data. We present a new method for the estimation of the density of bees in an arena based on a set of rules generated by the algorithms and demonstrate that the algorithm can classify the density with good accuracy. This enabled us to create a robot society that is able to develop communication channels (heat, vibration and airflow stimuli) to an animal society (honeybees) on its own.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-72926-8_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-70581-1_1,GMDH-Based Learning System for Mobile Robot Navigation in Heterogeneous Environment,Advances in Intelligent Systems and Computing II,10.1007/978-3-319-70581-1_1,Springer,2018-01-01,"One of the key tasks of mobile robotics is navigation, which for Outdoor-type robots is exacerbated by the functioning in an environment with a priori of unknown characteristics of underlying surfaces. In this paper, for the first time, the learning navigation system for mobile robot based on the group method of data handling (GMDH) is presented. The paper presents the results of training of models both for evaluating the robot’s pose (coordinates and angular orientation) in heterogeneous environment and classification of the type of underlying surfaces. In addition to the direct readings of the on-board sensors, additional parameters (reflecting how the robot perceives the surface terramechanics) were introduced to train the models. The results of testing of the obtained models demonstrate their performance in an essentially heterogeneous environment, when areas of the underlying surfaces are comparable with the robot’s dimensions. This testifies the operability of developed GMDH-based learning system for mobile robot navigation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-70581-1_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-90403-0_15,Group Cognition and Collaborative AI,Human and Machine Learning,10.1007/978-3-319-90403-0_15,Springer,2018-01-01,"Significant advances in artificial intelligence suggest that we will be using intelligent agents on a regular basis in the near future. This chapter discusses group cognition Group cognition as a principle for designing collaborative AI Collaborative AI . Group cognition is the ability to relate to other group members’ decisions, abilities, and beliefs. It thereby allows participants to adapt their understanding and actions to reach common objectives. Hence, it underpins collaboration. We review two concepts in the context of group cognition that could inform the development of AI and automation in pursuit of natural collaboration with humans: conversational grounding and theory of mind. These concepts are somewhat different from those already discussed in AI research. We outline some new implications for collaborative AI, aimed at extending skills and solution spaces and at improving joint cognitive and creative capacity.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-90403-0_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-75193-1_8,Traversability Cost Identification of Dynamic Environments Using Recurrent High Order Neural Networks for Robot Navigation,"Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications",10.1007/978-3-319-75193-1_8,Springer,2018-01-01,"In this paper, it is presented a neural network methodology for learning traversability cost maps to aid autonomous robotic navigation. This proposal is based on the control theory idea for dynamical system identification i.e. we solve the problem of learning and recognizing the pattern which describes the best the behavior of the cost function that represents the environment to obtain traversability cost maps as if we are identifying a dynamical system that is the rough terrain where the robot navigates. Recurrent High Order Neural Networks (RHONN) trained with Extended Kalman Filter (EKF) are used to identify rough terrain traversability costs, and besides the good results in the identification tasks, we get the advantages of using a robust machine learning method such as RHONNs. Our proposal gives the robot the capability to generalize the knowledge learned in previous navigation episodes when it is navigating on similar (but not necessarily equal) environments, so the robot can re-use learned knowledge, generalize it and also it can recognize hidden states. Experimental results show that our proposed approach can identify and learn very complex cost maps, we prove it with artificially generated maps as well as satellite maps of real land.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-75193-1_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-10-8237-5_30,Vision-Based Forward Kinematics Using ANN for Weld Line Detection with a 5-DOF Robot Manipulator,Advanced Computational and Communication Paradigms,10.1007/978-981-10-8237-5_30,Springer,2018-01-01,"While robotic manipulators are becoming a common sight in today’s industries and fast paced production lines, it is becoming difficult to develop foolproof methods for automation of these manipulators, owing to their geometric and structural variety. Creating a common algorithm for these manipulators would help in setting a base standard for their automation. Trio Motion coordinators are most widely used for robotic manipulators in recent times. The objective of this paper is to create a simple interface based on Visual Basic programming language to coordinate directly with the robot’s motion coordinator by bypassing all other programming methods which are otherwise needed for sending commands to the robot. This interface can be easily adapted for further tuning methods and also for more or lesser degrees-of-freedom robotic manipulators. MATLAB has been used for detecting the weld line in the image using image processing techniques. A suitable artificial neural network has been used to give forward kinematic solutions with image coordinates as the input.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-8237-5_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-01424-7_77,Kinematic Estimation with Neural Networks for Robotic Manipulators,Artificial Neural Networks and Machine Learning – ICANN 2018,10.1007/978-3-030-01424-7_77,Springer,2018-01-01,"In this paper, we focus on estimating the forward kinematic equation of robots with multilayer feed-forward neural networks. The effectiveness of this approach is tested on a simulated kinematic model of the 7-DOF Sawyer Robotic Arm. In the initial sections of the paper, we discuss related work that associates with the creation of model agnostic control schemes on a kinematic level. Moreover, we formalize the kinematic problem as a supervised problem and we propose an MLP architecture to solve the problem. Lastly, we present experimental results and discuss the potential and importance to create model agnostic control schemes with machine learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-01424-7_77,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-77158-8_4,Ownership: The Extended Self and the Extended Object,Psychological Ownership and Consumer Behavior,10.1007/978-3-319-77158-8_4,Springer,2018-01-01,"This chapter updates our notions of ownership in several ways. It notes changes in traditional ownership with the dematerialization of possessions with digitization of books, newspapers, films, letters, and music. It also considers how the rise of the sharing economy affects ownership. It considers who and what may be owned and by whom or what in the case of slaves, AI, the IoT, and humanoid robots. It considers military and ethical considerations that arise with battlefield robots and drones. It introduces decentralized autonomous organizations (DAOs); it considers human-robot relations, including sexual relations; and it discusses robot rights. Finally, it considers how such factors affect the extended self and offers a counterpart in the extended object.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-77158-8_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-13-2874-9_9,"I, Inhuman Lawyer: Developing Artificial Intelligence in the Legal Profession","Robotics, AI and the Future of Law",10.1007/978-981-13-2874-9_9,Springer,2018-01-01,"What are the possibilities of having AI Artificial Intelligence (AI) lawyers in the true sense—as autonomous, decision-making agents that can legally advise us or represent us? This chapter delves into the problems and possibilities of creating such systems. This idea is inevitably faced with a multitude of challenges, among them the challenge of translating law Law into an algorithm Algorithm being the most fundamental for the beginning of the creation of an AI Artificial Intelligence (AI) lawyer. Moreover, the chapter examines the linguistic aspects of such a translation and later moves on into the ethical aspect of creating such lawyers and ethically codifying their conduct. This is followed by a brief deliberation on whether Asimov’s Three Laws of Robotics Robotics would be helpful in this regard. The ethical discussion results in a proposal for a concept of Fairness by Design, conceived as the minimum standard for ethical behavior instilled in all AI Artificial Intelligence (AI) agents. The chapter also attempts to give a general overview of the current state-of-the-art AI Artificial Intelligence (AI) technologies employed in the legal domain Legal domain as well as imagines the future of AI Artificial Intelligence (AI) in Law Law . Subsequently, the chapter imagines an AI Artificial Intelligence (AI) agent deal with and resolve the “Solomon test” of splitting the baby. Finally, it is concluded that the advantage of having AI Artificial Intelligence (AI) lawyers can be measured by the possibility of redefining the legal profession Legal profession in its entirety as well as making legal advice and justice more accessible to all.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-2874-9_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-662-57600-7_10,Employee and Citizen Ownership of Business Capital in the Age of AI Robots,CSR und Mitarbeiterbeteiligung,10.1007/978-3-662-57600-7_10,Springer,2018-01-01,"This paper seeks to convince you that the best response to the coming dominance of AI robots in the world of work is to expand both employee ownership of firms and citizen ownership of business capital more broadly. Section 1 analyzes the likely effects of advances in AI robot technologies on the comparative advantage of machines versus humans in high-value-added work and the consequences for wages and salaries and income inequality. Section 2 argues that the best way to assure that living standards increase for all in the age of AI robots is through enhanced employee ownership and greater citizens’ stake in business capital, distributing capital income far more widely than today.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-662-57600-7_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-92052-8_43,Development of Thought Using a Humanoid Robot in an Elementary School Classroom,"Universal Access in Human-Computer Interaction. Virtual, Augmented, and Intelligent Environments",10.1007/978-3-319-92052-8_43,Springer,2018-01-01,"Sociable robots are being used increasingly as interfaces for various services. Children born after 2010, i.e., the “artificial intelligence generation,” are familiar with social robotic interfaces, and such interfaces can be an essential factor in their mental development. In this case study, the NAO humanoid robot was introduced to elementary school students, where the topic focused on the question “What is life for me?” Learning activities involved collaborative discussions with NAO, questioning a NAO programmer, watching a movie about a care robot, group discussions, activities in which the students pretended to be NAO while speaking to a human, and individual reflective writing. The learning activities did not involve lectures. Changes in student awareness were tracked based on their writings and recorded discussions. Initially, the students were interested in the robot’s mechanical functions. However, over time, following programming activities, consideration of NAO’s commonalities with humans, and discussions about the life of NAO, the students became aware that it was natural to feel that NAO possessed life while simultaneously understanding its mechanical nature. It is considered that the students projected their own consciousness onto NAO and expected NAO and expected it to feel happiness when working together.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-92052-8_43,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-56991-8_44,Rule-Based System to Assist a Tele-Operator with Driving a Mobile Robot,Proceedings of SAI Intelligent Systems Conference (IntelliSys) 2016,10.1007/978-3-319-56991-8_44,Springer,2018-01-01,"Simple real time AI techniques are presented that support tele-operated mobile robot operators when they are steering. They permit a tele-operator to be included in the steering as much as possible, while offering help when required to avoid obstacles and to reach their target destination. The direction to a destination (via point) becomes an extra input along with the usual inputs from a joystick and an obstacle avoidance sensor system. A recommended direction is suggested and that is mixed with joystick position and angle. A rule-based system provides a suggested angle to turn the robot and that is mixed with input from a joystick to help a tele-operator to steer their mobile robot towards a destination.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-56991-8_44,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-05587-5_42,Self-programming Robots Boosted by Neural Agents,Brain Informatics,10.1007/978-3-030-05587-5_42,Springer,2018-01-01,"This paper deals with Brain-Inspired robot controllers, based on a special kind of artificial neural structures that burn “dark” energy to promote the self-motivated initiation of behaviors. We exploit this ambient to train a virtual multi-joint robot, with many moving parts, muscles and sensors distributed through the robot body, interacting with elements that satisfy Newtonian laws. The robot faces a logical-mechanical challenge where a heavy, slippery ball, pressed against a wall has to be pushed up by means of coordinate muscles activation, where energy, timing and balancing conditions add noticeable technical complications. As in living brains our robots contains self-motivating neural agents that consumes energy and function by themselves even without external stimulus. Networks that handle sensory and timing information are combined with agents to construct our controller. We prove that by using appropriate learning algorithms, the self-motivating capacity of agents provides the robot with powerful self-programming aptitudes, capable of solving the ball lifting problem in a quick, efficient way.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-05587-5_42,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-51466-6_1,Robots and Political Economy,The Political Economy of Robots,10.1007/978-3-319-51466-6_1,Springer,2018-01-01,"Fears of artificial intelligence Artificial intelligence -induced apocalypse and Terminator conundrums reveal an enduring puzzle concerning the prospects for human prosperity and security in an automated global political economy. This puzzle reflects human fear of the unknown and the unpredictability of technological change. Each contribution herein, constitutes brief interventions intended to provoke reflection, deliberation, and investigation into the practical implications to human affairs presented by the advent of autonomous robots, artificial intelligence, and, more generally, automated and autonomous information technologies. Our objective is to emphasize that understanding how human affairs will affect and be effected by such technologies must include, in addition to theory, an analysis of how automated and autonomous information technologies may alter practices of human affairs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-51466-6_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-91803-7_39,HRI Design Research for Intelligent Household Service Robots: Teler as a Case Study,"Design, User Experience, and Usability: Designing Interactions",10.1007/978-3-319-91803-7_39,Springer,2018-01-01,"This paper analyzes the human-robot interaction (HRI) design based on artificial intelligence technology. Combined with the needs of artificial intelligence technology, this paper summed up the new characteristics of human-robot interaction which include high dimension, high tolerance, complex scenario merged with context awareness computing, consciousness awareness computing and emotion awareness computing. Take Teler, a household robot of Robotics Interaction Lab in Intel Labs China as the reference case, the paper analyzes the methods and characteristics of household robotics human-computer interaction. Multi-channel information input portal, parallel interactive framework and multi-sensory collaborative feedback are the new interaction design requirements. The paper summarizes the advantage and disadvantages of robot-human interaction in artificial intelligence field, sorts out information classification and information processing. In this paper, we present three human-robot interactive relationships which include passive feedback, proactive learning and active feedforward, and maps the three relationships with accurate command interaction, semi-opening dialog interaction and opening dialog system interaction. The three types of HRI associate with the different mental model, interaction model, information architecture, interactive behavior logic, information visualization and interface design. The paper presents the new method of interaction design for household robot context-awareness interaction and use the case Teler AI household service robot human-robot interaction design to verify the user experience targets and usability targets.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-91803-7_39,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-74322-6_17,Prototype-Based Research on Immersive Virtual Reality and on Self-Replicating Robots,Business Information Systems and Technology 4.0,10.1007/978-3-319-74322-6_17,Springer,2018-01-01,"This chapter presents our recent research in the field of virtual reality (VR) and self-replicating robots. The unifying approach lies in the research philosophy of using consumer market gadgets, mostly developed for the gaming and entertainment business, in order to design and implement research prototypes. With the prototypes, our research aims to better understand real-world problems and derive practice-oriented solutions for them. In the field of VR, these prototypes are dedicated to identifying new business-relevant use cases in order to provide an additional benefit for business and society. A wide range of examples, such as claustrophobia treatment, financial data analysis, gesture control and voice navigation are discussed. In the field of robotics, the idea of self-replicating robots governs particular research questions. Here, the focus is on using model prototypes enriched with artificial intelligence for indoor navigation, computer vision and machine learning. Finally, the prototype-based research approach using gadgets to produce results is discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-74322-6_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-64352-6_91,Artificial Intelligence and Collaborative Robot to Improve Airport Operations,Online Engineering & Internet of Things,10.1007/978-3-319-64352-6_91,Springer,2018-01-01,"Since air traffic is increasing, airport operations have to be more efficient and obviously still stay safe. To do so, it is important to find innovative solutions to improve those operations. Two projects are presented in this paper. The first one is an intelligent video surveillance to monitor airport operations. The second one is a collaborative mobile robot to improve maintenance time and traceability of maintenance operations. Those two solutions are the first steps in direction of the airport of the future. Management of the operations, autonomous vehicles, non-destructive testing and human-machine collaborations will evolve and change the airport activities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-64352-6_91,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-10-5687-1_31,Design and Development of Intelligent AGV Using Computer Vision and Artificial Intelligence,Soft Computing: Theories and Applications,10.1007/978-981-10-5687-1_31,Springer,2018-01-01,"The main aim of this paper is to develop a smart material handling system using an AGV (automated guided vehicle). The task is to transport a container of a fixed size from a defined start point to a defined end point. There is an overhead camera located at the boundary of the arena, in such a way that complete arena can be seen in a single frame. The camera will be capturing real-time images of the vehicle to determine its position and orientation using OpenCV library. The computer will also perform the task of path planning by using various artificial intelligence algorithms like RRT (rapidly random exploring tree) and A* (A Star). The outcome of this process will be the shortest path from beginning point to finish point while avoiding the obstacles. The commands should be enough for the robot to understand where it should go next, i.e., the next pose for the robot. This process continues until the goal is reached. To achieve this, few algorithms are developed for shape detection and edge detection. They help in determining the obstacles and the free area/ path where robot can traverse. The image from overhead camera is used to make the shortest global path from start to end using image processing. The computer will do this using various packages in ROS (robot operating system). This global path will generate waypoints for robot to traverse and the image will also provide current pose for the robot. Though the orientation of the obstacles varies the path of AGV and will always follow the shortest path. Thus, AGV shows the artificial intelligent.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-5687-1_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-76369-9_5,Lying Cheating Robots – Robots and Infidelity,Love and Sex with Robots,10.1007/978-3-319-76369-9_5,Springer,2018-01-01,"Love has been described as unpredictable, immeasurable and non-purchasable and as such, poses challenges for anyone in a relationship to both stay in love, and to not fall in love with someone else. Scientists are still discovering whether or not love follows any specific recipe. Outlooks, personality, sense of humor and talent may not perfectly guarantee an individual falls in love with another, and more importantly is able to sustain that relationship. This article portrays a futuristic scenario in which truly intelligent and emotional robots already exist. Here, the bi-directional love discussed in Lovotics is not simulated through engineering, but rather is genuine from the perspectives of both machine and human. This is a theoretical piece that draws on psychological theories of love, sex, attraction, associated emotions and behavior. The method involves reviewing previous literature on human-robot bi-directional love, and combines it with current discussions and theories of the realistic future potential of love relationships between humans and robots with full artificial intelligence and emotional capabilities. The result of the investigation is a multifaceted projection of the complexity humans will experience in love relationships with robots. Due to the incalculable nature of love, affection and sexual attraction, the development of robots with genuine capacity for emotions may not have the best outcome for a future of love and sex with robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-76369-9_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-69266-1_18,Knowledge-Based Expert System Using a Set of Rules to Assist a Tele-operated Mobile Robot,Intelligent Systems and Applications,10.1007/978-3-319-69266-1_18,Springer,2018-01-01,"This paper firstly reviews five artificial intelligence tools that might be useful in helping tele-operators to drive mobile robots: knowledge-based systems (including rule based systems and case-based reasoning), automatic knowledge acquisition, fuzzy logic, neural networks and genetic algorithms. Rule-based systems were selected to provide real time support to tele-operators with their steering because the systems allow tele-operators to be included in the driving as much as possible and to reach their target destination, while helping when needed to avoid an obstacle. A bearing to an end-point is added as an input with an obstacle avoidance sensor system and the usual inputs from a joystick. A recommended direction is combined with the angle and position of a joystick and the rule-based scheme generates a recommended angle to rotate the mobile robot. That recommended angle is then blended with the user input to assist tele-operators with steering their robots in the direction of their destinations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-69266-1_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-91262-2_67,Dual-Heuristic Dynamic Programming in the Three-Wheeled Mobile Transport Robot Control,Artificial Intelligence and Soft Computing,10.1007/978-3-319-91262-2_67,Springer,2018-01-01,"In this work an intelligent discrete tracking control system of a three-wheeled mobile transport robot is presented. The robot is a model of a forklift truck, with a drive wheel mounted in the rear part of the frame in movable steering module. The dynamics of the mobile transport robot was described using the second order Lagrange’s equations. In the tracking control system of the robot the Dual-Heuristic Dynamic Programming algorithm was used, which belongs to the family of Approximate Dynamic Programming algorithms. In the Dual-Heuristic Dynamic Programming algorithm Random Vector Functional Link Neural Networks were used to realize an actor and a critic structure. Numerical tests of robot motion on the desire trajectory were performed. The results of the numerical tests confirmed the correctness of the assumed design assumptions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-91262-2_67,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-05204-1_38,Adaptive Control of Human-Interacted Mobile Robots with Velocity Constraint,Social Robotics,10.1007/978-3-030-05204-1_38,Springer,2018-01-01,"In this paper, we present an adaptive control for mobile robots moving in human environments with velocity constraints. The mobile robot is commanded to track the desired trajectory while at the same time guarantee the satisfaction of the velocity constraints. Neural networks are constructed to deal with unstructured and unmodeled dynamic nonlinearities. Lyapunov function is employed during the course of control design to implement the validness of the proposed approach. The effectiveness of the proposed framework is verified through simulation studies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-05204-1_38,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-13-1080-5_6,Regulation Tomorrow: Strategies for Regulating New Technologies,Transnational Commercial and Consumer Law,10.1007/978-981-13-1080-5_6,Springer,2018-01-01,"In an age of constant, complex and disruptive technological innovation, knowing what , when, and how to structure regulatory interventions has become much more difficult. Regulators can find themselves in a situation where they believe they must opt for either reckless action (regulation without sufficient facts) or paralysis (doing nothing). Inevitably in such a situation, caution tends to trump risk. But such caution merely functions to reinforce the status quo and the result is that new technologies may struggle to reach the market in a timely or efficient manner. The solution? Law-making and regulatory design needs to become more proactive, dynamic and responsive. So how can regulators actually achieve these goals? What can they do to promote innovation and offer better opportunities to people wanting to build a new business around a disruptive technology or simply enjoy the benefits of a disruptive new technology as a consumer? The chapter focuses on three possible strategies for ‘regulation tomorrow’.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-1080-5_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-70836-2_42,Health 4.0 Oriented to Non-surgical Treatment,ROBOT 2017: Third Iberian Robotics Conference,10.1007/978-3-319-70836-2_42,Springer,2018-01-01,"The emerging technologies that are conforming the Industry 4.0 are also impacting on health. Artificial intelligence, 3D printing, robotics, big data, Internet of Things, augmented reality, among others, are adding a layer of digitization on classical processes, allowing to increase the effectiveness and efficiency in the processes related to health and opening a new space of possibilities. In this article, some examples will show the state of art of Health 4.0 in the non-surgical field.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-70836-2_42,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-99605-9_24,The Ethics of Inherent Trust in Care Robots for the Elderly,This Changes Everything – ICT and Climate Change: What Can We Do?,10.1007/978-3-319-99605-9_24,Springer,2018-01-01,"The way elderly care is delivered is changing. Attempts are being made to accommodate the increasing number of elderly, and the decline in the number of people available to care for them, with care robots. This change introduces ethical issues into robotics and healthcare. The two-part study (heuristic evaluation and survey) reported here examines a phenomenon which is a result of that change. The phenomenon rises out of a contradiction. All but 2 (who were undecided) of the 12 elderly survey respondents, out of the total of 102 respondents, wanted to be able to change how the presented care robot made decisions and 7 of those 12 elderly wanted to be able to examine its decision making process so as to ensure the care provided is personalized. However, at the same time, 34% of the elderly participants said they were willing to trust the care robot inherently, compared to only 16% of the participants who were under fifty. Additionally, 66% of the elderly respondents said they were very likely or likely to accept and use such a care robot in their everyday lives. The contradiction of inherent trust and simultaneous wariness about control gives rise to the phenomenon: elderly in need want control over their care to ensure it is personalized, but many may desperately take any help they can get. The possible causes, and ethical implications, of this phenomenon are the focus of this paper.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-99605-9_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-92925-5_19,From the Glass House to the Hive: The Private Sphere in the Era of Intelligent Home Assistant Robots,Privacy and Identity Management. The Smart Revolution,10.1007/978-3-319-92925-5_19,Springer,2018-01-01,"This paper introduces a re-conceptualization of the private sphere, following the presence inside the house of intelligent personal assistant robots that observe and act through sensors and actuators, and aggregate the data collected in the Cloud. This processing inserts the personal sphere of individuals into a complex and multi-layered informational structure, a “hive” of private spheres. An abstract model, named Aggregated Privateness Model, is presented herein to explain the dynamics of the “hive”. It sheds new light on a more collective dimension of ‘private’, a dimension which represents a context by itself, with normative mathematical rules and in which the expectations of privacy of individuals can be infringed based on the uses made of aggregated data. The Model also highlights how the behaviour of the individuals can influence the other private spheres in the cluster, as well as the Aggregation itself, due to a network effect, and how Diffused Network Liability could help compensating for such influences without incurring into practical impossibility.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-92925-5_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-61446-5_22,Future Directions of Digital Health,Digital Health,10.1007/978-3-319-61446-5_22,Springer,2018-01-01,"The technological revolution has brought structural changes to medicine and healthcare. With truly disruptive innovations such as artificial intelligence or advanced robotics, these changes will be more dramatic. All stakeholders of healthcare must prepare as their roles will be different too. The quest is finding a balance between using new technologies and keeping the human touch in care. Empowering patients, telemedicine, deep learning algorithms, whole-genome sequencing are all driving forces that will democratize healthcare and make care affordable, accessible and augmented. This will require breaking down the ivory tower; making patients manage their health and disease; as well as creating a regulatory framework which welcomes innovation in a way that products and services remain safe. While disruptive technologies can offer never-seen solutions in healthcare, we need to solve the ethical challenges first.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-61446-5_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-10-4585-1_19,Sound Localization in 3-D Space Using Kalman Filter and Neural Network for Human like Robotics,Networking Communication and Data Knowledge Engineering,10.1007/978-981-10-4585-1_19,Springer,2018-01-01,"Sound Localization is the process of identifying direction (with distance) and location of the source from which the sound is detected. It is one of the important functions of human brain. In brain sound localization is done through the neurons present in it. The sound signals from the outside world are come inside the brain through the ear. In this paper, the process of Sound Localization activity performed by human brain that incorporates realistic neuron models is discussed and the accurate position of the sound sources by using the Kalman filter and neural network is examined. The results demonstrate that finding position in 3D is more accurate as compared in 2D as its average error gets reduced. This work can be used to detect the location of the sound sources in three dimensions and can be also implemented in robots and cochlear implants for treating hearing loss.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-4585-1_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-01424-7_76,Mass-Spring Damper Array as a Mechanical Medium for Computation,Artificial Neural Networks and Machine Learning – ICANN 2018,10.1007/978-3-030-01424-7_76,Springer,2018-01-01,"Recently, it has been reported that the dynamics of mechanical structures can be used as a computational resource—also referred to as morphological computation. In particular soft materials have been shown to have the potential to be used for time series forecasting. Although most soft materials can be modeled by mass-spring systems, a limited number of researches has been performed on the computational capabilities of such systems. In this paper, we propose an array of masses linked in a grid-like structure by spring-damper connections to investigate systematically the influence of structural (size) and dynamic (stiffness, damping) parameters on the computational capabilities for time series forecasting. In addition, such a structure gives us a good approximation of two-dimensional elastic media, e.g., a rubber sheet, and therefore a direct pathway to potentially implement results in a real system. In particular, we compared the mass-spring array to echo state networks, which are standard machine learning techniques for this kind of problems and are also closely related to the underlying theoretical models applied when exploiting mechanical structures for computation. Our results suggest a clear connection of morphological features to computational capabilities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-01424-7_76,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-05204-1_59,Adaptive Neural Control for Robotic Manipulators Under Constrained Task Space,Social Robotics,10.1007/978-3-030-05204-1_59,Springer,2018-01-01,"A fundamental requirement in human-robot interaction is the capability for motion in the constrained task space. The control design for robotic manipulators is investigated in this paper, subject to uncertainties and constrained task space. The neural networks (NN) are employed to estimate the uncertainty of robotic dynamics, while the integral barrier Lyapunov Functional (iBLF) is used to handle the effect of constraint. With the proposed control strategy, the system output can converge to an adjustable constrained space without violating the predefined constrained region. Semi-globally uniformly ultimate boundedness of the closed-loop system is guaranteed via Lyapunov’s stability theory. Simulation examples are provided to illustrate the performance of the proposed strategy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-05204-1_59,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-10-7037-2_1,Neural Networks Based Single Robot Arm Control for Visual Servoing,Neural Networks for Cooperative Control of Multiple Robot Arms,10.1007/978-981-10-7037-2_1,Springer,2018-01-01,"In this chapter, we investigate the kinematic control of a single robot arm with an eye-in-hand camera for visual servoing by using neural networks. The visual servoing problem is formulated as a constrained quadratic program, which is then solved via a recurrent neural network. By this approach, the visual servoing with respect to a static point object is achieved with the feature coordinate errors in the image space converging to zero. Besides, joint angle and velocity limits of the robot arm are satisfied, which thus enhances the safety of the robot arm during the visual servoing process. The performance of the approach is guaranteed via theoretical analysis and validated via a simulative example.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-7037-2_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-10-7037-2_3,Neural Networks for Robot Arm Cooperation with a Hierarchical Control Topology,Neural Networks for Cooperative Control of Multiple Robot Arms,10.1007/978-981-10-7037-2_3,Springer,2018-01-01,"This chapter studies the decentralized robot arm cooperation with a hierarchical control topology. We present in this chapter a novel strategy capable of solving the problem even though there exists some robot arms unable to access the command signal directly. The cooperative task execution problem can be formulated as a constrained quadratic programming problem. By replacing the command signal with estimations with neighbor information, the control law becomes to work in the partial command coverage situation. We then prove in theory that the system indeed also globally stabilizes to the optimal solution of the constrained quadratic optimization problem. Simulations demonstrate the effectiveness of the method presented in this chapter.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-7037-2_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-10-7037-2_2,Neural Networks for Robot Arm Cooperation with a Star Control Topology,Neural Networks for Cooperative Control of Multiple Robot Arms,10.1007/978-981-10-7037-2_2,Springer,2018-01-01,This chapter studies the decentralized robot arm cooperation problem with a star control topology. The problem is formulated as a constrained quadratic program and then a recurrent neural network with independent modules is presented to solve the problem in a distributed manner. Each module in the neural network controls a single manipulator in real time without explicit communication with others and all the modules together collectively solve the common task. The global stability of the presented neural network and the optimality of the neural solution are proven in theory. Application orientated simulations demonstrate the effectiveness of the method.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-7037-2_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-05204-1_10,Robotic Understanding of Scene Contents and Spatial Constraints,Social Robotics,10.1007/978-3-030-05204-1_10,Springer,2018-01-01,The aim of this paper is to create a model which is able to be used to accurately identify objects as well as spacial relationships in a dynamic environment. This paper proposed methods to train a deep learning model which recognizes unique objects and positions of key items in an environment. The model requires a low amount of images compared to others and also can recognize multiple objects in the same frame due to the utilization of region proposal networks. Methods are also discussed to find the position of recognized objects which can be used for picking up recognized items with a robotic arm. The system utilizes logic operations to be able to deduct how different objects relate to each other in regard to their placement from one another based off of the localization technique. The paper discusses how to create spacial relationships specifically.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-05204-1_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-77179-3_40,Optimality in Control for Wheeled Robot,Automation 2018,10.1007/978-3-319-77179-3_40,Springer,2018-01-01,"It was applied in this paper a new approach to the problem of stabilisation of the motion of a wheeled robot in real time, as a mechanical object of unspecific description, considering variable operating conditions. To solve the thus understood motion stabilisation task under disturbance, the type H_∞ control method was used. This method is based on a two-person zero-sum differential game theory, in which the game is designed to determine the control to minimise the assumed quality indicator under the most unfavourable interference. This problem is reduced to solving the Hamilton-Jacobi-Isaac (HJI) equation in real time. The simulating example was inserted for the evaluation of analytical considerations, which showed high efficiency of the assumed solution, confirmed by high precision of execution of the set motion of the robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-77179-3_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-00692-1_13,Scene Recognition for Indoor Localization of Mobile Robots Using Deep CNN,Computer Vision and Graphics,10.1007/978-3-030-00692-1_13,Springer,2018-01-01,"In this paper we propose a deep neural network based algorithm for indoor place recognition. It uses transfer learning to retrain VGG-F, a pretrained convolutional neural network to classify places on images acquired by a humanoid robot. The network has been trained as well as evaluated on a dataset consisting of 8000 images, which were recorded in sixteen rooms. The dataset is freely accessed from our website. We demonstrated experimentally that the proposed algorithm considerably outperforms BoW algorithms, which are frequently used in loop-closure. It also outperforms an algorithm in which features extracted by FC-6 layer of the VGG-F are classified by a linear SVM.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-00692-1_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-73008-0_43,Distributed Convolutional Neural Networks for Human Activity Recognition in Wearable Robotics,Distributed Autonomous Robotic Systems,10.1007/978-3-319-73008-0_43,Springer,2018-01-01,"We investigate Hughes, Dana distributing convolutional Correll, Nikolaus neural networks (CNNs) for human activity recognition across computing nodes collocated with sensors at specific regions (body, arms and legs) on the wearer. We compare four CNN architectures. A distributed CNN is implemented on a network of Intel Edison nodes, demonstrating the capability of performing real-time classification. Two use a centralized, monolithic approach, and two are distributed across a number of computing nodes. While the accuracy of the distributed approaches are slightly worse than those of the monolithic CNNs, exploiting the hierarchy of the problem turns out to require much less memory — and therefore computation — than the monolithic CNNs, and only modest communication rates between nodes in the model, making the approach viable for a wide range of distributed systems ranging from wearable robots to multi-robot swarms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-73008-0_43,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-01424-7_72,De-noise-GAN: De-noising Images to Improve RoboCup Soccer Ball Detection,Artificial Neural Networks and Machine Learning – ICANN 2018,10.1007/978-3-030-01424-7_72,Springer,2018-01-01,"A moving robot or moving camera causes motion blur in the robot’s vision and distorts recorded images. We show that motion blur, differing lighting, and other distortions heavily affect the object localization performance of deep learning architectures for RoboCup Humanoid Soccer scenes. The paper proposes deep conditional generative models to apply visual noise filtering. Instead of generating new samples for a specific domain our model is constrained by reconstructing RoboCup soccer images. The conditional DCGAN (deep convolutional generative adversarial network) works semi-supervised. Thus there is no need for labeled training data. We show that object localization architectures significantly drop in accuracy when supplied with noisy input data and that our proposed model can significantly increase the accuracy again.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-01424-7_72,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-00308-1_3,Large-Scale Stochastic Scene Generation and Semantic Annotation for Deep Convolutional Neural Network Training in the RoboCup SPL,RoboCup 2017: Robot World Cup XXI,10.1007/978-3-030-00308-1_3,Springer,2018-01-01,"Object detection and classification are essential tasks for any robotics scenario, where data-driven approaches, specifically deep learning techniques, have been widely adopted in recent years. However, in the context of the RoboCup standard platform league these methods have not yet gained comparable popularity in large part due to the lack of (publicly) available large enough data sets that involve a tedious gathering and error-prone manual annotation process. We propose a framework for stochastic scene generation, rendering and automatic creation of semantically annotated ground truth masks. Used as training data in conjunction with deep convolutional neural networks we demonstrate compelling classification accuracy on real-world data in a multi-class setting. An evaluation on multiple neural network architectures with varying depth and representational capacity, corresponding run-times on current NAO-H25 hardware, and required sampled training data is provided.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-00308-1_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/s41598-017-17682-7,Intrinsic interactive reinforcement learning – Using error-related potentials for real world human-robot interaction,Scientific Reports,10.1038/s41598-017-17682-7,Nature,2017-12-14,"Reinforcement learning (RL) enables robots to learn its optimal behavioral strategy in dynamic environments based on feedback. Explicit human feedback during robot RL is advantageous, since an explicit reward function can be easily adapted. However, it is very demanding and tiresome for a human to continuously and explicitly generate feedback. Therefore, the development of implicit approaches is of high relevance. In this paper, we used an error-related potential (ErrP), an event-related activity in the human electroencephalogram (EEG), as an intrinsically generated implicit feedback (rewards) for RL. Initially we validated our approach with seven subjects in a simulated robot learning scenario. ErrPs were detected online in single trial with a balanced accuracy (bACC) of 91%, which was sufficient to learn to recognize gestures and the correct mapping between human gestures and robot actions in parallel. Finally, we validated our approach in a real robot scenario, in which seven subjects freely chose gestures and the real robot correctly learned the mapping between gestures and actions (ErrP detection (90% bACC)). In this paper, we demonstrated that intrinsically generated EEG-based human feedback in RL can successfully be used to implicitly improve gesture-based robot control during human-robot interaction. We call our approach intrinsic interactive RL.",https://www.nature.com/articles/s41598-017-17682-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41315-017-0039-1,A deep learning based fusion of RGB camera information and magnetic localization information for endoscopic capsule robots,International Journal of Intelligent Robotics and Applications,10.1007/s41315-017-0039-1,Springer,2017-12-01,"A reliable, real time localization functionality is crutial for actively controlled capsule endoscopy robots, which are an emerging, minimally invasive diagnostic and therapeutic technology for the gastrointestinal (GI) tract. In this study, we extend the success of deep learning approaches from various research fields to the problem of sensor fusion for endoscopic capsule robots. We propose a multi-sensor fusion based localization approach which combines endoscopic camera information and magnetic sensor based localization information. The results performed on real pig stomach dataset show that our method achieves sub-millimeter precision for both translational and rotational movements.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-017-0039-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-016-0371-5,Robust adaptive sliding mode control for industrial robot manipulator using fuzzy wavelet neural networks,"International Journal of Control, Automation and Systems",10.1007/s12555-016-0371-5,Springer,2017-12-01,"In this paper, a robust adaptive control method based on Dynamic Structure Fuzzy Wavelet Neural Networks (FWNNs) system is presented for trajectory tracking control of industrial robot manipulators (IRM) with uncertainties and disturbances via adaptive sliding mode control (SMC). Four layer FWNNs in the Dynamic structure FWNNs is constructed on the basis of fuzzy rules which associates with wavelet function in the consequent part, to compensate for structured and unstructured uncertainties and model complex processes. However, it is difficult to design a suitable control scheme to achieve the required approximation errors, such as friction forces, external disturbances error and parameter variations. To deal with the mentioned problems, all the parameters of the Dynamic structure FWNNs system are tuned on-line by an adaptive learning algorithm, and adaptive robust control laws are determined by Lyapunov stability theorem. By using Dynamic structure FWNNs, this control system could achieve desired tracking performance, the stability and robustness of the closed-loop manipulators system are guaranteed. In addition, the simulations and experimental performed on a three-link IRM are provided in comparison with wavelet network control (WNC) and adaptive Fuzzy control (AFC) to demonstrate the effectiveness and robustness of the proposed Dynamic structure FWNNs methodology.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-016-0371-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.3103/S0146411617080235,Siamese neural network for intelligent information security control in multi-robot systems,Automatic Control and Computer Sciences,10.3103/S0146411617080235,Springer,2017-12-01,"Anomaly detection of the robot system behavior is one of the important components of the information security control. In order to control robots equipped with many sensors it is difficult to apply the well-known Mahalanobis distance which allows us to analyze the current state of the sensors. Therefore, the Siamese neural network is proposed to intellectually support the security control. The Siamese network simplifies the anomaly detection of the robot system and realizes a non-linear analogue of the Mahalanobis distance. This peculiarity allows us to take into account complex data structures received from the robot sensors.",http://link.springer.com/openurl/fulltext?id=doi:10.3103/S0146411617080235,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-016-2398-1,SpikingLab: modelling agents controlled by Spiking Neural Networks in Netlogo,Neural Computing and Applications,10.1007/s00521-016-2398-1,Springer,2017-12-01,"The scientific interest attracted by Spiking Neural Networks (SNN) has lead to the development of tools for the simulation and study of neuronal dynamics ranging from phenomenological models to the more sophisticated and biologically accurate Hodgkin-and-Huxley-based and multi-compartmental models. However, despite the multiple features offered by neural modelling tools, their integration with environments for the simulation of robots and agents can be challenging and time consuming. The implementation of artificial neural circuits to control robots generally involves the following tasks: (1) understanding the simulation tools, (2) creating the neural circuit in the neural simulator, (3) linking the simulated neural circuit with the environment of the agent and (4) programming the appropriate interface in the robot or agent to use the neural controller. The accomplishment of the above-mentioned tasks can be challenging, especially for undergraduate students or novice researchers. This paper presents an alternative tool which facilitates the simulation of simple SNN circuits using the multi-agent simulation and the programming environment Netlogo (educational software that simplifies the study and experimentation of complex systems). The engine proposed and implemented in Netlogo for the simulation of a functional model of SNN is a simplification of integrate and fire (I&F) models. The characteristics of the engine (including neuronal dynamics, STDP learning and synaptic delay) are demonstrated through the implementation of an agent representing an artificial insect controlled by a simple neural circuit. The setup of the experiment and its outcomes are described in this work.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-016-2398-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41315-017-0037-3,Combining boosting machine learning and swarm intelligence for real time object detection and tracking: towards new meta-heuristics boosting classifiers,International Journal of Intelligent Robotics and Applications,10.1007/s41315-017-0037-3,Springer,2017-12-01,"Artificial vision in robotics involves real time detection of objects for fast decision making. Such intelligent systems require efficient algorithms and big learning database of examples for producing robust classifiers. Several methods of objects detection and tracking have been proposed in the literature. However, even though the detection rates have been improved, the processing time and the complexity of the models still representing a key challenge. In this paper, we present a real time object detection and tracking framework based on Adaboost classification, where a strong classifier is generated using an iterative combination of weak learners. This method is based on the use of discriminative features by analyzing different regions of the input image. Instead of performing a full traversal in the entire search space of all possible visual features, we propose to use intelligent heuristics for accelerating time processing and extracting relevant features in the image that lead to a best detection rate. The meta-heuristics involve the use of genetic algorithms, particle swarm optimization, random walk and a novel hybrid combination of these methods. The obtained results, in a case of intelligent transportation system, have shown considerable improvements in term of computation time, efficiency and accuracy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-017-0037-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11023-017-9417-6,Reframing AI Discourse,Minds and Machines,10.1007/s11023-017-9417-6,Springer,2017-12-01,"A critically important ethical issue facing the AI research community is how AI research and AI products can be responsibly conceptualised and presented to the public. A good deal of fear and concern about uncontrollable AI is now being displayed in public discourse. Public understanding of AI is being shaped in a way that may ultimately impede AI research. The public discourse as well as discourse among AI researchers leads to at least two problems: a confusion about the notion of ‘autonomy’ that induces people to attribute to machines something comparable to human autonomy, and a ‘sociotechnical blindness’ that hides the essential role played by humans at every stage of the design and deployment of an AI system. Here our purpose is to develop and use a language with the aim to reframe the discourse in AI and shed light on the real issues in the discipline.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11023-017-9417-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10845-015-1063-3,"Digital description of products, processes and resources for task-oriented programming of assembly systems",Journal of Intelligent Manufacturing,10.1007/s10845-015-1063-3,Springer,2017-12-01,"The ability to enable a fast modification and system-change, in order to fulfil quickly changing market needs, is one of the essential requirements of future production systems. Against this background, the central objective of this paper is the discussion of a new concept to simplify the application of task-oriented programming for assembly systems. For this purpose, a generic and comprehensible concept is used for the modeling of resources, processes and products. The core aspect is a method for the definition of multi-vendor skills in assembly systems. The implementation of the concepts in the engineering standard AutomationML and the integration into a programming system complete this contribution.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10845-015-1063-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-017-0026-1,Adaptive neural network second-order sliding mode control of dual arm robots,"International Journal of Control, Automation and Systems",10.1007/s12555-017-0026-1,Springer,2017-12-01,"An adaptive robust control system is considered for dual-arm manipulators (DAM) using the combination of second-order sliding mode control (SOSMC) and neural networks. The SOSMC deals with the system robustness when faced with external disturbances and parametric uncertainties. Meanwhile, the radial basis function network (RBFN) is to constitute an adaptation mechanism for approximating the unknown dynamic model of DAM. The stability of model estimator-integrated controller is analyzed using Lyapuov theory. To show the effectiveness of proposed controller, a four DOFs-DAM is applied as an illustrating example. The results reveal that the controller works well, excellently adapt to no information of robot modeling.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-017-0026-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11023-017-9418-5,"When Morals Ain’t Enough: Robots, Ethics, and the Rules of the Law",Minds and Machines,10.1007/s11023-017-9418-5,Springer,2017-12-01,"No single moral theory can instruct us as to whether and to what extent we are confronted with legal loopholes, e.g. whether or not new legal rules should be added to the system in the criminal law field. This question on the primary rules of the law appears crucial for today’s debate on roboethics and still, goes beyond the expertise of robo-ethicists. On the other hand, attention should be drawn to the secondary rules of the law: The unpredictability of robotic behaviour and the lack of data on the probability of events, their consequences and costs, make hard to determine the levels of risk and hence, the amount of insurance premiums and other mechanisms on which new forms of accountability for the behaviour of robots may hinge. By following Japanese thinking, the aim is to show why legally de-regulated, or special, zones for robotics, i.e. the secondary rules of the system, pave the way to understand what kind of primary rules we may want for our robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11023-017-9418-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-016-0492-x,Stable assist-as-needed controller design for a planar cable-driven robotic system,"International Journal of Control, Automation and Systems",10.1007/s12555-016-0492-x,Springer,2017-12-01,"Robot-assisted rehabilitation systems have shown promising advantages over traditional therapist-based methods. The type of the controller has an important role in the efficiency of such systems. In this regard, this paper presents a new assist-as-needed (AAN) controller for 4-cable planar robots. The main purpose is to design a bounded-input AAN controller with an adjustable assistance level and a guaranteed closed-loop stability. The proposed controller involves the advantages of both the model-based and non-model-based AAN controllers, and in this way can increase the efficiency of rehabilitation. The controller aims to follow a desired trajectory by allowing an adjustable tracking error, which enables the human subject to freely move the target limb inside this error area. This feature of the controller gives an important advantage over the existing model-based controllers. The controller also compensates for the dynamic modeling uncertainties of the system through an adaptive neural network. The adaptive term includes a forgetting factor to adjust the assistance level of neural network term. The stability of the closed-loop system is analysed, and the uniformly ultimately bounded stability is proven. The effectiveness of the proposed control scheme is validated through simulations conducted for gait rehabilitation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-016-0492-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-016-2242-7,Discrete-time sliding mode neuro-adaptive controller for SCARA robot arm,Neural Computing and Applications,10.1007/s00521-016-2242-7,Springer,2017-12-01,"This work presents a discrete-time sliding mode neuro-adaptive control (DTSMNAC) method for robot manipulators. Due to the dynamics variations and uncertainties in the robot model, the trajectory tracking of robot manipulators has been one of the research areas for the last years. The proposed control structure is a practical design that combines a discrete-time neuro-adaptation technique with sliding mode control to compensate the dynamics variations in the robot. Using an online adaptation technique, a DTSMNAC controller is used to approximate the equivalent control in the neighborhood of the sliding surface. A sliding control is included to guarantee that the discrete-time neural sliding mode control can improve a stable closed-loop system for the trajectory tracking control of the robot with dynamics variations. The proposed technique simultaneously ensures the stability of the adaptation of the neural networks and can be obtained a suitable equivalent control when the parameters of the robot dynamics are unknown in advance. This neural adaptive system is applied to a SCARA robot manipulator and shows to be able to ensure that the output tracking error will converge to zero. Finally, experiments on a SCARA robot have been developed to show the performance of the proposed technique, including the comparison with a PID controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-016-2242-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11721-017-0135-8,Cooperative object transport with a swarm of e-puck robots: robustness and scalability of evolved collective strategies,Swarm Intelligence,10.1007/s11721-017-0135-8,Springer,2017-12-01,"Cooperative object transport in distributed multi-robot systems requires the coordination and synchronisation of pushing/pulling forces by a group of autonomous robots in order to transport items that cannot be transported by a single agent. The results of this study show that fairly robust and scalable collective transport strategies can be generated by robots equipped with a relatively simple sensory apparatus (i.e. no force sensors and no devices for direct communication). In the experiments described in this paper, homogeneous groups of physical e-puck robots are required to coordinate and synchronise their actions in order to transport a heavy rectangular cuboid object as far as possible from its starting position to an arbitrary direction. The robots are controlled by dynamic neural networks synthesised using evolutionary computation techniques. The best evolved controller demonstrates an effective group transport strategy that is robust to variability in the physical characteristics of the object (i.e. object mass and size of the longest object’s side) and scalable to different group sizes. To run these experiments, we designed, built, and mounted on the robots a new sensor that returns the agents’ displacement on a 2D plane. The study shows that the feedback generated by the robots’ sensors relative to the object’s movement is sufficient to allow the robots to coordinate their efforts and to sustain the transports for an extended period of time. By extensively analysing successful behavioural strategies, we illustrate the nature of the operational mechanisms underpinning the coordination and synchronisation of actions during group transport.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11721-017-0135-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s13007-017-0246-7,A robot-assisted imaging pipeline for tracking the growths of maize ear and silks in a high-throughput phenotyping platform,Plant Methods,10.1186/s13007-017-0246-7,BioMed Central,2017-11-08,"Background In maize, silks are hundreds of filaments that simultaneously emerge from the ear for collecting pollen over a period of 1–7 days, which largely determines grain number especially under water deficit. Silk growth is a major trait for drought tolerance in maize, but its phenotyping is difficult at throughputs needed for genetic analyses. Results We have developed a reproducible pipeline that follows ear and silk growths every day for hundreds of plants, based on an ear detection algorithm that drives a robotized camera for obtaining detailed images of ears and silks. We first select, among 12 whole-plant side views, those best suited for detecting ear position. Images are segmented, the stem pixels are labelled and the ear position is identified based on changes in width along the stem. A mobile camera is then automatically positioned in real time at 30 cm from the ear, for a detailed picture in which silks are identified based on texture and colour. This allows analysis of the time course of ear and silk growths of thousands of plants. The pipeline was tested on a panel of 60 maize hybrids in the PHENOARCH phenotyping platform. Over 360 plants, ear position was correctly estimated in 86% of cases, before it could be visually assessed. Silk growth rate, estimated on all plants, decreased with time consistent with literature. The pipeline allowed clear identification of the effects of genotypes and water deficit on the rate and duration of silk growth. Conclusions The pipeline presented here, which combines computer vision, machine learning and robotics, provides a powerful tool for large-scale genetic analyses of the control of reproductive growth to changes in environmental conditions in a non-invasive and automatized way. It is available as Open Source software in the OpenAlea platform.",https://www.biomedcentral.com/openurl?doi=10.1186/s13007-017-0246-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-017-0483-7,Multimodal sensory fusion for soccer robot self-localization based on long short-term memory recurrent neural network,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-017-0483-7,Springer,2017-11-01,"Self-localization is a fundamental requirement for autonomous mobile robots. With the rapid development in sensor technology, the sensor suites of robot provide multimodal information that naturally ensures perception robustness, multimodal sensory fusion are able to provide a better solution for enhance the capability of self-localization. This paper proposes a multimodal sensory fusion method based on Long Short-Term Memory (LSTM) Recurrent Neural Network (RNN) for RoboCup 3D Simulation league. This approach fuses Inertia Navigation System (INS) and vision perceptor information from different sensors at feature level instead of raw data. The experiment results demonstrate that the proposed approach makes an improvement in predictive accuracy and efficiency compared with the standard Extended Kalman Filter (EKF) and the static Particle Filter (PF) methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-017-0483-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-017-0400-4,Learning Legible Motion from Human–Robot Interactions,International Journal of Social Robotics,10.1007/s12369-017-0400-4,Springer,2017-11-01,"In collaborative tasks, displaying legible behavior enables other members of the team to anticipate intentions and to thus coordinate their actions accordingly. Behavior is therefore considered to be legible when an observer is able to quickly and correctly infer the intention of the agent generating the behavior. In previous work, legible robot behavior has been generated by using model-based methods to optimize task-specific models of legibility. In our work, we rather use model-free reinforcement learning with a generic, task-independent cost function. In the context of experiments involving a joint task between (thirty) human subjects and a humanoid robot, we show that: (1) legible behavior arises when rewarding the efficiency of joint task completion during human–robot interactions (2) behavior that has been optimized for one subject is also more legible for other subjects (3) the universal legibility of behavior is influenced by the choice of the policy representation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-017-0400-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12204-017-1881-x,A real-time collision-free path planning of a rust removal robot using an improved neural network,Journal of Shanghai Jiaotong University (Science),10.1007/s12204-017-1881-x,Springer,2017-10-01,"In this paper, a real-time collision-free path planning of the rust removal robot in a ship environment is proposed, which is based on an improved biologically inspired neural network algorithm. This improved algorithm is based on the biologically inspired neural network and modified with obstacle detection sensors and kinematic state templates, and is implemented in a ship rust removal robot planning system for dynamic trajectory generation. The real-time optimal trajectory is generated by the biologically inspired neural network, and the moving obstacle detection process of a ship robot working on the wall is simulated with the obstacle detection sensors models. The local real-time trajectory can be re-planned by the updated local map information, where the obstacle detection sensors are used to inspect partial environment information and update the robot nearby information in real time in the original neural network algorithm. At the same time, the method of the kinematic state templates matching and searching is used to solve the pipes’ influence of the rust removal robot climbing on the wall, which can not only provide a smooth path, but also can judge the motion direction and turning angle of the robot. Comparison of the proposed approach with the simulation shows that the improved algorithm is capable of planning a real-time collision-free path with achieving the local environmental information and judging the rust removal robot’s motion direction and turning angle. This proposed algorithm can be good used in the ship rust removal robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12204-017-1881-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40815-016-0239-0,Distributed Consensus Formation Control with Collision and Obstacle Avoidance for Uncertain Networked Omnidirectional Multi-robot Systems Using Fuzzy Wavelet Neural Networks,International Journal of Fuzzy Systems,10.1007/s40815-016-0239-0,Springer,2017-10-01,"This paper presents a distributed consensus formation control with collision and obstacle avoidance using fuzzy wavelet neural networks (FWNNs) for a group of networked mobile Mecanum-wheeled omnidirectional robots (MWORs) with uncertainties. The dynamic behavior of each uncertain MWOR is modeled by a reduced three-input–three-output second-order state equation with uncertainties, and the multi-MWOR system is modeled by graph theory. Using the Lyapunov stability theory and online learning the system uncertainties via FWNNs, an adaptive and distributed consensus backstepping control approach is presented to carry out formation control in the presence of uncertainties. Collision and obstacle-avoidance methods are provided to avoid any collisions among MWORs and their working environments. Five simulations are conducted to show the effectiveness and merit of the proposed method .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40815-016-0239-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00170-017-0524-6,Polishing of uneven surfaces using industrial robots based on neural network and genetic algorithm,The International Journal of Advanced Manufacturing Technology,10.1007/s00170-017-0524-6,Springer,2017-10-01,"In conventional polishing processes, the polishing parameters are constant along the surface. Hence, if the desired material to be removed from the surface is not equally distributed, an over-polishing may occur for the areas with small material removal and under-polishing for the areas with large material removal. Consequently, the quality of the processed surface may not meet the manufacture requirements. In this paper, the authors proposed a polishing algorithm to deal with this problem using neural network (NNW) and genetic algorithm (GA). The NNW is used to predict the polishing performance parameters corresponding to a certain polishing parameters. In addition, the GA is employed to optimize the polishing parameters according to an objective function that includes the desired material removal and surface roughness improvement using the output from the trained NNW model. The effectiveness of the proposed algorithm is verified through experiments of polishing uneven surface.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00170-017-0524-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-017-0370-5,Hardware neural network models of CPG and PWM for controlling servomotor system in quadruped robot,Artificial Life and Robotics,10.1007/s10015-017-0370-5,Springer,2017-09-01,"This paper discusses the pulse-type hardware neural networks (P-HNNs) that contain a central pattern generator (CPG) and a pulsewidth modulation (PWM) servomotor controller and the application to quadruped robots. The purpose of our study is mimicking the biological neural networks and reproducing the similar motion of the living organisms in the robot. The CPG of the living organism generates the walking rhythms. We mimicked this CPG by modeling the cell body and the synapse of the living organism. The developed CPG composed of the P-HNN output four pulse signal sequences and the four outputs are introduced to each leg of the quadruped robot. On the other hand, the angle of the servomotor is controlled by the PWM. The PWM is obtained by modeling the axon of the living organism. The CPG and the PWM servo control system perform the walking motion of the quadruped robot. Moreover, the gate pattern change of quadruped animals is reproduced by these P-HNNs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-017-0370-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41315-017-0028-4,Wall-climbing robot for non-destructive evaluation using impact-echo and metric learning SVM,International Journal of Intelligent Robotics and Applications,10.1007/s41315-017-0028-4,Springer,2017-09-01,"The impact-echo (IE) acoustic inspection method is a non-destructive evaluation technique, which has been widely applied to detect the defects, structural deterioration level, and thickness of plate-like concrete structures. This paper presents a novel climbing robot, namely Rise-Rover, to perform automated IE signal collection from concrete structures with IE signal analyzing based on machine learning techniques. Rise-Rover is our new generation robot, and it has a novel and enhanced absorption system to support heavy load, and crawler-like suction cups to maintain high mobility performance while crossing small grooves. Moreover, the design enables a seamless transition between ground and wall. This paper applies the fast Fourier transform and wavelet transform for feature detection from collected IE signals. A distance metric learning based support vector machine approach is newly proposed to automatically classify the IE signals. With the visual-inertial odometry of the robot, the detected flaws of inspection area on the concrete plates are visualized in 2D/3D. Field tests on a concrete bridge deck demonstrate the efficiency of the proposed robot system in automatic health condition assessment for concrete structures.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41315-017-0028-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10506-017-9212-y,"Robot sex and consent: Is consent to sex between a robot and a human conceivable, possible, and desirable?",Artificial Intelligence and Law,10.1007/s10506-017-9212-y,Springer,2017-09-01,"The development of highly humanoid sex robots is on the technological horizon. If sex robots are integrated into the legal community as “electronic persons”, the issue of sexual consent arises, which is essential for legally and morally permissible sexual relations between human persons. This paper explores whether it is conceivable, possible, and desirable that humanoid robots should be designed such that they are capable of consenting to sex. We consider reasons for giving both “no” and “yes” answers to these three questions by examining the concept of consent in general, as well as critiques of its adequacy in the domain of sexual ethics; the relationship between consent and free will; and the relationship between consent and consciousness. Additionally we canvass the most influential existing literature on the ethics of sex with robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10506-017-9212-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10506-017-9214-9,"Of, for, and by the people: the legal lacuna of synthetic persons",Artificial Intelligence and Law,10.1007/s10506-017-9214-9,Springer,2017-09-01,"Conferring legal personhood on purely synthetic entities is a very real legal possibility, one under consideration presently by the European Union. We show here that such legislative action would be morally unnecessary and legally troublesome. While AI legal personhood may have some emotional or economic appeal, so do many superficially desirable hazards against which the law protects us. We review the utility and history of legal fictions of personhood, discussing salient precedents where such fictions resulted in abuse or incoherence. We conclude that difficulties in holding “electronic persons” accountable when they violate the rights of others outweigh the highly precarious moral interests that AI legal personhood might protect.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10506-017-9214-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11071-017-3631-x,Output-feedback formation control of wheeled mobile robots with actuators saturation compensation,Nonlinear Dynamics,10.1007/s11071-017-3631-x,Springer,2017-09-01,"This paper addresses output-feedback formation control of a group of wheeled mobile robots with saturating actuators. A virtual leader–follower strategy and a passivity-based design procedure are utilized to propose an adaptive neural network formation controller together with a nonlinear observer for the performance improvement of robots formation. The main tactic for the enhancement of the formation controller performance is the effective compensation of the actuators saturation nonlinearity by using neural networks and saturation functions. The need for velocity measurements is eliminated by a saturated observer that reduces unwanted peaks in the velocity estimates. A stability analysis is presented by using Lyapunov’s direct method. Finally, simulation results illustrate the efficiency of the proposed controller compared with existing results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11071-017-3631-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-016-0440-2,Egocentric-Vision based Hand Posture Control System for Reconnaissance Robots,Journal of Intelligent & Robotic Systems,10.1007/s10846-016-0440-2,Springer,2017-09-01,"To facilitate full-loaded commandos to control reconnaissance robots, in this paper, we propose a wearable hand posture control system based on egocentric-vision by imitating the sign language interaction way among commandos. Considering the characteristics of the egocentric-vision on the battlefield, such as complicated backgrounds, large ego-motions and extreme transitions in lighting, a new hand detector based on Binary Edge HOG Block (BEHB) features is proposed to extract articulated postures from the egocentric-vision. Different from many other methods that use skin color cues, our proposed hand detector adopts contour cues and part-based voting idea. This means that our algorithm can be used on the battlefield even in dark environment, because infrared cameras can be used to get contour images rather than skin color images. The experiment result shows that the proposed hand detector can get a better posture detection result on the NUS hand posture dataset II. To improve hand recognition accuracy, a deep ensemble hybrid classifier is proposed by combing hybrid CNN-SVM classifier and ensemble technique. Compared with other state-of-art algorithms, the proposed classifier yields a recognition accuracy of 97.72 % on the NUS hand posture dataset II. At last, to reduce misjudgments during consecutive posture switches, a vote filter is proposed and applied to the sequence of the recognition results. The scout experiment shows that our wearable hand posture control system is more suitable than traditional hand-held controllers for full-loaded commandos to control reconnaissance robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-016-0440-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-016-2095-0,A face recognition system based on convolution neural network using multiple distance face,Soft Computing,10.1007/s00500-016-2095-0,Springer,2017-09-01,"The recognition technology that recognizes or discriminates certain individuals is very important for the security that provides intelligence services. Face recognition rate can vary depending on variability of the face itself as well as other external factors such as illumination, background, angle and distance of a camera position. The paper suggests a proper method for long-distance face recognition by resolving the change in recognition rate resulting from distance change in long-distance face recognition. For the long-distance face recognition test, face images by actual distance from 1 to 9 m away were obtained directly. Actual face images taken by distance were applied to resolve the issue rising from distance change and CNN was applied to extract overall features of face. The test showed that proposed face recognition algorithm that used CNN as feature extraction and face images by actual distance for training was found to show the best performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-016-2095-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-016-0515-7,Global adaptive tracking control of robot manipulators using neural networks with finite-time learning convergence,"International Journal of Control, Automation and Systems",10.1007/s12555-016-0515-7,Springer,2017-08-01,"In this paper, the global adaptive neural control with finite-time (FT) convergence learning performance for a general class of nonlinear robot manipulators has been investigated. The scheme proposed in this paper offers a subtle blend of neural controller with robust controller, which palliates the limitation of neural approximation region to ensure globally uniformly ultimately bounded (GUUB) stability by integrating a switching mechanism. Morever, the proposed scheme guarantees the estimated neural weights converging to optimal values in finite time by embedding an adaptive learning algorithm driven by the estimated weights error. The optimal weights obtained through the learning process of the neural networks (NNs) will be reused next time for repeated tasks, and can thus reduce computational load, improve transient performance and enhance robustness. The simulation studies have been carried out to demonstrate the superior performance of the controller in comparison to the conventional methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-016-0515-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11265-016-1209-3,Deep Learning for Automated Occlusion Edge Detection in RGB-D Frames,Journal of Signal Processing Systems,10.1007/s11265-016-1209-3,Springer,2017-08-01,"Occlusion edges correspond to range discontinuity in a scene from the point of view of the observer. Detection of occlusion edges is an important prerequisite for many machine vision and mobile robotic tasks. Although they can be extracted from range data, extracting them from images and videos would be extremely beneficial. We trained a deep convolutional neural network (CNN) to identify occlusion edges in images and videos with just RGB, RGB-D and RGB-D-UV inputs, where D stands for depth and UV stands for horizontal and vertical components of the optical flow field respectively. The use of CNN avoids hand-crafting of features for automatically isolating occlusion edges and distinguishing them from appearance edges. Other than quantitative occlusion edge detection results, qualitative results are provided to evaluate input data requirements and to demonstrate the trade-off between high resolution analysis and frame-level computation time that is critical for real-time robotics applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11265-016-1209-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-015-0392-5,Cyclic error correction based Q-learning for mobile robots navigation,"International Journal of Control, Automation and Systems",10.1007/s12555-015-0392-5,Springer,2017-08-01,"Similar to control systems, reinforcement learning can capture notions of optimal behavior using natural interaction experience. In the context of reinforcement learning, the temporal difference error of the generated experience measures how well the learner responds to the system. Specially sequential difference of accumulated temporal difference error can indicate the learning performance. In this paper, we fully utilize the error correction in closed-loop peculiarity by mapping a representation error to the step-size component. The proposed cyclic step-size could better control how new estimates are iteratively blended together over time, and the new estimates guide the action selection process which in turn influence the value distribution. To guide more promising action decision, an ensemble action selector is proposed which incorporates the idea of ensemble wisdom of the weak. Experimental results conducted under gridworld mobile robot navigation task demonstrate the validity, capacity of fast learning and easy-plugged implementation of the derived algorithm, leading to increasing applicability to real-life problems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-015-0392-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11071-017-3454-9,FAT-based robust adaptive control of electrically driven robots without velocity measurements,Nonlinear Dynamics,10.1007/s11071-017-3454-9,Springer,2017-07-01,"Recently, regressor-free control approach has been presented in which uncertainties are estimated using function approximation techniques (FAT) such as the Fourier series expansion or Legendre polynomials. However, FAT-based observer design remains as an open problem. With this in mind, this paper presents a robust adaptive controller for electrically driven robots, without any need for velocity measurements. The mixed observer/control design procedure is based on universal approximation theory and using Stone–Weierstrass theorem. To highlight the contribution of the paper, it should be emphasized that in comparison with previous related FAT-based controllers, the proposed controller is simpler and less computational. In addition, the number of required Fourier series expansions, control laws, and also adaptation rules has been reduced. Moreover, the observer design is free of model. Simulation results of the controller on a 6-DOF industrial robot manipulator have been presented which proves robustness of the proposed controller against various uncertainties. The results are also compared to those obtained from Chebyshev neural network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11071-017-3454-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-017-0401-3,Fear of Autonomous Robots and Artificial Intelligence: Evidence from National Representative Data with Probability Sampling,International Journal of Social Robotics,10.1007/s12369-017-0401-3,Springer,2017-06-01,"People vary in the extent to which they report fear toward robots, especially when they perceive that the robot is autonomous or has artificial intelligence. This research examines a specific form of sociological fear, which we name as fear of autonomous robots and artificial intelligence (FARAI). This fear may serve to affect how people will respond to and interact with robots. Applying data from a nationally representative dataset with probability sampling ( N  = 1541), research questions examine (1) the extent and frequency of FARAI, (2) demographic and media exposure predictors, and (3) correlates with other types of fear (i.e., loneliness, drones, and unemployment). A latent class analysis reveals that approximately 26% of participants reported experiencing a heightened level of FARAI. Demographic analyses show that FARAI is connected to participant sex, age, education, and household income; albeit these effects were small. Media exposure to science fiction predicts FARAI above and beyond the demographic variables. Correlational results indicate that FARAI is associated with other types of fear, including loneliness, becoming unemployed, and drone use. In sum, these findings render a much needed glimpse and update regarding how much individuals fear robots and artificial intelligence.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-017-0401-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11633-016-1042-y,Navigation of non-holonomic mobile robot using neuro-fuzzy logic with integrated safe boundary algorithm,International Journal of Automation and Computing,10.1007/s11633-016-1042-y,Springer,2017-06-01,"In the present work, autonomous mobile robot (AMR) system is intended with basic behaviour, one is obstacle avoidance and the other is target seeking in various environments. The AMR is navigated using fuzzy logic, neural network and adaptive neuro-fuzzy inference system (ANFIS) controller with safe boundary algorithm. In this method of target seeking behaviour, the obstacle avoidance at every instant improves the performance of robot in navigation approach. The inputs to the controller are the signals from various sensors fixed at front face, left and right face of the AMR. The output signal from controller regulates the angular velocity of both front power wheels of the AMR. The shortest path is identified using fuzzy, neural network and ANFIS techniques with integrated safe boundary algorithm and the predicted results are validated with experimentation. The experimental result has proven that ANFIS with safe boundary algorithm yields better performance in navigation, in particular with curved/irregular obstacles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11633-016-1042-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11023-016-9406-1,The Epistemic Value of Brain–Machine Systems for the Study of the Brain,Minds and Machines,10.1007/s11023-016-9406-1,Springer,2017-06-01,"Bionic systems, connecting biological tissues with computer or robotic devices through brain–machine interfaces, can be used in various ways to discover biological mechanisms. In this article I outline and discuss a “stimulation-connection” bionics-supported methodology for the study of the brain, and compare it with other epistemic uses of bionic systems described in the literature. This methododology differs from the “synthetic”, simulative method often followed in theoretically driven Artificial Intelligence and cognitive (neuro) science, even though it involves machine models of biological systems. I also bring the previous analysis to bear on some claims on the epistemic value of bionic technologies made in the recent philosophical literature. I believe that the methodological reflections proposed here may contribute to the piecewise understanding of the many ways bionic technologies can be deployed not only to restore lost sensory-motor functions, but also to discover brain mechanisms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11023-016-9406-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11063-016-9562-6,A Neural Network Approach for Solving Optimal Control Problems with Inequality Constraints and Some Applications,Neural Processing Letters,10.1007/s11063-016-9562-6,Springer,2017-06-01,"In this paper, a class of nonlinear optimal control problems with inequality constraints is considered. Based on Karush–Kuhn–Tucker optimality conditions of nonlinear optimization problems and by constructing an error function, we define an unconstrained minimization problem. In the minimization problem, we use trial solutions for the state, Lagrange multipliers, and control functions where these trial solutions are constructed by using two-layered perceptron. We then minimize the error function using a dynamic optimization method where weights and biases associated with all neurons are unknown. The stability and convergence analysis of the dynamic optimization scheme is also studied. Substituting the optimal values of the weights and biases in the trial solutions, we obtain the optimal solution of the original problem. Several examples are given to show the efficiency of the method. We also provide two applicable examples in robotic engineering.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-016-9562-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-017-0465-1,Neuroevolution of Inverted Pendulum Control: A Comparative Study of Simulation Techniques,Journal of Intelligent & Robotic Systems,10.1007/s10846-017-0465-1,Springer,2017-06-01,"The inverted pendulum control problem is a classical benchmark in control theory. Amongst the approaches to developing control programs for an inverted pendulum, the evolution of Artificial Neural Network (ANN) based controllers has received some attention. The authors have previously shown that Evolutionary Robotics (ER) can successfully be used to evolve inverted pendulum stabilization controllers in simulation and that these controllers can transfer successfully from simulation to real-world robotic hardware. During this process, use was made of robotic simulators constructed from empirically-collected data and based on ANNs. The current work aims to compare this method of simulator construction with the more traditional method of building robotic simulators based on physics equations governing the robotic system under consideration. In order to compare ANN-based and physics-based simulators in the evolution of inverted pendulum controllers, a real-world wheeled inverted pendulum robot was considered. Simulators based on ANNs as well as on a system of ordinary differential equations describing the dynamics of the robot were developed. These two simulation techniques were then compared by using each in the simulation-based evolution of controllers. During the evolution process, the effects of injecting different levels of noise into the simulation was furthermore studied. Encouraging results were obtained, with controllers evolved using ANN-based simulators and realistic levels of noise outperforming those evolved using the physics-based simulators.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-017-0465-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-017-0468-y,Survey of Model-Based Reinforcement Learning: Applications on Robotics,Journal of Intelligent & Robotic Systems,10.1007/s10846-017-0468-y,Springer,2017-05-01,"Reinforcement learning is an appealing approach for allowing robots to learn new tasks. Relevant literature reveals a plethora of methods, but at the same time makes clear the lack of implementations for dealing with real life challenges. Current expectations raise the demand for adaptable robots. We argue that, by employing model-based reinforcement learning, the—now limited—adaptability characteristics of robotic systems can be expanded. Also, model-based reinforcement learning exhibits advantages that makes it more applicable to real life use-cases compared to model-free methods. Thus, in this survey, model-based methods that have been applied in robotics are covered. We categorize them based on the derivation of an optimal policy, the definition of the returns function, the type of the transition model and the learned task. Finally, we discuss the applicability of model-based reinforcement learning approaches in new applications, taking into consideration the state of the art in both algorithms and hardware.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-017-0468-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11192-017-2268-3,A patent search strategy based on machine learning for the emerging field of service robotics,Scientometrics,10.1007/s11192-017-2268-3,Springer,2017-05-01,"Emerging technologies are often not part of any official industry, patent or trademark classification systems. Thus, delineating boundaries to measure their early development stage is a nontrivial task. This paper is aimed to present a methodology to automatically classify patents concerning service robots. We introduce a synergy of a traditional technology identification process, namely keyword extraction and verification by an expert community, with a machine learning algorithm. The result is a novel possibility to allocate patents which (1) reduces expert bias regarding vested interests on lexical query methods, (2) avoids problems with citation approaches, and (3) facilitates evolutionary changes. Based upon a small core set of worldwide service robotics patent applications, we derive apt n-gram frequency vectors and train a support vector machine, relying only on titles, abstracts, and IPC categorization of each document. Altering the utilized Kernel functions and respective parameters, we reach a recall level of 83% and precision level of 85%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11192-017-2268-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-015-0070-7,Stability analysis of reference compensation technique for controlling robot manipulators by neural network,"International Journal of Control, Automation and Systems",10.1007/s12555-015-0070-7,Springer,2017-04-01,"Neural network control for robot manipulators is aimed to compensate for uncertainties in the robot dynamics. The location of a compensating point differentiates the control scheme into two categories, the feedback error learning (FEL) scheme and the reference compensation technique (RCT). The RCT scheme is relatively less used although it has several structural advantages. In this paper, the global stability of the RCT scheme is analyzed on the basis of Lyapunov function. The analysis turns out that the stability depends upon the magnitude of the controller gains. Simulation studies of controlling the position of a two-link robot manipulator are conducted.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-015-0070-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11948-016-9783-0,Can Artificial Intelligences Suffer from Mental Illness? A Philosophical Matter to Consider,Science and Engineering Ethics,10.1007/s11948-016-9783-0,Springer,2017-04-01,"The potential for artificial intelligences and robotics in achieving the capacity of consciousness, sentience and rationality offers the prospect that these agents have minds. If so, then there may be a potential for these minds to become dysfunctional, or for artificial intelligences and robots to suffer from mental illness. The existence of artificially intelligent psychopathology can be interpreted through the philosophical perspectives of mental illness. This offers new insights into what it means to have either robot or human mental disorders, but may also offer a platform on which to examine the mechanisms of biological or artificially intelligent psychiatric disease. The possibility of mental illnesses occurring in artificially intelligent individuals necessitates the consideration that at some level, they may have achieved a mental capability of consciousness, sentience and rationality such that they can subsequently become dysfunctional. The deeper philosophical understanding of these conditions in mankind and artificial intelligences might therefore offer reciprocal insights into mental health and mechanisms that may lead to the prevention of mental dysfunction.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-016-9783-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-015-2107-5,Diagonal recurrent neural networks for parameters identification of terrain based on wheel–soil interaction analysis,Neural Computing and Applications,10.1007/s00521-015-2107-5,Springer,2017-04-01,"Wheeled mobile robots (WMR) are often applied to travel on outdoor unstructured environment, such as loose soil or variable field terrain. Learning the knowledge of terrain has played a significant role for better mobility and stability of WMR. In this study, a diagonal recurrent neural network-based adaptive method is proposed to identify terrain parameters by the platform of a single driving wheel. According to the classical terramechanics model of wheel–soil interaction, a decoupling simplification model is developed by closed-form analytical equations. Five unknown terrain parameters are divided into two groups and included in two complex nonlinear equations. These parameters are used to compute the model outputs of force and torque of wheel–soil interaction. Dynamic back propagation algorithm is applied to update these parameters for compensating the errors between the prediction of neural network and measurable data in real time. The results of simulation show that the terrain parameters can be obtained and approximate the experimental value of terrain parameters when the predictive errors converge to zero.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-015-2107-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-016-0327-0,Gait pattern changing of quadruped robot using pulse-type hardware neural networks,Artificial Life and Robotics,10.1007/s10015-016-0327-0,Springer,2017-03-01,"This paper studied about gait pattern changing of the constructed quadruped robot system using pulse-type hardware neural networks (P-HNN). We constructed the 20 cm in size prototype quadruped robot system. Quadruped robot system consisted of mechanical components and electrical components. The mechanical components consisted of four legs, body frames and four servo motors. Quadruped animal-like locomotion could realize by only four servo motors using link mechanisms to each leg. The electrical components consisted of P-HNN, power supply circuit, control board and battery. P-HNN was constructed by analog discrete circuits which could mount on top of the quadruped robot. As a result, constructed P-HNN could output the locomotion rhythms which were necessary to generate the gait pattern of the quadruped robot. P-HNN could output the locomotion rhythms without using software programs or analog digital converter. In addition, P-HNN could change the locomotion rhythms by inputting the trigger pulse to the P-HNN. Our constructed quadruped robot system could perform the locomotion without using external devices.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-016-0327-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12668-016-0323-9,Neuromorphic Robot Dream,BioNanoScience,10.1007/s12668-016-0323-9,Springer,2017-03-01,"In this paper, we present the next step in our approach to neurobiologically plausible implementation of emotional reactions and behaviors for real-time autonomous robotic systems. The working metaphor we use is the “day” and the “night” phases of mammalian life. During the “day’ phase” a robotic system stores the inbound information and is controlled by a light-weight rule-based system in real time. In contrast to that, during the “night phase” information that has been stored is transferred to a supercomputing system to update the realistic neural network: emotional and behavioral strategies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12668-016-0323-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11071-016-3173-7,Fuzzy neural network and observer-based fault-tolerant adaptive nonlinear control of uncertain 5-DOF upper-limb exoskeleton robot for passive rehabilitation,Nonlinear Dynamics,10.1007/s11071-016-3173-7,Springer,2017-02-01,"This paper investigates the control of a 5-DOF upper-limb exoskeleton robot used for passive rehabilitation therapy. The robot is subject to uncertain dynamics, disturbance torques, unavailable full-state measurement, and different types of actuation faults. An adaptive nonlinear control scheme, which uses a new reaching law-based sliding mode control strategy, is proposed. This scheme incorporates a high-gain state observer with dynamic high-gain matrix and a fuzzy neural network (FNN) for state vector and nonlinear dynamics estimation, respectively. Using dynamic parameters, the scheme provides an efficient mean for simultaneously tackling the effects of FNN approximation errors, disturbance torques and actuation faults without any prior bounds knowledge and fault detection and diagnosis components. Using simulation results, it is shown that with the presented scheme, faster response, fewer oscillations during transient phase, good tracking accuracy, and chattering-free control torques with lower amplitudes are obtained.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11071-016-3173-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-014-0363-2,Robust model predictive control of biped robots with adaptive on-line gait generation,"International Journal of Control, Automation and Systems",10.1007/s12555-014-0363-2,Springer,2017-02-01,"In this paper, an on-line gait control scheme is proposed for the biped robots for walking up and down the stairs. In the proposed strategy, the nonlinear model predictive control approach is used for the trajectory planning and as well as for the control of the robot. The motion of the robot is expressed in the form of a cost function and some constraints that are related to the stable walking of the robot. The main feature of this method is that it does not need any off-line trajectory planning and the walking gait is formulated such that the environmental and stability constraints of the robot are satisfied. This on-line trajectory planning gives the important ability to the robot to adjust its gait lengths. In this way, the robot is able to ascend and descend the stairs without knowing the height and depth of the stairs in advance. In the control algorithm, the Radial-Basis Function (RBF) neural network with on-line training method is used to model the behavior of the robot over the prediction horizon. The stability analysis of the closed-loop system is performed using the Lyapunov method as well as the Poincaré map. The proposed method is applied to a 5-DOF biped robot in the sagittal plane. The simulation results show effectiveness of the proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-014-0363-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-57261-1_41,Dim Line Tracking Using Deep Learning for Autonomous Line Following Robot,Artificial Intelligence Trends in Intelligent Systems,10.1007/978-3-319-57261-1_41,Springer,2017-01-01,The proposed approach improves preprocessing of image data for the line following robot. The tracking algorithm uses Track–Before–Detect algorithm using Viterbi algorithm. Proposed technique uses deep learning for the estimation of the line and background area. The segmentation improves detection of weak line on the image disturbed by numerous additive patterns and Gaussian noise.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-57261-1_41,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-68792-6_33,A Deep Learning Approach for Object Recognition with NAO Soccer Robots,RoboCup 2016: Robot World Cup XX,10.1007/978-3-319-68792-6_33,Springer,2017-01-01,"The use of identical robots in the RoboCup Standard Platform League (SPL) made software development the key aspect to achieve good results in competitions. In particular, the visual detection process is crucial for extracting information about the environment. In this paper, we present a novel approach for object detection and classification based on Convolutional Neural Networks (CNN). The approach is designed to be used by NAO robots and is made of two stages: image region segmentation, for reducing the search space, and Deep Learning, for validation. The proposed method can be easily extended to deal with different objects and adapted to be used in other RoboCup leagues. Quantitative experiments have been conducted on a data set of annotated images captured in real conditions from NAO robots in action. The used data set is made available for the community.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-68792-6_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-46490-9_47,Integration of Machine Learning and Optimization for Robot Learning,Recent Global Research and Education: Technological Challenges,10.1007/978-3-319-46490-9_47,Springer,2017-01-01,"Learning ability in Robotics is acknowledged as one of the major challenges facing artificial intelligence. Although in the numerous areas within Robotics machine learning (ML) has long identified as a core technology, recently Robot learning, in particular, has been witnessing major challenges due to the theoretical advancement at the boundary between optimization and ML. In fact the integration of ML and optimization reported to be able to dramatically increase the decision-making quality and learning ability in decision systems. Here the novel integration of ML and optimization which can be applied to the complex and dynamic contexts of Robot learning is described. Furthermore with the aid of an educational Robotics kit the proposed methodology is evaluated.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-46490-9_47,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-10-2750-5_12,Control of Robot Using Neural Networks,Proceedings of International Conference on Communication and Networks,10.1007/978-981-10-2750-5_12,Springer,2017-01-01,The paper deals with motion control of autonomous robot. For an autonomous robot the main functionality which is to be implemented is its movement. The robot should be able to move from source to destination successfully avoiding all the obstacles in a known or unknown environment. This paper explains in detail 3 approaches for the motion control: (1) Neural Network where the problem is divided into sub problems FindSpace and FindPath (2) ANFIS (Adaptive Neuro-Fuzzy Inference System) where 6 layers are present (3) Fuzzy Logic along with neural network. Some simulation results are given which shows that Neural Network and fuzzy logic together gives better performance than Neural Network and fuzzy logic alone.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-2750-5_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-62416-7_20,Mobile Robot Localization via Machine Learning,Machine Learning and Data Mining in Pattern Recognition,10.1007/978-3-319-62416-7_20,Springer,2017-01-01,"We consider an appearance-based robot self-localization problem in the machine learning framework. Using recent manifold learning techniques, we propose a new geometrically motivated solution. The solution includes estimation of the robot localization mapping from the appearance manifold to the robot localization space, as well as estimation of the inverse mapping for image modeling. The latter allows solving the robot localization problem as a Kalman filtering problem.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-62416-7_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-40533-9_8,Intelligent Human–Robot Interaction Systems Using Reinforcement Learning and Neural Networks,Trends in Control and Decision-Making for Human–Robot Collaboration Systems,10.1007/978-3-319-40533-9_8,Springer,2017-01-01,"In this chapter, an intelligent human–robot system with adjustable robot autonomy is presented to assist the human operator to perform a given task with minimum workload Workload demands and optimal performance. The proposed control methodology consists of two feedback loops: an inner loop that makes the robot with unknown dynamics behave like a prescribed impedance model Impedance model as perceived by the operator, and an outer loop that finds the optimal parameters of this model to adjust the robot’s dynamics to the operator skills and minimize the tracking error Tracking error . A nonlinear robust controller using neural networks Neural network is used in the inner loop to make the nonlinear unknown robot dynamics behave like a prescribed impedance model. The problem of finding the optimal parameters of the prescribed impedance model is formulated as an optimal control Optimal control problem in the outer loop. The objective is to minimize the human effort and optimize the closed-loop behavior of the human–machine system Human-machine system for a given task. This design must take into account the unknown human dynamics as well as the desired overall performance of the human–robot system, which depends on the task. To obviate the requirement of the knowledge of the human model, reinforcement learning Reinforcement learning is used to learn the solution to the given optimal control problem online in real time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-40533-9_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-68792-6_31,Decentralized Reinforcement Learning Applied to Mobile Robots,RoboCup 2016: Robot World Cup XX,10.1007/978-3-319-68792-6_31,Springer,2017-01-01,"In this paper, decentralized reinforcement learning is applied to a control problem with a multidimensional action space. We propose a decentralized reinforcement learning architecture for a mobile robot, where the individual components of the commanded velocity vector are learned in parallel by separate agents. We empirically demonstrate that the decentralized architecture outperforms its centralized counterpart in terms of the learning time, while using less computational resources. The method is validated on two problems: an extended version of the 3-dimensional mountain car, and a ball-pushing behavior performed with a differential-drive robot, which is also tested on a physical setup.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-68792-6_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-65289-4_17,Toward Effective Soft Robot Control via Reinforcement Learning,Intelligent Robotics and Applications,10.1007/978-3-319-65289-4_17,Springer,2017-01-01,"A soft robot is a kind of robot that is constructed with soft, deformable and elastic materials. Control of soft robots presents complex modeling and planning challenges. We introduce a new approach to accomplish that, making two key contributions: designing an abstract representation of the state of soft robots, and developing a reinforcement learning method to derive effective control policies. The reinforcement learning process can be trained quickly by ignoring the specific materials and structural properties of the soft robot. We apply the approach to the Honeycomb PneuNets Soft Robot and demonstrate the effectiveness of the training method and its ability to produce good control policies under different conditions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-65289-4_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-48308-5_84,The Challenges of Reinforcement Learning in Robotics and Optimal Control,Proceedings of the International Conference on Advanced Intelligent Systems and Informatics 2016,10.1007/978-3-319-48308-5_84,Springer,2017-01-01,"Reinforcement Learning (RL) is an emerging technology for designing control systems that find optimal policy, through simulated or actual experience, according to a performance measure given by the designer. This paper discusses a widely used RL algorithm called Q-learning. This paper discuss how to apply these algorithms to robotics and optimal control systems, where several key challenges must be addressed for it to be useful. We discuss how Q-learning algorithm can adapted to work in continuous states and action spaces, the methods for computing rewards which generates an adaptive optimal controller and accelerate learning process and finally the safe exploration approaches.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-48308-5_84,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-10-6388-6_45,Multi-step Reinforcement Learning Algorithm of Mobile Robot Path Planning Based on Virtual Potential Field,Data Science,10.1007/978-981-10-6388-6_45,Springer,2017-01-01,"A algorithm of dynamic multi-step reinforcement learning based on virtual potential field path planning is proposed in this paper. Firstly, it is constructed the virtual potential field according to the known information. And then in view of $$ Q $$ learning algorithm of the $$ Q\left( \lambda \right) $$ algorithm, a multi-step reinforcement learning algorithm is proposed in this paper. It can update current $$ Q $$ value used of future dynamic $$ k $$ steps according to the current environment status. At the same time, the convergence is analyzed. Finally the simulation experiments are done. It shows that the proposed algorithm and convergence and so on are more efficiency than similar algorithms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-6388-6_45,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-70407-4_39,Making Sense of Indoor Spaces Using Semantic Web Mining and Situated Robot Perception,The Semantic Web: ESWC 2017 Satellite Events,10.1007/978-3-319-70407-4_39,Springer,2017-01-01,"Intelligent Autonomous Robots deployed in human environments must have understanding of the wide range of possible semantic identities associated with the spaces they inhabit – kitchens, living rooms, bathrooms, offices, garages, etc. We believe robots should learn this information through their own exploration and situated perception in order to uncover and exploit structure in their environments – structure that may not be apparent to human engineers, or that may emerge over time during a deployment. In this work, we combine semantic web-mining and situated robot perception to develop a system capable of assigning semantic categories to regions of space. This is accomplished by looking at web-mined relationships between room categories and objects identified by a Convolutional Neural Network trained on 1000 categories. Evaluated on real-world data, we show that our system exhibits several conceptual and technical advantages over similar systems, and uncovers semantic structure in the environment overlooked by ground-truth annotators.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-70407-4_39,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-59147-6_25,Machine Learning Improves Human-Robot Interaction in Productive Environments: A Review,Advances in Computational Intelligence,10.1007/978-3-319-59147-6_25,Springer,2017-01-01,"In the new generation of industries, including all the advances introduced by Industry 4.0, human robot interaction (HRI), by means of automatic learning and computer vision, become an important element to accomplish. HRI allows to create collaborative environments between people and robots, avoiding the latter generating a risk of occupational safety. In addition to the automatic systems, the interaction by mean of automated learning processes provides necessary information to increase productivity and minimize delivery response times by helping to optimize complex production planning processes. In this paper, it is presented a review of the technologies necessary to be considered as basic elements in all processes of industry 4.0 as a crucial linking element between humans, robots, intelligent and traditional machines.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-59147-6_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-63537-8_31,A Scalable Neuro-inspired Robot Controller Integrating a Machine Learning Algorithm and a Spiking Cerebellar-Like Network,Biomimetic and Biohybrid Systems,10.1007/978-3-319-63537-8_31,Springer,2017-01-01,"Combining Fable robot, a modular robot, with a neuroinspired controller, we present the proof of principle of a system that can scale to several neurally controlled compliant modules. The motor control and learning of a robot module are carried out by a Unit Learning Machine (ULM) that embeds the Locally Weighted Projection Regression algorithm (LWPR) and a spiking cerebellar-like microcircuit. The LWPR guarantees both an optimized representation of the input space and the learning of the dynamic internal model (IM) of the robot. However, the cerebellar-like sub-circuit integrates LWPR input-driven contributions to deliver accurate corrective commands to the global IM. This article extends the earlier work by including the Deep Cerebellar Nuclei (DCN) and by reproducing the Purkinje and the DCN layers using a spiking neural network (SNN) implemented on the neuromorphic SpiNNaker platform. The performance and robustness outcomes from the real robot tests are promising for neural control scalability.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-63537-8_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-49058-8_45,Action Unit Based Facial Expression Recognition Using Deep Learning,Advances in Robot Design and Intelligent Control,10.1007/978-3-319-49058-8_45,Springer,2017-01-01,"Social interactive robot needs the same behaviours and capabilities as human to be able to work in human daily life. Humans usually use different types of verbal and nonverbal cues in their communication. Facial expressions are good examples of nonverbal cues used in inter-human interaction. This paper presents a facial expression recognition approach using deep learning. The approach is based on the analysis of subtle changes in facial features of human face. The detected facial features, action units, are mapped to two psychological measurements, arousal and valence using support vector regression. Facial expression is then recognized by using these two values. The proposed approach has shown a recognition rate of more than 90%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-49058-8_45,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-53327-8_15,Self-learning Neural Network Control System for Physical Model with One Degree of Freedom of System of Active Vibration Isolation and Pointing of Payload Spacecraft,Smart Electromechanical Systems: The Central Nervous System,10.1007/978-3-319-53327-8_15,Springer,2017-01-01,"Purpose The area of biomimetic robots is successfully developing in intelligent robotics using SEMS and Neurotechnology. These robots are based on the borrowing its core elements from nature and able to adapt to the environment of the real world and to be truly intelligent autonomous robotic devices. For example, the neural network control system are used in intelligent robots, capable of self-learning like brain. Overall, the self-learning neural network control system have a structure similar central and peripheral nervous systems of vertebrates and man. The aim of the publication is the description of the developed model of the self-learning neural network control of a single-stage physical model of intelligence system of active vibration protection and very precise pointing of large precision space antennas. Results Model of the self-learning neural network control system of a single-stage physical model of intelligence system of active vibration protection and very precise pointing of the payload of the spacecraft is developed and tested. The advantages of application of neural PID controller are shown compared with conventional PID controller. Practical value The presented in the article the self-learning neural network control system of a single-stage physical model can be used to create autonomous intelligent robotic system capable to react to changing uncertain conditions in real time outside the operator’s actions, for example in deep space.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-53327-8_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-10-1645-5_29,Autonomous Quantum Reinforcement Learning for Robot Navigation,Proceedings of 2nd International Conference on Intelligent Computing and Applications,10.1007/978-981-10-1645-5_29,Springer,2017-01-01,In order to achieve a safe and traffic free transportation from place to place it is mandatory that a vehicle should communicate with other vehicles autonomously to control their speed and movement. Fuzzy logic control architecture which is placed in the vehicle has been designed to take appropriate decision based on the various parameters inside the vehicle. Number of input and output parameters and rules of operation can be varied easily in the fuzzy logic toolbox in MATLAB. The output will be sent to the micro-controller using RS232 serial communication. Now the micro-controller will take the appropriate action to execute the command received. So in order to communicate with other vehicle we have used GPS receiver which will transmit the current position of the vehicle to nearby vehicle ranging within 30 or 100 m using Zigbee communication in a common transmission frequency. If there is any vehicles present in this range it will accept and communicate back by sending the corresponding GPS location of that vehicle and the path of its course. If it is found to be moving on the same direction or path a communication with the vehicle will be established and data will be transmitted among them to achieve the safe and smooth traffic travel to increase the vehicle efficiency. The same rules will apply if there is more than one vehicle is present in the transmitting range. All these transmitting data will be privacy protected. We have successfully controlled prototype model and found that architecture is working autonomously up to the expectation and provides efficient travel for the vehicle.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-1645-5_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-49049-6_35,Acquisition of Cooperative Action by Rescue Agents with Distributed Roles,Intelligent and Evolutionary Systems,10.1007/978-3-319-49049-6_35,Springer,2017-01-01,"Fully anticipating the overall effect on society is difficult due to the many as-yet-unrecognized factors at disaster sites. There is a need for autonomous disaster relief robots, which can learn from the conditions they encounter and then take independent actions. Reinforcement learning is one way that robots can acquire information about appropriate behavior in new environments. In the present study, we present the results of a disaster relief simulation that included multiple autonomous robots working as a multi-agent system. In order to assist in the use of reinforcement learning for the efficient acquisition of action rules, we divided the task into various sub-tasks. We propose an approach in which cooperative action is obtained by giving each agent a different reward; this encourages the agents to play different roles. We investigated how the various autonomous agents determined the appropriate action rules and examined the influence of providing separate rewards to different agents in the system. We also compared the values of various actions in different learning situations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-49049-6_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-68792-6_21,Using Monte Carlo Search with Data Aggregation to Improve Robot Soccer Policies,RoboCup 2016: Robot World Cup XX,10.1007/978-3-319-68792-6_21,Springer,2017-01-01,"RoboCup soccer competitions are considered among the most challenging multi-robot adversarial environments, due to their high dynamism and the partial observability of the environment. In this paper we introduce a method based on a combination of Monte Carlo search and data aggregation (MCSDA) to adapt discrete-action soccer policies for a defender robot to the strategy of the opponent team. By exploiting a simple representation of the domain, a supervised learning algorithm is trained over an initial collection of data consisting of several simulations of human expert policies. Monte Carlo policy rollouts are then generated and aggregated to previous data to improve the learned policy over multiple epochs and games. The proposed approach has been extensively tested both on a soccer-dedicated simulator and on real robots. Using this method, our learning robot soccer team achieves an improvement in ball interceptions, as well as a reduction in the number of opponents’ goals. Together with a better performance, an overall more efficient positioning of the whole team within the field is achieved.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-68792-6_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-59081-3_15,Adaptive Neural Network Control for Constrained Robot Manipulators,Advances in Neural Networks - ISNN 2017,10.1007/978-3-319-59081-3_15,Springer,2017-01-01,"This paper presents an adaptive neural network (NN) control strategy for robot manipulators with uncertainties and constraints. Position, velocity and control input constraints are considered and tackled by introducing barrier Lyapunov functions in the backstepping procedure. The system uncertainties are estimated and compensated by a locally weighted online NN. The boundedness of the closed-loop control system and the feasibility of the proposed control law are demonstrated by theoretical analysis. The effectiveness of the proposed control strategy has been verified by simulation results on a robot manipulator.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-59081-3_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-70136-3_8,Cloud-Based Knowledge Sharing in Cooperative Robot Tracking of Multiple Targets with Deep Neural Network,Neural Information Processing,10.1007/978-3-319-70136-3_8,Springer,2017-01-01,"Cooperative robot tracking of multiple targets plays an important role in many realistic robot applications. In order to minimize the time during which any target is not tracked, target trading among robots at runtime is a common phenomenon. After a period of successful tracking, the robot can gain a lot of knowledge about the target details, for example, the appearance changes caused by motion and illumination. However, the accumulated knowledge is dropped simply in existing research while robots trading targets, which makes each robot has to learn the knowledge of target details from scratch. The absence of knowledge sharing heavily influences the tracking accuracy in practice. In this paper, we propose a novel approach named Cloudroid Tracking which enables knowledge sharing through the support of the back-end cloud infrastructure. Our approach adopts the deep neural network (DNN) and its online tuning mechanisms to enable the knowledge accumulation. The dynamic connection of multiple DNNs on the cloud infrastructure and multiple robots is enabled. No matter how the target changes, the robot can connect to the corresponding neural network which is responsible for a specific target. The experimental results on both open dataset and real robots show that our approach can promote the accuracy for robot tracking significantly.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-70136-3_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-69456-6_17,Neural Network Control Method for Mobile Robot Trajectory Tracking,Multi-disciplinary Trends in Artificial Intelligence,10.1007/978-3-319-69456-6_17,Springer,2017-01-01,"In this paper, we study movement control problems of nonholonomic mobile robots trajectory tracking and propose an adaptive mixed Pi-Sigma neural network (MPSNN) control method combined effectively with logical reasoning ability of fuzzy control and self-learning ability of neural network control. This method maps Takagi-Sugeno (T-S) fuzzy system to Pi-Sigma neural network (PSNN) structure. It explains the motion state transition process for mobile robot with inference process of T-S fuzzy system and gives neural network certainly physical meaning. The backpropagation iterative algorithm of MPSNN is designed based on the principle of error back propagation and the gradient descent method. The self-learning ability of PSNN is used to adjust T-S fuzzy rules and membership functions on-line to make the trajectory tracking controller of the design have portability and adaptability. In addition, it also designed the quadratic interpolation method to dynamically adjust learning rates in the network and improve the error convergence efficiency. Finally, we design two MPSNN trajectory tracking controllers based on Pi-Sigma neural network and verify the validity and superiority of the proposed method and the designed controller by using MATLAB numerical simulation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-69456-6_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-69131-2_13,A Balking Queue Approach for Modeling Human-Multi-Robot Interaction for Water Monitoring,PRIMA 2017: Principles and Practice of Multi-Agent Systems,10.1007/978-3-319-69131-2_13,Springer,2017-01-01,"We consider multi-robot scenarios where robots ask for operator interventions when facing difficulties. As the number of robots increases, the operator quickly becomes a bottleneck for the system. Queue theory can be effectively used to optimize the scheduling of the robots’ requests. Here we focus on a specific queuing model in which the robots decide whether to join the queue or balk based on a threshold value. Those thresholds are a trade-off between the reward earned by joining the queue and cost of waiting in the queue. Though such queuing models reduce the system’s waiting time, the cost of balking usually is not considered. Our aim is thus to find appropriate balking strategies for a robotic application to reduce the waiting time considering the expected balking costs. We propose using a Q-learning approach to compute balking thresholds and experimentally demonstrate the improvement of team performance compared to previous queuing models.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-69131-2_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-66471-2_22,Crossover of Affective Artificial Intelligence Between Robotics Simulator and Games,Interactive Collaborative Robotics,10.1007/978-3-319-66471-2_22,Springer,2017-01-01,"The aim of this paper is to share state of the art in the field of robotics and artificial intelligence from one side and gaming from other side. Inspired from affective computing in social robotics and in order to improve the learning factor of serious games, we introduce an affection layer which improves the emotional intelligence of a game character. As the components of that layer we propose modules which can be integrated in a game engine in order to enhance the verisimilitude of the virtual world. The proposed architecture can be integrated in several games to improve their emotional abilities which can lead to developing believable characters in the game environment. We believe that such ability increase the motivation for the user to learn since possibilities and situations would be much pragmatic.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-66471-2_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-10-5038-1_11,LegalAIze: Tackling the Normative Challenges of Artificial Intelligence and Robotics Through the Secondary Rules of Law,"New Technology, Big Data and the Law",10.1007/978-981-10-5038-1_11,Springer,2017-01-01,"A considerable number of studies have been devoted over the past years, to stress risks, threats and challenges brought on by the breath-taking advancements of technology in the fields of artificial intelligence (AI), and robotics. The intent of this chapter is to address this set of risks, threats, and challenges, from a threefold legal perspective. First, the focus is on the aim of the law to govern the process of technological innovation, and the different ways or techniques to attain that aim. Second, attention is drawn to matters of legal responsibility, especially in the civilian sector, by taking into account methods of accident control that either cut back on the scale of the activity via, e.g., strict liability rules, or aim to prevent such activities through the precautionary principle. Third, the focus here is on the risk of legislation that may hinder research in AI and robotics. Since there are several applications that can provide services useful to the well-being of humans, the aim should be to prevent this threat of legislators making individuals think twice before using or producing AI and robots. The overall idea is to flesh out specific secondary legal rules that should allow us to understand what kind of primary legal rules we may need. More particularly, the creation of legally de-regulated, or special, zones for AI and robotics appears a smart way to overcome current deadlocks of the law and to further theoretical frameworks with which we should better appreciate the space of potential systems that avoid undesirable behavior.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-5038-1_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-58637-3_37,The Importance of Specific Usability Guidelines for Robot User Interfaces,"Design, User Experience, and Usability: Designing Pleasurable Experiences",10.1007/978-3-319-58637-3_37,Springer,2017-01-01,"In the field of robotics, user interfaces have the important role of aiding humans in better interactions with robots. Hence, until full autonomy becomes a reality, user interfaces are an essential way to communicate necessary information to interact with robotic systems. This article examines which principles of design have been used in Human-Robot Interaction (HRI) to understand further how can usability guidelines can improve the development of user interfaces built to integrate solutions considered as “complex systems”; simultaneous compositions of software behaviors, present in a great deal of industrial solutions and HRI research. Industrial robots have been used in a variety of situations, ranging from in Situ maintenance, to space exploration and the central role of humans in the interaction with automated systems is to undertake what is called supervisory control through monitoring and supervision of operational tasks. Research in interface design can contribute significantly to increase system performance and collaboration between man and robots. As robotic systems evolve the goal for human-in-the-loop activities should not be to eliminate the human, but rather to create human-system collaboration with greater capabilities than the individual components. Therefore, the investigation of guidelines for the elaboration of the more efficient interface in the interaction with robots can greatly contribute with usability principles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-58637-3_37,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-68345-4_9,Vision-Based Robot Path Planning with Deep Learning,Computer Vision Systems,10.1007/978-3-319-68345-4_9,Springer,2017-01-01,"In this paper, a new method based on deep convolutional neural network (CNN) for path planning of robot is proposed, the aim of which is to transform the mission of path planning into a task of environment classification. Firstly, the images of road are collected from cameras installed as required, and then the comprehensive features are abstracted directly from original images through the CNN. Finally, according to the results of classification, the moving direction of robots is exported. In this way, we build an end-to-end recognition system which maps from raw data to motion behavior of robot. Furthermore, experiment has been provided to demonstrate the performance of the proposed method on different roads.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-68345-4_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-57738-8_2,Sex Robots from the Perspective of Machine Ethics,Love and Sex with Robots,10.1007/978-3-319-57738-8_2,Springer,2017-01-01,"This contribution explains firstly the terms and the phenomena of sex robots and robot sex and the foundations of machine ethics. Secondly it poses questions related to sex robots as moral agents, from a general and a specific perspective, aiming at assisting manufacturers and developers. By using the questions, the opportunities and risks can be discussed in a structured manner. Thirdly, the fields of applied ethics are included to work out the implications for humans as moral patients. At the end, the author summarizes the findings. Machine ethics, from his point of view, may help to construct sex robots and service robots with special capabilities which are moral machines in their appearance and in their behaviour and which may allow some people to complement their sexual activities and to lead a fulfilling life. The fields of applied ethics may be beneficial with respect to the adequate use of sex robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-57738-8_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-70022-9_49,Dynamic Gesture Recognition for Social Robots,Social Robotics,10.1007/978-3-319-70022-9_49,Springer,2017-01-01,"Interpreting users messages, both verbal and non-verbal is essential to achieve a natural Human-Robot Interaction. Traditionally, Social Robots, and particularly Care Robots, rely on interfaces such as voice, touch or images to acquire information from users although the latter is usually used to locate them. This manuscript present the main steps of machine learning-based approach, from the skeleton extraction to the features computation and the classification necessary to detect dynamic gestures, which provide more information than simple poses. 123 classification algorithms have been employed to analyse the performance and accuracy of the system. To train these classifiers a, 30 users were recording while performing 14 dynamic gestures, obtaining 1355 instances of 900 features for each of these. Results indicate that Random Forest classifier achieves the highest F-score using cross-validation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-70022-9_49,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-50115-4_43,Towards Learning to Perceive and Reason About Liquids,2016 International Symposium on Experimental Robotics,10.1007/978-3-319-50115-4_43,Springer,2017-01-01,"Recent advances in AI and robotics have claimed many incredible results with deep learning, yet no work to date has applied deep learning to the problem of liquid perception and reasoning. In this paper, we apply fully-convolutional deep neural networks to the tasks of detecting and tracking liquids. We evaluate three models: a single-frame network, multi-frame network, and a LSTM recurrent network. Our results show that the best liquid detection results are achieved when aggregating data over multiple frames and that the LSTM network outperforms the other two in both tasks. This suggests that LSTM-based neural networks have the potential to be a key component for enabling robots to handle liquids using robust, closed-loop controllers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-50115-4_43,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-68600-4_4,Neural End-to-End Self-learning of Visuomotor Skills by Environment Interaction,Artificial Neural Networks and Machine Learning – ICANN 2017,10.1007/978-3-319-68600-4_4,Springer,2017-01-01,"Deep learning with neural networks is dependent on large amounts of annotated training data. For the development of robotic visuomotor skills in complex environments, generating suitable training data is time-consuming and depends on the availability of accurate robot models. Deep reinforcement learning alleviates this challenge by letting robots learn in an unsupervised manner through trial and error at the cost of long training times. In contrast, we present an approach for acquiring visuomotor skills for grasping through fast self-learning: The robot generates suitable training data through interaction with the environment based on initial motor abilities. Supervised end-to-end learning of visuomotor skills is realized with a deep convolutional neural architecture that combines two important subtasks of grasping: object localization and inverse kinematics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-68600-4_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-015-2044-3,A study of fuzzy membership functions for dependence decision-making in security robot system,Neural Computing and Applications,10.1007/s00521-015-2044-3,Springer,2017-01-01,"This paper proposes comparison of fuzzy membership functions for decision-making in security robot system. Robot’s decision-making speed depends on fuzzy membership functions. The results of the study indicate that sigmoidal membership function coincide the best, two-sided Gaussian, Gaussian, generalized bell, and zero on both extremes with a rise in the middle member ship function coincide well. However, sigmoidal, with a mirror image membership function that opens to the right, and asymmetrical polynomial membership functions do not coincide well with the trapezoidal membership function. The result of the study indicates that trapezoidal MF gives the best performance, and triangular MF response is very close to that of trapezoidal MF.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-015-2044-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-63537-8_8,Analysing the Limitations of Deep Learning for Developmental Robotics,Biomimetic and Biohybrid Systems,10.1007/978-3-319-63537-8_8,Springer,2017-01-01,Deep learning is a powerful approach to machine learning however its inherent disadvantages leave much to be desired in the pursuit of the perfect learning machine. This paper outlines the multiple disadvantages of deep learning and offers a view into the implications to solving these problems and how this would affect the state of the art not only in developmental learning but also in real world applications.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-63537-8_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-59773-7_19,A Deep Learning Approach for Underwater Image Enhancement,Biomedical Applications Based on Natural and Artificial Computing,10.1007/978-3-319-59773-7_19,Springer,2017-01-01,Image processing in underwater robotics is one of the most challenging problems in autonomous underwater robotics due to light transmission in water. Although image restoration techniques are able to correctly remove the haze in a degraded image they need many images from the same location making impossible to use it in a real time system. Taking into account the great results of deep learning techniques in other image processing problems such as colorizing images or detecting objects a deep learning solution is proposed. A convolutional neural network is trained with image restoration techniques to dehaze single images outperforming other image enhancement techniques. The proposed approach is able to produce image restoration quality images with a single image as input. The neural network is validated using images from different locations and characteristics to prove the generalization capabilities.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-59773-7_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-66471-2_3,Emotion Recognition System for Human-Robot Interface: Comparison of Two Approaches,Interactive Collaborative Robotics,10.1007/978-3-319-66471-2_3,Springer,2017-01-01,This paper describes a system for automatic emotion recognition developed to enhance the communication capabilities of an anthropomorphic robot. Two versions of the classification algorithm are proposed and compared. The first version is based on a classic approach requiring the action unit estimation as a preliminary step to emotion recognition. The second version takes advantage of convolutional neural networks as a classifier. The designed system is capable of working in real time. The algorithms were implemented on C++ and tested on an extensive face expression database as well as in real conditions.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-66471-2_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-94-007-7194-9_135-1,Speech and Language in Humanoid Robots,Humanoid Robotics: A Reference,10.1007/978-94-007-7194-9_135-1,Springer,2017-01-01,"A fundamental behavioral and cognitive capability of humanoid robots is speech, as spoken language is the primary means of communication between humans. However, communication between people, and between humans and robots, is not only based on speech, but rather is a rich multimodal process combining spoken language with a variety of nonverbal behaviors such as eye gaze, gestures, tactile interaction, and emotional cues. This chapter gives an overview of the state of the art on language and speech capabilities in robots (i.e., “speech interface”), using multimodal approaches. The chapter considers the different levels of analysis of language studies. The computational solutions for the phonetic, lexical, and syntactic levels are general to linguistic analysis and do not require specific consideration from a robotics point of view. Other aspects of language analysis, as semantics and pragmatics, however, have specific peculiarity in robotics given their relationship to the difficult problem of “symbol grounding.” In robot language research, two main approaches have been used for the design of speech interfaces: one is based on standard, predefined natural language processing (NLP) techniques, and the second approach is based on learning methods. The chapter introduces the main NLP methods used in robot language research and subsequently looks at the speech interfaces based on such methods, also considering their use in multimodal interfaces. After this, we will look at language learning approaches which distinguish between developmental learning systems in which the robot goes through a series of developmental training phases, taking inspiration from human language learning, and machine learning approaches in which a set of learning techniques is used to engineer communication capabilities via training of multimodal speech interfaces. Finally, a critical assessment of the current state of the art and the identification of future lines of work is given.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-007-7194-9_135-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-48036-7_12,An Integrated Robotic System for Autonomous Brake Bleeding in Rail Yards,Intelligent Autonomous Systems 14,10.1007/978-3-319-48036-7_12,Springer,2017-01-01,"Current operations in rail yards are dangerous and limited by the operational capabilities of humans being able to perform safely in harsh conditions while maintain high productivity. Such issues call out the need for robust and capable autonomous systems. In this paper, we outline one such autonomous solution for the railroad domain, capable of performing the brake bleeding inspection task in a hump yard. Towards that, we integrated a large form factor mobile robot (the Clearpath Grizzly) with an industrial manipulator arm (Yasakawa Motoman SIA20F) to effectively detect, identify and subsequently manipulate the brake lever under harsh outdoor environments. In this paper, we focus on the system design and the core algorithms necessary for reliable and repeatable system execution. To test our developed solution, we performed extensive field tests in a fully operational rail yard with randomly picked rail cars under day and night-time conditions. The results from the testing are promising and validate the feasibility of deploying an autonomous brake bleeding solution for railyards.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-48036-7_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-68600-4_5,Learning of Labeling Room Space for Mobile Robots Based on Visual Motor Experience,Artificial Neural Networks and Machine Learning – ICANN 2017,10.1007/978-3-319-68600-4_5,Springer,2017-01-01,"A model was developed to allow a mobile robot to label the areas of a typical domestic room, using raw sequential visual and motor data, no explicit information on location was provided, and no maps were constructed. The model comprised a deep autoencoder and a recurrent neural network. The model was demonstrated to (1) learn to correctly label areas of different shapes and sizes, (2) be capable of adapting to changes in room shape and rearrangement of items in the room, and (3) attribute different labels to the same area, when approached from different angles. Analysis of the internal representations of the model showed that a topological structure corresponding to the room structure was self-organized as the trajectory of the internal activations of the network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-68600-4_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-64107-2_34,The Power of GMMs: Unsupervised Dirt Spot Detection for Industrial Floor Cleaning Robots,Towards Autonomous Robotic Systems,10.1007/978-3-319-64107-2_34,Springer,2017-01-01,"Small autonomous florr cleaning robots are the first robots to have entered our homes. These automatic vacuum cleaners have only used ver low-level dirt detection sensors and the vision systems have been constrained to plain-colored and simple-textured floors. However, for industrial applications, where efficiency and the quality of work are paramount, explicit high-level dirt detection is essential. To extend the usability of floor cleaning robots to theses real-world applications, we introduce a more general approach that detects dirt spots on single-colored as well as regularly-textured floors. Dirt detection is approached as a single-class classification problem, using unsupervised online learning of a Gaussian Mixture Model representing the floor pattern. An extensive evaluation shows that our method detects dirt spots on different floor types and that it outperforms state-of-the-art approaches especially for complex floor textures.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-64107-2_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-48036-7_60,View-Based Teaching/Playback with Photoelasticity for Force-Control Tasks,Intelligent Autonomous Systems 14,10.1007/978-3-319-48036-7_60,Springer,2017-01-01,"We study a novel robot programming method that uses the view-based approach: “view-based teaching/playback.” This method directly uses images for robot programming and can accommodate itself to changes of task conditions. However, our previous view-based teaching/playback cannot perform force-control tasks; for example, it cannot deal with pressing objects against walls, in which view of images does not change. In this paper, we extend the view-based teaching/playback so that it is applicable to force-control tasks using photoelasticity. In the experiment, the extended view-based teaching/playback succeeded in wall-pressing tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-48036-7_60,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-68600-4_17,Robot Localization and Orientation Detection Based on Place Cells and Head-Direction Cells,Artificial Neural Networks and Machine Learning – ICANN 2017,10.1007/978-3-319-68600-4_17,Springer,2017-01-01,"Place cells and head-direction cells play important roles in animal navigation and have distinguishable firing properties in biology. Recently, a slowness principle has been argued as the fundamental learning mechanism behind these firing activities. Based on this principle, we extend previous work, which produced only a continuum of place and head-direction cells and mixtures thereof, to achieve a clean separation of two different cell types from just one exploration. Due to the unsupervised learning strategy, these firing activities do not contain explicit information of position or orientation of an agent. In order to read out these intangible activities for real robots, we propose that place cell activities can be utilized to build a self-organizing topological map of the environment and thus for robot localization. At the same time, the robot’s current orientation can be read out from the head-direction cell activities. The final experimental results demonstrate the feasibility and effectiveness of the proposed methods, which provide a basis for robot navigation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-68600-4_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-68612-7_54,Dialogue-Based Neural Learning to Estimate the Sentiment of a Next Upcoming Utterance,Artificial Neural Networks and Machine Learning – ICANN 2017,10.1007/978-3-319-68612-7_54,Springer,2017-01-01,"In a conversation, humans use changes in a dialogue to predict safety-critical situations and use them to react accordingly. We propose to use the same cues for safer human-robot interaction for early verbal detection of dangerous situations. Due to the limited availability of sentiment-annotated dialogue corpora, we use a simple sentiment classification for utterances to neurally learn sentiment changes within dialogues and ultimately predict the sentiment of upcoming utterances. We train a recurrent neural network on context sequences of words, defined as two utterances of each speaker, to predict the sentiment class of the next utterance. Our results show that this leads to useful predictions of the sentiment class of the upcoming utterance. Results for two challenging dialogue datasets are reported to show that predictions are similar independent of the dataset used for training. The prediction accuracy is about 63% for binary and 58% for multi-class classification.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-68612-7_54,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-68600-4_31,Inherently Constraint-Aware Control of Many-Joint Robot Arms with Inverse Recurrent Models,Artificial Neural Networks and Machine Learning – ICANN 2017,10.1007/978-3-319-68600-4_31,Springer,2017-01-01,"In a recent study, it was demonstrated that Recurrent Neural Networks (RNNs) can be used to effectively control snake-like, many-joint robot arms in a particular way: The inverse kinematics for control are generated using back-propagation through time (BPTT) on recurrent forward models that learned to predict the end-effector pose of a robot arm, whereby each joint is associated with a certain computation time step of the RNN. This paper further investigates this approach in terms of constraint-aware control. Our contribution is twofold: First, we show that an RNN can be trained to also predict the poses of intermediate joints within such an arm, and that these can consequently be included in the control-optimization objective as well, giving full control over the entire arm. Second, we show that particular components of the arm’s target can be selectively switched on and off by means of “don’t care” signals. This enables us to handle constraints inherently and on-the-fly, without the need of any outer constraint mechanisms, such as additional penalty terms. The experiments demonstrating the effectiveness of our methodology are carried out on a simulated three dimensional 40-joint robot arm with 80 articulated degrees offreedom.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-68600-4_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-54377-2_22,Teaching Math in Elementary Schools by LabVIEW and Lego Robots,Advances in Automation and Robotics Research in Latin America,10.1007/978-3-319-54377-2_22,Springer,2017-01-01,"This paper shows a novel platform based on fuzzy logic system for developing a math tutor using LEGO® robots and LabVIEW programs to teach math in elementary schools. The platform is divided into two main parts; the first part is the LEGO® robots, which have preloaded programs for different math topics (exercises), and the second part runs LabVIEW programs for evaluating the progress of each child. The platform is used as a regular play in the classrooms. The robots are personal tutors for each child during the class. After the students finished to review the math topic with the robot, they have to solve a math exam that includes questions about the reviewed topic with LEGO® robot. The main program, which runs the complete math topic in the robot and the exam, was developed in LabVIEW and has an artificial intelligence method for searching the best set of questions and sending feedback regarding the exam results to the child. This platform was validated in two elementary schools located in Xalapa Veracruz, Mexico. The results confirm that the platform helps to increase the kid’s motivation about math and it opens new possibilities for teaching mathematics. Moreover, the kids learn at the same time different topics and skills such as robotics, computer science, mechanical systems, teamwork, and leadership.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-54377-2_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-015-1631-7,An empirical study on evaluating basic characteristics and adaptability to users of a preventive care system with learning communication robots,Soft Computing,10.1007/s00500-015-1631-7,Springer,2017-01-01,"In many countries, and particularly in Japan, rising medical costs and shortfalls in the number of healthcare personnel are becoming serious national problems. This paper proposes a Preventive Care system with learning Communication robots ( PrevCareCom ), aiming to provide a preventive care approach wherein the elderly can engage in exercise over the long term without getting bored while communicating with robots through match-up games. In the PrevCareCom, the preventive care exercises are based on a simple, traditional Japanese match-up game, and several kinds of robots are used as opponents. The proposed system encourages a sense of familiarity with the robots (agents) for elderly users based on the concept of human–agent interaction. Reinforcement learning methods are also used to adapt system parameters such as exercise intensity and robot behavioral policy to the athletic performance of each user. Several experiments were carried out with the cooperation of local governments and health and welfare facilities to investigate characteristics of the PrevCareCom and to evaluate how well it adapts to its users in terms of familiarity, quality and quantity of exercise. The results of experiments showed that the users’ interest in the proposed system and sense of familiarity with the robots were encouraged by playing the game and interacting with the robots. Questionnaire results also showed that the PrevCareCom could provide appropriate exercise loads for the users’ care prevention.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-015-1631-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-48506-5_22,An Emotional Robot,Computational Intelligence,10.1007/978-3-319-48506-5_22,Springer,2017-01-01,"The method to construct an emotional robot based on regulation of emotional responses with an emotion state embedded reinforcement learning system is proposed in this paper. Besides environmental states, the emotional robot has emotional states which are generated by stimulus received from sensor images. If the learning coefficient of emotions in Amygdala model is changed, generated emotional states in the robot are also different, even if the robot sees same sensor images. As a result, using the method, we can make kinds of robots with any emotions, having same structures. Through computer simulations, applying the proposed method to construct emotional robots, it is said the robots solve the path-finding problem including a variety of distinctive solutions. We find that each robot is able to have each individual solution depending on kinds of its emotions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-48506-5_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-60285-1_40,Intelligent Transport System Through the Recognition of Elements in the Environment,Highlights of Practical Applications of Cyber-Physical Multi-Agent Systems,10.1007/978-3-319-60285-1_40,Springer,2017-01-01,"Autonomous vehicles are becoming one of the developmental elements, not only for the transport of people but also in the field of data collection and monitoring, control of external elements or supervision and security. Their advantage is the ability to access dangerous areas which often cannot be accessed by humans. It is necessary that the vehicle recognizes its surrounding and reacts in an adequate way. In this work a study was carried out of the main techniques of artificial vision, machine learning and supervised learning applied in vehicles so they recognize the road and do not leave it. This work presents the viability of the different machine learning techniques for their application in the problem of autonomous driving. For this, an automobile robotic prototype has been constructed and an algorithm has been developed based on the Artificial Neural Network (ANN) algorithm and a user application which allows to carry out all integrated analysis and observe in real-time the vehicle’s view and the processing of the different snapshots. We have also demonstrated that the application of the stated algorithm, diverse processing techniques and artificial vision was sufficient, so that our robot could drive with precision and keep on the track of a road in a controlled environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-60285-1_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-49073-1_4,A Computer Vision Based Machine for Walnuts Sorting Using Robot Operating System,Advances in Information and Communication Technology,10.1007/978-3-319-49073-1_4,Springer,2017-01-01,"Industrial machines are generally expensive to implement due to their requirement of being fast and robust . In this paper, we proposed a new approach to the problem, particularly, a walnut sorting machine that was built cheaply using open solution. On hardware side, we used readily available electronics and on the software side, Robot Operating System was adopted to handle low level hardware abstraction. Machine Learning , Computer Vision and data processing techniques were implemented on top of them using high level programming language. This resulted in a highly functional, easy to maintain yet inexpensive walnuts sorting machine - which was confirmed by our Austrian partner’s testing. This success, hopefully, will pave the way for more projects using similar approaches.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-49073-1_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-41959-6_35,A Method for Neighborhood Gesture Learning Based on Resistance Distance,Advances in Human Factors in Robots and Unmanned Systems,10.1007/978-3-319-41959-6_35,Springer,2017-01-01,"Multimodal forms of human-robot interaction (HRI) including non-verbal forms promise easily adopted and intuitive use models for assistive devices. The research described in this paper targets an assistive robotic appliance which learns a user’s gestures for activities performed in a healthcare or aging in place setting. The proposed approach uses the Growing Neural Gas (GNG) algorithm in combination with the Q-Learning paradigm of reinforcement learning to shape robotic motions over time. Neighborhoods of nodes in the GNG network are combined to collectively leverage past learning by the group. Connections between nodes are assigned weights based on frequency of use which can be viewed as measures of electrical resistance. In this way, the GNG network may be traversed based on distances computed in the same manner as resistance in an electrical circuit. It is shown that this distance metric provides faster convergence of the algorithm when compared to shortest path neighborhood learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-41959-6_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-02520-4_5,Machine Learning Mechanisms for Quantum Robotics,Quantum Robotics,10.1007/978-3-031-02520-4_5,Springer,2017-01-01,"Applications of machine learning are ubiquitous in robotics today. Agent learning (previously covered) is only one of the forms of machine learning commonly used in classical robotics. We briefly summarize a few areas of classical robotics that have recently used machine learning: Automated analysis and data mining of sensor data for perception : A robot needs to be able to robustly understand its sensor data, mine it for patterns, and understand possible percepts (e.g., obstacles) in its world. Machine learning approaches are commonly being researched for computer vision [Cipolla et al., 2013], lidar [Lodha et al., 2006, Zhao et al., 2011], sonar [Dietterich, 1997], force sensing [Edsinger-Gonzales and Weber, 2004], and other such perception technologies. Robot localization : Robots need to be able to self-localize in an environment. Modern localization technologies (e.g., inertial navigation [Bagnell et al., 2010], wi-fi localization [Biswas and Veloso, 2010], range-sensor-based localization [Thrun et al., 2001]) all make extensive use of machine learning methods. Learning robot controllers and planners : Learning robot controllers from simulation or actual data are key techniques being employed in many domains involving robots. High-level robot planners also benefit from learning, such as learning retrospectively from experience. Online Learning [Gaskett and Cheng, 2003, Hadsell et al., 2007, Hagras, 2001], Reinforcement Learning [Kaelbling et al., 1996], and Deep Learning [Bengio, 2009, LeCun et al., 2010, Lenz et al., 2015] are key approaches being heavily researched by groups all over the world. Learning human-robot interaction : Data-driven approaches are being used to understand how humans and robots interact [Hiraki, 1995]. Machine learning approaches are being used to model this interaction and recognize user affect [Rani et al., 2006].",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-02520-4_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-70022-9_29,What Went Wrong and Why? Diagnosing Situated Interaction Failures in the Wild,Social Robotics,10.1007/978-3-319-70022-9_29,Springer,2017-01-01,"Effective situated interaction hinges on the well-coordinated operation of a set of competencies, including computer vision, speech recognition, and natural language, as well as higher-level inferences about turn taking and engagement. Systems often rely on a set of hand-coded and machine-learned components organized into several sensing and decision-making pipelines. Given their complexity and inter-dependencies, developing and debugging such systems can be challenging. “In-the-wild” deployments outside of controlled lab conditions bring further challenges due to unanticipated phenomena, including unexpected interactions such as playful engagements. We present a methodology for assessing performance, identifying problems, and diagnosing the root causes and influences of different types of failures on the overall performance of a situated interaction system functioning in the wild. We apply the methodology to a dataset of interactions collected with a robot deployed in a public space inside an office building. The analyses identify and characterize multiple types of failures, their causes, and their relationship to overall performance. We employ models that predict overall interaction quality from various combinations of failures. Finally, we discuss lessons learned with such a diagnostic methodology for improving situated systems deployed in the wild.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-70022-9_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-59060-8_35,Conditioned Anxiety Mechanism as a Basis for a Procedure of Control Module of an Autonomous Robot,Artificial Intelligence and Soft Computing,10.1007/978-3-319-59060-8_35,Springer,2017-01-01,"This paper is devoted to the problem of self-control of autonomous robot in a complex, unknown environment. In such an environment it is impossible to predict all situations the robot could be faced with. Because of this it is necessary to equip the robot with control procedures that allow it to avoid dangerous scenarios. Mechanisms that serve to avoid threatening events have been worked out during evolution and living organisms are equipped with them. Conditioned anxiety is one of such mechanisms. In this paper the way in which this mechanism can be adapted to control of behaviour of autonomous robot, is presented. The effectiveness of the proposed approach has been verified by using V-REP simulator.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-59060-8_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-41270-2_8,The Urbanite (Homo urbanus),Surviving the 21st Century,10.1007/978-3-319-41270-2_8,Springer,2017-01-01,"Rise of the megacities: their strengths and lethal flaws. Urban perils: pandemic disease and resource failures. Risks from man-made diseases, artificial intelligence and autonomous ‘killer robots’. The global surveillance state; its impact on human evolution and our ability to cope and change. The widening divide between rich and poor and its impact on social cohesion in solving global threats. What individuals can do to change the attitudes of governments and corporations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-41270-2_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-66945-8_7,Transformation in Investment Management,Digital Transformation in Financial Services,10.1007/978-3-319-66945-8_7,Springer,2017-01-01,"Digital transformation is shaking up investment management at least on four fronts. It allows the extended participation of people to the international world of capital markets, further pushing the limits of the concept of a “(cyber) capitalism” open to everybody. Secondly, it further contributes to develop the trading battlefield into a war among machines and AI-powered algorithms. Thirdly, it changes the world of advisory in money management, as robots are becoming better and nicer at this job. Not to mention, finally, the impacts on the back and middle office activities that are becoming more and more “industrialized by digitization”. Very large pay offs are at stake for markets and societies alike, but also new risks, as algorithms tend to think alike, even more than human beings, with potential effects still not fully understood and just partially addressed. Successful transformation will rely on this optimal relationship between men and machines.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-66945-8_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-10-3174-8_4,A Comparative Study Between Hopfield Neural Network and A* Path Planning Algorithms for Mobile Robot,Artificial Intelligence and Evolutionary Computations in Engineering Systems,10.1007/978-981-10-3174-8_4,Springer,2017-01-01,"Path planning is an important aspect of any mobile robot navigation to find a hazard-free path and an optimal path. Currently, the A* algorithm is considered to be one of the prominent algorithms for path planning in a known environment. However, with the rise of neural networks and machine learning, newer promising algorithms are emerging in this domain. Our work compares one such algorithm namely the Hopfield neural network-based path planning algorithm with A* in a static environment. Both the Hopfield network and the A* algorithm were implemented while minimizing the total run times of the programs. For this, both the algorithms were run in MATLAB environment and a set of mazes were then executed and their run times were compared. Based on the study, the A* algorithm fared better and the Hopfield network showed promising results with scope for further reduction in its run time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-3174-8_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-53327-8_14,Multiagent Approach to Control a Multisection Trunk-Type Manipulator,Smart Electromechanical Systems: The Central Nervous System,10.1007/978-3-319-53327-8_14,Springer,2017-01-01,"Purpose We consider a multisection trunk type manipulator built on the basis of parallel structure mechanisms, for example, on the basis of tripods or hexapods. Control of such a manipulator is a serious problem, as, in addition to control of each section of the manipulator, it is necessary to control the entire structure. To resolve this problem we suggest using a multiagent approach, neural networks and neuro-fuzzy technologies. We introduce an automatic control system for the trunk type manipulator, as well as the functions implemented by the coordinator and agents of this system. Results We investigate the efficiency of the adaptive agent built on the basis of a neural network inverse model of the control object, as well as on the basis of the reference model of the object in the form of another multilayer neural network . Practical value The presented in the article the automatic control system for the trunk type manipulator can be used to create intelligent robotic system capable to react to changing uncertain conditions in real time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-53327-8_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-70136-3_12,Event-Based Target Tracking Control for a Snake Robot Using a Dynamic Vision Sensor,Neural Information Processing,10.1007/978-3-319-70136-3_12,Springer,2017-01-01,"Dynamic Vision Sensor (DVS) is a promising neuromorphic vision sensor for autonomous locomotion control of mobile robots, as the DVS acquires visual information by mimicking retina to sense and encode the world as neural signals. In this paper, we present an autonomous target detecting and tracking control approach for a snake-like robot with a monocular DVS. By using Hough transform based on the Spiking Neural Network (SNN), the target pole is detected as two parallel lines from the event-based visual input. Then a depth estimation method based on the pose and motion of the robot is proposed. Furthermore, by combining the periodic motion feature of the snake-like robot, an adaptive tracking method based on the estimated depth information is introduced. Experiments are conducted on a snake-like robot to demonstrate the practicality and accuracy of our proposed method to track a target pole dynamically with a monocular DVS.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-70136-3_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-48036-7_68,Lighting- and Occlusion-Robust View-Based Teaching/Playback for Model-Free Robot Programming,Intelligent Autonomous Systems 14,10.1007/978-3-319-48036-7_68,Springer,2017-01-01,"In this paper, we investigate a model-free method for robot programming referred to as view-based teaching/playback. It uses neural networks to map factor scores of input images onto robot motions. The method can achieve greater robustness to changes in the task conditions, including the initial pose of the object, as compared to conventional teaching/playback. We devised an online algorithm for adaptively switching between range and grayscale images used in view-based teaching/playback. In its application to pushing tasks using an industrial manipulator, view-based teaching/playback using the proposed algorithm succeeded even under changing lighting conditions. We also devised an algorithm to cope with occlusions using subimages, which worked successfully in experiments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-48036-7_68,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1631/FITEE.1601650,Current trends in the development of intelligent unmanned autonomous systems,Frontiers of Information Technology & Electronic Engineering,10.1631/FITEE.1601650,Springer,2017-01-01,"Intelligent unmanned autonomous systems are some of the most important applications of artificial intelligence (AI). The development of such systems can significantly promote innovation in AI technologies. This paper introduces the trends in the development of intelligent unmanned autonomous systems by summarizing the main achievements in each technological platform. Furthermore, we classify the relevant technologies into seven areas, including AI technologies, unmanned vehicles, unmanned aerial vehicles, service robots, space robots, marine robots, and unmanned workshops/intelligent plants. Current trends and developments in each area are introduced.",http://link.springer.com/openurl/fulltext?id=doi:10.1631/FITEE.1601650,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-50115-4_29,EUROPtus: A Mixed-Initiative Controller for Multi-vehicle Oceanographic Field Experiments,2016 International Symposium on Experimental Robotics,10.1007/978-3-319-50115-4_29,Springer,2017-01-01,"Our research concerns the mixed-initiative coordination of air and underwater vehicles interacting over inter-operated radio and underwater communication networks for novel oceanographic field studies. In such an environment, operating multiple vehicles to observe dynamic oceanographic events such as fronts, plumes, blooms and cetaceans has required that we design, implement and operate software, methods and processes which can support ephemeral and unpredictable observations (including those of moving animals) in real-world settings with substantial constraints. We articulate an approach for coordinated measurements using such platforms, which relate directly to task outcomes. We show the use and operational value of a new Artificial Intelligence (AI) based mixed-initiative system, EUROPtus , for handling multiple platforms from a recent field experiment in open waters of the mid-Atlantic.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-50115-4_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-63537-8_28,Causal Biomimesis: Self-replication as Evolutionary Consequence,Biomimetic and Biohybrid Systems,10.1007/978-3-319-63537-8_28,Springer,2017-01-01,"For millions of years, hominins have been engaged in tool-making and concomitant experimentation. This cognitive enterprise has eventually led to the creation of synthetic intelligence in the form of complex computing and artificial agents, whose purported purpose is to elucidate the workings of human biology and consciousness, automate tasks, and develop interventions for disease. However, much of the expensive research efforts invested in understanding complex natural systems has resulted in limited rewards for treatment of disease. This paper proposes the novel ‘causal biomimesis’ hypothesis: with respect to the relationship between humans and artificial life, the virtually inevitable intrinsic evolutionary consequence of tool-making and biomimetic efforts—and the capacity for objective thought and the scientific method itself—is the full-scale replication of human cognitive functionality, agency, and potentially consciousness in silico . This self-replication transpires through a cycle of anthropogenic biomimetic auto-catalysis driven by instrumental cognition—from objective reasoning in hominin tool-maker through to post-biological reproduction by synthetic agents—and is self-organized and co-enacted between agent and the produced artefactual aggregates. In light of this radical hypothesis, existential and ethical implications are considered for further exploration.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-63537-8_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-63537-8_29,Non-ordinary Consciousness for Artificial Intelligence,Biomimetic and Biohybrid Systems,10.1007/978-3-319-63537-8_29,Springer,2017-01-01,"Humans are active agents in the design of artificial intelligence (AI), and our input into its development is critical. A case is made for recognizing the importance of including non-ordinary functional capacities of human consciousness in the development of synthetic life, in order for the latter to capture a wider range in the spectrum of neurobiological capabilities. These capacities can be revealed by studying self-cultivation practices designed by humans since prehistoric times for developing non-ordinary functionalities of consciousness. A neurophenomenological praxis is proposed as a model for self-cultivation by an agent in an entropic world. It is proposed that this approach will promote a more complete self-understanding in humans and enable a more thoroughly mutually-beneficial relationship between in life in vivo and in silico .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-63537-8_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-54215-7_6,Heavy Metal: AIs and Robots in Cinema,Hollyweird Science: The Next Generation,10.1007/978-3-319-54215-7_6,Springer,2017-01-01,"“Would you like fries with that?” is not only how students with technical majors mock their liberal arts peers, it is an example of the suggestive marketing that has long been commonplace in fast food restaurants. Now, the concept of suggestive marketing has exploded into a whole new dimension. Shop on a cloud-based marketing site like Amazon.com and purchase composer Bear McCreary’s Caprica soundtrack (see our discussion with Bear in Chap. 9 ), and the site will also offer you links to every CD he’s ever released, CDs that other shoppers who have purchased his material have purchased, and, oh, here’s a book about Caprica , and one about Battlestar Galactica as well.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-54215-7_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-64107-2_26,Homeostatic Robot Control Using Simple Neuromodulatory Techniques,Towards Autonomous Robotic Systems,10.1007/978-3-319-64107-2_26,Springer,2017-01-01,"The UESMANN (Uniform Excitatory Switching Multifunction Artificial Neural Network) architecture has been shown to produce interesting transitions between multiple behaviours using an extremely simple neuromodulatory regime. Previous work has concentrated on discrete classification tasks. In this work, three different simple neuromodulatory architectures including UESMANN are used to control a robot in a homeostatic task. The experiments show that UESMANN produces interesting and useful transitional behaviour in an embodied system, learning the two tasks in the same number of parameters (i.e. network weights) as networks which learned each individual task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-64107-2_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-63537-8_39,Using Deep Autoencoders to Investigate Image Matching in Visual Navigation,Biomimetic and Biohybrid Systems,10.1007/978-3-319-63537-8_39,Springer,2017-01-01,"This paper discusses the use of deep auto encoder networks to find a compressed representation of an image, which can be used for visual navigation. Images reconstructed from the compressed representation are tested to see if they retain enough information to be used as a visual compass (in which an image is matched with another to recall a bearing/movement direction) as this ability is at the heart of a visual route navigation algorithm. We show that both reconstructed images and compressed representations from different layers of the auto encoder can be used in this way, suggesting that a compact image code is sufficient for visual navigation and that deep networks hold promise for finding optimal visual encodings for this task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-63537-8_39,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-70136-3_2,A Learning-Based Decentralized Optimal Control Method for Modular and Reconfigurable Robots with Uncertain Environment,Neural Information Processing,10.1007/978-3-319-70136-3_2,Springer,2017-01-01,"This paper presents a novel decentralized control approach for modular and reconfigurable robots (MRRs) with uncertain environment contact under a learning-based optimal compensation strategy. Unlike the known optimal control methods that are merely suitable for specific classes of robotic systems without implementing dynamic compensations, in this investigation, the dynamic model of the MRR system is described as a synthesis of interconnected subsystems, in which the obtainable local dynamic information is utilized effectively to construct the feedback controller, thus making the decentralized optimal control problem of the MRR system be formulated as an optimal compensation issue of the model uncertainty. A policy iteration algorithm is employed to solve the Hamilton-Jacobi-Bellman (HJB) equation with a modified cost function, which is approximated by constructing a critic neural network, and then the approximate optimal control policy can be derived. The asymptotic stability of the closed-loop MRR system is proved by using the Lyapunov theory. At last, simulations are performed to verify the effectiveness of the proposed decentralized optimal control approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-70136-3_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-55372-6_18,Adaptive Training of Neural Networks for Control of Autonomous Mobile Robots,Sensing and Control for Autonomous Vehicles,10.1007/978-3-319-55372-6_18,Springer,2017-01-01,"We present an adaptive training Adaptive training procedure for a spiking neural network Neural networks (NN) , which is used for control of a mobile robot Mobile robot . Because of manufacturing tolerances, any hardware implementation of a spiking neural network Spiking Neural Networks (SNN) has non-identical nodes, which limit the performance of the controller. The adaptive training procedure renders the input-output maps of these non-identical nodes practically identical, therewith recovering the controller performance. The key idea is to replace the nodes of the spiking neural network by small networks of synchronizing neurons that we call clusters. The networks (and interaction weights) are generated adaptively by minimizing the errors in the collective input-output behavior of the cluster relative to that of a known reference. By means of numerical simulations we show that our adaptive training procedure yields the desired results and, moreover, the generated networks are consistent over trials. Thus, our adaptive training procedure generates optimal network structures with desired collective input-output behavior.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-55372-6_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-48036-7_61,Discovering the Relationship Between the Morphology and the Internal Model in a Robot System by Means of Neural Networks,Intelligent Autonomous Systems 14,10.1007/978-3-319-48036-7_61,Springer,2017-01-01,"Supervised machine learning techniques have proven very effective to solve the problems arising from model learning in robotics. A significant limitation of such approaches is that internal models learned for a specific robot are likely to fail when transferred to a robot with a different morphology. One of the challenges to relate the morphology and the internal model is the difference in the number of parameters that define them. We propose three neural network architectures for solving this problem, along with a case study to evaluate their performance, namely saccadic movements in a robotic head. We generate a huge dataset to test the performance of the proposed architectures. Our results suggest that the best solution is provided by the parallel neural network, due to the fact that the trained weights are independent of one another.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-48036-7_61,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-68600-4_6,Towards Grasping with Spiking Neural Networks for Anthropomorphic Robot Hands,Artificial Neural Networks and Machine Learning – ICANN 2017,10.1007/978-3-319-68600-4_6,Springer,2017-01-01,Representation and execution of movement in biology is an active field of research relevant to neurorobotics. Humans can remember grasp motions and modify them during execution based on the shape and the intended interaction with objects. We present a hierarchical spiking neural network with a biologically inspired architecture for representing different grasp motions. We demonstrate the ability of our network to learn from human demonstration using synaptic plasticity on two different exemplary grasp types (pinch and cylinder). We evaluate the performance of the network in simulation and on a real anthropomorphic robotic hand. The network exposes the ability of learning finger coordination and synergies between joints that can be used for grasping.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-68600-4_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-68600-4_2,Mixing Actual and Predicted Sensory States Based on Uncertainty Estimation for Flexible and Robust Robot Behavior,Artificial Neural Networks and Machine Learning – ICANN 2017,10.1007/978-3-319-68600-4_2,Springer,2017-01-01,"In this paper, we propose a method to dynamically modulate the input state of recurrent neural networks (RNNs) so as to realize flexible and robust robot behavior. We employ the so-called stochastic continuous-time RNN (S-CTRNN), which can learn to predict the mean and variance (or uncertainty) of subsequent sensorimotor information. Our proposed method uses this estimated uncertainty to determine a mixture ratio for combining actual and predicted sensory states of network input. The method is evaluated by conducting a robot learning experiment in which a robot is required to perform a sensory-dependent task and a sensory-independent task. The sensory-dependent task requires the robot to incorporate meaningful sensory information, and the sensory-independent task requires the robot to ignore irrelevant sensory information. Experimental results demonstrate that a robot controlled by our proposed method exhibits flexible and robust behavior, which results from dynamic modulation of the network input on the basis of the estimated uncertainty of actual sensory states.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-68600-4_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-66562-7_36,Analysis and Application of a Displacement CPG-Based Method on Articulated Frames,Advances in Computing,10.1007/978-3-319-66562-7_36,Springer,2017-01-01,"The large evolution of robotics in the last 20 years has been developed with the great contribution of new techniques from computational intelligence, inspired in living things. They have changed the design of articulated artificial systems. The Central Pattern Generators were revealed in the 90´s as regulators of autonomous and rhythmic movements on fish, reptiles, birds and mammals. In this work, through recurrent and dynamical neural networks for the simulation and physical assembly of a quadruped robot with three joints per leg, the concept of Central Pattern Generators (CPG) is applied. A distributed autonomous control architecture based on modular and hierarchical CPG is designed and embedded in software systems. Five recurrent neural networks, organized in two layers, are simultaneously managed to generate signals, synchronize and execute the movement of each joint from each leg, and for the total movement production of different gaits. Successful autonomous decision-making results found for different gaits are shown.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-66562-7_36,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-016-0378-4,Spatial Trajectory Tracking Control of a Fully Actuated Helicopter in Known Static Environment,Journal of Intelligent & Robotic Systems,10.1007/s10846-016-0378-4,Springer,2017-01-01,"In this paper, we consider the control problem of tracking a 3D spatial trajectory for a fully actuated helicopter in static known environment, which is predefined to avoid obstacles and collisions considering the distance, fuel consumption and other related constraints. For this purpose, a nonlinear controller using the radial basis function neural network (RBFNN) is designed. Based on Lyapunov analysis, the proposed adaptive neural network control succeeds in tracking the desired trajectory robustly to a small neighborhood of zero, and guarantees the boundedness of all the closed-loop signals at the same time. Extensive numerical results are given to illustrate the effectiveness of the designed controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-016-0378-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-94-007-7194-9_50-1,Humanoid Body Control Using Neural Networks and Fuzzy Logic,Humanoid Robotics: A Reference,10.1007/978-94-007-7194-9_50-1,Springer,2017-01-01,"A humanoid robot is assumed to be consisting of a number of rigid links connected through some joints, for simplicity. Relative movement of the links causes motion to the robot during its walking. Realizing the fact that body motion has significant effect on power requirement and overall balance of the robot, a few studies had been reported in the literature. The present chapter deals with the studies related to how to decide and control body movement of a biped robot (that is, simpler version of humanoid robot) while ascending through some staircases by using neural networks and fuzzy logic techniques. Similar studies may be conducted for modeling other types of movement of the robot like staircase descending, ditch crossing, turning, and others.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-007-7194-9_50-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-68600-4_27,Inferring Adaptive Goal-Directed Behavior Within Recurrent Neural Networks,Artificial Neural Networks and Machine Learning – ICANN 2017,10.1007/978-3-319-68600-4_27,Springer,2017-01-01,"This paper shows that active-inference-based, flexible, adaptive goal-directed behavior can be generated by utilizing temporal gradients in a recurrent neural network (RNN). The RNN learns a dynamical sensorimotor forward model of a partially observable environment. It then uses this model to execute goal-directed policy inference online. The internal neural activities encode the predictive state of the controlled entity. The active inference process projects these activities into the future via the RNN’s recurrences, following a tentative sequence of motor commands. This sequence is adapted by back-projecting error between the forward-projected hypothetical states and the desired goal states onto the motor commands. As an example, we show that a trained RNN model can be used to precisely control a multi-copter-like system. Moreover, we show that the RNN can plan hundreds of time steps ahead, unfolding non-linear imaginary paths around obstacles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-68600-4_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-48036-7_9,Fast and Accurate Crop and Weed Identification with Summarized Train Sets for Precision Agriculture,Intelligent Autonomous Systems 14,10.1007/978-3-319-48036-7_9,Springer,2017-01-01,"In this paper we present a perception system for agriculture robotics that enables an unmanned ground vehicle (UGV) equipped with a multi spectral camera to automatically perform the crop/weed detection and classification tasks in real-time. Our approach exploits a pipeline that includes two different convolutional neural networks (CNNs) applied to the input RGB+near infra-red (NIR) images. A lightweight CNN is used to perform a fast and robust, pixel-wise, binary image segmentation, in order to extract the pixels that represent projections of 3D points that belong to green vegetation. A deeper CNN is then used to classify the extracted pixels between the crop and weed classes. A further important contribution of this work is a novel unsupervised dataset summarization algorithm that automatically selects from a large dataset the most informative subsets that better describe the original one. This enables to streamline and speed-up the manual dataset labeling process, otherwise extremely time consuming, while preserving good classification performance. Experiments performed on different datasets taken from a real farm robot confirm the effectiveness of our approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-48036-7_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-66562-7_33,Evolutionary Parameter Estimation of Coupled Non-linear Oscillators,Advances in Computing,10.1007/978-3-319-66562-7_33,Springer,2017-01-01,"In nature, nonlinear oscillators are observed attached to the joints of the animal’s legs as they move. In this paper, a system identification method based on evolutionary computation applied to coupled nonlinear oscillators is presented. As an initial reference, is a coupled non-linear oscillator designed from a Central Pattern Generator, developed for a quadruped robot with three joints per leg, and electronically tuned. The method of identification is based on the MAGO evolutionary algorithm to minimize the error in the magnitude and in the phase shift of the signals. The procedure consists of two stages: coarse-tuning and fine-tuning. With a new parameterization of the same oscillator developed for the quadruped robot, the goodness of the identification method is revealed. The method is validated by parameterizing the Van der Pol Oscillator. The results are very satisfactory. The problem to be solved is to find a mathematical model that synthesizes the observed movement of a quadruped as it moves. From the images of the oscillations generated by the hip, knee and ankle of a horse, a system of coupled nonlinear differential equations is found that reproduce the movement of the quadruped with an approximation of more than 95%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-66562-7_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-70353-4_28,Image Classification for Ground Traversability Estimation in Robotics,Advanced Concepts for Intelligent Vision Systems,10.1007/978-3-319-70353-4_28,Springer,2017-01-01,"Mobile ground robots operating on uneven terrain must predict which areas of the environment they are able to pass in order to plan feasible paths. We cast traversability estimation as an image classification problem: we build a convolutional neural network that, given a square $$60 \times 60$$ 60 × 60 px image representing the heightmap of a small $$1.2 \times 1.2$$ 1.2 × 1.2 m patch of terrain, predicts whether the robot will be able to traverse such patch from bottom to top. The classifier is trained for a specific robot model, which may implement any locomotion type (wheeled, tracked, legged, snake-like), using simulation data on a variety of training terrains; once trained, the classifier can be quickly applied to patches extracted from unseen large heightmaps, in multiple orientations, thus building oriented traversability maps. We quantitatively validate the approach on real-elevation datasets.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-70353-4_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s40638-016-0055-x,Mobile robots exploration through cnn-based reinforcement learning,Robotics and Biomimetics,10.1186/s40638-016-0055-x,Springer,2016-12-21,"Exploration in an unknown environment is an elemental application for mobile robots. In this paper, we outlined a reinforcement learning method aiming for solving the exploration problem in a corridor environment. The learning model took the depth image from an RGB-D sensor as the only input. The feature representation of the depth image was extracted through a pre-trained convolutional-neural-networks model. Based on the recent success of deep Q-network on artificial intelligence, the robot controller achieved the exploration and obstacle avoidance abilities in several different simulated environments. It is the first time that the reinforcement learning is used to build an exploration strategy for mobile robots through raw sensor information.",https://www.biomedcentral.com/openurl?doi=10.1186/s40638-016-0055-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.3103/S0146411616080319,Detection of anomalous behavior in a robot system based on deep learning elements,Automatic Control and Computer Sciences,10.3103/S0146411616080319,Springer,2016-12-01,"The preprocessing procedure for anomalous behavior of robot system elements is proposed in the paper. It uses a special kind of a neural network called an autoencoder to solve two problems. The first problem is to decrease the dimensionality of the training data using the autoencoder to calculate the Mahalanobis distance, which can be viewed as one of the best metrics to detect the anomalous behavior of robots or sensors in the robot systems. The second problem is to apply the autoencoder to transfer learning. The autoencoder is trained by means of the target data which corresponds to the extreme operational conditions of the robot system. The source data containing the normal and anomalous observations derived from the normal operation conditions is reconstructed to the target data using the trained autoencoder. The reconstructed source data is used to define a optimal threshold for making decision on the anomaly of the observation based on the Mahalanobis distance.",http://link.springer.com/openurl/fulltext?id=doi:10.3103/S0146411616080319,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11023-016-9405-2,Dynamics of Perceptible Agency: The Case of Social Robots,Minds and Machines,10.1007/s11023-016-9405-2,Springer,2016-12-01,"How do we perceive the agency of others? Do the same rules apply when interacting with others who are radically different from ourselves, like other species or robots? We typically perceive other people and animals through their embodied behavior, as they dynamically engage various aspects of their affordance field. In second personal perception we also perceive social or interactional affordances of others. I discuss various aspects of perceptible agency, which might begin to give us some tools to understand interactions also with agents truly other than ourselves or “perhaps agents” like present and future social robots. Robots have various kinds of physical and behavioral presence and thus make their agency—if we want to call it that—perceptible in ways that computers and other forms of AI do not. The largely dualist assumptions pertaining to the hidden bodies of traditional Turing tests are discussed, as well as the social affordance effects of such indirect interactions as opposed to interactions in physically shared space. The question is what role various abilities to reveal, hide and dynamically control the body and broader behavior plays in heterogeneous tech or machine mediated interactions. I argue that the specifics and richness of perceptible agency matters to the kind of reciprocity we can obtain.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11023-016-9405-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-016-0788-9,XCS-based reinforcement learning algorithm for motion planning of a spherical mobile robot,Applied Intelligence,10.1007/s10489-016-0788-9,Springer,2016-10-01,"A Reinforcement Learning (RL) algorithm based on eXtended Classifier System (XCS) is used to navigate a spherical robot. Traditional motion planning strategies rely on pre-planned optimal trajectories and feedback control techniques. The proposed learning agent approach enjoys a direct model-free methodology that enables the robot to function in dynamic and/or partially observable environments. The agent uses a set of guard-action rules that determines the motion inputs at each step. Using a number of control inputs (actions) and the developed RL scheme, the agent learns to make near-optimal moves in response to the incoming position/orientation signals. The proposed method employs an improved variant of the XCS as its learning agent. Results of several simulated experiments for the spherical robot show that this approach is capable of planning a near-optimal path to a predefined target from any given position/orientation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-016-0788-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-016-0443-y,Looking Back on 20 Years of RoboCup,KI - Künstliche Intelligenz,10.1007/s13218-016-0443-y,Springer,2016-10-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-016-0443-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11071-016-2910-2,Distributed consensus-based formation control for nonholonomic wheeled mobile robots using adaptive neural network,Nonlinear Dynamics,10.1007/s11071-016-2910-2,Springer,2016-10-01,"This paper investigates the distributed formation control problem for multiple nonholonomic wheeled mobile robots. A variable transformation is first proposed to convert the formation control problem into a state consensus problem. Then, when the dynamics of the mobile robots are considered, the distributed kinematic controllers and neural network torque controllers are derived for each robot such that a group of nonholonomic mobile robots asymptotically converge to a desired geometric pattern along the specified reference trajectory. The specified reference trajectory is assumed to be the trajectory of a virtual leader whose information is available to only a subset of the followers. Also the followers are assumed to have only local interaction. Moreover, the neural network torque controllers proposed in this work can tackle the dynamics of robots with unmodeled bounded disturbances and unstructured unmodeled dynamics. Some sufficient conditions are derived for accomplish the asymptotically stability of the systems based on algebraic graph theory, matrix theory, and Lyapunov control approach. Finally, simulation examples illustrate the effectiveness of the proposed controllers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11071-016-2910-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-015-0423-7,AI and Robotics: RoboCup Evolution,KI - Künstliche Intelligenz,10.1007/s13218-015-0423-7,Springer,2016-10-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-015-0423-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-016-0450-z,Full-Body Motion Planning for Humanoid Robots using Rapidly Exploring Random Trees,KI - Künstliche Intelligenz,10.1007/s13218-016-0450-z,Springer,2016-10-01,"Humanoid robots with many degrees of freedom have an enormous range of possible motions. To be able to move in complex environments and dexterously manipulate objects, humanoid robots must be capable of creating and executing complex sequences of motions to accomplish their tasks. For soccer playing robots (e.g., the participants of RoboCup), the highly dynamic environment require real-time motion planning in spite of the enormous search space of possible motions. In this research, we propose a practical solution to the general movers problem in the context of motion planning for robots. The proposed robot motion planner uses a sample-based tree planner combined with an incremental simulator that models not only collisions, but also the dynamics of the motion. Thus it can ensure that the robot will be dynamically stable while executing the motion. The effectiveness of the robot motion planner is demonstrated both in simulation and on a real robot, using a variation of the Rapidly Exploring Random Tree (RRT) type of motion planner. The results of our empirical evaluation show that CONNECT works better than EXTEND versions of the RRT algorithms in simple domains, but that this advantage disappears in more obstacle-filled environments. The evaluation also shows that our motion planning system is able to find and execute complex motion plans for a small humanoid robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-016-0450-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10994-016-5580-x,Probabilistic inference for determining options in reinforcement learning,Machine Learning,10.1007/s10994-016-5580-x,Springer,2016-09-01,"Tasks that require many sequential decisions or complex solutions are hard to solve using conventional reinforcement learning algorithms. Based on the semi Markov decision process setting (SMDP) and the option framework, we propose a model which aims to alleviate these concerns. Instead of learning a single monolithic policy, the agent learns a set of simpler sub-policies as well as the initiation and termination probabilities for each of those sub-policies. While existing option learning algorithms frequently require manual specification of components such as the sub-policies, we present an algorithm which infers all relevant components of the option framework from data. Furthermore, the proposed approach is based on parametric option representations and works well in combination with current policy search methods, which are particularly well suited for continuous real-world tasks. We present results on SMDPs with discrete as well as continuous state-action spaces. The results show that the presented algorithm can combine simple sub-policies to solve complex tasks and can improve learning performance on simpler tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10994-016-5580-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11721-016-0126-1,Turing learning: a metric-free approach to inferring behavior and its application to swarms,Swarm Intelligence,10.1007/s11721-016-0126-1,Springer,2016-09-01,"We propose  Turing Learning , a novel system identification method for inferring the behavior of natural or artificial systems. Turing Learning simultaneously optimizes two populations of computer programs, one representing models of the behavior of the system under investigation, and the other representing classifiers . By observing the behavior of the system as well as the behaviors produced by the models, two sets of data samples are obtained. The classifiers are rewarded for discriminating between these two sets, that is, for correctly categorizing data samples as either genuine or counterfeit. Conversely, the models are rewarded for ‘tricking’ the classifiers into categorizing their data samples as genuine. Unlike other methods for system identification, Turing Learning does not require predefined metrics to quantify the difference between the system and its models. We present two case studies with swarms of simulated robots and prove that the underlying behaviors cannot be inferred by a metric-based system identification method. By contrast, Turing Learning infers the behaviors with high accuracy. It also produces a useful by-product—the classifiers—that can be used to detect abnormal behavior in the swarm. Moreover, we show that Turing Learning also successfully infers the behavior of physical robot swarms. The results show that collective behaviors can be directly inferred from motion trajectories of individuals in the swarm, which may have significant implications for the study of animal collectives. Furthermore, Turing Learning could prove useful whenever a behavior is not easily characterizable using metrics, making it suitable for a wide range of applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11721-016-0126-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-016-0303-8,Critical mass in the emergence of collective intelligence: a parallelized simulation of swarms in noisy environments,Artificial Life and Robotics,10.1007/s10015-016-0303-8,Springer,2016-09-01,"We extend an abstract agent-based swarming model based on the evolution of neural network controllers, to explore further the emergence of swarming. Our model is grounded in the ecological situation, in which agents can access some information from the environment about the resource location, but through a noisy channel. Swarming critically improves the efficiency of group foraging, by allowing agents to reach resource areas much more easily by correcting individual mistakes in group dynamics. As high levels of noise may make the emergence of collective behavior depend on a critical mass of agents, it is crucial to reach sufficient computing power to allow for the evolution of the whole set of dynamics in simulation. Since simulating neural controllers and information exchanges between agents are computationally intensive, to scale up simulations to model critical masses of individuals, the implementation requires careful optimization. We apply techniques from astrophysics known as treecodes to compute the signal propagation, and efficiently parallelize for multi-core architectures. Our results open up future research on signal-based emergent collective behavior as a valid collective strategy for uninformed search over a domain space.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-016-0303-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s12984-016-0172-3,Proportional estimation of finger movements from high-density surface electromyography,Journal of NeuroEngineering and Rehabilitation,10.1186/s12984-016-0172-3,BioMed Central,2016-08-04,"Background The importance to restore the hand function following an injury/disease of the nervous system led to the development of novel rehabilitation interventions. Surface electromyography can be used to create a user-driven control of a rehabilitation robot, in which the subject needs to engage actively, by using spared voluntary activation to trigger the assistance of the robot. Methods The study investigated methods for the selective estimation of individual finger movements from high-density surface electromyographic signals (HD-sEMG) with minimal interference between movements of other fingers. Regression was evaluated in online and offline control tests with nine healthy subjects (per test) using a linear discriminant analysis classifier (LDA), a common spatial patterns proportional estimator (CSP-PE), and a thresholding (THR) algorithm. In all tests, the subjects performed an isometric force tracking task guided by a moving visual marker indicating the contraction type (flexion/extension), desired activation level and the finger that should be moved. The outcome measures were mean square error (nMSE) between the reference and generated trajectories normalized to the peak-to-peak value of the reference, the classification accuracy (CA), the mean amplitude of the false activations (MAFA) and, in the offline tests only, the Pearson correlation coefficient (PCORR). Results The offline tests demonstrated that, for the reduced number of electrodes (≤24), the CSP-PE outperformed the LDA with higher precision of proportional estimation and less crosstalk between the movement classes (e.g., 8 electrodes, median MAFA ~ 0.6 vs. 1.1 %, median nMSE ~ 4.3 vs. 5.5 %). The LDA and the CSP-PE performed similarly in the online tests (median nMSE < 3.6 %, median MAFA < 0.7 %), but the CSP-PE provided a more stable performance across the tested conditions (less improvement between different sessions). Furthermore, THR, exploiting topographical information about the single finger activity from HD-sEMG, provided in many cases a regression accuracy similar to that of the pattern recognition techniques, but the performance was not consistent across subjects and fingers. Conclusions The CSP-PE is a method of choice for selective individual finger control with the limited number of electrodes (<24), whereas for the higher resolution of the recording, either method (CPS-PA or LDA) can be used with a similar performance. Despite the abundance of detection points, the simple THR showed to be significantly worse compared to both pattern recognition/regression methods. Nevertheless, THR is a simple method to apply (no training), and it could still give satisfactory performance in some subjects and/or simpler scenarios (e.g., control of selected fingers). These conclusions are important for guiding future developments towards the clinical application of the methods for individual finger control in rehabilitation robotics.",https://www.biomedcentral.com/openurl?doi=10.1186/s12984-016-0172-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-016-0364-9,Making New “New AI” Friends: Designing a Social Robot for Diabetic Children from an Embodied AI Perspective,International Journal of Social Robotics,10.1007/s12369-016-0364-9,Springer,2016-08-01,"Robin is a cognitively and motivationally autonomous affective robot toddler with “robot diabetes” that we have developed to support perceived self-efficacy and emotional wellbeing in children with diabetes. Robin provides children with positive mastery experiences of diabetes management in a playful but realistic and natural interaction context. Underlying the design of Robin is an “Embodied” (formerly also known as “New”) Artificial Intelligence (AI) approach to robotics. In this paper we discuss the rationale behind the design of Robin to meet the needs of our intended end users (both children and medical staff), and how “New AI” provides a suitable approach to developing a friendly companion that fulfills the therapeutic and affective requirements of our end users beyond other approaches commonly used in assistive robotics and child–robot interaction. Finally, we discuss how our approach permitted our robot to interact with and provide suitable experiences of diabetes management to children with very different social interaction styles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-016-0364-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11063-015-9452-3,An Evolutionary Radial Basis Function Neural Network with Robust Genetic-Based Immunecomputing for Online Tracking Control of Autonomous Robots,Neural Processing Letters,10.1007/s11063-015-9452-3,Springer,2016-08-01,This paper presents an evolutionary radial basis function neural network with genetic algorithm and artificial immune system (GAAIS-RBFNN) for tracking control of autonomous robots. Both the GAAIS-RBFNN computational intelligence and online tracking controller are implemented in one field-programmable gate array (FPGA) chip to cope with the optimal control problem of real-world mobile robotics. The hybrid GAAIS paradigm incorporated with Taguchi quality method is employed to determine the optimal structure of RBFNN. The control parameters of tracking controller are online tuned by minimizing the performance index using the proposed GAAIS-RBFNN to achieve trajectory tracking. Experimental results and comparative works are conducted to show the effectiveness and merit of the proposed FPGA-based GAAIS-RBFNN tracking controller using system-on-a-programmable-chip technology. This FPGA-based online hybrid GAAIS-RBFNN intelligent controller outperforms the existing bio-inspired RBFNN controllers using individual GA and AIS algorithms.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-015-9452-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11771-016-3257-z,Reliability-based design optimization for flexible mechanism with particle swarm optimization and advanced extremum response surface method,Journal of Central South University,10.1007/s11771-016-3257-z,Springer,2016-08-01,"To improve the computational efficiency of the reliability-based design optimization (RBDO) of flexible mechanism, particle swarm optimization-advanced extremum response surface method (PSO-AERSM) was proposed by integrating particle swarm optimization (PSO) algorithm and advanced extremum response surface method (AERSM). Firstly, the AERSM was developed and its mathematical model was established based on artificial neural network, and the PSO algorithm was investigated. And then the RBDO model of flexible mechanism was presented based on AERSM and PSO. Finally, regarding cross-sectional area as design variable, the reliability optimization of flexible mechanism was implemented subject to reliability degree and uncertainties based on the proposed approach. The optimization results show that the cross-section sizes obviously reduce by 22.96 mm^2 while keeping reliability degree. Through the comparison of methods, it is demonstrated that the AERSM holds high computational efficiency while keeping computational precision for the RBDO of flexible mechanism, and PSO algorithm minimizes the response of the objective function. The efforts of this work provide a useful sight for the reliability optimization of flexible mechanism, and enrich and develop the reliability theory as well.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11771-016-3257-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-014-0568-4,Attitude control for astronaut assisted robot in the space station,"International Journal of Control, Automation and Systems",10.1007/s12555-014-0568-4,Springer,2016-08-01,"Because of the limited working hours of astronauts in the space station, the in-cabin robot has high value in the technological validation and scientific research. Based on this requirement, we proposed and designed an Astronaut Assisted Robot(AAR) working in the space station. It can float in the space station cabin, fly autonomously, and hold a fixed position and/or posture. In addition, it also possesses environmental awareness capabilities and intelligence. Thus the AAR can assist astronauts to complete some special scientific experiments or technical tests. In this paper, the system architecture and experimental equipment of the AAR are designed firstly depending on the characteristics of space microgravity environment and the requirements of assisting astronauts missions. And then, the motion principles of the AAR are analyzed and the robot’s dynamic model is established by using the Newton - Euler algorithm. Since the attitude control of the robot is the basis for its free movement, the PID Neural Network( PIDNN) algorithm, which is a kind of intelligent control algorithm, is used to design the attitude controller of the AAR. Finally, the reasonability of the robot’s structural design and the availability of its attitude controllers are verified through the simulation experiments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-014-0568-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11071-016-2689-1,Robust adaptive position and force controller design of robot manipulator using fuzzy neural networks,Nonlinear Dynamics,10.1007/s11071-016-2689-1,Springer,2016-07-01,"This paper presents a robust adaptive position and force control scheme for an n -link robot manipulator under unknown environment. The robot manipulator’s model and the stiffness coefficient of contact environment are assumed to be not exactly known. Therefore, the traditional impedance force controller cannot be applied. We herein adopt the fuzzy neural networks (FNNs) to estimate the unknown model matrices of robot manipulator and the adaptive tracking position and force control is developed by the proposed adaptive scheme. Based on the Lyapunov stability theory, the stability of the closed-loop system and convergence of adjustable parameters are guaranteed. The corresponding update laws of FNNs’ parameters and estimated stiffness coefficient of contacting environment can be derived. Finally, simulation results of a two-link robot manipulator with environment constraint are introduced to illustrate the performance and effectiveness of our approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11071-016-2689-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-015-1688-3,Learning a robot controller using an adaptive hierarchical fuzzy rule-based system,Soft Computing,10.1007/s00500-015-1688-3,Springer,2016-07-01,"The majority of machine learning techniques applied to learning a robot controller generalise over either a uniform or pre-defined representation that is selected by a human designer. The approach taken in this paper is to reduce the reliance on the human designer by adapting the representation to improve the generalisation during the learning process. An extension of a Hierarchical Fuzzy Rule-Based System (HFRBS) is proposed that identifies and refines inaccurate regions of a fuzzy controller, while interacting with the environment, for both supervised and reinforcement learning problems. The paper shows that a controller using an adaptive HFRBS can learn a suitable control policy using a fewer number of fuzzy rules for both a supervised and reinforcement learning problem and is not sensitive to the layout as with a uniform representation. In supervised learning problems, a small number of extra trials are required to find an effective representation but for reinforcement learning problems, the process of adapting the representation is shown to significantly reduce the time taken to learn a suitable control policy and hence open the door to high-dimensional problems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-015-1688-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12541-016-0105-x,A novel adaptive finite-time tracking control for robotic manipulators using nonsingular terminal sliding mode and RBF neural networks,International Journal of Precision Engineering and Manufacturing,10.1007/s12541-016-0105-x,Springer,2016-07-01,"This paper presents a novel adaptive terminal sliding mode controller for the trajectory tracking of robotic manipulators using radial basis function neural networks (RBFNNs). First, a modified terminal sliding mode (TSM) surface is approached to avoid the singularity problem of conventional TSM. Then, a nonsingular TSM control is designed for joint position tracking of a robotic manipulator. In the control scheme, fully tuned RBFNNs are adopted to approximate the nonlinear unknown dynamics of the robotic manipulator. Adaptive learning algorithms are derived to allow online adjustment of the output weights, the centers and the variances in the RBFNNs. Meanwhile, a continuous robust control term is added to eliminate chattering efforts in the sliding mode control (SMC) system. The stability and finite-time convergence of the closed-loop system are established by using Lyapunov theory. Finally, the simulation results of a two-link robotic manipulator are presented to demonstrate the effectiveness of the proposed control method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12541-016-0105-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11071-016-2666-8,Adaptive attitude and position control of an insect-like flapping wing air vehicle,Nonlinear Dynamics,10.1007/s11071-016-2666-8,Springer,2016-07-01,"This study describes an adaptive sliding mode technique for attitude and position control of a rigid body insect-like flapping wing model in the presence of uncertainties. For this purpose, a six-degrees-of-freedom nonlinear and time-varying dynamic model of a typical hummingbird is considered for simulation studies. Based on the quasi-steady assumptions, three major aerodynamic loads including delayed stall, rotational lift and added mass are presented and analyzed, respectively. Using the averaging theory, a time-varying system is then transformed into the time-invariant system to design the adaptive controller. The controller is designed so that the closed-loop system will follow any desired trajectory without prior information about uncertainties. In the final stage, in order to find the wing kinematic parameters and to ensure the feasibility of the control commands, two feedforward artificial neural networks are developed and trained using aerodynamic forces and moments from the open-loop simulation data. In comparison with non-adaptive technique, it is shown that the adaptive sliding mode controller is able to stabilize the vehicle in the presence of input disturbances and model uncertainties.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11071-016-2666-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40593-016-0095-y,Letting Artificial Intelligence in Education Out of the Box: Educational Cobots and Smart Classrooms,International Journal of Artificial Intelligence in Education,10.1007/s40593-016-0095-y,Springer,2016-06-01,"This paper proposes that the field of AIED is now mature enough to break away from being delivered mainly through computers and pads so that it can engage with students in new ways and help teachers to teach more effectively. Mostly, the intelligent systems that AIED has delivered so far have used computers and other devices that were essentially designed for businesses or personal use, and not specifically for education. The future holds the promise of creating technologies designed specifically for learning and teaching by combining the power of AIED with advances in the field of robotics and in the increasing use of sensor devices to monitor our surroundings and actions. The paper assumes that “schools” (i.e., a place where children will gather to learn) will still exist in some shape or form in 25 years and that teachers will continue to oversee and promote learning among the students. It proposes that there will be educational cobots assisting teachers in the classrooms of tomorrow and provides examples from current work in robotics. It also envisions smart classrooms that make use of sensors to support learning and illustrates how they might be used in new ways if AIED applications are embedded into them.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40593-016-0095-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11548-015-1340-9,Erratum to: Surgical robotics beyond enhanced dexterity instrumentation: a survey of machine learning techniques and their role in intelligent and autonomous surgical actions,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-015-1340-9,Springer,2016-05-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-015-1340-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-015-0254-7,A Learning Behavior Based Controller for Maintaining Balance in Robotic Locomotion,Journal of Intelligent & Robotic Systems,10.1007/s10846-015-0254-7,Springer,2016-05-01,"The Behavior Based Locomotion Controller (BBLC) extends the applicability of the behavior based control (BBC) architecture to redundant systems with multiple task-space motions. A set of control behaviors are attributed to each task-space motion individually and a reinforcement learning algorithm is used to select the combination of behaviors which can achieve the control objective. The resulting behavior combination is an emergent control behavior robust to unknown environments due to the added learning capability. Hence, the BBLC is applicable to complex redundant systems operating in unknown environments, where the emergent control behaviors can satisfy higher level control objectives such as balance in locomotion. The balance control problem of two robotic systems, a bipedal robot walker and a mobile manipulator, are used to study the performance of this controller. Results show that the BBLC strategy can generate emergent balancing strategies capable of adapting to new unknown disturbances from the environment, using only a small fixed library of balancing behaviors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-015-0254-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-015-0637-0,"Human, machines, and the interpretation of formal systems",AI & SOCIETY,10.1007/s00146-015-0637-0,Springer,2016-05-01,"There are plenty of intelligent machines in our world today: digital computers and autonomous robots. At the heart of each of these machines there are automatic formal systems (programs running on a digital computer). Now, if the interpretation of a formal system does not belong to the formal system itself, if the interpretation has to be added, it is worth asking: in the case of these intelligent machines that are massively interspersed in our social interactions, where does the interpretation come from? In this paper, we analyse what we call the invisibility of interpretation. Dealing with various types of formal systems (computers, robots, formalist approaches to Economics), the human source of the interpretation of these systems is sometimes concealed by a formalist restriction. To show how the formalist restriction produces the invisibility of interpretation allows us to underline our responsibility, as human agents, for all this interpretative work—and its importance for us as human beings.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-015-0637-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-014-0273-3,Strategies for feet massage robot to position the pelma acupoints with model predictive and real-time optimization,"International Journal of Control, Automation and Systems",10.1007/s12555-014-0273-3,Springer,2016-04-01,"It is one of critical factors for a massage robot to find and position the acupuncture point precisely in order to cure the diseases. Based on large amount of sample data offline, Chinese medical empirical knowledge is also introduced to build the prediction model. The massagist prescription and the robot mechanism devise are both considered for robot positioning. Least squares method is of simplicity, easy to use and high efficiency. Its real-time calculation is very effective, too. A modeling method for robot positioning is proposed based on least squares. Knowledge consultation is set for the calculation of acupoint position. The robot needs to get the feature points of a foot to be massaged. The foot contour sampling data are divided into piecewise curve fitting. Qlearning is adopted to optimize the robot positioning for they are model free. CMAC (Cerebellar Model Articulation Controller) cerebellum model is incorporated into the function approximation of Q learning. The learning system is rewarded by referring to the strengths of instrumental signal. By the direct representation, the model of human pelma acupoint is expressed with the vector variables and formal computer language. Through prediction model’s calculation, the robot will work out the rough position of acupuncture point. Meanwhile, Q learning does the online adjustment for accurate location. These strategies provide for the robot to automatically search and position the pelma acupoint with little real-time computation and storage. The idea of this paper also prompts a research cue for the development of Chinese medical standardization.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-014-0273-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11760-015-0805-1,"Real-time, automatic shape-changing robot adjustment and gender classification","Signal, Image and Video Processing",10.1007/s11760-015-0805-1,Springer,2016-04-01,"This paper introduces the results of novel theoretical and practical studies aimed at providing automatic and accurate real-time activation and adjustment of shape-changing robots in accord to the shape of the body of the user. The proposed method consists of scanning, classifying the instances according to gender and size, performing analysis on both the user’s body and the prospective garment, which is be virtually fitted, modelling, extracting measurements and assigning reference points on them, segmenting the 3D visual data imported from the shape-changing robot, and finally, superimposing, adopting and depicting the resulting garment model on the user’s body. The estimation process of the positions of the moving actuators for adjusting the shape-changing robots tries to determine which input values could result in the closest representation of the desired sizes and distances through devising the mathematical description of a map relating them to each other. In order to classify the data obtained by the 3D scanner, first maximum likelihood function is used for selecting one of the shape-changing robots, according to the presumed gender and size, to be activated, and subsequently, support vector machine is utilized so as to find out which shape template from the dictionary best matches the scanning instance being considered. As a use case, the proposed method is applied to the visual data obtained by scanning Fits.me’s shape-changing robots using 3D laser scanner. The methods currently used are manual, whereas the proposed method is automatic and the experimental results show that it is the accurate and reliable.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11760-015-0805-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11548-015-1305-z,Surgical robotics beyond enhanced dexterity instrumentation: a survey of machine learning techniques and their role in intelligent and autonomous surgical actions,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-015-1305-z,Springer,2016-04-01,"Purpose Advances in technology and computing play an increasingly important role in the evolution of modern surgical techniques and paradigms. This article reviews the current role of machine learning (ML) techniques in the context of surgery with a focus on surgical robotics (SR). Also, we provide a perspective on the future possibilities for enhancing the effectiveness of procedures by integrating ML in the operating room. Methods The review is focused on ML techniques directly applied to surgery, surgical robotics, surgical training and assessment. The widespread use of ML methods in diagnosis and medical image computing is beyond the scope of the review. Searches were performed on PubMed and IEEE Explore using combinations of keywords: ML, surgery, robotics, surgical and medical robotics, skill learning, skill analysis and learning to perceive. Results Studies making use of ML methods in the context of surgery are increasingly being reported. In particular, there is an increasing interest in using ML for developing tools to understand and model surgical skill and competence or to extract surgical workflow. Many researchers begin to integrate this understanding into the control of recent surgical robots and devices. Conclusion ML is an expanding field. It is popular as it allows efficient processing of vast amounts of data for interpreting and real-time decision making. Already widely used in imaging and diagnosis, it is believed that ML will also play an important role in surgery and interventional treatments. In particular, ML could become a game changer into the conception of cognitive surgical robots . Such robots endowed with cognitive skills would assist the surgical team also on a cognitive level, such as possibly lowering the mental load of the team. For example, ML could help extracting surgical skill, learned through demonstration by human experts, and could transfer this to robotic skills. Such intelligent surgical assistance would significantly surpass the state of the art in surgical robotics. Current devices possess no intelligence whatsoever and are merely advanced and expensive instruments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-015-1305-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11063-015-9435-4,Editorial: Neural Processing Letters Special Issue on “Neural Networks for Vision and Robotics” ,Neural Processing Letters,10.1007/s11063-015-9435-4,Springer,2016-04-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-015-9435-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11063-015-9426-5,Introducing Synaptic Delays in the NEAT Algorithm to Improve Modelling in Cognitive Robotics,Neural Processing Letters,10.1007/s11063-015-9426-5,Springer,2016-04-01,"This paper describes and tests an approach to improve the temporal processing capabilities of the neuroevolution of augmenting topologies (NEAT) algorithm. This algorithm is quite popular within the robotics community for the production of trained neural networks without having to determine a priori their size and topology. The main drawback of the traditional NEAT algorithm is that, even though it can implement recurrent synaptic connections, which allow it to perform some time related processing tasks, its capabilities are rather limited, especially when dealing with precise time dependent phenomena. NEAT’s ability to capture the underlying dynamics that correspond to complex time series still has a lot of room for improvement. To address this issue, the paper describes a new implementation of the NEAT algorithm that is able to generate artificial neural networks (ANNs) with trainable time delayed synapses in addition to its previous capacities. We show that this approach, called $$\uptau $$ τ -NEAT improves the behavior of the neural networks obtained when dealing with complex time related processes. Several examples are presented, both dealing with the generation of ANNs that are able to produce complex theoretical signals such as chaotic signals or real data series, as in the case of the monthly number of international airline passengers or monthly $$\hbox {CO}_{2}$$ CO 2 concentrations. In these examples, $$\uptau $$ τ -NEAT clearly improves over the traditional NEAT algorithm in these tasks. A final example of the integration of this approach within a robot cognitive mechanism is also presented, showing the clear improvements it could provide in the modeling required for many cognitive processes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-015-9426-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-015-0258-1,Reinforcement learning in dynamic environment: abstraction of state-action space utilizing properties of the robot body and environment,Artificial Life and Robotics,10.1007/s10015-015-0258-1,Springer,2016-03-01,"In this paper, we address the autonomous control of a 3D snake-like robot through the use of reinforcement learning, and we apply it in a dynamic environment. In general, snake-like robots have high mobility that is realized by many degrees of freedom, and they can move over dynamically shifting environments such as rubble. However, this freedom and flexibility leads to a state explosion problem, and the complexity of the dynamic environment leads to incomplete learning by the robot. To solve these problems, we focus on the properties of the actual operating environment and the dynamics of a mechanical body. We design the body of the robot so that it can abstract small, but necessary state-action space by utilizing these properties, and we make it possible to apply reinforcement learning. To demonstrate the effectiveness of the proposed snake-like robot, we conduct experiments; from the experimental results we conclude that learning is completed within a reasonable time, and that effective behaviors for the robot to adapt itself to an unknown 3D dynamic environment were realized.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-015-0258-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-015-0260-7,EM-based policy hyper parameter exploration: application to standing and balancing of a two-wheeled smartphone robot,Artificial Life and Robotics,10.1007/s10015-015-0260-7,Springer,2016-03-01,"This paper proposes a novel policy search algorithm called EM-based Policy Hyper Parameter Exploration (EPHE) which integrates two reinforcement learning algorithms: Policy Gradient with Parameter Exploration (PGPE) and EM-based Reward-Weighted Regression. Like PGPE, EPHE evaluates a deterministic policy in each episode with the policy parameters sampled from a prior distribution given by the policy hyper parameters (mean and variance). Based on EM-based Reward-Weighted Regression, the policy hyper parameters are updated by reward-weighted averaging so that gradient calculation and tuning of the learning rate are not required. The proposed method is tested in the benchmarks of pendulum swing-up task, cart-pole balancing task and simulation of standing and balancing of a two-wheeled smartphone robot. Experimental results show that EPHE can achieve efficient learning without learning rate tuning even for a task with discontinuities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-015-0260-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-015-9523-3,Knowledge-enabled parameterization of whole-body control strategies for compliant service robots,Autonomous Robots,10.1007/s10514-015-9523-3,Springer,2016-03-01,"Compliant manipulation is one of the grand challenges for autonomous robots. Many household chores in human environments, such as cleaning the floor or wiping windows, rely on this principle. At the same time these tasks often require whole-body motions to cover a larger workspace. The performance of the actual task itself is thereby dependent on a large number of parameters that have to be taken into account. To tackle this issue we propose to utilize low-level compliant whole-body control strategies parameterized by high-level hybrid reasoning mechanisms. We categorize compliant wiping actions in order to determine relevant control parameters. According to these parameters we set up process models for each identified wiping action and implement generalized control strategies based on human task knowledge. We evaluate our approach experimentally on three whole-body manipulation tasks, namely scrubbing a mug with a sponge, skimming a window with a window wiper and bi-manually collecting the shards of a broken mug with a broom.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-015-9523-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-015-1873-4,Adaptive trajectory tracking neural network control with robust compensator for robot manipulators,Neural Computing and Applications,10.1007/s00521-015-1873-4,Springer,2016-02-01,"This paper presents an adaptive trajectory tracking neural network control using radial basis function (RBF) for an n -link robot manipulator with robust compensator to achieve the high-precision position tracking. One of the difficulties in designing a suitable control scheme which can achieve accurate trajectory tracking and good control performance is to guarantee the stability and robustness of control system, due to friction forces, external disturbances error, and parameter variations. To deal with this problem, the RBF network is investigated to the joint position control of an n -link robot manipulator. The RBF network is one approach which has shown a great promise in this sort of problems because of its fast learning algorithm and better approximation capabilities. The adaptive RBF network can effectively improve the control performance against large uncertainty of the system. The adaptive turning laws of network parameters are derived using the back-propagation algorithm and the Lyapunov stability theorem, so that the stability of the entire system and the convergence of the weight adaptation are guaranteed. In this control scheme, a robust compensator plays as an auxiliary controller to guarantee the stability and robustness under various environments such as the mass variation, the external disturbances, and modeling uncertainties. Finally, the simulation and experimental results in comparison with adaptive fuzzy and wavelet network control method are provided to verify the effectiveness of the proposed control methodology.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-015-1873-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-46131-1_33,Practical Bayesian Inverse Reinforcement Learning for Robot Navigation,Machine Learning and Knowledge Discovery in Databases,10.1007/978-3-319-46131-1_33,Springer,2016-01-01,"Inverse reinforcement learning (irl) provides a concise framework for learning behaviors from human demonstrations; and is highly desired in practical and difficult to specify tasks such as normative robot navigation. However, most existing irl algorithms are often ladened with practical challenges such as representation mismatch and poor scalability when deployed in real world tasks. Moreover, standard reinforcement learning (rl) representations often do not allow for incorporation of task constraints common for example in robot navigation. In this paper, we present an approach that tackles these challenges in a unified manner and delivers a learning setup that is both practical and scalable. We develop a graph-based spare representation for rl and a scalable irl algorithm based on sampled trajectories. Experimental evaluation in simulation and from a real deployment in a busy airport demonstrate the strengths of the learning setup over existing approaches.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-46131-1_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-1-4939-3474-4_126,Modeling Neuronal Systems,Neuroscience in the 21st Century,10.1007/978-1-4939-3474-4_126,Springer,2016-01-01,"This chapter provides a summary of current approaches to modeling neuronal systems at the levels of single cells, networks, and more complex multinetwork systems. It begins with a brief history describing how models based on neurophysiological data diverged from artificial intelligence research and became increasingly sophisticated as available computational power increased. It is shown how, in order to make simulation of large network systems practical, models based on detailed ion channel properties can be replaced by increasingly simple “integrate-and-fire” models, “rate-coded” models that do not instantiate individual neuronal action potential spikes, and even ensemble models that provide statistical summaries of the activity of masses of neurons. Event-driven models that reduce the need to perform routine membrane-potential decay calculations at small time intervals are discussed. Models for synaptic modification presumed to be involved in learning are described for both rate-coded and spiking neuron models. The chapter ends with some discussion of nervous system aspects that are often omitted from models and which may form suitable bases for future research, as well as pitfalls that need to be avoided by newcomers to this field.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4939-3474-4_126,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-07052-0_27,Co-Robots: Humans and Robots Operating as Partners,Handbook of Science and Technology Convergence,10.1007/978-3-319-07052-0_27,Springer,2016-01-01,"A new era of robotics research is being driven by pressing societal problems and creating a transformation in the way that we envision human-robot interactions. In this chapter, we discuss three application domains that best capture both the promise and the challenges that this transformation has generated: the effort to build robots that support cognitive and social growth, robots that work in the home doing domestic tasks for users that have no training in robotics, and collaborative robots that work side-by-side to solve manufacturing and assembly tasks with human workers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-07052-0_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-30933-0_49,Gradient Descent with Momentum Based Backpropagation Neural Network for Selection of Industrial Robot,Proceedings of First International Conference on Information and Communication Technology for Intelligent Systems: Volume 1,10.1007/978-3-319-30933-0_49,Springer,2016-01-01,"Fast development of industrial robots and its utilization by the manufacturing industries for many different applications is a critical task for the selection of robots. As a consequence, the selection process of the robot becomes very much complicated for the potential users because they have an extensive set of parameters of the available robots. In this paper, gradient descent momentum optimization algorithm is used with backpropagation neural network prediction technique for the selection of industrial robots. Through this proposed technique maximum, ten parameters are directly considered as an input for the selection process of robot where as up to seven robot parameter data be used in the existing methods. The rank of the preferred industrial robot evaluates from the perfectly the best probable robot that specifies the most genuine benchmark of robot selection for the particular application using the proposed algorithm. Moreover, the performance of the algorithms for the robot selection is analyzed using Mean Square Error (MSE), R-squared error (RSE), and Root Mean Square Error (RMSE).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-30933-0_49,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-30298-0_6,Optimized Neural Network Sliding Mode Control for Two Links Robot Using PSO Technique,Proceedings of the Mediterranean Conference on Information & Communication Technologies 2015,10.1007/978-3-319-30298-0_6,Springer,2016-01-01,"This work presents the neural network combined with the sliding mode control (NNSMC) to design a robust controller for the two-links robot system. Sliding mode control (SMC) is well known for its robustness and efficiency to deal with a wide range of control problems with nonlinear dynamics. However, for complex nonlinear systems, the uncertainties are large and produce higher amplitude of chattering due to the higher switching gain. In order to reduce this gain, neural network (NN) is used to estimate the uncertain parts of the system plant with on-line training using backpropagation (BP) algorithm. The learning rate is one of the parameters of BP algorithm which have a significant influence on results. Particle swarm optimization (PSO) algorithm with global search capabilities is used in this study to optimize this parameter in order to improve the network performance in term of the speed of convergence. The performance of the proposed approach is investigated in simulations and the control action used did not exhibit any chattering behavior.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-30298-0_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-47247-8_14,Humanoid Robot Gait on Sloping Floors Using Reinforcement Learning,Robotics,10.1007/978-3-319-47247-8_14,Springer,2016-01-01,"Climbing ramps is an important ability for humanoid robots: ramps exist everywhere in the world, such as in accessibility ramps and building entrances. This works proposes the use of Reinforcement Learning to learn the action policy that will make a robot walk in an upright position, in a lightly sloped terrain. The proposed architecture of our system is a two-layer combination of the traditional gait generation control loop with a reinforcement learning component. This allows the use of an accelerometer to generate a correction for the gait, when the slope of the floor where the robot is walking changes. Experiments performed on a real robot showed that the proposed architecture is a good solution for the stability problem.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-47247-8_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-27149-1_19,Analyzing the Relevance of Features for a Social Navigation Task,Robot 2015: Second Iberian Robotics Conference,10.1007/978-3-319-27149-1_19,Springer,2016-01-01,"Robot navigation in human environments is an active research area that poses serious challenges in both robot perception and actuation. Among them, social navigation and human-awareness have gained lot of attention in the last years due to its important role in human safety and robot acceptance. Several approaches have been proposed; learning by demonstrations stands as one of the most used approaches for estimating the insights of human social interactions. However, typically the features used to model the person-robot interaction are assumed to be given. It is very usual to consider general features like robot velocity, acceleration or distance to the persons, but there are not studies on the criteria used for such features selection. In this paper, we employ a supervised learning approach to analyze the most important features that might take part into the human-robot interaction during a robot social navigation task. To this end, different subsets of features are employed with an AdaBoost classifier and its classification accuracy is compared with that of humans in a social navigation experimental setup. The analysis shows how it is very important not only to consider the robot-person relative poses and velocities, but also to recognize the particular social situation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-27149-1_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-81-322-2656-7_52,Robotic Imitation of Human Hand Using RGB Color Gradient Mapping,Artificial Intelligence and Evolutionary Computations in Engineering Systems,10.1007/978-81-322-2656-7_52,Springer,2016-01-01,"The state-of-the-art developments in robotics reveal a scenario wherein human motion imitation has been developed through advancements in features and performance of sensors. Most of such robots uses flex sensors to acquire the information about the orientation of the body being imitated. However, these are slow and are highly vulnerable to damages and physical changes. There are image processing algorithms that are focused on a robots learning through ANN and are not into imitation without memory. This paper presents an overview of research attempts to use a robotic assembly to imitate a real object using image processing. The paper describes results in force, tactile and visual sensing, sensor-based control, and the configuration of a test-based robot integrated system for imitation of a human hand, using vision through image processing using RGB scheme; and one-on-one mapping for the acquisition of the current position of a body and orientation of the various parts of the robot in same fashion. This research has resulted in the development of a prototype capable of imitation and its applications are in the areas of medicine, defense, safety, and explorations for both research and commercial applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-81-322-2656-7_52,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-32967-3_2,The Dawn of the Conversational Interface,The Conversational Interface,10.1007/978-3-319-32967-3_2,Springer,2016-01-01,"With a conversational interface, people can speak to their smartphones and other smart devices in a natural way in order to obtain information, access Web services, issue commands, and engage in general chat. This chapter presents some examples of conversational interfaces and reviews technological advances that have made conversational interfaces possible. Following this, there is an overview of the technologies that make up a conversational interface.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-32967-3_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-26485-1_29,Heideggerian AI and the Being of Robots,Fundamental Issues of Artificial Intelligence,10.1007/978-3-319-26485-1_29,Springer,2016-01-01,"Current Heideggerian AI (HAI) is the attempt to revise the fundamentals of Artificial Intelligence based on Heidegger’s philosophy. While the debate is much monopolized with questions regarding the role of representations, there is overall agreement that HAI should be conceived to foster development of AI techniques, on the assumption that Heidegger’s ontological analysis of humans (Dasein) should apply to artificial systems. We argue this is inconsistent with Heidegger’s philosophy, as it denies ontological meaning to categories such as robot and human, considered the same type of beings. The aim of this paper is to steer HAI towards the question of our pre-ontological notions of artificial systems, and robots in particular. We present a provisional ontological analysis that considers robots specific, non-human and non-animal beings, which we derive from the relationship between robots and work. Robots are those machines that perform human labour – because in practice they can only transform it, their being is one that cannot be fulfilled.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-26485-1_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-1-4899-7502-7_738-1,Robot Learning,Encyclopedia of Machine Learning and Data Mining,10.1007/978-1-4899-7502-7_738-1,Springer,2016-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4899-7502-7_738-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-81-322-2740-3_53,Stabilization of Posture of Humanoid Using PID Controller in Gazebo Simulator Using Robot Operating System (ROS),"CAD/CAM, Robotics and Factories of the Future",10.1007/978-81-322-2740-3_53,Springer,2016-01-01,This paper presents an ongoing work for developing a simulation setup for testing gait algorithm for a humanoid robot. An open source simulator GAZEBO has been chosen for easy adoption by researchers. A model of humanoid robot has been built in Gazebo. A PID controller has been implemented using Ziegler Nichols tuning technique on the humanoid model for stabilizing the posture on the behalf of implementation of Reinforcement Learning based gait algorithm. The PID controller is written in Robot Operating System (ROS) and has been interfaced with the GAZEBO simulator.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-81-322-2740-3_53,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-43488-9_9,Artificial Neural Network Based Compliant Control for Robot Arms,From Animals to Animats 14,10.1007/978-3-319-43488-9_9,Springer,2016-01-01,"The aim of this paper is to present an artificial neural network (ANN) based adaptive nonlinear control approach of a robot arm, with highlight on its capability as a compliant control scheme. The approach is based on a computed torque law and consists of two main components: a feedforward controller (approximated by the ANN) and a proportional-derivative (PD) feedback loop. Here, the feedforward controller is used to approximate the nonlinear system dynamics and can also adapt to the long-term dynamics of the arm while the PD feedback loop can be tuned to obtain proper compliant behaviour to deal with instantaneous disturbances (e.g., collisions). The employed controller structure makes it possible to decouple these two components for individual parameter adjustments. The performance of the control approach is evaluated and demonstrated in physical simulation which shows promising results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-43488-9_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-47437-3_6,User Evaluation of an Interactive Learning Framework for Single-Arm and Dual-Arm Robots,Social Robotics,10.1007/978-3-319-47437-3_6,Springer,2016-01-01,"Social robots are expected to adapt to their users and, like their human counterparts, learn from the interaction. In our previous work, we proposed an interactive learning framework that enables a user to intervene and modify a segment of the robot arm trajectory. The framework uses gesture teleoperation and reinforcement learning to learn new motions. In the current work, we compared the user experience with the proposed framework implemented on the single-arm and dual-arm Barrett’s 7-DOF WAM robots equipped with a Microsoft Kinect camera for user tracking and gesture recognition. User performance and workload were measured in a series of trials with two groups of 6 participants using two robot settings in different order for counterbalancing. The experimental results showed that, for the same task, users required less time and produced shorter robot trajectories with the single-arm robot than with the dual-arm robot. The results also showed that the users who performed the task with the single-arm robot first experienced considerably less workload in performing the task with the dual-arm robot while achieving a higher task success rate in a shorter time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-47437-3_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-41009-8_57,Robot Indoor Navigation Based on Computer Vision and Machine Learning,Advances in Swarm Intelligence,10.1007/978-3-319-41009-8_57,Springer,2016-01-01,"Autonomous navigation, as a fundamental problem of intelligent mobile robots’ research, is the key technology of mobile robot to realize autonomous and intelligent. A method of combing computer vision and machine learning for the problem of robot indoor navigation is proposed in the paper. It realizes robot autonomous navigation through imitating the behavior of experts. Through a camera to perceive environmental information, expert provides some examples of navigation for robot to learn and robot learns a control strategy based on these samples using imitation learning algorithm. When robot is running, the control strategy learned can infer a corresponding control command based on the current perception of environmental information. Therefore, robot is able to mimic the behavior of expert to navigate autonomously.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-41009-8_57,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-44781-0_5,Deep Learning for Emotion Recognition in Faces,Artificial Neural Networks and Machine Learning – ICANN 2016,10.1007/978-3-319-44781-0_5,Springer,2016-01-01,"Deep Learning (DL) has shown real promise for the classification efficiency for emotion recognition problems. In this paper we present experimental results for a deeply-trained model for emotion recognition through the use of facial expression images. We explore two Convolutional Neural Network (CNN) architectures that offer automatic feature extraction and representation, followed by fully connected softmax layers to classify images into seven emotions. The first architecture explores the impact of reducing the number of deep learning layers and the second splits the input images horizontally into two streams based on eye and mouth positions. The first proposed architecture produces state of the art results with an accuracy rate of 96.93 % and the second architecture with split input produces an average accuracy rate of 86.73 %, respectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-44781-0_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-42297-8_50,Fuzzy Neural Sliding Mode Control for Robot Manipulator,Intelligent Computing Methodologies,10.1007/978-3-319-42297-8_50,Springer,2016-01-01,"A fuzzy neural sliding mode controller (FNNSMC) is proposed for robot manipulators. Sliding mode controller is implemented based on two radial basic function neural networks and a fuzzy system. The first neural network is used to estimate the robot dynamic function. The second neural network combines with a fuzzy system to present the switching control term of sliding mode control. This combination resolves the chattering phenomenon. The stability of proposed controller is proven. Finally, simulation is done on a 2-link serial robot manipulator to verify the effectiveness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-42297-8_50,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-47437-3_4,A Framework for Modelling Local Human-Robot Interactions Based on Unsupervised Learning,Social Robotics,10.1007/978-3-319-47437-3_4,Springer,2016-01-01,"This paper addresses the problem of teaching a robot interaction behaviors using the imitation learning paradigm. Particularly, the approach makes use of Gaussian Mixture Models (GMMs) to model the physical interaction of the robot and the person when the robot is teleoperated or guided by an expert. The learned models are integrated into a sample-based planner, an RRT*, at two levels: as a cost function in order to plan trajectories considering behavior constraints, and as configuration space sampling bias to discard samples with low cost according to the behaviors. The algorithm is successfully tested in the laboratory using an actual robot and real trajectories examples provided by an expert.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-47437-3_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-41009-8_49,Control Nonholonomic Mobile Robot with Hybrid Sliding Mode/Neuro Fuzzy Controller,Advances in Swarm Intelligence,10.1007/978-3-319-41009-8_49,Springer,2016-01-01,"Many works has been done in the mobile robots research domain, resulting different methods to enhance the performance of the mobile robot. This article will adopt a hybrid approach to improve the performance of a path tracking controller by designing an algorithm that uses two methods: the first one is Sliding Mode [SM], which will have one of its parameters controlled by the second one based on neurofuzzy [NF].",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-41009-8_49,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-44778-0_40,Dynamical Linking of Positive and Negative Sentences to Goal-Oriented Robot Behavior by Hierarchical RNN,Artificial Neural Networks and Machine Learning – ICANN 2016,10.1007/978-3-319-44778-0_40,Springer,2016-01-01,"Meanings of language expressions are constructed not only from words grounded in real-world matters, but also from words such as “not” that participate in the construction by working as logical operators. This study proposes a connectionist method for learning and internally representing functions that deal with both of these word groups, and grounding sentences constructed from them in corresponding behaviors just by experiencing raw sequential data of an imposed task. In the experiment, a robot implemented with a recurrent neural network is required to ground imperative positive and negative sentences given as a sequence of words in corresponding goal-oriented behavior. Analysis of the internal representations reveals that the network fulfilled the requirement by extracting XOR problems implicitly included in the target sequences and solving them by learning to represent the logical operations in its nonlinear dynamics in a self-organizing manner.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-44778-0_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-31056-5_5,Social Development of Artificial Cognition,Toward Robotic Socially Believable Behaving Systems - Volume I,10.1007/978-3-319-31056-5_5,Springer,2016-01-01,"Recent Adams, Samantha years Morse, Anthony have Di Nuovo, Alessandro seen Belpaeme, Tony a growing Cangelosi, Angelo interest De Greeff, Joachim in applying insights from developmental psychology to build artificial intelligence and robotic systems. This endeavour, called developmental robotics, not only is a novel method of creating artificially intelligent systems, but also offers a new perspective on the development of human cognition. While once cognition was thought to be the product of the embodied brain, we now know that natural and artificial cognition results from the interplay between an adaptive brain, a growing body, the physical environment and a responsive social environment. This chapter gives three examples of how humanoid robots are used to unveil aspects of development, and how we can use development and learning to build better robots. We focus on the domains of word-meaning acquisition, abstract concept acquisition and number acquisition, and show that cognition needs embodiment and a social environment to develop. In addition, we argue that Spiking Neural Networks offer great potential for the implementation of artificial cognition on robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-31056-5_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-26230-7_10,Evolutionary Function Approximation for Gait Generation on Legged Robots,Nature-Inspired Computing for Control Systems,10.1007/978-3-319-26230-7_10,Springer,2016-01-01,"Reinforcement learning methods can be computationally expensive. Their cost is prone to be higher when the cardinality of the state space representation becomes larger. This curse of dimensionality plays an important role on our work, since gait generation by using more degrees of freedom at each leg, implies a bigger state space after discretization, and look-up tables become impractical. Thus, appropriate function approximators are needed for such kind of tasks on robotics. This chapter shows the advantage of using reinforcement learning, specifically within the batch framework. A neuroevolution of augmenting topologies scheme is used as function approximator, a particular case of a topology and weight evolving artificial neural network which has proved to outperform a fixed-topology network for certain tasks. A comparison between function approximators within the batch reinforcement learning approach is tested on a simulated version of an hexapod robot designed and already built at our undergraduate and graduate students group.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-26230-7_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-47437-3_2,Adaptive Robot Assisted Therapy Using Interactive Reinforcement Learning,Social Robotics,10.1007/978-3-319-47437-3_2,Springer,2016-01-01,"In this paper, we present an interactive learning and adaptation framework that facilitates the adaptation of an interactive agent to a new user. We argue that Interactive Reinforcement Learning methods can be utilized and integrated to the adaptation mechanism, enabling the agent to refine its learned policy in order to cope with different users. We illustrate our framework with a use case in the domain of Robot Assisted Therapy. We present our results of the learning and adaptation experiments against different simulated users, showing the motivation of our work and discussing future directions towards the definition and implementation of our proposed framework.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-47437-3_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-32552-1_74,Learning from Humans,Springer Handbook of Robotics,10.1007/978-3-319-32552-1_74,Springer,2016-01-01,"This chapter surveys the main approaches developed to date to endow robots with the ability to learn from human guidance. The field is best known as robot programming by demonstration, robot learning from/by demonstration, apprenticeship learning and imitation learning. We start with a brief historical overview of the field. We then summarize the various approaches taken to solve four main questions: when, what, who and when to imitate. We emphasize the importance of choosing well the interface and the channels used to convey the demonstrations, with an eye on interfaces providing force control and force feedback. We then review algorithmic approaches to model skills individually and as a compound and algorithms that combine learning from human guidance with reinforcement learning. We close with a look on the use of language to guide teaching and a list of open issues.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-32552-1_74,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-43488-9_28,Adaptive Combinatorial Neural Control for Robust Locomotion of a Biped Robot,From Animals to Animats 14,10.1007/978-3-319-43488-9_28,Springer,2016-01-01,"Humans can perform natural and robust walking behavior. They can even quickly adapt to different situations, like changing their walking speed to synchronize with the speed of a treadmill. Reproducing such complex abilities with artificial bipedal systems is still a difficult problem. To tackle this problem, we present here an adaptive combinatorial neural control circuit consisting of reflex-based and central pattern generator (CPG)-based mechanisms. The reflex-based control mechanism basically generates energy-efficient bipedal locomotion while the CPG-based mechanism with synaptic plasticity ensures robustness against loss of global sensory feedback (e.g., foot contact sensors) as well as allows for adaptation within a few steps to deal with environmental changes. We have successfully applied our control approach to the biomechanical bipedal robot DACBOT. As a result, the robot can robustly walk with energy efficiency and quickly adapt to different speeds of a treadmill.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-43488-9_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-46681-1_28,Self and Non-self Discrimination Mechanism Based on Predictive Learning with Estimation of Uncertainty,Neural Information Processing,10.1007/978-3-319-46681-1_28,Springer,2016-01-01,"In this paper, we propose a model that can explain the mechanism of self and non-self discrimination. Infants gradually develop their abilities for self–other cognition through interaction with the environment. Predictive learning has been widely used to explain the mechanism of infants’ development. We hypothesized that infants’ cognitive abilities are developed through predictive learning and the uncertainty estimation of their sensory-motor inputs. We chose a stochastic continuous time recurrent neural network, which is a dynamical neural network model, to predict uncertainties as variances. From the perspective of cognitive developmental robotics, a predictive learning experiment with a robot was performed. The results indicate that training made the robot predict the regions related to its body more easily. We confirmed that self and non-self cognitive abilities might be acquired through predictive learning with uncertainty estimation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-46681-1_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-32703-7_179,A Robotic Cloud Ecosystem for Elderly Care and Ageing Well: The GrowMeUp Approach,XIV Mediterranean Conference on Medical and Biological Engineering and Computing 2016,10.1007/978-3-319-32703-7_179,Springer,2016-01-01,"Robotic systems in Ageing Well, like GrowMeUp, are among those assistive technologies, providing companionship and offering functionality related to the support of active and independent living, monitoring and maintaining safety, and enhancement of health and psychological well-being of the elderly. The work presented in this paper is based on the context of GrowMeUp project and focuses on presenting the main novelties introduced with the GrowMeUp system, providing a robotic cloud ecosystem, able to support, encourage and engage the older persons to stay socially involved and longer active and independent, in carrying out their daily life at home. Emphasis is given on the important issues of end user’s acceptance, usability and affordability and how technologies like cloud computing and different learning and intelligent dialoguing mechanisms are brought together in one solution to address these issues.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-32703-7_179,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-23180-8_22,Learning and Memory Processes in Autonomous Agents Using an Intelligent System of Decision-Making,Advanced and Intelligent Computations in Diagnosis and Control,10.1007/978-3-319-23180-8_22,Springer,2016-01-01,"This paper analyzes functions and structures of the memory that is an indispensable part of an Intelligent System of Decision-making (ISD), developed as a universal engine for autonomous robotics. A simplified way of processing and coding information in human cognitive processes is modelled and adopted for the use in autonomous systems. Based on such a knowledge structure, an artificial model of reality representation and a model of human memory (using, in particular, the concept of Long-Term Memory) are discussed. Finally, the paper presents a way of rearranging the system memory and modelling the processes of learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-23180-8_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-28860-4_7,Creating and Controlling Complex Biological Brains,Complex Systems,10.1007/978-3-319-28860-4_7,Springer,2016-01-01,"In this contribution, a look is taken at how animal and/or human brain cells can be cultivated (grown) and given a robot physical body (as a controlling brain) in which they can move around and interact with the world. This is realised as a new form of Artificial Intelligence Artificial intelligence in which the complexity Complexity of a highly nonlinear biological neural network is employed to uniquely control Complexity of controlling process a real-world robot. The communication/control feedback loop is described and considered in terms of learning, performance, long-term operation and specialisation within the neural structure. Experimental results are presented and philosophical arguments opened up, e.g. can the robot be considered to be a living, conscious entity?",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-28860-4_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-07052-0_19,Nanotechnology-Neuroscience Convergence,Handbook of Science and Technology Convergence,10.1007/978-3-319-07052-0_19,Springer,2016-01-01,"Roco et al. 2013 introduced the convergence of nanotechnology with biotechnology, information technology, and cognitive technology (NBIC) as a main trend in science and technology. They also provided a list of 20 visionary ideas for the next 10–30 years. According to their ideas, in the next 20 years, we expect to have humanlike intelligent robots, smartphones with real-time language translating function, and pocket-sized supercomputers through the advance in the NBIC. To pave the way for this, every computing system should be flexible, mobile, self-programmable, real time, and even self-learning. However, as the miniaturization trend continues following Moore’s law, it would be impractical to apply the current nanoelectronics to future computing systems due to enormous energy consumption and technological limits. Accordingly, the architecture and the functions of transistors used in the present computing system need to be improved and inspired by the human brain. Unfortunately, it is unclear how neural activities in the human brain result in cognitive process Cognitive process es such as learning and reasoning. Nevertheless, the convergence of neuroscience with nanotechnology is expected to bring us closer to building neuro-inspired chips for neurocomputers utilizing some clues on neural activity and structure. In this chapter, we will show various scientific problems and challenges in realizing neuro-inspired chips.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-07052-0_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-6265-072-5_9,Means and Methods of the Future: Autonomous Systems,Targeting: The Challenges of Modern Warfare,10.1007/978-94-6265-072-5_9,Springer,2016-01-01,"Autonomous systems will fundamentally alter the way wars are waged. In particular, autonomous weapon systems, capable of selecting and engaging targets without direct human operator involvement, represent a significant shift of humans away from the battlefield. As these new means and methods of warfare are introduced, many important targeting decisions will likely need to be made earlier and further away from the front lines. Fearful of these changes and coupled with other legal and moral concerns, groups opposed to autonomous weapons have formed and begun campaigning for a pre-emptive ban on their development and use. Nations intending to use these emerging technologies must grapple with how best to adjust their targeting processes and procedures to accommodate greater autonomy in weapon systems. This chapter examines these cutting-edge and controversial weapons with a particular emphasis on the legal impact on targeting during international armed conflicts. Initially, this chapter will explore the promising technological advances and operational benefits which indicate these weapon systems may become a reality in the not-so-distant future. The focus will then turn to the unique challenges the systems present to the law of armed conflict under both weapons law and targeting law principles. Next, the examination will shift to two key aspects of targeting most affected by autonomous systems: targeting doubt and subjectivity in targeting. The author ultimately concludes that autonomous weapon systems are unlikely to be deemed unlawful per se and that, while these targeting issues raise legitimate concerns, the use of autonomous weapons under many circumstances will be lawful.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-6265-072-5_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4899-7668-0_6,Artificial Brain Systems Based on Neural Network Discrete Chaotic Dynamics. Toward the Development of Conscious and Rational Robots,Robust Intelligence and Trust in Autonomous Systems,10.1007/978-1-4899-7668-0_6,Springer,2016-01-01,"Mathematical models, which we claim can correspond to the discrete chaotic biochemical reaction dynamics of living and thinking systems, have been derived herein from first physicochemical principles and applied to neural network operations. In this application, we are assuming that the biochemical reactions are accompanied and controlled by an “information exchange” between neurons, neural networks and the different types of neural networks responsible for a brain’s various cognitive functions. Both the qualitative and quantitative meaning of “information” and “information exchange” between neural networks have been formulated in relation to a neuron’s chaotic states; we have formally introduced them into basic artificial neural network ( ANN ) equations. As will be shown in this work, each ANN uses a dynamic principle as a driving force that instantiates specific properties such as “self-organization” and “self-synchronization”. These result in the emergence of “phenomenological” states that form the complex patterns which we associate with brain consciousness, cognition and creativity. Our proposed ANN generates practically an unlimited variety of discrete time and space patterns which are controlled by the continuous parameters of the proposed mathematical models. It has provided us with the confidence that with ANN learning and training, we can fit the proper architectural and mathematical models to the desired cognitive and creative properties for an artificial intelligent autonomous system. Results of numerical simulations will be presented in a form of 2D and 3D discrete time-space distributed patterns. Application of the approach to the art of mandalas we argue can be extended to a proposed approach for autonomous robot path planning as presented and discussed in this chapter.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4899-7668-0_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-43488-9_7,Modular Neural Control for Object Transportation of a Bio-inspired Hexapod Robot,From Animals to Animats 14,10.1007/978-3-319-43488-9_7,Springer,2016-01-01,"Insects, like dung beetles, can perform versatile motor behaviors including walking, climbing an object (i.e., dung ball), as well as manipulating and transporting it. To achieve such complex behaviors for artificial legged systems, we present here modular neural control of a bio-inspired hexapod robot. The controller utilizes discrete-time neurodynamics and consists of seven modules based on three generic neural networks. One is a neural oscillator network serving as a central pattern generator (CPG) which generates basic rhythmic patterns. The other two networks are so-called velocity regulating and phase switching networks. They are used for regulating the rhythmic patterns and changing their phase. As a result, the modular neural control enables the hexapod robot to walk and climb a large cylinder object with a diameter of 18 cm (i.e., $$\approx 2.8$$ times the robot’s body height). Additionally, it can also generate different hind leg movements for different object manipulation modes, like soft and hard pushing. Combining these pushing modes, the robot can quickly transport the object across an obstacle with a height up to 10 cm (i.e., $$\approx 1.5$$ times the robot’s body height). The controller was developed and evaluated using a physical simulation environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-43488-9_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-46687-3_31,Learning Visually Guided Risk-Aware Reaching on a Robot Controlled by a GPU Spiking Neural Network,Neural Information Processing,10.1007/978-3-319-46687-3_31,Springer,2016-01-01,"Risk-aware control is a new type of robust nonlinear stochastic controller in which state variables are represented by time-varying probability densities and the desired trajectory is replaced by a cost function that specifies both the goals of movement and the potential risks associated with deviations. Efficient implementation is possible using the theory of Stochastic Dynamic Operators (SDO), because for most physical systems the SDO operators are near-diagonal and can thus be implemented using distributed computation. I show such an implementation using 4.3 million spiking neurons simulated in real-time on a GPU. I demonstrate successful control of a commercial desktop robot for a visually-guided reaching task, and I show that the operators can be learned during repetitive practice using a recursive learning rule.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-46687-3_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-43506-0_52,Multimodal Recurrent Neural Network (MRNN) Based Self Balancing System: Applied into Two-Wheeled Robot,Intelligent Robotics and Applications,10.1007/978-3-319-43506-0_52,Springer,2016-01-01,"Biologically inspired control system is necessary to be increased. This paper proposed the new design of multimodal neural network inspired from human learning system which takes different action in different condition. The multimodal neural network consists of some recurrent neural networks (RNNs) those are separated into different condition. There is selector system that decides certain RNN system depending the current condition of the robot. In this paper, we implemented this system in pendulum mobile robot as the basic object of study. Several certain number of RNNs are implemented into certain different condition of tilt robot. RNN works alternately depending on the condition of robot. In order to prove the effectiveness of the proposed model, we simulated in the computer simulation Open Dynamic Engine (ODE) and compared with ordinary RNN. The proposed neural model successfully stabilize the applied robot (2-wheeled robot). This model is developed for implemented into humanoid balancing learning system as the final object of study.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-43506-0_52,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-662-48638-2_7,"Natural Versus Artificial Minds and the Supercomputing Era
",Bayesians Versus Frequentists,10.1007/978-3-662-48638-2_7,Springer,2016-01-01,"Computer sciences have completely changed the way scientific and social research is performed nowadays. This chapter analyzes the role of Bayesianism and frequentism into the emergence of e-science, artificial intelligence, and robotics, the generation of expert systems, and the overwhelming problem of how to analyze Big Data, a process called “data mining.” This review of the main systems and ideas will show us how Bayesianism is acquiring a determinant position among worldwide users of statistical tools.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-662-48638-2_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-32552-1_14,AI Reasoning Methods for Robotics,Springer Handbook of Robotics,10.1007/978-3-319-32552-1_14,Springer,2016-01-01,"Artificial intelligence ( AI artificial intelligence (AI) ) reasoning technology involving, e. g., inference, planning, and learning, has a track record with a healthy number of successful applications. So can it be used as a toolbox of methods for autonomous mobile robots? Not necessarily, as reasoning on a mobile robot about its dynamic, partially known environment may differ substantially from that in knowledge-based pure software systems, where most of the named successes have been registered. Moreover, recent knowledge about the robot’s environment cannot be given a priori, but needs to be updated from sensor data, involving challenging problems of symbol grounding and knowledge base change. This chapter sketches the main robotics-relevant topics of symbol-based AI reasoning. Basic methods of knowledge representation and inference are described in general, covering both logic- and probability-based approaches. The chapter first gives a motivation by example, to what extent symbolic reasoning has the potential of helping robots perform in the first place. Then (Sect.  14.2 ), we sketch the landscape of representation languages available for the endeavor. After that (Sect.  14.3 ), we present approaches and results for several types of practical, robotics-related reasoning tasks, with an emphasis on temporal and spatial reasoning. Plan-based robot control is described in some more detail in Sect.  14.4 . Section  14.5 concludes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-32552-1_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-26485-1_28,The Seminal Speculation of a Precursor: Elements of Embodied Cognition and Situated AI in Alan Turing,Fundamental Issues of Artificial Intelligence,10.1007/978-3-319-26485-1_28,Springer,2016-01-01,"Turing’s visionary contribution to cognitive science is not limited to the foundation of the symbolist approach to cognition and to the exploration of the connectionist approach: it additionally anticipated the germinal disclosure of the embodied approach. Even if Turing never directly dealt with the foundational speculation on the conceptual premises of embodiment, in his theoretical papers we find traces of the idea that a cognitive agent must develop a history of coupling with its natural and social environment, and that primitive bodily stimuli like pain and pleasure drive this coupling and elevate it to real learning by setting its normative preconditions. Turing did not consistently defend the centrality of embodiment, and ended up confounding or deemphasizing in various occasions the critical importance that he had himself implicitly recognized to the body. In line with the anti-representationist, radically enactive approaches to basic cognition, I believe that if Turing eventually failed to fully value the cognitive-developmental role played by the body, this was not because he proposed a computational and functionalist model of the mind, but because he tacitly assumed the content/vehicle dichotomy as a primitive of that model: in fact, he still believed that intelligence is a realized by decontextualized contents that can be detached and transmitted regardless of their mode of physical implementation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-26485-1_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-43488-9_20,Learning to Synchronously Imitate Gestures Using Entrainment Effect,From Animals to Animats 14,10.1007/978-3-319-43488-9_20,Springer,2016-01-01,"Synchronisation and coordination are omnipresent and essential in humans interactions. Because of their unavoidable and unintentional aspect, those phenomena could be the consequences of a low level mechanism: a driving force originating from external stimuli called the entrainment effect. In the light of its importance in interaction and wishing to define new HRI, we suggest to model this entrainment to highlight its efficiency for gesture learning during imitative games and for reducing the computational complexity. We will put forward the capacity of adaptation offered by the entrainment effect. Hence, we present in this paper a neural model for gesture learning by imitation using entrainment effect applied to a NAO robot interacting with a human partner.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-43488-9_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-23327-7_70,Kinematics and Energy Minimization Approach for Continuum Robot,Advances in Reconfigurable Mechanisms and Robots II,10.1007/978-3-319-23327-7_70,Springer,2016-01-01,"The outstanding compliance and adaptability of invertebrate limbs have motivated a recent surge of research activity in continuum robots. In previous studies, the dynamical model of the continuum robot is constructed by using the Lagrange method and the analytic method for the kinematics and dynamics of a continuum robot are shown. In this paper, we focus on the development of the kinematic models of the continuum robot and the energy optimal planning for the continuum robot. A multilayer neural network is used for solving the non-linearity of the rigid parallel mechanism. Based on Bishop frames, an optimal curve is used to generate the continuous backbone curve. The optimality criteria are used to choose the curve that satisfies task constraints while optimizing energy consumption. Kinematic models are validated through experiments done with the continuum robot. The results demonstrate that the proposed method for the continuum robot is feasible.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-23327-7_70,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-26485-1_24,Artificial Intelligence: The Point of View of Developmental Robotics,Fundamental Issues of Artificial Intelligence,10.1007/978-3-319-26485-1_24,Springer,2016-01-01,"We present here the research directions of the newly formed Artificial Intelligence Lab of Aldebaran Robotics. After a short historical review of AI, we introduce the field of developmental robotics, which stresses the importance of understanding the dynamical aspect of intelligence and the early developmental stages from sensorimotor categorization up to higher level socio-cognitive skills. Taking inspiration in particular from developmental psychology, the idea is to model the underlying mechanisms of gradual learning in the context of a progressively more complex interaction with the environment and with other agents. We review the different aspects of this approach that are explored in the lab, with a focus on language acquisition and symbol grounding.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-26485-1_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-31232-3_50,IT as a Driver for New Business,New Advances in Information Systems and Technologies,10.1007/978-3-319-31232-3_50,Springer,2016-01-01,"This research focuses on the role of Information Technologies (IT) as a driver for creating new business. The research question is “What are the key businesses that are emerging due to IT?” The research was supported on a qualitative methodology through documental analysis and semi-structured interviews to IT Managers of organizations which represents the main economic sectors. The technologies under analysis were Internet of Things, Cloud Technology, Big Data, Mobile Technologies, and Artificial Intelligence and Robotics. A main result of this research was the new disruptive business that are emerging from the impact of this technologies on the markets.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-31232-3_50,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-44188-7_6,Emotion Recognition Using Facial Expression Images for a Robotic Companion,Engineering Applications of Neural Networks,10.1007/978-3-319-44188-7_6,Springer,2016-01-01,"Social robots are gradually becoming part of society. However, social robots lack the ability to adequately interact with users in a natural manner and are in need of more human-like abilities. In this paper we present experimental results on emotion recognition through the use of facial expression images obtained from the KDEF database, a fundamental first step towards the development of an empathic social robot. We compare the performance of Support Vector Machines (SVM) and a Multilayer Perceptron Network (MLP) on facial expression classification. We employ Gabor filters as an image pre-processing step before classification. Our SVM model achieves an accuracy rate of 97.08 %, whereas our MLP achieves 93.5 %. These experiments serve as benchmark for our current research project in the area of social robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-44188-7_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-09483-0_129,Cybernetics,Encyclopedia of Global Bioethics,10.1007/978-3-319-09483-0_129,Springer,2016-01-01,"The original definition of cybernetics was proposed by Norbert Wiener (1948) as “the science of control and communication in the animal and the machine.” Cybernetics can be defined as the science that studies the communication and interactions between autonomous complex systems (machines and living organisms) through the use of information and control of their processes. In the medical field, as cybernetics evolves, physicians have resorted to support systems with intelligent and adaptive features to help them in many diagnostic and treatment tasks. These systems use artificial neural network and fuzzy logic algorithms. Moreover, these improvements have helped clinicians in decision-making, to offer an accurate diagnosis or to deliver a better treatment (i.e., wearable robots, such as prosthesis and mechanical substitutes), resulting in the possibility to develop new approaches for a higher quality in healthcare systems (i.e., e-health). However, the use and research of high-technology developments can give rise to ethical issues. Thus, it is crucial to address the bioethical concerns that surround the application of cybernetics in medicine. Dealing with medical bioethics, physicians are forced to face several moral theories in order to get a better approximation about specific problems and generate solutions based on a bioethical reflection process.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-09483-0_129,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-47437-3_28,Emotion in Robots Using Convolutional Neural Networks,Social Robotics,10.1007/978-3-319-47437-3_28,Springer,2016-01-01,"These years, emotion recognition has been one of the hot topics in computer science and especially in Human-Robot Interaction (HRI) and Robot-Robot Interaction (RRI). By emotion (recognition and expression), robots can recognize human behavior and emotion better and can communicate in a more human way. On that point are some research for unimodal emotion system for robots, but because, in the real world, Human emotions are multimodal then multimodal systems can work better for the recognition. Yet, beside this multimodality feature of human emotion, using a flexible and reliable learning method can help robots to recognize better and makes more beneficial interaction. Deep learning showed its force in this area and here our model is a multimodal method which use 3 main traits (Facial Expression, Speech and gesture) for emotion (recognition and expression) in robots. We implemented the model for six basic emotion states and there are some other states of emotion, such as mix emotions, which are really laborious to be picked out by robots. Our experiments show that a significant improvement of identification accuracy is accomplished when we use convolutional Neural Network (CNN) and multimodal information system, from 91 % reported in the previous research [ 27 ] to 98.8 %.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-47437-3_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-44778-0_18,Inverse Recurrent Models – An Application Scenario for Many-Joint Robot Arm Control,Artificial Neural Networks and Machine Learning – ICANN 2016,10.1007/978-3-319-44778-0_18,Springer,2016-01-01,"This paper investigates inverse recurrent forward models for many-joint robot arm control. First, Recurrent Neural Networks (RNNs) are trained to predict arm poses. Due their recurrence the RNNs naturally match the repetitive character of computing kinematic forward chains. We demonstrate that the trained RNNs are well suited to gain inverse kinematics robustly and precisely using Back-Propagation Trough Time even for complex robot arms with up to 40 universal joints with 120 articulated degrees of freedom and under difficult conditions. The concept is additionally proven on a real robot arm. The presented results are promising and reveal a novel perspective to neural robotic control.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-44778-0_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-40159-1_15,Task Allocation in Evolved Communicating Homogeneous Robots: The Importance of Being Different,"Trends in Practical Applications of Scalable Multi-Agent Systems, the PAAMS Collection",10.1007/978-3-319-40159-1_15,Springer,2016-01-01,"Social animals have conquered the world thanks to their ability to team up in order to solve survival problems. From ants to human beings, animals show ability to cooperate, communicate and divide labour among individuals. Cooperation allows members of a group to solve problems that a single individual could not, or to speed up a solution by splitting a task in subparts. Biological and swarm robotics studies suggest that division of labour can be favoured by differences in local information, especially in clonal individuals. However, environmental information alone could not suffice despite a task requires a role differentiation to be solved. In order to overcome this problem, in this paper, we analyse and discuss the role of a communication system able to differentiate signals emitted among a group of homogeneous robots to foster the evolution of a successful role allocation strategy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-40159-1_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-31153-1_14,On-line Evolution of Foraging Behaviour in a Population of Real Robots,Applications of Evolutionary Computation,10.1007/978-3-319-31153-1_14,Springer,2016-01-01,"This paper describes a study in evolutionary robotics conducted completely in hardware without using simulations. The experiments employ on-line evolution, where robot controllers evolve on-the-fly in the robots’ environment as the robots perform their tasks. The main issue we consider is the feasibility of tackling a non-trivial task in a realistic timeframe. In particular, we investigate whether a population of six robots can evolve foraging behaviour in one hour. The experiments demonstrate that this is possible and they also shed light on some of the important features of our evolutionary system. Further to the specific results we also advocate the system itself. It provides an example of a replicable and affordable experimental set-up for other researches to engage in research into on-line evolution in a population of real robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-31153-1_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-46687-3_44,Towards Robustness to Fluctuated Perceptual Patterns by a Deterministic Predictive Coding Model in a Task of Imitative Synchronization with Human Movement Patterns,Neural Information Processing,10.1007/978-3-319-46687-3_44,Springer,2016-01-01,"The current paper presents how performance of a particular deterministic dynamical neural network model in predictive coding scheme differ when it is trained for a set of prototypical movement patterns using their modulated teaching samples from when it is trained using unmodulated teaching samples. Multiple timescale neural network (MTRNN) trained with or without modulated patterns was applied in a simple numerical experiment for a task of imitative synchronization by inferencing the internal states by the error regression, and the results suggest that the scheme of training with modulated patterns can outperform the scheme of training without them. In our second experiment, our network was tested with naturally fluctuated movement patterns in an imitative interaction between a robot and different human subjects, and the results showed that a network trained with fluctuated patterns could achieve generalization in learning, and mutual imitation by synchronization was obtained.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-46687-3_44,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-46687-3_58,Implementation of a Modular Growing When Required Neural Gas Architecture for Recognition of Falls,Neural Information Processing,10.1007/978-3-319-46687-3_58,Springer,2016-01-01,"In this paper we aim for the replication of a state of the art architecture for recognition of human actions using skeleton poses obtained from a depth sensor. We review the usefulness of accurate human action recognition in the field of robotic elderly care, focusing on fall detection. We attempt fall recognition using a chained Growing When Required neural gas classifier that is fed only skeleton joints data. We test this architecture against Recurrent SOMs (RSOMs) to classify the TST Fall detection database ver. 2, a specialised dataset for fall sequences. We also introduce a simplified mathematical model of falls for easier and faster bench-testing of classification algorithms for fall detection. The outcome of classifying falls from our mathematical model was successful with an accuracy of $$ 97.12 \pm 1.65\,\%$$ and from the TST Fall detection database ver. 2 with an accuracy of $$90.2 \pm 2.68\,\%$$ when a filter was added.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-46687-3_58,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-39883-9_24,Robot Dream,Agent and Multi-Agent Systems: Technology and Applications,10.1007/978-3-319-39883-9_24,Springer,2016-01-01,"In this position paper we present a novel approach to neurobiologically plausible implementation of emotional reactions and behaviors for real-time autonomous robotic systems. The working metaphor we use is the “day” and “night” phases of mammalian life. During the “day” phase a robotic system stores the inbound information and is controlled by a light-weight rule-based system in real time. In contrast to that, during the “night” phase the stored information is been transferred to the supercomputing system to update the realistic neural network: emotional and behavioral strategies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-39883-9_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/1471-2202-16-S1-P169,ROS-MUSIC toolchain for spiking neural network simulations in a robotic environment,BMC Neuroscience,10.1186/1471-2202-16-S1-P169,BioMed Central,2015-12-18,,https://www.biomedcentral.com/openurl?doi=10.1186/1471-2202-16-S1-P169,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/1471-2202-16-S1-P104,Spiking neural network configuration designed for switching between basic forms of movement in a biped robot,BMC Neuroscience,10.1186/1471-2202-16-S1-P104,BioMed Central,2015-12-18,,https://www.biomedcentral.com/openurl?doi=10.1186/1471-2202-16-S1-P104,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-015-0184-4,On Exploiting Haptic Cues for Self-Supervised Learning of Depth-Based Robot Navigation Affordances,Journal of Intelligent & Robotic Systems,10.1007/s10846-015-0184-4,Springer,2015-12-01,"This article presents a method for online learning of robot navigation affordances from spatiotemporally correlated haptic and depth cues. The method allows the robot to incrementally learn which objects present in the environment are actually traversable. This is a critical requirement for any wheeled robot performing in natural environments, in which the inability to discern vegetation from non-traversable obstacles frequently hampers terrain progression. A wheeled robot prototype was developed in order to experimentally validate the proposed method. The robot prototype obtains haptic and depth sensory feedback from a pan-tilt telescopic antenna and from a structured light sensor, respectively. With the presented method, the robot learns a mapping between objects’ descriptors, given the range data provided by the sensor, and objects’ stiffness, as estimated from the interaction between the antenna and the object. Learning confidence estimation is considered in order to progressively reduce the number of required physical interactions with acquainted objects. To raise the number of meaningful interactions per object under time pressure, the several segments of the object under analysis are prioritised according to a set of morphological criteria. Field trials show the ability of the robot to progressively learn which elements of the environment are traversable.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-015-0184-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-015-0240-y,Development of quadruped robot with locomotion rhythm generator using pulse-type hardware neural networks,Artificial Life and Robotics,10.1007/s10015-015-0240-y,Springer,2015-12-01,"This paper discussed about development of quadruped robot which could perform the quadruped animal-like locomotion. Locomotion rhythm of the quadruped robot was generated using the pulse-type hardware neural networks (P-HNN). Quadruped robot had mechanical components and electrical components. The mechanical components of the quadruped robot consist of the body frame, link mechanisms, 4 legs and 4 servo motors to realize the quadruped animal-like locomotion. The body frame, link mechanisms and 4 legs were made from aluminum base alloy. The electrical components of the quadruped robot consist of control board, battery and P-HNN. P-HNN generates the locomotion rhythms using synchronization phenomena such as biological neural networks. The control board actuates the servo motors according to the generated locomotion rhythms. As a result, constructed quadruped robot could perform the quadruped animal-like locomotion using the generated locomotion rhythm, which was shown in this paper.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-015-0240-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-014-0171-1,Batch Reinforcement Learning for Robotic Soccer Using the Q-Batch Update-Rule,Journal of Intelligent & Robotic Systems,10.1007/s10846-014-0171-1,Springer,2015-12-01,"Reinforcement Learning is increasingly becoming a valuable alternative to tackle many of the challenges existing in a semi-structured, non-deterministic and adversarial environment such as robotic soccer. Batch Reinforcement Learning is a class of Reinforcement Learning methods characterized by processing a batch of interactions. By storing all past interactions, Batch RL methods are extremely data-efficient which makes this class of methods very appealing for robotics applications, specially when learning directly on physical robotic platforms.This paper presents the application of Batch Reinforcement Learning to obtain efficient robotic soccer controllers on physical platforms. To learn the controllers we propose the application of Q-Batch, a novel update-rule that exploits the episodic nature of the interactions in Batch Reinforcement Learning. The approach was validated in three different tasks with increasing difficulty. Results show the proposed approach is able to outperform hand-coded policies, for all the tasks, in a reduced amount of time. Additionally, for one of the tasks, a comparison between Q-Batch and Q-learning is carried out, and results show that, Q-Batch obtains better policies than Q-learning for the same amount of interaction time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-014-0171-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00422-015-0661-7,Cerebellum-inspired neural network solution of the inverse kinematics problem,Biological Cybernetics,10.1007/s00422-015-0661-7,Springer,2015-12-01,"The demand today for more complex robots that have manipulators with higher degrees of freedom is increasing because of technological advances. Obtaining the precise movement for a desired trajectory or a sequence of arm and positions requires the computation of the inverse kinematic (IK) function, which is a major problem in robotics. The solution of the IK problem leads robots to the precise position and orientation of their end-effector. We developed a bioinspired solution comparable with the cerebellar anatomy and function to solve the said problem. The proposed model is stable under all conditions merely by parameter determination, in contrast to recursive model-based solutions, which remain stable only under certain conditions. We modified the proposed model for the simple two-segmented arm to prove the feasibility of the model under a basic condition. A fuzzy neural network through its learning method was used to compute the parameters of the system. Simulation results show the practical feasibility and efficiency of the proposed model in robotics. The main advantage of the proposed model is its generalizability and potential use in any robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00422-015-0661-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11269-015-1134-4,Irrigation Demand Forecasting Using Artificial Neuro-Genetic Networks,Water Resources Management,10.1007/s11269-015-1134-4,Springer,2015-12-01,"In recent years, a significant evolution of forecasting methods has been possible due to advances in artificial computational intelligence. The achievement of the optimal architecture of an ANN is a complex process. Thus, in this work, an Evolutionary Robotic (study of the evolution of an ANN using Genetic Algorithm) approach has been used to obtain an Artificial Neuro-Genetic Networks (ANGN) to the short-term forecasting of daily irrigation water demand that maximizes the accuracy of the predictions. The methodology is applied in the Bembézar Irrigation District (Southern Spain). An optimal ANGN architecture (ANGN (7, 29, 16, 1)) has achieved obtaining a Standard Error Prediction (SEP) value of the daily water demand of 12.63 % and explaining 93 % of the total variance observed during validation process. The developed model proved to be a powerful tool that, without long dataset and time requirements, can be very useful for the development of management strategies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11269-015-1134-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-015-1848-5,Spiking neural network-based target tracking control for autonomous mobile robots,Neural Computing and Applications,10.1007/s00521-015-1848-5,Springer,2015-11-01,"In this paper, a target tracking controller based on spiking neural network is proposed for autonomous robots. This controller encodes the preprocessed environmental and target information provided by CCD cameras, encoders and ultrasonic sensors into spike trains, which are integrated by a three-layer spiking neural network (SNN). The outputs of SNN are generated based on the competition between the forward/backward neuron pair corresponding to each motor, with the weights evolved by the Hebbian learning. The application to target tracking of a mobile robot in unknown environment verifies the validity of the proposed controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-015-1848-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1134/S2079059715060179,Analysis of the cognitive properties of neural systems based on biofeedback,Russian Journal of Genetics: Applied Research,10.1134/S2079059715060179,Springer,2015-11-01,"Problems of cognitive system reengineering, i.e., the development of devices with cognitive properties on the basis of their biological prototypes, cannot be solved without understanding the basic features of the architecture of biological systems, information properties, and molecular organization of the primitive units forming the architecture: nerve cells. The construction of learning models makes it possible to study the activity of individual cells, not only in terms of behavioral responses to natural stimuli but also in experiments on isolated preparations with excitation of peripheral bodies and isolated cell structures. The software-tool complex NeuroFeedBack was developed; it includes a system of living neurons and a neurocomputer interface feedback. The complex provides the reception and processing of input signals from neurons, their visualization and storage, as well as the generation of output reinforcing stimuli applied to the neurons. Analysis of the functional activity of neurons of the right parietal ganglion of the Lymnaea stagnalis mollusk was performed with the complex in three models of reinforcement. It was shown that optimization of neural activity occurred under conditions of biofeedback, allowing the neuron to minimize the quantity of the reinforcing stimuli. The results provided grounds for the design of a hybrid robotic system in which living neural systems using a neurocomputer interface could solve navigation tasks, controlling a real-time mechanoelectronical device operating in a real environment. In the experiment, the use of the proposed programs of hybrid reinforcements allowed the robot to find a glowing light bulb and reach it in a few minutes.",http://link.springer.com/openurl/pdf?id=doi:10.1134/S2079059715060179,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-015-0356-1,Autonomous Learning of State Representations for Control: An Emerging Field Aims to Autonomously Learn State Representations for Reinforcement Learning Agents from Their Real-World Sensor Observations,KI - Künstliche Intelligenz,10.1007/s13218-015-0356-1,Springer,2015-11-01,"This article reviews an emerging field that aims for autonomous reinforcement learning (RL) directly on sensor-observations. Straightforward end-to-end RL has recently shown remarkable success, but relies on large amounts of samples. As this is not feasible in robotics, we review two approaches to learn intermediate state representations from previous experiences: deep auto-encoders and slow-feature analysis . We analyze theoretical properties of the representations and point to potential improvements.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-015-0356-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-015-0224-y,Designing a robot controller by using a simple brain-wave sensor and a machine learning technique,Artificial Life and Robotics,10.1007/s10015-015-0224-y,Springer,2015-10-01,"We designed a robot controller that can use unstable data, such as brain waves. The controller analyzes brain waves from a simple electroencephalograph. A user can concentrate to make the robot move faster, and relax to make it move slower. In order to judge the user’s state by his brain-wave data, we adopt a machine learning technique called support vector machine. We investigated improving the classification accuracy by increasing the number of data sets used to make the user concentration model. We increased the data sets from 30 to 180; consequently, the accuracy increased, with a maximum of about 80 % with 150 data sets. This indicates that our controller is able to accurately classify unstable data and can control a robot using brain waves from a simple electroencephalograph.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-015-0224-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-014-0150-6,Neural Network Control of a Rehabilitation Robot by State and Output Feedback,Journal of Intelligent & Robotic Systems,10.1007/s10846-014-0150-6,Springer,2015-10-01,"In this paper, neural network control is presented for a rehabilitation robot with unknown system dynamics. To deal with the system uncertainties and improve the system robustness, adaptive neural networks are used to approximate the unknown model of the robot and adapt interactions between the robot and the patient. Both full state feedback control and output feedback control are considered in this paper. With the proposed control, uniform ultimate boundedness of the closed loop system is achieved in the context of Lyapunov’s stability theory and its associated techniques. The state of the system is proven to converge to a small neighborhood of zero by appropriately choosing design parameters. Extensive simulations for a rehabilitation robot with constraints are carried out to illustrate the effectiveness of the proposed control.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-014-0150-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-015-9459-7,Learning state representations with robotic priors,Autonomous Robots,10.1007/s10514-015-9459-7,Springer,2015-10-01,"Robot learning is critically enabled by the availability of appropriate state representations. We propose a robotics-specific approach to learning such state representations. As robots accomplish tasks by interacting with the physical world, we can facilitate representation learning by considering the structure imposed by physics; this structure is reflected in the changes that occur in the world and in the way a robot can effect them. By exploiting this structure in learning, robots can obtain state representations consistent with the aspects of physics relevant to the learning task. We name this prior knowledge about the structure of interactions with the physical world robotic priors . We identify five robotic priors and explain how they can be used to learn pertinent state representations. We demonstrate the effectiveness of this approach in simulated and real robotic experiments with distracting moving objects. We show that our method extracts task-relevant state representations from high-dimensional observations, even in the presence of task-irrelevant distractions. We also show that the state representations learned by our method greatly improve generalization in reinforcement learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-015-9459-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10676-015-9377-6,"The tragedy of the master: automation, vulnerability, and distance",Ethics and Information Technology,10.1007/s10676-015-9377-6,Springer,2015-09-01,"Responding to long-standing warnings that robots and AI will enslave humans, I argue that the main problem we face is not that automation might turn us into slaves but, rather, that we remain masters. First I construct an argument concerning what I call ‘the tragedy of the master’: using the master–slave dialectic, I argue that automation technologies threaten to make us vulnerable, alienated, and automated masters. I elaborate the implications for power, knowledge, and experience. Then I critically discuss and question this argument but also the very thinking in terms of masters and slaves, which fuels both arguments. I question the discourse about slavery and object to the assumptions made about human–technology relations. However, I also show that the discussion about masters and slaves attends us to issues with human–human relations, in particular to the social consequences of automation such as power issues and the problem of the relation between automation and (un)employment. Finally, I reflect on how we can respond to our predicament, to ‘the tragedy of the master’.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10676-015-9377-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10339-015-0714-9,Neuromodelling based on evolutionary robotics: on the importance of motor control for spatial attention,Cognitive Processing,10.1007/s10339-015-0714-9,Springer,2015-09-01,"Mainstream approaches to modelling cognitive processes have typically focused on (1) reproducing their neural underpinning, without regard to sensory-motor systems and (2) producing a single, ideal computational model. Evolutionary robotics is an alternative possibility to bridge the gap between neural substrate and behavior by means of a sensory-motor apparatus, and a powerful tool to build a population of individuals rather than a single model. We trained 4 populations of neurorobots, equipped with a pan/tilt/zoom camera, and provided with different types of motor control in order to perform a cancellation task, often used to tap spatial cognition. Neurorobots’ eye movements were controlled by (a) position, (b) velocity, (c) simulated muscles and (d) simulated muscles with fixed level of zoom. Neurorobots provided with muscle and velocity control showed better performances than those controlled in position. This is an interesting result since muscle control can be considered a particular type of position control. Finally, neurorobots provided with muscle control and zoom outperformed those without zooming ability.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10339-015-0714-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13239-015-0225-y,Predictive Model Reference Adaptive Controller to Compensate Heart Motion in Minimally Invasive CABG Surgery,Cardiovascular Engineering and Technology,10.1007/s13239-015-0225-y,Springer,2015-09-01,"Heart beating is a major challenge in minimally invasive coronary artery surgery. A promising solution is to develop a motion compensation robotic system that gives the surgeon an impression of operating on motionless tissue by synchronizing the surgical tool automatically with the heart tissue motion. To achieve higher control accuracy, an intelligent controller called Predictive Model Reference Adaptive Controller is presented herein, which is adapted not only by observed reference signals but, also by unknown reference signals that are not observed by a camera but could be predicted by a state space estimator. To develop such a system, first the heart surface motion is tracked by the Lucas–Kanade tracking algorithm and validated by human observation. The results of implementing this control algorithm on a real human heart data set show capability of achieving a motion compensation system with high control accuracy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13239-015-0225-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12559-014-9311-y,Towards Autonomous Robots Via an Incremental Clustering and Associative Learning Architecture,Cognitive Computation,10.1007/s12559-014-9311-y,Springer,2015-08-01,"This paper presents a novel architecture for associative learning and recall of different sensor and actuator patterns. A modular design allows the inclusion of various input and output modalities. The approach is a generic one that can deal with any kind of multidimensional real-valued data. Sensory data are incrementally grouped into clusters, which represent different categories of the input data. Clusters of different sensors or actuators are associated with each other based on the co-occurrence of corresponding inputs. Upon presenting a previously learned pattern as a cue, associated patterns can be recalled. The proposed architecture has been evaluated in a practical situation in which a robot had to associate visual patterns in the form of road signs with different configurations of its arm joints. This experiment assessed how long it takes to learn stable representations of the input patterns and tested the recall performance for different durations of learning. Depending on the dimensionality of the data, stable representations require many inputs to be formed and only over time similar small clusters are combined into larger clusters. Nevertheless, sufficiently good recall can be achieved earlier when the topology is still in an immature state and similar patterns are distributed over several clusters. The proposed architecture tolerates small variations in the inputs and can generalise over the varying perceptions of specific patterns but remains sensitive to fine geometrical shapes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12559-014-9311-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-013-0006-5,Adaptive Position Tracking System and Force Control Strategy for Mobile Robot Manipulators Using Fuzzy Wavelet Neural Networks,Journal of Intelligent & Robotic Systems,10.1007/s10846-013-0006-5,Springer,2015-08-01,"In this paper, we propose an adaptive position tracking system and a force control strategy for nonholonomic mobile robot manipulators, which incorporate the merits of Fuzzy Wavelet Neural Networks (FWNNs). In general, it is not easy to adopt a model-based method to achieve this control object due to the uncertainties of mobile robot manipulators control system, such as unknown dynamics, disturbances and parameter variations. To solve this problem, an adaptive FWNNs control scheme with the online learning ability is utilized to approximate the unknown dynamics without the requirement of prior system information. In addition, an adaptive robust compensator is proposed to eliminate uncertainties that consist of approximation errors, disturbances, optimal parameters and higher order terms in Taylor series. According to adaptive position tracking control design, an adaptive robust control strategy is also considered for nonholonomic constraint force. The design of adaptive online learning algorithms is derived using Lyapunov stability theorem. Therefore, the proposed controllers prove that they not only can guarantee the stability of mobile robot manipulators control system but also guarantee tracking performance. The effectiveness and robustness of the proposed method are demonstrated by comparing simulations and experimental results that are implemented in an indoor cleaning crawler-type mobile robot manipulators system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-013-0006-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11044-014-9441-8,Motion optimization using Gaussian process dynamical models,Multibody System Dynamics,10.1007/s11044-014-9441-8,Springer,2015-08-01,"We propose an efficient method for generating suboptimal motions for multibody systems using Gaussian process dynamical models. Given a dynamical model for a multibody system, and a trial motion, a lower-dimensional Gaussian process dynamical model is fitted to the trial motion. New motions are then generated by performing a dynamic optimization in the lower-dimensional space. We introduce the notion of variance tubes as an intuitive and efficient means of restricting the optimization search space. The performance of our algorithm is evaluated through detailed case studies of raising motions for an arm and jumping motions for a humanoid.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11044-014-9441-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-015-9432-5,Real-time WiFi localization of heterogeneous robot teams using an online random forest,Autonomous Robots,10.1007/s10514-015-9432-5,Springer,2015-08-01,"In this paper we present a WiFi-based solution to the localization and mapping problem for teams of heterogeneous robots operating in unknown environments. By exploiting wireless signal strengths broadcast from access points, a robot with a large sensor payload creates a WiFi signal map that can then be shared and utilized for localization by sensor-deprived robots. In our approach, WiFi localization is cast as a classification problem. An online clustering algorithm processes incoming WiFi signals that are then incorporated into an online random forest (ORF). The algorithm’s robustness is increased by a Monte Carlo localization algorithm whose sensor model exploits the results of the ORF classification. The proposed algorithm is shown to run in real-time, allowing the robots to operate in completely unknown environments, where a priori information such as a blue-print or the access points’ location is unavailable. A comprehensive set of experiments not only compares our approach with other algorithms, but also validates the results across different scenarios covering both indoor and outdoor environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-015-9432-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-014-0132-2,Decentralized neural network control for guaranteed tracking error constraint of a robot manipulator,"International Journal of Control, Automation and Systems",10.1007/s12555-014-0132-2,Springer,2015-08-01,"In this paper, a new constrained error variable similar to sliding mode surface (SMC) is proposed to ensure a prescribed position tracking performance of a robot manipulator. A decentralized controller using this constrained error variable and a radial basis function network (RBF) is designed. The proposed decentralized and constrained control system ensures a prescribed transient and steady-state time positioning performance of the decentralized manipulator components without violation of the prescribed performance. The effectiveness of the proposed decentralized and robust control scheme was determined by comparing the results of simulated and experimental evaluation with the conventional SMC and finite-time terminal SMC methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-014-0132-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-014-0162-2,Robust Adaptive Trajectory Tracking Sliding mode control based on Neural networks for Cleaning and Detecting Robot Manipulators,Journal of Intelligent & Robotic Systems,10.1007/s10846-014-0162-2,Springer,2015-07-01,"This paper proposes an robust adaptive control method based on Radial Basis Function Neural networks (RBFNN) to investigate the joint position control for periodic motion and predefined trajectory tracking control of two link Cleaning and Detecting Robot Manipulators (CDRM). The proposed control scheme uses a three layer RBFNN to approximate nonlinear robot dynamics. The RBF network is one of the most popular intelligent approaches which has shown a great promise in this sort of problems because of simple network structure and its faster learning capacity. When the RBF networks are used to approximate a nonlinear dynamic system, the control system is stable. In addition, Sliding mode control (SMC) is a well known nonlinear control strategy because of its robustness. A robust term function is selected as an auxiliary controller to guarantee the stability and robustness under various envirorments, such as the mass variation, the external disturbances and modeling uncertainties. The adaptation laws for the weights of the RBFNN are adjusted using the Lyapunov stability theorem, the global stability and robustness of the entire control system are guaranteed, and the tracking errors converge to the required precison, and position is proved. Finally, experiments performed on a two-link CDRM in electric power substation are provided in comparison with proportional differential (PD) and adaptive Fuzzy (AF) control to demonstrate superior tracking precision and robustness of the proposed control methodology.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-014-0162-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13347-014-0150-2,Zombie Mouse in a Chinese Room,Philosophy & Technology,10.1007/s13347-014-0150-2,Springer,2015-06-01,"John Searle’s Chinese Room Argument (CRA) purports to demonstrate that syntax is not sufficient for semantics, and, hence, because computation cannot yield understanding, the computational theory of mind, which equates the mind to an information processing system based on formal computations, fails. In this paper, we use the CRA, and the debate that emerged from it, to develop a philosophical critique of recent advances in robotics and neuroscience. We describe results from a body of work that contributes to blurring the divide between biological and artificial systems; so-called animats, autonomous robots that are controlled by biological neural tissue and what may be described as remote-controlled rodents, living animals endowed with augmented abilities provided by external controllers. We argue that, even though at first sight, these chimeric systems may seem to escape the CRA, on closer analysis, they do not. We conclude by discussing the role of the body–brain dynamics in the processes that give rise to genuine understanding of the world, in line with recent proposals from enactive cognitive science.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13347-014-0150-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10115-014-0754-y,Online data-driven anomaly detection in autonomous robots,Knowledge and Information Systems,10.1007/s10115-014-0754-y,Springer,2015-06-01,"The use of autonomous robots is appealing for tasks, which are dangerous to humans. Autonomous robots might fail to perform their tasks since they are susceptible to varied sorts of faults such as point and contextual faults. Not all faults can be known in advance, and hence, anomaly detection is required. In this paper, we present an online data-driven anomaly detection approach ( ODDAD ) for autonomous robots. ODDAD is suitable for the dynamic nature of autonomous robots since it declares a fault based only on data collected online. In addition, it is unsupervised, model free and domain independent. ODDAD proceeds in three steps: data filtering, attributes grouping based on dependency between attributes and outliers detection for each group. Above a calculated threshold, an anomaly is declared. We empirically evaluate ODDAD in different domains: commercial unmanned aerial vehicles (UAVs), a vacuum-cleaning robot, a high-fidelity flight simulator and an electrical power system of a spacecraft. We show the significance and impact of each component of ODDAD . By comparing ODDAD to other state-of-the-art competing anomaly detection algorithms, we show its advantages.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10115-014-0754-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-014-1330-9,Applications and design of cooperative multi-agent ARN-based systems,Soft Computing,10.1007/s00500-014-1330-9,Springer,2015-06-01,"The Artificial Reaction Network (ARN) is an artificial chemistry inspired by Cell Signalling Networks. Its purpose is to represent chemical circuitry and to explore the computational properties responsible for generating emergent high-level behaviour. In this paper, the design and application of ARN-based cell-like agents termed “Cytobots” are explored. Such agents provide a facility to explore the dynamics and emergent properties of multicellular systems. The Cytobot ARN is constructed by combining functional motifs found in real biochemical networks. By instantiating this ARN, multiple Cytobots are created, each of which is capable of recognising environmental patterns, stigmergic communication with others and controlling its own trajectory. Applications in biological simulation and robotics are investigated by first applying the agents to model the life-cycle phases of the cellular slime mould D. discoideum and then to simulate an oil-spill clean-up operation. The results demonstrate that an ARN-based approach provides a powerful tool for modelling multi-agent biological systems and also has application in swarm robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-014-1330-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/521415a,Robotics: Ethics of artificial intelligence,Nature,10.1038/521415a,Nature,2015-05-28,Four leading researchers share their concerns and solutions for reducing societal risks from intelligent machines.,https://www.nature.com/articles/521415a,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11948-014-9541-0,Artificial Intelligence and Robot Responsibilities: Innovating Beyond Rights,Science and Engineering Ethics,10.1007/s11948-014-9541-0,Springer,2015-04-01,"The enduring innovations in artificial intelligence and robotics offer the promised capacity of computer consciousness, sentience and rationality. The development of these advanced technologies have been considered to merit rights, however these can only be ascribed in the context of commensurate responsibilities and duties. This represents the discernable next-step for evolution in this field. Addressing these needs requires attention to the philosophical perspectives of moral responsibility for artificial intelligence and robotics. A contrast to the moral status of animals may be considered. At a practical level, the attainment of responsibilities by artificial intelligence and robots can benefit from the established responsibilities and duties of human society, as their subsistence exists within this domain. These responsibilities can be further interpreted and crystalized through legal principles, many of which have been conserved from ancient Roman law. The ultimate and unified goal of stipulating these responsibilities resides through the advancement of mankind and the enduring preservation of the core tenets of humanity.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-014-9541-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-012-0447-9,Adaptive robust control based on RBF neural networks for duct cleaning robot,"International Journal of Control, Automation and Systems",10.1007/s12555-012-0447-9,Springer,2015-04-01,"In this paper, a control strategy for duct cleaning robot in the presence of uncertainties and various disturbances is proposed which combines the advantages of neural network technique and advanced adaptive robust theory. First of all, the configuration of the duct cleaning robot is introduced and the dynamic model is obtained based on the practical duct cleaning robot. Second, the RBF neural network is used to identify the unstructured and dynamic uncertainties due to its strong ability to approximate any nonlinear function to arbitrary accuracy. Using the learning ability of neural network, the designed controller can coordinately control the mobile plant and cleaning arm of duct cleaning robot with different dynamics efficiently. The neural network weights are only tuned on-line without tedious and lengthy off-line learning. Then, an adaptive robust control scheme based on RBF neural network is proposed, which ensures that the trajectories are accurately tracked even in the presence of external disturbances and uncertainties. Finally, based on the Lyapunov stability theory, the stability of the whole closed-loop control system, and the uniformly ultimately boundedness of the tracking errors are all strictly guaranteed. Moreover, simulation and experiment results are given to demonstrate that the proposed control approach can guarantee the whole system converges to desired manifold with well performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-012-0447-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-013-9397-8,An introduction to swarming robotics: application development trends,Artificial Intelligence Review,10.1007/s10462-013-9397-8,Springer,2015-04-01,"Animals help to sustain the environment’s life cycle and ecosystem. Without human intervention, these creatures carry out their ‘spontaneous routine’ jobs and contribute towards balance in nature. Any natural system that congregates as a result of some form of collective intelligence of nature is also known as swarm intelligence (SI). This metaphor inspires a variety of techniques to solve the problem of calculating, in most cases dealing with optimization problems and has sparked interest amongst scientists. It is very trying for a new researcher to understand the whole concept of swarming robotics (SR) and optimization algorithm (i.e. realizing the idea from animal’s perception to the SR application). In addition, the existing algorithms are computationally complicated, difficult to be understood by beginners as there are too many parameters. Thus, in this paper, we simplify the three branches of the main applications which are frequently used for SI namely: (1) optimization and networks design, (2) prediction and forecasting, and (3) SR. This paper summarizes the basic understanding overview of swarming robotics and discusses their basic concepts and principles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10462-013-9397-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-014-0151-5,Self-Learning Visual Servoing of Robot Manipulator Using Explanation-Based Fuzzy Neural Networks and Q-Learning,Journal of Intelligent & Robotic Systems,10.1007/s10846-014-0151-5,Springer,2015-04-01,"A new self-learning visual servoing system for the robot manipulators is proposed. This system includes two main properties: on-line self training and lifelong learning that are implemented by the Q-Learning algorithm and Explanation-based Fuzzy Neural Networks (EBFNN) respectively. We demonstrate that the number of training samples and the training time for a specific robot positioning accuracy can be reduced using explanation-based fuzzy neural networks and the Q-Learning algorithm. The system uses Q-learning to find the optimal policy in conjunction with the reinforcement learning. This policy is used by a robot to reach an object that has been randomly placed in a static workspace. Background knowledge about the robot and its environment is transferred to the robot agent during the learning process using a set of previously trained neural networks. This system learns the optimal policy in order to select the best action that maximizes the cumulative reward received at each time step. This learning approach does not use either a robot or camera model, or require calibration. Simulation results prove the effectiveness of this methodology to improve the learning process and the performance of the self-learning visual servoing system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-014-0151-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-014-1744-4,Solving time-varying quadratic programs based on finite-time Zhang neural networks and their application to robot tracking,Neural Computing and Applications,10.1007/s00521-014-1744-4,Springer,2015-04-01,"In this paper, finite-time Zhang neural networks (ZNNs) are designed to solve time-varying quadratic program (QP) problems and applied to robot tracking. Firstly, finite-time criteria and upper bounds of the convergent time are reviewed. Secondly, finite-time ZNNs with two tunable activation functions are proposed and applied to solve the time-varying QP problems. Finite-time convergent theorems of the proposed neural networks are presented and proved. The upper bounds of the convergent time are estimated less conservatively. The proposed neural networks also have superior robustness performance against perturbation with large implementation errors. Thirdly, feasibility and superiority of our method are shown by numerical simulations. At last, the proposed neural networks are applied to robot tracking. Simulation results also show the effectiveness of the proposed methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-014-1744-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13347-014-0156-9,Moral Deskilling and Upskilling in a New Machine Age: Reflections on the Ambiguous Future of Character,Philosophy & Technology,10.1007/s13347-014-0156-9,Springer,2015-03-01,"This paper explores the ambiguous impact of new information and communications technologies (ICTs) on the cultivation of moral skills in human beings. Just as twentieth century advances in machine automation resulted in the economic devaluation of practical knowledge and skillsets historically cultivated by machinists, artisans, and other highly trained workers (Braverman 1974 ), while also driving the cultivation of new skills in a variety of engineering and white collar occupations, ICTs are also recognized as potential causes of a complex pattern of economic deskilling, reskilling, and upskilling. In this paper, I adapt the conceptual apparatus of sociological debates over economic deskilling to illuminate a different potential for technological deskilling/upskilling, namely the ability of ICTs to contribute to the moral deskilling of human users, a potential that exists alongside rich but currently underrealized possibilities for moral reskilling and/or upskilling. I flesh out this general hypothesis by means of examples involving automated weapons technology, new media practices, and social robotics. I conclude that since moral skills are essential prerequisites for the effective development of practical wisdom and virtuous character, and since market and cultural forces are not presently aligned to bring about the more salutary of the ambiguous potentials presented here, the future shape of these developments warrants our close attention—and perhaps active intervention.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13347-014-0156-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11948-013-9513-9,AIonAI: A Humanitarian Law of Artificial Intelligence and Robotics,Science and Engineering Ethics,10.1007/s11948-013-9513-9,Springer,2015-02-01,"The enduring progression of artificial intelligence and cybernetics offers an ever-closer possibility of rational and sentient robots. The ethics and morals deriving from this technological prospect have been considered in the philosophy of artificial intelligence, the design of automatons with roboethics and the contemplation of machine ethics through the concept of artificial moral agents. Across these categories, the robotics laws first proposed by Isaac Asimov in the twentieth century remain well-recognised and esteemed due to their specification of preventing human harm, stipulating obedience to humans and incorporating robotic self-protection. However the overwhelming predominance in the study of this field has focussed on human–robot interactions without fully considering the ethical inevitability of future artificial intelligences communicating together and has not addressed the moral nature of robot–robot interactions. A new robotic law is proposed and termed AIonAI or artificial intelligence-on-artificial intelligence. This law tackles the overlooked area where future artificial intelligences will likely interact amongst themselves, potentially leading to exploitation. As such, they would benefit from adopting a universal law of rights to recognise inherent dignity and the inalienable rights of artificial intelligences. Such a consideration can help prevent exploitation and abuse of rational and sentient beings, but would also importantly reflect on our moral code of ethics and the humanity of our civilisation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-013-9513-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s40648-014-0025-4,View-based teaching/playback for robotic manipulation,ROBOMECH Journal,10.1186/s40648-014-0025-4,Springer,2015-01-31,"In this paper, we study a new method for robot programming: view-based teaching/playback. The motivation of its development is to achieve more robustness against changes of task conditions than conventional teaching/playback without losing its general versatility. For proof of concept, the method was implemented and tested on a virtual environment. The method is composed of two parts: teaching phase and playback phase. In the teaching phase, a human operator commands a robot to achieve a manipulation task. All the movements of the robot are recorded. All the images of the teaching scenes are also recorded by a camera. Then, a mapping from the recorded images to the movements is obtained as an artificial neural network. In the playback phase, the motion of the robot is determined by the output of the neural network calculated from scene images. We applied this view-based teaching/playback to pick-and-place and pushing by a robot hand with eight degrees of freedom in the virtual environment. Human demonstrated manipulation was successfully reproduced by the robot hand with our proposed method. Moreover, manipulation of the object from some initial positions that are not identical to those in the demonstrations was also successfully achieved with our method.",https://www.biomedcentral.com/openurl?doi=10.1186/s40648-014-0025-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-662-47487-7_24,Robot Reinforcement Learning for Automatically Avoiding a Dynamic Obstacle in a Virtual Environment,Advanced Multimedia and Ubiquitous Engineering,10.1007/978-3-662-47487-7_24,Springer,2015-01-01,"In a virtual environment, a robot can serve people by bringing things to them. However, when a robot moves within a house, it collides with a dynamic obstacle. These collisions make it difficult for a robot to complete its mission. We therefore apply reinforcement learning to the robot to make it more intelligent. Consequently, the robot can automatically move to avoid the dynamic obstacle in order to successfully complete its mission.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-662-47487-7_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-18615-3_45,Ball Dribbling for Humanoid Biped Robots: A Reinforcement Learning and Fuzzy Control Approach,RoboCup 2014: Robot World Cup XVIII,10.1007/978-3-319-18615-3_45,Springer,2015-01-01,"In the context of the humanoid robotics soccer, ball dribbling is a complex and challenging behavior that requires a proper interaction of the robot with the ball and the floor. We propose a methodology for modeling this behavior by splitting it in two sub problems: alignment and ball pushing. Alignment is achieved using a fuzzy controller in conjunction with an automatic foot selector. Ball-pushing is achieved using a reinforcement-learning based controller, which learns how to keep the robot near the ball, while controlling its speed when approaching and pushing the ball. Four different models for the reinforcement learning of the ball-pushing behavior are proposed and compared. The entire dribbling engine is tested using a 3D simulator and real NAO robots. Performance indices for evaluating the dribbling speed and ball-control are defined and measured. The obtained results validate the usefulness of the proposed methodology, showing asymptotic convergence in around fifty training episodes, and similar performance between simulated and real robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-18615-3_45,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-1-4614-6434-1_126-3,Modeling Neuronal Systems,Neuroscience in the 21st Century,10.1007/978-1-4614-6434-1_126-3,Springer,2015-01-01,"This chapter provides a summary of current approaches to modeling neuronal systems at the levels of single cells, networks, and more complex multinetwork systems. It begins with a brief history describing how models based on neurophysiological data diverged from artificial intelligence research and became increasingly sophisticated as available computational power increased. It is shown how, in order to make simulation of large network systems practical, models based on detailed ion channel properties can be replaced by increasingly simple “integrate-and-fire” models, “rate-coded” models that do not instantiate individual neuronal action potential spikes, and even ensemble models that provide statistical summaries of the activity of masses of neurons. Event-driven models that reduce the need to perform routine membrane-potential decay calculations at small time intervals are discussed. Models for synaptic modification presumed to be involved in learning are described for both rate-coded and spiking neuron models. The chapter ends with some discussion of nervous system aspects that are often omitted from models and which may form suitable bases for future research, as well as pitfalls that need to be avoided by newcomers to this field.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4614-6434-1_126-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-04033-2_27-1,Co-Robots: Humans and Robots Operating as Partners,Handbook of Science and Technology Convergence,10.1007/978-3-319-04033-2_27-1,Springer,2015-01-01,"A new era of robotics research is being driven by pressing societal problems and creating a transformation in the way that we envision human-robot interactions. In this chapter, we discuss three application domains that best capture both the promise and the challenges that this transformation has generated: the effort to build robots that support cognitive and social growth, robots that work in the home doing domestic tasks for users that have no training in robotics, and collaborative robots that work side-by-side to solve manufacturing and assembly tasks with human workers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-04033-2_27-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-19291-8_7,Users’ Belief Awareness in Reinforcement Learning-Based Situated Human–Robot Dialogue Management,Natural Language Dialog Systems and Intelligent Assistants,10.1007/978-3-319-19291-8_7,Springer,2015-01-01,"Others can have a different perception of the world than ours. Understanding this divergence is an ability, known as perspective taking in developmental psychology, that humans exploit in daily social interactions. A recent trend in robotics aims at endowing robots with similar mental mechanisms. The goal then is to enable them to naturally and efficiently plan tasks and communicate about them. In this paper we address this challenge extending a state-of-the-art goal-oriented dialogue management framework, the Hidden Information State (HIS). The new version makes use of the robot’s awareness of the users’ belief in a reinforcement learning-based situated dialogue management optimisation procedure. Thus the proposed solution enables the system to cope not only with the communication ambiguities due to noisy channel but also with the possible misunderstandings due to some divergence among the beliefs of the robot and its interlocutor in a human–robot interaction (HRI) context. We show the relevance of the approach by comparing different handcrafted and learnt dialogue policies with and without divergent belief reasoning in an in-house pick–place–carry scenario by means of user trials in a simulated 3D environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-19291-8_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-81-322-2208-8_13,Position and Orientation Control of a Mobile Robot Using Neural Networks,Computational Intelligence in Data Mining - Volume 2,10.1007/978-81-322-2208-8_13,Springer,2015-01-01,"In this paper, an adaptive neuro-control system with two levels is proposed for the motion control of a nonholonomic mobile robot. In the first level, a PD controller is designed to generate linear and angular velocities, necessary to track a reference trajectory. The proposed strategy is based on changing the robot control variables. Using this model, the nonholonomic constraints disappear and shows how the direct adaptive control theory can used to design robot controllers. In the second level, a neural network converts the desired velocities, provided by the first level, into a torque control. By introducing appropriate Lyapunov functions asymptotic stability of state variables and stability of system is guaranteed. The tracking performance of neural controller under disturbances is compared with PD controller. Sinusoidal trajectory and lemniscate trajectories are considered for this comparison.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-81-322-2208-8_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-22053-6_58,A Local Neural Networks Approximation Control of Uncertain Robot Manipulators,Advanced Intelligent Computing Theories and Applications,10.1007/978-3-319-22053-6_58,Springer,2015-01-01,"In this paper, an adaptive finite-time tracking control scheme is proposed for uncertain robotic manipulators. The controller is developed based on combination of terminal sliding mode control technique and radian basis function neural networks (RBFNNs). The RBFNNs are used to directly approximate individual element of the inertial matrix, the Coriolis matrix and gravity torques vector. The adaptation laws are derived to adjust on-line the parameters of RBFNNs. Finally, the simulation results of a two-link robot manipulator are presented to illustrate the effectiveness of the proposed control method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-22053-6_58,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-26561-2_1,Deep Feature-Action Processing with Mixture of Updates,Neural Information Processing,10.1007/978-3-319-26561-2_1,Springer,2015-01-01,"This paper explores the possibility of combining an actor and critic in one architecture and uses a mixture of updates to train them. It describes a model for robot navigation that uses architecture similar to an actor-critic reinforcement learning architecture. It sets up the actor as a layer seconded by another layer which deduce the value function. Therefore, the effect is to have similar to a critic outcome combined with the actor in one network. The model hence can be used as the base for a truly deep reinforcement learning architecture that can be explored in the future. More importantly this work explores the results of mixing conjugate gradient update with gradient update for the mentioned architecture. The reward signal is back propagated from the critic to the actor through conjugate gradient eligibility trace for the second layer combined with gradient eligibility trace for the first layer. We show that this mixture of updates seems to work well for this model. The features layer have been deeply trained by applying a simple PCA on the whole set of images histograms acquired during the first running episode. The model is also able to adapt to a reduced features dimension autonomously. Initial experimental result on real robot shows that the agent accomplished good success rate in reaching a goal location.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-26561-2_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-29339-4_24,A Study of Layered Learning Strategies Applied to Individual Behaviors in Robot Soccer,RoboCup 2015: Robot World Cup XIX,10.1007/978-3-319-29339-4_24,Springer,2015-01-01,Hierarchical task decomposition strategies allow robots and agents in general to address complex decision-making tasks. Layered learning is a hierarchical machine learning paradigm where a complex behavior is learned from a series of incrementally trained sub-tasks. This paper describes how layered learning can be applied to design individual behaviors in the context of soccer robotics. Three different layered learning strategies are implemented and analyzed using a ball-dribbling behavior as a case study. Performance indices for evaluating dribbling speed and ball-control are defined and measured. Experimental results validate the usefulness of the implemented layered learning strategies showing a trade-off between performance and learning speed.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-29339-4_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-09858-6_36,Identification of a Cylindrical Robot Using Recurrent Neural Networks,Multibody Mechatronic Systems,10.1007/978-3-319-09858-6_36,Springer,2015-01-01,"Neural identification techniques are very useful for the problem of unknown dynamics and uncertainties during the development of a model that accurately represents the behaviour of a robot. In this paper we use the model of a Recurrent Trainable Neural Network (RTNN) for modelling a cylindrical robot. The RTNN proposal is a multilayer network local feedback into the single hidden layer, to approach the robot dynamics. The learning algorithm for this topology is the Backpropagation (BP) dynamic. The simulation results of the approximation obtained through RTNN showed a good convergence and accurate tracking.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-09858-6_36,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-10380-8_57,Autonomous Robot Control by Neural Networks,CONTROLO’2014 – Proceedings of the 11th Portuguese Conference on Automatic Control,10.1007/978-3-319-10380-8_57,Springer,2015-01-01,"This work aims to apply the concepts associated with neural networks in the control of an autonomous robot system. The robot was tested in several arbitrary paths in order to verify the effectiveness of the neural control. The results show that the robot performed the tasks with success. Moreover, in the case of arbitrary paths the neural control outperforms other methodologies, such as fuzzy logic control.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-10380-8_57,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-11271-8_17,Artificial Intelligence Algorithms in Behavioural Control of Wheeled Mobile Robots Formation,Computational Intelligence,10.1007/978-3-319-11271-8_17,Springer,2015-01-01,"The paper presents an innovative approach to the problem of the wheeled mobile robots formation behavioural control with use of artificial intelligence algorithms. The control task is solved by application of adaptive dynamic programming algorithms in the hierarchical control system, that generates the collision free trajectories in the unknown 2D environment for all agents in the formation, and realises generated trajectories using tracking control algorithms. The hierarchical control system consists of three layers: the trajectory generator, the wheeled mobile robots formation control system and tracking control systems for individual agents. The trajectory generator presents the new approach to the behavioural control, where one neural dynamic programming algorithm generates the behavioural control signals that make possible to compute the trajectory for realisation of the complex task, which is a composition of two individual behaviours: “goal-seeking”and “obstacle avoiding“. Computer simulations have been conducted to illustrate the path planning process.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-11271-8_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-16841-8_15,Multi-Behaviour Robot Control using Genetic Network Programming with Fuzzy Reinforcement Learning,Robot Intelligence Technology and Applications 3,10.1007/978-3-319-16841-8_15,Springer,2015-01-01,"This research explores a new hybrid evolutionary learning methodology for multi-behaviour robot control. The new approach is an extension of the Fuzzy Genetic Network Programming algorithm with Reinforcement learning presented in [1]. The new learning system allows for the utilisation of any pre-trained intelligent systems as processing nodes comprising the phenotypes. We envisage that compounding the GNP with more powerful processing nodes would extend its computing prowess. As proof of concept, we demonstrate that the extended evolutionary system can learn multi-behaviours for robots by testing it on the simulated Mirosot robot soccer domain to learn both target pursuit and wall avoidance behaviours simultaneously. A discussion of the development of the new evolutionary system is presented following an incremental order of complexity. The experiments show that the proposed algorithm converges to the desired multi-behaviour, and that the obtained system accuracy is better than a system that does not utilise pre-trained intelligent processing nodes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-16841-8_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-19719-7_26,Reinforcement Learning in Single Robot Hose Transport Task: A Physical Proof of Concept,10th International Conference on Soft Computing Models in Industrial and Environmental Applications,10.1007/978-3-319-19719-7_26,Springer,2015-01-01,"In this paper we address the physical realization of proof of concept experiments demonstrating the suitability of the controllers learned by means of Reinforcement Learning (RL) techniques to accomplish tasks involving Linked Multi-Component Robotic System (LMCRS). In this paper, we deal with the task of transporting a hose by a single robot as a prototypical example of LMCRS, which can be extended to much more complex tasks. We describe how the complete system has been designed and built, explaining its different main components: the RL controller, the communications, and finally, the monitoring system. A previously learned RL controller has been tested solving a concrete problem with a determined state space modeling and discretization step. This physical realization validates our previous published works carried out through computer simulations, giving a strong argument in favor of the suitability of RL techniques to deal with real LMCRS systems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-19719-7_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-662-44599-0_1,Introduction,Evolutionary Humanoid Robotics,10.1007/978-3-662-44599-0_1,Springer,2015-01-01,"In this text we look to the past to two distinct strands of research into autonomous robots, evolutionary robotics and humanoid robot research, and how these strands are now beginning to converge in the novel field of evolutionary humanoid robotics. We investigate some of the current and emerging work in this new and exciting field. We address briefly some of the motivations. Why evolve robot bodies or brains, rather than go through a rigorous design process? And why should we have a particular interest in the creation of specifically humanoid robots, rather than, say, wheeled robots, or four-legged (quadrupedal) designs?",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-662-44599-0_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-25554-5_41,Socially-Assistive Emotional Robot that Learns from the Wizard During the Interaction for Preventing Low Back Pain in Children,Social Robotics,10.1007/978-3-319-25554-5_41,Springer,2015-01-01,"Back pain causes more global disability than any other health problem studied and the number of patients is growing. In Europe and in the US it is the number one cause of lost work days. This paper propounds a new approach by exploring the effect of utilizing a humanoid robot as a therapy-assistive tool in educating children to perform back exercises designed by a professional therapist. In our previous research a NAO robot was programmed and employed as a robotic assistant to a human physiotherapist to perform exercises in an elementary school in Slovakia. This paper goes further in designing a Wizard of Oz, where the exercises can be controlled and intervened by motivational behaviors of the robot (emotional expressions). Currently we are developing a system based on reinforcement learning that should adopt the motivational interventions from the Wizard. The promising results of this study in the physical therapy suggest the effective future use of social robots in reducing the symptoms of the most extended global disability in the world.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-25554-5_41,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-18833-1_34,Autonomous Robot Navigation Based on Pattern Recognition Techniques and Artificial Neural Networks,Bioinspired Computation in Artificial Systems,10.1007/978-3-319-18833-1_34,Springer,2015-01-01,"The autonomous navigation of robots is one of the main problems among the robots due to its complexity and dynamism as it depends on environmental conditions as the interaction between themselves, persons or any unannounced change in the environment. Pattern recognition has become an interesting research line in the area of robotics and computer vision, however, the problem of perception extends beyond that of classification, main idea is training a specified structure to perform the classifying a given pattern. In this work, we have proposed the application of pattern recognition techniques and neural networks with back propagation learning procedure for the autonomous robots navigation. The objective of this work is to achieve that a robot is capable of performing a path in an unknown environment, through pattern recognition identifying four classes that indicate what action to perform, and then, a dataset with 400 images that were randomly divided with 70% for the training process, 15% for validation and 15% for the test is generated to train by neural network with different configurations. This purpose ROS and robot TurtleBot 2 are used. The paper ends with a critical discussion of the experimental results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-18833-1_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-19719-7_25,Real Time Parallel Robot Direct Kinematic Problem Computation Using Neural Networks,10th International Conference on Soft Computing Models in Industrial and Environmental Applications,10.1007/978-3-319-19719-7_25,Springer,2015-01-01,"The calculation of the Direct Kinematic Problem (DKP) is one of the main issues in real-world applications of Parallel Robots, as iterative procedures have to be applied to compute the pose of the robot. Being this issue critical to robot Real-Time control, in this work a methodology to use Artificial Neural Networks to approximate the DKP is proposed and a comprehensive study is carried out to demonstrate experimentally the Real-Time performance benefits of the approach in a 3PRS parallel robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-19719-7_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-10990-9_19,Neural Network Control of a Four-Wheeled Mobile Robot Subject to Wheel Slip,Mechatronics - Ideas for Industrial Application,10.1007/978-3-319-10990-9_19,Springer,2015-01-01,"The paper presents design of a control structure that enables integration of a kinematic and a neural network controller for a four-wheeled mobile robot subject to wheels slip. The controller is proposed to make the actual velocity of the wheeled mobile robot reach the desired velocity, although the wheeled mobile robot is even with system uncertainties and disturbances. The proposed tracking control system consists of: the kinematic and proportional controller, the neural approximated term and robust term derived from the stability analysis carried out using Lyapunov stability theorem. The proposed control system works on-line, weights adaptation is realized in every discrete step of the control process, and a preliminary learning phase of neural networks weights is not required. Computer simulation was conducted to illustrate performance of the control system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-10990-9_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-26832-3_32,An Optimal Path Planning for Multiple Mobile Robots Using AIS and GA: A Hybrid Approach,Mining Intelligence and Knowledge Exploration,10.1007/978-3-319-26832-3_32,Springer,2015-01-01,"Design of proficient control algorithms for mobile robot navigation in an unknown and changing environment, with obstacles and walls is a complicated task. The objective for building the intelligent planner is to plan actions for multiple mobile robots to coordinate with others and to achieve the global goal by avoiding static and dynamic obstacles. This paper demonstrates a hybrid method of two optimization techniques that are Artificial Immune System (AIS) and Genetic Algorithm (GA). The capability of overcoming the shortcomings of individual algorithms without losing their advantage makes the hybrid techniques superior to the stand-alone ones. The main objective behind this is to improvise the result of a path planning approach than done on AIS and GA separately. The hybridization includes two phases; in first enhancing the local searching ability by AIS and secondly to add stochasticity, instead of choosing random population, the last generation of AIS will be accepted as input to the next process of GA in the hybrid AIS-GA. From the result and observations, it can be inferred that the proposed algorithm is able to efficiently explore the unknown environment by learning from past behavior towards reaching the target. The result obtained from the hybrid algorithm is compared over AIS and GA and found to be more efficient in terms of convergence speed and the time taken to reach at the target, making it a promising approach for solving the mobile robot path planning problem.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-26832-3_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-26532-2_30,"An Autonomous Mobile Robot with Functions of Action Learning, Memorizing, Recall and Identifying the Environment Using Gaussian Mixture Model",Neural Information Processing,10.1007/978-3-319-26532-2_30,Springer,2015-01-01,"In this paper, behavior scheme of autonomous mobile robots to achieve the objectives of them in environments are proposed, having function of identifying the current environment in which they are placed and making use of learning, memorizing and recalling behaviors of corresponding to each of plural different environments. Specifically, each robot has the function of identifying the environment using some behavioral statistical data for each environment, and if the robot has already experienced the environment, it behaves by making use of own experienced data stored in the database, otherwise it performs a new behavior learning and adds the learning results into the database.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-26532-2_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-25032-8_34,A Sense-Think-Act Architecture for Low-Cost Mobile Robotics,Research and Development in Intelligent Systems XXXII,10.1007/978-3-319-25032-8_34,Springer,2015-01-01,"The use of low cost devices to build autonomous robotic systems has gown significantly over recent years. The availability of high quality, low cost micro processors has only furthered this, and the subsequent development in programming paradigms. Development boards, such as the Arduino and Raspberry Pi products, have become a standard in a wide range of these robotic projects. However, there is no universally accepted architecture for using these boards for autonomous robotics. As these are commodity components, any solution must be resilient to any potential failure. This paper investigates the modulation of a robotic platform, to produce a stable and reliable base on which to build automated devices. A further, and critical, motivation is to create a fail safe system in which the loss of a module does not affect performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-25032-8_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-662-46898-2_6,Single-Master-Multi-Slaves Teleoperation,Intelligent Networked Teleoperation Control,10.1007/978-3-662-46898-2_6,Springer,2015-01-01,"Mobile manipulators have been extensively studied because of their reconfigurability and adaptability [265, 306] while multiple mobile manipulators in cooperation can perform a task which is impossible by a single robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-662-46898-2_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-11310-4_61,Adaptive Online Neural Network for Face Identification with Concept Drift,Intelligent Systems'2014,10.1007/978-3-319-11310-4_61,Springer,2015-01-01,Social robots and agents operate in dynamic social environments where number of users as well as their individual features change over time. In order to be able to identify its users the robot should adapt to the ongoing changes continuously. This paper specifies the problem of concept drift for face identification and proposes a solution based on a modification of online neural network.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-11310-4_61,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-26555-1_4,Efficient Motor Babbling Using Variance Predictions from a Recurrent Neural Network,Neural Information Processing,10.1007/978-3-319-26555-1_4,Springer,2015-01-01,"We propose an exploratory form of motor babbling that uses variance predictions from a recurrent neural network as a method to acquire the body dynamics of a robot with flexible joints. In conventional research methods, it is difficult to construct real robots because of the large number of motor babbling motions required. In motor babbling, different motions may be easy or difficult to predict. The variance is large in difficult-to-predict motions, whereas the variance is small in easy-to-predict motions. We use a Stochastic Continuous Timescale Recurrent Neural Network to predict the accuracy and variance of motions. Using the proposed method, a robot can explore motions based on variance. To evaluate the proposed method, experiments were conducted in which the robot learns crank turning and door opening/closing tasks after exploring its body dynamics. The results show that the proposed method is capable of efficient motion generation for any given motion tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-26555-1_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-10783-7_35,Application of Tracking-Learning-Detection for Object Tracking in Stereoscopic Images,Emergent Trends in Robotics and Intelligent Systems,10.1007/978-3-319-10783-7_35,Springer,2015-01-01,"We use Tracking-Learning-Detection algorithm (TLD) [1]-[3] to localize and track objects in images sensed simultaneously by two parallel cameras in order to determine 3D coordinates of the tracked object. TLD method was chosen for its state-of-art performance and high robustness. TLD stores the object to be tracked as a set of 2D grayscale images that is incrementally built. We have implemented the 3D tracking system into a PC, communicating with the Nao humanoid robot [4][5] equipped with a stereo camera head. Experiments evaluating the accuracy of the 3D tracking system are presented. The robot uses feed-forward control to touch the tracked object. The controller is an artificial neural network trained using the error Back-Propagation algorithm. Experiments evaluating the success rate of the robot touching the object are presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-10783-7_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-23485-4_20,A Case Study on the Scalability of Online Evolution of Robotic Controllers,Progress in Artificial Intelligence,10.1007/978-3-319-23485-4_20,Springer,2015-01-01,"Online evolution of controllers on real robots typically requires a prohibitively long evolution time. One potential solution is to distribute the evolutionary algorithm across a group of robots and evolve controllers in parallel. No systematic study on the scalability properties and dynamics of such algorithms with respect to the group size has, however, been conducted to date. In this paper, we present a case study on the scalability of online evolution. The algorithm used is odNEAT, which evolves artificial neural network controllers. We assess the scalability properties of odNEAT in four tasks with varying numbers of simulated e-puck-like robots. We show how online evolution algorithms can enable groups of different size to leverage their multiplicity, and how larger groups can: (i) achieve superior task performance, and (ii) enable a significant reduction in the evolution time and in the number of evaluations required to evolve controllers that solve the task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-23485-4_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-09668-1_7,"Emotion, Artificial Intelligence, and Ethics",Beyond Artificial Intelligence,10.1007/978-3-319-09668-1_7,Springer,2015-01-01,"The growing body of work in the new field of “affective robotics” involves both theoretical and practical ways to instill – or at least imitate – human emotion in Artificial Intelligence (AI), and also to induce emotions toward AI in humans. The aim of this is to guarantee that as AI becomes smarter and more powerful, it will remain tractable and attractive to us. Inducing emotions is important to this effort to create safer and more attractive AI because it is hoped that instantiation of emotions will eventually lead to robots that have moral and ethical codes, making them safer; and also that humans and AI will be able to develop mutual emotional attachments, facilitating the use of robots as human companions and helpers. This paper discusses some of the more significant of these recent efforts and addresses some important ethical questions that arise relative to these endeavors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-09668-1_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-25554-5_47,Social-Task Learning for HRI,Social Robotics,10.1007/978-3-319-25554-5_47,Springer,2015-01-01,"In this paper, we introduce a novel method for learning simultaneously a task and the related social interaction. We present an architecture based on Learning Classifier Systems that simultaneously learns a model of social interaction and uses it to bootstrap task learning, while minimizing the number of interactions with the human. We validate our method in simulation and we prove the feasibility of our approach on a real robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-25554-5_47,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-014-0567-4,Online exploratory behavior acquisition model based on reinforcement learning,Applied Intelligence,10.1007/s10489-014-0567-4,Springer,2015-01-01,"Discernment behavior is an exploratory behavior that supports object feature extraction and is a fundamental tool used by robots to orient themselves, operate objects, and establish knowledge. The main contribution of this paper is to propose an active perception model and analyzes the acquired motion patterns. In this study, we propose an active perception model in which a robot autonomously learns discernment behavior by interacting with multiple objects in its environment. During such interactions, the robot receives reinforcement signals according to the cluster distance of the observed data. In other words, we use a reinforcement learning approach to reward the successful recognition of objects. We apply our proposed model to a mobile robot simulation to observe its effectiveness. Results show that our proposed model effectively established intelligent strategies based on the relationship between object features and the robot’s configuration. In addition, we perform our experiments using real mobile robots and observe the suitability of the observed learned behaviors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-014-0567-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-10380-8_62,Visual Signature for Place Recognition in Indoor Scenarios,CONTROLO’2014 – Proceedings of the 11th Portuguese Conference on Automatic Control,10.1007/978-3-319-10380-8_62,Springer,2015-01-01,"Recognizing a place with a visual glance is the first capacity used by humans to understand where they are. Making this capacity available to robots will make it possible to increase the redundancy of the localization systems available in the robots, and improve semantic localization systems. However, to achieve this capacity it is necessary to build a robust visual signature that could be used by a classifier. This paper presents a new approach to extract a global descriptor from an image that can be used as the visual signature for indoor scenarios. This global descriptor was tested using videos acquired from three robots in three different indoor scenarios. This descriptor has shown good accuracy and computational performance when compared to other local and global descriptors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-10380-8_62,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-94-017-9548-7_74,Behavioral Interactions of Two Individual Arm Robots Using Independent Chaos in Recurrent Neural Networks,Advances in Cognitive Neurodynamics (IV),10.1007/978-94-017-9548-7_74,Springer,2015-01-01,"Based on a heuristic idea and by computer experiment, we show that chaos introduced into a recurrent neural network model can enable “complex control with simple rule(s)” under ill-posed situations. Furthermore, we show behavioral interactions of two individual arm robots driven by independent chaos implemented into each arm control system using recurrent neural networks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-017-9548-7_74,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-18833-1_22,Pyramid Representations of the Set of Actions in Reinforcement Learning,Bioinspired Computation in Artificial Systems,10.1007/978-3-319-18833-1_22,Springer,2015-01-01,"Future robot systems will perform increasingly complex tasks in decreasingly well-structured and known environments. Robots will need to adapt their hardware and software, first only to foreseen, but ultimately to more complex changes of the environment. In this paper we describe a learning strategy based on reinforcement which allows fast robot learning from scratch using only its interaction with the environment, even when the reward is provided by a human observer and therefore is highly non-deterministic and noisy. To get this our proposal uses a novel representation of the action space together with an ensemble of learners able to forecast the time interval before a robot failure",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-18833-1_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-22873-0_24,Vision-Based Automatic Hair Follicular Unit Separation,Intelligent Robotics and Applications,10.1007/978-3-319-22873-0_24,Springer,2015-01-01,"In this paper, a vision-based method is proposed to automatically recognize the hair follicles and plan the cutting path to separate them into units. By using color information and machine learning, hair area in the image can be recognized. And the interferences such as adipose shadows and scalpel parts will be eliminated by texture and area information. In order to recognize single piece of hair, a curve detection method is proposed which combine the linear Hough transform and the quadratic curve fitting method to detect hair pieces with follicles on them. After determining the location and distribution of hair follicles, based on the hair growth direction and the minimum external rectangle of hair area, cutting path will be planned to separate each follicular unit. Compared with the traditional artificial hair follicular unit separation, this method not only ensures the fitting accuracy, but also speeds up the processing speed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-22873-0_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-13407-9_21,Hand Gesture Recognition System Based in Computer Vision and Machine Learning,Developments in Medical Image Processing and Computational Vision,10.1007/978-3-319-13407-9_21,Springer,2015-01-01,"Hand gesture recognition is a natural way of human computer interaction and an area of very active research in computer vision and machine learning. This is an area with many different possible applications, giving users a simpler and more natural way to communicate with robots/systems interfaces, without the need for extra devices. So, the primary goal of gesture recognition research applied to Human-Computer Interaction (HCI) is to create systems, which can identify specific human gestures and use them to convey information or controlling devices. For that, vision-based hand gesture interfaces require fast and extremely robust hand detection, and gesture recognition in real time. This paper presents a solution, generic enough, with the help of machine learning algorithms, allowing its application in a wide range of human-computer interfaces, for real-time gesture recognition. Experiments carried out showed that the system was able to achieve an accuracy of 99.4 % in terms of hand posture recognition and an average accuracy of 93.72 % in terms of dynamic gesture recognition. To validate the proposed framework, two applications were implemented. The first one is a real-time system able to help a robotic soccer referee judge a game in real time. The prototype combines a vision-based hand gesture recognition system with a formal language definition, the Referee CommLang , into what is called the Referee Command Language Interface System (ReCLIS). The second one is a real-time system able to interpret the Portuguese Sign Language. Sign languages are not standard and universal and the grammars differ from country to country. Although the implemented prototype was only trained to recognize the vowels, it is easily extended to recognize the rest of the alphabet, being a solid foundation for the development of any vision-based sign language recognition user interface system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-13407-9_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-18615-3_5,"Tech United Eindhoven, Winner RoboCup 2014 MSL",RoboCup 2014: Robot World Cup XVIII,10.1007/978-3-319-18615-3_5,Springer,2015-01-01,"In this paper we discuss improvements in mechanical, electrical and software design, which we did to become RoboCup 2014 world champion. Regarding hardware and control our progress includes first steps towards improved passing accuracy via velocity feedback control on the shooting lever. In terms of intelligent gameplay we have worked on creating possibilities for in-game optimization of strategic decisions. Via qr-code detection we can pass coaching instructions to our robots and with a basic machine learning algorithm success and failure after free-kicks is taken into account. In the final part of this paper we briefly discuss progress we have made in designing a four-wheeled soccer robot with a suspension system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-18615-3_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-15847-1_7,Hive Collective Intelligence for Cloud Robotics: A Hybrid Distributed Robotic Controller Design for Learning and Adaptation,"Progress in Automation, Robotics and Measuring Techniques",10.1007/978-3-319-15847-1_7,Springer,2015-01-01,"The recent advent of Cloud Computing, inevitably gave rise to Cloud Robotics. Whilst the field is arguably still in its infancy, great promise is shown regarding the problem of limited computational power in Robotics. This is the most evident advantage of Cloud Robotics, but, other much more significant yet subtle advantages can now be identified. Moving away from traditional Robotics, and approaching Cloud Robotics through the prism of distributed systems or Swarm Intelligence offers quite an interesting composure; physical robots deployed across different areas, may delegate tasks to higher intelligence agents residing in the cloud. This design has certain distinct attributes, similar with the organisation of a Hive or bee colony. Such a parallelism is crucial for the foundations set hereinafter, as they express through the hive design, a new scheme of distributed robotic architectures. Delegation of agent intelligence, from the physical robot swarms to the cloud controllers, creates a unique type of Hive Intelligence, where the controllers residing in the cloud, may act as the brain of a ubiquitous group of robots, whilst the robots themselves act as proxies for the Hive Intelligence. The sensors of the hive system providing the input and output are the robots, yet the information processing may take place collectively, individually or on a central hub, thus offering the advantages of a hybrid swarm and cloud controller. The realisation that radical robotic architectures can be created and implemented with current Artificial Intelligence models, raises interesting questions, such as if robots belonging to a hive, can perform tasks and procedures better or faster, and if can they learn through their interactions, and hence become more adaptive and intelligent.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-15847-1_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-21548-8_5,Ethical Regulation of Robots Must Be Embedded in Their Operating Systems,A Construction Manual for Robots' Ethical Systems,10.1007/978-3-319-21548-8_5,Springer,2015-01-01,"The authors argue that unless computational deontic logics (or, for that matter, any other class of systems for mechanizing moral and/or legal principles) or achieving ethical control of future AIs and robots are woven into the operating-system level of such artifacts, such control will be at best dangerously brittle.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-21548-8_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-25554-5_40,An Embodied AI Approach to Individual Differences: Supporting Self-Efficacy in Diabetic Children with an Autonomous Robot,Social Robotics,10.1007/978-3-319-25554-5_40,Springer,2015-01-01,"In this paper we discuss how a motivationally autonomous robot, designed using the principles of embodied AI, provides a suitable approach to address individual differences of children interacting with a robot, without having to explicitly modify the system. We do this in the context of two pilot studies using Robin, a robot to support self-confidence in diabetic children.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-25554-5_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-22979-9_29,Crowdseeding: A Novel Approach for Designing Bioinspired Machines,Biomimetic and Biohybrid Systems,10.1007/978-3-319-22979-9_29,Springer,2015-01-01,"Crowdsourcing is a popular technique for distributing tasks to a group of anonymous workers over the web. Similarly, crowdseeding is any mechanism that extracts knowledge from the crowd, and then uses that knowledge to guide an automated process. Here we demonstrate a method that automatically distills features from a set of robot body plans designed by the crowd, and then uses those features to guide the automated design of robot body plans and controllers. This approach outperforms past work in which one feature was detected and distilled manually. This provides evidence that the crowd collectively possesses intuitions about the biomechanical advantages of certain body plans; we hypothesize that these intuitions derive from their experiences with biological organisms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-22979-9_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-22873-0_32,Recognizing Scenes by Simulating Implied Social Interaction Networks,Intelligent Robotics and Applications,10.1007/978-3-319-22873-0_32,Springer,2015-01-01,"Indoor scene recognition remains a challenging problem for autonomous systems. Recognizing public spaces (e.g., libraries, classrooms), which contain collections of commonplace objects (e.g., chairs, tables), is particularly vexing; different furniture arrangements imply different types of social interaction, hence different scene labels. If people arrange rooms to support social interactions of one type or another, then object relationships that reflect the general notion of social immediacy may resolve some of the ambiguity encountered during scene recognition. We thus describe an approach to indoor scene recognition that uses the context provided by inferred social affordances as input to a hybrid cognitive architecture (ACT-R) that can represent, apply and learn knowledge relevant to classifying scenes. To provide common ground, we demonstrate how sub-symbolic learning processes in ACT-R, which plausibly give rise to human cognition, can mimic the performance of a simple, widely used machine learning technique (k-nearest neighbor classification).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-22873-0_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-662-48558-3_4,Two-layers Local Coordinate Coding,Computer Vision,10.1007/978-3-662-48558-3_4,Springer,2015-01-01,"Extracting informative regularized representations of input signals plays a key role in the field of artificial intelligence, such as machine learning and robotics. Traditional approaches feature $$\ell _2$$ norm and sparse inducing $$\ell _p$$ norm ( $$0 \le p \le 1$$ ) based optimization methods, imposing strict regularization on the representations. However, these approaches overlook the fact that signals and atoms in the overcomplete dictionaries usually contain such wealth of structural information that could improves representations. This paper systematically exploits data manifold geometric structure where signals and atoms reside in, and thus presents a principled extension of sparse coding, i.e. two-layers local coordinate coding, which demonstrates a high dimensional nonlinear function could be locally approximated by a global linear function with quadratic approximation power. Moreover, to learn each latent layer, corresponding patterned optimization approaches are developed, encoding distance information between signals and atoms into the representations. Experimental results demonstrate the significance of this extension on improving the image classification performance and its potential applications for object recognition in robot system are also exploited.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-662-48558-3_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-18615-3_50,"RoboCup Small-Size League: Past, Present and Future",RoboCup 2014: Robot World Cup XVIII,10.1007/978-3-319-18615-3_50,Springer,2015-01-01,"The Small Size Robot League (SSL) was among the founding RoboCup leagues in the 1997 competition held during IJCAI’97 in Nagoya, Japan. Since then, the league has experienced various advances in terms of robot design, number of robots, field size, software algorithms and other infrastructure used during the games, among these the recent standardization of the vision system shared by all teams. The SSL league has been one of the fastest paced leagues in RoboCup where teamwork, coordination, high-level strategies and artificial intelligence have played a critical role in the league development. As robots speeds have greatly increased in the past years, the league has witnessed the development of advanced control and cooperative algorithms. In parallel, shared open software, in particular the shared vision system has made it easier for new teams to join the league. In this paper we discuss the past, present and future of the Small Size League in its path towards the goal of achieving robot vs. human soccer in 2050.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-18615-3_50,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-27343-3_2,A Metrics Framework for Quantifying Autonomy in Complex Systems,Multiagent System Technologies,10.1007/978-3-319-27343-3_2,Springer,2015-01-01,"Autonomous systems, often realized as multi-agent systems, are envisioned to deal with uncertain and dynamic environments. They are applied in dangerous situations, e.g. as rescue robots or to relieve humans from complex and tedious tasks like driving a car or infrastructure maintenance. But in order to further improve the technology a generic measurement and benchmarking of autonomy is required. Within this paper we present an improved understanding of autonomous systems. Based on this foundation we introduce our concept of a multi-dimensional autonomy metric framework that especially takes into account multi-system environments. Finally, our approach is illustrated by means of an example.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-27343-3_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-09668-1_9,Why Are We Afraid of Robots? The Role of Projection in the Popular Conception of Robots,Beyond Artificial Intelligence,10.1007/978-3-319-09668-1_9,Springer,2015-01-01,"The popular conception of robots in fiction, film and the media, as humanoid monsters seeking the destruction of the human race, says little about the future of robotics, but a great deal about contemporary society’s anxieties. Through an examination of the psychoanalytic conception of projection , this essay will examine how robots, cyborgs, androids and AI are constructed in the popular imagination, particularly, how robots come to be feared because they provide unsuitable containers for human projections and how at least part of what we fear in robots is our own idealisation of reason, science and technology.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-09668-1_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-08939-3_7,Artificial Humanoid for the Elderly People,GeNeDis 2014,10.1007/978-3-319-08939-3_7,Springer,2015-01-01,"While frailty and other multi-scale factors have to be correlated during a geriatric assessment, few prototype robots have already been developed in order to measure and provide real-time information, concerning elderly daily activities. Cognitive impairment and alterations on daily functions should be immediate recognized from caregivers, in order to be prevented and probably treated. In this chapter we recognize the necessity of artificial robots during the personal service of the elderly population, not only as a mobile laboratory-geriatrician, but mainly as a socialized digital humanoid able to develop social behavior and activate memories and emotions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-08939-3_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-24589-8_49,[self.]: Realization / Art Installation / Artificial Intelligence: A Demonstration,Entertainment Computing - ICEC 2015,10.1007/978-3-319-24589-8_49,Springer,2015-01-01,"This interactive installation paper describes [self.], an open source art installation where the people interacting with it determine its auditory and visual vocabulary. When the system starts, it knows nothing since the authors have decided that it should be without any kind of bias. However, the robot is equipped with the ability to learn and be creative with what it has internalized. In order to achieve this behaviour, biologically inspired models are implemented. The robot itself is made up of a moving head, mounted with a camera, projector, microphone and speaker. As an art installation, it has a clear robotic visual appearance, although it is designed to demonstrate life-like behaviour. This is done by making the system start in a “tabula rasa” state, forming categories and concepts as it learns through interaction. This is achieved by linking sounds, faces, video and their corresponding temporal information to form novel sentences. The robot also projects an association between sound and image; this is achieved using neural networks. This provides a visual and immediate way of seeing how the internal representations actually learn a certain concept.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-24589-8_49,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-25554-5_24,"“Yes Dear, that Belongs into the Shelf!” - Exploratory Studies with Elderly People Who Learn to Train an Adaptive Robot Companion",Social Robotics,10.1007/978-3-319-25554-5_24,Springer,2015-01-01,"Robot companions should be able to perform a variety of different tasks and to adapt to the user’s needs as well as to changing circumstances. To achieve this we can either built fully adaptive robots or adaptable and customizable robots. In this paper we present an adaptable companion which uses a decision making algorithm and user feedback to learn adequate behavior in new tasks. Using two different scenarios (household task, card game) the system was evaluated with elderly people in exploratory studies. We found that the perception and evaluation of the robot’s learning progress depends on the interaction scenario. Additionally, we discuss improvements for the algorithm in order to make the learning behavior appear more natural and humanlike.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-25554-5_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-16199-0_55,"Neural Network Fusion of Color, Depth and Location for Object Instance Recognition on a Mobile Robot",Computer Vision - ECCV 2014 Workshops,10.1007/978-3-319-16199-0_55,Springer,2015-01-01,"The development of mobile robots for domestic assistance requires solving problems integrating ideas from different fields of research like computer vision, robotic manipulation, localization and mapping. Semantic mapping, that is, the enrichment a map with high-level information like room and object identities, is an example of such a complex robotic task. Solving this task requires taking into account hard software and hardware constraints brought by the context of autonomous mobile robots, where short processing times and low energy consumption are mandatory. We present a light-weight scene segmentation and object instance recognition algorithm using an RGB-D camera and demonstrate it in a semantic mapping experiment. Our method uses a feed-forward neural network to fuse texture, color and depth information. Running at 3 Hz on a single laptop computer, our algorithm achieves a recognition rate of 97 % in a controlled environment, and 87 % in the adversarial conditions of a real robotic task. Our results demonstrate that state of the art recognition rates on a database does not guarantee performance in a real world experiment. We also show the benefit in these conditions of fusing several recognition decisions and data from different sources. The database we compiled for the purpose of this study is publicly available.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-16199-0_55,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-94-017-9548-7_37,Geometry of Dynamic Movement Primitives in Neural Space: A FORCE-Learning Approach,Advances in Cognitive Neurodynamics (IV),10.1007/978-94-017-9548-7_37,Springer,2015-01-01,"Dynamic movement primitives are one of key concepts for understanding dexterous and flexible movements of biological bodies. In the field of robotics engineering, simple types of nonlinear differential equations are used to generate movement primitives from demonstrations, but it remains unclear how nonlinear dynamics in the real brain can also generate movement primitives in biologically natural ways. The aim of this study is to investigate a possible role of nonlinear dynamics in random recurrent neural networks (RNNs) for skillful motor learning. We show that one-shot temporal patterns such arm reaching movements can be trained by a type of RNN-learning so-called FORCE-learning recently proposed by Sussillo and Abbott and a number of patterns are summarized as a manifold embedded in a space of synaptic weights of readout neurons. We also discuss how generalization of learning against untrained motor patterns can be achieved by identifying nonlinear coordinates (meta-parameters) on this manifold in a higher level of the central nervous system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-017-9548-7_37,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-14636-2_5,Punctuated Anytime Learning for Autonomous Agent Control,Control and Systems Engineering,10.1007/978-3-319-14636-2_5,Springer,2015-01-01,"In this chapter we will discuss Punctuated Anytime Learning (PAL), which uses Evolutionary Computation running offline to learn online control programs for autonomous agents. Two methods of PAL will be discussed and considering their strengths and weaknesses they will be employed to learn control programs for autonomous agents operating in two distinct environments. One is a hexapod robot that needs an appropriate gait for its circumstances and the other is a virtual agent operating in Xpilot, the 2D space combat game.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-14636-2_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-09903-3_8,Analysing the Multiple Timescale Recurrent Neural Network for Embodied Language Understanding,Artificial Neural Networks,10.1007/978-3-319-09903-3_8,Springer,2015-01-01,"How the human brain understands natural language and how we can exploit this understanding for building intelligent grounded language systems is open research. Recently, researchers claimed that language is embodied in most – if not all – sensory and sensorimotor modalities and that the brain’s architecture favours the emergence of language. In this chapter we investigate the characteristics of such an architecture and propose a model based on the Multiple Timescale Recurrent Neural Network, extended by embodied visual perception, and tested in a real world scenario. We show that such an architecture can learn the meaning of utterances with respect to visual perception and that it can produce verbal utterances that correctly describe previously unknown scenes. In addition we rigorously study the timescale mechanism (also known as hysteresis) and explore the impact of the architectural connectivity in the language acquisition task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-09903-3_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-287-062-9_6,Sensory Feedback Control of Complex Dynamical Robot Systems,Task-Space Sensory Feedback Control of Robot Manipulators,10.1007/978-981-287-062-9_6,Springer,2015-01-01,Task-space sensory feedback control methods are also effective in dealing with various types of uncertainty in robot systems with more complicated dynamic behavior.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-287-062-9_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-014-0162-x,Intelligent nonlinear observer design for a class of nonlinear discrete-time flexible joint robot,Intelligent Service Robotics,10.1007/s11370-014-0162-x,Springer,2015-01-01,"In this paper, a nonlinear intelligent observer design is applied for a class of nonlinear discrete-time flexible joint robot (DFJR) dynamic system based on artificial neural network (ANN). The DFJR system has a relatively complex nonlinear dynamic and internal states’ estimation of it poses a challenging robotic problem. Multilayer perceptron (MLP) is an important class of feed-forward ANNs that maps set of inputs onto a set of suitable outputs. The ANN under online learning is one of the artificial intelligence methods. Therefore, the MLP neural nonlinear observer is trained online and it is robust in the presence of external and internal uncertainties. The learning method of the intelligent observer is a simple back propagation (BP) algorithm and, furthermore, the learning method of estimation of the link positions and the velocities is BP-developed algorithm. Simulation results show promising performance of the proposed observer in the presence of measurement noise and parameters uncertainties.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-014-0162-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-16841-8_51,Robust Camera Calibration for the MiroSot and the AndroSot Vision Systems Using Artificial Neural Networks,Robot Intelligence Technology and Applications 3,10.1007/978-3-319-16841-8_51,Springer,2015-01-01,"The MirosSot and the AndroSot soccer robots have the ability to recognize, and navigate within, their environments without human intervention. An overhead global camera, usually at a fixed position, is used for the robot’s vision. Because of the lens distortion, images obtained from the camera do not accurately represent the robot’s environment. The distortions affect the coordinates. A technique to calibrate the camera is required to transform the skewed coordinates of the objects in the image to the physical coordinates, which define their real-world position. In this study, a method is proposed for camera calibration using an artificial neural network (ANN) in a two-step process. First, ANN was used to select the camera height and the lens focal lengths for high accuracy. Second, ANN was used to map a coordinate transformation from the camera coordinates to the physical coordinates. During the learning process, the weight of each node in the ANN model changed until the best architecture is reached. The experiments thus resulted in an optimum ANN architecture of 2×4×25×2. The accuracy and efficiency of the camera calibration method were obtained by relearning using the ANN whenever changes to the environmental occurred. Relearning was done using the new input data set for each respective environmental change. Based on our experiments, the average transformation error of the calibration method, using many types of camera, camera positions, camera heights, lens sizes, and focal lengths, was 0.18283 cm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-16841-8_51,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-05350-9_6,Images and Icons in Artificial Intelligence and Robotics,The Visual Language of Technique,10.1007/978-3-319-05350-9_6,Springer,2015-01-01,"Artificial Intelligence and Robotics are Engineering disciplines that took their origin in highly multi-disciplinary environments, and still get contributions from different disciplines of both Engineering, Science, and Humanities. Images in AI and Robotics play many different roles, spanning from support for research and technical achievements, to object itself of research and technical activities, to support for emotion exchange and relationship between people and machines, to icons used as recognizable markers to vulgarize achievements both in the scientific community, and on media aimed at general public information. We discuss these roles and give examples for them.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-05350-9_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-10891-9_2,Cognitive Modeling for Automating Learning in Visually-Guided Manipulative Tasks,"Informatics in Control, Automation and Robotics",10.1007/978-3-319-10891-9_2,Springer,2015-01-01,"Robot manipulators, as general-purpose machines, can be used to perform various tasks. Though, adaptations to specific scenarios require of some technical efforts. In particular, the descriptions of the task result in a robot program which must be modified whenever changes are introduced. Another source of variations are undesired changes due to the entropic properties of systems; in effect, robots must be re-calibrated with certain frequency to produce the desired results. To ensure adaptability, cognitive robotists aim to design systems capable of learning and decision making. Moreover, control techniques such as visual-servoing allow robust control under inaccuracies in the estimates of the system’s parameters. This paper reports the design of a platform called CRR, which combines the computational cognition paradigm for decision making and learning, with the visual-servoing control technique for the automation of manipulative tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-10891-9_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-18833-1_33,Neural Modeling of Hose Dynamics to Speedup Reinforcement Learning Experiments,Bioinspired Computation in Artificial Systems,10.1007/978-3-319-18833-1_33,Springer,2015-01-01,"Two main practical problems arise when dealing with autonomous learning of the control of Linked Multi-Component Robotic Systems (L-MCRS) with Reinforcement Learning (RL): time and space consumption, due to the convergence conditions of the RL algorithm applied, i.e. Q-Learning algorithm, and the complexity of the system model. Model approximate response allows to speedup the realization of RL experiments. We have used a multivariate regression approximation model based on Artificial Neural Networks (ANN), which has achieved a 90% and 27% of time and space savings compared to the conventional Geometrically Exact Dynamic Splines (GEDS) model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-18833-1_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-24309-2_20,Testing a Learn-Verify-Repair Approach for Safe Human-Robot Interaction,AI*IA 2015 Advances in Artificial Intelligence,10.1007/978-3-319-24309-2_20,Springer,2015-01-01,"Ensuring safe behaviors, i.e., minimizing the probability that a control strategy yields undesirable effects, becomes crucial when robots interact with humans in semi-structured environments through adaptive control strategies. In previous papers, we contributed to propose an approach that ( i ) computes control policies through reinforcement learning, ( ii ) verifies them against safety requirements with probabilistic model checking, and ( iii ) repairs them with greedy local methods until requirements are met. Such learn-verify-repair work-flow was shown effective in some — relatively simple and confined — test cases. In this paper, we frame human-robot interaction in light of such previous contributions, and we test the effectiveness of the learn-verify-repair approach in a more realistic factory-to-home deployment scenario. The purpose of our test is to assess whether we can verify that interaction patterns are carried out with negligible human-to-robot collision probability and whether, in the presence of user tuning, strategies which determine offending behaviors can be effectively repaired.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-24309-2_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-17912-4_6,Applications,Introduction to Annotated Logics,10.1007/978-3-319-17912-4_6,Springer,2015-01-01,"This chapter discusses applications of annotated logics for various areas. After reviewing paraconsistent logic programming and generalized annotated logic programming, we survey promising applications to knowledge representation, neural computing, automation and robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-17912-4_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-26555-1_33,Real-Time Robust Model Predictive Control of Mobile Robots Based on Recurrent Neural Networks,Neural Information Processing,10.1007/978-3-319-26555-1_33,Springer,2015-01-01,"This paper presents a novel model predictive control (MPC) approach to tracking control of mobile robots based on recurrent neural networks (RNNs). The tracking control problem is firstly formulated as a sequential dynamic optimization problem in framework of MPC. Then a novel neurodynamic approach is developed for computing the optimal control signals in real time, where multiple RNNs are applied in a collective fashion. The proposed approach enables MPC of mobile robots to be synthesized in real time. Simulation results are provided to substantiate the effectiveness of the proposed approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-26555-1_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-11173-5_3,Robust Control of Robot Arms via Quasi Sliding Modes and Neural Networks,Advances and Applications in Sliding Mode Control systems,10.1007/978-3-319-11173-5_3,Springer,2015-01-01,"This chapter presents a control approach for robotic manipulators based on a discrete-time sliding mode control which has received much less coverage in the literature with respect to continuous time sliding-mode strategies. This is due to its major drawback, consisting in the presence of a sector, of width depending on the available bound on system uncertainties, where robustness is lost because the sliding mode condition cannot be exactly imposed. For this reason, only ultimate boundedness of trajectories can be guaranteed, and the larger the uncertainties affecting the system are, the wider is the bound on trajectories which can be guaranteed. As a possible solution to this problem, in this chapter a discontinuous control law has been proposed, employing a controller inside the sector based on an estimation, as accurate as possible, of the overall effect of uncertainties affecting the system. Different solutions for obtaining this estimate have been considered and the achievable performances have be compared using experimental data. The first approach consists in estimating the uncertain terms by a well established method which is an adaptive on-line procedure for autoregressive modeling of non-stationary multivariable time series by means of a Kalman filtering. In the second solution, radial basis neural networks are used to perform the estimation of the uncertainties affecting the system. The proposed control system is evaluated on the ERICC robot arm. Experimental evidence shows satisfactory trajectory tracking performances and noticeable robustness in the presence of model inaccuracies and payload perturbations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-11173-5_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-20294-5_70,ROBOG Autonomously Navigating Outdoor Robo-Guide,"Swarm, Evolutionary, and Memetic Computing",10.1007/978-3-319-20294-5_70,Springer,2015-01-01,ROBO G : The Robo-Guide is an autonomously navigating vehicle capable of learning the navigational directions of a locality by using Artificial Neural Networks. The main task of ROBO G is to guide people from one location to any other location in a trained region. The prime feature of ROBO G is its simplicity of implementation and working. The map information is learned by Artificial Neural Network using the proposed concept of branch and node. The Multi-Layered Perceptron is trained using the standard Error Back Propagation Algorithm. Road Detection & Tracking and Destination Identification are employed to achieve autonomous navigation. All the Image Processing techniques used are computationally inexpensive. The ROBO G is tested successfully in the outdoor environment for autonomous navigation and due to the simplicity in implementation it can be easily trained for any region.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-20294-5_70,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/2050-5736-2-S1-A25,Robotics and machine learning approaches to improve robustness of USgFUS: FUTURA,Journal of Therapeutic Ultrasound,10.1186/2050-5736-2-S1-A25,BioMed Central,2014-12-10,,https://www.biomedcentral.com/openurl?doi=10.1186/2050-5736-2-S1-A25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12541-014-0622-4,An GPS/DR navigation system using neural network for mobile robot,International Journal of Precision Engineering and Manufacturing,10.1007/s12541-014-0622-4,Springer,2014-12-01,Dead reckoning (DR) is frequently used for mobile robot navigation as it can provide precise short term navigation information but the errors of a DR system can accumulate over time. A global positioning system (GPS) can be used for outside navigation and localization but the error of a single GPS receiver is still big even though an error intentionally introduced into the system called the selective availability policy (SA) was already removed. Standard differential GPS (DGPS) can provide an accuracy of less than one meter but it is too expensive for the mass market aside from the need of having a base station to provide differential data. This paper proposes a new GPS/DR fusion method based on the data characteristics of a cheap single GPS receiver and use neural network to estimate the output of the GPS receiver to provide precise navigation information to the mobile robot. Simulation results validated the performance of the proposed method and showed its potential use in outdoor mobile robot navigation.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12541-014-0622-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10409-014-0074-1,Dynamical analysis and performance evaluation of a biped robot under multi-source random disturbances,Acta Mechanica Sinica,10.1007/s10409-014-0074-1,Springer,2014-12-01,"During bipedal walking, it is critical to detect and adjust the robot postures by feedback control to maintain its normal state amidst multi-source random disturbances arising from some unavoidable uncertain factors. The radical basis function (RBF) neural network model of a five-link biped robot is established, and two certain disturbances and a randomly uncertain disturbance are then mixed with the optimal torques in the network model to study the performance of the biped robot by several evaluation indices and a specific Poincaré map. In contrast with the simulations, the response varies as desired under optimal inputting while the output is fluctuating in the situation of disturbance driving. Simulation results from noise inputting also show that the dynamics of the robot is less sensitive to the disturbance of knee joint input of the swing leg than those of the other three joints, the response errors of the biped will be increasing with higher disturbance levels, and especially there are larger output fluctuations in the knee and hip joints of the swing leg.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10409-014-0074-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-013-0223-x,Interpretation of Social Touch on an Artificial Arm Covered with an EIT-based Sensitive Skin,International Journal of Social Robotics,10.1007/s12369-013-0223-x,Springer,2014-11-01,During social interaction humans extract important information from tactile stimuli that improves their understanding of the interaction. The development of a similar capacity in a robot will contribute to the future success of intuitive human–robot interactions. This paper presents experiments on the classification of social touch on a full-sized mannequin arm covered with touch-sensitive artificial skin. The flexible and stretchable sensitive skin was implemented using electrical impedance tomography. A classifier based on the LogitBoost algorithm was used to classify six emotions and six social messages transmitted by humans when touching the artificial arm. Experimental results show that classification of social touch can be achieved with accuracies comparable to those achieved by humans.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-013-0223-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-014-0325-0,Is Model-Based Robot Programming a Mirage? A Brief Survey of AI Reasoning in Robotics,KI - Künstliche Intelligenz,10.1007/s13218-014-0325-0,Springer,2014-11-01,"Researchers in AI and Robotics have in common the desire to “make robots intelligent”, evidence of which can be traced back to the earliest AI systems. One major contribution of AI to Robotics is the model-centered approach, whereby intelligence is the result of reasoning in models of the world which can be changed to suit different environments, physical capabilities, and tasks. Dually, robots have contributed to the formulation and resolution of challenging issues in AI, and are constantly eroding the modeling abstractions underlying AI problem solving techniques. Forty-eight years after the first AI-driven robot, this article provides an updated perspective on the successes and challenges which lie at the intersection of AI and Robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-014-0325-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11768-014-3181-4,Adaptive-backstepping force/motion control for mobile-manipulator robot based on fuzzy CMAC neural networks,Control Theory and Technology,10.1007/s11768-014-3181-4,Springer,2014-11-01,"In this paper, an adaptive backstepping fuzzy cerebellar-model-articulation-control neural-networks control (ABFCNC) system for motion/force control of the mobile-manipulator robot (MMR) is proposed. By applying the ABFCNC in the tracking-position controller, the unknown dynamics and parameter variation problems of the MMR control system are relaxed. In addition, an adaptive robust compensator is proposed to eliminate uncertainties that consist of approximation errors, uncertain disturbances. Based on the tracking position-ABFCNC design, an adaptive robust control strategy is also developed for the nonholonomicconstraint force of the MMR. The design of adaptive-online learning algorithms is obtained by using the Lyapunov stability theorem. Therefore, the proposed method proves that it not only can guarantee the stability and robustness but also the tracking performances of the MMR control system. The effectiveness and robustness of the proposed control system are verified by comparative simulation results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11768-014-3181-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-014-0155-9,Hybrid trigonometric compound function neural networks for tracking control of a nonholonomic mobile robot,Intelligent Service Robotics,10.1007/s11370-014-0155-9,Springer,2014-10-01,"The purpose of this paper is to propose a hybrid trigonometric compound function neural network (NN) to improve the NN-based tracking control performance of a nonholonomic mobile robot with nonlinear disturbances. In the mobile robot control system, two NN controllers embedded in the closed-loop control system have the simple continuous learning and rapid convergence capability without the dynamics information of the mobile robot to realize the tracking control of the mobile robot. The neuron functions of the hidden layer in the three-layer feedforward network structure consist of the compound cosine function and the compound sine function combining a cosine or a sine function with a unipolar sigmoid function. The main advantages of this NN-based mobile robot control system are better real-time control capability and control accuracy by use of the proposed NN controllers for a nonholonomic mobile robot with nonlinear disturbances. Through simulation experiments applied to the nonholonomic mobile robot with the nonlinear disturbances of dynamics uncertainty and external disturbances, the simulation results show that the proposed NN control system of a nonholonomic mobile robot has better real-time control capability and control accuracy than the compound cosine function NN control system of a nonholonomic mobile robot and then verify the effectiveness of the proposed hybrid trigonometric compound function NN controller for improving the tracking control performance of a nonholonomic mobile robot with nonlinear disturbances.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-014-0155-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-013-1174-8,Exploring aspects of cell intelligence with artificial reaction networks,Soft Computing,10.1007/s00500-013-1174-8,Springer,2014-10-01,"The Artificial Reaction Network (ARN) is a Cell Signalling Network inspired connectionist representation belonging to the branch of A-Life known as Artificial Chemistry. Its purpose is to represent chemical circuitry and to explore computational properties responsible for generating emergent high-level behaviour associated with cells. In this paper, the computational mechanisms involved in pattern recognition and spatio-temporal pattern generation are examined in robotic control tasks. The results show that the ARN has application in limbed robotic control and computational functionality in common with Artificial Neural Networks. Like spiking neural models, the ARN can combine pattern recognition and complex temporal control functionality in a single network, however it offers increased flexibility. Furthermore, the results illustrate parallels between emergent neural and cell intelligence.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-013-1174-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00366-013-0313-2,A neural-network committee machine approach to the inverse kinematics problem solution of robotic manipulators,Engineering with Computers,10.1007/s00366-013-0313-2,Springer,2014-10-01,"In robotics, inverse kinematics problem solution is a fundamental problem in robotics. Many traditional inverse kinematics problem solutions, such as the geometric, iterative, and algebraic approaches, are inadequate for redundant robots. Recently, much attention has been focused on a neural-network-based inverse kinematics problem solution in robotics. However, the result obtained from the neural network requires to be improved for some sensitive tasks. In this paper, a neural-network committee machine (NNCM) was designed to solve the inverse kinematics of a 6-DOF redundant robotic manipulator to improve the precision of the solution. Ten neural networks (NN) were designed to obtain a committee machine to solve the inverse kinematics problem using separately prepared data set since a neural network can give better result than other ones. The data sets for the neural-network training were prepared using prepared simulation software including robot kinematics model. The solution of each neural network was evaluated using direct kinematics equation of the robot to select the best one. As a result, the committee machine implementation increased the performance of the learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00366-013-0313-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-014-0050-9,From the Editor-in-Chief,Journal of Intelligent & Robotic Systems,10.1007/s10846-014-0050-9,Springer,2014-09-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-014-0050-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40309-014-0043-8,"Is the post-human a post-woman? Cyborgs, robots, artificial intelligence and the futures of gender: a case study",European Journal of Futures Research,10.1007/s40309-014-0043-8,Springer,2014-08-31,"This study aims to shed light on the debate about the futures of gender, by taking into account its significance in the current development of Artificial Intelligence (AI), cyborg technologies and robotics. Its reflections are sustained by empirical data obtained between November 2010 and January 2011, when the author engaged in a study related to Gender and Artificial Intelligence at the Department of Cybernetics, University of Reading (England) under the supervision of Professor Kevin Warwick, known as the first human cyborg for his experiments “Cyborg I” (1998) and “Cyborg II” (2002). In this context, the author formulated a questionnaire which was answered by more than one hundred students and researchers of the Department. The specific question motivating this research was: how and to what extent do gender and the intersectional differences characterizing the human species inform the development of cyborgs, robots and AI? The results of the questionnaire, presented in this article, offer original and controversial perspectives on how such epistemological approaches may impact the futures.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40309-014-0043-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-013-1503-y,Swarm robots reinforcement learning convergence accuracy-based learning classifier systems with gradient descent (XCS-GD),Neural Computing and Applications,10.1007/s00521-013-1503-y,Springer,2014-08-01,"This paper presented a novel approach accuracy-based learning classifier system with gradient descent (XCS-GD) to research on swarm robots reinforcement learning convergence. XCS-GD combines covering operator and genetic algorithm. XCS-GD is responsible for adjusting precision and reducing search space according to some reward obtained from the environment, XCS-GD’s innovation discovery component is responsible for discovering new better reinforcement learning rules. The experiment and simulation showed that XCS-GD approach can achieve convergence very quickly in swarm robots reinforcement learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-013-1503-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-014-9384-1,Discovering relevant task spaces using inverse feedback control,Autonomous Robots,10.1007/s10514-014-9384-1,Springer,2014-08-01,"Learning complex skills by repeating and generalizing expert behavior is a fundamental problem in robotics. However, the usual approaches do not answer the question of what are appropriate representations to generate motion for a specific task. Since it is time-consuming for a human expert to manually design the motion control representation for a task, we propose to uncover such structure from data-observed motion trajectories. Inspired by Inverse Optimal Control, we present a novel method to learn a latent value function, imitate and generalize demonstrated behavior, and discover a task relevant motion representation. We test our method, called Task Space Retrieval Using Inverse Feedback Control (TRIC), on several challenging high-dimensional tasks. TRIC learns the important control dimensions for the tasks from a few example movements and is able to robustly generalize to new situations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-014-9384-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12065-014-0111-9,An evolutionary robotics approach for the distributed control of satellite formations,Evolutionary Intelligence,10.1007/s12065-014-0111-9,Springer,2014-08-01,"We propose and study a decentralized formation flying control architecture based on the evolutionary robotic technique. We develop our control architecture for the MIT SPHERES robotic platform on board the International Space Station and we show how it is able to achieve micrometre and microradians precision at the path planning level. Our controllers are homogeneous across satellites and do not make use of labels (i.e. all satellites can be exchanged at any time). The evolutionary process is able to produce homogeneous controllers able to plan, with high precision, for the acquisition and maintenance of any triangular formation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12065-014-0111-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-013-1455-2,Adaptive neural control using reinforcement learning for a class of robot manipulator,Neural Computing and Applications,10.1007/s00521-013-1455-2,Springer,2014-07-01,"In this paper, an adaptive control algorithm is proposed for a class of robot manipulator systems with unknown functions and dead-zone input by using a reinforcement learning scheme. The parameters of the dead zone are supposed to be unknown but bounded. The unknown functions can be approximated based on the neural networks, which is one part of the reinforcement learning scheme, namely an action network. The other part is called critic network which is used to approximate the reinforcement signal. Then, the prominent advantage of the proposed approach is that an optimal control input can be obtained by using two networks compared with the results of robot manipulator with dead zone: an additional term is given to compensate for the effect of the dead zone, and a special design procedure to solve the difficulties in constructing the controllers and adaptation laws. Based on the Lyapunov analysis theory, all the signals of the closed-loop system are proved to be bounded and the system output can track the reference signal to a bounded compact set. Finally, a simulation example is given to illustrate the effectiveness of the approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-013-1455-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-013-1133-4,Bio-insect and artificial robot interaction: learning mechanism and experiment,Soft Computing,10.1007/s00500-013-1133-4,Springer,2014-06-01,"This paper addresses fuzzy-logic-based reinforcement learning architecture and experimental results for the interaction between an artificial robot and a living bio-insect. The main goal of this research is to drag the bio-insect towards the desired goal area without any human aid. To achieve the goal, we seek to design robot intelligence architecture such that the robot can drag the bio-insect using its own learning mechanism. The main difficulties of this research are to find an interaction mechanism between the robot and bio-insect and to design a robot intelligence architecture. In simple interaction experiment, the bio-insect does not react to stimuli such as light, vibration, or artificial robot motion. From various trials-and-error efforts, we empirically found an actuation mechanism for the interaction between the robot and bio-insect. Nevertheless, it is difficult to control the movement of the bio-insect due to its uncertain and complex behavior. For the artificial robot, we design a fuzzy-logic-based reinforcement learning architecture that helps the artificial robot learn how to control the movement of the bio-insect under uncertain and complex behavior. Here, we present the experimental results regarding the interaction between an artificial robot and a bio-insect.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-013-1133-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-013-9857-z,Policy Improvements for Probabilistic Pursuit-Evasion Game,Journal of Intelligent & Robotic Systems,10.1007/s10846-013-9857-z,Springer,2014-06-01,"This paper focuses on a pursuit-evasion game (PEG) which involves two teams: one side consists of pursuers trying to minimize the time required to capture evaders, and the other side consists of evaders trying to maximize the capture time by escaping the pursuers. In this paper, we propose a hybrid pursuit policy for a probabilistic PEG, which possesses the combined merits of local-max and global-max pursuit policies proposed in previous literature. A method to find optimal pursuit and evasion polices for two competitive parties of the pursuers and evaders is also proposed. For this, we employ an episodic parameter optimization (EPO) algorithm to learn good values for the weighting parameters of a hybrid pursuit policy and an intelligent evasion policy. The EPO algorithm is performed during the numerous repeated simulation runs of the PEG and the reward of each episode is updated using reinforcement learning, and the optimal weighting parameters are selected by using particle swarm optimization. We analyze the trend of the optimal parameter values with respect to the number of the pursuers and evaders. The proposed strategy is validated both in simulations and experiments with small ground robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-013-9857-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-013-1121-8,Neural network learning from demonstration and epipolar geometry for visual control of a nonholonomic mobile robot,Soft Computing,10.1007/s00500-013-1121-8,Springer,2014-05-01,"The control of a robot system using camera information is a challenging task regarding unpredictable conditions, such as feature point mismatch and changing scene illumination. This paper presents a solution for the visual control of a nonholonomic mobile robot in demanding real world circumstances based on machine learning techniques. A novel intelligent approach for mobile robots using neural networks (NNs), learning from demonstration (LfD) framework, and epipolar geometry between two views is proposed and evaluated in a series of experiments. A direct mapping from the image space to the actuator command is conducted using two phases. In an offline phase, NN–LfD approach is employed in order to relate the feature position in the image plane with the angular velocity for lateral motion correction. An online phase refers to a switching vision based scheme between the epipole based linear velocity controller and NN–LfD based angular velocity controller, which selection depends on the feature distance from the pre-defined interest area in the image. In total, 18 architectures and 6 learning algorithms are tested in order to find optimal solution for robot control. The best training outcomes for each learning algorithms are then employed in real time so as to discover optimal NN configuration for robot orientation correction. Experiments conducted on a nonholonomic mobile robot in a structured indoor environment confirm an excellent performance with respect to the system robustness and positioning accuracy in the desired location.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-013-1121-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11071-013-0811-1,WiFi assisted NAT traversal scheme for surveillance patrol robot,Nonlinear Dynamics,10.1007/s11071-013-0811-1,Springer,2014-04-01,"With the advances in wireless communication technology and artificial intelligence, robots are gradually being introduced as part of our life. Previous research proposed a SIP-enabled Surveillance Patrol Robot (SSPR), which tracks a moving object actively and informs the householder of such security alarm. However, the underlying signaling protocol for communication and data streams suffer from the network address translation (NAT) traversal problem as most peer-to-peer (P2P) applications. NAT is a commonly adopted technique to share one public IPv4 address among several hosts located behind a NAT device for alleviating the exhaustion of IPv4 address. NAT devices typically block session requests originating from outside, prevent the establishment of peer-to-peer (P2P) sessions and cause NAT traversal problem. This study proposes WANTS, a WiFi Assisted NAT Traversal Scheme for SSPR. When SSPR is activated, it retrieves the topology information from a server to choose the candidate access point (AP) for handoff. Then SSPR uses the collected network context information to assist its NAT traversal procedure after handoff. Experimental results confirm that WANTS reduces not only connectivity check delay but also protocol messages as compared to the Interactivity Connectivity Establishment (ICE), which is the most acknowledged approach to creating a session across NATs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11071-013-0811-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13347-013-0114-y,Machines and the Moral Community,Philosophy & Technology,10.1007/s13347-013-0114-y,Springer,2014-03-01,"A key distinction in ethics is between members and nonmembers of the moral community. Over time, our notion of this community has expanded as we have moved from a rationality criterion to a sentience criterion for membership. I argue that a sentience criterion is insufficient to accommodate all members of the moral community; the true underlying criterion can be understood in terms of whether a being has interests. This may be extended to conscious, self-aware machines, as well as to any autonomous intelligent machines. Such machines exhibit an ability to formulate desires for the course of their own existence; this gives them basic moral standing. While not all machines display autonomy, those which do must be treated as moral patients; to ignore their claims to moral recognition is to repeat past errors. I thus urge moral generosity with respect to the ethical claims of intelligent machines.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13347-013-0114-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-013-0135-8,Cooperative behavior control of robot group using stress antibody allotment reward,Artificial Life and Robotics,10.1007/s10015-013-0135-8,Springer,2014-02-01,"Lately, development in robotics for utilizing in both industry and home is in much progress. In this research, a group of robots is made to handle relatively complicated tasks. Cooperative action among robots is one of the research areas in robotics that is progressing remarkably well. Reinforcement learning is known as a common approach in robotics for deploying acquisition of action under dynamic environment. However, until recently, reinforcement learning is only applied to one agent problem. In multi-agent environment where plural robots exist, it was difficult to differentiate between learning of achievement of task and learning of performing cooperative action. This paper introduces a method of implementing reinforcement learning to induce cooperation among a group of robots where its task is to transport luggage of various weights to a destination. The general Q-learning method is used as a learning algorithm. Also, the switching of learning mode is proposed for reduction of learning time and learning area. Finally, grid world simulation is carried out to evaluate the proposed methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-013-0135-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10994-013-5383-2,Learning perceptually grounded word meanings from unaligned parallel data,Machine Learning,10.1007/s10994-013-5383-2,Springer,2014-02-01,"In order for robots to effectively understand natural language commands, they must be able to acquire meaning representations that can be mapped to perceptual features in the external world. Previous approaches to learning these grounded meaning representations require detailed annotations at training time. In this paper, we present an approach to grounded language acquisition which is capable of jointly learning a policy for following natural language commands such as “Pick up the tire pallet,” as well as a mapping between specific phrases in the language and aspects of the external world; for example the mapping between the words “the tire pallet” and a specific object in the environment. Our approach assumes a parametric form for the policy that the robot uses to choose actions in response to a natural language command that factors based on the structure of the language. We use a gradient method to optimize model parameters. Our evaluation demonstrates the effectiveness of the model on a corpus of commands given to a robotic forklift by untrained users.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10994-013-5383-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-03413-3_31,"Leg Detection and Tracking for a Mobile Robot and Based on a Laser Device, Supervised Learning and Particle Filtering",ROBOT2013: First Iberian Robotics Conference,10.1007/978-3-319-03413-3_31,Springer,2014-01-01,"People detection and tracking is an essential skill to obtain social and interactive robots. Computer vision has been widely used to solve this task but images are affected by noise and illumination changes. Laser range finder is robust against illumination changes so that it can bring useful information to carry out the detection and tracking. In fact, multisensor approaches are showing the best results. In this work, we present a new method to detect and track people using a laser range finder. Patterns of leg are learnt from 2d laser data using supervised learning. Unlike others leg detection approaches, people can be still or moving at the surroundings of the robot. The method of leg detection is used as observation model in a particle filter to track the motion of a person. Experiments in a real indoor environment have been carried out to validate the proposal.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-03413-3_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-03194-1_2,Reinforcement Learning in Robotics: A Survey,Learning Motor Skills,10.1007/978-3-319-03194-1_2,Springer,2014-01-01,"Reinforcement learning offers to robotics a framework and set of tools for the design of sophisticated and hard-to-engineer behaviors. Conversely, the challenges of robotic problems provide both inspiration, impact, and validation for developments in reinforcement learning. The relationship between disciplines has sufficient promise to be likened to that between physics and mathematics. In this article, we attempt to strengthen the links between the two research communities by providing a survey of work in reinforcement learning for behavior generation in robots. We highlight both key challenges in robot reinforcement learning as well as notable successes. We discuss how contributions tamed the complexity of the domain and study the role of algorithms, representations, and prior knowledge in achieving these successes. As a result, a particular focus of our chapter lies on the choice between model-based and model-free as well as between value function-based and policy search methods. By analyzing a simple problem in some detail we demonstrate how reinforcement learning approaches may be profitably applied, and we note throughout open questions and the tremendous potential for future research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-03194-1_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-662-44468-9_47,The Open-Source TEXPLORE Code Release for Reinforcement Learning on Robots,RoboCup 2013: Robot World Cup XVII,10.1007/978-3-662-44468-9_47,Springer,2014-01-01,"The use of robots in society could be expanded by using reinforcement learning (RL) to allow robots to learn and adapt to new situations on-line. RL is a paradigm for learning sequential decision making tasks, usually formulated as a Markov Decision Process (MDP). For an RL algorithm to be practical for robotic control tasks, it must learn in very few samples, while continually taking actions in real-time. In addition, the algorithm must learn efficiently in the face of noise, sensor/actuator delays, and continuous state features. In this paper, we present the texplore ROS code release, which contains texplore , the first algorithm to address all of these challenges together. We demonstrate texplore learning to control the velocity of an autonomous vehicle in real-time. texplore has been released as an open-source ROS repository, enabling learning on a variety of robot tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-662-44468-9_47,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12541-013-0302-9,Non-holonomic agricultural robot with neural network on-line learning controller,International Journal of Precision Engineering and Manufacturing,10.1007/s12541-013-0302-9,Springer,2014-01-01,"The present study represents agricultural applications of non-holonomic mobile robots. Agricultural robots are significantly affected by various disturbances such as a loading capacity and modeling errors of robots. Abundant studies of mobile robots using online learning have investigated real-time elimination of control errors that are associated to inaccurate modeling of robots and controls of disturbance effects by online learning using neural network. However, a certain problem from errors of online learning may occur in case of the robot that is located on out of tracking path. The above problem may be resulted in the difference by control errors occurring between desired values and current values. Therefore, stepwise optimization of robot control with desired values should be necessary. Online learning for agricultural mobile robots is possibly performed with accurate calculation of control errors using the stepwise optimization of desired values as a standard. In summary, the present study demonstrates a reference robot is used to calculate accurate control errors for non-holomic mobile robot that is driven by pulse. The control error of the non-holonomic mobile robot through online feedback-error learning is almost 1.3% in agricultural application.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12541-013-0302-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-94-007-7214-4_12,Solving the Forward Kinematics of Cable-Driven Parallel Robots with Neural Networks and Interval Arithmetic,Computational Kinematics,10.1007/978-94-007-7214-4_12,Springer,2014-01-01,"This paper investigates a new approach for solving the forward kinematics of cable-driven parallel robots. This approach combines an interval algorithm with neural networks to provide a fast but accurate initial guess. The neural networks increase the computation speed by a factor of 200 or more, while the interval algorithm provides guaranteed convergence and a definite solution to any chosen degree of accuracy. Iterative techniques are faster still, but the proposed algorithm is considered real-time feasible.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-007-7214-4_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-03194-1_4,Policy Search for Motor Primitives in Robotics,Learning Motor Skills,10.1007/978-3-319-03194-1_4,Springer,2014-01-01,"Many motor skills in humanoid robotics can be learned using parametrized motor primitives. While successful applications to date have been achieved with imitation learning, most of the interesting motor learning problems are high-dimensional reinforcement learning problems. These problems are often beyond the reach of current reinforcement learning methods. In this chapter, we study parametrized policy search methods and apply these to benchmark problems of motor primitive learning in robotics. We show that many well-known parametrized policy search methods can be derived from a general, common framework. This framework yields both policy gradient methods and expectation-maximization (EM) inspired algorithms. We introduce a novel EM-inspired algorithm for policy learning that is particularly well-suited for dynamical system motor primitives. We compare this algorithm, both in simulation and on a real robot, to several well-known parametrized policy search methods such as episodic REINFORCE, ‘Vanilla’ Policy Gradients with optimal baselines, episodic Natural Actor Critic, and episodic Reward-Weighted Regression. We show that the proposed method out-performs them on an empirical benchmark of learning dynamical system motor primitives both in simulation and on a real robot. We apply it in the context of motor learning and show that it can learn a complex Ball-in-a-Cup task on a real Barrett WAM robot arm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-03194-1_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-28572-1_24,Experiments with Motor Primitives in Table Tennis,Experimental Robotics,10.1007/978-3-642-28572-1_24,Springer,2014-01-01,"Efficient acquisition of new motor skills is among the most important abilities in order to make robot application more flexible, reduce the amount and cost of human programming as well as to make future robots more autonomous. However, most machine learning approaches to date are not capable to meet this challenge as they do not scale into the domain of high dimensional anthropomorphic and service robots. Instead, robot skill learning needs to rely upon task-appropriate approaches and domain insights. A particularly powerful approach has been driven by the concept of re-usable motor primitives. These have been used to learn a variety of “elementary movements” such as striking movements (e.g., hitting a T-ball, striking a table tennis ball), rhythmic movements (e.g., drumming, gaits for legged locomotion, padlling balls on a string), grasping, jumping and many others. Here, we take the approach to the next level and show experimentally how most elements required for table tennis can be addressed using motor primitives. We show four important components: (i) We present a motor primitive formulation that can deal with hitting and striking movements. (ii) We show how these can be initialized by imitation learning and (iii) generalized by reinforcement learning. (iv) We show how selection, generalization and pruning for motor primitives can be dealt with using a mixture of motor primitives. The resulting experimental prototypes can be shown to work well in practice.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-28572-1_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-03194-1_7,Conclusion,Learning Motor Skills,10.1007/978-3-319-03194-1_7,Springer,2014-01-01,"In this book, we have discussed reinforcement learning approaches for motor skills represented by motor primitives. In the next section, we provide an overview of the key contributions in this book and then we discuss possible directions for extending the presented research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-03194-1_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-05582-4_50,Hand-Eye Calibration and Inverse Kinematics of Robot Arm Using Neural Network,Robot Intelligence Technology and Applications 2,10.1007/978-3-319-05582-4_50,Springer,2014-01-01,"Traditional technologies for solving hand-eye calibration and inverse kinematics are cumbersome and time consuming due to the high nonlinearity in the models. An alternative to the traditional approaches is the artificial neural network inspired by the remarkable abilities of the animals in different tasks. This paper describes the theory and implementation of neural networks for hand-eye calibration and inverse kinematics of a six degrees of freedom robot arm equipped with a stereo vision system. The feedforward neural network and the network training with error propagation algorithm are applied. The proposed approaches are validated in experiments. The results indicate that the hand-eye calibration with simple neural network outperforms the conventional method. Meanwhile, the neural network exhibits a promising performance in solving inverse kinematics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-05582-4_50,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-05476-6_48,Artificial Neural Network Based Prediction Model of the Sliding Mode Control in Coordinating Two Robot Manipulators,Intelligent Information and Database Systems,10.1007/978-3-319-05476-6_48,Springer,2014-01-01,The design of a decentralized controlling law in the coordinated transportation area of an object by multiple robot manipulators employing implicit communication between them is a specific alternative in synchronization problems. A decentralized controller is presented in this work which is combination of the sliding mode control and artificial neural network which guarantees robustness in the system. Implicit communication among robot manipulators considers the light weight beam angle in this controller. A multi layer feed forward neural network based prediction model is presented not only to improve trajectory tracking of multiple robots but also to solve the chattering phenomena in the sliding mode control. The simulation results show the effectiveness of the proposed controller on two cooperative PUMA 560 robot manipulators.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-05476-6_48,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-662-44911-0_13,A Curious Vision System for Autonomous and Cumulative Object Learning,"Computer Vision, Imaging and Computer Graphics -- Theory and Applications",10.1007/978-3-662-44911-0_13,Springer,2014-01-01,"We introduce a fully autonomous active vision system that explores its environment and learns visual representations of objects in the scene. The system design is motivated by the fact that infants learn internal representations of the world without much human assistance. Inspired by this, we build a curiosity driven system that is drawn towards locations in the scene that provide the highest potential for learning. In particular, the attention on a stimulus in the scene is related to the improvement in its internal model. This makes the system learn dynamic changes of object appearance in a cumulative fashion. We also introduce a self-correction mechanism in the system that rectifies situations where several distinct models have been learned for the same object or a single model has been learned for adjacent objects. We demonstrate through experiments that the curiosity-driven learning leads to a higher learning speed and improved accuracy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-662-44911-0_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-09339-0_9,Artificial Curiosity Driven Robots with Spatiotemporal Regularity Discovery Ability,Intelligent Computing Methodologies,10.1007/978-3-319-09339-0_9,Springer,2014-01-01,"Autonomous reinforcement learning (RL) robots usually need to learn from raw, high dimensional data generated by visual sensors and often corrupted by noise. These sorts of tasks are quite challenging and cannot be addressed without an efficient mechanism to encode and simplify the raw data. A recent study proposed an artificial curios robot (ACR) for this problem. However, this model is incapable of handling non-Markovian tasks and discovering spatiotemporal patterns in its milieu. This paper presents a method to solve this problem by extending ACR. A straightforward, but not efficient, solution is to keep recoding of previous observations which makes the algorithm intractable. We, instead, construct a perceptual context in a compact way. Using different environments, we show that the proposed algorithm can discover the regularity in its environment without any prior information on the task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-09339-0_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-07230-2_19,A Method for Lifelong Gesture Learning Based on Growing Neural Gas,Human-Computer Interaction. Advanced Interaction Modalities and Techniques,10.1007/978-3-319-07230-2_19,Springer,2014-01-01,"Gesture-based interfaces offer the possibility of an intuitive command language for assistive robotics and ubiquitous computing. As an individual’s health changes with age, their ability to consistently perform standard gestures may decrease, particularly towards the end of life. Thus, such interfaces will need to be capable of learning commands which are not choreographed ahead of time by the system designers. This circumstance illustrates the need for a system which engages in lifelong learning and is capable of discerning new gestures and the user’s desired response to them. This paper describes an innovative approach to lifelong learning based on clustered gesture representations identified through the Growing Neural Gas algorithm. The simulated approach utilizes a user-generated reward signal to progressively refine the response of an assistive robot toward a preferred goal configuration.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-07230-2_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-37835-5_36,Cognitive Emotion Research of Humanoid Expression Robot,Foundations and Practical Applications of Cognitive Systems and Information Processing,10.1007/978-3-642-37835-5_36,Springer,2014-01-01,"Humanoid expression robot is a rising hot spot in the field of Artificial Intelligence (AI), and is very important to the human–computer harmonious interaction. People never stop the humanoid research of robots, which is the trend of the future. This paper wants to discuss three issues. First, can robot have cognitive emotion and show us? Second, how computer or analogous machines simulate complex emotions of human? Can the current emotion theory support and guide the development of cognitive robot? Third, combined with the current techniques and cognitive theory basis, how to design and build humanoid expression robot? Finally, the authors analyze the cognitive basis of emotion theory, and give the robot model and emotion model of cognitive expression.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-37835-5_36,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-05506-0_22,An Adaptive Variable Structure Control Approach Based on Neural Networks and Filter for Four-Wheel Omnidirectional Mobile Robots,Cloud Computing,10.1007/978-3-319-05506-0_22,Springer,2014-01-01,"For dynamic model of a four-wheel omnidirectional mobile robot (FOMR) usually contains parameter uncertainties, in addition, with the influence of exogenous disturbances, the traditional method for motion control has not good performance. An adaptive variable structure control approach based on neural networks and filter (ANFVSC) is presented in this paper. According to the variable structure control theory and Radial Basis Function neural networks, combining the filter, the ANFVSC is applied to deal with the inherent buffeting with normal variable structure control method. The contribution of ANFVSC in improving the control system performance is shown via simulation. The results show that this method has good tracking robustness and a high control precision, simple achievement and effectively eliminated buffeting.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-05506-0_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-08864-8_12,Adaptive Landmark-Based Navigation System Using Learning Techniques,From Animals to Animats 13,10.1007/978-3-319-08864-8_12,Springer,2014-01-01,"The goal-directed navigational ability of animals is an essential prerequisite for them to survive. They can learn to navigate to a distal goal in a complex environment. During this long-distance navigation, they exploit environmental features, like landmarks, to guide them towards their goal. Inspired by this, we develop an adaptive landmark-based navigation system based on sequential reinforcement learning. In addition, correlation-based learning is also integrated into the system to improve learning performance. The proposed system has been applied to simulated simple wheeled and more complex hexapod robots. As a result, it allows the robots to successfully learn to navigate to distal goals in complex environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-08864-8_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-81-322-1695-7_18,Research on Neural Network Predictive Control of Induction Motor Servo System for Robot,Proceedings of International Conference on Soft Computing Techniques and Engineering Application,10.1007/978-81-322-1695-7_18,Springer,2014-01-01,"Neural network control has some applications in many areas; the neural network has strong capability of self-learning, adaptive and fault tolerance, and predictive control for complex systems that has strong adaptability. Through combining the approximation ability of neural network for nonlinear objects and optimization strategy of predictive control, predictive control scheme based on BP neural network has been proposed. In this paper, predictive control algorithm design idea based on BP neural network is proposed: Firstly, by the use of BP neural network model predictive control, the controlled object prediction model can be established, then by taking advantage of the prediction model, based on the input and output information of the current system and the future output values of predict objects, by the use of feedback correction, so as to overcome the model prediction error due to other uncertain disturbance in the system, more accurate predictive value of the object can be obtained. On this basis, based on the future corrected predicted value of the object, with given system output values, the control variable can be scrolling optimized to obtain future system control sequence according to the defined quadratic performance standard. The predictive control has achieved good control effect based on BP neural network; it has proved the feasibility and superiority of this control scheme.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-81-322-1695-7_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-09333-8_26,Visual Servoing of Robot Manipulator Based on Second Order Sliding Observer and Neural Compensation,Intelligent Computing Theory,10.1007/978-3-319-09333-8_26,Springer,2014-01-01,"In this paper, we propose a PD-like visual servoing with second order sliding mode observer and neural network compensation algorithm for planar robot manipulators with only position measurement. This controller is designed based on a combining of a PD controller, neural network compensation and a velocity observer. First, a PD controller is designed as a nominal controller to control robot. Then, in order to compensate the uncertainties, an online learning neural network is designed. Furthermore, the controller incorporates a super-twisting second-order sliding mode observer for estimating the joint velocities; therefore, the velocity measurement is not required. The stability of the closed-loop controller-observer is proved based on the Lyapunov method. Finally, a computer simulation results are presented to evaluate the proposed controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-09333-8_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-05582-4_77,Neural Network Control for the Balancing Performance of a Single-Wheel Transportation Vehicle: Gyrocycle,Robot Intelligence Technology and Applications 2,10.1007/978-3-319-05582-4_77,Springer,2014-01-01,"A single-wheel mobile robot has been developed for carrying a driver. Since a single-wheel mobile robot carries a human driver, the size and weight are larger compared with other sing-wheel mobile robots. To maximize the gyroscopic effects, Gyrocycle is designed to have two flywheels that need to be synchronized. In addition to the synchronization of two flywheels, Gyrocycle is tested for the robust balancing perfromance by unknown payloads. A neural network control method is used to control the balance. Experimental studies are conducted to verify the perfromance by the neural network controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-05582-4_77,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-662-44468-9_24,Motivated Reinforcement Learning for Improved Head Actuation of Humanoid Robots,RoboCup 2013: Robot World Cup XVII,10.1007/978-3-662-44468-9_24,Springer,2014-01-01,"The ability of an autonomous agent to self-localise within its environment is critically dependent on its ability to make accurate observations of static, salient features. This notion has driven considerable research into the development and improvement of feature extraction and object recognition algorithms, both within RoboCup and the robotics community at large. Instead, this paper focuses on the rarely-considered issue imposed by the limited field of view of humanoid robots; namely, determining an optimal policy for actuating a robot’s head, to ensure it observes regions of the environment that will maximise the positional information provided. The complexity of this task is magnified by a number of common computational issues; specifically high dimensional state spaces and noisy environmental observations. This paper details the application of motivated reinforcement learning to partially overcome these issues, leading to an 11% improvement (relative to the null case of uniformly distributed actuation policies) in self-localisation and ball-localisation for an agent trained online for less than one hour. The method is demonstrated as a viable method for improving self-localisation in robotics, without the need for further optimisation of object recognition or tuning of probabilistic filters.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-662-44468-9_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-662-45523-4_63,HyperNEAT Versus RL PoWER for Online Gait Learning in Modular Robots,Applications of Evolutionary Computation,10.1007/978-3-662-45523-4_63,Springer,2014-01-01,"This paper addresses a principal problem of in vivo evolution of modular multi-cellular robots, where robot ‘babies’ can be produced with arbitrary shapes and sizes. In such a system we need a generic learning mechanism that enables newborn morphologies to obtain a suitable gait quickly after ‘birth’. In this study we investigate and compare the reinforcement learning method RL PoWeR with HyperNEAT. We conduct simulation experiments using robot morphologies with different size and complexity. The experiments give insights into the differences in solution quality and algorithm efficiency, suggesting that reinforcement learning is the preferred option for this online learning problem.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-662-45523-4_63,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-05431-5_10,Mathematical Modeling of Human Affective Behavior Aimed to Design Robot EI-Controller,New Trends in Medical and Service Robots,10.1007/978-3-319-05431-5_10,Springer,2014-01-01,"The chapter regards to building emotion-driven behavior and social development in robots based on theory of personality from personality psychology. More precisely, the chapter concerns with modeling attributes of human emotional intelligence with aim to develop robot EI-controller capable to manage and use emotions, mange relationship with others and increase the autonomy. Brief theoretical background of personality psychology, regarding categorization of human personality types and types of temperament are presented in the chapter, too. Besides, it will be analyzed how differences amongst personality traits determine human affective and social behavior in circumstances of different physical and social environmental conditions. Based on the theory from psychology, a generic model of human emotion-driven behavior as an element of emotional intelligence is proposed. Corresponding simulator is developed in the chapter, too. Designed EI-model is tested in simulation experiments. For this purpose, a “trigger” (an emotion-causal event) is assumed. Different personality profiles, exterior and interior influencing factors are varied in simulation tests. Proposed model is validated by comparison of the simulation results and results obtained experimentally by using results of the tests of human examinees. The on-line psychological questionnaires available at the Internet were used as appropriate tests.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-05431-5_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-08201-1_16,A Multi-agent Efficient Control System for a Production Mobile Robot,Neural Networks and Artificial Intelligence,10.1007/978-3-319-08201-1_16,Springer,2014-01-01,"This paper presents the results of the experiments of a multi-agent control architecture for the efficient control of a multi-wheeled mobile platform. Multi-agent system incorporates multiple Q-learning agents, which permits them to effectively control every wheel relative to other wheels. The learning process was divided into two steps: module positioning – where the agents learn to minimize the error of orientation and cooperative movement – where the agents learn to adjust the desired velocity in order to conform to the desired position in formation. From this decomposition every module agent will have two control policies for forward and angular velocity, respectively. The experiments were carried out with a real robot. Our results indicate the successful application of the proposed control architecture for the real production robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-08201-1_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-662-43645-5_2,Heuristically-Accelerated Reinforcement Learning: A Comparative Analysis of Performance,Towards Autonomous Robotic Systems,10.1007/978-3-662-43645-5_2,Springer,2014-01-01,"This paper presents a comparative analysis of three Reinforcement Learning algorithms (Q-learning, Q( $$\lambda $$ )-learning and QS-learning) and their heuristically-accelerated variants (HAQL, HAQ( $$\lambda $$ ) and HAQS) where heuristics bias action selection, thus speeding up the learning. The experiments were performed in a simulated robot soccer environment which reproduces the conditions of a real competition league environment. The results clearly demonstrate that the use of heuristics substantially improves the performance of the learning algorithms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-662-43645-5_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-08979-9_22,A Robot Waiter Learning from Experiences,Machine Learning and Data Mining in Pattern Recognition,10.1007/978-3-319-08979-9_22,Springer,2014-01-01,"In this contribution, we consider learning tasks of a robot simulating a waiter in a restaurant. The robot records experiences and creates or adapts concepts represented in the web ontology language OWL 2, extended by quantitative spatial and temporal information. As a typical task, the robot is instructed to perform a specific activity in a few concrete scenarios and then expected to autonomously apply the conceptualized experiences to a new scenario. Constructing concepts from examples in a formal knowledge representation framework is well understood in principle, but several aspects important for realistic applications in robotics have remained unattended and are addressed in this paper. First, we consider conceptual representations of activity concepts combined with relevant factual knowledge about the environment. Second, the instructions can be coarse, confined to essential steps of a task, hence the robot has to autonomously determine the relevant context. Third, we propose a ”Good Common Subsumer” as opposed to the formal ”Least Common Subsumer” for the conceptualization of examples in order to obtain cognitively plausible results. Experiments are based on work in Project RACE where a PR2 robot is employed for recording experiences, learning and applying the learnt concepts.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-08979-9_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-4585-42-2_40,Using Time Proportionate Intensity Images with Non-linear Classifiers for Hand Gesture Recognition,"The 8th International Conference on Robotic, Vision, Signal Processing & Power Applications",10.1007/978-981-4585-42-2_40,Springer,2014-01-01,"Gestures are signals that contain important spatiotemporal information. Understanding gestures is a trivial task for humans, but for machines it is a challenging task involving thousands of computations per video frame. This paper investigates an efficient hand gesture recognition technique which is based on time projections of the hand location. For recognition, non-linear classifiers, namely Support Vector Machines and Artificial Neural Networks, are tested. The proposed method performs much faster than the conventional Markov Model based gesture recognition techniques while achieving comparable recognition results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-4585-42-2_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-09333-8_30,An Adaptive Tracking Controller for Differential Wheeled Mobile Robots with Unknown Wheel Slips,Intelligent Computing Theory,10.1007/978-3-319-09333-8_30,Springer,2014-01-01,This paper investigates the tracking control of mobile robot in the presence of wheel slip and external disturbance forces. An adaptive tracking controller is proposed based on a three-layer neural networks. The uncertainties due to the wheel slip and external force are compensated online by neural networks. The stability of the closed-loop system is ensured by using Lyapunov method. The validity of the proposed controller is confirmed by a simulation example of tracking a circle trajectory.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-09333-8_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-13650-9_35,AI-Based Design of a Parallel Robot Used as a Laser Tracker System: Intelligent vs. Nonlinear Classical Controllers,Nature-Inspired Computation and Machine Learning,10.1007/978-3-319-13650-9_35,Springer,2014-01-01,"Classical ways for coordinate measuring devices are manual theodolites, photogrammetry-based systems, total stations and a recently-introduced device referred to as laser tracker systems. Basically, a laser tracker system is a more accurate and reliable 3D measurement tool that allows to increase and maintain accuracy as time goes by. Laser tracker systems deals with industry-based measuring problems which can be alignment, reverse engineering, tool building, part inspection, installation, and manufacturing and assembly integration. A very interesting case of the latter is robot-tracking calibration in an welding line. In a welding line, robots are controlled in order to keep a prescribed trajectory to accomplish its welding task properly. Nevertheless, in spite of a good control algorithm design, as time goes by, deviations appear and some maintenance has to be done on the robotic unit. So, robot calibration can be done with a laser tracker. Although laser tracker systems are made by very well established and serious companies, their laser products may be very expensive for small or medium size industries. Our contribution is to offer a parallel robot-based laser tracker system model whose implementation would result cheaper than sophisticated laser devices and takes advantage of the parallel robot bondages as high payload. As a first step, simulations of the controlled systems are done here. This parallel robot-based laser tracker is designed to help in the calibration process which consists in repeating some specified trajectory for the serial (welding) robot. The laser tracker system tracks the welding robot trajectory in a day-by-day period of time (for instance) in order to identify the moment when a deviation of the reference trajectory happens. Hence, corrections can be done avoiding greater problems in the welding line. In order to design the parallel robot-based tracker system, a kinematic analysis and a dynamical modeling have to be done in order to design a set of controllers which will be assessed. All of it assisted by AI (artificial intelligence) algorithms. The laser tracker kinematic analysis was done assisted by ANN (artificial neural networks) and by GA (genetic algorithms). This fact allowed to compute numerically/graphically the laser tracker workspace in order to warrant the right accessibility of the corresponding 3D (three dimensional) space. A dynamical model which represents the parallel robot-based laser tracker system was also obtained. This model was used by our set of controllers. The controller design is split into two groups: One considers AI-based algorithms and the second one, classical design-based controllers. A comparison between the two groups is done and advantages/disadvantages are shown in terms of performance in the presence of a persistent perturbation which models ground vibrations in the factory the welding robots are. Such vibrations are endlessly present because they are produced by other assembling machines which disturb the welding process. So, in spite of this perturbation our parallel robot-based laser tracker system showed to behave well with Intelligent Control keeping good tracking of a sinusoidal welding calibration trajectory in the serial robot. In this work it is assumed that a laser device is mounted in the parallel robot with inertial dynamical effect on the parallel robot. Analytical developments are provided as well as numerical/graphical solutions done in MATLAB/SIMULINK to deal with this complex dynamical system. An integral viewpoint with ANN, GA, and Fuzzy Logic was used in this study.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-13650-9_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-08189-2_12,"Understanding the Foundations and Devices in Humour to Determine Practical Design Methods for Systems That Create and/or Detect Humour in Video Games, Robots and other Forms of Artificial Intelligence",Intelligent Technologies for Interactive Entertainment,10.1007/978-3-319-08189-2_12,Springer,2014-01-01,"There have been numerous attempts to understand humour’s nature and meanings and a few attempts to formalize the sum of this knowledge but the practical aspects of humour recognition and creation have not been given the same level of attention. In a 14 year study of stand-up comedy, social humour, and other humourous forms I have attempted to isolate specific devices that can be utilized in the creation of humour in video games, avatars, robots, and other forms of artificial intelligence. The human experience of humour also involves the frequent repetition of previously experienced humour termed in this paper as ""repeatables"". A comprehensive use of devices and ""repeatables"" combined with an understanding of the role of humour in the evolution of human cognition, language, and social systems has the potential to yield an improved ability to entertain, educate, and communicate in digital formats.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-08189-2_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-09979-8_7,Passive Brain-Computer Interfaces for Robot-Assisted Rehabilitation,Brain-Computer Interface Research,10.1007/978-3-319-09979-8_7,Springer,2014-01-01,"Stroke patients must exercise intensely with rehabilitation robots to achieve satisfactory rehabilitation outcome, but ensuring appropriate exercise difficulty is a challenging task. Brain-computer interfaces would be suitable for such difficulty adaptations since they capture both conscious and subconscious aspects of workload, but have seen little use in rehabilitation. This chapter reviews previous work on passive brain–computer interfaces and highlights the practical challenges of applying the technology to motor rehabilitation. Preliminary results of a study on workload estimation in a rehabilitation robot with healthy subjects are then presented. Adaptive stepwise regression is used to estimate different types of workload from electroencephalography signals recorded at different sites. Results show that electroencephalography can achieve more accurate workload estimation than autonomic nervous system responses and that adaptive estimation methods can further improve accuracy. However, the number of electrode sites needs to be reduced and issues such as motion artefacts must be resolved before passive brain-computer interfaces can be used in motor rehabilitation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-09979-8_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-03413-3_18,Haptic Feedback in Surgical Robotics: Still a Challenge,ROBOT2013: First Iberian Robotics Conference,10.1007/978-3-319-03413-3_18,Springer,2014-01-01,"Endowing current surgical robotic systems with haptic feedback to perform minimally invasive surgery (MIS), such as laparoscopy, is still a challenge. Haptic is a feature lost in surgical teleoperated systems limiting surgeons capabilities and ability. The availability of haptics would provide important advantages to the surgeon: Improved tissue manipulation, reducing the breaking of sutures and increase the feeling of telepresence, among others. To design and develop a haptic system, the measurement of forces can be implemented based on two approaches: Direct and indirect force sensing. MIS performed with surgical robots, imposes many technical constraints to measure forces, such as: Miniaturization, need of sterilization or materials compatibility, making it necessary to rely on indirect force sensing. Based on mathematical models of the components involved in an intervention and indirect force sensing techniques, a global perspective on how to address the problem of measurement of tool-tissue interaction forces is presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-03413-3_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-09435-9_19,I-CLIPS Brain: A Hybrid Cognitive System for Social Robots,Biomimetic and Biohybrid Systems,10.1007/978-3-319-09435-9_19,Springer,2014-01-01,"Sensing and interpreting the interlocutor’s social behaviours is a core challenge in the development of social robots. Social robots require both an innovative sensory apparatus able to perceive the “social and emotional world” in which they act and a cognitive system able to manage this incoming sensory information and plan an organized and pondered response. In order to allow scientists to design cognitive models for this new generation of social machines, it is necessary to develop control architectures that can be easily used also by researchers without technical skills of programming such as psychologists and neuroscientists. In this work an innovative hybrid deliberative/reactive cognitive architecture for controlling a social humanoid robot is presented. Design and implementation of the overall architecture take inspiration from the human nervous system. In particular, the cognitive system is based on the Damasio’s thesis. The architecture has been preliminary tested with the FACE robot. A social behaviour has been modeled to make FACE able to properly follow a human subject during a basic social interaction task and perform facial expressions as a reaction to the social context.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-09435-9_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-05582-4_64,Bowling with the DARwIn-Op Humanoid Robot,Robot Intelligence Technology and Applications 2,10.1007/978-3-319-05582-4_64,Springer,2014-01-01,"In this paper, we will describe our approach in building an application, which empowers the DARwIn-OP Humanoid robot to play a bowling game. The main difficulties of bowling, in both humans and robots, is steady walking control, vision processing to detect the pins and ball, precise localization of the ball and decision-making of angles to throw. The aim of this project is to contribute to better and more enjoyable robot and human interaction as well as to humanoid robot research area.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-05582-4_64,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-4585-36-1_8,Adaptive Trajectory Tracking of Wheeled Mobile Robot with Uncertain Parameters,Computational Intelligence for Decision Support in Cyber-Physical Systems,10.1007/978-981-4585-36-1_8,Springer,2014-01-01,"A wheeled mobile robot (WMR) belongs to the class of non-holonomic systems with highly nonlinear dynamics. Because of their fast maneuvering and energy saving characteristics, these robots are especially popular in following or tracking a pre-defined trajectory. The trajectory of a WMR is controlled with the help of two very different control schemes namely model dependent approach and model free approach. While the model dependent approach relies on a particular model for the controller design, the model free method controls the trajectory with the help of learning methods. A Direct Model Reference Adaptive Controller (D-MRAC) is described for the model based technique, while an Adaptive Neuro-Fuzzy Inference System (ANFIS) is used for the model-free adaptive control design. With the help of simulations, it is shown that data driven intelligent approach is comparable to model dependent approach in terms of tracking performance and therefore can be preferred over complex model dependent adaptive algorithms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-4585-36-1_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-11973-1_8,Real-Time Gender Based Behavior System for Human-Robot Interaction,Social Robotics,10.1007/978-3-319-11973-1_8,Springer,2014-01-01,"This work introduces a real-time system able to lead humanoid robot behavior depending on the gender of the interacting person. It exploits Aldebaran NAO humanoid robot view capabilities by applying a gender prediction algorithm based on the face analysis. The system can also manage multiple persons at the same time, recognizing if the group is composed by men, women or is a mixed one and, in the latter case, to know the exact number of males and females, customizing its response in each case. The system can allow for applications of human-robot interaction requiring an high level of realism, like rehabilitation or artificial intelligence.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-11973-1_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-04033-2_19-1,Nanotechnology-Neuroscience Convergence,Handbook of Science and Technology Convergence,10.1007/978-3-319-04033-2_19-1,Springer,2014-01-01,"Roco et al. 2013 introduced the convergence of nanotechnology with biotechnology, information technology, and cognitive technology (NBIC) as a main trend in science and technology. They also provided a list of 20 visionary ideas for the next 10–30 years. According to their ideas, in the next 20 years, we expect to have humanlike intelligent robots, smartphones with real-time language translating function, and pocket-sized supercomputers through the advance in the NBIC. To pave the way for this, every computing system should be flexible, mobile, self-programmable, real time, and even self-learning. However, as the miniaturization trend continues following Moore’s law, it would be impractical to apply the current nanoelectronics to future computing systems due to enormous energy consumption and technological limits. Accordingly, the architecture and the functions of transistors used in the present computing system need to be improved and inspired by the human brain. Unfortunately, it is unclear how neural activities in the human brain result in cognitive process Cognitive process es such as learning and reasoning. Nevertheless, the convergence of neuroscience with nanotechnology is expected to bring us closer to building neuro-inspired chips for neurocomputers utilizing some clues on neural activity and structure. In this chapter, we will show various scientific problems and challenges in realizing neuro-inspired chips.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-04033-2_19-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12541-013-0306-5,Prediction and compensation of relative position error along industrial robot end-effector paths,International Journal of Precision Engineering and Manufacturing,10.1007/s12541-013-0306-5,Springer,2014-01-01,"In on-line and especially in off-line programming of industrial robots the attainable accuracy has to be taken into account. Especially in the case of off-line programming along particular trajectories followed, neglecting position errors leads to a need for kinematic calibration procedures which, however, apply to the robot controller level. If end effector error is taken into consideration in off-line programming a compensated commanded trajectory can be programmed. This is different to well-established calibration procedures, because it keeps the original kinematic model of the robot and tries to improve accuracy along the particular trajectory of interest. In this paper, the methodology for measuring, predicting and compensating end effector position errors is presented. A straight line trajectory is used as an example in connection to a particular industrial robotic arm. Measurements are taken using white-light metrology. Based on these measurements an error prediction model is constructed by training an Artificial Neural Network. A second neural network model is trained to yield joint coordinates that minimise position error, which is proved by employing the prediction model on the results of the compensation model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12541-013-0306-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-07650-8_23,Multi-robot Hunting Using Mobile Agents,Agent and Multi-Agent Systems: Technologies and Applications,10.1007/978-3-319-07650-8_23,Springer,2014-01-01,"Multi-robot hunting problem is one of the popular issues treated with multi-robot systems. The purpose of the problem is to search and capture a target using an invisible signal, through which the multirobots can sense the distance to the target. This paper proposes a new method in which the multiple robots cooperatively search for a target using mobile agents. In the method, we employ multiple mobile software agents. The mobile agents traverse mobile robots through migrations while collecting the information of the target. Since each robot just needs to establish a connection with another robot for migration of a mobile agent, our method reduces the total communication cost of the system. Also, the mobile agents’ migration manner is restricted within the view range of the camera of a robot, and thus mainly makes robots around the target active, which contributes to suppressing moving cost. We have implemented a simulator for the mobile agents based hunting system. We show the effectiveness of our method through numerical experiments on the simulator.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-07650-8_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-09952-1_9,"Evolutionary Swarm Robotics: Genetic Diversity, Task-Allocation and Task-Switching",Swarm Intelligence,10.1007/978-3-319-09952-1_9,Springer,2014-01-01,"The goal of this study is to investigate the role of genetic diversity for engineering more resilient evolutionary swarm robotic systems. The resilience of the swarm is evaluated with respect to the capability of the system to re-distribute agents to tasks in response to changes in operating conditions. We compare the performances of two evolutionary approaches: the clonal approach in which the teams are genetically homogeneous, and the aclonal approach in which the teams are genetically heterogeneous. We show that the aclonal approach outperforms the clonal approach for the design of robot teams engaged in two task-allocation scenarios, and that heterogeneous teams tend to rely on less plastic strategies. The significance of this study for evolutionary swarm robotics is discussed and directions for future work are indicated.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-09952-1_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-11973-1_39,Adaptive Object Learning for Robot Carinet,Social Robotics,10.1007/978-3-319-11973-1_39,Springer,2014-01-01,"In this paper, an adaptive object learning method based on deep neural network is developed for a robot to learn features of moving objects, e.g., humans and vehicles, via observation. The proposed method provides a solution for the robot to learn unknown moving objects in a real-time scenario. A hybrid scheme of learning and identification is proposed to recognize the moving object by fusion of foreground segmentation and identification.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-11973-1_39,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-07176-3_26,Globalised Dual Heuristic Dynamic Programming in Tracking Control of the Wheeled Mobile Robot,Artificial Intelligence and Soft Computing,10.1007/978-3-319-07176-3_26,Springer,2014-01-01,"The paper presents an application of the Approximate Dynamic Programming algorithm in Globalised Dual Heuristic Dynamic Programming configuration in the tracking control problem of the wheeled mobile robot Pioneer 2-DX. The Globalised Dual Heuristic Dynamic Programming algorithm is realised in the form of two structures, the actor and the critic, that can be implemented in the form of any adaptive algorithm, e.g. Artificial Neural Networks. The actor generates the suboptimal control law, the critic approximates the value function and its difference with respect to the states, what is equal to evaluation of the realised control law. The discrete tracking control system is composed of the Globalised Dual Heuristic Dynamic Programming algorithm, the PD controller and the supervisory term, which structure derives from the stability analysis realised using the Lapunov stability theorem. The proposed control system works on-line and its performance was verified using the wheeled mobile robot Pioneer 2-DX.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-07176-3_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-01466-1_11,Global Path Planning in Grid-Based Environments Using Novel Metaheuristic Algorithm,ICT Innovations 2013,10.1007/978-3-319-01466-1_11,Springer,2014-01-01,"The global path planning problem is very challenging NP-complete problem in the domain of robotics. Many metaheuristic approaches have been developed up to date, to provide an optimal solution to this problem. In this work we present a novel Quad-Harmony Search (QHS) algorithm based on Quad-tree free space decomposition methodology and Harmony Search optimization. The developed algorithm has been evaluated on various grid based environments with different percentage of obstacle coverage. The results have demonstrated that it is superior in terms of time and optimality of the solution compared to other known metaheuristic algorithms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-01466-1_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-09051-1_4,[5.1] to [5.2] Moderate Versions of the Inflection Point and Positive Derivative,Toward Post Ageing,10.1007/978-3-319-09051-1_4,Springer,2014-01-01,"In the discussion of the shift from [4.0] to the different versions of [5.x] inflection points, we will introduce a secondary degree typology to categorize the developments along the change in direction (and along the positive derivative) using the labels of moderate and radical regarding the intersection of technology with ageing issues. The demarcation between the two will be determined by the direct relevance to and association with the GRIN technologies (Garreau 2005 ), ( genetic, robotic, information, and nano processes). The moderate versions of the [5.x] inflection point have ample connections and references to technology and Ageing in the publications and still represent the prevailing view, but the topics have primarily focused on assistive technology, the human factor, applied psychology and cognitive science (see Helal et al. 2008 ).The moderate versions have focused on the use of the Internet by older adults, computer-mediated and computer-based communication, household and safety monitoring, and tele-health applications (see Grierson et al. 2009 ; Kang et al. 2010 ; Orlov 2010 ). In order to reach the radical version of the emergent inflection point—and thus merit a greater inflection point “score” [5.x]—the publication would have to explicitly indicate the intersection of technologies and bioengineering issues with the ageing process to which Garreau ( 2005 ) has alluded.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-09051-1_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-11973-1_33,Integrating Reinforcement Learning and Declarative Programming to Learn Causal Laws in Dynamic Domains,Social Robotics,10.1007/978-3-319-11973-1_33,Springer,2014-01-01,"Robots deployed to assist and collaborate with humans in complex domains need the ability to represent and reason with incomplete domain knowledge, and to learn from minimal feedback obtained from non-expert human participants. This paper presents an architecture that combines the complementary strengths of Reinforcement Learning (RL) and declarative programming to support such commonsense reasoning and incremental learning of the rules governing the domain dynamics. Answer Set Prolog (ASP), a declarative language, is used to represent domain knowledge. The robot’s current beliefs, obtained by inference in the ASP program, are used to formulate the task of learning previously unknown domain rules as an RL problem. The learned rules are, in turn, encoded in the ASP program and used to plan action sequences for subsequent tasks. The architecture is illustrated and evaluated in the context of a simulated robot that plans action sequences to arrange tabletop objects in desired configurations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-11973-1_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-09435-9_17,Capturing Stochastic Insect Movements with Liquid State Machines,Biomimetic and Biohybrid Systems,10.1007/978-3-319-09435-9_17,Springer,2014-01-01,A Liquid State Machine (LSM) is trained to model the stochastic behavior of a cockroach exploring an unknown environment. The LSM is a recurrent neural network of leaky-integrate-and-fire neurons interconnected by synapses with intrinsic dynamics and outputs to an Artificial Neural Network (ANN). The LSM is trained by a reinforcement approach to produce a probability distribution over a discrete control space which is then sampled by the controller to determine the next course of action. The LSM is able to capture several observed phenomenon of cockroach exploratory behavior including resting under shelters and wall following.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-09435-9_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-662-45523-4_62,Speeding Up Online Evolution of Robotic Controllers with Macro-neurons,Applications of Evolutionary Computation,10.1007/978-3-662-45523-4_62,Springer,2014-01-01,"In this paper, we introduce a novel approach to the online evolution of robotic controllers. We propose accelerating and scaling online evolution to more complex tasks by giving the evolutionary process direct access to behavioural building blocks prespecified in the neural architecture as macro-neurons . During task execution, both the structure and the parameters of macro-neurons and of the entire neural network are under evolutionary control. We perform a series of simulation-based experiments in which an e-puck-like robot must learn to solve a deceptive and dynamic phototaxis task with three light sources. We show that: (i) evolution is able to progressively complexify controllers by using the behavioural building blocks as a substrate, (ii) macro-neurons, either evolved or preprogrammed, enable a significant reduction in the adaptation time and the synthesis of high performing solutions, and (iii) evolution is able to inhibit the execution of detrimental task-unrelated behaviours and adapt non-optimised macro-neurons.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-662-45523-4_62,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-08864-8_14,Developmental Dynamics of RNNPB: New Insight about Infant Action Development,From Animals to Animats 13,10.1007/978-3-319-08864-8_14,Springer,2014-01-01,"Developmental studies have suggested that infants’ action is goal-directed. When imitating an action, younger infants tend to reproduce the goal while ignoring the means (i.e., the movement to achieve the goal) whereas older infants can imitate both. We suggest that the developmental dynamics of a Recurrent Neural Network with Parametric Bias (RNNPB) may explain the mechanism of infant development. Our RNNPB model was trained to reproduce six types of actions (2 different goals x 3 different means), during which parametric biases were self-organized to represent the difference with respect to both the goal and means. Our analysis of the self-organizing process of the parametric biases revealed an infant-like developmental change in action learning: the RNNPB first adapted to the goal and then to the means. The different saliency of these two features caused this phased development. We discuss the analogy of our result to infant action development.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-08864-8_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-08864-8_7,Multiple Decoupled CPGs with Local Sensory Feedback for Adaptive Locomotion Behaviors of Bio-inspired Walking Robots,From Animals to Animats 13,10.1007/978-3-319-08864-8_7,Springer,2014-01-01,"Walking animals show versatile locomotion. They can also adapt their movement according to the changes of their morphology and the environmental conditions. These emergent properties are realized by biomechanics, distributed central pattern generators (CPGs), local sensory feedback, and their interactions during body and leg movements through the environment. Based on this concept, we present here an artificial bio-inspired walking system. Its intralimb coordination is formed by multiple decoupled CPGs while its interlimb coordination is attained by the interactions between body dynamics and the environment through local sensory feedback of each leg. Simulation results show that this bio-inspired approach generates self-organizing emergent locomotion allowing the robot to adaptively form regular patterns, to stably walk while pushing an object with its front legs or performing multiple stepping of the front legs, to deal with morphological change, and to synchronize its movement with another robot during a collaborative task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-08864-8_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-05544-2_129-1,Cybernetics,Encyclopedia of Global Bioethics,10.1007/978-3-319-05544-2_129-1,Springer,2014-01-01,"The original definition of cybernetics was proposed by Norbert Wiener (1948) as “the science of control and communication in the animal and the machine.” Cybernetics can be defined as the science that studies the communication and interactions between autonomous complex systems (machines and living organisms) through the use of information and control of their processes. In the medical field, as cybernetics evolves, physicians have resorted to support systems with intelligent and adaptive features to help them in many diagnostic and treatment tasks. These systems use artificial neural network and fuzzy logic algorithms. Moreover, these improvements have helped clinicians in decision-making, to offer an accurate diagnosis or to deliver a better treatment (i.e., wearable robots, such as prosthesis and mechanical substitutes), resulting in the possibility to develop new approaches for a higher quality in healthcare systems (i.e., e-health). However, the use and research of high-technology developments can give rise to ethical issues. Thus, it is crucial to address the bioethical concerns that surround the application of cybernetics in medicine. Dealing with medical bioethics, physicians are forced to face several moral theories in order to get a better approximation about specific problems and generate solutions based on a bioethical reflection process.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-05544-2_129-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-07176-3_27,Fuzzy Sensor-Based Navigation with Neural Tracking Control of the Wheeled Mobile Robot,Artificial Intelligence and Soft Computing,10.1007/978-3-319-07176-3_27,Springer,2014-01-01,"Navigation of the wheeled mobile robot in the unknown environment with simultaneous realisation of the generated trajectory, is one of the most challenging and up to date problems in the modern mobile robotics. In the article a new approach is presented to a collision-free trajectory generating for a wheeled mobile robot, realised in a form of the hierarchical control system with two layers. The first layer is a tracking control system, where the Neuro-Dynamic Programming algorithm in the Dual Heuristic Dynamic Programming configuration was applied. The second layer is a trajectory generator where the Fuzzy Logic systems were used. The presented control system generates and realises trajectory of the wheeled mobile robot within the complex task of goal-seeking and obstacle avoiding. The proposed hierarchical control system works on-line, its performance was verified using the wheeled mobile robot Pioneer 2-DX.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-07176-3_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-08864-8_15,Simulating the Emergence of Early Physical and Social Interactions : A Developmental Route through Low Level Visuomotor Learning,From Animals to Animats 13,10.1007/978-3-319-08864-8_15,Springer,2014-01-01,"In this paper, we propose a bio-inspired and developmental neural model that allows a robot, after learning its own dynamics during a babbling phase, to gain imitative and shape recognition abilities leading to early attempts for physical and social interactions. We use a motor controller based on oscillators. During the babbling step, the robot learns to associate its motor primitives (oscillators) to the visual optical flow induced by its own arm. It also statically learn to recognize its arm by selecting moving local view (feature points) in the visual field. In real indoor experiments we demonstrate that, using the same model, early physical (reaching objects) and social (immediate imitation) interactions can emerge through visual ambiguities induced by the external visual stimuli.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-08864-8_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-11179-7_103,Development of a Dynamically Extendable SpiNNaker Chip Computing Module,Artificial Neural Networks and Machine Learning – ICANN 2014,10.1007/978-3-319-11179-7_103,Springer,2014-01-01,"The SpiNNaker neural computing project has created a hardware architecture capable of scaling up to a system with more than a million embedded cores, in order to simulate more than one billion spiking neurons in biological real time. The heart of this system is the SpiNNaker chip, a multi-processor System-on-Chip with a high level of interconnectivity between its processing units. Here we present a Dynamically Extendable SpiNNaker Chip Computing Module that allows a SpiNNaker machine to be deployed on small mobile robots. A non-neural application, the simulation of the movement of a flock of birds, was developed to demonstrate the general purpose capabilities of this new platform. The developed SpiNNaker machine allows the simulation of up to one million spiking neurons in real time with a single SpiNNaker chip and is scalable up to 256 computing nodes in its current state.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-11179-7_103,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-012-1243-4,A hierarchical reinforcement learning approach for optimal path tracking of wheeled mobile robots,Neural Computing and Applications,10.1007/s00521-012-1243-4,Springer,2013-12-01,"Robust motion control is fundamental to autonomous mobile robots. In the past few years, reinforcement learning (RL) has attracted considerable attention in the feedback control of wheeled mobile robot. However, it is still difficult for RL to solve problems with large or continuous state spaces, which is common in robotics. To improve the generalization ability of RL, this paper presents a novel hierarchical RL approach for optimal path tracking of wheeled mobile robots. In the proposed approach, a graph Laplacian-based hierarchical approximate policy iteration (GHAPI) algorithm is developed, in which the basis functions are constructed automatically using the graph Laplacian operator. In GHAPI, the state space of an Markov decision process is divided into several subspaces and approximate policy iteration is carried out on each subspace. Then, a near-optimal path-tracking control strategy can be obtained by GHAPI combined with proportional-derivative (PD) control. The performance of the proposed approach is evaluated by using a P3-AT wheeled mobile robot. It is demonstrated that the GHAPI-based PD control can obtain better near-optimal control policies than previous approaches.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-012-1243-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-012-1193-x,Multi-robot task allocation using CNP combines with neural network,Neural Computing and Applications,10.1007/s00521-012-1193-x,Springer,2013-12-01,"Contract Net Protocol is a suitable method for multi-robot task allocation problems. However, it is difficult to find a function to evaluate robots’ bids when each robot gives more than one bid price to reflect its different abilities. We propose a method to fuse these prices and to decide which robot is the successful bidder using a BP neural network. The experiment result shows that the method is effective.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-012-1193-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-013-0092-2,Reduction of state space in reinforcement learning by sensor selection,Artificial Life and Robotics,10.1007/s10015-013-0092-2,Springer,2013-12-01,"Much research has been conducted on the application of reinforcement learning to robots. Learning time is a matter of concern in reinforcement learning. In reinforcement learning, information from sensors is projected on to a state space. A robot learns the correspondence between each state and action in state space and determines the best correspondence. When the state space is expanded according to the number of sensors, the number of correspondences learnt by the robot is increased. Therefore, learning the best correspondence becomes time consuming. In this study, we focus on the importance of sensors for a robot to perform a particular task. The sensors that are applicable to a task differ for different tasks. A robot does not need to use all installed sensors to perform a task. The state space should consist of only those sensors that are essential to a task. Using such a state space consisting of only important sensors, a robot can learn correspondences faster than in the case of a state space consisting of all installed sensors. Therefore, in this paper, we propose a relatively fast learning system in which a robot can autonomously select those sensors that are essential to a task and a state space for only such important sensors is constructed. We define the measure of importance of a sensor for a task. The measure is the coefficient of correlation between the value of each sensor and reward in reinforcement learning. A robot determines the importance of sensors based on this correlation. Consequently, the state space is reduced based on the importance of sensors. Thus, the robot can efficiently learn correspondences owing to the reduced state space. We confirm the effectiveness of our proposed system through a simulation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-013-0092-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-012-1157-1,Pulse neural network–based adaptive iterative learning control for uncertain robots,Neural Computing and Applications,10.1007/s00521-012-1157-1,Springer,2013-12-01,"An adaptive iterative learning control algorithm based on pulse neural network (PNN) is proposed for trajectory tracking of uncertain robot system. Sliding mode variable structure control is used to improve the robustness to disturbance and perturbation, and boundary layer is used to eliminate the chattering of sliding mode control. In the iterative domain, the unknown parameters are tuned and used for part of the controller. Running in parallel, the PNN can perform real-time state estimation for improving the system convergence. We analyze the stability and convergence of this algorithm by using the Lyapunove-like methodology. The simulation results show that the expected control purpose can be achieved using the proposed algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-012-1157-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-013-0278-8,"AI, Robotics and the Role of ECCAI",KI - Künstliche Intelligenz,10.1007/s13218-013-0278-8,Springer,2013-11-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-013-0278-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-013-9827-5,Neural Network Identification Based Multivariable Feedback Linearization Robust Control for a Two-Link Manipulator,Journal of Intelligent & Robotic Systems,10.1007/s10846-013-9827-5,Springer,2013-11-01,"Regarding to the variations of the load and unmodeled dynamic, robot manipulators are known as a nonlinear dynamic system. Overcoming such problems like uncertainties and nonlinear characteristics in the model of two-link manipulator is the principal goal of this paper. To approach to this aim, a neural network is combined with a linear robust control in which the result has the advantages of, the first, approximated nonlinear elements and the second, the guaranteed robustness. To design the proposed controller, at first, multivariable feedback linearization is employed to convert the nonlinear model to linear one. Second, the unknown parameters of the system are identified by neural network based on a new proposed learning rule. Third, Mixed linear feedback-H_ ∞  robust control method is proposed to stabilize the closed loop system. The closed loop system based on the proposed controller is analyzed and some numerical simulations are performed. Results show suitable responses of the closed loop system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-013-9827-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-013-0136-4,Tracking control of a nonholonomic mobile robot using compound cosine function neural networks,Intelligent Service Robotics,10.1007/s11370-013-0136-4,Springer,2013-10-01,"The purpose of this paper is to propose a compound cosine function neural network with continuous learning algorithm for the velocity and orientation angle tracking control of a nonholonomic mobile robot with nonlinear disturbances. Herein, two neural network (NN) controllers embedded in the closed-loop control system have the simple continuous learning and rapid convergence capability without the dynamics information of the mobile robot to realize the adaptive control of the mobile robot. The neuron function of the hidden layer in the three-layer feed-forward network structure is on the basis of combining a cosine function with a unipolar sigmoid function. The developed neural network controllers have simple algorithm and fast learning convergence because the weight values are only adjusted between the nodes in hidden layer and the output nodes, while the weight values between the input layer and the hidden layer are one, i.e. constant, without the weight adjustment. Therefore, the main advantages of this control system are the real-time control capability and the robustness by use of the proposed neural network controllers for a nonholonomic mobile robot with nonlinear disturbances. Through simulation experiments applied to the nonholonomic mobile robot with the nonlinear disturbances which are considered as dynamics uncertainty and external disturbances, the simulation results show that the proposed NN control system of nonholonomic mobile robots has real-time control capability, better robustness and higher control precision. The compound cosine function neural network provides us with a new way to solve tracking control problems for mobile robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-013-0136-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11245-012-9128-9,Safety Engineering for Artificial General Intelligence,Topoi,10.1007/s11245-012-9128-9,Springer,2013-10-01,"Machine ethics and robot rights are quickly becoming hot topics in artificial intelligence and robotics communities. We will argue that attempts to attribute moral agency and assign rights to all intelligent machines are misguided, whether applied to infrahuman or superhuman AIs, as are proposals to limit the negative effects of AIs by constraining their behavior. As an alternative, we propose a new science of safety engineering for intelligent artificial agents based on maximizing for what humans value. In particular, we challenge the scientific community to develop intelligent systems that have human-friendly values that they provably retain, even under recursive self-improvement.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11245-012-9128-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/2193-1801-2-495,"The dilemma of the symbols: analogies between philosophy, biology and artificial life",SpringerPlus,10.1186/2193-1801-2-495,Springer,2013-10-01,"This article analyzes some analogies going from Artificial Life questions about the symbol–matter connection to Artificial Intelligence questions about symbol-grounding. It focuses on the notion of the interpretability of syntax and how the symbols are integrated in a unity (""binding problem""). Utilizing the DNA code as a model, this paper discusses how syntactic features could be defined as high-grade characteristics of the non syntactic relations in a material-dynamic structure, by using an emergentist approach. This topic furnishes the ground for a confutation of J. Searle’s statement that syntax is observer-relative, as he wrote in his book ""Mind: A Brief Introduction"" . Moreover the evolving discussion also modifies the classic symbol-processing doctrine in the mind which Searle attacks as a strong AL argument, that life could be implemented in a computational mode. Lastly, this paper furnishes a new way of support for the autonomous systems thesis in Artificial Life and Artificial Intelligence, using, inter alia, the ""adaptive resonance theory"" (ART).",https://www.biomedcentral.com/openurl?doi=10.1186/2193-1801-2-495,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11063-013-9282-0,Control of an Industrial PA10-7CE Robot Arm Based on Decentralized Neural Backstepping Approach,Neural Processing Letters,10.1007/s11063-013-9282-0,Springer,2013-10-01,"This paper presents a discrete-time decentralized control strategy for trajectory tracking of a Mitsubishi PA10-7CE robot arm. A high order neural network is used to approximate a decentralized control law designed by the backstepping technique as applied to a block strict feedback form. The weights for each neural network are adapted online by extended Kalman filter training algorithm. The motion of each joint is controlled independently using only local angular position and velocity measurements. The stability analysis for closed-loop system via Lyapunov theory is included. Finally, the simulations results show the feasibility of the proposed scheme.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-013-9282-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-012-9782-6,Simulating Robots Without Conventional Physics: A Neural Network Approach,Journal of Intelligent & Robotic Systems,10.1007/s10846-012-9782-6,Springer,2013-09-01,"The construction of physics-based simulators for use in Evolutionary Robotics (ER) can be complex and time-consuming. Alternative simulation schemes construct robotic simulators from empirically-collected data. Such empirical simulators, however, also have associated challenges. This paper therefore investigates the potential use of Artificial Neural Networks, henceforth simply referred to as Neural Networks (NNs), as alternative robotic simulators. In contrast to physics models, NN-based simulators can be constructed without requiring an explicit mathematical model of the system being modeled, which can simplify simulator development. The generalization abilities of NNs, along with NNs’ noise tolerance, suggest that NNs could be well-suited to application in robotics simulation. Investigating whether NNs can be effectively used as robotic simulators in ER is thus the endeavour of this work. Two robot morphologies were selected on which the NN simulators created in this work were based, namely a differentially steered robot and an inverted pendulum robot. Accuracy tests indicated that NN simulators created for these robots generally trained well and could generalize well on data not presented during simulator construction. In order to validate the feasibility of the created NN simulators in the ER process, these simulators were subsequently used to evolve controllers in simulation, similar to controllers developed in related studies. Encouraging results were obtained, with the newly-evolved controllers allowing experimental robots to exhibit obstacle avoidance, light-approaching behaviour and inverted pendulum stabilization. It was thus clearly established that NN-based robotic simulators can be successfully employed as alternative simulation schemes in the ER process.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-012-9782-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10676-012-9305-y,"David J. Gunkel: The machine question: critical perspectives on AI, robots, and ethics",Ethics and Information Technology,10.1007/s10676-012-9305-y,Springer,2013-09-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10676-012-9305-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/1743-0003-10-96,Optimized intelligent control of a 2-degree of freedom robot for rehabilitation of lower limbs using neural network and genetic algorithm,Journal of NeuroEngineering and Rehabilitation,10.1186/1743-0003-10-96,BioMed Central,2013-08-14,"Background There is an increasing trend in using robots for medical purposes. One specific area is rehabilitation. Rehabilitation is one of the non-drug treatments in community health which means the restoration of the abilities to maximize independence. It is a prolonged work and costly labor. On the other hand, by using the flexible and efficient robots in rehabilitation area, this process will be more useful for handicapped patients. Methods In this study, a rule-based intelligent control methodology is proposed to mimic the behavior of a healthy limb in a satisfactory way by a 2-DOF planar robot. Inverse kinematic of the planar robot will be solved by neural networks and control parameters will be optimized by genetic algorithm, as rehabilitation progress. Results The results of simulations are presented by defining a physiotherapy simple mode on desired trajectory. MATLAB/Simulink is used for simulations. The system is capable of learning the action of the physiotherapist for each patient and imitating this behaviour in the absence of a physiotherapist that can be called robotherapy. Conclusions In this study, a therapeutic exercise planar 2-DOF robot is designed and controlled for lower-limb rehabilitation. The robot manipulator is controlled by combination of hybrid and adaptive controls. Some safety factors and stability constraints are defined and obtained. The robot is stopped when the safety factors are not satisfied. Kinematics of robot is estimated by an MLP neural network and proper control parameters are achieved using GA optimization.",https://www.biomedcentral.com/openurl?doi=10.1186/1743-0003-10-96,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11071-013-0923-7,Topology-aware handoff scheme for surveillance patrol robot,Nonlinear Dynamics,10.1007/s11071-013-0923-7,Springer,2013-08-01,"With the advances in wireless communication technology and artificial intelligence, robots are gradually being introduced as a part of our life. Similarly to most mobile devices, mobile robots suffer from handoff latency. This paper proposes TASPR, a Topology-Aware Surveillance Patrol Robot, which can integrate the robotic status and topology information to assist handoff between access points (APs). TASPR uses Topology-Aware Hand-Off Scheme (TAHOS) to find the most promising AP from a list of candidate APs. When TASPR decides to initiate a handoff procedure, it analyzes moving direction, received signal strength and topology information to filter out unnecessary scannings. Thus, TAHOS has less handoff latency compared to conventional handoff procedure and neighbor graph algorithm (NGA).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11071-013-0923-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.3103/S1060992X13030028,Hebbian ensemble neural network for robot movement control,Optical Memory and Neural Networks,10.3103/S1060992X13030028,Springer,2013-07-01,"When a robot moves among obstacles it sometimes needs to perform relatively complex maneuvers. The problem of selection of adequate maneuvers can be considered as an image recognition problem. At the input we have the image of a situation presented by the camera or rangefinder, and the output will present us with an appropriate maneuver that has to be performed to approach the goal. In contrast to the usual recognition system, the number of possible maneuvers can be enormous. It is practically impossible to enumerate them and give a name to each of them. For this reason it is necessary to develop a formalism for different maneuver representations. We propose the use of Hebbian ensemble neural networks for this purpose. This paper contains a brief description of Hebbian ensemble neural networks and some results of information capacity estimation. Information capacity shows how many ensembles can be stored in the neural network of a given size (given number of neurons in the network). It is shown that the number of ensembles can be much larger than the number of neurons in the network.",http://link.springer.com/openurl/fulltext?id=doi:10.3103/S1060992X13030028,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12021-012-9174-x,Three Tools for the Real-Time Simulation of Embodied Spiking Neural Networks Using GPUs,Neuroinformatics,10.1007/s12021-012-9174-x,Springer,2013-07-01,"This paper presents a toolbox of solutions that enable the user to construct biologically-inspired spiking neural networks with tens of thousands of neurons and millions of connections that can be simulated in real time, visualized in 3D and connected to robots and other devices. NeMo is a high performance simulator that works with a variety of neural and oscillator models and performs parallel simulations on either GPUs or multi-core processors. SpikeStream is a visualization and analysis environment that works with NeMo and can construct networks, store them in a database and visualize their activity in 3D. The iSpike library provides biologically-inspired conversion between real data and spike representations to support work with robots, such as the iCub. Each of the tools described in this paper can be used independently with other software, and they also work well together.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12021-012-9174-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-012-0966-6,Stability analysis of robust adaptive hybrid position/force controller for robot manipulators using neural network with uncertainties,Neural Computing and Applications,10.1007/s00521-012-0966-6,Springer,2013-06-01,"The aim of this paper is to design a robust adaptive neural network-based hybrid position/force control scheme for robot manipulators in the presence of model uncertainties and external disturbance. The feedforward neural network employed to learn a highly nonlinear function requires no preliminary learning. The control purposes are to achieve the stability in the sense of Lyapunov for desired interaction force between the end-effector and the environment and to regulate robot tip position in cartesian space. An adaptive compensator is also developed to eliminate the effect of disturbance term of neural network approximation error and external disturbance or unmodeled dynamics etc. A key feature of this compensator is that the prior information of the disturbance bound is not required. Finally, a comparative simulation study with a model-based robust control scheme for a two-link robot manipulator is presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-012-0966-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-013-9328-1,DCOB: Action space for reinforcement learning of high DoF robots,Autonomous Robots,10.1007/s10514-013-9328-1,Springer,2013-05-01,"Reinforcement learning (RL) for robot control is an important technology for future robots since it enables us to design a robot’s behavior using the reward function. However, RL for high degree-of-freedom robot control is still an open issue. This paper proposes a discrete action space DCOB which is generated from the basis functions (BFs) given to approximate a value function. The remarkable feature is that, by reducing the number of BFs to enable the robot to learn quickly the value function, the size of DCOB is also reduced, which improves the learning speed. In addition, a method WF-DCOB is proposed to enhance the performance, where wire-fitting is utilized to search for continuous actions around each discrete action of DCOB. We apply the proposed methods to motion learning tasks of a simulated humanoid robot and a real spider robot. The experimental results demonstrate outstanding performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-013-9328-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11768-013-1240-x,Robust dynamic surface control of flexible joint robots using recurrent neural networks,Journal of Control Theory and Applications,10.1007/s11768-013-1240-x,Springer,2013-05-01,"A robust neuro-adaptive controller for uncertain flexible joint robots is presented. This control scheme integrates H-infinity disturbance attenuation design and recurrent neural network adaptive control technique into the dynamic surface control framework. Two recurrent neural networks are used to adaptively learn the uncertain functions in a flexible joint robot. Then, the effects of approximation error and filter error on the tracking performance are attenuated to a prescribed level by the embedded H-infinity controller, so that the desired H-infinity tracking performance can be achieved. Finally, simulation results verify the effectiveness of the proposed control scheme.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11768-013-1240-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11771-013-1601-0,Dyna-QUF: Dyna-Q based univector field navigation for autonomous mobile robots in unknown environments,Journal of Central South University,10.1007/s11771-013-1601-0,Springer,2013-05-01,"A novel approach was presented to solve the navigation problem of autonomous mobile robots in unknown environments with dense obstacles based on a univector field method. In an obstacle-free environment, a robot is ensured to reach the goal position with the desired posture by following the univector field. Contrariwise, the univector field cannot guarantee that the robot will avoid obstacles in environments. In order to create an intelligent mobile robot being able to perform the obstacle avoidance task while following the univector field, Dyna-Q algorithm is developed to train the robot in learning moving directions to attain a collision-free path for its navigation. Simulations on the computer as well as experiments on the real world prove that the proposed algorithm is efficient for training the robot in reaching the goal position with the desired final orientation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11771-013-1601-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-012-0404-4,Art and robotics: sixty years of situated machines,AI & SOCIETY,10.1007/s00146-012-0404-4,Springer,2013-05-01,"This paper pursues the intertwined tracks of robotics and art since the mid 20th century, taking a loose chronological approach that considers both the devices themselves and their discursive contexts. Relevant research has occurred in a variety of cultural locations, often outside of or prior to formalized robotics contexts. Research was even conducted under the aegis of art or cultural practices where robotics has been pursued for other than instrumental purposes. In hindsight, some of that work seems remarkably prescient of contemporary trends. The context of cultural robotics is a highly charged interdisciplinary test environment in which the theory and pragmatics of technical research confronts the phenomenological realities of physical and social being in the world, and the performative and processual practices of the arts. In this context, issues of embodiment, material instantiation, structural coupling, and machine sensing have provoked the reconsideration of notions of (machine) intelligence and cognitivist paradigms. The paradoxical condition of robotics vis-à-vis artificial intelligence is reflected upon. This paper discusses the possibility of a new embodied ontology of robotics that draws upon both cybernetics and post-cognitive approaches.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-012-0404-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-011-0789-x,Neural network-based self-learning control for power transmission line deicing robot,Neural Computing and Applications,10.1007/s00521-011-0789-x,Springer,2013-04-01,"Recently, the application of the maintenance transmission line robot has been very popular in the power industry. However, difficulties in the control of maintenance transmission line robot exist due to multiple nonlinearities, plant parameter variations and external disturbances. This paper investigates the possibility of using neural network as a promising self-learning control alternative for the control problem of inspection and deicing transmission line robot. We first discuss the mechanical structure, as well as dynamic model of a deicing robot. And then, a neural network-based self-learning control strategy consists of a fuzzy neural network controller and an ELM-based single-layer-feedback neural networks identifier are proposed for this deicing transmission line robot. Both the structure and the learning algorithm of the control system are presented. The proposed controller is verified by computer simulations and experiments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-011-0789-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-012-9115-3,Backstepping sliding mode control with FWNN for strict output feedback non-smooth nonlinear dynamic system,"International Journal of Control, Automation and Systems",10.1007/s12555-012-9115-3,Springer,2013-04-01,"An output feedback backstepping sliding mode control scheme was developed for precision positioning of a strict single-input and single-output (SISO) non-smooth nonlinear dynamic system that could compensate for deadzone, dynamic friction, uncertainty and estimations of immeasurable states. An adaptive fuzzy wavelet neural networks (FWNNs) technique was used to provide improved approximation ability to the system uncertainty. The adaptive laws were derived for application to estimate the deadzone and friction parameters using recursive backstepping controller design procedures. In addition, the sliding mode control method was also combined to enforce the robustness of the output feedback backstepping controller against disturbance. The Lyapunov stability theorem was used to prove stability of the proposed control system. The usefulness of the proposed control system was verified by simulations and experiments on a robot manipulator in the presence of a deadzone and friction in the actuator.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-012-9115-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1631/jzus.C1200226,State-chain sequential feedback reinforcement learning for path planning of autonomous mobile robots,Journal of Zhejiang University SCIENCE C,10.1631/jzus.C1200226,Springer,2013-03-01,"This paper deals with a new approach based on Q -learning for solving the problem of mobile robot path planning in complex unknown static environments. As a computational approach to learning through interaction with the environment, reinforcement learning algorithms have been widely used for intelligent robot control, especially in the field of autonomous mobile robots. However, the learning process is slow and cumbersome. For practical applications, rapid rates of convergence are required. Aiming at the problem of slow convergence and long learning time for Q -learning based mobile robot path planning, a state-chain sequential feedback Q -learning algorithm is proposed for quickly searching for the optimal path of mobile robots in complex unknown static environments. The state chain is built during the searching process. After one action is chosen and the reward is received, the Q -values of the state-action pairs on the previously built state chain are sequentially updated with one-step Q -learning. With the increasing number of Q -values updated after one action, the number of actual steps for convergence decreases and thus, the learning time decreases, where a step is a state transition. Extensive simulations validate the efficiency of the newly proposed approach for mobile robot path planning in complex environments. The results show that the new approach has a high convergence speed and that the robot can find the collision-free optimal path in complex unknown static environments with much shorter time, compared with the one-step Q -learning algorithm and the Q ( λ )-learning algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1631/jzus.C1200226,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10994-012-5322-7,TEXPLORE: real-time sample-efficient reinforcement learning for robots,Machine Learning,10.1007/s10994-012-5322-7,Springer,2013-03-01,"The use of robots in society could be expanded by using reinforcement learning (RL) to allow robots to learn and adapt to new situations online. RL is a paradigm for learning sequential decision making tasks, usually formulated as a Markov Decision Process (MDP). For an RL algorithm to be practical for robotic control tasks, it must learn in very few samples, while continually taking actions in real-time. In addition, the algorithm must learn efficiently in the face of noise, sensor/actuator delays, and continuous state features. In this article, we present texplore , the first algorithm to address all of these challenges together. texplore is a model-based RL method that learns a random forest model of the domain which generalizes dynamics to unseen states. The agent explores states that are promising for the final policy, while ignoring states that do not appear promising. With sample-based planning and a novel parallel architecture, texplore can select actions continually in real-time whenever necessary. We empirically evaluate the importance of each component of texplore in isolation and then demonstrate the complete algorithm learning to control the velocity of an autonomous vehicle in real-time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10994-012-5322-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.3103/S0005105513010056,The state and perspective of Russian studies in artificial intelligence (Based on the Proceedings of the 13th Russian Conference on Artificial Intelligence with International Participation),Automatic Documentation and Mathematical Linguistics,10.3103/S0005105513010056,Springer,2013-02-01,The main directions of research in the field of artificial intelligence are presented on the basis of the Proceedings of the 13th Russian Conference on Artificial Intelligence with International Participation.,http://link.springer.com/openurl/fulltext?id=doi:10.3103/S0005105513010056,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-38622-0_8,Alignment in Vision-Oriented Syntactic Language Games for Teams of Robots Using Stochastic Regular Grammars and Reinforcement Learning,Natural and Artificial Computation in Engineering and Medical Applications,10.1007/978-3-642-38622-0_8,Springer,2013-01-01,"This paper approaches the syntactic alignment of a robot team by means of dialogic language games by applying online probabilistic reinforcement learning algorithms. The main contribution of the paper is the application of stochastic regular grammars, with learning capability, to generate the robots’ language. First, the paper describes the syntactic language games, in particular the type of grammar and syntactic rules of the robots’ language and the dynamic process of the language games which are based on dialogic communicative acts and a reinforcement learning policy that allows the robot team to converge to a common language. Afterwards, the experimental results are presented and discussed. The experimental work has been organized around the linguistic description of visual scenes of the blocks world type.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-38622-0_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-38637-4_17,Interplay between Natural and Artificial Intelligence in Training Autistic Children with Robots,Natural and Artificial Models in Computation and Biology,10.1007/978-3-642-38637-4_17,Springer,2013-01-01,"The need to understand and model human-like behavior and intelligence has been embraced by a multidisciplinary community for several decades. The success so far has been shown in solutions for a concrete task or a competence, and these solutions are seldom a truly multidisciplinary effort. In this paper we analyze the needs and the opportunities for combining artificial intelligence and bio-inspired computation within an application domain that provides a cluster of solutions instead of searching for a solution to a single task. We analyze applications of training children with autism spectrum disorder (ASD) with a humanoid robot, because it must include multidisciplinary effort and at the same time there is a clear need for better models of human-like behavior which will be tested in real life scenarios through these robots. We designed, implemented, and carried out three applied behavior analysis (ABA) based robot interventions. All interventions aim to promote self initiated social behavior in children with ASD. We found out that the standardization of the robot training scenarios and using unified robot platforms can be an enabler for integrating multiple intelligent and bio-inspired algorithms for creation of tailored, but domain specific robot skills and competencies. This approach might set a new trend to how artificial and bio-inspired robot applications develop. We suggest that social computing techniques are a pragmatic solution to creation of standardized training scenarios and therefore enable the replacement of perceivably intelligent robot behaviors with truly intelligent ones.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-38637-4_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-37105-9_29,An Intelligent Variable Spraying Decision-Making System Based on Fuzzy Neural Network for Greenhouse Mobile Robot,Intelligent Computing for Sustainable Energy and Environment,10.1007/978-3-642-37105-9_29,Springer,2013-01-01,"To improve the effective utilization rate of pesticide and reduce the pesticide residues and chemical pollution during spraying process, an intelligent decision-making method for variable spraying based on fuzzy neural network is designed according to the feature of the mobile robot spraying in greenhouse, combined with the spraying principle of variable spraying system for row-walking mobile robot. The decision system of offline training fuzzy neural network is built by integrating the information of the level of plant diseases and insect pests, the distance and area of spraying target. The simulation results show that the fuzzy neural network intelligent decision-making method can realize real-time and quick decisions by off-line training. It has the greater decision accuracy than the fuzzy decision system on the samples not appearing in training because of its strong adaptability and generalization ability and has a good fit for the uncertain work environment in greenhouse.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-37105-9_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-33926-4_39,"A Sociology of Intelligent, Autonomous Cothinkers and Coagents",Intelligent Autonomous Systems 12,10.1007/978-3-642-33926-4_39,Springer,2013-01-01,"Scientific and technological progress has brought robots where machine-based cognition and cooperation abilities start to emerge; not only between robots and humans but also among multiple robots themselves. In order to technically improve performances in latter case, as well as, by analogy, to better understand how humans can interact with one another and grow communities, time as come to further, scientifically and technically develop sociology-related knowledge and ontologies. Critical theoretical bases for cognition have been built and demonstrated, both in the human and machine-based cases, providing valuable contributions in this regard. Now sociable competences are considered, allowing for incrementally binding individuals and small groups into holistic units of increasing scope. Ultimately, what is also considered here is a kind of common, meta-human, secular framework where robots and humans can best co-think and co-act. Concepts have now been complemented and validated by real size implementation and experimentation in the domain of homes, as well as industrial and public environments. This should motivate the reader to get familiar with the proposed formal, quantitative MCS framework, thereby getting better insight in judgment and better ability to quantify requirements.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-33926-4_39,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-38577-3_28,Online Exploratory Behavior Acquisition of Mobile Robot Based on Reinforcement Learning,Recent Trends in Applied Artificial Intelligence,10.1007/978-3-642-38577-3_28,Springer,2013-01-01,"In this study, we propose an online active perception system that autonomously acquires exploratory behaviors suitable for each embodiment of mobile robots using online learning. We especially focus on a type of exploratory behavior that extracts object features useful for robot’s orientation and object operation. The proposed system is composed of a classification system and a reinforcement learning system. While a robot is interacting with objects, the classification system classifies observed data and calculates reward values according to the cluster distance of the observed data. On the other hand, the reinforcement learning system acquires effective exploratory behaviors useful for the classification according to the reward. We validated the effectiveness of the system in a mobile robot simulation. Three different shaped objects were placed beside the robot one by one. In this learning, the robot learned different behaviors corresponding to each object. The result showed that the behaviors were the exploratory behaviors that distinguish the difference of corner angles of the objects.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-38577-3_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-1-4020-8265-8_100626,Machine Learning in Robots,Encyclopedia of Sciences and Religions,10.1007/978-1-4020-8265-8_100626,Springer,2013-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4020-8265-8_100626,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-01168-4_1,Introduction,TEXPLORE: Temporal Difference Reinforcement Learning for Robots and Time-Constrained Domains,10.1007/978-3-319-01168-4_1,Springer,2013-01-01,"This chapter presents the motivation and objectives for this book, and an overview of the work presented in the book. I begin by presenting the motivation for applying reinforcement learning (RL) to robots. Next, I present four specific challenges for applying RL to robotics problems. Then I describe a particular challenge of learning in few enough samples to be effective on domains with limited, expensive samples such as robots. I then provide a brief overview of the texplore algorithm introduced in this book and how it addresses these issues. Finally I present the contributions of this book and preview of each chapter of the book.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-01168-4_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-39194-1_6,"Home Robots, Learn by Themselves",Universal Access in Human-Computer Interaction. Applications and Services for Quality of Life,10.1007/978-3-642-39194-1_6,Springer,2013-01-01,"To build an intelligent robot, we must develop an autonomous mental development system that incrementally and speedily learns from humans, its environments, and electronic data. This paper presents an ultra-fast, multimodal, and online incremental transfer learning method using the STAR-SOINN. We conducted two experiments to evaluate our method. The results suggest that recognition accuracy is higher than the system that simply adds modalities. The proposed method can work very quickly (approximately 1.5 [s] to learn one object, and 30 [ms] for a single estimation). We implemented this method on an actual robot that could estimate attributes of “unknown” objects by transferring attribute information of known objects. We believe this method can become a base technology for future robots. SOINN is an unsupervised online-learning method capable of incremental learning. By approximating the distribution of input data and the number of classes, a self-organized network is formed. SOINN offers the following advantages: network formation is not required to be predetermined beforehand, high robustness to noise, and reduced computational cost. In the near future, a SOINN device will accompany an individual from birth; this will allow the agent to share personal histories with its owner. In this occasion, a person’s SOINN will know ""everything"" about its owner, lending assistance at any time and place throughout one’s lifetime. Besides having a personal SOINN, an individual can install this self-enhanced agent into human-made products - making use of learned preferences to make the system more efficient. If deemed non-confidential, an individual’s SOINN could also autonomously communicate another SOINN to share information.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-39194-1_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-38460-8_20,Hybrid Reinforcement Learning and Uneven Generalization of Learning Space Method for Robot Obstacle Avoidance,Proceedings of 2013 Chinese Intelligent Automation Conference,10.1007/978-3-642-38460-8_20,Springer,2013-01-01,"This paper introduces a hybrid reinforcement learning algorithm for robot obstacle avoidance. This algorithm is based on SARSA (λ), and mix with the supervised learning. This hybrid learning algorithm can reduce the learning time obviously which is demonstrated by the simulations. In reinforcement learning, generalization of learning space is important for learning efficiency. An uneven generalization model is designed for improving the learning efficiency. The simulations show that the uneven model can not only reduce the learning time, but also the moving steps.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-38460-8_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-40846-5_33,How Do You Help a Robot to Find a Place? A Supervised Learning Paradigm to Semantically Infer about Places,Hybrid Artificial Intelligent Systems,10.1007/978-3-642-40846-5_33,Springer,2013-01-01,"In this paper a visual place recognition algorithm suitable for semantic inference is presented. It combines place and object classification attributes suitable for the recognition of congested and cluttered scenes. The place learning task is undertaken by a method capable of abstracting appearance information from the places to be memorized. The detected visual features are treated as a bag of words and quantized by a clustering algorithm to form a visual vocabulary of the explored places. Each query image is represented by a consistency histogram spread over the memorized vocabulary. Simultaneously, an object recognition approach based on Hierarchical Temporal Memory network, updates the robot’s belief of its current position exploiting the features of scattered objects within the scene. The input images which are introduced to the network undergo a saliency computation step and are subsequently thresholded based on an entropy metric for detecting multiple objects. The place and object decisions are fused by voting to infer the semantic attributes of a particular place. The efficiency of the proposed framework has been experimentally evaluated on a real dataset and proved capable of accurately recognizing multiple dissimilar places.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-40846-5_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-39479-9_62,Fault Tolerant Control for Robot Manipulators Using Neural Network and Second-Order Sliding Mode Observer,Intelligent Computing Theories,10.1007/978-3-642-39479-9_62,Springer,2013-01-01,"This paper investigates an algorithm for fault tolerant control of uncertain robot manipulator with only joint position measurement using neural network and second-order sliding mode observer. First, a neural network (NN) observer is designed to estimate the modeling uncertainties. Based on the obtained uncertainty estimation, a second-order sliding mode observer is then designed for two purposes: 1) Providing the velocity estimation, 2) providing the fault information that is used for fault detection, isolation and identification. Finally, a fault tolerant control scheme is proposed for compensating the effect of uncertainties and faults based on the fault estimation information. Computer simulation results on a PUMA560 industrial robot are shown to verify the effectiveness of the proposed strategy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-39479-9_62,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-42042-9_59,A Service-Oriented Approach with Neural Networks and Knowledge Ontologies for Robot Control,Neural Information Processing,10.1007/978-3-642-42042-9_59,Springer,2013-01-01,"Researchers have been building robots able to interact and work with people at home. To share and reuse robot code between different developers, we present a service-based approach that exploits the standard web interface to create reusable robotic services. Our approach includes knowledge ontology planning and neural network learning strategies for robot control. In addition, several service functions, including service discovery, selection, composition, and reconfiguration have been developed for operating the services. The proposed approach has been implemented and evaluated. The results show that our approach can be used to build robotic services successfully.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-42042-9_59,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-37374-9_32,Application of Fuzzy Logic in Learning Autonomous Robots Systems,Robot Intelligence Technology and Applications 2012,10.1007/978-3-642-37374-9_32,Springer,2013-01-01,"Autonomous Robots Systems (ARS) can learn by establishing plans, executing them in a given environment and analyzing the results of the execution. The logic used among this process is usually the classic logic, which most of the times ends up being too restrictive and not consistent with the world the ARS is facing. This paper proposes the application of fuzzy logic to address this issue and improve the ARS learning curve considerably.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-37374-9_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-38622-0_33,A Neural Network Approximation of L-MCRS Dynamics for Reinforcement Learning Experiments,Natural and Artificial Computation in Engineering and Medical Applications,10.1007/978-3-642-38622-0_33,Springer,2013-01-01,"The autonomous learning of the control of Linked Multicomponent Robotic Systems (L-MCRS) is an open research issue. We are pursuing the application of Reinforcement Learning algorithms to achieve such control. However, accurate simulations needed for RL trials are time consuming, so that the process of training and validation becomes excesively long. In order to obtain results in affordable time, we perform the approximation of the detailed dynamic model of the L-MCRS by Artificial Neural Networks (ANN).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-38622-0_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-33926-4_3,A Generalized Neural Network Approach to Mobile Robot Navigation and Obstacle Avoidance,Intelligent Autonomous Systems 12,10.1007/978-3-642-33926-4_3,Springer,2013-01-01,"Navigation is one of the most important problems in developing and designing intelligent mobile robots. To locally navigate and autonomously plan a path to arrive to a desired destination, Artificial Neural Networks (ANNs) are employed to model complex relationships between inputs and outputs or to find patterns in data as they provide more suitable solutions than the traditional methods. However, current neural network navigation approaches are limited to one kind of robot platform and range sensor, and usually are not extendable to other types of robots with different range sensors without the need to change the network structures. In this paper, we propose a general method to interpret the data from various types of 2-dimensional range sensors and a neural network algorithm to perform the navigation task. Our approach can yield a global navigation algorithm which can be applied to various types of range sensors and robot platforms. Moreover, this method contributes positively to reducing the time required for training the networks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-33926-4_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-39068-5_17,Global Tracking Control of a Wheeled Mobile Robot Using RBF Neural Networks,Advances in Neural Networks – ISNN 2013,10.1007/978-3-642-39068-5_17,Springer,2013-01-01,"In this paper, the global tracking control problem for a class of wheeled mobile robots is considered and a new adaptive position tracking control scheme is proposed where radial basis function (RBF) neural network (NN) is utilized to model the uncertainty. The feedback compensation scheme is obtained, where the information of reference position and real position of robot are both used as the NN input. Compered with the existing results, the main advantage is that the global stability of the closed-loop system can be ensured and the NN approximation domain can be determined based on the reference signal a prior. Finally, a simulation example is provided to demonstrate the effectiveness of the proposed control scheme.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-39068-5_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-37518-7_8,Examples of Planar Multilink Manipulators,Repetitive Motion Planning and Control of Redundant Robot Manipulators,10.1007/978-3-642-37518-7_8,Springer,2013-01-01,"In Chaps.  2 and 3 , we have theoretically demonstrated the effectiveness of such a physically constrained RMP scheme (and its solvers) on solving the joint-angle drift problem. In this chapter, a dual neural network (introduced in Chap.  4 ) and an LVI-based primal–dual neural network (introduced in Chap.  5 ) are presented for online repetitive motion planning (RMP) of redundant robot manipulators (with multilink planar manipulators as examples). As real-time QP solvers, the aforementioned two kinds of neural networks both have piecewise-linear dynamics and can globally exponentially converge to the optimal solution of strictly-convex quadratic programs. Furthermore, the neural-network-based physically constrained RMP scheme is simulated based on the multilink planar robot manipulators. Computer-simulation results substantiate the theoretical analysis and also show the effective remedy of the joint-angle drift problem of robot manipulators.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-37518-7_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-38679-4_31,Self-Organizing Incremental Neural Network (SOINN) as a Mechanism for Motor Babbling and Sensory-Motor Learning in Developmental Robotics,Advances in Computational Intelligence,10.1007/978-3-642-38679-4_31,Springer,2013-01-01,"Learning how to control arm joints for goal-directed reaching tasks is one of the earliest skills that need to be acquired by Developmental Robotics in order to scaffold into tasks of higher Intelligence. Motor Babbling seems as a promising approach toward the generation of internal models and control policies for robotic arms. In this paper we propose a mechanism for learning sensory-motor associations using layered arrangement of Self-Organizing Neural Network (SOINN) and joint-egocentric representations. The robot starts off by random exploratory motion, then it gradually shift into more coordinated, goal-directed actions based on the measure of error-change. The main contribution of this research is in the proposition of a novel architecture for online sensory-motor learning using SOINN networks without the need to provide the system with a kinematic model or a preprogrammed joint control scheme. The viability of the proposed mechanism is demonstrated using a simulated planar robotic arm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-38679-4_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-36669-7_99,Artificial Neural Network Based Control Strategy Research and Simulation on Robot Uncalibrated Visual Servoing System,Intelligent Science and Intelligent Data Engineering,10.1007/978-3-642-36669-7_99,Springer,2013-01-01,"This paper presents a control strategy and new simulation model for the visual servoing control system with an eye-in-hand configuration from a 6-DOF robot of puma560. Because of the complexity of the calibration method on calculating image Jacobian matrix, an uncalibration method based on neural network is proposed. Firstly, simulation model of image-based robot visual servoing control system in Matlab7.8.0(R2009a) is established. Then, the concept of uncalibration is introduced and BP neural network controller is used as the visual controller instead of the calibration method to calculate image Jacobian matrix. Furthermore a convenient and wide range simulation model of robot uncalibrated visual servoing control system based on BP neural network is designed. The simulation results show that the simulation model is feasible, and can be achieved uncalibrated visual positioning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-36669-7_99,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-94-007-4792-0_48,Autonomous Robot with Internal Topological Representation,Advances in Cognitive Neurodynamics (III),10.1007/978-94-007-4792-0_48,Springer,2013-01-01,"In this study, we implement the Map Initialized Perceptron (MIP), which is a hierarchical model of neural network with a Self-organizing map in the internal layer, as a trainable controller for autonomous robot. Our objective is to empirically investigate the correlation between the fidelity of internal representation and the learning ability of the robot in the physical environment. We believe that a well organized internal representation will enable better artificial learning systems and knowledge representation, which than can be utilized for designing better learning mechanisms, morphologies and environments. We support this hypothesis in this paper with some empirical experiments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-007-4792-0_48,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-34274-5_53,A Robot Uses an Evaluation Based on Internal Time to Become Self-aware and Discriminate Itself from Others,Biologically Inspired Cognitive Architectures 2012,10.1007/978-3-642-34274-5_53,Springer,2013-01-01,"The authors are attempting to clarify the nature of human consciousness by creating functions similar to that phenomenon in a robot. First of all, they focused on self-aware, confirming a new hypothesis from an experiment on a robot using a neural network with the MoNAD structure which they created based on the concept of a human neural circuit. The basis of this hypothesis is that “the entity receives an anticipated response within a certain evaluation standard based on internal time.” This paper discusses the theory of awareness in robots, related experiments, this hypothesis and the prospects for the future.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-34274-5_53,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-42057-3_50,A Hierarchical Path Planning Approach Based on Reinforcement Learning for Mobile Robots,Intelligence Science and Big Data Engineering,10.1007/978-3-642-42057-3_50,Springer,2013-01-01,"In this paper, we propose a novel hierarchical path planning algorithm for mobile robots based on A* and reinforcement learning (RL) with the structure of two layers. In the first layer, we adopt the A* search algorithm to plan a geometric path and select several points as sub-target points for the planning of the next stage. In the second layer, a local path planning algorithm based on an approximate RL method called Least Square Policy Iteration (LSPI) is used to find a kinematically feasible path with these sub-targets. After learning, the local path planner in the second layer has good generalization performance. The path obtained by the proposed algorithm is smooth and safe for executing. Simulations have been carried out and the results demonstrate the validity of the proposed scheme.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-42057-3_50,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-42057-3_91,Kernel-Based Representation Policy Iteration with Applications to Optimal Path Tracking of Wheeled Mobile Robots,Intelligence Science and Big Data Engineering,10.1007/978-3-642-42057-3_91,Springer,2013-01-01,"How to improve the generalization and approximation ability in reinforcement learning (RL) is still an open issue in recent years. Aiming at this problem, this paper presents a novel kernel-based representation policy iteration (KRPI) method for reinforcement learning in optimal path tracking of mobile robots. In the proposed method, the kernel trick is employed to map the original state space into a high-dimensional feature space and the Laplacian operator in the feature space is obtained by minimizing an objective function of optimal embedding. In the experiments, the KRPI-based PD controller was applied to the optimal path tracking problem of a wheeled mobile robot. It is demonstrated that the proposed method can obtain better near-optimal control policies than previous approaches.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-42057-3_91,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-45008-2_4,Online Gait Learning for Modular Robots with Arbitrary Shapes and Sizes,Theory and Practice of Natural Computing,10.1007/978-3-642-45008-2_4,Springer,2013-01-01,"This paper addresses a principal problem of in vivo evolution of modular multi-cellular robots. To evolve robot morphologies and controllers in real-space and real-time we need a generic learning mechanism that enables arbitrary modular shapes to obtain a suitable gait quickly after ‘birth’. In this study we investigate a reinforcement learning method and conduct simulation experiments using robot morphologies with different size and complexity. The experiments give insights into the online dynamics of gait learning, the distribution of lucky / unlucky runs and their dependence on the size and complexity of the modular robotic organisms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-45008-2_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-007-4786-9_9,An Analysis of the Genetic Evolution of a Ball-Beam Robotic Controller Based on a Three Dimensional Look up Table Chromosome,IAENG Transactions on Engineering Technologies,10.1007/978-94-007-4786-9_9,Springer,2013-01-01,"This chapter describes how a robotic controller based on a 3-dimensional lookup table was used to control a ball balancing beam system. The evolved motion of the beam and the corresponding chromosome is analysed. The 3 system states of the ball and beam were translated by the lookup table into a motor speed and direction which maintained the ball in balance. The ball-beam states included the ball position, ball speed, and beam position. The reproduction method used 2-point crossover with a mutation rate of 2 percent. The selection method was tournament, and the population size was 100 individuals. Successful evolution was achieved on 4 lookup tables, each containing different maximum motor speeds. Each evolved lookup table was able to maintain the ball in balance for more than 5 minutes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-007-4786-9_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4471-5340-5_41,Marvin Minsky,Giants of Computing,10.1007/978-1-4471-5340-5_41,Springer,2013-01-01,"Marvin Minsky is an American cognitive scientist, a pioneer of robotics and neural networks, author, inventor and one of the founders of the artificial intelligence field. He is Toshiba professor of media arts and sciences and professor of electrical engineering and computer science at the Massachusetts Institute of Technology.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-5340-5_41,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-32375-1_1,Intrinsically Motivated Learning Systems: An Overview,Intrinsically Motivated Learning in Natural and Artificial Systems,10.1007/978-3-642-32375-1_1,Springer,2013-01-01,"This chapter introduces the field of intrinsically motivated learning systems and illustrates the content, objectives, and organisation of the book. The chapter first expands the concept of intrinsic motivations, then introduces a taxonomy of three classes of intrinsic-motivation mechanisms (based on predictors, on novelty detection, and on competence), and finally introduces and reviews the various contributions of the book. The contributions are organised in six parts. The contributions of the first part provide general overviews on the concept of intrinsic motivations, the possible mechanisms that may implement them, and the functions that they can play. The contributions of the second, third, and fourth part focus on the three classes of the aforementioned intrinsic-motivation mechanisms. The contributions of the fifth part discuss mechanisms that are complementary to intrinsic motivations. The contributions of the sixth part introduce tools and experimental paradigms that can be used to investigate intrinsic motivations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-32375-1_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-40409-2_28,Multi Agent Reinforcement Learning for Gridworld Soccer Leadingpass,Intelligent Robotics Systems: Inspiring the NEXT,10.1007/978-3-642-40409-2_28,Springer,2013-01-01,"Soccer robotics is an emerging field that combines artificial intelligence and mobile robotics with the popular sport of soccer. Robotic soccer agents need to cooperate to complete tasks or subtasks, one way is by learning to coordinate their action. Leadingpass is considered as a task that had to be performed successfully by the team, or opponent could intercept the ball that leads the team to lose the game. This paper describes how Reinforcement Learning (RL) methods are applied to the learning scenario, that the learning agents cooperatively complete the leadingpass task in the Gridworld soccer environment. Not only RL algorithms for single agent case, but also for multi agent case.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-40409-2_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-012-0164-9,A State Representation Model for Robots Unaffected by Environmental Changes,International Journal of Social Robotics,10.1007/s12369-012-0164-9,Springer,2013-01-01,"To interact with the external environment, robots represent it as a state using sensor data. In this study, we present a state representation based on noisy sensor data using distances among probability distributions. Our proposed representation is not influenced by environmental changes, that is, sensor signals maintain an identical state even after certain environmental changes. We represent sensor signals as probability distributions and the distances between such distributions express a state. To confirm the effectiveness of our proposed state representation, we conducted experiments using a mobile robot with distance sensors. Experimental results confirmed that our proposed representation correctly recognizes similar states using a converted sensor signal.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-012-0164-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-32177-1_3,Coaching Robots: Online Behavior Learning from Human Subjective Feedback,Innovations in Intelligent Machines -3,10.1007/978-3-642-32177-1_3,Springer,2013-01-01,"This chapter describes a novel methodology for behavior learning of an agent, called Coaching. The proposed method is an interactive and iterative learning method which allows a human trainer to give a subjective evaluation to the robotic agent in real time, and the agent can update the reward function dynamically based on this evaluation simultaneously. We demonstrated that the agent is capable of learning the desired behavior by receiving simple and subjective instructions such as positive and negative. The proposed approach is also effective when it is difficult to determine a suitable reward function for the learning situation in advance. We have conducted several experiments with a simulated and a real robot arm system, and the advantage of the proposed method is verified throughout those experiments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-32177-1_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-31674-6_29,Artificial Intelligence Safety Engineering: Why Machine Ethics Is a Wrong Approach,Philosophy and Theory of Artificial Intelligence,10.1007/978-3-642-31674-6_29,Springer,2013-01-01,Machine ethics and robot rights are quickly becoming hot topics in artificial intelligence/robotics communities. We will argue that the attempts to allow machines to make ethical decisions or to have rights are misguided. Instead we propose a new science of safety engineering for intelligent artificial agents. In particular we issue a challenge to the scientific community to develop intelligent systems capable of proving that they are in fact safe even under recursive self-improvement.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-31674-6_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-012-9315-y,Fast motion planning from experience: trajectory prediction for speeding up movement generation,Autonomous Robots,10.1007/s10514-012-9315-y,Springer,2013-01-01,"Trajectory planning and optimization is a fundamental problem in articulated robotics. Algorithms used typically for this problem compute optimal trajectories from scratch in a new situation. In effect, extensive data is accumulated containing situations together with the respective optimized trajectories—but this data is in practice hardly exploited. This article describes a novel method to learn from such data and speed up motion generation, a method we denote tajectory pediction. The main idea is to use demonstrated optimal motions to quickly predict appropriate trajectories for novel situations. These can be used to initialize and thereby drastically speed-up subsequent optimization of robotic movements. Our approach has two essential ingredients. First, to generalize from previous situations to new ones we need a situation descriptor—we construct features for such descriptors and use a sparse regularized feature selection approach to improve generalization. Second, the transfer of previously optimized trajectories to a new situation should not be made in joint angle space—we propose a more efficient task space transfer. We present extensive results in simulation to illustrate the benefits of the new method, and demonstrate it also with real robot hardware. Our experiments in diverse tasks show that we can predict good motion trajectories in new situations for which the refinement is much faster than an optimization from scratch.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-012-9315-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-03473-7_7,Behaviors of Actors in a Resource-Exchange Model of Geopolitics,Complex Sciences,10.1007/978-3-319-03473-7_7,Springer,2013-01-01,"We present initial findings of an ongoing effort to endow the key players in a nation-state model with intelligent behaviors. The model is based on resource exchange as the fundamental interaction between agents. In initial versions, model agents were severely limited in their ability to respond and adapt to changes in their environment. By modeling agents with a broader range of capabilities, we can potentially evaluate policies more robustly. To this end, we have developed a hierarchical behavioral module, based on an extension of the proven ATLANTIS architecture, in order to provide flexible decision-making algorithms to agents. A Three-Layer Architecture for Navigating Through Intricate Situations (ATLANTIS) was originally conceived for autonomous robot navigation at NASA’s JPL. It describes a multi-level approach to artificial intelligence. We demonstrate the suitability of our reification for guiding vastly different types of decisions in our simulations over a broad range of time scales.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-03473-7_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-38610-7_33,Adaptive Critic Designs in Control of Robots Formation in Unknown Environment,Artificial Intelligence and Soft Computing,10.1007/978-3-642-38610-7_33,Springer,2013-01-01,"In the presented article a new approach to a collision-free trajectory generating for a wheeled mobile robots formation with Adaptive Critic Designs and Fuzzy Logic algorithm, is proposed. The presented hierarchical control system consists of a trajectory generating algorithm based on a conception of reactive navigation of the wheeled mobile robots formation in the unknown 2D environment, a control system that generates individual trajectories for all agents in formation, and agents tracking control systems. A strategy of reactive navigation is developed including two main behaviours: a obstacle avoiding behaviour and a goal-seeking behaviour, realised in a form of Adaptive Critic Design algorithms. These individual behaviours are combined using two approaches: cooperative connection approach and the fuzzy combiner, that determines influence of the individual behaviours on the trajectory generation process, according to the environment conditions. Computer simulations have been conducted to illustrate the process of path planning in different environment conditions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-38610-7_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-37387-9_1,Neural Network Development and Training for the Simulation of Dynamic Robot Movement Behavior,Recent Advances in Robotics and Automation,10.1007/978-3-642-37387-9_1,Springer,2013-01-01,"In this chapter the design and evaluation of artificial neural networks for learning static and dynamic positioning behavior of an industrial robot are presented. For the collection of training data, an approach based on the Levenberg–Marquardt algorithm was used to calibrate the robot and the coordinate measuring machine to a common reference system. A sequential approach for the network design development is presented. The network was verified by measuring different robot path segments with varying motion parameters, e.g. speed, payload and path geometry. Different layouts and configurations of feed-forward networks with backpropagation learning algorithms were examined resulting in a multi-layer network based on the calculation of the forward transformation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-37387-9_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-39068-5_25,EMG-Based Neural Network Control of an Upper-Limb Power-Assist Exoskeleton Robot,Advances in Neural Networks – ISNN 2013,10.1007/978-3-642-39068-5_25,Springer,2013-01-01,"The paper presents the electromyogram (EMG)-based neural network control of an upper-limb power-assist exoskeleton robot, which is proposed to control the robot in accordance with the user’s motion intention. The upper limb rehabilitation exoskeleton is with high precision for co-manipulation tasks of human and robot because of its backdrivability, precise positioning capabilities, and zero backlash due to its harmonic drive transmission (HDT). The novelty of this work is the development of an adaptive neural network modeling and control approach to handle the unknown parameters of the harmonic drive transmission in the robot to facilitate motion control. We have conducted the experiments on human subject to identify the various parameters of the harmonic drive system combining sEMG information signals.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-39068-5_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-40409-2_30,Camera Calibration: Transformation Real-World Coordinates into Camera Coordinates Using Neural Network,Intelligent Robotics Systems: Inspiring the NEXT,10.1007/978-3-642-40409-2_30,Springer,2013-01-01,"Vision system will make robotic system has the ability to see and modeled the real world objects. There are many factors that can affect the process of robot vision such as lens distortion, camera position which is not always at the center on the robot environment, the robot and other objects movement. In this research, we design an architecture using neural network to apply for global vision in autonomous mobile robot engine. The scheme is concerning to the development of camera calibration technique using neural network for precise and accurate position and orientation the robots. Its goal is to develop a robust camera calibration technique, to estimate the parameters of a transformation in the real world coordinate into image coordinate systems in autonomous mobile robots. The objective of our research is to propose and develop calibration techniques in a global overhead vision system for autonomous mobile robots. It aims to map and identify the identity of a robot in various conditions and camera position. Artificial Neural Network method (ANN) has been proposed as a method for solving coordinates transformation problems for non-linear lens distortion. The coordinate transformation was tested by placing cameras at various heights and setting camera angle with various zoom and focal length values.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-40409-2_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-011-0692-5,Superior robustness of power-sum activation functions in Zhang neural networks for time-varying quadratic programs perturbed with large implementation errors,Neural Computing and Applications,10.1007/s00521-011-0692-5,Springer,2013-01-01,"A special class of recurrent neural network termed Zhang neural network (ZNN) depicted in the implicit dynamics has recently been introduced for online solution of time-varying convex quadratic programming (QP) problems. Global exponential convergence of such a ZNN model is achieved theoretically in an error-free situation. This paper investigates the performance analysis of the perturbed ZNN model using a special type of activation functions (namely, power-sum activation functions) when solving the time-varying QP problems. Robustness analysis and simulation results demonstrate the superior characteristics of using power-sum activation functions in the context of large ZNN-implementation errors, compared with the case of using linear activation functions. Furthermore, the application to inverse kinematic control of a redundant robot arm also verifies the feasibility and effectiveness of the ZNN model for time-varying QP problems solving.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-011-0692-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-34816-7_8,Backstepping Control with RBF,Radial Basis Function (RBF) Neural Network Control for Mechanical Systems,10.1007/978-3-642-34816-7_8,Springer,2013-01-01,"This chapter introduces backstepping controller design with RBF neural network approximation. Several controller design examples for mechanical systems are given, including backstepping controller for inverted pendulum, backstepping controller for single-link flexible joint robot, and adaptive backstepping controller for single-link flexible joint robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-34816-7_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-42054-2_67,Development of Proactive and Reactive Behavior via Meta-learning of Prediction Error Variance,Neural Information Processing,10.1007/978-3-642-42054-2_67,Springer,2013-01-01,"This paper investigates a possible neurodynamic mechanism that enables autonomous switching between two basic behavioral modes, namely a “proactive mode” and a “reactive mode.” In the proactive mode, actions are generated as intended, whereas in the reactive mode actions are generated in response to the sensory state. We conducted neurorobotics experiments to investigate how these two modes can develop and how a robot can learn to switch autonomously between the two modes as necessary by utilizing our recently developed dynamic neural network model. Tasks designed for the robot included switching between proactive imitation of other’s predictable movements using acquired memories and reactive following of other’s unpredictable movements through iterative learning of alternating predictable and unpredictable movement patterns. The experimental results revealed that this “meta-learning” capability can lead to self-organization of adequate contextual dynamical structures that can perform autonomous switching between the different behavioral modes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-42054-2_67,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-39250-4_25,Using Saliency-Based Visual Attention Methods for Achieving Illumination Invariance in Robot Soccer,RoboCup 2012: Robot Soccer World Cup XVI,10.1007/978-3-642-39250-4_25,Springer,2013-01-01,"In order to be able to beat the world champion human soccer team in the year 2050, soccer playing robots will need to have very robust vision systems that can cope with drastic changes in illumination conditions. However, the current vision systems are still brittle and they require exhaustive and repeated color calibration procedures to perform acceptably well. In this paper, we investigate the suitability of biologically inspired saliency-based visual attention models for developing robust vision systems for soccer playing robots while focusing on the illumination invariance aspect of the solution. The experiment results demonstrate successful and accurate detection of the ball even when the illumination conditions change continuously and dramatically.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-39250-4_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4614-4430-5_17,"Artificial Intelligence, Robotics, and Electronic Performance Support Systems",Educational Media and Technology Yearbook,10.1007/978-1-4614-4430-5_17,Springer,2013-01-01,"Artificial Intelligence Review : Springer Science + Business Media, PO Box 2485, Secaucus, NJ 07096–2485, USA. www.springer.com/journal/10462 , tel: 800-777-4643, fax: 201-348-4505, service-ny@springer.com [8/yr; $862 inst (print/online), Artificial Intelligence Review : Springer Science + Business Media, PO Box 2485, Secaucus, NJ 07096–2485, USA. www.springer.com/journal/10462 , tel: 800-777-4643, fax: 201-348-4505, service-ny@springer.com [8/yr; $862 inst (print/online), $1,034 inst (print + online, content through 1997)]. Publishes reports and evaluations, as well as commentary on issues and development in artificial intelligence foundations and current research.,034 inst (print + online, content through 1997)]. Publishes reports and evaluations, as well as commentary on issues and development in artificial intelligence foundations and current research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4614-4430-5_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-33648-5_1,The Nexus Between Artificial Intelligence and Economics,The Nexus between Artificial Intelligence and Economics,10.1007/978-3-642-33648-5_1,Springer,2013-01-01,"We review recent developments in artificial intelligence and relate them to economics. Artificial intelligence represents the technology most likely to lead to a singularity, an infinite rate of innovation and productivity growth. This could occur via dramatic increases in life expectancy, the development of whole brain emulation, and innovations in robotics. We argue that there is no reason to believe that artificial intelligence would increase human happiness. We describe some recent development in agent-based modeling in economics, which can be interpreted as the introduction of artificially intelligent agents into economics. We argue that classical economic theory, which assumes that all agents are rational and have infinite computational ability, is very relevant in describing the behavior of future artificially intelligent entities. Economic implications of accelerating innovation, greater longevity, and the introduction of robot labor are considered.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-33648-5_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-40415-3_5,Censys: A Model for Distributed Embodied Cognition,Intelligent Virtual Agents,10.1007/978-3-642-40415-3_5,Springer,2013-01-01,"The role of the body in the generation of behavior is a topic that has sparked the attention of many fields from philosophy to science and more recently robotics. We address the question of how an embodied agent should be modeled in order to change the traditional dualist approach of creating embodied agents. By looking at behavior generation as a shared process between mind and body, we are able to create modules that generate and manage behavior, which are neither part of the body nor the mind, thus allowing a more flexible and natural control. A case study is presented to demonstrate and discuss our model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-40415-3_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-37374-9_85,Robotic Reasoning with Ontological Semantic Technology,Robot Intelligence Technology and Applications 2012,10.1007/978-3-642-37374-9_85,Springer,2013-01-01,"The paper discusses the ways in which Ontological Semantic Technology (OST) can contribute to current robotic systems. Based on the example of a robotic car oil changer, the paper demonstrates how OST can represent background knowledge and drive object-based inference and anomaly detection rules as well as complex script-based behavior in field and service robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-37374-9_85,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-40669-0_9,Dynamics of Neuronal Models in Online Neuroevolution of Robotic Controllers,Progress in Artificial Intelligence,10.1007/978-3-642-40669-0_9,Springer,2013-01-01,"In this paper, we investigate the dynamics of different neuronal models on online neuroevolution of robotic controllers in multirobot systems. We compare the performance and robustness of neural network-based controllers using summing neurons, multiplicative neurons, and a combination of the two. We perform a series of simulation-based experiments in which a group of e-puck-like robots must perform an integrated navigation and obstacle avoidance task in environments of different complexity. We show that: (i) multiplicative controllers and hybrid controllers maintain stable performance levels across tasks of different complexity, (ii) summing controllers evolve diverse behaviours that vary qualitatively during task execution, and (iii) multiplicative controllers lead to less diverse and more static behaviours that are maintained despite environmental changes. Complementary, hybrid controllers exhibit both behavioural characteristics, and display superior generalisation capabilities in simple and complex tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-40669-0_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-35638-4_22,Control of an Industrial PA10-7CE Redundant Robot Using a Decentralized Neural Approach,Computational Intelligence,10.1007/978-3-642-35638-4_22,Springer,2013-01-01,This paper presents a discrete-time decentralized control strategy for trajectory tracking of a seven degrees of freedom (DOF) redundant robot. A high order neural network (HONN) is used to approximate a decentralized control law designed by the backstepping technique as applied to a block strict feedback form (BSFF). The neural network learning is performed online using Kalman filtering. The motion of each joint is controlled independently using only local angular position and velocity measurements. The proposed controller is validated via simulations.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-35638-4_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-012-0051-3,A faster path planner using accelerated particle swarm optimization,Artificial Life and Robotics,10.1007/s10015-012-0051-3,Springer,2012-12-01,"The idea of placing small mobile robots to move around in a large building to detect potential intruders has been around for some time. However, there are still two major hurdles to overcome: to locate itself in the environment and to make a decision on how to move around safely and effectively at a reasonable computation cost. This paper describes a mathematical model for developing a scheme for an autonomous low cost mobile robot system using visual simultaneous localization and mapping and accelerated particle swarm intelligent path planner. The results indicated that this system could provide a solution for the problem of indoor mobile robot navigation. Advances in computer technology make this technique a cost effective solution for a future home service robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-012-0051-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-012-9674-9,Mutual Synchronization of Multiple Robot Manipulators with Unknown Dynamics,Journal of Intelligent & Robotic Systems,10.1007/s10846-012-9674-9,Springer,2012-11-01,"In this paper, we investigate the mutual synchronization control problem of multiple robot manipulators in the case that the desired trajectory is only available to a portion of the team members, and the dynamics and the external disturbances of the manipulators are unknown. Treating the weighted average of the outputs of the neighbors as the reference trajectory, an adaptive neural network (NN) tracking control is designed for each manipulator. Based on the Lyapunov analysis, rigid mathematical proof is provided for the proposed algorithm for both state feedback and output feedback cases. It is shown that, under the proposed adaptive NN control, the tracking error of each manipulator converges to an adjustable neighborhood of the origin. Simulations are provided to demonstrate the effectiveness of the proposed approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-012-9674-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-011-9244-8,A multi-agent reinforcement learning approach to robot soccer,Artificial Intelligence Review,10.1007/s10462-011-9244-8,Springer,2012-10-01,"In this paper, a multi-agent reinforcement learning method based on action prediction of other agent is proposed. In a multi-agent system, action selection of the learning agent is unavoidably impacted by other agents’ actions. Therefore, joint-state and joint-action are involved in the multi-agent reinforcement learning system. A novel agent action prediction method based on the probabilistic neural network (PNN) is proposed. PNN is used to predict the actions of other agents. Furthermore, the sharing policy mechanism is used to exchange the learning policy of multiple agents, the aim of which is to speed up the learning. Finally, the application of presented method to robot soccer is studied. Through learning, robot players can master the mapping policy from the state information to the action space. Moreover, multiple robots coordination and cooperation are well realized.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10462-011-9244-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-011-0738-6,Towards a Multiple-Lookahead-Levels agent reinforcement-learning technique and its implementation in integrated circuits,The Journal of Supercomputing,10.1007/s11227-011-0738-6,Springer,2012-10-01,"Reinforcement learning (RL) techniques have contributed and continue to tremendously contribute to the advancement of machine learning and its many related recent applications. As it is well known, some of the main limitations of existing RL techniques are, in general, their slow convergence and their computational complexity. The contributions of this paper are two-fold: (1) First, it introduces a technique for reinforcement learning using multiple lookahead levels that grants an autonomous agent more visibility in its environment and helps it learn faster. This technique extends the Watkins’s Q-Learning algorithm by using the Multiple-Lookahead-Levels (MLL) model equation that we develop and present here. An analysis of the convergence of the MLL equation and proof of its effectiveness are performed. A method to compute the improvement rate of the agent’s learning speed between different look-ahead levels is also proposed and implemented. Here, both the time and space complexities are examined. Results show that the number of steps, required to achieve the goal, per learning path exponentially decreases with the learning path number (time). Results also show that the number of steps per learning path, to some degree, is less at any time when the number of look-ahead levels is higher (space). Furthermore, we perform the analysis of the MLL system in the time domain and prove its temporal stability using Lyapunov theory. (2) Second, based on this Lyapunov stability analysis, we subsequently, and for the first time, propose a circuit architecture for the MLL technique’s software configurable hardware system design for real-time applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11227-011-0738-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.2478/s13230-013-0108-6,Adaptive exploration through covariance matrix adaptation enables developmental motor learning,Paladyn,10.2478/s13230-013-0108-6,Springer,2012-09-01,"The “Policy Improvement with Path Integrals” (PI^2) [25] and “Covariance Matrix Adaptation — Evolutionary Strategy” [8] are considered to be state-of-the-art in direct reinforcement learning and stochastic optimization respectively. We have recently shown that incorporating covariance matrix adaptation into PI^2- which yields the PI _CMA ^2 algorithm — enables adaptive exploration by continually and autonomously reconsidering the exploration/exploitation trade-off. In this article, we provide an overview of our recent work on covariance matrix adaptation for direct reinforcement learning [22–24], highlight its relevance to developmental robotics, and conduct further experiments to analyze the results. We investigate two complementary phenomena from developmental robotics. First, we demonstrate PI _CMA ^2 ’s ability to adapt to slowly or abruptly changing tasks due to its continual and adaptive exploration. This is an important component of life-long skill learning in dynamic environments. Second, we show on a reaching task how PI _CMA ^2 subsequently releases degrees of freedom from proximal to more distal limbs as learning progresses. A similar effect is observed in human development, where it is known as ‘proximodistal maturation’.",http://link.springer.com/openurl/pdf?id=doi:10.2478/s13230-013-0108-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12559-012-9135-6,The Self-Cognisant Robot,Cognitive Computation,10.1007/s12559-012-9135-6,Springer,2012-09-01,"This work discusses the challenge of developing self-cognisant artificial intelligence systems, looking at the possible benefits and the main issues in this quest. It is argued that the degree of complexity, variation, and specialisation of technological artefacts used nowadays, along with their sheer number, represent an issue that can and should be addressed through an important step towards greater autonomy, that is, the integration of learning, which will allow the artefact to observe its own functionality and build a model of itself. This model can be used to adjust the expectations from an imperfectly manufactured item, patch up its performance and control its consistency over time, so providing a form of self-certification and a warning mechanism in case of deterioration. It is suggested that these goals cannot be fully achieved without the ability of the learner to model its own performance, and the implications and issues of this self-reflective learning are debated. A possible way of quantifying the faculty for self-cognition is proposed, and relevant areas of computer science, philosophy and the study of the evolution of language are mentioned.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12559-012-9135-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11071-012-0422-2,Nonlinear model identification for Artemia population motion,Nonlinear Dynamics,10.1007/s11071-012-0422-2,Springer,2012-09-01,"In this paper, two different nonlinear models for Artemia swarming are derived. In order to generate the data suitable for identification, a robot driving the Artemia population has been built. The obtained data have been then used to identify the parameters of a model based on Newton’s equations and a black-box NARX model implemented by neural networks. The performances obtained validate the physical hypotheses underlying the gray-box model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11071-012-0422-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12064-011-0141-0,Variants of guided self-organization for robot control,Theory in Biosciences,10.1007/s12064-011-0141-0,Springer,2012-09-01,"Autonomous robots can generate exploratory behavior by self-organization of the sensorimotor loop. We show that the behavioral manifold that is covered in this way can be modified in a goal-dependent way without reducing the self-induced activity of the robot. We present three strategies for guided self-organization, namely by using external rewards, a problem-specific error function, or assumptions about the symmetries of the desired behavior. The strategies are analyzed for two different robots in a physically realistic simulation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12064-011-0141-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.2478/s13230-013-0111-y,A synchrony-based perspective for partner selection and attentional mechanism in human-robot interaction,Paladyn,10.2478/s13230-013-0111-y,Springer,2012-09-01,"Future robots must co-exist and directly interact with human beings. Designing these agents imply solving hard problems linked to human-robot interaction tasks. For instance, how a robot can choose an interacting partner among various agents and how a robot locates regions of interest in its visual field. Studies of neurobiology and psychology collectively named synchrony as an indispensable parameter for social interaction. We assumed that Human-Robot interaction could be initiated by synchrony detection. In this paper, we present a developmental approach for analyzing unintentional synchronization in human-robot interaction. Using our neural network model, the robot learns from a babbling step its inner dynamics by associating its own motor activities (oscillators) with the visual stimulus induced by its own motion. After learning the robot is capable of choosing an interacting agent and of localizing the spatial position of its preferred partner by synchrony detection.",http://link.springer.com/openurl/fulltext?id=doi:10.2478/s13230-013-0111-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12541-012-0181-5,Tracking control of redundant robot manipulators using RBF neural network and an adaptive bound on disturbances,International Journal of Precision Engineering and Manufacturing,10.1007/s12541-012-0181-5,Springer,2012-08-01,"In this paper, a hybrid trajectory tracking controller is designed for redundant robot manipulators, consisting of RBF neural network and an adaptive bound on disturbances. The controller is composed of computed torque type part, RBF neural network and an adaptive controller. The controller achieves end-effector trajectory tracking as well as subtask tracking effectively. The controller is able to learn the existing structured and unstructured uncertainties in the system in online manner. The RBF network learns the unknown part of the robot dynamics with no requirement of the offline training. The adaptive controller is used to estimate the unknown bounds on unstructured uncertainties and neural network reconstruction error. The overall system is proved to be asymptotically stable in the sense of Lyapunov. Finally, numerical simulation studies are performed on a 3R planar robot manipulator to show the effectiveness of the control scheme.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12541-012-0181-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-011-0311-2,Soft computing-based approaches to predict energy consumption and stability margin of six-legged robots moving on gradient terrains,Applied Intelligence,10.1007/s10489-011-0311-2,Springer,2012-07-01,"Soft computing-based approaches have been developed to predict specific energy consumption and stability margin of a six-legged robot ascending and descending some gradient terrains. Three different neuro-fuzzy and one neural network-based approaches have been developed. The performances of these approaches are compared among themselves, through computer simulations. Genetic algorithm-tuned multiple adaptive neuro-fuzzy inference system is found to perform better than other three approaches for predicting both the outputs. This could be due to a more exhaustive search carried out by the genetic algorithm in comparison with back-propagation algorithm and the use of two separate adaptive neuro-fuzzy inference systems for two different outputs. A designer may use the developed soft computing-based approaches in order to predict specific energy consumption and stability margin of the robot for a set of input parameters, beforehand.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-011-0311-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11277-012-0603-9,"Wireless Robotics: A History, an Overview, and the Need for Standardization",Wireless Personal Communications,10.1007/s11277-012-0603-9,Springer,2012-06-01,"The field of Robotics is one of the most fascinating areas of research in the world. Right now, hundreds of universities, corporations, and governments are spending billions researching and developing intelligent robotic systems for use in automation, military, medicine, electronics, food and beverage, service and a host of other industries. There is no doubt that robotic systems will play a major role in shaping the future of the world and as research and industry merge, progress in robotics technology will advance several times beyond the current level. This progress will be driven by a need to not only make life easier for consumers, but also to improve communities and even nations as a whole. The market for wireless robots and robotic systems far exceeds the current utilization and as technology advances, the use of robots will be incorporated primarily or indirectly in almost all fields. Of course the most interesting application is use of mobile and communicative robotic systems in everyday life. The possibilities are limited only by human creativity and intellect—the driving force that can turn this industry into the forerunner for an autonomous robot assisted future. Two of the most important areas for furthering the wide scale adaption of robotics are “autonomous mobility” and “wireless communications”. The field of endeavor by which robotic systems communicate wirelessly is known as Wireless Robotics. Advances in the field of Wireless Robotics are necessary to further the growth of robotic systems and their use in everyday life. Research and development in this field needs to progress more rapidly in order to see faster adoption of robots in everyday life. One way to stimulate this growth is by leveraging expertise on a global scale. But for people to cooperate in a global environment and be able to design systems without running into compatibility issues, standards are necessary. In this paper, we shall provide a brief background on the origin of robots and our fascination with them, discuss various use cases in current life, and provide the motivation for standardization in the field of Wireless Robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11277-012-0603-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-011-9241-y,A robot decision making framework using constraint programming,Artificial Intelligence Review,10.1007/s10462-011-9241-y,Springer,2012-06-01,"An intelligent robotic system must be capable of making the best decision at any given moment. The criteria for which task is “best” can be derived by performance metrics as well as the ability for it to satisfy all constraints upon the robot and its mission. Constraints may exist based on safety, reliability, accuracy, etc. This paper presents a decision framework capable of assisting a robotic system to select a task that satisfies all constraints as well as is optimized based upon one or more performance criteria. The framework models this decision process as a constraint satisfaction problem using techniques and algorithms from constraint programming and constraint optimization in order to provide a solution in real-time. This paper presents this framework and initial results provided through two demonstrations. The first utilizes simulation to provide an initial proof of concept, and the second, a security robot demonstration, is performed using a physical robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10462-011-9241-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-012-0310-z,Hybrid moment/position control of a parallel robot,"International Journal of Control, Automation and Systems",10.1007/s12555-012-0310-z,Springer,2012-06-01,"In this paper, a hybrid moment/position controller in task space is proposed for tasks involving a contact between a robot and its environment. We consider a contour-tracking task performed by a six DOF (Degrees Of Freedom) parallel robot. The task space dynamic model of the robot in contact with its environment, seen as a black box, is estimated by a MLP-NN (MultiLayer Perceptron Neural Network). The neural network non-linearity is treated using Taylor series expansion. An adaptation algorithm of the neural parameters resulting from a closed-loop stability analysis is proposed. The performance of the proposed controller is validated on the C5 parallel robot by considering two different environments: rigid and compliant.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-012-0310-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-011-9627-8,Odometry-Based Viterbi Localization with Artificial Neural Networks and Laser Range Finders for Mobile Robots,Journal of Intelligent & Robotic Systems,10.1007/s10846-011-9627-8,Springer,2012-04-01,"This paper proposes an approach that solves the Robot Localization problem by using a conditional state-transition Hidden Markov Model (HMM). Through the use of Self Organized Maps (SOMs) a Tolerant Observation Model (TOM) is built, while odometer-dependent transition probabilities are used for building an Odometer-Dependent Motion Model (ODMM). By using the Viterbi Algorithm and establishing a trigger value when evaluating the state-transition updates, the presented approach can easily take care of Position Tracking (PT), Global Localization (GL) and Robot Kidnapping (RK) with an ease of implementation difficult to achieve in most of the state-of-the-art localization algorithms. Also, an optimization is presented to allow the algorithm to run in standard microprocessors in real time, without the need of huge probability gridmaps.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-011-9627-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-011-9624-y,Modelling Shared Attention Through Relational Reinforcement Learning,Journal of Intelligent & Robotic Systems,10.1007/s10846-011-9624-y,Springer,2012-04-01,"Shared attention is a type of communication very important among human beings. It is sometimes reserved for the more complex form of communication being constituted by a sequence of four steps: mutual gaze, gaze following, imperative pointing and declarative pointing. Some approaches have been proposed in Human−Robot Interaction area to solve part of shared attention process, that is, the most of works proposed try to solve the first two steps. Models based on temporal difference, neural networks, probabilistic and reinforcement learning are methods used in several works. In this article, we are presenting a robotic architecture that provides a robot or agent, the capacity of learning mutual gaze, gaze following and declarative pointing using a robotic head interacting with a caregiver. Three learning methods have been incorporated to this architecture and a comparison of their performance has been done to find the most adequate to be used in real experiment. The learning capabilities of this architecture have been analyzed by observing the robot interacting with the human in a controlled environment. The experimental results show that the robotic head is able to produce appropriate behavior and to learn from sociable interaction.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-011-9624-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.2478/s13230-012-0013-4,Robot path planning using dynamic programming with accelerating nodes,Paladyn,10.2478/s13230-012-0013-4,Springer,2012-03-01,"We solve the problem of robot path planning using Dynamic Programming (DP) designed to perform well in case of a sudden path blockage. A conventional DP algorithm works well for real time scenarios only when the update frequency is high i.e. changes can be readily propagated. In case updates are costly, for a sudden blockage the robot continues moving along the wrong path or stands stationary. We propose a modified DP that has nodes with additional processing (called accelerating nodes) to enable different segments of the map to become informed about the blockage rapidly. We further quickly compute an alternative path in case of a blockage. Experimental results verify that usage of accelerating nodes makes the robot follow optimal paths in dynamic environments.",http://link.springer.com/openurl/fulltext?id=doi:10.2478/s13230-012-0013-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-011-0972-2,"Mutual learning of multi-consciousness agents, including an ego for an autonomous vehicle",Artificial Life and Robotics,10.1007/s10015-011-0972-2,Springer,2012-02-01,"In this paper, we propose a multi-agent learning system for the control of an intelligent robot, based on a model of the human consciousnesses, including the ego. We pay attention to the intelligent learning processes of human beings. We try to give a robot a high learning ability by modeling the roles of the human consciousnesses, including the ego. In most ordinary methods, the instructions for learning are given from outside the system only. In the proposed method, the instructions are given not only from outside, but also from inside (from other agents in the system). Therefore, the robot can learn efficiently because it has more instructions than usual. The learning is also more flexible, since an agent learns by instructions from other agents while the learning agent and one of the instructing agents exchange roles according to changes in the environment. We experimentally verified that the proposed method is efficient by using an actual robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-011-0972-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-012-0119-9,An efficient initialization approach of Q-learning for mobile robots,"International Journal of Control, Automation and Systems",10.1007/s12555-012-0119-9,Springer,2012-02-01,"This article demonstrates that Q-learning can be accelerated by appropriately specifying initial Q-values using dynamic wave expansion neural network. In our method, the neural network has the same topography as robot work space. Each neuron corresponds to a certain discrete state. Every neuron of the network will reach an equilibrium state according to the initial environment information. The activity of the special neuron denotes the maximum cumulative reward by following the optimal policy from the corresponding state when the network is stable. Then the initial Q-values are defined as the immediate reward plus the maximum cumulative reward by following the optimal policy beginning at the succeeding state. In this way, we create a mapping between the known environment information and the initial values of Q-table based on neural network. The prior knowledge can be incorporated into the learning system, and give robots a better learning foundation. Results of experiments in a grid world problem show that neural network-based Q-learning enables a robot to acquire an optimal policy with better learning performance compared to conventional Q-learning and potential field-based Qlearning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-012-0119-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11633-012-0612-x,Design of robotic visual servo control based on neural network and genetic algorithm,International Journal of Automation and Computing,10.1007/s11633-012-0612-x,Springer,2012-02-01,"A new visual servo control scheme for a robotic manipulator is presented in this paper, where a back propagation (BP) neural network is used to make a direct transition from image feature to joint angles without requiring robot kinematics and camera calibration. To speed up the convergence and avoid local minimum of the neural network, this paper uses a genetic algorithm to find the optimal initial weights and thresholds and then uses the BP algorithm to train the neural network according to the data given. The proposed method can effectively combine the good global searching ability of genetic algorithms with the accurate local searching feature of BP neural network. The Simulink model for PUMA560 robot visual servo system based on the improved BP neural network is built with the Robotics Toolbox of Matlab. The simulation results indicate that the proposed method can accelerate convergence of the image errors and provide a simple and effective way of robot control.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11633-012-0612-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10851-011-0292-0,The Kosko Subsethood Fuzzy Associative Memory (KS-FAM): Mathematical Background and Applications in Computer Vision,Journal of Mathematical Imaging and Vision,10.1007/s10851-011-0292-0,Springer,2012-02-01,"Many well-known fuzzy associative memory (FAM) models can be viewed as (fuzzy) morphological neural networks (MNNs) because they perform an operation of (fuzzy) mathematical morphology at every node, possibly followed by the application of an activation function. The vast majority of these FAMs represent distributive models given by single-layer matrix memories. Although the Kosko subsethood FAM (KS-FAM) can also be classified as a fuzzy morphological associative memory (FMAM), the KS-FAM constitutes a two-layer non-distributive model. In this paper, we prove several theorems concerning the conditions of perfect recall, the absolute storage capacity, and the output patterns produced by the KS-FAM. In addition, we propose a normalization strategy for the training and recall phases of the KS-FAM. We employ this strategy to compare the error correction capabilities of the KS-FAM and other fuzzy and gray-scale associative memories in terms of some experimental results concerning gray-scale image reconstruction. Finally, we apply the KS-FAM to the task of vision-based self-localization in robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10851-011-0292-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-27645-3_18,Reinforcement Learning in Robotics: A Survey,Reinforcement Learning,10.1007/978-3-642-27645-3_18,Springer,2012-01-01,"As most action generation problems of autonomous robots can be phrased in terms of sequential decision problems, robotics offers a tremendously important and interesting application platform for reinforcement learning. Similarly, the real-world challenges of this domain pose a major real-world check for reinforcement learning. Hence, the interplay between both disciplines can be seen as promising as the one between physics and mathematics. Nevertheless, only a fraction of the scientists working on reinforcement learning are sufficiently tied to robotics to oversee most problems encountered in this context. Thus, we will bring the most important challenges faced by robot reinforcement learning to their attention. To achieve this goal, we will attempt to survey most work that has successfully applied reinforcement learning to behavior generation for real robots. We discuss how the presented successful approaches have been made tractable despite the complexity of the domain and will study how representations or the inclusion of prior knowledge can make a significant difference. As a result, a particular focus of our chapter lies on the choice between model-based and model-free as well as between value function-based and policy search methods. As a result, we obtain a fairly complete survey of robot reinforcement learning which should allow a general reinforcement learning researcher to understand this domain.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-27645-3_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-24728-6_28,Mobile Robot Navigation Using Reinforcement Learning Based on Neural Network with Short Term Memory,Advanced Intelligent Computing,10.1007/978-3-642-24728-6_28,Springer,2012-01-01,In this paper we propose a novel bio-inspired model of a mobile robot navigation system. The novelty of our work consists in combining short term memory and online neural network learning using history of events stored in this memory. The neural network is trained with a modified error back propagation algorithm that utilizes reward and punishment principal while interacting with the environment.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-24728-6_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-28939-2_2,Reinforcement Learning as Heuristic for Action-Rule Preferences,Programming Multi-Agent Systems,10.1007/978-3-642-28939-2_2,Springer,2012-01-01,"A common action selection mechanism used in agent-oriented programming is to base action selection on a set of rules. Since rules need not be mutually exclusive, agents are often underspecified. This means that the decision-making of such agents leaves room for multiple choices of actions. Underspecification implies there is potential for improvement or optimalization of the agent’s behavior. Such optimalization, however, is not always naturally coded using BDI-like agent concepts. In this paper, we propose an approach to exploit this potential for improvement using reinforcement learning. This approach is based on learning rule priorities to solve the rule-selection problem, and we show that using this approach the behavior of an agent is significantly improved. Key here is the use of a state representation that combines the set of rules of the agent with a domain-independent heuristic based on the number of active goals. Our experiments show that this provides a useful generic base for learning while avoiding the state-explosion problem or overfitting.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-28939-2_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-1-4419-1428-6_5526,Robot Reinforcement Learning,Encyclopedia of the Sciences of Learning,10.1007/978-1-4419-1428-6_5526,Springer,2012-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4419-1428-6_5526,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-32060-6_45,Adaptivity on the Robot Brain Architecture Level Using Reinforcement Learning,RoboCup 2011: Robot Soccer World Cup XV,10.1007/978-3-642-32060-6_45,Springer,2012-01-01,"The design and implementation of a robot brain often requires making decisions between different modules with similar functionality. Many implementations and components are easy to create or can be downloaded, but it is difficult to assess which combination of modules work well and which does not. This paper discusses a reinforcement learning mechanism where the robot is choosing between the different components using empirical feedback and optimization criteria. With the interval estimation algorithm the robot deselects poorly functioning modules and retains only the best ones. A discount factor ensures that the robot keeps adapting to new circumstances in the real world. This allows the robot to adapt itself continuously on the architecture level and also allows working with large development teams creating several different implementations with similar functionalities to give the robot biggest chance to solve a task. The architecture is tested in the RoboCup@Home setting and can handle failure situations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-32060-6_45,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-1-4419-1428-6_4815,Machine Learning in Robots,Encyclopedia of the Sciences of Learning,10.1007/978-1-4419-1428-6_4815,Springer,2012-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4419-1428-6_4815,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-35101-3_72,On-Line Model-Based Continuous State Reinforcement Learning Using Background Knowledge,AI 2012: Advances in Artificial Intelligence,10.1007/978-3-642-35101-3_72,Springer,2012-01-01,"Without a model the application of reinforcement learning to control a dynamic system can be hampered by several shortcomings. The number of trials needed to learn a good policy can be costly and time consuming for robotic applications where data is gathered in real-time. In this paper we describe a variable resolution model-based reinforcement learning approach that distributes sample points in the state-space in proportion to the effect of actions. In this way the base learner economises on storage to approximate an effective model. Our approach is conducive to including background knowledge to speed up learning. We show how different types of background knowledge can used to speed up learning in this setting. In particular, we show good performance for a weak type of background knowledge by initially overgeneralising local experience.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-35101-3_72,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-35731-2_3,"Three Roads to Complexity, AI and the Law of Robots: On Crimes, Contracts, and Torts","AI Approaches to the Complexity of Legal Systems. Models and Ethical Challenges for Legal Systems, Legal Language and Legal Ontologies, Argumentation and Software Agents",10.1007/978-3-642-35731-2_3,Springer,2012-01-01,"The paper examines the impact of robotics technology on contemporary legal systems and, more particularly, some of the legal challenges brought on by the information revolution in the fields of criminal law, contracts, and tort law. Whereas, in international humanitarian law, scholars and lawmakers debate on whether autonomous lethal weapons should be banned, robots are reshaping notions of agency and human responsibility in civil (as opposed to criminal) law. Although time is not ripe for the “legal personification” of robots, we should admit new forms of both contractual and tort liability for the behaviour of these “intelligent machines.” After all, this is the first time ever legal systems will hold people responsible for what an artificial state-transition system “decides” to do.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-35731-2_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-28314-7_9,A Hierarchical Reinforcement Learning Based Approach for Multi-robot Cooperation in Unknown Environments,Proceedings of the 2011 2nd International Congress on Computer Applications and Computational Science,10.1007/978-3-642-28314-7_9,Springer,2012-01-01,"Reinforcement learning is a good method for multi-robot systems to handle tasks in unknown environments or with obscure models. MAXQ is a hierarchical reinforcement learning algorithm, which is limited by some inherent problems. In addition, much research has focused on the completion of the task, rather than the ability to deal with new tasks. In this paper, an improved MAXQ approach is adopted to tune the parameters of the cooperation rules. The proposed scheme is applied to target searching tasks by multi-robots. The simulation results demonstrate the effectiveness and efficiency of the proposed scheme.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-28314-7_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-30223-7_36,Robot Reinforcement Learning Methods Based on XCSG,Advances in Computer Science and Information Engineering,10.1007/978-3-642-30223-7_36,Springer,2012-01-01,"This paper proposed a robot reinforcement learning method based on learning classifier system. A Learning Classifier System is a accuracy-based machine learning system with gradient descent that combines reinforcement learning and rule discovery system. The genetic algorithm and the covering operator act as innovation discovery components which are responsible for discovering new better reinforcement learning rules. The reinforcement learning component is responsible for adjusting the fitness of rules in the system according to some reward obtained from the environment. The advantage of this approach is its accuracy-based representation, which can easily reduce learning space, improve online learning ability and robot robustness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-30223-7_36,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-35197-6_21,Biologically Inspired Architecture for Spatiotemporal Learning of Mobile Robots,"Trends in Intelligent Robotics, Automation, and Manufacturing",10.1007/978-3-642-35197-6_21,Springer,2012-01-01,"Biological systems can adapt excellently to the demands of a dynamic world and changing tasks. What kind of information processing and reasoning do they use? There are numerous studies in psychology, cognitive neuroscience and artificial intelligence which complement each other and help in getting a better understanding of this riddle. Our paper presents a biologically inspired architecture for a spatiotemporal learning system. Multiple interconnected memory structures are used to incorporate different learning paradigms. Concurrent inherent learning processes complete the functionality of corresponding memory types. Our architecture has been evaluated in the context of mobile rescue robots: The task consists of searching objects while navigating in an unknown maze.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-35197-6_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-25992-0_109,Optimization and Verification for a Robot Control System Based on Learning Petri Net Model,"Informatics in Control, Automation and Robotics",10.1007/978-3-642-25992-0_109,Springer,2012-01-01,"The optimization and verification for a robot control system have been studied respectively. In this paper, we propose a robot control model which combines optimization and verification based on Learning Petri Net (LPN). In our former work, learning Petri net model has been constructed based on high-level time Petri net and Reinforcement Learning (RL). The reinforcement learning is applied to optimize the parameters of Petri net. These parameters adjusting may make the properties of learning Petri net change. In this paper, the verification algorithms for learning Petri net are proposed. Using this model, a robot control system with optimization and verification capability is constructed. Finally, for the purpose of certification of the effectiveness of our proposed methods, this robot control system is used to control a robot system – E-puck as an example. The result of the experiment shows the methods are correct and effective.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-25992-0_109,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-28942-2_10,Decentralized Multi-tasks Distribution in Heterogeneous Robot Teams by Means of Ant Colony Optimization and Learning Automata,Hybrid Artificial Intelligent Systems,10.1007/978-3-642-28942-2_10,Springer,2012-01-01,"This paper focuses on the general problem of coordinating multiple robots. More specifically, it addresses the self-election of heterogeneous specialized tasks by autonomous robots. In this paper we focus on a specifically distributed or decentralized approach as we are particularly interested on decentralized solution where the robots themselves autonomously and in an individual manner, are responsible of selecting a particular task so that all the existing tasks are optimally distributed and executed. In this regard, we have established an experimental scenario to solve the corresponding multi-tasks distribution problem and we propose a solution using two different approaches by applying Ant Colony Optimization-based deterministic algorithms as well as Learning Automata-based probabilistic algorithms. We have evaluated the robustness of the algorithm, perturbing the number of pending loads to simulate the robot’s error in estimating the real number of pending tasks and also the dynamic generation of loads through time. The paper ends with a critical discussion of experimental results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-28942-2_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11071-011-0027-1,ZMP based neural network inspired humanoid robot control,Nonlinear Dynamics,10.1007/s11071-011-0027-1,Springer,2012-01-01,"This paper concerns ZMP-based control that is inspired by artificial neural networks for humanoid robot walking on varying sloped surfaces. Humanoid robots are currently one of the most exciting research topics in the field of robotics, and maintaining stability while they are standing, walking or moving is a key concern. To ensure a steady and smooth walking gait of such robots, a feedforward type of neural network architecture, trained by the back-propagation algorithm, is employed. The inputs and outputs of the neural network architecture are the ZMP x and ZMP y errors of the robot, and the x , y positions of the robot, respectively. The neural network developed allows the controller to generate the desired balance of the robot positions, resulting in a steady gait for the robot as it moves around on a flat floor, and when it is descending or ascending slopes. In this paper, experiments of humanoid robot walking are carried out, in which the actual position data from a prototype robot are measured in real-time situations, and fed into a neural network inspired controller designed for stable bipedal walking. In addition, natural walking motions on the different surfaces with varying slopes are obtained and the performance of the resulting controller is shown to be satisfactory.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11071-011-0027-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-31919-8_5,A Path Prediction Method for Human-Accompanying Mobile Robot Based on Neural Network,Intelligent Science and Intelligent Data Engineering,10.1007/978-3-642-31919-8_5,Springer,2012-01-01,"This paper presents a path prediction method for human-accompanying mobile robot such as robotic wheelchair, domestic robot and tour guide robot. An accompanying human is detected using an in-vehicle laser range sensor (LRS). A new filter gets a smoothed track from raw LRS data of human footprints. Back propagation neural network predicts future positions of the accompanying human from the human track. Based on the future positions, a cubic spline generates a future path of the accompanying human. The experimental result validates the feasibility of the path prediction method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-31919-8_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-33503-7_12,Adaptive Neural Network Control of Robot with Passive Last Joint,Intelligent Robotics and Applications,10.1007/978-3-642-33503-7_12,Springer,2012-01-01,"Adaptive control of a robot manipulator with a passive joint (which has neither an actuator nor a holding brake) is investigated. With the aim to shape the controlled manipulator dynamics to be of minimized motion tracking errors and joint accelerations, we employ a linear quadratic regulator (LQR) optimization technique to obtain an optimal reference model. Adaptive neural network (NN) control has been developed to ensure the reference model can be matched in finite time, in the presence of various uncertainties.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-33503-7_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-28111-2_19,Synthetic Intelligence: Beyond Artificial Intelligence and Robotics,Integral Biomathics,10.1007/978-3-642-28111-2_19,Springer,2012-01-01,"The development of engineered systems having properties of autonomy and intelligence has been a visionary research goal of the twentieth century. However, there are a number of persistent and fundamental problems that continue to frustrate this goal. Behind these problems is an outmoded industrial foundation for the contemporary discourse and practices addressing intelligent robotics that must be superseded as engineering progresses more deeply into molecular and biological modalities. These developments inspire the proposal of a paradigm of engineered synthetic intelligence as an alternative to artificial intelligence, in which intelligence is pursued in a bottom-up way from systems of molecular and cellular elements, designed and fabricated from the molecular level and up. This paradigm no longer emphasizes the definition of representation and the logic of cognitive operations. Rather, it emphasizes the design of self-replicating, self-assembling and self-organizing biomolecular elements capable of generating cognizing systems as larger scale assemblies, analogous to the neurobiological system manifesting human cognition.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-28111-2_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4471-2359-0_15,Artificial Intelligence,A Brief History of Computing,10.1007/978-1-4471-2359-0_15,Springer,2012-01-01,"The long-term goal of artificial intelligence is to create a thinking machine that is intelligent, has consciousness, has the ability to learn, has free will and is ethical. The field involves several disciplines such as philosophy, psychology, linguistics, machine vision, cognitive science, mathematics, logic and ethics. Artificial intelligence is a young field, and the term was coined by John McCarthy and others in 1956. Alan Turing had earlier devised the Turing test as a way to test the intelligent behaviour of a machine. There are deep philosophical problems in artificial intelligence, and some researchers believe that its goals are impossible or incoherent. These views are shared by Hubert Dreyfus and John Searle. Even if artificial intelligence is possible, there are moral issues to consider such as the exploitation of artificial machines by humans and whether it is ethical to do this. Weizenbaum has argued that artificial intelligence is unethical.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-2359-0_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-010-0451-x,Reinforcement learning technique using agent state occurrence frequency with analysis of knowledge sharing on the agent’s learning process in multiagent environments,The Journal of Supercomputing,10.1007/s11227-010-0451-x,Springer,2012-01-01,"Reinforcement learning techniques like the Q-Learning one as well as the Multiple-Lookahead-Levels one that we introduced in our prior work require the agent to complete an initial exploratory path followed by as many hypothetical and physical paths as necessary to find the optimal path to the goal. This paper introduces a reinforcement learning technique that uses a distance measure to the goal as a primary gauge for an autonomous agent’s action selection. In this paper, we take advantage of the first random walk to acquire initial information about the goal. Once the agent’s goal is reached, the agent’s first perceived internal model of the environment is updated to reflect and include said goal. This is done by the agent tracing back its steps to its origin starting point. We show in this paper, no exploratory or hypothetical paths are required after the goal is initially reached or detected, and the agent requires a maximum of two physical paths to find the optimal path to the goal. The agent’s state occurrence frequency is introduced as well and used to support the proposed Distance-Only technique. A computation speed performance analysis is carried out, and the Distance-and-Frequency technique is shown to require less computation time than the Q-Learning one. Furthermore, we present and demonstrate how multiple agents using the Distance-and-Frequency technique can share knowledge of the environment and study the effect of that knowledge sharing on the agents’ learning process.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11227-010-0451-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-27534-0_19,Adaptive Control of Robot Systems with Simple Rules Using Chaotic Dynamics in Quasi-layered Recurrent Neural Networks,Computational Intelligence,10.1007/978-3-642-27534-0_19,Springer,2012-01-01,"A novel idea of adaptive control with simple rules using chaotic dynamics in a recurrent neural network model and two kinds of quasi-layered recurrent neural network model have been proposed. Since chaos in brain was discovered in the context of brain function, the authors have claimed that chaos has complex functional potentialities and have presented the results of computer experiments which use chaos to solve several kinds of “ill-posed problems”. The key idea is to harness the onset of complex nonlinear dynamics in dynamical systems. More specifically, attractor dynamics and chaotic dynamics in a recurrent neural network model are introduced by changing a system parameter, “connectivity” in one type of model and via “sensitive response of chaos to external inputs” in other models. In this report, we will show the following. (1) A global outline of our idea and our recurrent neural network models with neuro-chaos , (2) Several computer experiments on the use of the neuro-chaos recurrent neural network models for solving of 2-dimensional mazes by an autonomous robot, in the context of an ill-posed problem setting, (3) Hardware implementations of the computer experiments using robots with two-wheels or two-legs driven by a neuro chaos simulator. Successful results of maze-solving are shown not only for computer experiments but also for practical experiments, (4) A proposal for a pseudo-neuron device using semiconductor and opto-electronic technologies. The device is called a “dynamic self-electro optical effect devices (DSEED)”, and it has the potential to be a “neuromorphic device” or even a “brainmorphic device”. (5) A proto-type model of intra-brain communications between far distant neurons in the brain is proposed, from a heuristic point of view based on observations of neuron synchronization phenomena associated with advanced brain functioning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-27534-0_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-33460-3_1,Machine Learning for Robotics,Machine Learning and Knowledge Discovery in Databases,10.1007/978-3-642-33460-3_1,Springer,2012-01-01,"Robots are typically far less capable in autonomous mode than in tele-operated mode. The few exceptions tend to stem from long days (and more often weeks, or even years) of expert engineering for a specific robot and its operating environment. Current control methodology is quite slow and labor intensive. I believe advances in machine learning have the potential to revolutionize robotics. In this talk, I will present new machine learning techniques we have developed that are tailored to robotics. I will describe in depth “Apprenticeship learning”, a new approach to high-performance robot control based on learning for control from ensembles of expert human demonstrations. Our initial work in apprenticeship learning has enabled the most advanced helicopter aerobatics to-date, including maneuvers such as chaos, tic-tocs, and auto-rotation landings which only exceptional expert human pilots can fly. Our most recent work in apprenticeship learning is providing traction on learning to perform challenging robotic manipulation tasks, such as knot-tying. I will also briefly highlight three other machine learning for robotics developments: Inverse reinforcement learning and its application to quadruped locomotion, Safe exploration in reinforcement learning which enables robots to learn on their own, and Learning for perception with application to robotic laundry.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-33460-3_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-28783-1_4,A Layered Learning Approach to 3D Multimodal People Detection Using Low-Cost Sensors in a Mobile Robot,Ambient Intelligence - Software and Applications,10.1007/978-3-642-28783-1_4,Springer,2012-01-01,In this paper we propose a novel approach for low cost multimodal detection of humans with mobile service robots. Detecting people is a key capability for robots that operate in populated environments. The main objective of this article is to illustrate the implementation of machine learning paradigms with computer vision techniques to improve human detection using 3D vision and a thermal sensor. Experimental results carried out in a manufacturing shop-floor show that the percentage of wrong classified using only Kinect is drastically reduced with the classification algorithms and with the combination of the three information sources.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-28783-1_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-34478-7_79,A Target-Reaching Controller for Mobile Robots Using Spiking Neural Networks,Neural Information Processing,10.1007/978-3-642-34478-7_79,Springer,2012-01-01,"Autonomous navigation plays important role in mobile robots. In this paper, a navigation controller based on spiking neural networks (SNNs) for mobile robots is presented. The proposed target-reaching navigation controller, in which the reactive architecture is used, is composed of three sub-controllers: the obstacle-avoidance controller and the wall-following controller using spiking neural networks (SNNs), and the goal-reaching controller. The experimental results show that the navigation controller can control the mobile robot to reach the target successfully while avoiding the obstacle and following the wall to get rid of the deadlock caused by local minimum. The proposed navigation controller does not require accurate mathematical models of the environment, and is suitable to unknown and unstructured environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-34478-7_79,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-22907-7_9,Gait Evolution for Humanoid Robot in a Physically Simulated Environment,Intelligent Computer Graphics 2011,10.1007/978-3-642-22907-7_9,Springer,2012-01-01,"This article describes a bio-inspired system and the associated series of experiments, for the evolution of walking behavior in a simulated humanoid robot. A previous study has demonstrated the potential of this approach for evolving controllers based on simulated humanoid robots with a restricted range of movements. The development of anthropomorphic bipedal locomotion is addressed by means of artificial evolution using a genetic algorithm. The proposed task is investigated using full rigid-body dynamics simulation of a bipedal robot with 15 degrees of freedom. Stable bipedal gait with a velocity of 0.94 m/s is realized. Locomotion controllers are evolved from scratch, for example neither does the evolved controller have any a priori knowledge on how to walk, nor does it have any information about the kinematics structure of the robot. Instead, locomotion control is achieved based on intensive use of sensory information. In this work, the emergence of non-trivial walking behaviors is entirely due to evolution.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-22907-7_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-30135-3_1,Introduction,Multi-Locomotion Robotic Systems,10.1007/978-3-642-30135-3_1,Springer,2012-01-01,"It is often pointed that the aging society resulted from declining birthrate become an inevitable problem. Its effect in production site is deterioration of workforce. If the ratio of elderly people to all population is high, it is natural to necessitate manufacturing technology that makes it possible to maintain productivity by a small number of workers. From this background, it is easily conceivable that robots play a role as substitute for human and conduct some tasks in collaboration to human. Besides, it is also conceivable that robots take an active part not only in production site such as factories but in human daily life and society such as home, medical scene, disaster relief, nursing care, and entertainment. In fact, pet robot, which is highly valued, is put on sale and highly functional animal-like robot, which is developed actively, is realized in recent years. Advancing robotics technology, it is expected to develop life-supporting robots to match with human life and cohabit with human e.g. nursing-care robots to attend elderly or sick people and home-helper robots to fulfill cleaning, washing, and cooking.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-30135-3_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-31368-4_8,Bio-inspired Navigation of Mobile Robots,Autonomous and Intelligent Systems,10.1007/978-3-642-31368-4_8,Springer,2012-01-01,"This paper presents a bio-inspired neural network algorithm for mobile robot path planning in unknown environments. A novel learning algorithm combining Skinner’s operant conditioning and a shunting neural dynamics model is applied to the path planning. The proposed algorithm depends mainly on an angular velocity map that has two parts: one from the target, which drives the robot to move toward to target, and the other from obstacles that repels the robot for obstacle avoidance. An improved biological learning algorithm is proposed for mobile robot path planning. Simulation results show that the proposed algorithm not only allows the robot to navigate efficiently in cluttered environments, but also significantly improves the computational and training time. The proposed algorithm offers insights into the research and applications of biologically inspired neural networks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-31368-4_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-29455-6_18,From the EXPO 2010 Shanghai to Look Forward to the Development of Robot Technology,Software Engineering and Knowledge Engineering: Theory and Practice,10.1007/978-3-642-29455-6_18,Springer,2012-01-01,"Starting from the robots exhibited in the Shanghai World Expo and the most advanced robotic products of today,this article will discuss the classification of robot applications as well as the main factors which influence the development of it and look towards the future development directions of robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-29455-6_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-33093-3_35,Unsupervised Learning of a Reduced Dimensional Controller for a Tendon Driven Robot Platform,From Animals to Animats 12,10.1007/978-3-642-33093-3_35,Springer,2012-01-01,"In this paper we present a developmental framework to carry out goal-oriented learning in a low-dimensional space. The framework uses two stages of learning: one to synthesise a set of motor synergies and reduce the dimensionality of the control space in an unsupervised manner, and another to carry out supervised learning in the reduced control space. We test our framework in a reaching task carried out on a (real) tendon-driven robot actuated by four artificial muscles. Our results show that the robot is capable of learning to reach using a reduced control space using no prior information about its body apart from that inherent to the unsupervised and supervised learning rules.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-33093-3_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4614-3064-3_1,Grounding Language through Evolutionary Language Games,Language Grounding in Robots,10.1007/978-1-4614-3064-3_1,Springer,2012-01-01,"This chapter introduces a new experimental paradigm for studying issues in the grounding of language and robots, and the integration of all aspects of intelligence into a single system. The paradigm is based on designing and implementing artificial agents so that they are able to play language games about situations they perceive and act upon in the real world. The agents are not pre-programmed with an existing language but with the necessary cognitive functions to self-organize communication systems from scratch, to learn them from human language users if there are sufficiently frequent interactions, and to participate in the on-going cultural evolution of language.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4614-3064-3_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-27329-2_52,A Machine Vision System for Chinese Chess-Playing Robot,Mechanical Engineering and Technology,10.1007/978-3-642-27329-2_52,Springer,2012-01-01,"This paper introduces a machine vision system for Chinese chess-playing robots which is usually regarded as a form of recreation. The machine vision system with two color cameras takes simultaneously two images of a chessboard and round pieces on the chessboard from different angles (views). Firstly, original images are handled by a series of image processing operations such as color conversion, binarization and denoise. Secondly, a hierarchical Hough transform algorithm was taken to detect lines and circles in the binarized image. Circles with reasonable radii nearly centered on the crossings of chessboard will be considered as pieces on the chessboard and its corresponding Chinese character inside the circle would be recognized based on BP neural network and ring intersection points. The 3D coordinates of pieces can be calculated through computation and then transformed to coordinates expressed by row and column. Finally, results of image processing and pattern recognition procedures will be sent to robot control system to manipulate end-effector of a robot to move round pieces from one place to another desired. Experimental results reveal that the designed machine vision system in this paper can work well with higher reliability.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-27329-2_52,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-27216-5_23,Adaptive Multi-robot Team Reconfiguration Using a Policy-Reuse Reinforcement Learning Approach,Advanced Agent Technology,10.1007/978-3-642-27216-5_23,Springer,2012-01-01,"We consider the problem of dynamically adjusting the formation and size of robot teams performing distributed area coverage, when they encounter obstacles or occlusions along their path. Based on our earlier formulation of the robotic team formation problem as a coalitional game called a weighted voting game (WVG), we show that the robot team size can be dynamically adapted by adjusting the WVG’s quota parameter. We use a Q-learning algorithm to learn the value of the quota parameter and a policy reuse mechanism to adapt the learning process to changes in the underlying environment. Experimental results using simulated e-puck robots within the Webots simulator show that our Q-learning algorithm converges within a finite number of steps in different types of environments. Using the learning algorithm also improves the performance of an area coverage application where multiple robot teams move in formation to explore an initially unknown environment by 5 − 10%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-27216-5_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-33093-3_30,Multi-timescale Nexting in a Reinforcement Learning Robot,From Animals to Animats 12,10.1007/978-3-642-33093-3_30,Springer,2012-01-01,"The term “nexting” has been used by psychologists to refer to the propensity of people and many other animals to continually predict what will happen next in an immediate, local, and personal sense. The ability to “next” constitutes a basic kind of awareness and knowledge of one’s environment. In this paper we present results with a robot that learns to next in real time, predicting thousands of features of the world’s state, including all sensory inputs, at timescales from 0.1 to 8 seconds. This was achieved by treating each state feature as a reward-like target and applying temporal-difference methods to learn a corresponding value function with a discount rate corresponding to the timescale. We show that two thousand predictions, each dependent on six thousand state features, can be learned and updated online at better than 10Hz on a laptop computer, using the standard TD( λ ) algorithm with linear function approximation. We show that this approach is efficient enough to be practical, with most of the learning complete within 30 minutes. We also show that a single tile-coded feature representation suffices to accurately predict many different signals at a significant range of timescales. Finally, we show that the accuracy of our learned predictions compares favorably with the optimal off-line solution.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-33093-3_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-29946-9_29,Introduction of Fixed Mode States into Online Profit Sharing and Its Application to Waist Trajectory Generation of Biped Robot,Recent Advances in Reinforcement Learning,10.1007/978-3-642-29946-9_29,Springer,2012-01-01,"In reinforcement learning of long-term tasks, learning efficiency may deteriorate when an agent’s probabilistic actions cause too many mistakes before task learning reaches its goal. The new type of state we propose – fixed mode – to which a normal state shifts if it has already received sufficient reward – chooses an action based on a greedy strategy, eliminating randomness of action selection and increasing efficiency. We start by proposing the combining of an algorithm with penalty avoiding rational policy making and online profit sharing with fixed mode states. We then discuss the target system and learning-controller design. In simulation, the learning task involves stabilizing of biped walking by using the learning controller to modify a robot’s waist trajectory. We then discuss simulation results and the effectiveness of our proposal.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-29946-9_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-32527-4_5,Adaptive Interface Mapping for Intuitive Teleoperation of Multi-DOF Robots,Advances in Autonomous Robotics,10.1007/978-3-642-32527-4_5,Springer,2012-01-01,"The supervisory control of multi-DOF robots by humans is a demanding application. If a single operator is tasked with direct control of a humanoid robot, performing coordinated tasks becomes non-intuitive and corresponds to unsustainable mental loads even for the most skilled operators. In this paper we use reinforcement learning to adaptively change the interface mapping from the operator user interface to the robot in such a way as to reduce the associated operator mental load. Based on the results of the interaction with the robot, we change the dynamical map describing the relationship between user commands and robot actions. The contribution of this paper is the adaptation of the interface map using reinforcement learning with reward functions associated with quantitative performance metrics. We present promising experimental results showing that the use of the proposed scheme can result in an easier to use interface map for a multi-DOF assistive robot controlled via a brain activity sensor.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-32527-4_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-28487-8_28,Evaluation of the Improved Penalty Avoiding Rational Policy Making Algorithm in Real World Environment,Intelligent Information and Database Systems,10.1007/978-3-642-28487-8_28,Springer,2012-01-01,"We focus on a potential capability of Exploitation-oriented Learning (XoL) in non-Markov multi-agent environments. XoL has some degree of rationality in non-Markov environments and is also confirmed the effectiveness by computer simulations. Penalty Avoiding Rational Policy Making algorithm (PARP) that is one of XoL methods was planed to learn a penalty avoiding policy. PARP is improved to save memories and to cope with uncertainties, that is called Improved PARP. Though the effectiveness of Improved PARP has been confirmed on computer simulations, there is no result in real world environment. In this paper, we show the effectiveness of Improved PARP in real world environment using a keepaway task that is a testbed of multi-agent soccer environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-28487-8_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4614-3064-3_4,Evolving Humanoid Behaviors for Language Games,Language Grounding in Robots,10.1007/978-1-4614-3064-3_4,Springer,2012-01-01,"Evolutionary techniques are applied to develop the neural control of humanoid robots. These robots were designed to act as agents in embodied language games. The basic ingredients needed to bring forth the desired behaviors are described: an appropriate physical simulator of the robots, an interactive evolution environment and various analysis tools. A modular approach to neural control is taken and is supported by a corresponding evolutionary algorithm, such that complete neural control networks are composed of specific functional units, the so called neuro-modules. Examples of such modules are described and their use is demonstrated by means of two developed networks for a walking and a gesture behavior.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4614-3064-3_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4614-3064-3_6,Posture Recognition Based on Slow Feature Analysis,Language Grounding in Robots,10.1007/978-1-4614-3064-3_6,Springer,2012-01-01,"Basic postures such as sit, stand and lie are ubiquitous in human interaction. In order to build robots that aid and support humans in their daily life, we need to understand how posture categories can be learned and recognized. This paper presents an unsupervised learning approach to posture recognition for a biped humanoid robot. The approach is based on Slow Feature Analysis (SFA), a biologically inspired algorithm for extracting slowly changing signals from signals varying on a fast time scale. Two experiments are carried out: First, we consider the problem of recognizing static postures in a multimodal sensory stream which consists of visual and proprioceptive stimuli. Secondly, we show how to extract a low-dimensional representation of the sensory state space which is suitable for posture recognition in a more complex setting. We point out that the beneficial performance of SFA in this task can be related to the fact that SFA computes manifolds which are used in robotics to model invariants in motion and behavior. Based on this insight, we also propose a method for using SFA components for guided exploration of the state space.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4614-3064-3_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-2467-2_209,Online Actor-Critic Learning for Motion Control of Non-holonomic Mobile Robot,"Electrical, Information Engineering and Mechatronics 2011",10.1007/978-1-4471-2467-2_209,Springer,2012-01-01,"This paper presents a control structure designed for non-holonomic mobile robots by an online algorithm based on policy iteration for learning the continuous-time (CT) optimal control solution with infinite horizon cost. The algorithm learns online in real-time to the solution of Hamilton–Jacobi–Bellman (HJB) equation which has been used for optimal control design. This method finds in real-time suitable approximations of both the optimal cost and control policy, while also guaranteeing closed-loop stability, which implemented as an actor/critic structure involves simultaneous continuous-time adaptation of both actor and critic neural networks (NNs). Simulation examples show the effectiveness of the new algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-2467-2_209,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-33269-2_60,Learning How to Select an Action: A Computational Model,Artificial Neural Networks and Machine Learning – ICANN 2012,10.1007/978-3-642-33269-2_60,Springer,2012-01-01,"Neurophysiological experimental results suggest that basal ganglia plays crucial role in action selection while dopamine modifies this process. There are computational models based on these experimental results for action selection. This work focuses on modification of action selection by dopamine release. In the model, a dynamical system is considered for action selection and modification of action selection process is realized by reinforcement learning. The ability of the proposed dynamical system is investigated by bifurcation analysis. Based on the results of this bifurcation analysis, the effect of reinforcement learning on action selection is discussed. The model is implemented on a mobile robot and a foraging task is realized where an exploration in an unfamiliar environment with training in the world is accomplished. Thus, this work fulfills its aim of showing the efficiency of brain-inspired computational models in controlling intelligent agents.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-33269-2_60,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-33486-3_8,APRIL: Active Preference Learning-Based Reinforcement Learning,Machine Learning and Knowledge Discovery in Databases,10.1007/978-3-642-33486-3_8,Springer,2012-01-01,"This paper focuses on reinforcement learning (RL) with limited prior knowledge. In the domain of swarm robotics for instance, the expert can hardly design a reward function or demonstrate the target behavior, forbidding the use of both standard RL and inverse reinforcement learning. Although with a limited expertise, the human expert is still often able to emit preferences and rank the agent demonstrations. Earlier work has presented an iterative preference-based RL framework: expert preferences are exploited to learn an approximate policy return, thus enabling the agent to achieve direct policy search. Iteratively, the agent selects a new candidate policy and demonstrates it; the expert ranks the new demonstration comparatively to the previous best one; the expert’s ranking feedback enables the agent to refine the approximate policy return, and the process is iterated. In this paper, preference-based reinforcement learning is combined with active ranking in order to decrease the number of ranking queries to the expert needed to yield a satisfactory policy. Experiments on the mountain car and the cancer treatment testbeds witness that a couple of dozen rankings enable to learn a competent policy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-33486-3_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-33503-7_43,Far-Field Terrain Perception Using Max-Margin Markov Networks,Intelligent Robotics and Applications,10.1007/978-3-642-33503-7_43,Springer,2012-01-01,"Far-field terrain perception plays an important role in performing outdoor robot navigation, such as earlier recognition of obstacles, efficient path planning. Stereo vision is an effective tool to detect obstacles in the near-field, but it cannot provide reliable information in the far-field, which may lead to suboptimal trajectories. This can be settled through the use of machine learning to accomplish near-to-farlearning, in which near-field terrain appearance features and stereo readings are used to train models able to predict far-field terrain. In this paper, we propose a near-to-far learning method using Max-Margin Markov Networks (M3N) to enhance long-range terrain perception for autonomous mobile robots. The method not only includes appearance features as its prediction basis, but also uses spatial relationships between adjacent parts. The experiment results show that our method outperforms other existing approaches.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-33503-7_43,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-94-007-4620-6_23,Inverse Kinematics Solver for Android Faces with Elastic Skin,Latest Advances in Robot Kinematics,10.1007/978-94-007-4620-6_23,Springer,2012-01-01,"The ability of androids to display facial expressions is a key factor towards more natural human-robot interaction. However, controlling the facial expressions of such robots with elastic facial skin is difficult due to the complexity of modeling the skin deformation. We propose a method to solve the inverse kinematics of android faces to control the android’s facial expression using target feature points. In our method, we use an artificial neural network to model the forward kinematics and minimizing a weighted squared error function for solving the inverse kinematics. We then implement an inverse kinematics solver and evaluate our method using an actual android.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-007-4620-6_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4614-3094-0_6,"Humans, Robots, Artificial Intelligence, and Autonomous Entities in Space",Social Foundations of Human Space Exploration,10.1007/978-1-4614-3094-0_6,Springer,2012-01-01,"Humans and physical technologies have interacted intimately throughout all of human existence. Humans as such have never existed “without technology.” Indeed, humans become “human” and change the meaning of being human in large measure by interacting with each other and their environment through technologies. For much of human history, our technologies, though necessary tools for human activities, were largely or completely dumb – dependent on humans to function. Over time, we have also made smarter and smarter technologies, able to do more on their own, if properly designed, built, and maintained.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4614-3094-0_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-1-84996-169-1_1,Machine Vision for Industrial Applications,Machine Vision Handbook,10.1007/978-1-84996-169-1_1,Springer,2012-01-01,"Machine Vision is related to, but distinct from Computer Vision, Image Processing, Artificial Intelligence & Pattern Recognition. The subject is concerned with the engineering of integrated mechanical-optical-electronic-software systems for examining natural objects and materials, human artifacts and manufacturing processes, in order to detect defects and improve quality, operating efficiency and the safety of both products and processes. It is also used to control machines used in manufacturing. Machine Vision necessarily involves the harmonious integration of mechanical handling, lighting, optics, video cameras, image sensors (visible, UV, IR and X-ray sensor arrays, as well as laser scanners), digital, analogue and video electronics, signal processing, image processing, computer systems architecture, software, industrial engineering, human-computer interfacing, control systems, manufacturing, existing work practices and quality assurance methods. Machine Vision is not a scientific endeavour; it is a branch of Systems Engineering. Hence, consideration of application requirements pays a key role in the design of practical vision systems. The basic philosophy of Machine Vision is set out in this chapter and the structure of this book is outlined. This is a pragmatic, empirical, experimental subject and is not unduly burdened by the search for mathematical rigour, or theoretical purity. There is one simple design maxim: if it works, use it! This is justified here by consideration of lessons learned from four practical application studies. Later in the book these same ideas will emerge many times over.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-84996-169-1_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-29350-4_62,Will a Robot Be a Human?,Artificial Intelligence and Soft Computing,10.1007/978-3-642-29350-4_62,Springer,2012-01-01,"It has been a long-standing contention on whether or not robots can eventually be as intelligent as humans. Neither side of the contention has provided solid arguments of proving this way or the other. We reason in this article that a digital robot will not have same mental experience as a human so far as the self-awareness of an existing person cannot be duplicated. This thesis draws a line between biological humans and digital robots. It makes us rethink the issues such as the limitation of computer software, how far machine intelligence can go, whether robots will eventually dominate humans intellectually, what machines are, and who we are.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-29350-4_62,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-31525-1_26,Parallel Implementation of Instinctual and Learning Neural Mechanisms in a Simulated Mobile Robot,Biomimetic and Biohybrid Systems,10.1007/978-3-642-31525-1_26,Springer,2012-01-01,"The question of how biological learning and instinctive neural mechanisms interact with each other in the course of development to produce novel, adaptive behaviors was explored via a robotic simulation. Instinctive behavior in the agent was implemented in a hard-wired network which produced obstacle avoidance. Phototactic behavior was produced in two serially connected plastic layers. A self-organizing feature map was combined with a reinforcement learning layer to produce a learning network. The reinforcement came from an internally generated signal. Both the adaptive and fixed networks supplied motor control signals to the robot motors. The sizes of the self-organizing layer, reinforcement layer, and the complexity of the environment were varied and effects on robot phototactic efficiency and accuracy in the mature networks were measured. A significant interaction of the three independent variables was found, supporting the idea that organisms evolve distinct combinations of instinctive and plastic neural mechanisms which are tailored to the demands of the environment in which their species evolved.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-31525-1_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-33260-9_34,Neural Network Modeling of a Flexible Manipulator Robot,Computer Information Systems and Industrial Management,10.1007/978-3-642-33260-9_34,Springer,2012-01-01,"This paper presents an artificial neural networks application for a flexible process modeling. A flexible planar single-link manipulator robot is considered. The dynamic behavior of this process is described using Lagrange equations and finite elements method. The artificial neural networks are all variations on the parallel distributed processing (PDP) idea. The architecture of each network is based on very similar building blocks which perform the processing. Therefore, two feed-forward and recurrent neural networks are developed and trained using back-propagation algorithm to identify the dynamics of the flexible process. Simulation results of the system responses are given and discussed in terms of level of error reduction. Finally, a conclusion encloses the paper.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-33260-9_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-010-0257-9,A new approach to simultaneous localization and map building with implicit model learning using neuro evolutionary optimization,Applied Intelligence,10.1007/s10489-010-0257-9,Springer,2012-01-01,"This paper presents Neuro-Evolutionary Optimization SLAM (NeoSLAM) a novel approach to SLAM that uses a neural network (NN) to autonomously learn both a nonlinear motion model and the noise statistics of measurement data. The NN is trained using evolutionary optimization to learn the residual error of the motion model, which is then added to the odometry data to obtain the full motion model estimate. Stochastic optimization is used, to accommodate any kind of cost function. Prediction and correction are performed simultaneously within our neural framework, which implicitly integrates the motion and sensor models. An evolutionary programming (EP) algorithm is used to progressively refine the neural model until it generates a trajectory that is most consistent with the actual sensor measurements. During this learning process, NeoSLAM does not require any prior knowledge of motion or sensor models and shows consistently good performance regardless of the robot and the sensor noise type. Furthermore, NeoSLAM does not require the data association step at loop closing which is crucial in most other SLAM algorithms, but can still generate an accurate map. Experiments in various complex environments with widely-varying types of noise show that the learning capability of NeoSLAM ensures performance that is consistently less sensitive to noise and more accurate than that of other SLAM methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-010-0257-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-33269-2_40,Self-calibrating Marker Tracking in 3D with Event-Based Vision Sensors,Artificial Neural Networks and Machine Learning – ICANN 2012,10.1007/978-3-642-33269-2_40,Springer,2012-01-01,"Following an object’s position relative to oneself is a fundamental functionality required in intelligent real-world interacting robotic systems. This paper presents a computationally efficient vision based 3D tracking system, which can ultimately operate in real-time on autonomous mobile robots in cluttered environments. At the core of the system, two neural inspired event-based dynamic vision sensors (eDVS) independently track a high frequency flickering LED in their respective 2D angular coordinate frame. A self-adjusted feed-forward neural network maps those independent 2D angular coordinates into a Cartesian 3D position in world coordinates. During an initial calibration phase, an object composed of multiple independent markers with known geometry provides relative position information between those markers for network training (without ever using absolute world coordinates for training). In a subsequent application phase tracking a single marker yields position estimates relative to sensor origin, while tracking multiple markers provides additional orientation. The neural inspired vision-based tracking system runs in real-time on ARM7 microcontrollers, without the need for an external PC.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-33269-2_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4614-3064-3_2,"Myon, a New Humanoid",Language Grounding in Robots,10.1007/978-1-4614-3064-3_2,Springer,2012-01-01,"This chapter introduces the modular humanoid robot Myon, covering its mechatronical design, embedded low-level software, distributed processing architecture, and the complementary experimental environment. The Myon humanoid is the descendant of various robotic hardware platforms which have been built over the years and therefore combines the latest research results on the one hand, and the expertise of how a robot has to be built for experiments on embodiment and language evolution on the other hand. In contrast to many other platforms, the Myon humanoid can be used as a whole or in parts. Both the underlying architecture and the supportive application software allow for ad hoc changes in the experimental setup.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4614-3064-3_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-23424-8_10,An Interactively Constrained Neuro-Evolution Approach for Behavior Control of Complex Robots,Variants of Evolutionary Algorithms for Real-World Applications,10.1007/978-3-642-23424-8_10,Springer,2012-01-01,"Behavior control of complex technical systems, such as robots, is a challenging problem. In this context, embodied neuro-control is a bio-inspired method for handling this type of problems, and evolutionary robotics has taken up some essential research topics in this field. However, for systems with many multi-modal sensor inputs and actuating outputs, new evolutionary methods have to be applied because the search spaces are high-dimensional and comprise many local optima. This becomes even harder when functional recurrent network structures cannot be given in advance and have to be evolved together with other parameters like synaptic weights and bias terms. This chapter describes a new evolutionary method, called Interactively Constrained Neuro  −  Evolution (ICONE), which restricts large search spaces by utilizing not only domain knowledge and user experience but also by applying constraints to the networks. The interactive use of this tool enables the experimenter to bias the solution space towards desired control approaches. The application of the ICONE method is demonstrated by evolving a walking behavior for a physical humanoid robot, for which a whole library of behaviors has been developed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-23424-8_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4614-3064-3_3,Neural Implementation of Behavior Control,Language Grounding in Robots,10.1007/978-1-4614-3064-3_3,Springer,2012-01-01,"The dynamical systems approach and recurrent neural control provides a rich foundation for the generation of natural behaviors on autonomous robots because the environment, the robot, and control systems are regarded as a single dynamical system. Robot behaviors can thus be shaped as attractors of this dynamical system. Within this framework, sensorimotor loops for walking and keeping balance have been realized on the Myon robot. Different behaviors can be shaped as co-existing attractors which allows for smooth and reliable switching between them. We introduce the concept of Cognitive Sensorimotor Loops (CSLs) as well as the use of quadrics and discuss their benefits for behavior control. The presentation of every technique is accompanied by a real world example using humanoid robots. Finally, a grasping motion is developed using the same methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4614-3064-3_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-24728-6_4,A Robust Fault Detection and Isolation Scheme for Robot Manipulators Based on Neural Networks,Advanced Intelligent Computing,10.1007/978-3-642-24728-6_4,Springer,2012-01-01,"This paper investigates an algorithm to the robust fault detection and isolation(FDI) in robot manipulators using Neural Networks(NNs). Two Neural Networks are utilized: the first NN (NN1) is employed to reproduce the robot’s dynamic behavior, while the second NN (NN2) is used to achieve the online approximation for fault detection and isolation. This approach focused on detecting changes in the robot dynamics due to faults. An online monitoring is used not only to detect faults but also to provide estimates of the fault characteristics. A computer simulation example for a two link robot manipulator shows the effectiveness of the proposed algorithm in the fault detection and isolation design process.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-24728-6_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-33515-0_2,Intelligent Prescription-Diagnosis Function for Rehabilitation Training Robot System,Intelligent Robotics and Applications,10.1007/978-3-642-33515-0_2,Springer,2012-01-01,"A prescription-diagnosis function based on integrating support vector machine and generalized dynamic fuzzy neural networks (SVM-GDFNN) is developed to automatically recommend a suitable training mode to the impaired limb. Considering the outstanding generalization ability and misclassified samples mainly distributed nearby the support vector for SVM method, SVM is adopted to recommend a preliminary prescription diagnosis for the sample and GDFNN is employed to rediagnose the sample nearby the support vector. Finally, the training mode of impaired limb is prescribed according to the designed principles. In addition, wavelet packet decomposition is applied to extract the features representing the impaired-limb movement performance. Clinical experiment results indicate that the suggested method can effectively reduce the misdiagnosis and serve with a high diagnostic accuracy. Meanwhile, the designed rehabilitation system well manages the promising prescription-diagnosis function, improving the intelligent level.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-33515-0_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-33269-2_42,A Proposed Neural Control for the Trajectory Tracking of a Nonholonomic Mobile Robot with Disturbances,Artificial Neural Networks and Machine Learning – ICANN 2012,10.1007/978-3-642-33269-2_42,Springer,2012-01-01,"In this paper, a trajectory tracking control problem for a nonholonomic mobile robot by the integration of a kinematic neural controller (KNC) and a torque neural controller (TNC) is proposed, where both the kinematic and dynamic models contains disturbances. The KNC is a variable structure controller (VSC) based on the sliding mode control theory (SMC), and applied to compensate the kinematic disturbances. The TNC is a inertia-based controller constituted of a dynamic neural controller (DNC) and a robust neural compensator (RNC), and applied to compensate the mobile robot dynamics, and bounded unknown disturbances. Stability analysis with basis on Lyapunov method and simulations results are provided to show the effectiveness of the proposed approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-33269-2_42,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-35506-6_31,Transparent Neural Networks,Artificial General Intelligence,10.1007/978-3-642-35506-6_31,Springer,2012-01-01,"We present the transparent neural networks , a graph-based computational model that was designed with the aim of facilitating human understanding. We also give an algorithm for developing such networks automatically by interacting with the environment. This is done by adding and removing structures for spatial and temporal memory. Thus we automatically obtain a monolithic computational model which integrates concept formation with deductive, inductive, and abductive reasoning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-35506-6_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-33269-2_38,Exploratory Behaviour Depends on Multisensory Integration during Spatial Learning,Artificial Neural Networks and Machine Learning – ICANN 2012,10.1007/978-3-642-33269-2_38,Springer,2012-01-01,"Active exploration is a necessary component of a putative spatial representation system in the mammalian brain. We address the problem of how spatial exploratory behaviour is generated in rodents by combining an artificial neural network model of place coding with a multiobjective evolutionary algorithm that tunes the model parameters so as to maximise the efficiency of environment exploration. A central property of the spatial representation model is an online calibration between external visual cues and path integration, a widely accepted concept in theoretical accounts of spatial learning in animals. We find that the artificially evolved exploration model leads to recurrent patterns of exploratory behaviour in a way observed in experimental studies of spatial exploration in rodents. Our results provide a link between the functional organisation of the biological spatial learning network and the observed high-level patterns of exploratory behaviour.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-33269-2_38,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-33093-3_14,Multimodal Integration of Visual Place Cells and Grid Cells for Navigation Tasks of a Real Robot,From Animals to Animats 12,10.1007/978-3-642-33093-3_14,Springer,2012-01-01,"In the present study, we propose a model of multimodal place cells merging visual and proprioceptive primitives. First we will briefly present our previous sensory-motor architecture, highlighting limitations of a visual-only based system. Then we will introduce a new model of proprioceptive localization, giving rise to the so-called grid cells, wich are congruent with neurobiological studies made on rodent. Finally we will show how a simple conditionning rule between both modalities can outperform visual-only driven models by producing robust multimodal place cells. Experiments show that this model enhances robot localization and also allows to solve some benchmark problems for real life robotics applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-33093-3_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-32909-8_31,3D Vision-Based Autonomous Navigation System Using ANN and Kinect Sensor,Engineering Applications of Neural Networks,10.1007/978-3-642-32909-8_31,Springer,2012-01-01,"In this paper, we present an autonomous navigation system based on a finite state machine (FSM) learned by an artificial neural network (ANN) in an indoor navigation task. This system uses a kinect as the only sensor. In the first step, the ANN is trained to recognize the different specific environment configurations, identifying the different environment situations (states) based on the kinect detections. Then, a specific sequence of states and actions is generated for any route defined by the user, configuring a path in a topological like map. So, the robot becomes able to autonomously navigate through this environment, reaching the destination after going through a sequence of specific environment places, each place being identified by its local properties, as for example, straight path, path turning to left, path turning to right, bifurcations and path intersections. The experiments were performed with a Pioneer P3-AT robot equipped with a kinect sensor in order to validate and evaluate this approach. The proposed method demonstrated to be a promising approach to autonomous mobile robots navigation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-32909-8_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-011-9553-9,Occupancy Grid Learning Using Contextual Forward Modelling,Journal of Intelligent & Robotic Systems,10.1007/s10846-011-9553-9,Springer,2011-12-01,A mode versus clarity dilemma exists in occupancy grid based robotic mapping. This arises as two general approaches have emerged in the domain with diametric operational modes and differing representational abilities; the inverse and the forward approach. Their classification relates to the sensory model employed by the approaches. The inverse approach is characterised by an ability to construct a map in real time. This ability comes at the cost of reduced representational clarity however. The forward approach is capable of producing more accurate maps but requires all sensory data a priori. This work investigates if sub dividing the mapping problem into its constituent elements of sensor data evaluation and representation may facilitate improved real time map generation. ConForM ( Con textual For ward M odelling) is presented as a technique for spatial perception and map building which addresses this problem which embodies this approach. Results from in-depth empirical evaluation illustrate the associated improvement in map quality resultant from the technique.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-011-9553-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.3103/S0147688211050054,Dynamic planning of robot behavior based on an “intellectual” neuron network,Scientific and Technical Information Processing,10.3103/S0147688211050054,Springer,2011-12-01,"We examine the questions of applying large pyramidal neural (intellectual neuron) networks to solve equipment object control problems. We consider the description of a system for dynamic planning of mobile robot behavior, constructed based on a network of similar elements.",http://link.springer.com/openurl/fulltext?id=doi:10.3103/S0147688211050054,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-011-0113-z,Learning the Selection of Actions for an Autonomous Social Robot by Reinforcement Learning Based on Motivations,International Journal of Social Robotics,10.1007/s12369-011-0113-z,Springer,2011-11-01,"Autonomy is a prime issue on robotics field and it is closely related to decision making. Last researches on decision making for social robots are focused on biologically inspired mechanisms for taking decisions. Following this approach, we propose a motivational system for decision making, using internal (drives) and external stimuli for learning to choose the right action. Actions are selected from a finite set of skills in order to keep robot’s needs within an acceptable range. The robot uses reinforcement learning in order to calculate the suitability of every action in each state. The state of the robot is determined by the dominant motivation and its relation to the objects presents in its environment. The used reinforcement learning method exploits a new algorithm called Object Q-Learning. The proposed reduction of the state space and the new algorithm considering the collateral effects (relationship between different objects) results in a suitable algorithm to be applied to robots living in real environments. In this paper, a first implementation of the decision making system and the learning process is implemented on a social robot showing an improvement in robot’s performance. The quality of its performance will be determined by observing the evolution of the robot’s wellbeing.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-011-0113-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10339-011-0404-1,Model learning for robot control: a survey,Cognitive Processing,10.1007/s10339-011-0404-1,Springer,2011-11-01,"Models are among the most essential tools in robotics, such as kinematics and dynamics models of the robot’s own body and controllable external objects. It is widely believed that intelligent mammals also rely on internal models in order to generate their actions. However, while classical robotics relies on manually generated models that are based on human insights into physics, future autonomous, cognitive robots need to be able to automatically generate models that are based on information which is extracted from the data streams accessible to the robot. In this paper, we survey the progress in model learning with a strong focus on robot control on a kinematic as well as dynamical level. Here, a model describes essential information about the behavior of the environment and the influence of an agent on this environment. In the context of model-based learning control, we view the model from three different perspectives. First, we need to study the different possible model learning architectures for robotics. Second, we discuss what kind of problems these architecture and the domain of robotics imply for the applicable learning methods. From this discussion, we deduce future directions of real-time learning algorithms. Third, we show where these scenarios have been used successfully in several case studies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10339-011-0404-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-011-0366-y,Special issue on social impact of AI: killer robots or friendly fridges,AI & SOCIETY,10.1007/s00146-011-0366-y,Springer,2011-10-11,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-011-0366-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-010-0212-9,A neural network based retrainable framework for robust object recognition with application to mobile robotics,Applied Intelligence,10.1007/s10489-010-0212-9,Springer,2011-10-01,"In this paper, we address object recognition for a mobile robot which is deployed in a multistory building. To move to another floor, a mobile robot should recognize various objects related to an elevator, e.g., elevator control, call buttons, and LED displays. To this end, we propose a neural network based retrainable framework for object recognition, which consists of four components—preprocessing, binary classification, object identification, and outlier rejection. The binary classifier, a key component of our system, is a neural network that can be retrained, the motivation of which is to adapt to varying environments, especially with illuminations. Without incurring any extra process to prepare new training samples for retraining, they are freely obtained as a result of the outlier rejection component, being extracted on-line. To realize a practical system, we adopt a parallel architecture integrating both recognition and retraining processes for seamless object recognition, and furthermore detect and cope with the deterioration of a retrained neural network to ensure high reliability. We demonstrate the positive effect of retraining on the object recognition performance by conducting experiments over hundreds of images obtained in daytime and nighttime.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-010-0212-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-010-0496-z,Combining GRN modeling and demonstration-based programming for robot control,Neural Computing and Applications,10.1007/s00521-010-0496-z,Springer,2011-09-01,"In recent years, gene regulatory networks (GRNs) have been proposed to work as reliable and robust control mechanisms for robots. Because recurrent neural networks (RNNs) have the unique characteristic of presenting system dynamics over time, we thus adopt such kind of network structure and the principles of gene regulation to develop a biologically and computationally plausible GRN model for robot control. To simulate the regulatory effects and to make our model inferable from time-series data, we also implement an enhanced network-learning algorithm to derive network parameters efficiently. In addition, we present a procedure of programming-by-demonstration to collect behavior sequence data of the robot as expression profiles, and then employ our network-modeling framework to infer controllers. To verify the proposed approach, experiments have been conducted, and the results show that our regulatory model can be inferred for robot control successfully.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-010-0496-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.2478/s13230-012-0003-6,Modular non-computational-connectionist-hybrid neural network approach to robotic systems,Paladyn,10.2478/s13230-012-0003-6,Springer,2011-09-01,"Spiking neural networks are usually limited in their applications due to their complex mathematical models and the lack of intuitive learning algorithms. In this paper, a simpler, novel neural network derived from a leaky integrate and fire neuron model, the ‘cavalcade’ neuron, is presented. A simulation for the neural network has been developed and two basic learning algorithms implemented within the environment. These algorithms successfully learn some basic temporal and instantaneous problems. Inspiration for neural network structures from these experiments are then taken and applied to process sensor information so as to successfully control a mobile robot.",http://link.springer.com/openurl/fulltext?id=doi:10.2478/s13230-012-0003-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13369-011-0081-5,Using Linde Buzo Gray Clustering Neural Networks for Solving the Motion Equations of a Mobile Robot,Arabian Journal for Science and Engineering,10.1007/s13369-011-0081-5,Springer,2011-07-29," In this paper, motion equations for the synchro-drive robot Nomad 200 are solved by using Linde Buzo Gray (LBG) clustering neural networks. The trajectories of the Nomad 200 are assumed to be composed of straight line segments and curves. The structure of the curves is determined by only two parameters, turn angle and translational velocity in the curve. The curves of the trajectories are found by using artificial neural networks (ANN) and the LBG clustered ANN. In this study a clustering method is used to improve the learning and test the performance of the ANN. In general, the LBG algorithm is used in image processing as a quantizer. This is the first publication where the LBG algorithm is successfully used in clustering ANN data sets. Thus, the best training data set of the ANN is achieved and minimum error values are obtained. It is shown that LBG-ANN models are better than the classic ANN models.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13369-011-0081-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13347-011-0038-3,Martial Bliss: War and Peace in Popular Science Robotics,Philosophy & Technology,10.1007/s13347-011-0038-3,Springer,2011-07-13,"In considering how to best deploy robotic systems in public and private sectors, we must consider what individuals will expect from the robots with which they interact. Public awareness of robotics—as both military machines and domestic helpers—emerges out of a braided stream composed of science fiction and popular science. These two genres influence news media, government and corporate spending, and public expectations. In the Euro-American West, both science fiction and popular science are ambivalent about the military applications for robotics, and thus we can expect their readers to fear the dangers posed by advanced robotics while still eagerly anticipating the benefits to be accrued through them. The chief pop science authors in robotics and artificial intelligence have a decidedly apocalyptic bent and have thus been described as leaders in a social movement called ""Apocalyptic AI."" In one form or another, such authors look forward to a transcendent future in which machine life succeeds human life, thanks to the march of evolutionary progress. The apocalyptic promises of popular robotics presume that presently exponential growth in computing will continue indefinitely, producing a ""Singularity."" During the Singularity, technological progress will be so rapid that undreamt of changes will take place on earth, the most important of which will be the evolutionary succession of human beings by massively intelligent robots and the ""uploading"" of human consciousness into computer bodies. This supposedly inevitable transition into post-biological life looms across the entire scope of pop robotics and artificial intelligence (AI), and it is from beneath that shadow that all popular books engage the military and the ethics of warfare. Creating a just future will require that we transcend the apocalyptic discourse of pop science and establish an ethical approach to researching and deploying robots, one that emphasizes human rather than robot welfare; doing so will require the collaboration of social scientists, humanists, and scientists.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13347-011-0038-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-010-0417-1,Identification of a golf swing robot using soft computing approach,Neural Computing and Applications,10.1007/s00521-010-0417-1,Springer,2011-07-01,"Golf swing robots have been recently developed in an attempt to simulate the ultra high-speed swing motions of golfers. Accurate identification of a golf swing robot is an important and challenging research topic, which has been regarded as a fundamental basis in the motion analysis and control of the robots. But there have been few studies conducted on the golf swing robot identification, and comparative analyses using different kinds of soft computing methodologies have not been found in the literature. This paper investigates the identification of a golf swing robot based on four kinds of soft computing methods, including feedforward neural networks (FFNN), dynamic recurrent neural networks (DRNN), fuzzy neural networks (FNN) and dynamic recurrent fuzzy neural networks (DRFNN). The performance comparison is evaluated based on three sets of swing trajectory data with different boundary conditions. The sensitivity of the results to the changes in system structure and learning rate is also investigated. The results suggest that both FNN and DRFNN can be used as a soft computing method to identify a golf robot more accurately than FFNN and DRNN, which can be used in the motion control of the robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-010-0417-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-010-9466-z,A Dual Neural Network for Kinematic Control of Redundant Manipulators Using Input Pattern Switching,Journal of Intelligent & Robotic Systems,10.1007/s10846-010-9466-z,Springer,2011-07-01,"This paper presents a dual neural network for kinematic control of a seven degrees of freedom robot manipulator. The first network is a static multilayer perceptron with two hidden layers which is trained to mimic the Jacobian of a seven DOF manipulator. The second network is a recurrent neural network which is used for determining the inverse kinematics solutions of the manipulator; The redundancy is used to minimize the joint velocities in the least squares sense. Simulation results show relatively good comparison between the outputs of the actual Jacobian matrix and multilayer neural network. The first network maps motions of the seven joints of the manipulator into 42 elements of the Jacobian matrix, with surprisingly smaller computations than the actual trigonometric function evaluations. A new technique, input-pattern-switching, is presented which improves the global training of the static network. The recurrent network was designed to work with the neural network approximation of the Jacobian matrix instead of the actual Jacobian. The combination of these two networks has resulted in a time-efficient procedure for kinematic control of robot manipulators which avoids most of the complexity present in the classical-trigonometric-based methods. Also, by electronic implementation of the networks, kinematic solutions can be obtained in a very timely manner (few nanoseconds).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-010-9466-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-010-9462-3,Adaptive Impedance Control for Upper-Limb Rehabilitation Robot Using Evolutionary Dynamic Recurrent Fuzzy Neural Network,Journal of Intelligent & Robotic Systems,10.1007/s10846-010-9462-3,Springer,2011-06-01,"Control system implementation is one of the major difficulties in rehabilitation robot design. A newly developed adaptive impedance controller based on evolutionary dynamic fuzzy neural network (EDRFNN) is presented, where the desired impedance between robot and impaired limb can be regulated in real time according to the impaired limb’s physical recovery condition. Firstly, the impaired limb’s damping and stiffness parameters for evaluating its physical recovery condition are online estimated by using a slide average least squares (SALS)identification algorithm. Then, hybrid learning algorithms for EDRFNN impedance controller are proposed, which comprise genetic algorithm (GA), hybrid evolutionary programming (HEP) and dynamic back-propagation (BP) learning algorithm. GA and HEP are used to off-line optimize DRFNN parameters so as to get suboptimal impedance control parameters. Dynamic BP learning algorithm is further online fine-tuned based on the error gradient descent method. Moreover, the convergence of a closed loop system is proven using the discrete-type Lyapunov function to guarantee the global convergence of tracking error. Finally, simulation results show that the proposed controller provides good dynamic control performance and robustness with regard to the change of the impaired limb’s physical condition.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-010-9462-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12559-010-9090-z,Dissociated Emergent Response System and Fine-Processing System in Human Neural Network and a Heuristic Neural Architecture for Autonomous Humanoid Robots,Cognitive Computation,10.1007/s12559-010-9090-z,Springer,2011-06-01,"The current study investigated the functional connectivity of the primary sensory system with resting state fMRI and applied such knowledge into the design of the neural architecture of autonomous humanoid robots. Correlation and Granger causality analysis was utilized to reveal the functional connectivity patterns. Dissociation was found among the primary sensory system, in that the olfactory cortex and the somatosensory cortex were strongly connected to the amygdala whereas the visual cortex and the auditory cortex were strongly connected with the frontal cortex. The posterior cingulate cortex and the anterior cingulate cortex were found to maintain constant communication with the primary sensory system, the frontal cortex, and the amygdala. Such neural architecture inspired the design of dissociated emergent response system and fine-processing system in autonomous humanoid robots, with separate processing units and another consolidation center to coordinate the two systems. Such design can help autonomous robots to detect and respond quickly to danger, so as to maintain their sustainability and independence.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12559-010-9090-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12541-011-0054-3,Neural network based hybrid force/position control for robot manipulators,International Journal of Precision Engineering and Manufacturing,10.1007/s12541-011-0054-3,Springer,2011-06-01,"This paper presents a neural network based adaptive control scheme for hybrid force/position control for rigid robot manipulators. Firstly the robot dynamics is decomposed into force, position and redundant joint subspaces. Based on this decomposition, a neural network based controller is proposed that achieves the stability in the sense of Lyapunov for desired interaction force between the end-effector and the environment as well as regulate robot tip position in cartesian space. A feedforward neural network is employed to learn the parametric uncertainties, existing in the dynamical model of the robot manipulator. Finally numerical simulation studies are carried out for a two link rigid robot manipulator.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12541-011-0054-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00607-010-0133-9,Zhang neural network solving for time-varying full-rank matrix Moore–Penrose inverse,Computing,10.1007/s00607-010-0133-9,Springer,2011-06-01,"Zhang neural networks (ZNN), a special kind of recurrent neural networks (RNN) with implicit dynamics, have recently been introduced to generalize to the solution of online time-varying problems. In comparison with conventional gradient-based neural networks, such RNN models are elegantly designed by defining matrix-valued indefinite error functions. In this paper, we generalize, investigate and analyze ZNN models for online time-varying full-rank matrix Moore–Penrose inversion. The computer-simulation results and application to inverse kinematic control of redundant robot arms demonstrate the feasibility and effectiveness of ZNN models for online time-varying full-rank matrix Moore–Penrose inversion.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00607-010-0133-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-011-9224-5,Mobility characterization for autonomous mobile robots using machine learning,Autonomous Robots,10.1007/s10514-011-9224-5,Springer,2011-05-01,"This paper presents a supervised learning approach to improving the autonomous mobility of wheeled robots through sensing the robot’s interaction with terrain ‘underfoot.’ Mobility characterization is cast as a hierarchical task, in which pre-immobilization detection is achieved using support vector machines in time to prevent full immobilization, and if a pre-immobilization condition is detected, the associated terrain feature affecting mobility is identified using a Hidden Markov model. These methods are implemented using a hierarchical, layered control scheme developed for the Yeti robot, a 73-kg, four-wheeled robot designed to perform autonomous medium-range missions in polar terrain. The methodology is motivated by the difficultly of visually recognizing terrain features that impact mobility in low contrast terrain. The efficacy of the approach is evaluated using data from a suite of proprioceptive sensors. Real-time implementation shows that Yeti can consistently detect pre-immobilization conditions, stop in time to avoid unrecoverable immobilization, identify the terrain feature presenting the mobility challenge, and execute an escape sequence to retreat from the condition.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-011-9224-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-011-0215-2,SSPQL: Stochastic shortest path-based Q-learning,"International Journal of Control, Automation and Systems",10.1007/s12555-011-0215-2,Springer,2011-04-01,"Reinforcement learning (RL) has been widely used as a mechanism for autonomous robots to learn state-action pairs by interacting with their environment. However, most RL methods usually suffer from slow convergence when deriving an optimum policy in practical applications. To solve this problem, a stochastic shortest path-based Q-learning (SSPQL) is proposed, combining a stochastic shortest path-finding method with Q-learning, a well-known model-free RL method. The rationale is, if a robot has an internal state-transition model which is incrementally learnt, then the robot can infer the local optimum policy by using a stochastic shortest path-finding method. By increasing state-action pair values comprising of these local optimum policies, a robot can then reach a goal quickly and as a result, this process can enhance convergence speed. To demonstrate the validity of this proposed learning approach, several experimental results are presented in this paper.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-011-0215-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-010-9212-1,Learning the behavior model of a robot,Autonomous Robots,10.1007/s10514-010-9212-1,Springer,2011-02-01,"Complex artifacts are designed today from well specified and well modeled components. But most often, the models of these components cannot be composed into a global functional model of the artifact. A significant observation, modeling and identification effort is required to get such a global model, which is needed in order to better understand, control and improve the designed artifact. Robotics provides a good illustration of this need. Autonomous robots are able to achieve more and more complex tasks, relying on more advanced sensor-motor functions. To better understand their behavior and improve their performance, it becomes necessary but more difficult to characterize and to model, at the global level, how robots behave in a given environment. Low-level models of sensors, actuators and controllers cannot be easily combined into a behavior model. Sometimes high level models operators used for planning are also available, but generally they are too coarse to represent the actual robot behavior. We propose here a general framework for learning from observation data the behavior model of a robot when performing a given task. The behavior is modeled as a Dynamic Bayesian Network , a convenient stochastic structured representations. We show how such a probabilistic model can be learned and how it can be used to improve, on line, the robot behavior with respect to a specific environment and user preferences. Framework and algorithms are detailed; they are substantiated by experimental results for autonomous navigation tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-010-9212-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1631/jzus.C0910528,A tracking and predicting scheme for ping pong robot,Journal of Zhejiang University SCIENCE C,10.1631/jzus.C0910528,Springer,2011-02-01,"We describe a new tracking and predicting scheme applied to a lab-made ping pong robot. The robot has a monocular vision system comprised of a camera and a light. We propose an optimized strategy to calibrate the light center using the least square method. An ellipse fitting method is used to precisely locate the center of ball and shadow on the captured image. After the triangulation of the ball position in the world coordinates, a tracking algorithm based on a Kalman filter outputs an accurate estimation of the flight states including the ball position and velocity. Furthermore, a neural network model is constructed and trained to predict the following flight path. Experimental results show that this scheme can achieve a good predicting precision and success rate of striking an incoming ball. The robot can achieve a success rate of about 80% to return a flight ball of 5 m/s to the opposite court.",http://link.springer.com/openurl/fulltext?id=doi:10.1631/jzus.C0910528,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00422-011-0422-1,Deriving neural network controllers from neuro-biological data: implementation of a single-leg stick insect controller,Biological Cybernetics,10.1007/s00422-011-0422-1,Springer,2011-02-01,"This article presents modular recurrent neural network controllers for single legs of a biomimetic six-legged robot equipped with standard DC motors. Following arguments of Ekeberg et al. (Arthropod Struct Dev 33:287–300, 2004 ), completely decentralized and sensori-driven neuro-controllers were derived from neuro-biological data of stick-insects. Parameters of the controllers were either hand-tuned or optimized by an evolutionary algorithm. Employing identical controller structures, qualitatively similar behaviors were achieved for robot and for stick insect simulations. For a wide range of perturbing conditions, as for instance changing ground height or up- and downhill walking, swing as well as stance control were shown to be robust. Behavioral adaptations, like varying locomotion speeds, could be achieved by changes in neural parameters as well as by a mechanical coupling to the environment. To a large extent the simulated walking behavior matched biological data. For example, this was the case for body support force profiles and swing trajectories under varying ground heights. The results suggest that the single-leg controllers are suitable as modules for hexapod controllers, and they might therefore bridge morphological- and behavioral-based approaches to stick insect locomotion control.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00422-011-0422-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11633-010-0554-0,Adaptive learning with large variability of teaching signals for neural networks and its application to motion control of an industrial robot,International Journal of Automation and Computing,10.1007/s11633-010-0554-0,Springer,2011-02-01,"Recently, various control methods represented by proportional-integral-derivative (PID) control are used for robotic control. To cope with the requirements for high response and precision, advanced feedforward controllers such as gravity compensator, Coriolis/centrifugal force compensator and friction compensators have been built in the controller. Generally, it causes heavy computational load when calculating the compensating value within a short sampling period. In this paper, integrated recurrent neural networks are applied as a feedforward controller for PUMA560 manipulator. The feedforward controller works instead of gravity and Coriolis/centrifugal force compensators. In the learning process of the neural network by using back propagation algorithm, the learning coefficient and gain of sigmoid function are tuned intuitively and empirically according to teaching signals. The tuning is complicated because it is being conducted by trial and error. Especially, when the scale of teaching signal is large, the problem becomes crucial. To cope with the problem which concerns the learning performance, a simple and adaptive learning technique for large scale teaching signals is proposed. The learning techniques and control effectiveness are evaluated through simulations using the dynamic model of PUMA560 manipulator.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11633-010-0554-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-94-007-2598-0_49,Simulation-Based Evaluations of Reinforcement Learning Algorithms for Autonomous Mobile Robot Path Planning,IT Convergence and Services,10.1007/978-94-007-2598-0_49,Springer,2011-01-01,"This work aims to evaluate the efficiency of the five fundamental reinforcement learning algorithms including Q-learning, Sarsa, Watkins’s Q(λ), Sarsa(λ), and Dyna-Q, and indicate which one is the most efficient of the five algorithms for the path planning problem of autonomous mobile robots. In the sense of the reinforcement learning algorithms, the Q-learning algorithm is the most popular and seems to be the most effective model-free algorithm for a learning robot. However, our experimental results show that the Dyna-Q algorithm, a method learns from the past model-learning and direct reinforcement learning is particularly efficient for this problem in a large environment of states.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-007-2598-0_49,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12206-010-1023-y,Self-learning navigation algorithm for vision-based mobile robots using machine learning algorithms,Journal of Mechanical Science and Technology,10.1007/s12206-010-1023-y,Springer,2011-01-01,"Many mobile robot navigation methods use, among others, laser scanners, ultrasonic sensors, vision cameras for detecting obstacles and following paths. However, humans use only visual (e.g. eye) information for navigation. In this paper, we propose a mobile robot control method based on machine learning algorithms which use only camera vision. To efficiently define the state of the robot from raw images, our algorithm uses image-processing and feature selection steps to choose the feature subset for a neural network and uses the output of the neural network learned through supervised learning. The output of the neural network uses the state of a reinforcement learning algorithm to learn obstacle-avoiding and path-following strategies using camera vision image. The algorithm is verified by two experiments, which are line tracking and obstacle avoidance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12206-010-1023-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-23232-9_21,Real-World Reinforcement Learning for Autonomous Humanoid Robot Charging in a Home Environment,Towards Autonomous Robotic Systems,10.1007/978-3-642-23232-9_21,Springer,2011-01-01,"In this paper we investigate and develop a real-world reinforcement learning approach to autonomously recharge a humanoid Nao robot [1]. Using a supervised reinforcement learning approach, combined with a Gaussian distributed states activation, we are able to teach the robot to navigate towards a docking station, and thus extend the duration of autonomy of the Nao by recharging. The control concept is based on visual information provided by naomarks and six basic actions. It was developed and tested using a real Nao robot within a home environment scenario. No simulation was involved. This approach promises to be a robust way of implementing real-world reinforcement learning, has only few model assumptions and offers faster learning than conventional Q-learning or SARSA.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-23232-9_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-23232-9_15,Instance-Based Reinforcement Learning Technique with a Meta-learning Mechanism for Robust Multi-Robot Systems,Towards Autonomous Robotic Systems,10.1007/978-3-642-23232-9_15,Springer,2011-01-01,"In recent years, the subject of learning autonomous robots has been widely discussed. Reinforcement learning (RL) is a popular method in this domain. However, its performance is quite sensitive to the discretization of state and action spaces. To overcome this problem, we have developed a new technique called Bayesian-discrimination-function-based RL (BRL). BRL has proven to be more effective than other standard RL algorithms in dealing with multi-robot system (MRS) problems. However, similar to most learning systems, BRL occasionally suffers from overfitting. This paper introduces an extension of BRL for improving the robustness of MRSs. Meta-learning based on the information entropy of firing rules is adopted for adaptively modifying its learning parameters. Physical experiments are conducted to verify the effectiveness of our proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-23232-9_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-21344-1_17,Coordination of Communication in Robot Teams by Reinforcement Learning,Foundations on Natural and Artificial Computation,10.1007/978-3-642-21344-1_17,Springer,2011-01-01,"In Multi-agent systems, the study of language and communication is an active field of research. In this paper we present the application of Reinforcement Learning (RL) to the self-emergence of a common lexicon in robot teams. By modeling the vocabulary or lexicon of each agent as an association matrix or look-up table that maps the meanings (i.e. the objects encountered by the robots or the states of the environment itself) into symbols or signals we check whether it is possible for the robot team to converge in an autonomous, decentralized way to a common lexicon by means of RL, so that the communication efficiency of the entire robot team is optimal. We have conducted several experiments aimed at testing whether it is possible to converge with RL to an optimal Saussurean Communication System. We have organized our experiments alongside two main lines: first, we have investigated the effect of the team size centered on teams of moderated size in the order of 5 and 10 individuals, typical of multi-robot systems. Second, and foremost, we have also investigated the effect of the lexicon size on the convergence results. To analyze the convergence of the robot team we have defined the team’s consensus when all the robots (i.e. 100% of the population) share the same association matrix or lexicon. As a general conclusion we have shown that RL allows the convergence to lexicon consensus in a population of autonomous agents.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-21344-1_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-22577-2_52,Autonomous Robot Motion Control Using Fuzzy PID Controller,High Performance Architecture and Grid Computing,10.1007/978-3-642-22577-2_52,Springer,2011-01-01,"Autonomous robots roles are increasing in different aspects of engineering and everyday life. This paper describes an autonomous robot motion control system based on fuzzy logic Proportional Integral Derivative (PID) controller. Fuzzy rules are embedded in the controller to tune the gain parameters of PID and to make them helpful in real time applications. This paper discusses the design aspects of fuzzy PID controller for mobile robot that decrease rise time, remove steady sate error quickly and avoids overshoot. The performance of robot design has been verified with rule based evaluation using Matlab and results obtained have been found to be robust. Overall, the performances criteria in terms of its response towards rise time, steady sate error and overshoot have been found to be good.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-22577-2_52,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-94-007-2598-0_46,Q(λ) Based Vector Direction for Path Planning Problem of Autonomous Mobile Robots,IT Convergence and Services,10.1007/978-94-007-2598-0_46,Springer,2011-01-01,"This paper presents a novel algorithm to improve the efficiency of path planning for autonomous mobile robots. In an obstacle-free environment, the path planning of a robot is attained by following the vector direction from its current position to the goal position. In an obstacle environment, while following the vector direction, a robot has to avoid obstacles by rotating the moving direction. To accomplish the obstacle avoidance task for the mobile robot, the Q(λ) algorithm is employed to train the robot to learn suitable moving directions. Experimental results show that the proposed algorithm is soundness and completeness with a fast learning rate in the large environment of states and obstacles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-007-2598-0_46,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-21344-1_20,Study of a Multi-Robot Collaborative Task through Reinforcement Learning,Foundations on Natural and Artificial Computation,10.1007/978-3-642-21344-1_20,Springer,2011-01-01,"A open issue in multi-robots systems is coordinating the collaboration between several agents to obtain a common goal. The most popular solutions use complex systems, several types of sensors and complicated controls systems. This paper describes a general approach for coordinating the movement of objects by using reinforcement learning. Thus, the method proposes a framework in which two robots are able to work together in order to achieve a common goal. We use simple robots without any kind of internal sensors and they only obtain information from a central camera. The main objective of this paper is to define and to verify a method based on reinforcement learning for multi-robot systems, which learn to coordinate their actions for achieving common goal.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-21344-1_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-23232-9_46,Learning to Grasp Information with Your Own Hands,Towards Autonomous Robotic Systems,10.1007/978-3-642-23232-9_46,Springer,2011-01-01,"Autonomous robots immersed in a complex world can seldom directly access relevant parts of the environment by only using their sensors. Indeed, finding relevant information for a task can require the execution of actions that explicitly aim at unveiling previously hidden information. Informativeness of an action depends strongly on the current environment and task beyond the architecture of the agent. An autonomous adaptive agent has to learn to exploit the epistemic (e.g., information-gathering) implications of actions that are not architecturally designed to acquire information (e.g. orientation of sensors). The selection of these actions cannot be hardwired as general-purpose information-gathering actions, because differently from sensor control actions they can have effects on the environment and can affect the task execution. In robotics information-gathering actions have been used in navigation [7]; in active vision [4]; and in manipulation [3]. In all these works the informative value of each action was known and exploited at design time while the problem of actively facing un-predicted state uncertainty has not received much .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-23232-9_46,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-25085-9_65,Teaching a Robot to Perform Task through Imitation and On-line Feedback,"Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications",10.1007/978-3-642-25085-9_65,Springer,2011-01-01,"Service robots are becoming increasingly available and it is expected that they will be part of many human activities in the near future. It is desirable for these robots to adapt themselves to the user’s needs, so non-expert users will have to teach them how to perform new tasks in natural ways. In this paper a new teaching by demonstration algorithm is described. It uses a Kinect® sensor to track the movements of a user, eliminating the need of special sensors or environment conditions, it represents the tasks with a relational representation to facilitate the correspondence problem between the user and robot arm and to learn how to perform tasks in a more general description, it uses reinforcement learning to improve over the initial sequences provided by the user, and it incorporates on-line feedback from the user during the learning process creating a novel dynamic reward shaping mechanism to converge faster to an optimal policy. We demonstrate the approach by learning simple manipulation tasks of a robot arm and show its superiority over more traditional reinforcement learning algorithms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-25085-9_65,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-25324-9_38,Stochastic Learning Automata for Self-coordination in Heterogeneous Multi-Tasks Selection in Multi-Robot Systems,Advances in Artificial Intelligence,10.1007/978-3-642-25324-9_38,Springer,2011-01-01,"This paper focuses on the general problem of coordinating multiple robots. More specifically, it addresses the self-election of heterogeneous specialized tasks by autonomous robots, as opposed to the usual multi-tasks allocation problem in multi-robot systems in which an external controller distributes the existing tasks among the individual robots. In this work we are considering a specifically distributed or decentralized approach in which we are particularly interested on decentralized solution where the robots themselves autonomously and in an individual manner, are responsible of selecting a particular task so that all the existing tasks are optimally distributed and executed. In this regard, we have established an experimental scenario and we propose a solution through automata learning-based probabilistic algorithm, to solve the corresponding multi-tasks distribution problem. The paper ends with a critical discussion of experimental results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-25324-9_38,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-24769-9_27,Market-Based Dynamic Task Allocation Using Heuristically Accelerated Reinforcement Learning,Progress in Artificial Intelligence,10.1007/978-3-642-24769-9_27,Springer,2011-01-01,"This paper presents a Multi-Robot Task Allocation (MRTA) system, implemented on a RoboCup Small Size League team, where robots participate of auctions for the available roles, such as attacker or defender, and use Heuristically Accelerated Reinforcement Learning to evaluate their aptitude to perform these roles, given the situation of the team, in real-time. The performance of the task allocation mechanism is evaluated and compared in different implementation variants, and results show that the proposed MRTA system significantly increases the team performance, when compared to pre-programmed team behavior algorithms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-24769-9_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-24965-5_8,Emergence of Purposive and Grounded Communication through Reinforcement Learning,Neural Information Processing,10.1007/978-3-642-24965-5_8,Springer,2011-01-01,"Communication is not just the manipulation of words, but needs to decide what is communicated considering the surrounding situations and to understand the communicated signals considering how to reflect it on the actions. In this paper, aiming to the emergence of purposive and grounded communication, communication is seamlessly involved in the entire process consisted of one neural network, and no special learning for communication but reinforcement learning is used to train it. A real robot control task was done in which a transmitter agent generates two sounds from 1,785 camera image signals of the robot field, and a receiver agent controls the robot according to the received sounds. After learning, appropriate communication was established to lead the robot to the goal. It was found that, for the learning, the experience of controlling the robot by the transmitter is useful, and the correlation between the communication signals and robot motion is important.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-24965-5_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-24055-3_46,An AI Based Framework Proposal for Real Time Robot Design Using Framsticks,Advances in Digital Image Processing and Information Technology,10.1007/978-3-642-24055-3_46,Springer,2011-01-01,"Real time modeling of Robot is increasing day by day especially in automated industries. In this paper we propose a framework to design real time robots for industries using AI techniques like Co-Evolution, Virtual Ecology, Life time learning. Beyond that monitoring complex and non complex behaviors in different environments and obtaining the parameters that influence hardware design. Here we have created a virtual khepera robot and simulated in Framsticks and designed hardware components based on the outcome of simulation parameters. Even control programs were also generated using the same data.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-24055-3_46,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-25489-5_58,Surface Defects Classification Using Artificial Neural Networks in Vision Based Polishing Robot,Intelligent Robotics and Applications,10.1007/978-3-642-25489-5_58,Springer,2011-01-01,"One of the highly skilled tasks in manufacturing is the polishing process. The purpose of polishing is to get uniform surface roughness. In order to reduce the polishing time and to cope with the shortage of skilled workers, robotic polishing technology has been investigated. This paper proposes a vision system to measure surface defects that have been classified to some level of surface roughness. Artificial neural networks are used to classify surface defects and to give a decision in order to drive the actuator of the arm robot. Force and rotation time have been chosen as output parameters of artificial neural networks. The results show that although there is a considerable change in both parameter values acquired from vision data compared to real data, it is still possible to obtain surface defects classification using a vision sensor to a certain limit of accuracy. The overall results of this research would encourage further developments in this area to achieve robust computer vision based surface measurement systems for industrial robotics, especially in the polishing process.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-25489-5_58,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-21222-2_55,Empirical Study of Q-Learning Based Elemental Hose Transport Control,Hybrid Artificial Intelligent Systems,10.1007/978-3-642-21222-2_55,Springer,2011-01-01,"Non-rigid physical elements attached to robotic systems introduce non-linear dynamics that requires innovative control approaches. This paper describes some of our results applying Q-Learning to learn the control commands to solve a hose transportation problem. The learning process is developed in a simulated environment. Computationally expensive but dynamically accurate Geometrically Exact Dynamic Splines (GEDS) have been used to model the hose to be transported by a single robot, showing the difficulties of controlling flexible elastic passive linking elements.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-21222-2_55,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-21501-8_11,A Cognitive Approach for Robots’ Vision Using Unsupervised Learning and Visual Saliency,Advances in Computational Intelligence,10.1007/978-3-642-21501-8_11,Springer,2011-01-01,"In this work we contribute to development of an online unsupervised technique allowing learning of objects from unlabeled images and their detection when seen again. We were inspired by early processing stages of human visual system and by existing work on human infants learning. We suggest a novel fast algorithm for detection of visually salient objects, which is employed to extract objects of interest from images for learning. We demonstrate how this can be used in along with state-of-the-art object recognition algorithms such as SURF and Viola-Jones framework to enable a machine to learn to re-detect previously seen objects in new conditions. We provide results of experiments done on a mobile robot in common office environment with multiple every-day objects.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-21501-8_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-19959-2_4,Error Compensation and Calibration of Inter-section Line Welding Robot Based on a Wavelet Neural Network,"Robotic Welding, Intelligence and Automation",10.1007/978-3-642-19959-2_4,Springer,2011-01-01,"The main source of error of saddle-back coping welding robots is discussed in this paper. In view of the error source, a three-layered wavelet neural network compensation model is designed. Two steps are involved in using this model: the first step is to compensate the position error of torch point caused by axes 4 and 5 of a robot, the second step is to compensate all the five axes movement error respectively. The corresponding simulation and experimentation are conducted based on the compensation algorithm. Results show that this compensation model can greatly improve the movement precision of the robot. The average position error of torch point is reduced by 80%, and the average movement error of each axis is reduced by 60%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-19959-2_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-21222-2_58,"
              Topos 2: Spiking Neural Networks for Bipedal Walking in Humanoid Robots",Hybrid Artificial Intelligent Systems,10.1007/978-3-642-21222-2_58,Springer,2011-01-01,"This work analyses the state of the art in the field of Evolutionary Robotics and marks the path we select in the design of evolutionary strategies. The aim of this text is to describe the lines that we are going to follow in the foreseeable future. Our goal is to create through evolution the neural network that couples with a complex humanoid robot body. For us the problems of a non-structured environment and of Evolutionary Robotics need a sub-symbolic conexionist approach based in Nouvelle AI that can cope with the coupling among sensorimotor, neural and environment parts. We also describe the tools we choose to accomplish this task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-21222-2_58,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-21402-8_55,Research on Neural Network Controller for the System of Online Synchro Record and Simulation of Motion,Advanced Research on Computer Science and Information Engineering,10.1007/978-3-642-21402-8_55,Springer,2011-01-01,"Technology of online synch record and simulation of motion is a spiry integral technology of mechanics, electrics and hydraulics. Systematical study of it is carried out using a 6-DOF(Degree Of Freedom) synchronous on-line recorder and simulator. The algorithm of the 6-DOF synchronous on-line recorder and simulator is deduced. the adaptive neural network controller is designed accordingly. with the existing hydraulic servo driven 6-DOF simulator, a synchronous on-line recorder and simulator control system is set up, and the experiment proves the algorithm is correct and the controller’s design is fully a success.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-21402-8_55,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1057/9780230304949_10,Artificial Intelligence,The Politics of Emerging Strategic Technologies,10.1057/9780230304949_10,Springer,2011-01-01,"Cognitive science is an interdisciplinary field that broadly encompasses the study of the mind and intelligence. Some of the sciences and specialties included under the umbrella of cognitive science are: artificial intelligence (AI), linguistics, anthropology, psychology, neuroscience, philosophy and education. From a strategic technology perspective, and especially when looking at strategic technologies in the context of their influence on human nature and geopolitics, the sciences of AI and neuroscience are especially relevant and significant. This chapter looks more closely at the AI dimension of cognitive science. The neuroscience component is evaluated in Part II of this book.",http://link.springer.com/openurl/fulltext?id=doi:10.1057/9780230304949_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-0348-0130-0_19,Increasing Learning Speed by Imitation in Multi-robot Societies,Organic Computing — A Paradigm Shift for Complex Systems,10.1007/978-3-0348-0130-0_19,Springer,2011-01-01,"The paradigm of imitation provides a powerful means for increasing the overall learning speed in a group of robots. While separately exploring the environment in order to learn how to behave with respect to a pre-defined goal, a robot gathers experience based on its own actions and interactions with the surroundings, respectively. By accumulating additional experience via observing the behaviour of other robots, the learning process can be significantly improved in terms of speed and quality. Within this article we present an approach, that enables robots in a multi-robot society to imitate any other available robot without imposing unnecessary restrictions regarding the robots’ design. Therefore, it benefits not only from its own actions, but also from actions that an observed robot performs. In order to realise the imitation paradigm, we solve three main challenges, namely enabling a robot to decide whom and when to imitate, to interpret and thereby understand the behaviour of an observed robot, and to integrate the experience gathered by observation into its individual learning process.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-0348-0130-0_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-22288-7_14,A Reinforcement Learning Approach with Spline-Fit Object Tracking for AIBO Robot’s High Level Decision Making,"Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing 2011",10.1007/978-3-642-22288-7_14,Springer,2011-01-01,"Robocup is a popular test bed for AI programs around the world. Robosoccer is one of the two major parts of Robocup, in which AIBO entertainment robots take part in the middle sized soccer event. The three key challenges that robots need to face in this event are manoeuvrability, image recognition and decision making skills. This paper focuses on the decision making problem in Robosoccer- The goal keeper problem. We investigate whether reinforcement learning (RL) as a form of semi-supervised learning can effectively contribute to the goal keeper’s decision making process when penalty shot and two attacker problem are considered. Currently, the decision making process in Robosoccer is carried out using rule-base system. RL also is used for quadruped locomotion and navigation purpose in Robosoccer using AIBO. Moreover the ball distance is being calculated using IR sensors available at the nose of the robot. In this paper, we propose a reinforcement learning based approach that uses a dynamic state-action mapping using back propagation of reward and Q-learning along with spline fit (QLSF) for the final choice of high level functions in order to save the goal. The novelty of our approach is that the agent learns while playing and can take independent decision which overcomes the limitations of rule-base system due to fixed and limited predefined decision rules. The spline fit method used with the nose camera was also able to find out the location and the ball distance more accurately compare to the IR sensors. The noise source and near and far sensor dilemma problem with IR sensor was neutralized using the proposed spline fit method. Performance of the proposed method has been verified against the bench mark data set made with Upenn’03 code logic and a base line experiment with IR sensors. It was found that the efficiency of our QLSF approach in goalkeeping was better than the rule based approach in conjunction with the IR sensors. The QLSF develops a semi-supervised learning process over the rule-base system’s input-output mapping process, given in the Upenn’03 code.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-22288-7_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-23808-6_1,Sparse Kernel-SARSA(λ) with an Eligibility Trace,Machine Learning and Knowledge Discovery in Databases,10.1007/978-3-642-23808-6_1,Springer,2011-01-01,We introduce the first online kernelized version of SARSA( λ ) to permit sparsification for arbitrary λ for 0 ≤  λ  ≤ 1; this is possible via a novel kernelization of the eligibility trace that is maintained separately from the kernelized value function. This separation is crucial for preserving the functional structure of the eligibility trace when using sparse kernel projection techniques that are essential for memory efficiency and capacity control. The result is a simple and practical Kernel-SARSA( λ ) algorithm for general 0 ≤  λ  ≤ 1 that is memory-efficient in comparison to standard SARSA( λ ) (using various basis functions) on a range of domains including a real robotics task running on a Willow Garage PR2 robot.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-23808-6_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-19457-3_28,Towards Motor Skill Learning for Robotics,Robotics Research,10.1007/978-3-642-19457-3_28,Springer,2011-01-01,"Learning robots that can acquire new motor skills and refine existing one has been a long standing vision of robotics, artificial intelligence, and the cognitive sciences. Early steps towards this goal in the 1980s made clear that reasoning and human insights will not suffice. Instead, new hope has been offered by the rise of modern machine learning approaches. However, to date, it becomes increasingly clear that off-the-shelf machine learning approaches will not suffice for motor skill learning as these methods often do not scale into the high-dimensional domains of manipulator and humanoid robotics nor do they fulfill the real-time requirement of our domain. As an alternative, we propose to break the generic skill learning problem into parts that we can understand well from a robotics point of view. After designing appropriate learning approaches for these basic components, these will serve as the ingredients of a general approach to motor skill learning. In this paper, we discuss our recent and current progress in this direction. For doing so, we present our work on learning to control, on learning elementary movements as well as our steps towards learning of complex tasks. We show several evaluations both using real robots as well as physically realistic simulations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-19457-3_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-19539-6_10,Adhering to Terrain Characteristics for Position Estimation of Mobile Robots,"Informatics in Control, Automation and Robotics",10.1007/978-3-642-19539-6_10,Springer,2011-01-01,"Outdoor environments bear the problem of different terrains along with changing driving properties. Therefore, compared to indoor environments, the kinematics of mobile robots is much more complex. In this paper we present a comprehensive approach to learn the function of outdoor kinematics for mobile robots. Future robot positions are estimated by employing Gaussian process regression (GPR) in combination with an Unscented Kalman filter (UKF). Our approach uses optimized terrain models according to the classification of the current terrain – accomplished through Gaussian process classification (GPC) and a second order Bayesian filter (BF). Experiments showed our approach to provide more accurate estimates compared to single terrain model methods, as well as to be competitive to other dynamic approaches.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-19539-6_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-0348-0130-0_36,A Fast Hierarchical Learning Approach for Autonomous Robots,Organic Computing — A Paradigm Shift for Complex Systems,10.1007/978-3-0348-0130-0_36,Springer,2011-01-01,"In this article we present an approach that enables robots to learn how to act and react robustly in continuous and noisy environments while not loosing track of the overall feasibility, i.e. minimising the execution time in order to keep up continuous learning. We do so by combining reinforcement learning mechanisms with techniques belonging to the field of multivariate statistics on three different levels of abstraction: the motivation layer and the two simultaneously learning strategy and skill layers. The motivation layer allows for modelling occasionally contradicting goals in terms of drives in a very intuitive fashion. A drive represents one single goal, that a robot wants to be satisfied, like charging its battery, when it is nearly exhausted, or transporting an object to a target position. The strategy layer encapsulates the main reinforcement learning algorithm based on an abstracted and dynamically adjusted Markovian state space. By means of state abstraction, we minimise the overall state space size in order to ensure feasibility of the learning process in a dynamically changing environment. The skill layer finally realises a generalised learning method for learning reactive low-level behaviours, that enable a robot to interact with the environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-0348-0130-0_36,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-23232-9_26,Supervised Traversability Learning for Robot Navigation,Towards Autonomous Robotic Systems,10.1007/978-3-642-23232-9_26,Springer,2011-01-01,"This work presents a machine learning method for terrain’s traversability classification. Stereo vision is used to provide the depth map of the scene. Then, a v-disparity image calculation and processing step extracts suitable features about the scene’s characteristics. The resulting data are used as input for the training of a support vector machine (SVM). The evaluation of the traversability classification is performed with a leave-one-out cross validation procedure applied on a test image data set. This data set includes manually labeled traversable and non-traversable scenes. The proposed method is able to classify the scene of further stereo image pairs as traversable or non-traversable, which is often the first step towards more advanced autonomous robot navigation behaviours.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-23232-9_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-27272-1_3,Elements of Hybrid Control in Autonomous Systems and Cognitics,Research and Education in Robotics - EUROBOT 2010,10.1007/978-3-642-27272-1_3,Springer,2011-01-01,"Intelligent systems and robots have made significant progress in recent years, in artificial intelligence (AI), situated automata, reactive systems, classical control, computer infrastructure and networks. The paper shows that hybrid approaches (i.e. a mix of these mentioned techniques), and in general cognitics (i.e. automated cognition), offer multiple benefits: assessing various cognitive elements, predicting phenomena, compensating for disturbances, embedding programmed systems in reality, estimating entities in virtually all regions of high dimensional spaces, learning and being expert, and running on digital processors with the best software methods. Additionally, some concepts are newly discussed, in order to facilitate a coherent global view: deliberation, top-down approaches, creativity and ingenuity are also important items in the general picture. The paper finally also addresses learning; it appears that only chance has the cognitive power to yield truly novel models, while expert resources remain necessary to collect, optimize, and make use of them effectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-27272-1_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-21283-3_20,Towards Self-reflecting Machines: Two-Minds in One Robot,Advances in Artificial Life. Darwin Meets von Neumann,10.1007/978-3-642-21283-3_20,Springer,2011-01-01,"We introduce a technique that allows a robot to increase its resiliency and learning skills by exploiting a process akin to self-reflection. A robot contains two controllers: A pure reactive innate controller, and a reflective controller that can observe, model and control the innate controller. The reflective controller adapts the innate controller without access to the innate controller’s internal state or architecture; Instead, it models it and then synthesizes filters that exploit its existing capabilities for new situations. In this paper we explore a number of scenarios where the innate controller is a recurrent neural network. We demonstrate significant adaptation ability with relatively few physical trials.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-21283-3_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-27272-1_5,Flexible Robot Strategy Design Using Belief-Desire-Intention Model,Research and Education in Robotics - EUROBOT 2010,10.1007/978-3-642-27272-1_5,Springer,2011-01-01,"This paper describes PROFETA, a Python framework developed by the authors to write robot strategies by means of the Belief- Desire-Intention (BDI) programming paradigm. This paradigm has been proposed in the field of autonomous agents programming and can be successfully applied also to autonomous robots thanks to their behavioural similarity with software agents. The paper describes the BDI model and AgentSpeak, a formal declarative language suitably designed for BDI agents. Then it introduces PROFETA, which takes inspiration from AgentSpeak and is designed with the objective of adding declarative constructs (needed by a BDI model) to an object-oriented and imperative language like Python. The result is a flexible environment that combines the power of both the classical object-oriented paradigm—useful for algorithm and control loop programming—and declarative approach—useful for AI and strategy programming. A case-study, based on Eurobot 2010 competition, shows such abilities, highlighting the main characteristics and advantages of PROFETA in strategy design.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-27272-1_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-25504-5_12,Homewrecker 2.0: An Exploration of Liability for Heart Balm Torts Involving AI Humanoid Consorts,Social Robotics,10.1007/978-3-642-25504-5_12,Springer,2011-01-01,"With the development of artificially intelligent humanoid consorts, robotics is venturing into a realm of legal liability that has traditionally governed social interactions between humans and other humans, rather than interactions between humans and machines. How can and should legal systems deal with the problems that arise in regulated human interpersonal and sexual relationships when there is an AI sex doll in the mix? Heart balm torts, traditionally used to hold a third party paramour civilly liable for the dissolution of a protected relationship, provide a potential answer. Finding an appropriate entity to be liable will be problematic, though robot producers and the AI entity itself could both be potential defendants in a heart balm case. Producers may be able to limit liability if they can incorporate the experience of heartbreak and compassion into their creations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-25504-5_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-21738-8_43,Robot Trajectory Prediction and Recognition Based on a Computational Mirror Neurons Model,Artificial Neural Networks and Machine Learning – ICANN 2011,10.1007/978-3-642-21738-8_43,Springer,2011-01-01,"Mirror neurons are premotor neurons that are considered to play a role in goal-directed actions, action understanding and even social cognition. As one of the promising research areas in psychology, cognitive neuroscience and cognitive physiology, understanding mirror neurons in a social cognition context, whether with neural or computational models, is still an open issue [5]. In this paper, we mainly focus on the action understanding aspect of mirror neurons, which can be regarded as a fundamental function of social cooperation and social cognition. Our proposed initial architecture is to learn a simulation of the walking pattern of a humanoid robot and to predict where the robot is heading on the basis of its previous walking trajectory.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-21738-8_43,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-21283-3_23,Acquisition of Adaptive Behavior for Virtual Modular Robot Using Evolutionary Computation,Advances in Artificial Life. Darwin Meets von Neumann,10.1007/978-3-642-21283-3_23,Springer,2011-01-01,"In areas such as evolutionary robotics and artificial life, simulating artificial robots and organisms are significant challenges to acquire their proper behaviors that achieve given tasks. This study proposes Animated Robot (”Anibot”), which can behave by obeying physical laws in a virtual 3D environment. Especially, we aim to obtain a control system in evolution which makes it possible to behave ”Anibot” autonomously. This paper focuses on a virtual modular robot with a flexible structure and simulating it for learning and controlling. The experimental results show that the modular robot can move toward a light source as its goal in different circumstances. In addition, we discuss an adaptive ability in the different circumstances and a motion mechanism of an obtained behavior.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-21283-3_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-21501-8_67,Context Separability Mediated by the Granular Layer in a Spiking Cerebellum Model for Robot Control,Advances in Computational Intelligence,10.1007/978-3-642-21501-8_67,Springer,2011-01-01,"In this paper, we study how a biologically-plausible cerebellum architecture can store and retrieve different robotic-arm internal models (in synaptic connections between granular layer and Purkinje cells) at the granule layer (dynamic modifications of a base robot-arm-plant model), and how the model microstructure and input signal representations can efficiently infer models in a robot control scenario during object manipulation. More specifically, we have evaluated the contribution of the granular layer to the ability of the cerebellum to generate corrective actions. To achieve this we have embedded a spiking cerebellar model into an analog control loop whose output commands a simulated robot arm. The performance results obtained by using a cerebellum which includes granular layer are compared to those using a cerebellum without this layer. The results show that this layer effectively contributes to the generation of accurate cerebellar corrections. This work represents a well defined case of study in the field of neurobotics, in which biologically plausible neural systems and robots are used to study the functionality of biological systems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-21501-8_67,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-17875-7_1,Industrial Robots in Contact-Free Operation,Modelling and Control for Intelligent Industrial Systems,10.1007/978-3-642-17875-7_1,Springer,2011-01-01,"A study of industrial robotic systems is provided, for the case of contact-free operation. This part of the book includes the dynamic and kinematic analysis of rigid-link robotic manipulators, and expands towards more specialized topics, such as dynamic and kinematic analysis of flexible-link robots, and control of rigid-link and flexible-link robots in contact-free operation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-17875-7_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-20217-9_21,Human vs. Robotic Soccer: How Far Are They? A Statistical Comparison,RoboCup 2010: Robot Soccer World Cup XIV,10.1007/978-3-642-20217-9_21,Springer,2011-01-01,"In soccer games, a performance indicator is defined as a selection of action variables that aims to define all aspects of accomplishment of the game goals. However their perception during the match is extremely difficult. Over the years, soccer has been used in many research areas including the robotic international soccer competition, RoboCup. The aim of this research project is to present a comparison study, performed to detect similarities between these two games (Human versus Robotic Simulation 2D soccer). Having an off-line automatic event detection tool as a base, a collection of final game statistics was done and the Mann-Whitney test was used to verify their statistical significance. The results show that the most frequent events occurred in both types of game are successful passes. In what concerns stopped game situation types, in both types of games, the most frequent one is the Throw in situation (Human-59,8%, versus Robotic-74,1%) and the less frequent is the Corner situation (Human-13,7%, versus Robotic-10,3%). Some differences still reside, especially in the frequency of set pieces and the action prior the goal.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-20217-9_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-23169-8_2,The Future of Human-Machine Interaction: Implant Technology,Man-Machine Interactions 2,10.1007/978-3-642-23169-8_2,Springer,2011-01-01,"In this paper a look is taken at how the use of implant and electrode technology can be employed to create biological brains for robots, to enable human enhancement and to diminish the effects of certain neural illnesses. In all cases the end result is to increase the range of abilities of the recipients. An indication is given of a number of areas in which such technology has already had a profound effect, a key element being the need for a clear interface linking a biological brain directly with computer technology. The emphasis is placed on practical scientific studies that have been and are being undertaken and reported on. The area of focus is the use of electrode technology, where either a connection is made directly with the cerebral cortex and/or nervous system or where implants into the human body are involved. The paper also considers robots that have biological brains in which human neurons can be employed as the sole thinking machine for a real world robot body.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-23169-8_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-20206-3_16,Dual Adaptive Neurocontrol of Mobile Robots Using the Unscented Transform: Monte Carlo and Experimental Validation,Computational Intelligence,10.1007/978-3-642-20206-3_16,Springer,2011-01-01,"In contrast to most adaptive schemes, dual adaptive controllers do not rely on the heuristic certainty equivalence assumption, but aim to strike a balance between estimation and control at all times. Yet, few such controllers have ever been implemented and tested in practice, especially within the context of intelligent control, and to the best of our knowledge none on mobile robots. With the help of Mont Carlo simulation and real-life experiments, this article presents and validates a novel dual adaptive neurocontroller based on the unscented transform, for the dynamic control of nonholonomic wheeled mobile robots. The robot nonlinear dynamic functions are unknown to the controller and a multilayer perceptron neural network, trained via an unscented Kalman predictor, is used for their approximation in real-time. Moreover, the proposed novel dual adaptive control law employs the unscented transform to improve further the system’s performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-20206-3_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-25330-0_37,Control of a Service Robot Using the Mexican Sign Language,Advances in Soft Computing,10.1007/978-3-642-25330-0_37,Springer,2011-01-01,"This paper presents the results of our research in automatic recognition of the Mexican Sign Language (MSL) alphabet as control element for a service robot. The technique of active contours was used for image segmentation in order to recognize de signs. Once segmented, we proceeded to obtain the signature of the corresponding sign and trained a neural network for its recognition. Every symbol of the MSL was assigned to a task that the robotic system had to perform; we defined eight different tasks. The system was validated using a simulation environment and a real system. For the real case, we used a mobile platform (Powerbot) equipped with a manipulator with 6 degrees of freedom (PowerCube). For simulation of the mobile platforms, RoboWorks was used as the simulation environment. In both, simulated and real platforms, tests were performed with different images to those learned by the system, obtaining in both cases a recognition rate of 95.8%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-25330-0_37,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-23768-3_16,An Exploration of the Utilization of Electroencephalography and Neural Nets to Control Robots,Human-Computer Interaction – INTERACT 2011,10.1007/978-3-642-23768-3_16,Springer,2011-01-01,"It has long been known that as neurons fire within the brain they produce measurable electrical activity. Electroencephalography (EEG) is the measurement and recording of these electrical signals using sensors arrayed across the scalp. The idea of Brain-Computer interfaces (BCIs), which allow the control of devices using brain signals, naturally present themselves to many extremely useful applications including prosthetic devices, restoring or aiding in communication and hearing, military applications, video gaming and virtual reality, and robotic control, and have the possibility of significantly improving the quality of life of many disabled individuals. The purpose of this research is to examine an off the shelf EEG system, the Emotiv EPOC© System, as a cost-effective gateway to non-invasive portable EEG measurements and to build a BCI to control a robot, the Parallax Scribbler®. We built middleware to interpret the outputs from the Emotiv and map them into commands for the Scribbler robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-23768-3_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-23857-4_21,A Trajectory Tracking Application of Redundant Planar Robot Arm via Support Vector Machines,Adaptive and Intelligent Systems,10.1007/978-3-642-23857-4_21,Springer,2011-01-01,"In this paper we present a kinematic based trajectory tracking application of redundant planar robot arm by using support vector machine method (SVM). The main advantages of using the proposed method are that, it does not suffer from singularity that is the main problem of redundancy in robot kinematics and better results for the kinematic model of redundant robot arm can be obtained by using less training data. Training data are obtained by using the forward differential kinematic model of the robot arm. We also implement the trajectory tracking application by using Artificial Neural Networks (ANN). Two methods are compared with respect to their generalization performances, and training performance. Simulation results are given.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-23857-4_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-22194-1_29,Robotics Application within Bioengineering: Neuroprosthesis Test Bench and Model Based Neural Control for a Robotic Leg,Intelligent Decision Technologies,10.1007/978-3-642-22194-1_29,Springer,2011-01-01,"This work deals with motion analysis of the human body, with robotic leg control and then with neuroprosthesis test bench. The issues raised in motion analysis are of interest for controlling motion-specific parameters for movement of the robotic leg. The resulting data are used for further processing in humanoid robotics and assistive and recuperative technologies for people with disabilities. The results are implemented on a robotic leg, which has been developed in our laboratories. It has been used to build a neuroprosthesis control test bench. A model based neural control strategy is implemented, too. The performances of the implemented control strategies for trajectory tracking are analysed by computer simulation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-22194-1_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-010-9429-4,Distributed Reinforcement Learning for Coordinate Multi-Robot Foraging,Journal of Intelligent & Robotic Systems,10.1007/s10846-010-9429-4,Springer,2010-12-01,"In this paper, we propose a distributed dynamic correlation matrix based multi-Q (D-DCM-Multi-Q) learning method for multi-robot systems. First, a dynamic correlation matrix is proposed for multi-agent reinforcement learning, which not only considers each individual robot’s Q-value, but also the correlated Q-values of neighboring robots. Then, the theoretical analysis of the system convergence for this D-DCM-Multi-Q method is provided. Various simulations for multi-robot foraging as well as a proof-of-concept experiment with a physical multi-robot system have been conducted to evaluate the proposed D-DCM-Multi-Q method. The extensive simulation/experimental results show the effectiveness, robustness, and stability of the proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-010-9429-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1016/S1672-6529(09)60233-X,Supervised Neural Q_learning based Motion Control for Bionic Underwater Robots,Journal of Bionic Engineering,10.1016/S1672-6529(09)60233-X,Springer,2010-12-01,"Bionic underwater robots have been a hot research area in recent years. The motion control methods for a kind of bionic underwater robot with two undulating fins are discussed in this paper. The equations of motion for the bionic underwater robot are described. To apply the reinforcement learning to the actual robot control, a Supervised Neural Q_learning (SNQL) algorithm is put forward. This algorithm is based on conventional Q_learning algorithm, but has three remarkable distinctions: (1) using a feedforward neural network to approximate the Q_function table; (2) adopting a learning sample database to speed up learning and improve the stability of learning system; (3) introducing a supervised control in the earlier stage of learning for safety and to speed up learning again. Experiments of swimming straightforward are carried out with SNQL algorithm. Results indicate that the SNQL algorithm is more effective than pure neural Q_learning or supervised control. It is a feasible approach to figure out the motion control for bionic underwater robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1016/S1672-6529(09)60233-X,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12130-010-9120-x,Robotrust and Legal Responsibility,"Knowledge, Technology & Policy",10.1007/s12130-010-9120-x,Springer,2010-12-01,"The paper examines some aspects of today’s debate on trust and e-trust and, more specifically, issues of legal responsibility for the production and use of robots. Their impact on human-to-human interaction has produced new problems both in the fields of contractual and extra-contractual liability in that robots negotiate, enter into contracts, establish rights and obligations between humans, while reshaping matters of responsibility and risk in trust relations. Whether or not robotrust concerns human-to-robot or even robot-to-robot relations, there is a new generation of cases involving human-to-human contractual and extra-contractual liability for robots’ behaviour because, for the first time, legal systems hold you responsible for what an artificial system autonomously decides to do.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12130-010-9120-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11771-010-0637-7,Seam tracking control for mobile welding robot based on vision sensor,Journal of Central South University of Technology,10.1007/s11771-010-0637-7,Springer,2010-12-01,"To solve the seam tracking problem of mobile welding robot, a new controller based on the dynamics of mobile welding robot was designed using the method of backstepping kinematics into dynamics. A self-turning fuzzy controller and a fuzzy-Gaussian neural network (FGNN) controller were designed to complete coordinately controlling of cross-slider and wheels. The fuzzy-neural control algorithm was described by applying the Gaussian function and back propagation (BP) learning rule was used to tune the membership function in real time by applying the FGNN controller. To make the tracking more quickly and smoothly, the neural network controller based on dynamic model was designed, which utilized self-learning and self-adaptive ability of the neural network to deal with the partial uncertainty and the disturbances of the parameters of the robot dynamic model and real-time compensate the dynamics coupling. The results show that the selected control input torques make the system globally and asymptotically stable based on the Lyapunov function selected out; the accuracy of the proposed controller tracing is within ±0.4 mm and can satisfy the requirements of practical welding project.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11771-010-0637-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-010-0831-6,Artificial neural network dexterous robotics hand optimal control methodology: grasping and manipulation forces optimization,Artificial Life and Robotics,10.1007/s10015-010-0831-6,Springer,2010-12-01,"Optimal fingertip forces can always be computed through the well-known optimization algorithms. However, computation time has always remained a real-time constraint. This article presents an efficient scheme to compute optimal grasping and manipulation forces for dexterous robotics hands. This is expressed as a quadratic optimization problem, and an artificial neural network (ANN) is used to learn such quadratic optimization formulations. Computation has been based on a nonlinear model of fingertip contacts and slips. In achieving object grasping while in motion, the hand Jacobian is considered an important matrix to be computed, but it is also highly intensive for real-time computed applications. Consequently, we investigated an efficient approach using artificial neural networks to learn optimal grasping forces. An ANN is used here to learn the optimal contact forces relating hand joint-space torques to the resulting object force. The results have indicated that the ANN has reduced computation times to reasonable values owing to its ability to map nonlinear force relations. Furthermore, the results have revealed that ANNs are capable of learning highly nonlinear relations relating to distributed fingertip forces and joint torques. The technique developed has also proved to be suitable for off-line learning of computed fingertip forces, even with large training samples.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-010-0831-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12065-010-0039-7,Real-world transfer of evolved artificial immune system behaviours between small and large scale robotic platforms,Evolutionary Intelligence,10.1007/s12065-010-0039-7,Springer,2010-12-01,"In mobile robotics, a solid test for adaptation is the ability of a control system to function not only in a diverse number of physical environments, but also on a number of different robotic platforms. This paper demonstrates that a set of behaviours evolved in simulation on a miniature robot (epuck) can be transferred to a much larger-scale platform (Pioneer), both in simulation and in the real world. The chosen architecture uses artificial evolution of epuck behaviours to obtain a genetic sequence, which is then employed to seed an idiotypic, artificial immune system (AIS) on the Pioneers. Despite numerous hardware and software differences between the platforms, navigation and target-finding experiments show that the evolved behaviours transfer very well to the larger robot when the idiotypic AIS technique is used. In contrast, transferability is poor when reinforcement learning alone is used, which validates the adaptability of the chosen architecture.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12065-010-0039-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-010-9422-y,A Human-Robot Collaborative Reinforcement Learning Algorithm,Journal of Intelligent & Robotic Systems,10.1007/s10846-010-9422-y,Springer,2010-11-01,"This paper presents a new reinforcement learning algorithm that enables collaborative learning between a robot and a human. The algorithm which is based on the Q ( λ ) approach expedites the learning process by taking advantage of human intelligence and expertise. The algorithm denoted as CQ ( λ ) provides the robot with self awareness to adaptively switch its collaboration level from autonomous (self performing, the robot decides which actions to take, according to its learning function) to semi-autonomous (a human advisor guides the robot and the robot combines this knowledge into its learning function). This awareness is represented by a self test of its learning performance. The approach of variable autonomy is demonstrated and evaluated using a fixed-arm robot for finding the optimal shaking policy to empty the contents of a plastic bag. A comparison between the CQ ( λ ) and the traditional Q ( λ )-reinforcement learning algorithm, resulted in faster convergence for the CQ ( λ ) collaborative reinforcement learning algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-010-9422-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-010-0059-6,Semantic 3D Object Maps for Everyday Manipulation in Human Living Environments,KI - Künstliche Intelligenz,10.1007/s13218-010-0059-6,Springer,2010-11-01,"Environment models serve as important resources for an autonomous robot by providing it with the necessary task-relevant information about its habitat. Their use enables robots to perform their tasks more reliably, flexibly, and efficiently. As autonomous robotic platforms get more sophisticated manipulation capabilities, they also need more expressive and comprehensive environment models: for manipulation purposes their models have to include the objects present in the world, together with their position, form, and other aspects, as well as an interpretation of these objects with respect to the robot tasks. The dissertation presented in this article (Rusu, PhD thesis, 2009 ) proposes Semantic 3D Object Models as a novel representation of the robot’s operating environment that satisfies these requirements and shows how these models can be automatically acquired from dense 3D range data.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-010-0059-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-010-9421-z,Neural Network Solution for Forward Kinematics Problem of Cable Robots,Journal of Intelligent & Robotic Systems,10.1007/s10846-010-9421-z,Springer,2010-11-01,"Forward kinematics problem of cable robots is very difficult to solve the same as that of parallel robots and in the contrary to the serial manipulators’. This problem is almost impossible to solve analytically because of the nonlinearity and complexity of the robot’s kinematic equations. Numerical methods are the most common solutions for this problem of the parallel and cable robots. But, convergency of these methods is the drawback of using them. In this paper, neural network approach is used to solve the forward kinematics problem of an exemplary 3D cable robot. This problem is solved in the typical workspace of the robot. The neural network used in this paper is of the MLP type and a back propagation procedure is utilized to train the network. A simulation study is performed and the results show the advantages of this method in enhancement of convergency together with very small modeling errors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-010-9421-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-010-0049-8,Constraint Based World Modeling for Multi Agent Systems in Dynamic Environments,KI - Künstliche Intelligenz,10.1007/s13218-010-0049-8,Springer,2010-11-01,"Mobile autonomous robotics is a young and complex field of research. Since the world is uncertain and since robots can only gain partial information about it, probabilistic navigation algorithms became popular whenever a robot has to localize itself or surrounding objects. Furthermore, cooperative exploration and localization approaches have become very relevant lately, as robots begin to act not just alone but in groups. Within my thesis I analyze, how information can be exchanged between robots in order to improve their world model. Therefore I examine how communication of spatial percept-relations can help to improve the accuracy of the world model, in particular when the robots are poorly self-localized. First, percept-relations are being used to increase the modeling accuracy in static situations, later the approach is extended to moving objects. After focussing on suitable sensory data for communication, in the second part I present a Bayesian modeling approach, using constraint satisfaction techniques for complex belief functions. Constraint based localization methods will be analyzed in order to have a group of robots efficiently localized and to model their environment. The presented algorithms were implemented and tested within the RoboCup Standard Platform League (SPL).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13218-010-0049-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-010-9199-7,Using efference copy and a forward internal model for adaptive biped walking,Autonomous Robots,10.1007/s10514-010-9199-7,Springer,2010-11-01,"To behave properly in an unknown environment, animals or robots must distinguish external from self-generated stimuli on their sensors. The biologically inspired concepts of efference copy and internal model have been successfully applied to a number of robot control problems. Here we present an application of this for our dynamic walking robot RunBot. We use efference copies of the motor commands with a simple forward internal model to predict the expected self-generated acceleration during walking. The difference to the actually measured acceleration is then used to stabilize the walking on terrains with changing slopes through its upper body component controller. As a consequence, the controller drives the upper body component (UBC) to lean forwards/backwards as soon as an error occurs resulting in dynamical stable walking. We have evaluated the performance of the system on four different track configurations. Furthermore we believe that the experimental studies pursued here will sharpen our understanding of how the efference copies influence dynamic locomotion control to the benefit of modern neural control strategies in robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-010-9199-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-010-9433-8,From the Editor-in-Chief,Journal of Intelligent & Robotic Systems,10.1007/s10846-010-9433-8,Springer,2010-10-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-010-9433-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11063-010-9154-9,Improved Output Tracking of a Flexible-Joint Arm using Neural Networks,Neural Processing Letters,10.1007/s11063-010-9154-9,Springer,2010-10-01,"This works presents a neural-adaptive control strategy for trajectory tracking for a two-link flexible joint robot, with experimental results. The method of backstepping with tuning functions (using analytic differentiation) guides the design, rather than using neural approximation of derivatives. Traditional tuning function design results in a weight update dominated by the last error in the backstepping design, not the output error. The novel method in this paper weights the errors in the tuning function so that the output error becomes significant in training. An additional modification ensures robustness to approximation errors. Experimental results show the improved performance compared to both derivative-estimation and normal tuning function methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-010-9154-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-010-0413-3,Recognition and path planning strategy for autonomous navigation in the elevator environment,"International Journal of Control, Automation and Systems",10.1007/s12555-010-0413-3,Springer,2010-08-01,"This paper presents a robust and reliable method for a mobile robot to get on/off an elevator in a multistory building. Getting on/off the elevator requires the robot to perform two different tasks: a recognition task and a navigation task. First, we propose a recognition algorithm for the elevator buttons and status so that the robot reacts flexibly to the current elevator status. We first apply an adaptive threshold to the current image in order to get a binary image. Then we extract the candidates of the buttons and the floor number after preliminary filtering. Ambiguous candidates are rejected using an artificial neural network, and a matching method is applied to finally recognize the call buttons, destination floor buttons, moving direction and current location of the elevator. Second, we suggest a path planning algorithm to navigate into and out of the elevator without any collision. By constructing an occupancy grid map and computing a target function, we find the best position for the robot to get on the elevator. Then we plan an optimal path to the best position using a potential field method. Experiments were carried out in several simulated and real environments including empty, crowd and blocked scenarios. The approach presented here has been found to allow the robot to navigate in the elevator without collisions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-010-0413-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11548-010-0481-0,Development of a colon endoscope robot that adjusts its locomotion through the use of reinforcement learning,International Journal of Computer Assisted Radiology and Surgery,10.1007/s11548-010-0481-0,Springer,2010-07-01,"Purpose Fibre optic colonoscopy is usually performed with manual introduction and advancement of the endoscope, but there is potential for a robot capable of locomoting autonomously from the rectum to the caecum. A prototype robot was designed and tested. Methods The robot colonic endoscope consists in a front body with clockwise helical fin and a rear body with anticlockwise one, both connected via a DC motor. Input voltage is adjusted automatically by the robot, through the use of reinforcement learning, determining speed and direction (forward or backward). Results Experiments were performed both in-vitro and in-vivo, showing the feasibility of the robot. The device is capable of moving in a slippery environment, and reinforcement learning algorithms such as Q-learning and SARSA can obtain better results than simply applying full tension to the robot. Conclusions This self-propelled robotic endoscope has potential as an alternative to current fibre optic colonoscopy examination methods, especially with the addition of new sensors under development.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11548-010-0481-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12541-010-0044-x,Posture optimization for a humanoid robot using a simple genetic algorithm,International Journal of Precision Engineering and Manufacturing,10.1007/s12541-010-0044-x,Springer,2010-06-01,"This study proposes a method of real-time posture optimization of humanoid robots using a genetic algorithm and neural network. Here, the motion of a humanoid robot pushing an object is considered. When the robot starts pushing the object, the palms of its hands and the soles of its feet are assumed to be fixed on the object and on the ground, respectively, and they sense the reaction force from those surfaces. The reaction force results in changes of torques in the joints. This study determines an optimized posture using a genetic algorithm such that either the torques are evenly distributed over all joints or the torque of the weakest joint is rapidly reduced. Several different optimized postures are then generated by varying the reaction forces at the palms and the soles. The data is used as training patterns for a multilayer perceptron neural network with a back-propagation learning algorithm. Using the trained neural network, the humanoid robot can find the optimal posture for different reaction forces in real time. Several simulations were conducted to confirm the effectiveness of the proposed method. The simulation results showed that the proposed method can be used for real-time posture optimization of humanoid robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12541-010-0044-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-009-0248-8,Incremental learning of gestures for human–robot interaction,AI & SOCIETY,10.1007/s00146-009-0248-8,Springer,2010-05-01,"For a robot to cohabit with people, it should be able to learn people’s nonverbal social behavior from experience. In this paper, we propose a novel machine learning method for recognizing gestures used in interaction and communication. Our method enables robots to learn gestures incrementally during human–robot interaction in an unsupervised manner. It allows the user to leave the number and types of gestures undefined prior to the learning. The proposed method (HB-SOINN) is based on a self-organizing incremental neural network and the hidden Markov model. We have added an interactive learning mechanism to HB-SOINN to prevent a single cluster from running into a failure as a result of polysemy of being assigned more than one meaning. For example, a sentence: “Keep on going left slowly” has three meanings such as, “ Keep on (1)”, “ going left (2)”, “ slowly (3)”. We experimentally tested the clustering performance of the proposed method against data obtained from measuring gestures using a motion capture device. The results show that the classification performance of HB-SOINN exceeds that of conventional clustering approaches. In addition, we have found that the interactive learning function improves the learning performance of HB-SOINN.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-009-0248-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11768-010-8038-x,Adaptive RBF neural network control of robot with actuator nonlinearities,Journal of Control Theory and Applications,10.1007/s11768-010-8038-x,Springer,2010-05-01,"In this paper, an adaptive neural network control scheme for robot manipulators with actuator nonlinearities is presented. The control scheme consists of an adaptive neural network controller and an actuator nonlinearities compensator. Since the actuator nonlinearities are usually included in the robot driving motor, a compensator using radial basis function (RBF) network is proposed to estimate the actuator nonlinearities and eliminate their effects. Subsequently, an adaptive neural network controller that neither requires the evaluation of inverse dynamical model nor the time-consuming training process is given. In addition, GL matrix and its product operator are introduced to help prove the stability of the closed control system. Considering the adaptive neural network controller and the RBF network compensator as the whole control scheme, the closed-loop system is proved to be uniformly ultimately bounded (UUB). The whole scheme provides a general procedure to control the robot manipulators with actuator nonlinearities. Simulation results verify the effectiveness of the designed scheme and the theoretical discussion.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11768-010-8038-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-010-0607-x,Robust path tracking control of mobile robot via dynamic petri recurrent fuzzy neural network,Soft Computing,10.1007/s00500-010-0607-x,Springer,2010-04-01,"This study focuses on the design of robust path tracking control for a mobile robot via a dynamic Petri recurrent fuzzy neural network (DPRFNN). In the DPRFNN, the concept of a Petri net (PN) and the recurrent frame of internal feedback loops are incorporated into a traditional fuzzy neural network (FNN) to alleviate the computation burden of parameter learning and to enhance the dynamic mapping of network ability. This five-layer DPRFNN is utilized for the major role in the proposed control scheme, and the corresponding adaptation laws of network parameters are established in the sense of projection algorithm and Lyapunov stability theorem to ensure the network convergence as well as stable control performance without the requirement of detailed system information and the compensation of auxiliary controllers. In addition, the effectiveness of the proposed robust DPRFNN control scheme is verified by experimental results of a differential-driving mobile robot under different moving paths and the occurrence of uncertainties, and its superiority is indicated in comparison with a stabilizing control system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-010-0607-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12541-010-0029-9,Enhanced SLAM for a mobile robot using extended Kalman Filter and neural networks,International Journal of Precision Engineering and Manufacturing,10.1007/s12541-010-0029-9,Springer,2010-04-01,"This paper presents a Hybrid filter based Simultaneous Localization and Mapping (SLAM) scheme for a mobile robot to compensate for the Extended Kalman Filter (EKF) based SLAM errors inherently caused by its linearization process. The proposed Hybrid filter consists of a Radial Basis Function (RBF) and EKF which is a milestone for SLAM applications. A mobile robot autonomously explores the environment by interpreting the scene, building an appropriate map, and localizing itself relative to this map. A probabilistic approach has dominated the solution to the SLAM problem, which is a fundamental requirement for mobile robot navigation. The proposed approach, based on a Hybrid filter, has some advantages in handling a robotic system with nonlinear dynamics because of the learning property of the neural networks. The simulation and experimental results show the effectiveness of the proposed algorithm comparing with an EKF based SLAM and Multi Layer Perceptron (MLP) method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12541-010-0029-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10677-009-9186-2,"Health Care, Capabilities, and AI Assistive Technologies",Ethical Theory and Moral Practice,10.1007/s10677-009-9186-2,Springer,2010-04-01,"Scenarios involving the introduction of artificially intelligent (AI) assistive technologies in health care practices raise several ethical issues. In this paper, I discuss four objections to introducing AI assistive technologies in health care practices as replacements of human care. I analyse them as demands for felt care, good care, private care, and real care. I argue that although these objections cannot stand as good reasons for a general and a priori rejection of AI assistive technologies as such or as replacements of human care, they demand us to clarify what is at stake, to develop more comprehensive criteria for good care, and to rethink existing practices of care. In response to these challenges, I propose a (modified) capabilities approach to care and emphasize the inherent social dimension of care. I also discuss the demand for real care by introducing the ‘Care Experience Machine’ thought experiment. I conclude that if we set the standards of care too high when evaluating the introduction of AI assistive technologies in health care, we have to reject many of our existing, low-tech health care practices.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10677-009-9186-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-009-0294-7,Application of neural processing paradigm in visual landmark recognition and autonomous robot navigation,Neural Computing and Applications,10.1007/s00521-009-0294-7,Springer,2010-03-01,"This article addresses the issue of visual landmark recognition in autonomous robot navigation along known routes, by intuitively exploiting the functions of the human visual system and its navigational ability. A feedforward–feedbackward architecture has been developed for recognising visual landmarks in real time. It integrates the theoretical concepts from the pre-attentive and attentive stages in the human visual system, the selective attention adaptive resonance theory neural network and its derivatives, and computational approaches towards object recognition in computer vision. The architecture mimics the pre-attentive and attentive stages in the context of object recognition, embedding neural network processing paradigm into a computational template-matching approach in computer vision. The real-time landmark recognition capability is achieved by mimicking the pre-attentive stage, where it models a selective attention mechanism for optimal computational resource allocation, focusing only on the regions of interest to address the computational restrictive nature of current computer processing power. Similarly, the recognition of visual landmarks in both clean and cluttered backgrounds is implemented in the attentive stage by developing a memory feedback modulation (MFM) mechanism that enables knowledge from the memory to interact and enhance the efficiency of earlier stages in the architecture. Furthermore, it also incorporates both top-down and bottom-up facilitatory and inhibition pathways between the memory and the earlier stages to enable the architecture to recognise a 2D landmark, which is partially occluded by adjacent features in the surroundings. The results show that the architecture is able to recognise objects in cluttered backgrounds using real-images in both indoor and outdoor scenes. Furthermore, the architecture application in autonomous robot navigation has been demonstrated through a number of real-time trials in both indoor and outdoor environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-009-0294-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-010-0120-0,Position control of a mobile inverted pendulum system using radial basis function network,"International Journal of Control, Automation and Systems",10.1007/s12555-010-0120-0,Springer,2010-02-01,This article presents the implementation of position control of a mobile inverted pendulum (MIP) system by using the radial basis function (RBF) network. The MIP has two wheels to move on the plane and to balance the pendulum. The MIP is a nonlinear system whose dynamics is nonholonomic. The goal of this study was to control the MIP to maintain the balance of the pendulum while tracking a desired position of the cart. The reference compensation technique scheme is used as a neural network control method for the MIP. The back-propagation learning algorithm of the RBF network is derived for online learning and control. The control algorithm has been embedded on a DSP 2812 board to achieve real-time control. Experimental results are conducted and show successful control performances of both balancing and tracking the desired position of the MIP.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-010-0120-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11633-010-0055-1,Action control of soccer robots based on simulated human intelligence,International Journal of Automation and Computing,10.1007/s11633-010-0055-1,Springer,2010-02-01,"A multi-modal action control approach is proposed for an autonomous soccer robot when the bottom hardware is unchangeable. Different from existing methods, the proposed control approach defines actions with the principle of “perception-planning-action” inspired by human intelligence. Character extraction is used to divide the perception input into different modes. Different control modes are built by combining different control methods for the linear velocity and angular velocity. Based on production rules, the motion control is realized by connecting different perceptions to the corresponding control mode. Simulation and real experiments are conducted with the middle-sized robot Frontier-I, and the proposed method is compared with a proportional-integral-derivative (PID) control method to display its feasibility and performance. The results show that the multi-modal action control method can make robots react rapidly in a dynamic environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11633-010-0055-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-009-9149-y,Artificial biochemical networks: a different connectionist paradigm,Artificial Intelligence Review,10.1007/s10462-009-9149-y,Springer,2010-02-01,"Connectionist models are usually based on artificial neural networks. However, there is another route towards parallel distributed processing. This is by considering the origins of the intelligence displayed by the single celled organisms known as protoctists. Such intelligence arises by means of the biochemical interactions within the animal. An artificial model of this might therefore be termed an artificial biochemical network or ABN. This paper describes the attributes of such networks and illustrates their abilities in pattern recognition problems and in generating time-varying signals of a type which can be used in many control tasks. The flexibility of the system is explained using legged robots as an example. The networks are trained using back propagation and evolutionary algorithms such as genetic algorithms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10462-009-9149-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-009-0262-2,A neural framework for adaptive robot control,Neural Computing and Applications,10.1007/s00521-009-0262-2,Springer,2010-02-01,"This paper investigates how dynamics in recurrent neural networks can be used to solve some specific mobile robot problems such as motion control and behavior generation . We have designed an adaptive motion control approach based on a novel recurrent neural network, called Echo state networks. The advantage is that no knowledge about the dynamic model is required, and no synaptic weight changing is needed in presence of time varying parameters in the robot. To generate the robot behavior over time, we adopted a biologically inspired approach called neural fields. Due to its dynamical properties, a neural field produces only one localized peak that indicates the optimum movement direction, which navigates a mobile robot to its goal in an unknown environment without any collisions with static or moving obstacles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-009-0262-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-10781-8_11,Position Estimation of Mobile Robots Using Unsupervised Learning Algorithms,ICT Innovations 2009,10.1007/978-3-642-10781-8_11,Springer,2010-01-01,"Estimating the position of a mobile robot in an environment is a crucial issue. It allows the robot to obtain more precisely the knowledge of its current state and to make the problem of generating command sequences for achieving a certain goal an easier task. The robot learns the environment using an unsupervised learning method and generates a percept – action- percept graph, based on the readings of an ultrasound sensor. The graph is then used in the process of position estimation by matching the current sensory reading category with an existing node category. Our approach allows the robot to generate a set of controls to reach a desired destination. For the learning of the environment, two unsupervised algorithms FuzzyART neural network and GNG network were used. The approach was tested for its ability to recognize previously learnt positions. Both algorithms that were used were compared for their precision.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-10781-8_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-13495-1_82,Multi-robot Formation Control Using Reinforcement Learning Method,Advances in Swarm Intelligence,10.1007/978-3-642-13495-1_82,Springer,2010-01-01,"Formation is a good example of the research for multi-robot cooperation. Many different ways can be used to accomplish this task, but the main drawbacks of most of these methods are that robots can’t self-learn. In Brooks’ behavioral opinion, this paper is to verify that the reinforcement learning method can be used for robots to select different behaviors in various different situations. Experiments are performed to illustrate the team robots’ capability of self-learning and autonomy. The results show that the robots can get a self-formation in a barrier environment after learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-13495-1_82,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-14831-6_27,Robot Reinforcement Learning Based on Learning Classifier System,Advanced Intelligent Computing Theories and Applications,10.1007/978-3-642-14831-6_27,Springer,2010-01-01,"This paper proposed a robot reinforcement learning method based on learning classifier system. A learning Classifier System is a rule-based machine learning system that combines reinforcement learning and genetic algorithms. The reinforcement learning component is responsible for adjusting the strength of rules in the system according to some reward obtained from the environment. The genetic algorithm acts as an innovation discovery component which is responsible for discovering new better learning rules. The advantages of this approach are its rule-based representation, which can easily reduce learning space, improve online learning ability and robustness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-14831-6_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-15399-0_73,Study on an Emotion Generation Model for a Robot Using a Chaotic Neural Network,Entertainment Computing - ICEC 2010,10.1007/978-3-642-15399-0_73,Springer,2010-01-01,"This paper proposes an emotion-generation model for complex change using a chaotic neural network (CNN). Using a CNN, the proposed model will solve the problem of past studies that have indicated that robotic emotion changes are simplistic. The model uses the principle of an adaptation level, which is used in Russell’s emotion model to generate emotion. This paper considers the effectiveness of this approach using simulation, and shows that the model can express a change of “adaptation”. In addition, through the chaos of CNN, the proposed model can express different changes, even if the values of CNN’s input values remain the same.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-15399-0_73,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-16111-7_38,Dynamic Bayesian Networks for Learning Interactions between Assistive Robotic Walker and Human Users,KI 2010: Advances in Artificial Intelligence,10.1007/978-3-642-16111-7_38,Springer,2010-01-01,"Detection of individuals intentions and actions from a stream of human behaviour is an open problem. Yet for robotic agents to be truly perceived as human-friendly entities they need to respond naturally to the physical interactions with the surrounding environment, most notably with the user. This paper proposes a generative probabilistic approach in the form of Dynamic Bayesian Networks (DBN) to seamlessly account for users attitudes. A model is presented which can learn to recognize a subset of possible actions by the user of a gait stability support power rollator walker, such as standing up, sitting down or assistive strolling, and adapt the behaviour of the device accordingly. The communication between the user and the device is implicit, without any explicit intention such as a keypad or voice.The end result is a decision making mechanism that best matches the users cognitive attitude towards a set of assistive tasks, effectively incorporating the evolving activity model of the user in the process. The proposed framework is evaluated in real-life condition.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-16111-7_38,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-12990-2_59,"Neural Networks L
              _2-Gain Control for Robot System",Advances in Neural Network Research and Applications,10.1007/978-3-642-12990-2_59,Springer,2010-01-01,"A new L _2-gain disturbance rejection controller and adaptive adjustment are combined into a hybrid robust control scheme, which is proposed for robot tracking control systems. The proposed controller deals mainly with external disturbances and nonlinear uncertainty in motion control. A neural network (NN) is used to approximate the uncertainties in a robotic system. Meanwhile, the approximating error of the NN is attenuated to a prescribed level by the adaptive robust controller. The adaptive techniques of NN will improve robustness with respect to uncertainty of system, as a result, improving the dynamic performance of robot system. A simulation example demonstrates the effectiveness of the proposed control strategy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-12990-2_59,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-04025-2_9,Skill Transfer of a Mobile Robot Obtained by Reinforcement Learning to a Different Mobile Robot,Brain-Inspired Information Technology,10.1007/978-3-642-04025-2_9,Springer,2010-01-01,"Reinforcement learning (RL) is suitable for navigation of a mobile robot. We overcame some difficulties of RL which are large computational cost and determination of parameter values for RL with the help of a genetic algorithm (GA) and method of parameter prediction based on results of GA and complexity measure. As a result of these proposals, we succeeded in navigating the real robot practically. In our previous studies, we just one kind of mobile robot, which has three wheels. Our RL method can decrease the computational cost for learning of navigation and development of mobile robots, provided the skill obtained by RL for one mobile robot can be transferred to other mobile robots. To verify the generalization capability of RL in navigation of a mobile robot, the present paper proposes to transfer the skill obtained by RL to a different kind of a mobile robot. We carried out the experiment and we succeeded in transferring the skill obtained by RL to a different mobile robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-04025-2_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-04025-2_5,Brain-Inspired Emergence of Behaviors Based on Values and Curiosity in Mobile Robots,Brain-Inspired Information Technology,10.1007/978-3-642-04025-2_5,Springer,2010-01-01,"We propose to introduce the desire for existence, specific curiosity, diversive curiosity, and novelty into reinforcement learning as intrinsic rewards for developing truly autonomous mobile robots capable of behaving without being told what to do. A pursuit-evasion game composed of predators and their prey is selected as a testbed. Simulation experiments and experiments using real mobile robots, WITHs, on a robotic field well demonstrate the effectiveness of introducing intrinsic rewards in addition to external rewards in the conventional reinforcement learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-04025-2_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-84882-694-6_60,Path Searching of a Robot Manipulator Using Reinforcement Learning and Self-Organizing Maps,Service Robotics and Mechatronics,10.1007/978-1-84882-694-6_60,Springer,2010-01-01,"In some applications such as search-and-rescue tasks, it is necessary for a robot manipulator to obtain a path, which can adapt to unknown and changeable environment. Reinforcement learning is effective for this purpose, since it is an algorithm for an agent to achieve an objective task by trial and error, where the agent only needs the goal of the task. A path searching method of an articulated robot in three-dimensional Cartesian space is focused on, while avoiding obstacles. In order to reduce the memory resources and the convergence time, a method of restructuring a configuration space by using self-organizing maps (SOM) is proposed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-84882-694-6_60,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-15844-5_34,Open-Ended Evolutionary Robotics: An Information Theoretic Approach,"Parallel Problem Solving from Nature, PPSN XI",10.1007/978-3-642-15844-5_34,Springer,2010-01-01,"This paper is concerned with designing self-driven fitness functions for Embedded Evolutionary Robotics. The proposed approach considers the entropy of the sensori-motor stream generated by the robot controller. This entropy is computed using unsupervised learning; its maximization, achieved by an on-board evolutionary algorithm, implements a “curiosity instinct”, favouring controllers visiting many diverse sensori-motor states (sms). Further, the set of sms discovered by an individual can be transmitted to its offspring, making a cultural evolution mode possible. Cumulative entropy (computed from ancestors and current individual visits to the sms) defines another self-driven fitness; its optimization implements a “discovery instinct”, as it favours controllers visiting new or rare sensori-motor states. Empirical results on the benchmark problems proposed by Lehman and Stanley (2008) comparatively demonstrate the merits of the approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-15844-5_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-13232-2_39,Design of a Neural Network for an Identification of a Robot Model with a Positive Definite Inertia Matrix,Artifical Intelligence and Soft Computing,10.1007/978-3-642-13232-2_39,Springer,2010-01-01,This article presents a method of designing the neural network for the identification of the robot model in a form of Lagrange-Euler equations. It allows to identify the positive definite inertia matrix. A proposed design of a neural network structure is based on the Cholesky decomposition.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-13232-2_39,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-15393-8_18, A Sensing System for an Autonomous Mobile Robot Based on the Paraconsistent Artificial Neural Network,Knowledge-Based and Intelligent Information and Engineering Systems,10.1007/978-3-642-15393-8_18,Springer,2010-01-01,This paper shows a sensing system for an autonomous mobile robot. The Sensing System is based on the Paraconsistent Neural Network. The type of artificial neural network used in this work is based on the Paraconsistent Evidential Logic – E τ . The objective of the Sensing System is to inform the other robot components the position where there is an obstacle. The reached results have been satisfactory.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-15393-8_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-15822-3_34,Sliding Mode Control of Robot Based on Neural Network Model with Positive Definite Inertia Matrix,Artificial Neural Networks – ICANN 2010,10.1007/978-3-642-15822-3_34,Springer,2010-01-01,"A synthesis of a sliding mode control law, for a robot arm, based on the robot model with a positive definite inertia matrix, identified with an artificial neural network, is presented. The structure of the neural network resemble a Lagrange-Euler mathematical model of the robot, and identifies the positive definite inertia matrix. A design of the neural model is based on the Cholesky decomposition of the identified inertia matrix.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-15822-3_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-15399-0_69,Study on an Information Processing Model with Psychological Memory for a Kansei Robot,Entertainment Computing - ICEC 2010,10.1007/978-3-642-15399-0_69,Springer,2010-01-01,"In this paper, we propose an information processing model for a kansei robot. This model handles memory based on human psychology. We expect that on incorporating the model, a robot can exhibit human characteristics because of using psychological memory. To verify the model, we first perform a comparison between the results of the experiment performed using this model and that of an actual psychological experiment. The results of the comparison suggest that the memory functions of the model are similar to the human memory functions. Second, we conduct the process of learning movement actions to verify that the robot on which the model was implemented learned movement for moving to many places and decreasing its curiosity.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-15399-0_69,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-17319-6_49,Accelerating Point-Based POMDP Algorithms via Greedy Strategies,"Simulation, Modeling, and Programming for Autonomous Robots",10.1007/978-3-642-17319-6_49,Springer,2010-01-01,"Many planning tasks of autonomous robots can be modeled as partially observable Markov decision process (POMDP) problems. Point-based algorithms are well-known algorithms for solving large-scale POMDP problems. Several leading point-based algorithms eschew some flawed but very useful heuristics to find an ε -optimal policy. This paper aims at exploiting these avoided heuristics by a simple framework. The main idea of this framework is to construct a greedy strategy and combine it with the leading algorithms. We present an implementation to verify the framework’s validity. The greedy strategy in this implementation stems from some common ignored heuristics in three leading algorithms, and therefore can be well combined with them. Experimental results show that the combined algorithms are more efficient than the original algorithms. On some benchmark problems, the combined algorithms have achieved about an order of magnitude improvement in runtime. These results provide an empirical evidence for our proposed framework’s efficiency.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-17319-6_49,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-05181-4_14,Abstraction Levels for Robotic Imitation: Overview and Computational Approaches,From Motor Learning to Interaction Learning in Robots,10.1007/978-3-642-05181-4_14,Springer,2010-01-01,"This chapter reviews several approaches to the problem of learning by imitation in robotics. We start by describing several cognitive processes identified in the literature as necessary for imitation. We then proceed by surveying different approaches to this problem, placing particular emphasys on methods whereby an agent first learns about its own body dynamics by means of self-exploration and then uses this knowledge about its own body to recognize the actions being performed by other agents. This general approach is related to the motor theory of perception, particularly to the mirror neurons found in primates. We distinguish three fundamental classes of methods, corresponding to three abstraction levels at which imitation can be addressed. As such, the methods surveyed herein exhibit behaviors that range from raw sensory-motor trajectory matching to high-level abstract task replication. We also discuss the impact that knowledge about the world and/or the demonstrator can have on the particular behaviors exhibited.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-05181-4_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-05181-4_10,Imitation and Reinforcement Learning for Motor Primitives with Perceptual Coupling,From Motor Learning to Interaction Learning in Robots,10.1007/978-3-642-05181-4_10,Springer,2010-01-01,"Traditional motor primitive approaches deal largely with open-loop policies which can only deal with small perturbations. In this paper, we present a new type of motor primitive policies which serve as closed-loop policies together with an appropriate learning algorithm. Our new motor primitives are an augmented version version of the dynamical system-based motor primitives [Ijspeert et al(2002)Ijspeert, Nakanishi, and Schaal] that incorporates perceptual coupling to external variables. We show that these motor primitives can perform complex tasks such as Ball-in-a-Cup or Kendama task even with large variances in the initial conditions where a skilled human player would be challenged. We initialize the open-loop policies by imitation learning and the perceptual coupling with a handcrafted solution. We first improve the open-loop policies and subsequently the perceptual coupling using a novel reinforcement learning method which is particularly well-suited for dynamical system-based motor primitives.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-05181-4_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-17248-9_11,State Representation with Perceptual Constancy Based on Active Motion,Social Robotics,10.1007/978-3-642-17248-9_11,Springer,2010-01-01,"In a robot system, it is important to consider how the outside environment is expressed as a state using sensor information. In this study, we provide a state representation that can express the sensor output changed by environmental change as the same state. It assumes that sensor outputs are probability distributions, and the distances between the distributions of each sensor’s output are used to express a state. To confirm the effectiveness of the proposed state representation, we conducted experiments using a mobile robot. The results confirmed that the proposed representation could recognize similar states using a converted sensor output.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-17248-9_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-15822-3_22,An Incremental Probabilistic Neural Network for Regression and Reinforcement Learning Tasks,Artificial Neural Networks – ICANN 2010,10.1007/978-3-642-15822-3_22,Springer,2010-01-01,"This paper presents a new probabilistic neural network model, called IPNN (for Incremental Probabilistic Neural Network), which is able to learn continuously probability distributions from data flows. The proposed model is inspired by the Specht’s general regression neural network, but have several improvements which makes it more suitable to be used on-line in and robotic tasks. Moreover, IPNN is able to automatically define the network structure in an incremental way, with new units added whenever necessary to represent new training data. The performed experiments shows that IPNN is very useful in regression and reinforcement learning tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-15822-3_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-13769-3_11,Automatic Behavior Pattern Classification for Social Robots,Hybrid Artificial Intelligence Systems,10.1007/978-3-642-13769-3_11,Springer,2010-01-01,"In this paper, we focus our attention on providing robots with a system that allows them to automatically detect behavior patterns in other robots, as a first step to introducing social responsive robots. The system is called ANPAC (Automatic Neural-based Pattern Classification). Its main feature is that ANPAC automatically adjusts the optimal processing window size and obtains the appropriate features through a dimensional transformation process that allow for the classification of behavioral patterns of large groups of entities from perception datasets. Here we present the basic elements and operation of ANPAC, and illustrate its applicability through the detection of behavior patterns in the motion of flocks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-13769-3_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-05177-7_22,Comparison of Machine Learning for Autonomous Robot Discovery,Advances in Machine Learning I,10.1007/978-3-642-05177-7_22,Springer,2010-01-01,"In this paper we consider autonomous robot discovery through experimentation in the robot’s environment. We analyse the applicability of machine learning (ML) methods with respect to various levels of robot discovery tasks, from extracting simple laws among the observed variables, to discovering completely new notions that were never explicitly mentioned in the data directly. We first present some illustrative experiments in robot learning in the XPERO European project. Then we formulate criteria for a comparison of learning methods and a systematic list of types of learning or discovery tasks, and discuss the suitability of chosen ML methods for these tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-05177-7_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-13232-2_32,Discrete Model-Based Adaptive Critic Designs in Wheeled Mobile Robot Control,Artifical Intelligence and Soft Computing,10.1007/978-3-642-13232-2_32,Springer,2010-01-01,"In this paper a discrete tracking control algorithm for a non-holonomic two–wheeled mobile robot (WMR) is presented. The basis of the control algorithm is an Adaptive Critic Design (ACD) in two model-based configurations: Heuristic Dynamic Programming (HDP) and Dual Heuristic Programming (DHP). In proposed control algorithm Actor–Critic structure, composed of two neural networks (NN), is supplied by a PD controller and a supervisory term derived from the Lyapunov stability theorem. The control algorithm works on-line and does not require preliminary learning. Verification of the proposed control algorithm was realized on a WMR Pioneer–2DX.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-13232-2_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-05181-4_1,From Motor Learning to Interaction Learning in Robots,From Motor Learning to Interaction Learning in Robots,10.1007/978-3-642-05181-4_1,Springer,2010-01-01,"The number of advanced robot systems has been increasing in recent years yielding a large variety of versatile designs with many degrees of freedom. These robots have the potential of being applicable in uncertain tasks outside wellstructured industrial settings. However, the complexity of both systems and tasks is often beyond the reach of classical robot programming methods. As a result, a more autonomous solution for robot task acquisition is needed where robots adaptively adjust their behaviour to the encountered situations and required tasks. Learning approaches pose one of the most appealing ways to achieve this goal. However, while learning approaches are of high importance for robotics, we cannot simply use off-the-shelf methods from the machine learning community as these usually do not scale into the domains of robotics due to excessive computational cost as well as a lack of scalability. Instead, domain appropriate approaches are needed. In this book, we focus on several core domains of robot learning. For accurate task execution, we need motor learning capabilities. For fast learning of the motor tasks, imitation learning offers the most promising approach. Self improvement requires reinforcement learning approaches that scale into the domain of complex robots. Finally, for efficient interaction of humans with robot systems, we will need a form of interaction learning. This chapter provides a general introduction to these issues and briefly presents the contributions of the subsequent chapters to the corresponding research topics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-05181-4_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-16761-4_10,Teaching a Robot to Perform Tasks with Voice Commands,Advances in Artificial Intelligence,10.1007/978-3-642-16761-4_10,Springer,2010-01-01,"The full deployment of service robots in daily activities will require the robot to adapt to the needs of non-expert users, particularly, to learn how to perform new tasks from “natural” interactions. Reinforcement learning has been widely used in robotics, however, traditional algorithms require long training times, and may have problems with continuous spaces. Programming by demonstration has been used to instruct a robot, but is limited by the quality of the trace provided by the user. In this paper, we introduce a novel approach that can handle continuous spaces, can produce continuous actions and incorporates the user’s intervention to quickly learn optimal policies of tasks defined by the user. It is shown how the continuous actions produce smooth trajectories and how the user’s intervention allows the robot to learn significantly faster optimal policies. The proposed approach is tested in a simulated robot with very promising results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-16761-4_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-14547-6_26,Can a Developmental AIS Provide Immunity to a Multi-cellular Robotics System?,Artificial Immune Systems,10.1007/978-3-642-14547-6_26,Springer,2010-01-01,The major challenge to multi-cellular robotics system is how to ensure the system is homeostatically stable. This position paper proposes a developmental artificial immune system (dev-AIS) framework that tries to provide and maintain homeostasis to the multi-cellular robotics system. If immunity is defined as the ability to maintain homeostasis; the dev-AIS framework will be designed based on the understanding and the abstraction of how different organisms attain for this property through evolution and developmental process. Progress in evolution drove the evolution of immunity from this simple relationship to the development of the immune system in multi-cellular organisms.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-14547-6_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-05181-4_7,Learning to Exploit Proximal Force Sensing: A Comparison Approach,From Motor Learning to Interaction Learning in Robots,10.1007/978-3-642-05181-4_7,Springer,2010-01-01,"We present an evaluation of different techniques for the estimation of forces and torques measured by a single six-axis force/torque sensor placed along the kinematic chain of a humanoid robot arm. In order to retrieve the external forces and detect possible contact situations, the internal forces must be estimated. The prediction performance of an analytically derived dynamic model as well as two supervised machine learning techniques, namely Least Squares Support Vector Machines and Neural Networks, are investigated on this problem. The performance are evaluated on the normalized mean square error (NMSE) and the comparison is made with respect to the dimension of the training set, the information contained in the input space and, finally, using a Euclidean subsampling strategy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-05181-4_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-17248-9_14,A Software Framework for Multi Player Robot Games,Social Robotics,10.1007/978-3-642-17248-9_14,Springer,2010-01-01,"Robot games have been proposed as a way to motivate people to do physical exercises while playing. Although this area is very new, both commercial and scientific robot games have been developed mainly based on interaction with a single user and a robot. The goal of this paper is to describe a generic software framework which can be used to create games where multiple players can play against a mobile robot. The paper shows how an adaptive AI system (D2) developed for real-time strategy (RTS) computer games can be successfully applied in a robotics context using the robotics control framework Player/Stage. D2 is based on Case-Based Planning which learns from demonstration. Using the proposed framework, the paper shows how a robot learns a strategy for an implementation of a simple game.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-17248-9_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-16587-0_39,An Adaptive RBF Neural Network Control Strategy for Lower Limb Rehabilitation Robot,Intelligent Robotics and Applications,10.1007/978-3-642-16587-0_39,Springer,2010-01-01,"This paper proposed an adaptive control strategy based on RBF (radial basis function) neural network and PD Computed-Torque algorithm for precise tracking of a predefined trajectory. This control strategy can not only give a small tracking error, but also have a good robustness to the modeling errors of the robot dynamics equation and also to the system friction. With this control algorithm, the robot can work in assist-as-needed mode by detecting the human active joint torque. At last, a simulation result using matlab simulink is given to illustrate the effectiveness of our control strategy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-16587-0_39,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-11876-0_39,Cooperative Multi-robot Map Merging Using Fast-SLAM,RoboCup 2009: Robot Soccer World Cup XIII,10.1007/978-3-642-11876-0_39,Springer,2010-01-01,"Multi-robot map merging is an essential task for cooperative robot navigation. In the realistic case, the robots do not know the initial positions of the others and this adds extra challenges to the problem. Some approaches search transformation parameters using the local maps and some approaches assume the robots will observe each other and use robot to robot observations. This work extends a previous work which is based on EKF-SLAM to the Fast-SLAM algorithm. The robots can observe each other and non-unique landmarks using visual sensors and merge maps by propagating uncertainty. Another contribution is the calibration of noise parameters with supervised data using the Evolutionary Strategies method. The developed algorithms are tested in both simulated and real robot experiments and the improvements and applicability of the developed methods are shown with the results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-11876-0_39,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-17322-6_30,Towards Semantic Navigation in Mobile Robotics,Graph Transformations and Model-Driven Engineering,10.1007/978-3-642-17322-6_30,Springer,2010-01-01,"Nowadays mobile robots find application in many areas of production, public transport, security and defense, exploration of space, etc. In order to make further progress in this domain of engineering, a significant barrier has to be broken: robots must be able to understand the meaning of surrounding world. Until now, mobile robots have only perceived geometrical features of the environment. Rapid progress in sensory devices (video cameras, laser range finders, microwave radars) and sufficient computational power available on-board makes it possible to develop robot controllers that possess certain knowledge about the area of application and which are able to reason at a semantic level. The first part of the paper deals with mobile robots dedicated to operate inside buildings. A concept of the semantic navigation based upon hypergraphs is introduced. Then it is shown how semantic information, useful for mobile robots, can be extracted from the digital documentation of a building. In the second part of the paper we report the latest results on extracting semantic features from the raw data supplied by laser scanners. The aim of this research is to develop a system that will enable a mobile robot to operate in a building with ability to recognise and identify objects of certain classes. Data processing techniques involved in this system include a 3D-model of the environment updated on-line, rule-based and feature-based classifiers of objects, a path planner utilizing cellular networks and other advanced tools. Experiments carried out under real-life conditions validate the proposed solutions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-17322-6_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-15193-4_45,Learning Inverse Kinematics for Pose-Constraint Bi-manual Movements,From Animals to Animats 11,10.1007/978-3-642-15193-4_45,Springer,2010-01-01,"We present a neural network approach to learn inverse kinematics of the humanoid robot ASIMO, where we focus on bi-manual tool use. The learning copes with both the highly redundant inverse kinematics of ASIMO and the additional arbitrary constraint imposed by the tool that couples both hands. We show that this complex kinematics can be learned from few ground-truth examples using an efficient recurrent reservoir framework, which has been introduced previously for kinematics learning and movement generation. We analyze and quantify the network’s generalization for a given tool by means of reproducing the constraint in untrained target motions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-15193-4_45,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-15819-3_50,Designing Simple Nonlinear Filters Using Hysteresis of Single Recurrent Neurons for Acoustic Signal Recognition in Robots,Artificial Neural Networks – ICANN 2010,10.1007/978-3-642-15819-3_50,Springer,2010-01-01,"In this article we exploit the discrete-time dynamics of a single neuron with self-connection to systematically design simple signal filters. Due to hysteresis effects and transient dynamics, this single neuron behaves as an adjustable low-pass filter for specific parameter configurations. Extending this neuro-module by two more recurrent neurons leads to versatile high- and band-pass filters. The approach presented here helps to understand how the dynamical properties of recurrent neural networks can be used for filter design. Furthermore, it gives guidance to a new way of implementing sensory preprocessing for acoustic signal recognition in autonomous robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-15819-3_50,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-05177-7_21,Automatic Selection of Object Recognition Methods Using Reinforcement Learning,Advances in Machine Learning I,10.1007/978-3-642-05177-7_21,Springer,2010-01-01,"Selecting which algorithms should be used by a mobile robot computer vision system is a decision that is usually made a priori by the system developer, based on past experience and intuition, not systematically taking into account information that can be found in the images and in the visual process itself to learn which algorithm should be used, in execution time. This paper presents a method that uses Reinforcement Learning to decide which algorithm should be used to recognize objects seen by a mobile robot in an indoor environment, based on simple attributes extracted on-line from the images, such as mean intensity and intensity deviation. Two state-of-the-art object recognition algorithms can be selected: the constellation method proposed by Lowe together with its interest point detector and descriptor, the Scale-Invariant Feature Transform and Nistér and Stewénius Vocabulary Tree approach. A set of empirical evaluations was conducted using a household mobile robots image database, and results obtained shows that the approach adopted here is very promising.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-05177-7_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-90-481-9112-3_11,An Intelligent Control System Based on Non-Invasive Man Machine Interaction,Innovations in Computing Sciences and Software Engineering,10.1007/978-90-481-9112-3_11,Springer,2010-01-01,This paper presents further development of intelligent multi-agent based e-health care system for people with movement disabilities. The research results present further development of multi-layered model of this system with integration of fuzzy neural control of speed of two wheelchair type robots working in real time by providing movement support for disabled individuals. An approach of filtering of skin conductance (SC) signals using Nadaraya-Watson kernel regression smoothing for emotion recognition of disabled individuals is described and implemented in the system by R software tool. The unsupervised clustering by self organizing maps (SOM) of data sample of physiological parameters extracted from SC signals was proposed in order to reduce teacher noise as well as to increase of speed and accuracy of learning process of multi-layer perceptron (MLP) training.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-90-481-9112-3_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-84882-694-6_47,Calibration of Kinematic Parameters of a Robot Using Neural Networks by a Laser Tracking System,Service Robotics and Mechatronics,10.1007/978-1-84882-694-6_47,Springer,2010-01-01,"Almost the industrial robot tasks are performed by the teaching playback method. This method has problem that the laborious and time-consuming online manual teaching is inevitable. Thus, the offline teaching based on the high positioning accuracy is desired. However, a nominal kinematic model does not consider the geometric errors and non-geometric errors. Therefore, some method of calibrating precisely the parameters is required. The kinematic parameters are calibrated by minimizing errors between the measured positions and the predicted ones by nonlinear least square method. After that, the residual errors caused by non-geometric parameters are further reduced by using neural networks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-84882-694-6_47,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-17537-4_4,Human Localization by Fuzzy Spiking Neural Network Based on Informationally Structured Space,Neural Information Processing. Theory and Algorithms,10.1007/978-3-642-17537-4_4,Springer,2010-01-01,"This paper analyzes the performance of the human localization by a spiking neural network in informationally structured space based on sensor networks. First, we discuss the importance of information structuralization. Next, we apply a spiking neural network to extract the human position in a room equipped with sensor network devices. Next, we propose how to update the base value as a method of preprocessing to generate input values to the spiking neurons, and the learning method of the spiking neural network based on the time series of measured data. Finally, we show several experimental results, and discuss the effectiveness of the proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-17537-4_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-17298-4_31,Supplanting Neural Networks with ODEs in Evolutionary Robotics,Simulated Evolution and Learning,10.1007/978-3-642-17298-4_31,Springer,2010-01-01,"A new approach to evolutionary robotics is presented. Neural networks are abstracted and supplanted by a system of ordinary differential equations that govern the changes in controller outputs. The equations are evolved as trees using an evolutionary algorithm based on symbolic regression in genetic programming. Initial proof-of-concept experiments are performed using a simulated two-wheeled robot that must drive a straight line while wheel response properties vary. Evolved controllers demonstrate the ability to learn and adapt to a changing environment, as well as the ability to generalize and perform well in novel situations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-17298-4_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-84882-694-6_49,Evolutionary Artificial Neural Networks using Extended Minimal Simulation on Evolutionary Robotics,Service Robotics and Mechatronics,10.1007/978-1-84882-694-6_49,Springer,2010-01-01,"In this paper, we try to construct a simulation using evolutionary artificial neural networks models for building the robot controller and adopt an expansion that introduces noise to acquire precise and advanced processing for the robot. In ER approach addressing virtual spaces that contain noise, a simulation technique is called Minimal Simulation. In some experiments, it was shown that the controller was able to be acquired by simulation, yet it does not reach the level that is necessary for the development of a general simulation methodology. Therefore, we propose Extended Minimal Simulation method that introduces alternative coding techniques and show the effect of this technique.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-84882-694-6_49,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-15992-3_5,Learning and Fast Object Recognition in Robot Skill Acquisition: A New Method,Advances in Pattern Recognition,10.1007/978-3-642-15992-3_5,Springer,2010-01-01,"Invariant object recognition aims at recognising an object independently of its position, scale and orientation. This is important in robot skill acquisition during grasping operations especially when working in unstructured environments. In this paper we present an approach to aid the learning of manipulative skills on-line. We introduce and approach based on an ANN for object learning and recognition using a descriptive vector built on recurrent patterns. Experimental learning results using a fast camera are presented. Some simple parts (i.e. circular, squared and radiused-square) were used for comparing different connectionist models (Backpropagation, Perceptron and FuzzyARTMAP) and to select the appropriate model. Later during experiments, complex figures were learned using the chosen FuzzyARTMAP algorithm showing a 93.8% overall efficiency and 100% recognition rate with not so complex parts. Recognition times were lower than 1 ms, which clearly indicates the suitability of the approach to be implemented in robotic real-world operations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-15992-3_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-009-0674-1,Intelligent control of a three-DOF planar underactuated manipulator,Artificial Life and Robotics,10.1007/s10015-009-0674-1,Springer,2009-12-06,"Recently, computational intelligence has been applied extensively in control engineering, especially for systems that cannot easily be controlled by conventional means. In this article, attention is paid to the control of a three-DOF planar underactuated manipulator, also known as the three-link gymnastic robot, by utilizing a neural network (NN) and a genetic algorithm (GA). In an attempt to make the problem more analogous to human gymnastics, constraints are applied to the joint angles. With different swing-up timings, the performance of the proposed controller is investigated and control simulations are performed. Numerical simulations show that the neurocontroller is able to control the system effectively within the constraints and given timings.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-009-0674-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10458-009-9082-0,A grounding framework,Autonomous Agents and Multi-Agent Systems,10.1007/s10458-009-9082-0,Springer,2009-12-01,"In order for an agent to achieve its objectives, make sound decisions, communicate and collaborate with others effectively it must have high quality representations . Representations can encapsulate objects, situations, experiences, decisions and behavior just to name a few. Our interest is in designing high quality representations, therefore it makes sense to ask of any representation; what does it represent; why is it represented; how is it represented; and importantly how well is it represented. This paper identifies the need to develop a better understanding of the grounding process as key to answering these important questions. The lack of a comprehensive understanding of grounding is a major obstacle in the quest to develop genuinely intelligent systems that can make their own representations as they seek to achieve their objectives. We develop an innovative framework which provides a powerful tool for describing, dissecting and inspecting grounding capabilities with the necessary flexibility to conduct meaningful and insightful analysis and evaluation. The framework is based on a set of clearly articulated principles and has three main applications. First, it can be used at both theoretical and practical levels to analyze grounding capabilities of a single system and to evaluate its performance. Second, it can be used to conduct comparative analysis and evaluation of grounding capabilities across a set of systems. Third, it offers a practical guide to assist the design and construction of high performance systems with effective grounding capabilities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10458-009-9082-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12293-009-0015-x,Fast reinforcement learning for simple physical robots,Memetic Computing,10.1007/s12293-009-0015-x,Springer,2009-09-25,"In the past few years, the field of autonomous robot has been rigorously studied and non-industrial applications of robotics are rapidly emerging. One of the most interesting aspects of this field is the development of the learning ability which enables robots to autonomously adapt to given environments without human guidance. As opposed to the conventional methods of robots’ control, where human logically design the behavior of a robot, the ability to acquire action strategies through some learning processes will not only significantly reduce the production costs of robots but also improves the applicability of robots in wider tasks and environments. However, learning algorithms usually require large calculation cost, which make them unsuitable for robots with limited resources. In this study, we propose a simple two-layered neural network that implements a novel and fast Reinforcement Learning. The proposed learning method requires significantly less calculation resources, hence is applicable to small physical robots running in the real world environments. For this study, we built several simple robots and implemented the proposed learning mechanism to them. In the experiments, to evaluate the efficacy of the proposed learning mechanism, several robots were simultaneously trained to acquire obstacle avoidance strategies in the same environment, thus, forming a dynamic environment where the learning task is substantially harder than in the case of learning in a static environment and promising result was obtained.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12293-009-0015-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-009-9157-4,Reactive direction control for a mobile robot: a locust-like control of escape direction emerges when a bilateral pair of model locust visual neurons are integrated,Autonomous Robots,10.1007/s10514-009-9157-4,Springer,2009-09-25,"Locusts possess a bilateral pair of uniquely identifiable visual neurons that respond vigorously to the image of an approaching object. These neurons are called the lobula giant movement detectors (LGMDs). The locust LGMDs have been extensively studied and this has lead to the development of an LGMD model for use as an artificial collision detector in robotic applications. To date, robots have been equipped with only a single, central artificial LGMD sensor, and this triggers a non-directional stop or rotation when a potentially colliding object is detected. Clearly, for a robot to behave autonomously, it must react differently to stimuli approaching from different directions. In this study, we implement a bilateral pair of LGMD models in Khepera robots equipped with normal and panoramic cameras. We integrate the responses of these LGMD models using methodologies inspired by research on escape direction control in cockroaches. Using ‘randomised winner-take-all’ or ‘steering wheel’ algorithms for LGMD model integration, the Khepera robots could escape an approaching threat in real time and with a similar distribution of escape directions as real locusts. We also found that by optimising these algorithms, we could use them to integrate the left and right DCMD responses of real jumping locusts offline and reproduce the actual escape directions that the locusts took in a particular trial. Our results significantly advance the development of an artificial collision detection and evasion system based on the locust LGMD by allowing it reactive control over robot behaviour. The success of this approach may also indicate some important areas to be pursued in future biological research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-009-9157-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12559-009-9021-z,Actor-Critic Learning for Platform-Independent Robot Navigation,Cognitive Computation,10.1007/s12559-009-9021-z,Springer,2009-09-01,"This article describes an approach in the field of reinforcement learning for robot control and a new Modular Actor-Critic architecture which supports platform-independent robot control. The architecture is tested on a landmark approaching task using movable pan/tilt cameras which successfully control both a large PeopleBot and a small Sony Aibo robot to perform the navigation task, with no retraining required. The architecture provides insight into the skills transfer between different robotic platforms and the modularisation of the architecture derived from splitting the control tasks into their component parts. The architecture and underlying principles could be used in rapid prototyping of new robotic platforms, where an already functioning control system can be used to allow more sophisticated navigation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12559-009-9021-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-009-9336-8,Asymptotic Adaptive Neural Network Tracking Control of Nonholonomic Mobile Robot Formations,Journal of Intelligent and Robotic Systems,10.1007/s10846-009-9336-8,Springer,2009-09-01,"In this paper, asymptotically stable control laws are developed for leader–follower based formation control using backstepping in order to accommodate the dynamics of the robots and the formation. First, a kinematic controller is developed around control strategies for single mobile robots and the idea of virtual leaders. The virtual leader is replaced with a physical mobile robot leader, and an auxiliary velocity control law is developed in order to prove the global asymptotic stability of the followers which in turn allows the local asymptotic stability of the entire formation. A novel approach is taken in the development of the dynamical controller such that the torque control inputs for the follower robots include the dynamics of the follower robot as well as the dynamics of its leader, and two cases are considered—the case when the robot dynamics are known and the case when they are unknown. In the first case, a robust adaptive control term is utilized to account for unmodeled dynamics. For the latter, a robust adaptive term is augmented with a NN control law to achieve asymptotic tracking performance in contrast with most NN controllers where a bounded tracking error result is shown. Additionally, the NN approximation error is assumed to be a function of tracking errors instead of a constant upper bound, which is commonly found in the literature. The stability of the follower robots as well as the entire formation is demonstrated in each case using Lyapunov methods and numerical results are provided.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-009-9336-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-009-0026-2,"Personal Robots, Appearance, and Human Good: A Methodological Reflection on Roboethics",International Journal of Social Robotics,10.1007/s12369-009-0026-2,Springer,2009-08-01,"The development of pet robots, toy robots, and sex robots suggests a near-future scenario of habitual living with ‘personal’ robots. How should we evaluate their potential impact on the quality of our lives and existence? In this paper, I argue for an approach to ethics of personal robots that advocates a methodological turn from robots to humans, from mind to interaction, from intelligent thinking to social-emotional being, from reality to appearance, from right to good, from external criteria to good internal to practice, and from theory to experience and imagination. First I outline what I take to be a common approach to roboethics, then I sketch the contours of an alternative methodology: ethics of personal robots as an ethics of appearance, human good, experience, and imagination. The result is a sketch of an empirically informed anthropocentric ethics that aims at understanding and evaluating what robots do to humans as social and emotional beings in virtue of their appearance, in particular how they may contribute to human good and human flourishing. Starting from concrete experience and practice and being sufficiently sensitive to individual and cultural differences, this approach invites us to be attentive to how human good emerges in human–robot interaction and to imagine, possibilities of living with personal robots that help to constitute good human lives.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-009-0026-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-009-9132-0,Learning model-free robot control by a Monte Carlo EM algorithm,Autonomous Robots,10.1007/s10514-009-9132-0,Springer,2009-08-01,"We address the problem of learning robot control by model-free reinforcement learning (RL). We adopt the probabilistic model for model-free RL of Vlassis and Toussaint (Proceedings of the international conference on machine learning, Montreal, Canada, 2009 ), and we propose a Monte Carlo EM algorithm (MCEM) for control learning that searches directly in the space of controller parameters using information obtained from randomly generated robot trajectories. MCEM is related to, and generalizes, the PoWER algorithm of Kober and Peters (Proceedings of the neural information processing systems, 2009 ). In the finite-horizon case MCEM reduces precisely to PoWER, but MCEM can also handle the discounted infinite-horizon case. An interesting result is that the infinite-horizon case can be viewed as a ‘randomized’ version of the finite-horizon case, in the sense that the length of each sampled trajectory is a random draw from an appropriately constructed geometric distribution. We provide some preliminary experiments demonstrating the effects of fixed (PoWER) vs randomized (MCEM) horizon length in two simulated and one real robot control tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-009-9132-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-009-9133-z,Nonparametric representation of an approximated Poincaré map for learning biped locomotion,Autonomous Robots,10.1007/s10514-009-9133-z,Springer,2009-08-01,"We propose approximating a Poincaré map of biped walking dynamics using Gaussian processes. We locally optimize parameters of a given biped walking controller based on the approximated Poincaré map. By using Gaussian processes, we can estimate a probability distribution of a target nonlinear function with a given covariance. Thus, an optimization method can take the uncertainty of approximated maps into account throughout the learning process. We use a reinforcement learning (RL) method as the optimization method. Although RL is a useful non-linear optimizer, it is usually difficult to apply RL to real robotic systems due to the large number of iterations required to acquire suitable policies. In this study, we first approximated the Poincaré map by using data from a real robot, and then applied RL using the estimated map in order to optimize stepping and walking policies. We show that we can improve stepping and walking policies both in simulated and real environments. Experimental validation on a humanoid robot of the approach is presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-009-9133-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-009-9120-4,Reinforcement learning for robot soccer,Autonomous Robots,10.1007/s10514-009-9120-4,Springer,2009-07-01,"Batch reinforcement learning methods provide a powerful framework for learning efficiently and effectively in autonomous robots. The paper reviews some recent work of the authors aiming at the successful application of reinforcement learning in a challenging and complex domain. It discusses several variants of the general batch learning framework, particularly tailored to the use of multilayer perceptrons to approximate value functions over continuous state spaces. The batch learning framework is successfully used to learn crucial skills in our soccer-playing robots participating in the RoboCup competitions. This is demonstrated on three different case studies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-009-9120-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-009-0254-2,AI-SIMCOG: a simulator for spiking neurons and multiple animats’ behaviours,Neural Computing and Applications,10.1007/s00521-009-0254-2,Springer,2009-06-01,"Designing a biologically inspired neural architecture as a controller for a complete animat or physical robot environment, to test the hypotheses on intelligence or cognition is non-trivial, particularly, if the controller is a network of spiking neurons. As a result, simulators that integrate spike coding and artificial or real-world platforms are scarce. In this paper, we present artificial intelligence simulator of cognition, a software simulator designed to explore the computational power of pulsed coding at the level of small cognitive systems. Our focus is on convivial graphical user interface, real-time operation and multilevel Hebbian synaptic adaptation, accomplished through a set of non-linear dynamic weights and on-line, life-long modulation. Inclusions of transducer and hormone components, intrinsic oscillator and several learning functions in a discrete spiking neural algorithm are distinctive features of the software. Additional features are the easy link between the production of specific neural architectures and an artificial 2D-world simulator, where one or more animats implement an input–output transfer function in real-time, as do robots in the real world. As a result, the simulator code is exportable to a robot’s microprocessor. This realistic neural model is thus amenable to investigate several time related cognitive problems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-009-0254-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10852-009-9105-5,AIS Based Distributed Wireless Sensor Network for Mobile Search and Rescue Robot Tracking,Journal of Mathematical Modelling and Algorithms,10.1007/s10852-009-9105-5,Springer,2009-06-01,"This research presents the implementation of GSCF, an AIS-based control framework, on a distributed wireless sensor network for tracking search and rescue robots in open fields. The General Suppression Control Framework (GSCF) is a framework inspired by the suppression hypothesis of the immune discrimination theory. The framework consists of five distinct components; each carries a specific function that can generate long-term and short-term influences to other components by the use of humoral and cellular signals. The goal of the research is to develop mathematical models that can assist the control and analyses of robots behavior through the use of Suppressor Cells in the Suppression Modulator. Acquire data from the physical robot will be used as simulation parameters in future search and rescue research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10852-009-9105-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10458-009-9095-8,Teaching a pet-robot to understand user feedback through interactive virtual training tasks,Autonomous Agents and Multi-Agent Systems,10.1007/s10458-009-9095-8,Springer,2009-05-10,"In this paper, we present a human-robot teaching framework that uses “virtual” games as a means for adapting a robot to its user through natural interaction in a controlled environment. We present an experimental study in which participants instruct an AIBO pet robot while playing different games together on a computer generated playfield. By playing the games and receiving instruction and feedback from its user, the robot learns to understand the user’s typical way of giving multimodal positive and negative feedback. The games are designed in such a way that the robot can reliably predict positive or negative feedback based on the game state and explore its user’s reward behavior by making good or bad moves. We implemented a two-staged learning method combining Hidden Markov Models and a mathematical model of classical conditioning to learn how to discriminate between positive and negative feedback. The system combines multimodal speech and touch input for reliable recognition. After finishing the training, the system was able to recognize positive and negative reward with an average accuracy of 90.33%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10458-009-9095-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10339-008-0234-y,Brain and mind operational architectonics and man-made “machine” consciousness,Cognitive Processing,10.1007/s10339-008-0234-y,Springer,2009-05-01,To build a true conscious robot requires that a robot’s “brain” be capable of supporting the phenomenal consciousness as human’s brain enjoys. Operational Architectonics framework through exploration of the temporal structure of information flow and inter-area interactions within the network of functional neuronal populations [by examining topographic sharp transition processes in the scalp electroencephalogram (EEG) on the millisecond scale] reveals and describes the EEG architecture which is analogous to the architecture of the phenomenal world. This suggests that the task of creating the “machine” consciousness would require a machine implementation that can support the kind of hierarchical architecture found in EEG.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10339-008-0234-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-009-9323-0,On Multiple Secondary Task Execution of Redundant Nonholonomic Mobile Manipulators,Journal of Intelligent and Robotic Systems,10.1007/s10846-009-9323-0,Springer,2009-04-18,"This paper investigates self-motion control of redundant nonholonomic mobile manipulators, to execute multiple secondary tasks including tip-over prevention, singularity removal, obstacle avoidance and physical limits escape. An extended gradient projection method (EGPM) is proposed to determine self-motion directions, and a real-time fuzzy logic self-motion planner (FLSMP) is devised to generate the corresponding self-motion magnitudes. Unlike the task-priority allocation method and the extended Jacobian method, the proposed scheme is simple to implement and is free from algorithm singularities. The proposed dynamic model is established with consideration of nonholonomic constraints of the mobile platform, interactive motions between the mobile platform and the onboard manipulator, as well as self-motions allowed by redundancy of the entire robot. Furthermore, a robust adaptive neural-network controller (RANNC) is developed to accomplish multiple secondary tasks without affecting the primary one in the workspace. The RANNC does not rely on precise prior knowledge of dynamic parameters and can suppress bounded external disturbance effectively. In addition, the RANNC does not require any off-line training and can ensure the control performance by online adjusting the neural-network parameters through adaptation laws. The effectiveness of the proposed algorithm is verified via simulations on a three-wheeled redundant nonholonomic mobile manipulator.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-009-9323-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-009-9114-2,Clustering sensor data for autonomous terrain identification using time-dependency,Autonomous Robots,10.1007/s10514-009-9114-2,Springer,2009-04-01,"In this paper we are interested in autonomous vehicles that can automatically develop terrain classifiers without human interaction or feedback. A key issue is the clustering of time-series data collected by the sensors of a ground-based vehicle moving over several terrain surfaces (e.g. concrete or soil). In this context, we present a novel off-line windowless clustering algorithm that exploits time-dependency between samples. In terrain coverage, sets of sensory measurements are returned that are spatially, and hence temporally, correlated. Our algorithm works by finding a set of parameter values for a user-specified classifier that minimize a cost function. This cost function is related to the change in classifier probability estimates over time. The main advantage over other existing methods is its ability to cluster data for fast-switching systems that either have high process or observation noise, or complex distributions that cannot be properly characterized within the time interval that the system stays in a single state. The algorithm was evaluated using three different classifiers (linear separator, mixture of Gaussians and k -Nearest Neighbor), over both synthetic data sets and two different mobile robotic platforms, with success. Comparisons are provided against a window-based algorithm and against a hidden Markov model trained with Expectation-Maximization, with positive results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-009-9114-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-008-0604-7,Cooperative control of multiple neural networks for an indoor blimp robot,Artificial Life and Robotics,10.1007/s10015-008-0604-7,Springer,2009-03-01,"We report on the cooperative control of multiple neural networks for an indoor blimp robot. In our research group, the indoor blimp robot has been studied to achieve various flying robot applications. The objective of this article is to propose a robust controller that can adapt to mechanical accidents such as the breakdown of propellers. In our proposed method, each propeller thrust is independently calculated by a small neural network. We confirm the advantage of the proposed method against the control by a single large neural network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-008-0604-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00422-009-0295-8,Learning to reach by reinforcement learning using a receptive field based function approximation approach with continuous actions,Biological Cybernetics,10.1007/s00422-009-0295-8,Springer,2009-02-20,"Reinforcement learning methods can be used in robotics applications especially for specific target-oriented problems, for example the reward-based recalibration of goal directed actions. To this end still relatively large and continuous state-action spaces need to be efficiently handled. The goal of this paper is, thus, to develop a novel, rather simple method which uses reinforcement learning with function approximation in conjunction with different reward-strategies for solving such problems. For the testing of our method, we use a four degree-of-freedom reaching problem in 3D-space simulated by a two-joint robot arm system with two DOF each. Function approximation is based on 4D, overlapping kernels (receptive fields) and the state-action space contains about 10,000 of these. Different types of reward structures are being compared, for example, reward-on- touching-only against reward-on-approach. Furthermore, forbidden joint configurations are punished. A continuous action space is used. In spite of a rather large number of states and the continuous action space these reward/punishment strategies allow the system to find a good solution usually within about 20 trials. The efficiency of our method demonstrated in this test scenario suggests that it might be possible to use it on a real robot for problems where mixed rewards can be defined in situations where other types of learning might be difficult.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00422-009-0295-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11768-009-7130-6,Robust adaptive control for a nonholonomic mobile robot with unknown parameters,Journal of Control Theory and Applications,10.1007/s11768-009-7130-6,Springer,2009-02-01,"A robust adaptive controller for a nonholonomic mobile robot with unknown kinematic and dynamic parameters is proposed. A kinematic controller whose output is the input of the relevant dynamic controller is provided by using the concept of backstepping. An adaptive algorithm is developed in the kinematic controller to approximate the unknown kinematic parameters, and a simple single-layer neural network is used to express the highly nonlinear robot dynamics in terms of the known and unknown parameters. In order to attenuate the effects of the uncertainties and disturbances on tracking performance, a sliding mode control term is added to the dynamic controller. In the deterministic design of feedback controllers for the uncertain dynamic systems, upper bounds on the norm of the uncertainties are an important clue to guarantee the stability of the closed-loop system. However, sometimes these upper bounds may not be easily obtained because of the complexity of the structure of the uncertainties. Thereby, simple adaptation laws are proposed to approximate upper bounds on the norm of the uncertainties to address this problem. The stability of the proposed control system is shown through the Lyapunov method. Lastly, a design example for a mobile robot with two actuated wheels is provided and the feasibility of the controller is demonstrated by numerical simulations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11768-009-7130-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-10817-4_114,The Study on Optimal Gait for Five-Legged Robot with Reinforcement Learning,Intelligent Robotics and Applications,10.1007/978-3-642-10817-4_114,Springer,2009-01-01,"The research of legged robot was rapidly developed. It can be seen from recent ideas about new systems of robot movement that take ideas from nature, called biology inspired. This type of robot begins replacing wheeled robot with various functions and interesting maneuvers ability. However, designers should decide how many legs are required to realize the ideas. One of the ideas that are rarely developed is odd number of legs. This research focused on five legs robot that inspired from starfish. To realize the intelligent system in robot that does not depend on the model, this research used reinforcement learning algorithm to find the optimal gait when robot is walking. In order to achieve this goal, trial and error have been used to provide learning through an interaction between robot and environment based on a policy of reward and punishment. The algorithm is successfully implemented to get the optimal gait on a five-legged robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-10817-4_114,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-04070-2_54,Natural Language Human-Robot Interface Using Evolvable Fuzzy Neural Networks for Mobile Technology,Emerging Intelligent Computing Technology and Applications,10.1007/978-3-642-04070-2_54,Springer,2009-01-01,"In this paper, a human-robot speech interface for mobile technology is described which consists of intelligent mechanisms of human identification, speech recognition, word and command recognition, command meaning and effect analysis, command safety assessment, process supervision as well as human reaction assessment. A review of selected issues is carried out with regards to recognition and evaluation of speech commands in natural language using hybrid neural networks. The paper presents experimental results of automatic recognition and evaluation of spoken commands of a manufacturing robot model simulating the execution of laser processing tasks in a virtual production process.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-04070-2_54,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-01513-7_30,Reinforcement Learning Control of a Real Mobile Robot Using Approximate Policy Iteration,Advances in Neural Networks – ISNN 2009,10.1007/978-3-642-01513-7_30,Springer,2009-01-01,"Machine learning for mobile robots has attracted lots of research interests in recent years. However, there are still many challenges to apply learning techniques in real mobile robots, e.g., generalization in continuous spaces, learning efficiency and convergence, etc. In this paper, a reinforcement learning path-following control strategy based on approximate policy iteration (API) is developed for a real mobile robot. It has some advantages such as optimized control policies can be obtained without much a priori knowledge on dynamic models of mobile robot, etc. Two kinds of API-based control method, i.e., API with linear approximation and API with kernel machines, are implemented in the path following control task and the efficiency of the proposed control strategy is illustrated in the experimental studies on the real mobile robot based on the Pioneer3-AT platform. Experimental results verify that the API-based learning controller has better convergence and path following accuracy compared to conventional PD control methods. Finally, the learning control performance of the two API methods is also evaluated and compared.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-01513-7_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-03737-5_18,New Trends in Robotic Reinforcement Learning: Single and Multi-robot Case,Towards Intelligent Engineering and Information Technology,10.1007/978-3-642-03737-5_18,Springer,2009-01-01,"A rather general approach to learning control is the framework of Reinforcement Learning, described in this chapter. Reinforcement learning offers one of the most general framework to take traditional robotics towards true autonomy and versatility. Single robot reinforcement learning as well as Multi-robot reinforcement learning are a very challenging areas due to several issues, such as large state spaces, difficulty in reward assignment, nondeterministic action selections, and difficulty in merging learned experiences from other robots. There are still many difficulties in application iof robotics reinforcement learning and in scaling up the multi agent reinforcement learning to multi-robot systems. After reviewing important approaches in this field, some problems and promising research directions will be given.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-03737-5_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-01513-7_21,Q-Learning Based on Dynamical Structure Neural Network for Robot Navigation in Unknown Environment,Advances in Neural Networks – ISNN 2009,10.1007/978-3-642-01513-7_21,Springer,2009-01-01,"An automation learning and navigation strategy based on dynamical structure neural network and reinforcement learning was proposed in this paper. The neural network can adjust its structure according to the complexity of the working environment. New nodes or even new hidden-layers can be inserted or deleted during the training process. In such a way, the mapping relations between environment states and responding action were established, and the dimension explosion problem was solved at the same time. Simulation and Pioneer3-DX mobile robot navigation experiments were done to test the proposed algorithm. Results show that the robot can learn the correct action and finish the navigation task without people’s guidance, and the performance was better than artificial potential field method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-01513-7_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-05258-3_30,A Two-Stage Relational Reinforcement Learning with Continuous Actions for Real Service Robots,MICAI 2009: Advances in Artificial Intelligence,10.1007/978-3-642-05258-3_30,Springer,2009-01-01,"Reinforcement Learning is a commonly used technique in robotics, however, traditional algorithms are unable to handle large amounts of data coming from the robot’s sensors, require long training times, are unable to re-use learned policies on similar domains, and use discrete actions. This work introduces TS - RRLCA , a two stage method to tackle these problems. In the first stage, low-level data coming from the robot’s sensors is transformed into a more natural, relational representation based on rooms, walls, corners, doors and obstacles, significantly reducing the state space. We also use Behavioural Cloning, i.e., traces provided by the user to learn, in few iterations, a relational policy that can be re-used in different environments. In the second stage, we use Locally Weighted Regression to transform the initial policy into a continuous actions policy. We tested our approach with a real service robot on different environments for different navigation and following tasks. Results show how the policies can be used on different domains and perform smoother, faster and shorter paths than the original policies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-05258-3_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-02490-0_93,Brain-Inspired Emergence of Behaviors Based on the Desire for Existence by Reinforcement Learning,Advances in Neuro-Information Processing,10.1007/978-3-642-02490-0_93,Springer,2009-01-01,"To develop truly autonomous mobile robots, we proposed to introduce internal rewards such as the desire for existence, specific curiosity, diversive curiosity, boredom, and novelty into reinforcement learning. They are expected to make mobile robots capable of behaving appropriately without being told what to do. Firstly, we proposed to use multiple sources of rewards to endow mobile robots with ability to behave properly in the real world. Secondly, we proposed task-independent internal rewards. Thirdly, we proposed to attain engineering merit of internal rewards in addition to scientific interest. A pursuit-evasion game comprising a predator and its prey on a robotic field was selected as a testbed to demonstrate the effectiveness of internal rewards in reinforcement learning. The present paper focuses on learning of pursuit timing to maximize accumulated future rewards by Q-learning and SARSA.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-02490-0_93,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-89222-9_16,Designing Toys That Come Alive: Curious Robots for Creative Play,Entertainment Computing - ICEC 2008,10.1007/978-3-540-89222-9_16,Springer,2009-01-01,"Creative thinking requires imagination, creativity, play, sharing and reflection. This paper presents an architecture for a curious, reconfigurable robot that encourages creative design thinking by permitting designed structures to learn behaviours. These behaviours encourage designers to play with different structures, reflect on the relationship between structure and behaviour and imagine new structures. A demonstration of the architecture is described using the Lego Mindstorms platform. The demonstration shows how a curious robot can adapt new behaviours in response to changes in its structure, and how this can encourage the creative thinking spiral and creative design.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-89222-9_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-04772-5_54,Applying Reinforcement Learning to Multi-robot System Behavior Coordination,Computer Aided Systems Theory - EUROCAST 2009,10.1007/978-3-642-04772-5_54,Springer,2009-01-01,"We have applied ANLAGIS to a coordination problem Multi-robot Systems, specifically the storage of a set of elements is in the warehouses. We have combined ANLAGIS along with Reinforcement Learning for each of the behaviors that stem from this task, besides drawing up the coordination of these behaviors in order to perform the task in a satisfactory way.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-04772-5_54,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-02565-5_15,Anticipatory Driving for a Robot-Car Based on Supervised Learning,Anticipatory Behavior in Adaptive Learning Systems,10.1007/978-3-642-02565-5_15,Springer,2009-01-01,"Prediction and Planning are essential elements of successful human driving, making them equally important for autonomously driving systems. Many approaches achieve planning based on built-in world-knowledge. However, we show how a learning-based system can be extended to planning, needing little a priori knowledge. A car-like robot is trained by a human driver by constructing a database, where look ahead sensory information is stored together with action sequences . From that we achieve a novel form of velocity control, based only on information in image coordinates. For steering we employ a two-level approach in which database information is combined with an additional reactive controller. The result is a trajectory planning robot running at real-time, issuing steering and velocity control commands in a human manner.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-02565-5_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-01513-7_20,Tracking Control of Robot Manipulators via Orthogonal Polynomials Neural Network,Advances in Neural Networks – ISNN 2009,10.1007/978-3-642-01513-7_20,Springer,2009-01-01,"In this paper, an orthogonal functions neural network is used to achieve the control of nonlinear systems. The adaptive controller is constructed by using Chebyshev orthogonal polynomials neural network, which has advantages such as simple structure and fast convergence speed. The adaptive learning law of orthogonal neural network is derived to guarantee that the adaptive weight errors and tracking errors are bound by using Lyapunov stability theory. Simulation results are given for a two-link robot in the end of the paper, and the control scheme is validated.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-01513-7_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-90-481-2311-7_33,Developing Emotion-Based Pet Robots,Advances in Electrical Engineering and Computational Science,10.1007/978-90-481-2311-7_33,Springer,2009-01-01,"Designing robots for home entertainment has become an important application of intelligent autonomous robot. Yet, robot design takes considerable amount of time and the short life cycle of toy-type robots with fixed prototypes and repetitive behaviors is in fact disadvantageous. Therefore, it is important to develop a framework of robot configuration so that the user can always change the characteristics of his pet robot easily. In this paper, we present a user-oriented interactive framework to construct emotion-based pet robots. Experimental results show the efficiency of the proposed framework.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-90-481-2311-7_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-02481-8_79,Using Gaussian Processes in Bayesian Robot Programming,"Distributed Computing, Artificial Intelligence, Bioinformatics, Soft Computing, and Ambient Assisted Living",10.1007/978-3-642-02481-8_79,Springer,2009-01-01,"In this paper, we present an adaptation of Gaussian Processes for learning a joint probabilistic distribution using Bayesian Programming. More specifically, a robot navigation problem will be showed as a case of study. In addition, Gaussian Processes will be compared with one of the most popular techniques for machine learning: Neural Networks. Finally, we will discuss about the accuracy of these methods and will conclude proposing some future lines for this research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-02481-8_79,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-03885-3_13,Radial Pulse Type Changed by the Applied Pressure in Same Position,"World Congress on Medical Physics and Biomedical Engineering, September 7 - 12, 2009, Munich, Germany",10.1007/978-3-642-03885-3_13,Springer,2009-01-01,"It has been shown that the systolic augmentation index (AI) in the central arteries, including the aorta and carotid arteries, changes with age. The AI can also be obtained from the peripheral arteries. And recently some investigations prove that simple and easily-obtainable radial AI is also age-dependent and could be a useful index of vascular aging. A new method to measure pulse waveform by multi-step pressure applied on radial artery was developed by DAEYOMEDI Co., Ltd. This system borrowed a robot arm for applying precision pressure to take pulses stably and to find out a representative pulse waveform. Radial arterial waveforms were obtained from 45 subjects with no cardiovascular disease and from 56 subjects with hypertension by using radial tonometer (DMP-3000 (with five pressure steps). In this study, it was founded that radial pulse waveform types could be changed by the applied pressure and that the waveform types were different between healthy young people and hypertension patients.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-03885-3_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-03737-5_19,Points of View on Building an Intelligent Robot,Towards Intelligent Engineering and Information Technology,10.1007/978-3-642-03737-5_19,Springer,2009-01-01,"Aspects concerning the building of an intelligent robot are discussed. The intelligent robot belongs to a class of autonomous robots. The hardware and software architectures of the robot are analyzed. They are part of the new three level intelligent control system architecture. The mathematical model of the merged robot and trajectory tracking is derived in order to be used as controlled plant. The pole placement approach is applied in the design of the state feedback controller. Real-time experimental results done in trajectory tracking validate the architectures, models and design method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-03737-5_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-00264-9_11,Multiple Moving Obstacles Avoidance for Wheeled Type Robots Using Neural Network,Intelligent Unmanned Systems: Theory and Applications,10.1007/978-3-642-00264-9_11,Springer,2009-01-01,"Mobile robot path planning in a movement environment is an important problem. We studied acquisition of a path to a destination and multiple moving obstacles avoidance of a wheeled type robot. The paper proposes a method of path planning based on neural network and genetic algorithm. The avoidance action of a wheeled type robot is determined from the obstacle configuration, the robot’s self-state and destination information using a neural network. The design parameter of neural network is adjusted by using genetic algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-00264-9_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-04274-4_77,Unsupervised Learning in Reservoir Computing: Modeling Hippocampal Place Cells for Small Mobile Robots,Artificial Neural Networks – ICANN 2009,10.1007/978-3-642-04274-4_77,Springer,2009-01-01,"Biological systems (e.g., rats) have efficient and robust localization abilities provided by the so called, place cells, which are found in the hippocampus of rodents and primates (these cells encode locations of the animal’s environment). This work seeks to model these place cells by employing three (biologically plausible) techniques: Reservoir Computing (RC), Slow Feature Analysis (SFA), and Independent Component Analysis (ICA). The proposed architecture is composed of three layers, where the bottom layer is a dynamic reservoir of recurrent nodes with fixed weights. The upper layers (SFA and ICA) provides a self-organized formation of place cells, learned in an unsupervised way. Experiments show that a simulated mobile robot with 17 noisy short-range distance sensors is able to self-localize in its environment with the proposed architecture, forming a spatial representation which is dependent on the robot direction.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-04274-4_77,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-04020-7_107,Speech Emotion Recognition Research Based on Wavelet Neural Network for Robot Pet,Emerging Intelligent Computing Technology and Applications. With Aspects of Artificial Intelligence,10.1007/978-3-642-04020-7_107,Springer,2009-01-01,"In this paper, we present an emotion recognition system using wavelet neural network and BP neural network for special human affective state in the speech signal. 750 short emotional sentences with different contents from 5 speakers were collected as experiment materials. The features relevant with energy, speech rate, pitch and formant are extracted from speech signals. Neural network are used as the classifier for 5 emotions including anger, calmness, happiness, sadness and boredom. Compared with the traditional BP network, the results of experiments show that the wavelet neural network has faster convergence speed and higher recognition rate.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-04020-7_107,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-02490-0_94,A Neural Network Based Controller for an Outdoor Mobile Robot,Advances in Neuro-Information Processing,10.1007/978-3-642-02490-0_94,Springer,2009-01-01,"A wheeled mobile mechanism with a passive and/or active linkage mechanism for travel in rough terrain is developed and evaluated. In our previous research, we developed a switching controller system for wheeled mobile robots in outdoor environment. This system consists of two sub-systems: an environment recognition system using a self-organizing map and an adjusted control system using a neural network. In this paper, we propose a new controller design method based on a neural network. The proposed method involves three kinds of controllers: an elementary controller, adjusted controllers, and simplified controllers. In the experiments, our proposed method results in less oscillatory motion in outdoor environment and performs better than a well tuned PID controller does.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-02490-0_94,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4020-8919-0_17,Behavior Emergence in Autonomous Robot Control by Means of Evolutionary Neural Networks,Advances in Computational Algorithms and Data Analysis,10.1007/978-1-4020-8919-0_17,Springer,2009-01-01,"We study the emergence of intelligent behavior of a simple mobile robot. Robot control system is realized by mechanisms based on neural networks and evolutionary algorithms. The evolutionary algorithm is responsible for the adaptation of a neural network parameters based on the robot's performance in a simulated environment. In experiments, we demonstrate the performance of evolutionary algorithm on selected problems, namely maze exploration and discrimination of walls and cylinders. A comparison of different networks architectures is presented and discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4020-8919-0_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-04772-5_57,Cooperative and Competitive Behaviors in a Multi-robot System for Surveillance Tasks,Computer Aided Systems Theory - EUROCAST 2009,10.1007/978-3-642-04772-5_57,Springer,2009-01-01,"In this paper we present a control architecture for multi-robot systems in dynamic environments, where the low level behaviors are obtained through artificial neural networks and evolutionary algorithms to achieve collaborative behaviors in a multi-robot system. As an example, we have cooperative tasks establishing a surveillance scenario stressing cooperation and competition between them.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-04772-5_57,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-02921-9_55,Robust Moving Object Detection from a Moving Video Camera Using Neural Network and Kalman Filter,RoboCup 2008: Robot Soccer World Cup XII,10.1007/978-3-642-02921-9_55,Springer,2009-01-01,"Detecting motion of objects in images, while the camera is moving, is a complicated task. In this paper, we propose a novel method to effectively solve this problem by using Neural Network and Kalman Filter. This technique uses parameters of camera motion to overcome problems caused by error in the image processing outputs. We have implemented this technique in the MRL Middle Size Soccer Robots. The experimental results show a low error rate of 2.2% which suggests that the combined approach performs significantly better than the traditional techniques.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-02921-9_55,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4020-6710-5_13,The Anatomy of A.L.I.C.E.,Parsing the Turing Test,10.1007/978-1-4020-6710-5_13,Springer,2009-01-01,"This paper is a technical presentation of Artificial Linguistic Internet Computer Entity (A.L.I.C.E.) and Artificial Intelligence Markup Language (AIML), set in context by historical and philosophical ruminations on human consciousness. A.L.I.C.E., the first AIML-based personality program, won the Loebner Prize as “the most human computer” at the annual Turing Test contests in 2000, 2001, and 2004. The program, and the organization that develops it, is a product of the world of free software. More than 500 volunteers from around the world have contributed to her development. This paper describes the history of A.L.I.C.E. and AIML-free software since 1995, noting that the theme and strategy of deception and pretense upon which AIML is based can be traced through the history of Artificial Intelligence research. This paper goes on to show how to use AIML to create robot personalities like A.L.I.C.E. that pretend to be intelligent and selfaware. The paper winds up with a survey of some of the philosophical literature on the question of consciousness. We consider Searle’s Chinese Room, and the view that natural language understanding by a computer is impossible. We note that the proposition “consciousness is an illusion” may be undermined by the paradoxes it apparently implies. We conclude that A.L.I.C.E. does pass the Turing Test, at least, to paraphrase Abraham Lincoln, for some of the people some of the time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4020-6710-5_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-00616-6_13,Co-evolution of Rewards and Meta-parameters in Embodied Evolution,Creating Brain-Like Intelligence,10.1007/978-3-642-00616-6_13,Springer,2009-01-01,"Embodied evolution is a methodology for evolutionary robotics that mimics the distributed, asynchronous, and autonomous properties of biological evolution. The evaluation, selection, and reproduction are carried out by cooperation and competition of the robots, without any need for human intervention. An embodied evolution framework is therefore well suited to study the adaptive learning mechanisms for artificial agents that share the same fundamental constraints as biological agents: self-preservation and self-reproduction. In this paper we propose a framework for performing embodied evolution with a limited number of robots, by utilizing time-sharing in subpopulations of virtual agents. Within this framework, we explore the combination of within-generation learning of basic survival behaviors by reinforcement learning, and evolutionary adaptations over the generations of the basic behavior selection policy, the reward functions, and meta-parameters for reinforcement learning. We apply a biologically inspired selection scheme, in which there is no explicit communication of the individuals’ fitness information. The individuals can only reproduce offspring by mating, a pair-wise exchange of genotypes, and the probability that an individual reproduces offspring in its own subpopulation is dependent on the individual’s “health”, i.e., energy level, at the mating occasion. We validate the proposed method by comparing the proposed method with evolution using standard centralized selection, in simulation, and by transferring the obtained solutions to hardware using two real robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-00616-6_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-00616-6_1,Creating Brain-Like Intelligence,Creating Brain-Like Intelligence,10.1007/978-3-642-00616-6_1,Springer,2009-01-01,"In this chapter, we discuss the new research field brain-like intelligence and introduce and relate the contributions to this volume to each other.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-00616-6_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-00609-8_7,Learning Communicative Meanings of Utterances by Robots,New Frontiers in Artificial Intelligence,10.1007/978-3-642-00609-8_7,Springer,2009-01-01,"This paper describes a computational mechanism that enables a robot to return suitable utterances to a human or perform actions by learning the meanings of interrogative words, such as “what” and “which.” Previous studies of language acquisition by robots have proposed methods to learn words, such as “box” and “blue,” that indicate objects or events in the world. However, the robots could not learn and understand interrogative words by those methods because the words do not directly indicate objects or events. The meanings of those words are grounded in communication and stimulate specific responses by a listener. These are called communicative meanings. Our proposed method learns the relationship between human utterances and robot responses that have communicative meanings on the basis of a graphical model of the human-robot interaction.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-00609-8_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-01510-6_123,Study of Iterative Learning Control Algorithm Based on Neural Network,Advances in Neural Networks – ISNN 2009,10.1007/978-3-642-01510-6_123,Springer,2009-01-01,"Aiming at a kind of nonlinear systems part of which is either uncertain or with interference, a neural network iterative learning control algorithm based on feedback is proposed. It combines iterative learning control and feedback control, the latter made the system follow the track of expected trace in the direction of time axis, and the former made the system follow the expected trace in the direction of iterative axis.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-01510-6_123,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-02481-8_187,Control of Mobile Robot Considering Actuator Dynamics with Uncertainties in the Kinematic and Dynamic Models,"Distributed Computing, Artificial Intelligence, Bioinformatics, Soft Computing, and Ambient Assisted Living",10.1007/978-3-642-02481-8_187,Springer,2009-01-01,"In this paper, a trajectory tracking control for a nonholonomic mobile robot by the integration of a neural kinematic controller (NKC) and neural dynamic controller (NDC) is investigated, where the wheel actuator (e.g., dc motor) dynamics is integrated with mobile robot dynamics and kinematics so that the actuator input voltages are the control inputs, as well as both the kinematic and dynamic models contains parametric and/or nonparametric uncertainties. The proposed neural controller (PNC) is constituted of the NKC and the NDC, and were designed by use of a modelling technique of Gaussian radial basis function neural networks (RBFNNs). The NKC is applied to compensate the uncertainties in the kinematic parameters of the mobile robot. The NDC, based on the sliding mode theory, is applied to compensate the mobile robot dynamics, and parametric and/or nonparametric uncertainties. Also, the PNC are not dependent of the mobile robot kinematics and dynamics neither require the off-line training process. Stability analysis with basis on Lyapunov theory and numerical simulation is provided to show the effectiveness of the PNC.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-02481-8_187,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-02490-0_129,An Improved Modular Neural Network Model for Adaptive Trajectory Tracking Control of Robot Manipulators,Advances in Neuro-Information Processing,10.1007/978-3-642-02490-0_129,Springer,2009-01-01,"A novel approach is presented for adaptive trajectory tracking of robot manipulators using a three-stage hierarchical neural network model involving Support Vector Machines (SVM) and an adaptive unsupervised Neural Network. It involves a novel adaptive Self Organizing feature map (SOFM) in the first stage which aims at clustering the input variable space into smaller sub-spaces representative of the input space probability distribution and preserving its original topology, while rapidly increasing, on the other hand, cluster distances. Moreover, its codebook vector adaptation rule involves m-winning neurons dynamics and not the winner takes all approach. During convergence phase of the map a group of Support Vector Machines, associated with its codebook vectors, is simultaneously trained in an online fashion so that each SVM learns to positively respond when the input data belong to the topological sub-space represented by its corresponding codebook vector, taking into account similarity with that codebook vector. Moreover, it learns to negatively respond to input data not belonging to such a previously mentioned corresponding topological sub-space. The proposed methodology is applied, with promising results, to the design of a neural-adaptive trajectory tracking controller, by involving the computer-torque approach, which combines the proposed three-stage neural network model with a classical servo PD feedback controller. The results achieved by the suggested hierarchical SVM approach are favorably compared to the ones obtained by traditional (PD) and non-hierarchical neural network based controllers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-02490-0_129,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-03737-5_35,A Service-Orientated Arhitecture for Holonic Manufacturing Control,Towards Intelligent Engineering and Information Technology,10.1007/978-3-642-03737-5_35,Springer,2009-01-01,"The paper describes a solution and implementing framework for the management of changes which may occur in a holonic manufacturing system. This solution is part of the semi-heterarchical control architecture developed for agile job shop assembly with intelligent robots-vision workstations. Two categories of changes in the manufacturing system are considered: (i) changes occurring in resource status at process level: breakdown, failure of (vision-based) in-line inspection operation, and depletion of local robot storages; (ii) changes in production orders at business (ERP) level: rush orders. All these situations trigger production plan update and rescheduling (they redefine the list of Order Holons) by pipelining CNP-type resource bidding at shop-floor horizon with global product scheduling at aggregate batch horizon. Failure- and recovery management are developed as generic scenarios embedding the CNP mechanism into production selfrescheduling. Implementing solutions and experimental results are reported for a 6-station robot-vision assembly cell with twin-track closed-loop pallet transportation system, Cartesian pallet feeding station, dual assembly component feeder with robot-vision tending and product tracking RD/WR devices. Future developments will consider manufacturing integration at enterprise level.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-03737-5_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-03969-0_18,Combining GRN Modeling and Demonstration-Based Programming for Robot Control,Engineering Applications of Neural Networks,10.1007/978-3-642-03969-0_18,Springer,2009-01-01,"Gene regulatory networks dynamically orchestrate the level of expression for each gene in the genome. With such unique characteristics, they can be modeled as reliable and robust control mechanisms for robots. In this work we devise a recurrent neural network-based GRN model to control robots. To simulate the regulatory effects and make our model inferable from time-series data, we develop an enhanced learning algorithm, coupled with some heuristic techniques of data processing for performance improvement. We also establish a method of programming by demonstration to collect behavior sequence data of the robot as the expression profiles, and then employ our framework to infer controllers automatically. To verify the proposed approach, experiments have been conducted and the results show that our regulatory model can be inferred for robot control successfully.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-03969-0_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-88464-4_7,Complex Systems and Perception,Spatial Temporal Patterns for Action-Oriented Perception in Roving Robots,10.1007/978-3-540-88464-4_7,Springer,2009-01-01,"This Chapter concludes Part II of the present Volume. Here the hypothesis of an internal model arises is needed at the aim to generate internal representations which enable the robot to reach a suitable behavior so as to optimize ideally arbitrary motivational needs. Strongly based on the idea, common to Behavior-based robotics, that perception is a holistic process, strongly connected to behavioral needs of the robot, here we present a bio-inspired framework for sensing-perception-action, based on complex self-organizing dynamics. These are able to generate internal models of the environment, strictly depending both on the environment and on the robot motivation. The strategy, as a starting simple task, is applied to a roving robot in a random foraging task. Perception is here considered as a complex and emergent phenomenon where a huge amount of information coming from sensors is used to form an abstract and concise representation of the environment, useful to take a suitable action or sequence of actions. In this chapter a model for perceptual representation is formalized by means of Reaction-Diffusion Cellular Nonlinear Networks (RD-CNNs) used to generate self-organising Turing patterns . They are thought as attractive states for particular set of environmental conditions in order to associate, via a reinforcement learning, a proper action. Learning is also introduced at the afferent stage to shape the environment information according to the particular emerging pattern. The basins of attraction for the Turing patterns are so dynamically tuned by an unsupervised learning in order to form an internal, abstract and plastic representation of the environment, as recorded by the sensors. In the second part of the Chapter, the representation layer together with the other blocks already introduced in the previous Chapters (i.e. basic behaviours, correlation layer, memory blocks, and others), has been structured in an unique framework, the SPARK cognitive model. The role assigned to the representation layer inside this complete architecture consists in modulating the influence of each basic behaviour with respect to the final behaviour performed by the robot to fulfill the assigned mission.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-88464-4_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-90-481-2311-7_35,Reorganising Artificial Neural Network Topologies,Advances in Electrical Engineering and Computational Science,10.1007/978-90-481-2311-7_35,Springer,2009-01-01,"This chapter describes a novel way of complexifying artificial neural networks through topological reorganisation. The neural networks are reorganised to optimise their neural complexity, which is a measure of the information-theoretic complexity of the network. Complexification of neural networks here happens through rearranging connections, i.e. removing one or more connections and placing them elsewhere. The results verify that a structural reorganisation can help to increase the probability of discovering a neural network capable of adequately solving complex tasks. The networks and the methodology proposed are tested in a simulation of a mobile robot racing around a track.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-90-481-2311-7_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-04391-8_17,Modeling Gait Using CPG (Central Pattern Generator) and Neural Network,Biometric ID Management and Multimodal Communication,10.1007/978-3-642-04391-8_17,Springer,2009-01-01,"In this study, we utilize CPG (Central Pattern Generator) concept in modeling a bipedal gait. For simplicity, only lower extremity body of a biped is considered and modeled. Actually, gait is a result of a locomotor which is inherent in our bodies. In other words, the locomotor applies appropriate torques to joints to move our bodies and generate gait cycles. Consequently, to overcome the gait modeling problem, we should know structure of locomotor and how it works. Actually, each locomotor mainly consists of two parts: path planning and controlling parts. Task of path planning part is to generate appropriate trajectories of joint angles in order to walk properly. We use CPG to generate these proper trajectories. Our CPG is a combination of several oscillators because of the fact that gait is a periodic or semi-periodic movement and it can be represented as sinusoidal oscillators using Fourier transform. Second part is to design a controller for tracking above-mentioned trajectories. We utilize Neural Networks (NNs) as controllers which can learn inverse model of the biped. In comparison with traditional PDs, NNs have some benefits such as: nonlinearity and adjusting weights is so much faster, easier and fully automatically. Lastly, to do this, someone is asked to walk on a treadmill. Trajectories are recorded and collected by six cameras and CPG can then be computed by Fourier transform. Next, Neural Networks will be trained in order to use as controllers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-04391-8_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-03156-4_10,Learning RNN-Based Gene Regulatory Networks for Robot Control,Advances in Computational Intelligence,10.1007/978-3-642-03156-4_10,Springer,2009-01-01,"With the unique characteristic of orchestrating gene expression level in cellular metabolism during the development of living organisms, gene regulatory networks can be modeled as reliable and robust control mechanisms for robots. In this work we devise a recurrent neural network-based GRN model to control robots. To simulate the regulatory effects and make our model inferable from time-series data, we develop an enhanced learning algorithm, coupled with some heuristic techniques of data processing for performance improvement. We also establish a method of programming by demonstration to collect behavior sequence data of the robot as the expression profiles, and then employ our framework to infer controllers automatically. To verify the proposed approach, experiments have been conducted and the results show that our regulatory model can be inferred for robot control successfully.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-03156-4_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-89933-4_17,Advancing Artificial Intelligence through Minimalist Humanoid Robotics,Design and Control of Intelligent Robotic Systems,10.1007/978-3-540-89933-4_17,Springer,2009-01-01,"While the robots that most quickly come to mind to the general public are those with the most elaborate features and movements, those that are most useful in advancing the state of the art in artificial intelligence (AI) are very different. Minimalist robots are inexpensive and therefore more broadly available for research and educational purposes, but also force the researcher to rely on good, adaptable solutions to hard AI problems rather than relying on expensive specialized hardware that will only work under strict conditions. This chapter describes our work in minimalist humanoid robots, focussing mainly on Tao-Pie-Pie, a robot that competed successfully in numerous RoboCup and FIRA competitions. The chapter describes our motivations in designing minimalist robots and our rationale for working with humanoid robots, and describes the development of Tao-Pie-Pie, including contrasting this robot with other work and developing its walking gait and balancing reflexes. We then describe some issues in evaluating humanoid robots, and describe ongoing work.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-89933-4_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-02490-0_123,Using Spiking Neural Networks for the Generation of Coordinated Action Sequences in Robots,Advances in Neuro-Information Processing,10.1007/978-3-642-02490-0_123,Springer,2009-01-01,"SNNs have been tested as possible candidates for the implementation of robot controllers, in particular behaviour based controllers, but in most approaches their real power, related to their inherent temporal processing, and, especially, temporal pattern generating capabilities, have been ignored. This paper is concerned with showing how SNNs in their most dynamic form can be easily evolved to provide the adaptable or sensor and context modulated pattern generating capabilities required for the generation of action sequences in robots. In fact, the objective is to have a structure that can provide a sequence of actions or a periodic pattern that extends in time from a very time limited sensorial cue.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-02490-0_123,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-04277-5_80,Robospike Sensory Processing for a Mobile Robot Using Spiking Neural Networks,Artificial Neural Networks – ICANN 2009,10.1007/978-3-642-04277-5_80,Springer,2009-01-01,"Current research in intelligent systems investigates their deployment in dynamic and complex environments. Such systems require the capability to be aware of their operating environment and to process effectively sensory information from multiple sensory sources. The abilities observed in the animal kingdom to process sensory information in varying conditions, from many different sensory sources, is an inspiration for intelligent systems research. Sensory processing in the mammalian brain involves thousands of neurons in cortical columns, with extensive interconnect. However it is known that interconnections between neurons and thus the source of spiking activity within these biological columns is locally based. Cortical columns are also stimulated by connections from related areas within the brain which are dedicated to the processing of alternative sensory stimuli. This paper reports on an approach to emulate biological sensory fusion, based on Spiking Neural Networks (SNN) and Liquid State Machines (LSM), and is assessed in experiments involving the control of a mobile robot in a reactive manner. The results show that the sensory processing provided by the Liquid State Machine enables the reactive control of the robot within its environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-04277-5_80,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-01513-7_28,Hybrid Filter Based Simultaneous Localization and Mapping for a Mobile Robot,Advances in Neural Networks – ISNN 2009,10.1007/978-3-642-01513-7_28,Springer,2009-01-01,"We propose a hybrid filter based SLAM (Simultaneous Localization and Mapping) for a mobile robot to compensate for the EKF (Extended Kalman Filter) based SLAM error inherently caused by the linearization process. A mobile robot autonomously explores the environment by interpreting the scene, building an appropriate map, and localizing itself relative to this map. A probabilistic approach has dominated the solution to the SLAM problem. This solution is a fundamental requirement for robot navigation. The EKF algorithm with a RBF (Radial Basis Function) has some advantages in handling a robotic system having nonlinear dynamics because of the learning property of neural networks. We modified an already developed Matlab simulation source for the hybrid filter-SLAM for simulation and comparison. The simulation results showed the effectiveness of the proposed algorithms as compared with an EKF-based SLAM.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-01513-7_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-03070-3_46,Learning with a Quadruped Chopstick Robot,Machine Learning and Data Mining in Pattern Recognition,10.1007/978-3-642-03070-3_46,Springer,2009-01-01,"Organisms exhibit a close structure-function relationship and a slight change in structure may in turn change their outputs accordingly [1]. This feature is important as it is the main reason why organisms have better malleability than computers in dealing with environmental changes. A quadruped chopstick robot controlled by a biologically-motivated neuromolecular model, named Miky, has been developed. Miky’s skeleton and its four feet were comprised of 16 deposable chopsticks, with each foot being controlled by an actuator (motor). The neuromolecular model is a multilevel neural network which captures the biological structure-function relationship and serves to transform signals sent from its sensors into a sequence of signals in space and time for controlling Miky’s feet (through actuators). The task is to teach Miky to walk, jump, pace, gallop, or make a turn. Our experimental result shows that Miky exhibits a close structure-function relationship that allows it to learn to accomplish these tasks in a continuous manner.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-03070-3_46,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-02490-0_15,Hybrid Design Principles and Time Constants in the Construction of Brain-Based Robotics: A Real-Time Simulator of Oscillatory Neural Networks Interacting with the Real Environment via Robotic Devices,Advances in Neuro-Information Processing,10.1007/978-3-642-02490-0_15,Springer,2009-01-01,"One of most important concepts in robotics and artificial intelligence is the embodied approach, focusing on the importance of having a body that functionally connects to the external world. This setup suggests that the intelligence develops through sensorimotor skills and through situations that would actually be confronted in the environment. We support this concept and propose to further extend it to embodiment in the time domain. Nervous systems have variable processing times. The different time courses proceed in the nervous system in parallel, and individual circuits independently and cooperatively work under the constraints of temporal properties. We here propose an experimental platform of oscillatory neural networks having real-time communication with the environment through the robot’s body. The synchronization mechanism of oscillations in neural activities have the advantage of synthetic controls known in motor coordination, but we extend this to circuits for cognitive functions like episodic memory formation and decision making of the robotic behavior by using the theta phase coding mechanism. A slow oscillation, like the theta rhythm, enables behavioral temporal sequences to be compressed in sequential firings during each oscillation cycle, and this helps to represent cognitive information in episodes composed of past-present-future structures. The temporal structure is crucial for recognition of the current context and adaptability in dynamic environments, and it smoothly controls sensorimotor local circuits with faster time scales. This work represents a tiny step towards constructing the brain by focusing on the temporal structure, yet this approach may elucidate the new nature of the brain-based intelligence.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-02490-0_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-008-9098-3,The sensory ego-sphere: a mediating interface between sensors and cognition,Autonomous Robots,10.1007/s10514-008-9098-3,Springer,2008-12-04,"The Sensory Ego-Sphere (SES) is an interface for a robot that serves to mediate information between sensors and cognition. The SES can be visualized as a sphere centered on the coordinate frame of the robot, spatially indexed by polar and azimuthal angles. Internally, the SES is a graph with a fixed number of edges that partitions surrounding space and contains localized sensor information from the robot. This paper describes the SES and gives the results of implementing the SES on multiple robots, both humanoid and mobile, to support essential functions such as a localized short-term memory, spatio-temporal sensory-motor event detection, attentional processing, data sharing, and ego-centric navigation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-008-9098-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-008-9241-6,A Multi-functional Entertaining and Educational Robot,Journal of Intelligent and Robotic Systems,10.1007/s10846-008-9241-6,Springer,2008-12-01,"This paper presents a multi-functional autonomous intelligent robot, DOC-1, which has actions exclusively driven by artificial intelligence programs. The mechanism of this robot was designed to fulfill tasks defined by various functions such as gripping character cubes and teacups, playing the Gobang board game, and rotating and stacking character cubes. Further emphasis was placed on load lifting capability, weight reduction, energy conservation, and performance reliability. The serial port of a minicomputer is used as the communication interface between the software and electromechanical components. A custom-made chip serves as the control kernel that controls the motions of servo motors that move the arms and head of the robot, two DC motors which drive the wheels, and also a number of lights. With the integrated artificial intelligence software and the robot control system, this intelligent robot DOC-1 can perform a number of autonomous functions that make it interactive with human beings.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-008-9241-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11741-008-0515-1,Adaptive proportional integral differential control based on radial basis function neural network identification of a two-degree-of-freedom closed-chain robot,Journal of Shanghai University (English Edition),10.1007/s11741-008-0515-1,Springer,2008-10-01,"A closed-chain robot has several advantages over an open-chain robot, such as high mechanical rigidity, high payload, high precision. Accurate trajectory control of a robot is essential in practical use. This paper presents an adaptive proportional integral differential (PID) control algorithm based on radial basis function (RBF) neural network for trajectory tracking of a two-degree-of-freedom (2-DOF) closed-chain robot. In this scheme, an RBF neural network is used to approximate the unknown nonlinear dynamics of the robot, at the same time, the PID parameters can be adjusted online and the high precision can be obtained. Simulation results show that the control algorithm accurately tracks a 2-DOF closed-chain robot trajectories. The results also indicate that the system robustness and tracking performance are superior to the classic PID method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11741-008-0515-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12065-008-0015-7,"MENNAG: a modular, regular and hierarchical encoding for neural-networks based on attribute grammars",Evolutionary Intelligence,10.1007/s12065-008-0015-7,Springer,2008-10-01,"Recent work in the evolutionary computation field suggests that the implementation of the principles of modularity (functional localization of functions), repetition (multiple use of the same sub-structure) and hierarchy (recursive composition of sub-structures) could improve the evolvability of complex systems. The generation of neural networks through evolutionary algorithms should in particular benefit from an adapted use of these notions. We have consequently developed modular encoding for neural networks based on attribute grammars (MENNAG), a new encoding designed to generate the structure of neural networks and parameters with evolutionary algorithms, while explicitly enabling these three above-mentioned principles. We expressed this encoding in the formalism of attribute grammars in order to facilitate understanding and future modifications. It has been tested on two preliminary benchmark problems: cart-pole control and robotic arm control, the latter being specifically designed to evaluate the repetition capabilities of an encoding. We compared MENNAG to a direct encoding, ModNet, NEAT, a multi-layer perceptron with a fixed structure and to reference controllers. Results show that MENNAG performs better than comparable encodings on both problems, suggesting a promising potential for future applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12065-008-0015-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-008-9283-9,A Neuro-Sliding Mode Control Scheme for Constrained Robots with Uncertain Jacobian,Journal of Intelligent and Robotic Systems,10.1007/s10846-008-9283-9,Springer,2008-09-21,"The joint robot control requires to map desired cartesian tasks into desired joint trajectories, by using the ill-posed inverse kinematics mapping. In order to avoid inverse kinematics, the control problem is formulated directly in task space to gives rise to cartesian robot control. In addition, when the robot is constrained due to its kinematic mappings yields a stiff system and an additional complexity arises to implement cartesian control for constrained robots. In this paper, an alternative approach is proposed to guarantee global convergence of force and position cartesian tracking errors under the assumption that the jacobian is not exactly known. A neuro-sliding mode controller is presented, where a small size adaptive neural network compensates approximately for the inverse dynamics and an inner control loop induces second order sliding modes to guarantee tracking. The sliding mode variable tunes the online adaptation of the weights. A passivity analysis yields the energy Lyapunov function to prove boundedness of all closed-loop signals and variable structure control theory is used to finally conclude convergence of position and force tracking errors. Experimental results are provided to visualize the expected performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-008-9283-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10483-008-0903-z,Adaptive neural network control for coordinated motion of a dual-arm space robot system with uncertain parameters,Applied Mathematics and Mechanics,10.1007/s10483-008-0903-z,Springer,2008-09-01,"Control of coordinated motion between the base attitude and the arm joints of a free-floating dual-arm space robot with uncertain parameters is discussed. By combining the relation of system linear momentum conversation with the Lagrangian approach, the dynamic equation of a robot is established. Based on the above results, the free-floating dual-arm space robot system is modeled with RBF neural networks, the GL matrix and its product operator. With all uncertain inertial system parameters, an adaptive RBF neural network control scheme is developed for coordinated motion between the base attitude and the arm joints. The proposed scheme does not need linear parameterization of the dynamic equation of the system and any accurate prior-knowledge of the actual inertial parameters. Also it does not need to train the neural network offline so that it would present real-time and online applications. A planar free-floating dual-arm space robot is simulated to show feasibility of the proposed scheme.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10483-008-0903-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00422-008-0249-6,Application of chaotic dynamics in a recurrent neural network to control: hardware implementation into a novel autonomous roving robot,Biological Cybernetics,10.1007/s00422-008-0249-6,Springer,2008-09-01,"Originating from a viewpoint that complex/chaotic dynamics would play an important role in biological system including brains, chaotic dynamics introduced in a recurrent neural network was applied to control. The results of computer experiment was successfully implemented into a novel autonomous roving robot, which can only catch rough target information with uncertainty by a few sensors. It was employed to solve practical two-dimensional mazes using adaptive neural dynamics generated by the recurrent neural network in which four prototype simple motions are embedded. Adaptive switching of a system parameter in the neural network results in stationary motion or chaotic motion depending on dynamical situations. The results of hardware implementation and practical experiment using it show that, in given two-dimensional mazes, the robot can successfully avoid obstacles and reach the target. Therefore, we believe that chaotic dynamics has novel potential capability in controlling, and could be utilized to practical engineering application.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00422-008-0249-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11771-008-0104-x,Solution to reinforcement learning problems with artificial potential field,Journal of Central South University of Technology,10.1007/s11771-008-0104-x,Springer,2008-08-01,"A novel method was designed to solve reinforcement learning problems with artificial potential field. Firstly a reinforcement learning problem was transferred to a path planning problem by using artificial potential field(APF), which was a very appropriate method to model a reinforcement learning problem. Secondly, a new APF algorithm was proposed to overcome the local minimum problem in the potential field methods with a virtual water-flow concept. The performance of this new method was tested by a gridworld problem named as key and door maze. The experimental results show that within 45 trials, good and deterministic policies are found in almost all simulations. In comparison with WIERING’s HQ-learning system which needs 20 000 trials for stable solution, the proposed new method can obtain optimal and stable policy far more quickly than HQ-learning. Therefore, the new method is simple and effective to give an optimal solution to the reinforcement learning problem.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11771-008-0104-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-008-0181-7,"Neural networks for control, robotics and diagnostics",Neural Computing and Applications,10.1007/s00521-008-0181-7,Springer,2008-08-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-008-0181-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-008-0131-1,Neural networks-based adaptive bidding with the contract net protocol in multi-robot systems,Applied Intelligence,10.1007/s10489-008-0131-1,Springer,2008-07-03,"This paper investigates the effectiveness of using the Contract Net Protocol, an auction type system, for controlling task allocation among a group of robots, and presents and evaluates a strategy of using Artificial Neural Networks to formulate adaptive bids within the framework of the Contract Net Protocol. The robots were used in a foraging environment and showed that excellent communication among robots leads to a need for a social control mechanism for managing the robots, such as the Contract Net Protocol. The experiments also confirmed that a moderate benefit can be gained by using adaptive bidding within the framework of the Contract Net Protocol.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-008-0131-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.3103/S1068371208070122,Formation of trajectory of industrial robot based on artificial neural network,Russian Electrical Engineering,10.3103/S1068371208070122,Springer,2008-07-01,The application of the neural network approach to solving the problem of optimizing the trajectory of industrial robots with respect to minimum energy consumption and maximum performance is considered. The results of an investigation of the proposed approach for industrial robots are presented.,http://link.springer.com/openurl/fulltext?id=doi:10.3103/S1068371208070122,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-007-0245-0,Fuzzy neural networks for obstacle pattern recognition and collision avoidance of fish robots,Soft Computing,10.1007/s00500-007-0245-0,Springer,2008-05-01,The problems of detection and pattern recognition of obstacles are the most important concerns for fish robots’ path planning to make natural and smooth movements as well as to avoid collision. We can get better control results of fish robot trajectories if we obtain more information in detail about obstacle shapes. The method employing only simple distance measuring IR sensors without cameras and image processing is proposed. The capability of a fish robot to recognize the features of an obstacle to avoid collision is improved using neuro-fuzzy inferences. Approaching angles of the fish robot to an obstacle as well as the evident features such as obstacles’ sizes and shape angles are obtained through neural network training algorithms based on the scanned data. Experimental results show the successful path control of the fish robot without hitting on obstacles.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-007-0245-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11071-007-9272-8,A proposed hybrid neural network for position control of a walking robot,Nonlinear Dynamics,10.1007/s11071-007-9272-8,Springer,2008-05-01,"The use of a proposed recurrent neural network control system to control a four-legged walking robot is presented in this paper. The control system consists of a neural controller, a standard PD controller, and the walking robot. The robot is a planar four-legged walking robot. The proposed Neural Network (NN) is employed as an inverse controller of the robot. The NN has three layers, which are input, hybrid hidden and output layers. In addition to feedforward connections from the input layer to the hidden layer and from the hidden layer to the output layer, there is also a feedback connection from the output layer to the hidden layer and from the hidden layer to itself. The reason to use a hybrid layer is that the robot’s dynamics consists of linear and nonlinear parts. The results show that the neural-network controller can efficiently control the prescribed positions of the stance and swing legs during the double stance phase of the gait cycle after sufficient training periods. The goal of the use of this proposed neural network is to increase the robustness of the control of the dynamic walking gait of this robot in the case of external disturbances. Also, the PD controller alone and Computed Torque Method (CTM) control system are used to control the walking robot’s position for comparison.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11071-007-9272-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11768-008-6058-6,Robust chattering-free sliding mode control of space robot in task space,Journal of Control Theory and Applications,10.1007/s11768-008-6058-6,Springer,2008-05-01,"This paper studies the tracking control problem of a free-floating space robot in a task space. Considering the model uncertainties and external disturbance, a robust sliding mode controller is proposed using the Lyapunov direct method and dissipative theory. To eliminate the chattering phenomenon, an radial basis function (RBF) neural network is applied to replace the discontinuous part of the control signal. A novel on-line learning method of the weights and parameters of the RBF neural network established using Lyapunov function assures the stability of the system. It is proved that the proposed controller can guarantee that the L _2 gain from disturbance to tracking error is lower than the given index γ. Simulation results show that the control method is valid.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11768-008-6058-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10472-008-9105-6,"Editorial: Annals of Mathematics and Artificial Intelligence special issue on multi-robot coverage, search, and exploration",Annals of Mathematics and Artificial Intelligence,10.1007/s10472-008-9105-6,Springer,2008-04-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10472-008-9105-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10732-007-9031-5,Accelerating autonomous learning by using heuristic selection of actions,Journal of Heuristics,10.1007/s10732-007-9031-5,Springer,2008-04-01,"This paper investigates how to make improved action selection for online policy learning in robotic scenarios using reinforcement learning (RL) algorithms. Since finding control policies using any RL algorithm can be very time consuming, we propose to combine RL algorithms with heuristic functions for selecting promising actions during the learning process. With this aim, we investigate the use of heuristics for increasing the rate of convergence of RL algorithms and contribute with a new learning algorithm, Heuristically Accelerated Q-learning (HAQL), which incorporates heuristics for action selection to the Q-Learning algorithm. Experimental results on robot navigation show that the use of even very simple heuristic functions results in significant performance enhancement of the learning rate.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10732-007-9031-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-007-0453-9,Adaptive control of a looper-like robot based on the CPG-actor-critic method,Artificial Life and Robotics,10.1007/s10015-007-0453-9,Springer,2008-03-01,"Adaptability to the environment is crucial for mobile robots, because the circumstances, including the body of the robot, may change. A robot with a large number of degrees of freedom possesses the potential to adapt to such circumstances, but it is difficult to design a good controller for such a robot. We previously proposed a reinforcement learning (RL) method called the CPG actor-critic method, and applied it to the automatic acquisition of vermicular locomotion of a looper-like robot through computer simulations. In this study, we developed a looper-like robot and applied our RL method to the control of this robot. Experimental results demonstrate fast acquisition of a vermicular forward motion, supporting the real applicability of our method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-007-0453-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1016/S1672-6529(08)60083-9,A Controller Design Method Based on a Neural Network for an Outdoor Mobile Robot,Journal of Bionic Engineering,10.1016/S1672-6529(08)60083-9,Springer,2008-03-01,"A wheeled mobile mechanism with a passive and/or active linkage mechanism for travel in rough terrain is developed and evaluated. In our previous research, we developed a switching controller system for wheeled mobile robots in rough terrain. This system consists of two sub-systems: an environment recognition system using a self-organizing map and an adjusted control system using a neural network. In this paper, we propose a new controller design method based on a neural network. The proposed method involves three kinds of controllers: an elementary controller, adjusted controllers, and simplified controllers. In the experiments, our proposed method results in less oscillatory motion in rough terrain and performs better than a well tuned PID controller does.",http://link.springer.com/openurl/fulltext?id=doi:10.1016/S1672-6529(08)60083-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-007-0479-z,Central pattern generators based on Matsuoka oscillators for the locomotion of biped robots,Artificial Life and Robotics,10.1007/s10015-007-0479-z,Springer,2008-03-01,"Biologically inspired control approaches based on central pattern generators (CPGs) with neural oscillators have been drawing much attention for the purpose of generating rhythmic motion for biped robots with human-like locomotion. This article describes the design of a neural-oscillator-based gait-rhythm generator using a network of Matsuoka oscillators to generate a walking pattern for biped robots. This includes the proper consideration of the oscillator’s parameters, such as a time constant for the adaptation rate, coupling factors for mutual inhibitory connections, etc., to obtain a stable and desirable response from the network. The article examines the characteristics of a CPG network with six oscillators, and the effect of assigning symmetrical and asymmetrical coupling coefficients among oscillators within the network structure under different possible inhibitions and excitations. The kinematics and dynamics of a five-link biped robot have been modeled, and its joints are actuated through simulation by the torques output from the neural rhythm generator to generate the trajectories for hip, knee, and ankle joints. The parameters of the neural oscillators are tuned to achieve flexible trajectories. The CPG-based control strategy is implemented and tested through a simulation.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10015-007-0479-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-006-0079-1,An optimized modular neural network controller based on environment classification and selective sensor usage for mobile robot reactive navigation,Neural Computing and Applications,10.1007/s00521-006-0079-1,Springer,2008-03-01,"A new approach to the design of a neural network (NN) based navigator is proposed in which the mobile robot travels to a pre-defined goal position safely and efficiently without any prior map of the environment. This navigator can be optimized for any user-defined objective function through the use of an evolutionary algorithm. The motivation of this research is to develop an efficient methodology for general goal-directed navigation in generic indoor environments as opposed to learning specialized primitive behaviors in a limited environment. To this end, a modular NN has been employed to achieve the necessary generalization capability across a variety of indoor environments. Herein, each NN module takes charge of navigating in a specialized local environment, which is the result of decomposing the whole path into a sequence of local paths through clustering of all the possible environments. We verify the efficacy of the proposed algorithm over a variety of both simulated and real unstructured indoor environments using our autonomous mobile robot platform.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-006-0079-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-007-9190-5,Soft Computing-Based Navigation Schemes for a Real Wheeled Robot Moving Among Static Obstacles,Journal of Intelligent and Robotic Systems,10.1007/s10846-007-9190-5,Springer,2008-03-01,"Collision-free, time-optimal navigation of a real wheeled robot in the presence of some static obstacles is undertaken in the present study. Two soft computing-based approaches, namely genetic-fuzzy system and genetic-neural system and a conventional potential field approach have been developed for this purpose. Training is given to the soft computing-based navigation schemes off-line and the performance of the optimal motion planner is tested on a real robot. A CCD camera is used to collect information of the environment. After processing the collected data, the communication between the robot and the host computer is obtained with the help of a radio-frequency module. Both the soft computing-based approaches are found to perform better than the potential field method in terms of the traveling time taken by the robot. Moreover, the performance of fuzzy logic-based motion planner is found to be comparable with that of neural network-based motion planner, although the training of the former is seen to be computationally less expensive than the latter. Sometimes the potential field method is unable to yield any feasible solution, specifically when the obstacle is found to be just ahead of the robot, whereas soft computing-based approaches have tackled such a situation well.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-007-9190-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1016/S1672-6529(08)60081-5,Environment Recognition System Based on Multiple Classification Analyses for Mobile Robots,Journal of Bionic Engineering,10.1016/S1672-6529(08)60081-5,Springer,2008-03-01,"Various mechanisms have recently been developed that combine linkage mechanisms and wheels. In particular, the combination of passive linkage mechanisms and small wheels is a main research trend because standard wheeled mobile mechanisms find it difficult to move on rough terrain. In our previous research, a six-wheel mobile robot employing a passive linkage mechanism has been developed to enhance maneuverability and was able to climb over a 0.20 m bump and stairs. We designed a hybrid velocity and torque controller using a neural network since simple velocity controllers fail to climb up. In this paper, we propose an environment recognition system for a wheeled mobile robot that consists of multiple classification analyses to make the robot more adaptive to various environments by selecting a suitable system such as decision making, navigation and controller using the result of the environment recognition system. We evaluate the recognition performance in operation environments; slopes, bumps and stairs by comparing principle component, k -means and self-organizing map analyses.",http://link.springer.com/openurl/fulltext?id=doi:10.1016/S1672-6529(08)60081-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-007-9183-4,A Prey Catching and Predator Avoidance Neural-Schema Architecture for Single and Multiple Robots,Journal of Intelligent and Robotic Systems,10.1007/s10846-007-9183-4,Springer,2008-02-01,The paper presents a biologically inspired multi-level neural-schema architecture for prey catching and predator avoidance in single and multiple autonomous robotic systems. The architecture is inspired on anuran (frogs and toads) neuroethological studies and wolf pack group behaviors. The single robot architecture exploits visuomotor coordination models developed to explain anuran behavior in the presence of preys and predators. The multiple robot architecture extends the individual prey catching and predator avoidance model to experiment with group behavior. The robotic modeling architecture distinguishes between higher-level schemas representing behavior and lower-level neural structures representing brain regions. We present results from single and multiple robot experiments developed using the NSL/ASL/MIRO system and Sony AIBO ERS-210 robots.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-007-9183-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-87442-3_148,A Novel Multi-robot Coordination Method Based on Reinforcement Learning,Advanced Intelligent Computing Theories and Applications. With Aspects of Theoretical and Methodological Issues,10.1007/978-3-540-87442-3_148,Springer,2008-01-01,"Focusing on multi-robot coordination, role transformation and reinforcement learning method are combined in this paper. Under centralize control framework, the distance nearest rule which means that the nearest robot ranges from obstacles is selected to be the master robot for controlling salve robots is presented. Meanwhile, different from traditional way which reinforcement learning is applied in online learning of multi-robot coordination, this paper proposed a novel behavior weight method based on reinforcement learning, the robot behavior weights are optimized through interacting with environment and the coordination policy based on maximum behavior value is presented to plan the collision avoidance behavior of robot. The learning method proposed in this paper is applied to the application related to collaboration movement of mobile robots and demonstrated by the simulation results presented in this paper.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-87442-3_148,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-85984-0_1,A Miniature Robot System with Fuzzy Wavelet Basis Neural Network Controller,Advanced Intelligent Computing Theories and Applications. With Aspects of Artificial Intelligence,10.1007/978-3-540-85984-0_1,Springer,2008-01-01,"This paper described the structure of a flexible miniature robot system which can move in human cavities, it makes inchworm-like movement driven by a 3-DOF pneumatic rubber actuator and holds its positions by air chambers. The driving characteristics in axial and bending directions of the actuator were analyzed and the robot control system was designed. The four-layer neural network and the five-layer neural network controllers were proposed to estimate the straight movement and the bending movement respectively. The tracking response and the tracking errors were studied in detail. Results prove that good static and dynamic control effects of the robot system can be obtained by the proposed fuzzy wavelet basis neural networks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-85984-0_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-0-387-09695-7_15,Batch Reinforcement Learning for Controlling a Mobile Wheeled Pendulum Robot,Artificial Intelligence in Theory and Practice II,10.1007/978-0-387-09695-7_15,Springer,2008-01-01,"In this paper we present an application of Reinforcement Learning (RL) methods in the field of robot control. The main objective is to analyze the behavior of batch RL algorithms when applied to a mobile robot of the kind called Mobile Wheeled Pendulum (MWP). In this paper we focus on the common problem in classical control theory of following a reference state (e.g., position set point) and try to solve it by RL. In this case, the state space of the robot has one more dimension, in order to represent the desired variable state, while the cost function is evaluated considering the difference between the state and the reference. Within this framework some interesting aspects arise, like the ability of the RL algorithm to generalize to reference points never considered during the training phase. The performance of the learning method has been empirically analyzed and, when possible, compared to a classic control algorithm, namely linear quadratic optimal control (LQR).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-0-387-09695-7_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-88513-9_120,A Fuzzy Neural Network Based on T-S Model for Mobile Robots to Avoid Obstacles,Intelligent Robotics and Applications,10.1007/978-3-540-88513-9_120,Springer,2008-01-01,"A fuzzy neural network method based on T-S model was proposed for mobile robots to avoid obstacles. Using the proposed method, the obstacles in all environment types can be recognized, so the mobile robots could reach destination without collision. The new method not only has the advantage of fuzzy logic and neural network, but also has good self-study ability. First the data collected by 8 ultrasonic sensors were classified. Then the navigation algorithm based on T-S model was carried out. The test results show that the mobile robot using this fuzzy neural network can recognize the obstacles in all environment types, decide its action, and then arrive at destination after 231 seconds averagely in ten tests. It is faster than the mobile robot using BP neural network which takes 239 seconds",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-88513-9_120,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-007-9174-5,Hybrid Dynamic Control Algorithm for Humanoid Robots Based on Reinforcement Learning,Journal of Intelligent and Robotic Systems,10.1007/s10846-007-9174-5,Springer,2008-01-01,"In this paper, hybrid integrated dynamic control algorithm for humanoid locomotion mechanism is presented. The proposed structure of controller involves two feedback loops: model-based dynamic controller including impart-force controller and reinforcement learning feedback controller around zero-moment point. The proposed new reinforcement learning algorithm is based on modified version of actor-critic architecture for dynamic reactive compensation. Simulation experiments were carried out in order to validate the proposed control approach.The obtained simulation results served as the basis for a critical evaluation of the controller performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-007-9174-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-85563-7_84,"A Simple Goal Seeking Navigation Method for a Mobile Robot Using Human Sense, Fuzzy Logic and Reinforcement Learning",Knowledge-Based Intelligent Information and Engineering Systems,10.1007/978-3-540-85563-7_84,Springer,2008-01-01,"This paper proposes a new fuzzy logic-based navigation method for a mobile robot moving in an unknown environment. This method endows the robot the capabilities of obstacles avoidance and goal seeking without being stuck in local minima. A simple Fuzzy controller is constructed based on the human sense and a fuzzy reinforcement learning algorithm is used to fine tune the fuzzy rule base parameters. The advantages of the proposed method are its simplicity, its easy implementation for industrial applications, and the robot joins its objective despite the environment complexity. Some simulation results of the proposed method and a comparison with previous works are provided.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-85563-7_84,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-69134-1_25,A Reinforcement Learning Technique with an Adaptive Action Generator for a Multi-robot System,From Animals to Animats 10,10.1007/978-3-540-69134-1_25,Springer,2008-01-01,"We have developed a new reinforcement learning (RL) technique called Bayesian-discrimination-function-based reinforcement learning (BRL). BRL is unique, in that it does not have state and action spaces designed by a human designer, but adaptively segments them through the learning process. Compared to other standard RL algorithms, BRL has been proven to be more effective in handling problems encountered by multi-robot systems (MRS), which operate in a learning environment that is naturally dynamic. Furthermore, we have developed an extended form of BRL in order to improve the learning efficiency. Instead of generating a random action when a robot functioning within the framework of the standard BRL encounters an unknown situation, the extended BRL generates an action determined by linear interpolation among the rules that have high similarity to the current sensory input. In this study, we investigate the robustness of the extended BRL through further experiments. In both physical experiments and computer simulations, the extended BRL shows higher robustness and relearning ability against an environmental change as compared to the standard BRL.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-69134-1_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-87656-4_77,Applying Reinforcement Learning to Multi-robot Team Coordination,Hybrid Artificial Intelligence Systems,10.1007/978-3-540-87656-4_77,Springer,2008-01-01,"Multi-robot systems are one of the most challenging problems in autonomous robots. Teams of homogeneous or heterogeneous robots must be able to solve complex tasks. Sometimes the tasks have a cooperative basis in which the global objective is shared by all the robots. In other situations, the robots can be different and even contradictory goals, defining a kind of competitive problems. The multi-robot systems domain is a perfect example in which the uncertainty and vagueness in sensor readings and robot odometry must be handled by using techniques which can deal with this kind of imprecise data. In this paper we introduce the use of Reinforcement Learning techniques for solving cooperative problems in teams of homogeneous robots. As an example, the problem of maintaining a mobile robots formation is studied.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-87656-4_77,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-87732-5_44,Robot Navigation Based on Fuzzy RL Algorithm,Advances in Neural Networks - ISNN 2008,10.1007/978-3-540-87732-5_44,Springer,2008-01-01,"This paper focused on the problem of the autonomous mobile robot navigation under the unknown and changing environment. The reinforcement learning (RL) is applied to learn behaviors of reactive robot. T-S fuzzy neural network and RL are integrated. T-S network is used to implement the mapping from the state space to Q values corresponding with action space of RL. The problem of continuous, infinite states and actions in RL is able to be solved through the function approximation of proposed method. Finally, the method of this paper is applied to learn behaviors for the reactive robot. The experiment shows that the algorithm can effectively solve the problem of navigation in a complicated unknown environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-87732-5_44,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-89076-8_24,An Emphatic Humanoid Robot with Emotional Latent Semantic Behavior,"Simulation, Modeling, and Programming for Autonomous Robots",10.1007/978-3-540-89076-8_24,Springer,2008-01-01,"In this paper we propose an Entertainment Humanoid Robot model based on Latent Semantic Analysis, that tries to exhibit an emotional behavior in the interaction with human. Latent Semantic Analysis (LSA), based on vector space allows the coding of the words semantics by specific statistical computations applied to a large corpus of text. We illustrate how the creation and the use of this emotional conceptual space can provide a framework upon which to build “Latent Semantic Behavior” because it simulates the emotional-associative capabilities of human beings. This approach integrates traditional knowledge representation with intuitive capabilities provided by geometric and sub-symbolic information modeling. To validate the effectiveness of our approach we have simulated an Humanoid Robot Robovie-M on dInfoBots a linux based framework developed in our Mobile Robot Lab.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-89076-8_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-87734-9_23,TOPN Based Temporal Performance Evaluation Method of Neural Network Based Robot Controller,Advances in Neural Networks - ISNN 2008,10.1007/978-3-540-87734-9_23,Springer,2008-01-01,"These years, for some neural network (NN) controller based time critical systems, temporal performance is always required to be evaluated. In order to model complex time critical systems, timed hierarchical object-oriented Petri net (TOPN) has been proposed. On the base of TOPN method, this paper has proposed worst case execution time (WCET) calculation method called time accumulation effect (TAE) calculation, whose goal is to evaluate the performance of TOPN models such as NN based robot controller systems etc al. TAE method can be used to calculate the worst case execution time interval directly on the base of integral linear programming (ILP) method. The use and benefits of TAE calculation for TOPN models have also been illustrated by analyzing one robot controller system model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-87734-9_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-68847-1_51,A Neural Network-Based Approach to Robot Motion Control ,RoboCup 2007: Robot Soccer World Cup XI,10.1007/978-3-540-68847-1_51,Springer,2008-01-01,"The joint controllers used in robots like the Sony Aibo are designed for the task of moving the joints of the robot to a given position. However, they are not well suited to the problem of making a robot move through a desired trajectory at speeds close to the physical capabilities of the robot, and in many cases, they cannot be bypassed easily. In this paper, we propose an approach that models both the robot’s joints and its built-in controllers as a single system that is in turn controlled by a neural network. The neural network controls the entire trajectory of a robot instead of just its static position. We implement and evaluate our approach on a Sony Aibo ERS-7.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-68847-1_51,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-87536-9_40,Policy Gradients with Parameter-Based Exploration for Control,Artificial Neural Networks - ICANN 2008,10.1007/978-3-540-87536-9_40,Springer,2008-01-01,"We present a model-free reinforcement learning method for partially observable Markov decision problems. Our method estimates a likelihood gradient by sampling directly in parameter space, which leads to lower variance gradient estimates than those obtained by policy gradient methods such as REINFORCE. For several complex control tasks, including robust standing with a humanoid robot, we show that our method outperforms well-known algorithms from the fields of policy gradients, finite difference methods and population based heuristics. We also provide a detailed analysis of the differences between our method and the other algorithms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-87536-9_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-211-78775-5_15,"Practical Issues of “Dynamical Systems, Wave based Computation and Neuro-Inspired Robots” — Introduction","Dynamical Systems, Wave-Based Computation and Neuro-Inspired Robots",10.1007/978-3-211-78775-5_15,Springer,2008-01-01,"This Chapter introduces the topics covered during the practice hours of the course “Dynamical Systems, Wave based Computation and Neuro-Inspired Robots”. These practice hours were divided into two parts. Firstly, the course participants were asked to learn the basics on CNNs by using a CNN simulator. Then, they were divided in several groups and a project was assigned to each group. In this Chapter the project objectives are introduced, while in the following Chapters the projects are detailed in the contributions given by the course participants.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-211-78775-5_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-87734-9_18,An Affective Model Applied in Playmate Robot for Children,Advances in Neural Networks - ISNN 2008,10.1007/978-3-540-87734-9_18,Springer,2008-01-01,It is always the focus of researchers’ attention to endow the robot with the emotion similar to human in human robot interaction. This paper present an artificial affective model based on Hidden Markov Model (HMM). It can achieve the transfer of several affective states under some basic hypothesis and restriction. The paper also shows some simulation results of affective states change. It is the basis for architecture in support of interactive robot. Then the paper explains the technical route of playmate robot for children in detail. The robot can behave like a human child and attempt daily communication with human supported by the affective model and these technologies.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-87734-9_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-87881-0_46,CLIVE – An Artificially Intelligent Chat Robot for Conversational Language Practice,"Artificial Intelligence: Theories, Models and Applications",10.1007/978-3-540-87881-0_46,Springer,2008-01-01,"This paper presents an artificially intelligent chat robot called CLIVE. The aim of CLIVE is to provide to a useful and engaging method for people learning a foreign language, to practice their conversational skills. Unlike other systems that focus on providing a limited or structured tutoring experience for language learning, CLIVE has the ability of holding open, natural human-like conversations with people on a wide range of topics. This provides users with a life-like experience that is a more natural way of learning a new language. Experiments were conducted between CLIVE and real human users and an analysis of the conversations shows that CLIVE performs with accuracy and is an accepted method of language practice amongst users.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-87881-0_46,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-87559-8_15,Embedded Neural Network for Swarm Learning of Physical Robots,Artificial Neural Networks - ICANN 2008,10.1007/978-3-540-87559-8_15,Springer,2008-01-01,"In this study we ran real time learning of multiple physical autonomous robots situated in a real dynamic environment. Each robot has an onboard micro controller where a simple neural network is embedded. The neural network was built with the consideration of the power and calculation resources limitation which is a general characteristic of simple robots. In the experiments, several autonomous robots were placed in one environment, where each of them was given a specific task which was expressed as the evaluation function for the robot’s neural network. The learning processes of the robots were started simultaneously from their randomized initial conditions. The presence of several robots consequently formed a dynamic environment, in which an action of one robot affected the learning process of others. We demonstrated the efficiency of the embedded learning mechanism with respect to different environmental factors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-87559-8_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-88513-9_115,Path Planning Algorithm for Robot in 3D Environment Based on Neural Network,Intelligent Robotics and Applications,10.1007/978-3-540-88513-9_115,Springer,2008-01-01,The problem of path planning is studied for the case of a robot moving in a three-dimensional known environment. An aggressive algorithm using a description of the obstacles based on neural network is proposed. The algorithm allows constructing an optimal path and the calculation speed for the proposed algorithm is comparatively fast. Simulation results show the effectiveness of the proposed algorithm.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-88513-9_115,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-68847-1_34,A Framework for Learning in Humanoid Simulated Robots,RoboCup 2007: Robot Soccer World Cup XI,10.1007/978-3-540-68847-1_34,Springer,2008-01-01,"One of the most important characteristics of intelligent activity is the ability to change behaviour according to many forms of feedback. Through learning an agent can interact with its environment to improve its performance over time. However, most of the techniques known that involves learning are time expensive, i.e., once the agent is supposed to learn over time by experimentation, the task has to be executed many times. Hence, high fidelity simulators can save a lot of time. In this context, this paper describes the framework designed to allow a team of real RoboNova-I humanoids robots to be simulated under USARSim environment. Details about the complete process of modeling and programming the robot are given, as well as the learning methodology proposed to improve robot’s performance. Due to the use of a high fidelity model, the learning algorithms can be widely explored in simulation before adapted to real robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-68847-1_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-69162-4_112,Task Segmentation in a Mobile Robot by mnSOM and Clustering with Spatio-temporal Contiguity,Neural Information Processing,10.1007/978-3-540-69162-4_112,Springer,2008-01-01,"In our previous study, task segmentation by mnSOM implicitly assumes that winner modules corresponding to subsequences in the same class share the same label. This paper proposes to do task segmentation by applying various clustering methods to the resulting mnSOM without using the above assumption. Firstly we use the conventional hierarchical clustering. It assumes that the distances between any pair of modules are provided with precision, but this is not exactly true. Accordingly, this is followed by a clustering based on only the distance between spatially adjacent modules with modification by their temporal contiguity. This clustering with spatio-temporal contiguity provides superior performance to the conventional hierarchical clustering and comparable performance with mnSOM using the implicit assumption.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-69162-4_112,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-211-78775-5_18,Wave-based control of a bio-inspired hexapod robot,"Dynamical Systems, Wave-Based Computation and Neuro-Inspired Robots",10.1007/978-3-211-78775-5_18,Springer,2008-01-01,"The main idea of this work is to merge locomotion based on neural approach of Rexabot robot and real-time wave-based navigation in a complex, dynamically changing environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-211-78775-5_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-88513-9_68,Study of Cooperation Strategy of Robot Based on Parallel Q-Learning Algorithm,Intelligent Robotics and Applications,10.1007/978-3-540-88513-9_68,Springer,2008-01-01,"How to solve MR (Multi-Robots) in a dynamic environment of the study of knowledge, and to complete a task or solve a problem, the robot can have the same goal , also different goals. Therefore, to put forward two architectures, which are more suitable for MR studying, according to the architecture, to design the improved learning methods algorithm Q for MR, which solve the problems of coordination and cooperation, such as the credit distribution, distribution of resources, tasks and conflict resolution. MR may be learning in independent environment, and fusing results after learning cycle, and the final results is going to be shared by all the robots, and as the basis of reference passing into next learning cycle, increase learning chances between MR and environment. Simulation results show that the learning algorithm enables MR learning rapidly and quickly surrounded by a mobile group, complying with better effective.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-88513-9_68,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-69162-4_25,Policy Learning for Motor Skills,Neural Information Processing,10.1007/978-3-540-69162-4_25,Springer,2008-01-01,"Policy learning which allows autonomous robots to adapt to novel situations has been a long standing vision of robotics, artificial intelligence, and cognitive sciences. However, to date, learning techniques have yet to fulfill this promise as only few methods manage to scale into the high-dimensional domains of manipulator robotics, or even the new upcoming trend of humanoid robotics, and usually scaling was only achieved in precisely pre-structured domains. In this paper, we investigate the ingredients for a general approach policy learning with the goal of an application to motor skill refinement in order to get one step closer towards human-like performance. For doing so, we study two major components for such an approach, i.e., firstly, we study policy learning algorithms which can be applied in the general setting of motor skill learning, and, secondly, we study a theoretically well-founded general approach to representing the required control structures for task representation and execution.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-69162-4_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-540-30301-5_60,Robot Programming by Demonstration,Springer Handbook of Robotics,10.1007/978-3-540-30301-5_60,Springer,2008-01-01,"Robot programming by demonstration (PbD) has become a central programming by demonstration (PbD) topic of robotics that spans across general research areas such as human-robot interaction, machine learning, machine vision and motor control. Robot PbD started about 30 years ago, and has grown importantly during the past decade. The rationale for moving from purely preprogrammed robots to very flexible user-based interfaces for training robots to perform a task is three-fold. First and foremost, PbD, also referred to as imitation learning , is a powerful mechanism for reducing the complexity of search spaces for learning. When observing either good or bad examples, one can reduce the search for a possible solution, by either starting the search from the observed good solution (local optima), or conversely, by eliminating from the search space what is known as a bad solution. Imitation learning is, thus, a powerful tool for enhancing and accelerating learning in both animals and artifacts. Second, imitation learning offers an implicit means of training a machine, such that explicit and tedious programming of a task by a human user can be minimized or eliminated (Fig.  59.1 ). Imitation learning is thus a  natural means of interacting with a machine that would be accessible to lay people. Fig. 59.1 Left: A robot learns how to make a chess move (namely moving the queen forward) by generalizing across different demonstrations of the task performed in slightly different situations (different starting positions of the hand). The robot records its jointsʼ trajectories and learns to extract what-to-imitate , i.e. that the task constraints are reduced to a subpart of the motion located in a plane defined by the three chess pieces. Right: The robot reproduces the skill in a new context (for different initial position of the chess piece) by finding an appropriate controller that satisfies both the task constraints and constraints relative to its body limitation ( how-to-imitate problem), adapted from [ 59.1 ] Third, studying and modeling the coupling of perception and action, which is at the core of imitation learning, helps us to understand the mechanisms by which the self-organization of perception and action could arise during development. The reciprocal interaction of perception and action could explain how competence in motor control can be grounded in rich structure of perceptual variables, and vice versa, how the processes of perception can develop as means to create successful actions. PbD promises were thus multiple. On the one hand, one hoped that it would make learning faster, in contrast to tedious reinforcement learning methods or trials-and-error learning. On the other hand, one expected that the methods, being user-friendly, would enhance the application of robots in human daily environments. Recent progresses in the field, which we review in this chapter, show that the field has made a leap forward during the past decade toward these goals. In addition, we anticipate that these promises may be fulfilled very soon. Section  59.1 presents a brief historical overview of robot Programming by Demonstration (PbD), introducing several issues that will be discussed later in this chapter. Section  59.2 reviews engineering approaches to robot PbD with an emphasis on machine learning approaches that provide the robot with the ability to adapt the learned skill to different situations (Sect.  59.2.1 ). This section discusses also the different types of representation that one may use to encode a skill and presents incremental learning techniques to refine the skill progressively (Sect.  59.2.4 ). Section  59.2.3 emphasizes the importance to give the teacher an active role during learning and presents different ways in which the user can convey cues to the robot to help it to improve its learning. Section  59.2.4 discusses how PbD can be jointly used with other learning strategies to overcome some limitations of PbD. Section  59.3 reviews works that take a more biological approach to robot PbD and develops models of either the cognitive or neural processes of imitation learning in primates. Finally, Sect.  59.4 lists various open issues in robot PbD that have yet been little explored by the field.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-30301-5_60,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-87702-8_11,Endowing Artificial Systems with Anticipatory Capabilities: Success Cases,The Challenge of Anticipation,10.1007/978-3-540-87702-8_11,Springer,2008-01-01,"This book has provided various theoretical perspectives on anticipatory processes in natural and artificial cognitive systems. Advantages have been proposed and confirmed in various detailed case studies, which may have given the reader detailed insights into anticipatory processes and their importance in various cognitive systems tasks. To wrap up these advantages and give a concluding overview of various current anticipatory process advantages, this final chapter highlights a concise collection of precise success stories of anticipations in artificial cognitive systems. We survey fourteen case studies, which were developed during the EU project MindRACES . In these studies, simulated or real robots were tested in different environmental tasks, which required advanced sensorimotor and cognitive abilities. These abilities included the initiation and control of goal-directed actions, the orientation of attention, finding and reaching goal locations, and performing mental experiments for action selection. All the studies have shown advantages of anticipatory mechanisms compared to reactive mechanisms in terms of increased robot autonomy and adaptivity. In some cases, anticipations even caused the development of new cognitive abilities, which were simply impossible without anticipatory mechanisms. For each case study, we indicate relevant associated publications, in which the interested reader may find further details on the relevant computational architectures, the involved anticipatory mechanisms, as well as on the analytical and quantitative results. While the book as a whole has laid out the theoretical principles and design methodology for such advancements, this final chapter thus provides various possible starting points for further developments in both the surveyed system architectures and the presented solutions to the cognitive tasks addressed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-87702-8_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-89722-4_17,Policy Learning – A Unified Perspective with Applications in Robotics,Recent Advances in Reinforcement Learning,10.1007/978-3-540-89722-4_17,Springer,2008-01-01,"Policy Learning approaches are among the best suited methods for high-dimensional, continuous control systems such as anthropomorphic robot arms and humanoid robots. In this paper, we show two contributions: firstly, we show a unified perspective which allows us to derive several policy learning algorithms from a common point of view, i.e, policy gradient algorithms, natural-gradient algorithms and EM-like policy learning. Secondly, we present several applications to both robot motor primitive learning as well as to robot control in task space. Results both from simulation and several different real robots are shown.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-89722-4_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-68847-1_19,Heuristic Reinforcement Learning Applied to RoboCup Simulation Agents,RoboCup 2007: Robot Soccer World Cup XI,10.1007/978-3-540-68847-1_19,Springer,2008-01-01,"This paper describes the design and implementation of robotic agents for the RoboCup Simulation 2D category that learns using a recently proposed Heuristic Reinforcement Learning algorithm, the Heuristically Accelerated Q –Learning (HAQL). This algorithm allows the use of heuristics to speed up the well-known Reinforcement Learning algorithm Q –Learning. A heuristic function that influences the choice of the actions characterizes the HAQL algorithm. A set of empirical evaluations was conducted in the RoboCup 2D Simulator, and experimental results show that even very simple heuristics enhances significantly the performance of the agents.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-68847-1_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-85984-0_35,Rule-Based Analysis of Behaviour Learned by Evolutionary and Reinforcement Algorithms,Advanced Intelligent Computing Theories and Applications. With Aspects of Artificial Intelligence,10.1007/978-3-540-85984-0_35,Springer,2008-01-01,"We study behavioural patterns learned by a robotic agent by means of two different control and adaptive approaches — a radial basis function neural network trained by evolutionary algorithm, and a traditional reinforcement Q-learning algorithm. In both cases, a set of rules controlling the agent is derived from the learned controllers, and these sets are compared. It is shown that both procedures lead to reasonable and compact, albeit rather different, rule sets.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-85984-0_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4020-8387-7_127,Roving Robot Autonomously Controled by Chaotic Memory Dynamics in Quasi-Layered Recurrent Neural Networks for Sensing and Driving,Advances in Cognitive Neurodynamics ICCN 2007,10.1007/978-1-4020-8387-7_127,Springer,2008-01-01,"Chaotic dynamics is applied to 2-dimensional motion control. We propose a quasi-layered recurrent neural network consisting of sensing neurons and driving neuros, where in sensing neurons, sensitive response to external input is utilized, whereas in driving neurons, complex dynamics is utilized to generate complex motions. A hardware implementation into a roving robot is shown.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4020-8387-7_127,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-540-30301-5_10,AI Reasoning Methods for Robotics,Springer Handbook of Robotics,10.1007/978-3-540-30301-5_10,Springer,2008-01-01,"Artificial intelligence (AI) reasoning technology involving, e.g., inference, planning, and learning, has a track record with a healthy number of successful applications. So, can it be used as a toolbox of methods for autonomous mobile robots? Not necessarily, as reasoning on a mobile robot about its dynamic, partially known environment may differ substantially from that in knowledge-based pure software systems, where most of the named successes have been registered. This Chapter sketches the main robotics-relevant topics of symbol-based AI reasoning. Basic methods of knowledge representation and inference are described in general, covering both logic- and probability-based approaches. Then, some robotics-related particularities are addressed specially: issues in logic-based high-level robot control, fuzzy logics, and reasoning under time constraints. Two generic applications of reasoning are then described in some detail: action planning and learning. General reasoning is currently not a standard feature onboard autonomous mobile robots. Beyond sketching the state of the art in robotics-related AI reasoning, this Chapter points to the involved research problems that remain to be solved towards that end. The Chapter first reviews knowledge representation and deduction in general (Sect.  9.1 ), and then goes into some detail regarding reasoning issues that are considered particularly relevant for applications in robots (Sect.  9.2 ). Having presented reasoning methods , we then enter the field of generic reasoning applications , namely, action planning (Sect.  9.3 ) and machine learning (Sect.  9.4 ). Section  9.5 concludes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-30301-5_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-69158-7_36,Pattern-Based Reasoning System Using Self-incremental Neural Network for Propositional Logic,Neural Information Processing,10.1007/978-3-540-69158-7_36,Springer,2008-01-01,"We propose an architecture for reasoning with pattern-based if-then rules that is effective for intelligent systems like robots solving varying tasks autonomously in a real environment. The proposed system can store pattern-based if-then rules of propositional logic, including conjunctions, disjunctions, negations, and implications. The naive pattern-based reasoning can store pattern-based if-then rules and make inferences using them. However, it remains insufficient for intelligent systems operating in a real environment. The proposed system uses an algorithm that is inspired by self-incremental neural networks such as SONIN and SOINN-AM in order to achieve incremental learning, generalization, avoidance of duplicate results, and robustness to noise, which are important properties for intelligent systems",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-69158-7_36,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-69158-7_114,Global Localization for the Mobile Robot Based on Natural Number Recognition in Corridor Environment,Neural Information Processing,10.1007/978-3-540-69158-7_114,Springer,2008-01-01,"This paper proposes global localization for mobile robot by introducing local goal based navigation and model-based object recognition. In navigation stage, the robot follows the wall while detecting a door using a laser scanner, and then sets up the local goal near detected door. In recognition stage, room number is recognized and also ambiguous room number is rejected by multistage rejection method (MRSM) in order to reduce false recognition. Recognition results by various methods are demonstrated and room number feature map is built after exploring the whole corridor of LG research center.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-69158-7_114,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-77465-5_3,Dynamically Self-generated Fuzzy Neural Networks with Industry Applications,Soft Computing Applications in Industry,10.1007/978-3-540-77465-5_3,Springer,2008-01-01,"Over the last few decades, fuzzy logic has been shown as a powerful methodology for dealing with imprecision and nonlinearity efficiently. Applications can be found in a wide context ranging from medicine to finance, from human factors to consumer products, from vehicle control to computational linguistics, and so on (Wang 1997; Dubois and Prade 2000; Passino and Yurkovich 1998; Jang et al. 1997; Sugeno 1985; Pedrycz 1993). However, one of the shortcomings of fuzzy logic is the lack of systematic design. To circumvent this problem, fuzzy logic is usually combined with Neural Networks (NNs) by virtue of the learning capability of NNs. NNs are networks of highly interconnected neural computing elements that have the ability of responding to input stimuli and learning to adapt to the environment. Both fuzzy systems and NNs are dynamic and parallel processing systems that estimate input-output functions (Mitra and Hayashi 2000). The merits of both fuzzy and neural systems can be integrated in Fuzzy Neural Networks (FNNs) (Lee and Lee 1974, 1975; Pal and Mitra 1999; Zanchettin and Ludermir 2003). Therefore, the integration of fuzzy and neural systems leads to a symbiotic relationship in which fuzzy systems provide a powerful framework for expert knowledge representation, while NNs provide learning capabilities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-77465-5_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-70534-5_21,Neural Networks,Embedded Robotics,10.1007/978-3-540-70534-5_21,Springer,2008-01-01,"The artificial neural network (ANN), often simply called neural network (NN), is a processing model loosely derived from biological neurons [Gurney 2002]. Neural networks are often used for classification problems or decision making problems that do not have a simple or straightforward algorithmic solution. The beauty of a neural network is its ability to learn an input to output mapping from a set of training cases without explicit programming, and then being able to generalize this mapping to cases not seen previously. There is a large research community as well as numerous industrial users working on neural network principles and applications [Rumelhart, McClelland 1986], [Zaknich 2003]. In this chapter, we only briefly touch on this subject and concentrate on the topics relevant to mobile robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-70534-5_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-75767-2_5,Evolutionary Learning of Neural Structures for Visuo-Motor Control,Computational Intelligence in Medical Informatics,10.1007/978-3-540-75767-2_5,Springer,2008-01-01,"Evolutionary Learning of Neural Structures for Visuo-Motor Control Artificial neural networks are computing tools, modeled after the human brain in order to make its vast learning and data processing potential available to computers. These networks are known to be powerful tools with natural learning capabilities. However, learning the structure and synaptic weights of an artificial neural network to solve a complex problem can be a very difficult task. With a growing size of the required network the dimension of the search space can make it next to impossible to find a globally optimal solution. We apply a relatively new method called EANT to develop a network that moves a robot arm in a visuo-motor control scenario with the goal to align its hand with an object. EANT starts from a simple initial network and gradually develops it further using an evolutionary method. On a larger scale new neural structures are added to a current generation of networks. On a smaller scale the current individuals (structures) are optimised by changing their parameters. Using a simulation to evaluate the individuals a reinforcement learning procedure for neural topologies has been realised. We present results from experiments with two types of optimisation strategies for the parameter optimisation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-75767-2_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-88513-9_21,A Hybrid Intelligent System for Pipeline Robot Navigation in Unknown Environment,Intelligent Robotics and Applications,10.1007/978-3-540-88513-9_21,Springer,2008-01-01,"This paper developed a fuzzy logic controller with a neural network control system for sensor based pipeline robot navigation in pipe environment. The fuzzy controller creates initial membership functions and fuzzy logic rules. the neural network, which automatically process range information for determining a good steering angle in local regions. This NN-fuzzy system is used to control the mobile pipeline robot, which is equipped with an array of ultrasonic sensors to acquire the distance between the pipeline robot and obstacle. On the basis of this system, a strategy for combining local behavior control with global behavior control planning was proposed in this paper. Finally a pipeline robot runs in simulation environment. The experimental results show that appropriate control mechanisms of the fuzzy controller are obtained by evolution. The controller has evolved well enough to smoothly drive the pipeline robot in different pipe environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-88513-9_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-89076-8_11,YARS: A Physical 3D Simulator for Evolving Controllers for Real Robots,"Simulation, Modeling, and Programming for Autonomous Robots",10.1007/978-3-540-89076-8_11,Springer,2008-01-01,"This paper presents YARS (Yet Another Robot Simulator), which was initially developed in the context of evolutionary robotics (ER), yet includes features which are also of benefit to those outside of this field. An experiment in YARS is defined by a single XML file, which includes the simulator configuration, the (randomisable) environment, and any number of (mobile) robots. Robots are either controlled through an automatised communication, or by dynamically loaded C++ programs. Therefore, YARS, although still under active development, is comparable with commercial and open-source robot simulators which include a physics engine such as Webots and Breve but with a much stronger focus on requirements originating from the field of evolutionary robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-89076-8_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-87732-5_41,Research on Fish Intelligence for Fish Trajectory Prediction Based on Neural Network,Advances in Neural Networks - ISNN 2008,10.1007/978-3-540-87732-5_41,Springer,2008-01-01,"This paper researches the behavior modes of some intelligent creature in some environment. The gained modes are used as movement models to construct NN to predict the moving trajectory and then catch it. Firstly the behavior patterns of fish that kept trying to escape from the net attached at robot’s hand were studied through lots of experiments. The patterns were divided into five sorts and the learning procedures were divided into three stages. Based on this, the position, orientation and speed of each time were used as the input of multi layer perceptron (MLP) neural networks (NN), and the positions of the fish at next time were the outputs. The NN adopted extended delta-bar-delta (DBD) algorithm as learning method. Thus the NNs were constructed to study the moving regulations of fish in every pattern to predict the moving trajectory. The simulation results shows that the BP NN constructed here have the advantage of faster learning rate, higher identifying precision and can predict the fish trajectory successfully. The research is significant for visual servo in robotic system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-87732-5_41,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-540-30301-5_62,Evolutionary Robotics,Springer Handbook of Robotics,10.1007/978-3-540-30301-5_62,Springer,2008-01-01,"Evolutionary Robotics is a method for automatically generating artificial brains and morphologies of autonomous robots. This approach is useful both for investigating the design space of robotic applications and for testing scientific hypotheses of biological mechanisms and processes. In this chapter we provide an overview of methods and results of Evolutionary Robotics with robots of different shapes, dimensions, and operation features. We consider both simulated and physical robots with special consideration to the transfer between the two worlds.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-30301-5_62,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-211-78775-5_7,Realization of bio-inspired locomotion machines via nonlinear dynamical circuits,"Dynamical Systems, Wave-Based Computation and Neuro-Inspired Robots",10.1007/978-3-211-78775-5_7,Springer,2008-01-01,"In the previous lecture some design guidelines for CPGs by means of CNNs were given, giving particular attention to the realization of the gaits in a hexapod structure. In this lecture it will be shonw that the same spatial-temporal dynamics can be also used to obtain patterns for other kinds of bio-inspired moving machines. For the sake of clarity, in the following section the basic cell dynamical model, formally identical to that one used in the previous lecture, is briefly recalled.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-211-78775-5_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-85072-4_35,AIS Based Distributed Wireless Sensor Network for Mobile Search and Rescue Robot Tracking,Artificial Immune Systems,10.1007/978-3-540-85072-4_35,Springer,2008-01-01,"The General Suppression Control Framework (GSCF) is a framework inspired by the suppression hypothesis of the immune discrimination theory. The framework consists of five distinct components, the Affinity Evaluator, Cell Differentiator, Cell Reactor, Suppression Modulator, and the Local Environment. These reactive components, each responsible for a specific function, can generate long-term and short-term influences to other components by the use of humoral and cellular signals.This paper presents the design and application of a GSCF based distributed wireless sensor network prototyping system for tracking mobile search and rescue robots. The main objective of this physical prototyping system is to demonstrate the possibility of applying advanced Zigbee sensors to form a network that can locate a small group of mobile robots within the wireless sensor network. Another important objective of the prototyping system presented is to identify potential technological constraints in the physical system. Referencing to the result obtained, future research can be formulated and realistic simulation environment can be developed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-85072-4_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-78317-6_17,Multilayer Perceptron Adaptive Dynamic Control of Mobile Robots: Experimental Validation,European Robotics Symposium 2008,10.1007/978-3-540-78317-6_17,Springer,2008-01-01,"This paper presents experimental results acquired from the implementation of an adaptive control scheme for nonholonomic mobile robots, which was recently proposed by the same authors and tested only by simulations. The control system comprises a trajectory tracking kinematic controller, which generates the reference wheel velocities, and a cascade dynamic controller, which estimates the robot’s uncertain nonlinear dynamic functions in real-time via a multilayer perceptron neural network. In this manner precise velocity tracking is attained, even in the presence of unknown and/or time-varying dynamics. The experimental mobile robot, designed and built for the purpose of this research, is also presented in this paper.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-78317-6_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-87734-9_22,An Application of Wavelet Networks in the Carrying Robot Walking,Advances in Neural Networks - ISNN 2008,10.1007/978-3-540-87734-9_22,Springer,2008-01-01,"We found that neuron model is inadequate owing to its defects such as those inherent in its structure and in its capability of information storage. So we propose an intelligent neurons assemblage model with generalized wavelet basis function network as its excited function. Not only the wavelet neural networks’ convergence rate is much faster and its nonlinear approach capability is much better but also its intelligent characteristics, such as the variable-scale adaptive adjustment of structure and the generalized information storage, make it reflect much more faith fully the biological original. Static learning of the inverse dynamics model and adaptive virtual torque control based on Lyapunov stability of the carrying robot walking are demonstrated to prove that the proposed mechanism is valid.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-87734-9_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-69162-4_99,Integrated Model for Informal Inference Based on Neural Networks,Neural Information Processing,10.1007/978-3-540-69162-4_99,Springer,2008-01-01,"Inference is one of human’s high-level functionalities and it is not easy to implement in machine. It is believed that inference is not results of single neuron’s activity. Instead, it is a complex activity generated by multiple neural networks. Unlike computer, it is more flexible and concludes differently even for the similar situations in case of human. In this paper, these characteristics are defined as “informality.” Informality in inference can be implemented using the interaction of multiple neural networks with the inclusion of internal or subjective properties. Simple inference tasks such as pattern recognition and robot control are solved based on the informal inference ideas. Especially, fuzzy integral and behavior network methods are adopted to realize that. Experimental results show that the informal inference can perform better with more flexibility compared to the previous static approaches.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-69162-4_99,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-78582-8_79,Using Multiple Models to Imitate the YMCA,Agent and Multi-Agent Systems: Technologies and Applications,10.1007/978-3-540-78582-8_79,Springer,2008-01-01,"Learning by imitation enables people to program robots simply by showing them what to do, instead of having to specify the motor commands of the robot. To achieve imitative behaviour in a simulated robot, a modular connectionist architecture for motor learning and control was implemented. The architecture was used to imitate human dance movements. The architecture self-organizes the decomposition of the movement to be imitated across different modules. The results show that the decomposition of the movement tends to be both competitive (i.e. one module dominates the others for a part of the movement) and collaborative (i.e. modules cooperate in controlling the robot).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-78582-8_79,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-75398-8_15,Convolutional Neural Networks for Image Processing with Applications in Mobile Robotics,"Speech, Audio, Image and Biomedical Signal Processing using Neural Networks",10.1007/978-3-540-75398-8_15,Springer,2008-01-01,"Convolutional neural networks (CNNs) represent an interesting method for adaptive image processing, and form a link between general feed-forward neural networks and adaptive filters. Two-dimensional CNNs are formed by one or more layers of two-dimensional filters, with possible non-linear activation functions and/or down-sampling. Convolutional neural networks (CNNs) impose constraints on the weights and connectivity of the network, providing a framework well suited to the processing of spatially or temporally distributed data. CNNs possess key properties of translation invariance and spatially local connections (receptive fields). The socalled “weight-sharing” property of CNNs limits the number of free parameters. Although CNNs have been applied to face and character recognition, it is fair to say that the full potential of CNNs has not yet been realised. This chapter presents a description of the convolutional neural network architecture, and reports some of our work applying CNNs to theoretical and real-world image processing problems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-75398-8_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-69134-1_7,Internal and External Memory in Neuroevolution for Learning in Non-stationary Problems,From Animals to Animats 10,10.1007/978-3-540-69134-1_7,Springer,2008-01-01,"This paper deals with the topic of learning through neuroevolutionary algorithms in non-stationary settings. This kind of algorithms that evolve the parameters and/or the topology of a population of Artificial Neural Networks have provided successful results in optimization problems in stationary settings. Their application to non-stationary problems, that is, problems that involve changes in the objective function, still requires more research. In this paper we address the problem through the integration of implicit, internal or genotypic, memory structures and external explicit memories in an algorithm called Promoter Based Genetic Algorithm with External Memory (PBGA-EM). The capabilities introduced in a simple genetic algorithm by these two elements are shown on different tests where the objective function of a problem is changed in an unpredictable manner.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-69134-1_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-88190-2_33,Evolving an Artificial Homeostatic System,Advances in Artificial Intelligence - SBIA 2008,10.1007/978-3-540-88190-2_33,Springer,2008-01-01,"Theory presented by Ashby states that the process of homeostasis is directly related to intelligence and to the ability of an individual in successfully adapting to dynamic environments or disruptions. This paper presents an artificial homeostatic system under evolutionary control, composed of an extended model of the GasNet artificial neural network framework, named NSGasNet, and an artificial endocrine system. Mimicking properties of the neuro-endocrine interaction, the system is shown to be able to properly coordinate the behaviour of a simulated agent that presents internal dynamics and is devoted to explore the scenario without endangering its essential organization. Moreover, sensorimotor disruptions are applied, impelling the system to adapt in order to maintain some variables within limits, ensuring the agent survival. It is envisaged that the proposed framework is a step towards the design of a generic model for coordinating more complex behaviours, and potentially coping with further severe disruptions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-88190-2_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11071-007-9234-1,An adaptive critic neural network for motion control of a wheeled mobile robot,Nonlinear Dynamics,10.1007/s11071-007-9234-1,Springer,2007-12-01,"In this paper, we propose a new application of the adaptive critic methodology for the feedback control of wheeled mobile robots, based on a critic signal provided by a neural network (NN). The adaptive critic architecture uses a high-level supervisory NN adaptive critic element (ACE), to generate the reinforcement signal to optimise the associative search element (ASE), which is applied to approximate the non-linear functions of the mobile robot. The proposed tracking controller is derived from Lyapunov stability theory and can guarantee tracking performance and stability. A series of computer simulations have been used to emulate the performance of the proposed solution for a wheeled mobile robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11071-007-9234-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-007-9175-4,From the Editor-in-Chief,Journal of Intelligent and Robotic Systems,10.1007/s10846-007-9175-4,Springer,2007-12-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-007-9175-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1016/S1672-6529(07)60042-0,A switching controller system for a wheeled mobile robot,Journal of Bionic Engineering,10.1016/S1672-6529(07)60042-0,Springer,2007-12-01,"A wheeled mobile mechanism with a passive and/or active linkage mechanism for rough terrain environment is developed and evaluated. The wheeled mobile mechanism which has high mobility in rough terrain needs sophisticated system to adapt various environments. We focus on the development of a switching controller system for wheeled mobile robots in rough terrain. This system consists of two sub-systems: an environment recognition system using link angles and an adaptive control system. In the environment recognition system, we introduce a Self-Organizing Map (SOM) for clustering link angles. In the adaptive controllers, we introduce neural networks to calculate the inverse model of the wheeled mobile robot. The environment recognition system can recognize the environment in which the robot travels, and the adjustable controllers are tuned by experimental results for each environment. The dual sub-system switching controller system is experimentally evaluated. The system recognizes its environment and adapts by switching the adjustable controllers. This system demonstrates superior performance to a well-tuned single PID controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1016/S1672-6529(07)60042-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10958-007-0494-6,Editor’s preface,Journal of Mathematical Sciences,10.1007/s10958-007-0494-6,Springer,2007-11-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10958-007-0494-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/npre.2007.1234.1,Semiotic Dynamics Solves the Symbol Grounding Problem,Nature Precedings,10.1038/npre.2007.1234.1,Nature,2007-10-17,"Language requires the capacity to link symbols (words, sentences) through the intermediary of internal representations to the physical world, a process known as symbol grounding. One of the biggest debates in the cognitive sciences concerns the question how human brains are able to do this. Do we need a material explanation or a system explanation? John Searle’s well known Chinese Room thought experiment, which continues to generate a vast polemic literature of arguments and counter-arguments, has argued that autonomously establishing internal representations of the world (called ’intentionality’ in philosophical parlance) is based on special properties of human neural tissue and that consequently an artificial system, such as an autonomous physical robot, can never achieve this. Here we study the Grounded Naming Game as a particular example of symbolic interaction and investigate a dynamical system that autonomously builds up and uses the semiotic networks necessary for performance in the game. We demonstrate in real experiments with physical robots that such a dynamical system indeed leads to a successful emergent communication system and hence that symbol grounding and intentionality can be explained in terms of a particular kind of system dynamics. The human brain has obviously the right mechanisms to participate in this kind of dynamics but the same dynamics can also be embodied in other types of physical systems.",https://www.nature.com/articles/npre.2007.1234.1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-007-9160-y,Neuro-Kinematics Based Dexterous Robotics Hand Force Optimization,Journal of Intelligent and Robotic Systems,10.1007/s10846-007-9160-y,Springer,2007-10-01,"The complexity of computing appropriate distribution of manipulation forces among fingers of a four-fingered robot hand defined in a dynamically Task-Space coordinate task is addressed. Finger-object interactions are modelled as point frictional contacts, consequently, the system is indeterminate. Hence, an optimal solution does necessitate for controlling forces acting on a grasped object. A fast and efficient method for computing optimal grasping and manipulation forces is presented based on a quadratic optimisation formulation, where computation has been based on using the nonlinear factual model of contacts. Furthermore, in order to achieve grasping while in motion, the hand inverse Jacobian has to be intensively computed, consequently, we investigate an efficient approach of employing an artificial neural network for the multi-finger robot hand in which the object motion is defined in. The approach followed here is to let an ANN to learn the nonlinear inverse kinematics functional relating the hand joints positions and displacements to object displacement. This is done by considering the inverse hand Jacobian, in addition to the interaction between hand fingers and the object being grasped and manipulated.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-007-9160-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10111-007-0062-3,Gesture recognition for control of rehabilitation robots,"Cognition, Technology & Work",10.1007/s10111-007-0062-3,Springer,2007-10-01,This paper describes the development of a control user interface for a wheelchair-mounted manipulator for use by severely disabled persons. It explains the construction of the interface using tasks to define the user interface architecture. The prototype robot used several gesture recognition systems to achieve a level of usability better than other robots used for rehabilitation at the time. The use of neural networks and other procedures is evaluated. It outlines the experiments used to evaluate the user responses and draws conclusions about the effectiveness of the whole system. It demonstrates the possibility of control using a head mouse.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10111-007-0062-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF03179036,Intelligent phase plane switching control of a pneumatic muscle robot arm with Magneto-Rheological Brake,Journal of Mechanical Science and Technology,10.1007/BF03179036,Springer,2007-08-01,"Pneumatic cylinders are one kind of low cost actuation sources which have been applied in industrial and robotics field, since they have a high power/weight ratio, a high-tension force and a long durability. To overcome the shortcomings of conventional pneumatic cylinders, a number of newer pneumatic actuators have been developed such as McKibben Muscle, Rubber Actuator and Pneumatic Artificial Muscle (PAM) Manipulators. However, some limitations still exist, such as the air compressibility and the lack of damping ability of the actuator bring the dynamic delay of the pressure response and cause the oscillatory motion. In addition, the nonlinearities in the PAM manipulator still limit the controllability. Therefore, it is not easy to realize motion with high accuracy and high speed and with respect to various external inertia loads. To overcome these problems, a novel controller which harmonizes a phase plane switching control method (PPSC) with conventional PID controller and the adaptabilities of neural network is newly proposed. In order to realize satisfactory control performance a variable damper, Magneto-Rheological Brake (MRB), is equipped to the joint of the robot. The mixture of conventional PID controller and an intelligent phase plane switching control using neural network (IPPSC) brings us a novel controller. The experiments were carried out in a robot arm, which is driven by two PAM actuators, and the effectiveness of the proposed control algorithm was demonstrated through experiments, which had proved that the stability of the manipulator can be improved greatly in a high gain control by using MRB with 1PPSC and without regard for the changes of external inertia loads.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF03179036,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10676-007-9138-2,AI Armageddon and the Three Laws of Robotics,Ethics and Information Technology,10.1007/s10676-007-9138-2,Springer,2007-07-01,"After 50 years, the fields of artificial intelligence and robotics capture the imagination of the general public while, at the same time, engendering a great deal of fear and skepticism. Isaac Asimov recognized this deep-seated misconception of technology and created the Three Laws of Robotics. The first part of this paper examines the underlying fear of intelligent robots, revisits Asimov’s response, and reports on some current opinions on the use of the Three Laws by practitioners. Finally, an argument against robotic rebellion is made along with a call for personal responsibility and suggestions for implementing safety constraints in intelligent robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10676-007-9138-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-007-9133-1,Robust Recurrent Neural Network Control of Biped Robot,Journal of Intelligent and Robotic Systems,10.1007/s10846-007-9133-1,Springer,2007-06-01,"In this paper, a recurrent neural network (RNN) control scheme is proposed for a biped robot trajectory tracking system. An adaptive online training algorithm is optimized to improve the transient response of the network via so-called conic sector theorem. Furthermore, L _2-stability of weight estimation error of RNN is guaranteed such that the robustness of the controller is ensured in the presence of uncertainties. In consideration of practical applications, the algorithm is developed in the discrete-time domain. Simulations for a seven-link robot model are presented to justify the advantage of the proposed approach. We give comparisons between the standard PD control and the proposed RNN compensation method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-007-9133-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-007-9025-z,Introduction to the special issue on the science behind embodied AI : The robots of the AAAI competition and exhibition,Autonomous Robots,10.1007/s10514-007-9025-z,Springer,2007-05-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-007-9025-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-007-9126-0,Neural Network Feedback Control: Work at UTA’s Automation and Robotics Research Institute,Journal of Intelligent and Robotic Systems,10.1007/s10846-007-9126-0,Springer,2007-04-01,"This is an outline of research in neural networks for feedback control done since the mid 1990s at the Automation and Robotics Research Institute (ARRI) of The University of Texas at Arlington (UTA). It shows how the developments of Intelligent Control Systems based on neural networks have followed three main generations. This statement provides a short, broad-brush perspective on the development of intelligent neural feedback controllers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-007-9126-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-006-0007-1,Movement prediction from real-world images using a liquid state machine,Applied Intelligence,10.1007/s10489-006-0007-1,Springer,2007-04-01,"The prediction of time series is an important task in finance, economy, object tracking, state estimation and robotics. Prediction is in general either based on a well-known mathematical description of the system behind the time series or learned from previously collected time series. In this work we introduce a novel approach to learn predictions of real world time series like object trajectories in robotics. In a sequence of experiments we evaluate whether a liquid state machine in combination with a supervised learning algorithm can be used to predict ball trajectories with input data coming from a video camera mounted on a robot participating in the RoboCup. The pre-processed video data is fed into a recurrent spiking neural network. Connections to some output neurons are trained by linear regression to predict the position of a ball in various time steps ahead. The main advantages of this approach are that due to the nonlinear projection of the input data to a high-dimensional space simple learning algorithms can be used, that the liquid state machine provides temporal memory capabilities and that this kind of computation appears biologically more plausible than conventional methods for prediction. Our results support the idea that learning with a liquid state machine is a generic powerful tool for prediction.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-006-0007-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11023-007-9056-4,"Computation, Coherence, and Ethical Reasoning",Minds and Machines,10.1007/s11023-007-9056-4,Springer,2007-03-01,"Theories of moral, and more generally, practical reasoning sometimes draw on the notion of coherence. Admirably, Paul Thagard has attempted to give a computationally detailed account of the kind of coherence involved in practical reasoning, claiming that it will help overcome problems in foundationalist approaches to ethics. The arguments herein rebut the alleged role of coherence in practical reasoning endorsed by Thagard. While there are some general lessons to be learned from the preceding, no attempt is made to argue against all forms of coherence in all contexts. Nor is the usefulness of computational modelling called into question. The point will be that coherence cannot be as useful in understanding moral reasoning as coherentists may think. This result has clear implications for the future of Machine Ethics, a newly emerging subfield of AI.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11023-007-9056-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-006-0056-8,Controlling a robot manipulator with fuzzy voice commands using a probabilistic neural network,Neural Computing and Applications,10.1007/s00521-006-0056-8,Springer,2007-02-01,"Natural language commands are generated by intelligent human beings. As a result, they contain a lot of information. Therefore, if it is possible to learn from such commands and reuse that knowledge, it will be a very efficient process. In this paper, learning from such information rich voice commands for controlling a robot is studied. First, new concepts of fuzzy coach-player system and sub-coach are proposed for controlling robots with natural language commands. Then, the characteristics of the subjective human decision making process are discussed and a Probabilistic Neural Network (PNN) based learning method is proposed to learn from such commands and to reuse the acquired knowledge. Finally, the proposed concept is demonstrated and confirmed with experiments conducted using a PA-10 redundant manipulator.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-006-0056-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-73956-2_21,The robot for practical verifying of artificial intelligence methods: Micro-mouse task,Recent Advances in Mechatronics,10.1007/978-3-540-73956-2_21,Springer,2007-01-01,"Robot localization and path planning belong to actual problems in robotics. The paper is focused on design of small autonomous robot for practical verifying artificial intelligence methods concretely on Micromouse task. The physical model was designed with respect to its simple construction, unpretentious production and relatively little cost but sufficient capability for performing different experiments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-73956-2_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74024-7_5,Imitative Reinforcement Learning for Soccer Playing Robots,RoboCup 2006: Robot Soccer World Cup X,10.1007/978-3-540-74024-7_5,Springer,2007-01-01,"In this paper, we apply Reinforcement Learning (RL) to a real-world task. While complex problems have been solved by RL in simulated worlds, the costs of obtaining enough training examples often prohibits the use of plain RL in real-world scenarios. We propose three approaches to reduce training expenses for real-world RL. Firstly, we replace the random exploration of the huge search space, which plain RL uses, by guided exploration that imitates a teacher. Secondly, we use experiences not only once but store and reuse them later on when their value is easier to assess. Finally, we utilize function approximators in order to represent the experience in a way that balances between generalization and discrimination. We evaluate the performance of the combined extensions of plain RL using a humanoid robot in the RoboCup soccer domain. As we show in simulation and real-world experiments, our approach enables the robot to quickly learn fundamental soccer skills.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74024-7_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-72383-7_88,Generalized Dynamic Fuzzy Neural Network-Based Tracking Control of Robot Manipulators,Advances in Neural Networks – ISNN 2007,10.1007/978-3-540-72383-7_88,Springer,2007-01-01,"A robust adaptive control based on generalized dynamic fuzzy neural network (GD-FNN) is presented for robot manipulators. Fuzzy control rules can be generated or deleted automatically according to their significance to the control system, and no predefined fuzzy rules are required. Being use of radial basis function neural network (RBFNN) the learning speed is very fast. The asymptotic stability of the control system is established using Lyapunov theorem. Simulations are given for a two-link robot in the end of paper, and validated the control arithmetic.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-72383-7_88,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74913-4_33,Improving Search Efficiency in the Action Space of an Instance-Based Reinforcement Learning Technique for Multi-robot Systems,Advances in Artificial Life,10.1007/978-3-540-74913-4_33,Springer,2007-01-01,"We have developed a new reinforcement learning technique called Bayesian-discrimination-function-based reinforcement learning (BRL). BRL is unique, in that it not only learns in the predefined state and action spaces, but also simultaneously changes their segmentation. BRL has proven to be more effective than other standard RL algorithms in dealing with multi-robot system (MRS) problems, where the learning environment is naturally dynamic. This paper introduces an extended form of BRL that improves its learning efficiency. Instead of generating a random action when a robot encounters an unknown situation, the extended BRL generates an action calculated by a linear interpolation among the rules with high similarity to the current sensory input. In both physical experiments and computer simulations, the extended BRL showed higher search efficiency than the standard BRL.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74913-4_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-72588-6_12,Multi-robot Cooperation Based on Hierarchical Reinforcement Learning,Computational Science – ICCS 2007,10.1007/978-3-540-72588-6_12,Springer,2007-01-01,"Multi-agent reinforcement learning for multi-robot systems is a challenging issue in both robotics and artificial intelligence. But multi-agent reinforcement learning is bedeviled by the curse of dimensionality. In this paper, a novel hierarchical reinforcement learning approach named MOMQ is presented for multi-robot cooperation. The performance of MOMQ is demonstrated in three-robot trash collection task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-72588-6_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-72383-7_97,Appearance-Based Map Learning for Mobile Robot by Using Generalized Regression Neural Network,Advances in Neural Networks – ISNN 2007,10.1007/978-3-540-72383-7_97,Springer,2007-01-01,"Regression analysis between features of high-dimension is receiving attention in environmental learning of mobile robot. In this paper, we propose a novel framework, namely General regression neural network (GRNN), for approximating the functional relationship between high-dimensional map features and robot’s states. We firstly adopt PCA to preprocess images taken from omnidirenctional vision. The method extracts map features optimally and reduces the correlated features while keeping the minimum reconstruction error. Then, the robot states and corresponding features of the training panoramic snapshots are used to train the given neural network. This enables robot to memorize the environmental features as well as to predict available scene given its location information. Experimental results are shown finally.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-72383-7_97,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-77296-5_31,A Human-Like Robot Torso ZAR5 with Fluidic Muscles: Toward a Common Platform for Embodied AI,50 Years of Artificial Intelligence,10.1007/978-3-540-77296-5_31,Springer,2007-01-01,"“Without embodiment artificial intelligence is nothing.” Algorithms in the field of artificial intelligence are mostly tested on a computer instead of testing on a real platform. Our anthropomorphic robot ZAR5 (in German Zwei-Arm-Roboter in the 5^th version) is the first biologically inspired and completely artificial muscle driven robot torso that can be fully controlled by a data suit and two five finger data gloves. The underlying biological principles of sensor technology, signal processing, control architecture und actuator technology of our robot platform meet the requirements of biological based technical realization and support a distributed programming and control as well as an online self-adaptation and relearning processing. The following elaboration focuses on biological inspiration for the embodiment of artificial intelligence, gives a short insight into technical realisation of a humanoid robot, which is of high importance in this context, and accentuates highlights relating to a possible paradigm shift in artificial intelligence.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-77296-5_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-74972-1_24,Evolution of Neuro-controllers for Multi-link Robots,Innovations in Hybrid Intelligent Systems,10.1007/978-3-540-74972-1_24,Springer,2007-01-01,"A general method to learn the inverse kinematics of multi-link robots by means of neuro-controllers is presented. We can find analytical solutions for the most used and known robots in the bibliography. However, these solutions are specific to a particular robot configuration and are not generally applicable to other robot morphologies. The proposed method is general in the sense that it is not dependant on the robot morphology. We base our method in the Evolutionary Computation paradigm for obtaining incrementally better neuro-controllers. Furthermore, the proposed method solves some very specific issues in robotic neuro-controller learning. (1) It allows to escape from any neural network learning algorithm which relies on the classical supervised input-target learning scheme and hence it lets to obtain neuro-controllers without providing targets or correct answers which -in this case- are un known in prior. (2) It can converge beyond local optimal solutions which is one of the main drawbacks of some neural-network training algorithms based on gradient descent when applied to highly redundant robot morphologies. (3) Using learning algorithms such as the Neuro-Evolution of Augmenting Topologies (NEAT) it is also possible learning the neural network topology on-the-fly which is a common source of empirical testing in neuro-controllers design. Finally, experimental results are provided by applying the method in two multi-link robot learning tasks with a comparison between fixed and learnable topologies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74972-1_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-73424-6_8,Using Learned Features from 3D Data for Robot Navigation,Autonomous Robots and Agents,10.1007/978-3-540-73424-6_8,Springer,2007-01-01,"We describe a novel method for classifying terrain in unstructured, natural environments for the purpose of aiding mobile robot navigation. This method operates on range data provided by stereo without the traditional preliminary extraction of geometric features such as height and slope, replacing these measurements with 2D histograms representing the shape and permeability of objects within a local region. A convolutional neural network is trained to categorize the histogram samples according to the traversability of the terrain they represent for a small mobile robot. In live and offline testing in a wide variety of environments, it demonstrates state-of-the-art performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-73424-6_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-73424-6_22,Autonomous Stride-Frequency and Step-Length Adjustment for Bipedal Walking Control,Autonomous Robots and Agents,10.1007/978-3-540-73424-6_22,Springer,2007-01-01,"This work focuses on the stride-frequency and step-length autonomous adjustment in response to the environment perturbations. Reinforcement learning is assigned to supervise the stride-frequency. A simple momentum estimation further promised the adjustment. In the learning agent, a sorted action-choose table instructed the learning to find out the proper action in a straightforward way. Incorporating the step-length real-time adjustment mode, the biped is able to smoothly transit motions and walk adaptively to the environment. Dynamic simulation results showed that the supervision is effective.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-73424-6_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-73422-2_2,Optical Flow Approaches for Self-supervised Learning in Autonomous Mobile Robot Navigation,Autonomous Navigation in Dynamic Environments,10.1007/978-3-540-73422-2_2,Springer,2007-01-01,"A common theme in autonomous mobile robotics is the desire to sense farther ahead of the robot than current approaches allow. This greater range would enable earlier recognition of hazards, better path planning, and higher speeds. In scenarios where the long range sensor modality is computer vision this has led to interest in developing techniques that can effectively identify and respond to obstacles at greater distances than those for which stereo vision methods are useful. This paper presents work on optical flow techniques that leverage the difference in appearance between objects at close range and the same objects at more distant locations in order to interpret monocular video streams in a useful manner. In particular, two applications are discussed: self-supervised off-road autonomous navigation, and adaptive road following in unstructured environments. Examples of the utility of the optical flow techniques discussed here in both arenas are provided.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-73422-2_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-72393-6_21,State Space Partition for Reinforcement Learning Based on Fuzzy Min-Max Neural Network,Advances in Neural Networks – ISNN 2007,10.1007/978-3-540-72393-6_21,Springer,2007-01-01,"In this paper, a tabular reinforcement learning (RL) method is proposed based on improved fuzzy min-max (FMM) neural network. The method is named FMM-RL. The FMM neural network is used to segment the state space of the RL problem. The aim is to solve the “curse of dimensionality” problem of RL. Furthermore, the speed of convergence is improved evidently. Regions of state space serve as the hyperboxes of FMM. The minimal and maximal points of the hyperbox are used to define the state space partition boundaries. During the training of FMM neural network, the state space is partitioned via operations on hyperbox. Therefore, a favorable generalization performance of state space can be obtained. Finally, the method of this paper is applied to learn behaviors for the reactive robot. The experiment shows that the algorithm can effectively solve the problem of navigation in a complicated unknown environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-72393-6_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74913-4_77,Guided Self-organisation for Autonomous Robot Development,Advances in Artificial Life,10.1007/978-3-540-74913-4_77,Springer,2007-01-01,"The paper presents a method to guide the self-organised development of behaviours of autonomous robots. In earlier publications we demonstrated how to use the homeokinesis principle and dynamical systems theory to obtain self-organised playful but goal-free behaviour. Now we extend this framework by reinforcement signals. We validate the mechanisms with two experiment with a spherical robot. The first experiment aims at fast motion, where the robot reaches on average about twice the speed of a not reinforcement robot. In the second experiment spinning motion is rewarded and we demonstrate that the robot successfully develops pirouettes and curved motion which only rarely occur among the natural behaviours of the robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74913-4_77,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74205-0_21,Usage of Hybrid Neural Network Model MLP-ART for Navigation of Mobile Robot,Advanced Intelligent Computing Theories and Applications. With Aspects of Artificial Intelligence,10.1007/978-3-540-74205-0_21,Springer,2007-01-01,We suggest to apply the hybrid neural network based on multi layer perceptron (MLP) and adaptive resonance theory (ART-2) for solving of navigation task of mobile robots. This approach provides semi supervised learning in unknown environment with incremental learning inherent to ART and capability of adaptation to transformation of images inherent to MLP. Proposed approach is evaluated in experiments with program model of robot.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74205-0_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74695-9_68,Event Detection and Localization in Mobile Robot Navigation Using Reservoir Computing,Artificial Neural Networks – ICANN 2007,10.1007/978-3-540-74695-9_68,Springer,2007-01-01,"Reservoir Computing (RC) uses a randomly created recurrent neural network where only a linear readout layer is trained. In this work, RC is used for detecting complex events in autonomous robot navigation. This can be extended to robot localization based solely on sensory information. The robot thus builds an implicit map of the environment without the use of odometry data. These techniques are demonstrated in simulation on several complex and even dynamic environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74695-9_68,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74913-4_40,Evolution of Acoustic Communication Between Two Cooperating Robots,Advances in Artificial Life,10.1007/978-3-540-74913-4_40,Springer,2007-01-01,"In this paper we describe a model in which artificial evolution is employed to design neural mechanisms that control the motion of two autonomous robots required to communicate through sound to perform a common task. The results of this work are a “proof-of-concept”: they demonstrate that evolution can exploit a very simple sound communication system, to design the mechanisms that allow the robots cooperate by employing acoustic interactions. The analysis of the evolved strategies uncover the basic properties of the communication protocol.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74913-4_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-4-431-35873-2_7,Multi-Robot Concurrent Learning in Museum Problem,Distributed Autonomous Robotic Systems 6,10.1007/978-4-431-35873-2_7,Springer,2007-01-01,"Multi-robot concurrent learning on how to cooperatively work through the interaction with the environment is one of the ultimate goals in robotics and artificial intelligence research. In this paper, we introduce a distributed multi-robot learning algorithm that integrates reinforcement learning and neural networks (weighting network). By retrieving continuous environment state and implicit feedback (reward), the robots can generate appropriate behaviors without deliberative hard coding. We test the learning algorithm in the “museum” problem, in which robots collaboratively track moving targets. Simulation results demonstrate the efficacy of our learning algorithms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-4-431-35873-2_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-71629-7_77,Neural Network Control for Visual Guidance System of Mobile Robot,Adaptive and Natural Computing Algorithms,10.1007/978-3-540-71629-7_77,Springer,2007-01-01,"This paper describes a neural network control for a visual guidance system of a mobile robot to follow a guideline. Without complicated geometric reasoning from the image of a guideline to the robot-centered representation of a bird’s eye view in conventional studies, the proposed system transfers the input of image information into the output of a steering angle directly. The neural network controller replaces the nonlinear relation of image information to a steering angle of robot on the real ground. For image information, the feature points of guideline are extracted from a camera image. In a straight and curved guideline, the driving performances by the proposed technology are measured in simulation and experimental test.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-71629-7_77,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-49720-2_8,A Hybrid Adaptive Architecture for Mobile Robots Based on Reactive Behaviours,Mobile Robots: The Evolutionary Approach,10.1007/978-3-540-49720-2_8,Springer,2007-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-49720-2_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74769-7_6,A Novel Neural Network Based Reinforcement Learning,Bio-Inspired Computational Intelligence and Applications,10.1007/978-3-540-74769-7_6,Springer,2007-01-01,"Many function-approaching methods such as neural network, fuzzy method are used in reinforcement learning methods for solving its huge problem space dimensions. This paper presents a novel ART2 neural network based reinforcement learning method (ART2-RL) to solve the space problem. Because of its adaptive resonance characteristic, ART2 neural network is used to process the space measurement of reinforcement learning and improve the learning speed. This paper also gives the reinforcement learning algorithm based on ART2. A simulation of path planning of mobile robot has been developed to prove the validity of ART2-RL. As the complexity of the simulation increased, the result shows that the number of collision between robot and obstacles is effectively decreased; the novel neural network model provides significant improvement in the space measurement of reinforcement learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74769-7_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74205-0_105,Research of the Fault Diagnosis Method for the Thruster of AUV Based on Information Fusion,Advanced Intelligent Computing Theories and Applications. With Aspects of Artificial Intelligence,10.1007/978-3-540-74205-0_105,Springer,2007-01-01,"Aiming at the problem of thruster fault diagnosis of AUV, the motion condition model of AUV based on the improved dynamic recursive Elman neural network, and the performance model of thruster based on the Radial Basis Function network were established. And the fault fusion diagnosis method was proposed according to the overall and local fault detection. Through comparing the output value of motion condition model with the measured value of actual speed and angle, it obtained the overall fault information. Also, it obtained the direct fault information through analyzing the residual which was produced by comparing the output of the performance model with the measured value of the actual voltage and current of the each thruster. According to the decision level information fusion of two kinds of information, it realized the fault diagnosis of thrusters and analyzed the fault degree and reliability. The results of the fault-simulation experiment show that the proposed fault fusion diagnosis method for the thruster of AUV is feasible and effective.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74205-0_105,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-72383-7_100,Hybrid Force and Position Control of Robotic Manipulators Using Passivity Backstepping Neural Networks,Advances in Neural Networks – ISNN 2007,10.1007/978-3-540-72383-7_100,Springer,2007-01-01,"This paper presents a method of force/position control by using the backstepping and passivity strict-feedback neural networks technique; passivity monitor can evaluate stability of a system based on the concept of passivity. The parameters estimation for the design is made by the neural networks technology, using the decouple method and matrix transforming technology, decomposing the robot system as the position subsystem and the force subsystem, then the control law of these subsystems are designed respectively. The results obtained are satisfactory by using hybrid force and position control, the error is negligible and the global stability of the system can also be obtained.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-72383-7_100,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4020-6264-3_80,Q-Learning based Univector Field Navigation Method for Mobile Robots,"Advances and Innovations in Systems, Computing Sciences and Software Engineering",10.1007/978-1-4020-6264-3_80,Springer,2007-01-01,"In this paper, the Q-Learning based univector field method is proposed for mobile robot to accomplish the obstacle avoidance and the robot orientation at the target position. Univector field method guarantees the desired posture of the robot at the target position. But it does not navigate the robot to avoid obstacles. To solve this problem, modified univector field is used and trained by Q-learning. When the robot following the field to get the desired posture collides with obstacles, univector fields at collision positions are modified according to the reinforcement of Q-learning algorithm. With this proposed navigation method, robot navigation task in a dynamically changing environment becomes easier by using double action Q-learning [8] to train univector field instead of ordinary Q-learning. Computer simulations and experimental results are carried out for an obstacle avoidance mobile robot to demonstrate the effectiveness of the proposed scheme.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4020-6264-3_80,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-73325-6_29,Self-organizing Multiple Models for Imitation: Teaching a Robot to Dance the YMCA,New Trends in Applied Artificial Intelligence,10.1007/978-3-540-73325-6_29,Springer,2007-01-01,"The traditional approach to implement motor behaviour in a robot required a programmer to carefully decide the joint velocities at each timestep. By using the principle of learning by imitation, the robot can instead be taught simply by showing it what to do. This paper investigates the self-organization of a connectionist modular architecture for motor learning and control that is used to imitate human dancing. We have observed that the internal representation of a motion behaviour tends to be captured by more than one module. This supports the hypothesis that a modular architecture for motor learning is capable of self-organizing the decomposition of a movement.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-73325-6_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-006-9103-z,Fuzzy Policy Reinforcement Learning in Cooperative Multi-robot Systems,Journal of Intelligent and Robotic Systems,10.1007/s10846-006-9103-z,Springer,2007-01-01,"A multi-agent reinforcement learning algorithm with fuzzy policy is addressed in this paper. This algorithm is used to deal with some control problems in cooperative multi-robot systems. Specifically, a leader-follower robotic system and a flocking system are investigated. In the leader-follower robotic system, the leader robot tries to track a desired trajectory, while the follower robot tries to follow the reader to keep a formation. Two different fuzzy policies are developed for the leader and follower, respectively. In the flocking system, multiple robots adopt the same fuzzy policy to flock. Initial fuzzy policies are manually crafted for these cooperative behaviors. The proposed learning algorithm finely tunes the parameters of the fuzzy policies through the policy gradient approach to improve control performance. Our simulation results demonstrate that the control performance can be improved after the learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-006-9103-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-72383-7_83,Obstacle Avoidance Path Planning for Mobile Robot Based on Ant-Q Reinforcement Learning Algorithm,Advances in Neural Networks – ISNN 2007,10.1007/978-3-540-72383-7_83,Springer,2007-01-01,"Path planning is an important task in mobile robot control. When the robot must move rapidly from any arbitrary start positions to any target positions in environment, a proper path must avoid both static obstacles and moving obstacles of arbitrary shape. In this paper, an obstacle avoidance path planning approach for mobile robots is proposed by using Ant-Q algorithm. Ant-Q is an algorithm in the family of ant colony based methods that are distributed algorithms for combinatorial optimization problems based on the metaphor of ant colonies. In the simulation, we experimentally investigate the sensitivity of the Ant-Q algorithm to its three methods of delayed reinforcement updating and we compare it with the results obtained by other heuristic approaches based on genetic algorithm or traditional ant colony system. At last, we will show very good results obtained by applying Ant-Q to bigger problem: Ant-Q find very good path at higher convergence rate.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-72383-7_83,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74913-4_30,Evolution and Learning in an Intrinsically Motivated Reinforcement Learning Robot,Advances in Artificial Life,10.1007/978-3-540-74913-4_30,Springer,2007-01-01,"Studying the role played by evolution and learning in adaptive behavior is a very important topic in artificial life research. This paper investigates the interplay between learning and evolution when agents have to solve several different tasks, as it is the case for real organisms but typically not for artificial agents. Recently, an important thread of research in machine learning and developmental robotics has begun to investigate how agents can solve different tasks by composing general skills acquired on the basis of internal motivations. This work presents a hierarchical, neural-network, actor-critic architecture designed for implementing this kind of intrinsically motivated reinforcement learning in real robots. We compare the results of several experiments in which the various components of the architecture are either trained during lifetime or evolved through a genetic algorithm. The most important results show that systems using both evolution and learning outperform systems using either one of the two, and that, among the former, systems evolving internal reinforcers for learning building-block skills have a higher evolvability than those directly evolving the related behaviors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74913-4_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4020-5626-0_21,Direct Gradient-Based Reinforcement Learning for Robot Behavior Learning,"Informatics in Control, Automation and Robotics II",10.1007/978-1-4020-5626-0_21,Springer,2007-01-01,"Autonomous Underwater Vehicles (AUV) represent a challenging control problem with complex, noisy, dynamics. Nowadays, not only the continuous scientific advances in underwater robotics but the increasing number of sub sea missions and its complexity ask for an automatization of submarine processes. This paper proposes a high-level control system for solving the action selection problem of an autonomous robot. The system is characterized by the use of Reinforcement Learning Direct Policy Search methods (RLDPS) for learning the internal state/action mapping of some behaviors. We demonstrate its feasibility with simulated experiments using the model of our underwater robot URIS in a target following task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4020-5626-0_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74171-8_42,Cooperation Between Multiple Agents Based on Partially Sharing Policy,Advanced Intelligent Computing Theories and Applications. With Aspects of Theoretical and Methodological Issues,10.1007/978-3-540-74171-8_42,Springer,2007-01-01,"In human society, learning is essential to intelligent behavior. However, people do not need to learn everything from scratch by their own discovery. Instead, they exchange information and knowledge with one another and learn from their peers and teachers. When a task is too complex for an individual to handle, one may cooperate with its partners in order to accomplish it. Like human society, cooperation exists in the other species, such as ants that are known to communicate about the locations of food and move it cooperatively. Using the experience and knowledge of other agents, a learning agent may learn faster, make fewer mistakes, and create rules for unstructured situations. In the proposed learning algorithm, an agent adapts to comply with its peers by learning carefully when it obtains a positive reinforcement feedback signal, but should learn more aggressively if a negative reward follows the action just taken. These two properties are applied to develop the proposed cooperative learning method conceptually. The algorithm is implemented in some cooperative tasks and demonstrates that agents can learn to accomplish a task together efficiently through a repetitive trials.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74171-8_42,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74024-7_8,Autonomous Learning of Ball Trapping in the Four-Legged Robot League,RoboCup 2006: Robot Soccer World Cup X,10.1007/978-3-540-74024-7_8,Springer,2007-01-01,"This paper describes an autonomous learning method used with real robots in order to acquire ball trapping skills in the four-legged robot league. These skills involve stopping and controlling an oncoming ball and are essential to passing a ball to each other. We first prepare some training equipment and then experiment with only one robot. The robot can use our method to acquire these necessary skills on its own, much in the same way that a human practicing against a wall can learn the proper movements and actions of soccer on his/her own. We also experiment with two robots, and our findings suggest that robots communicating between each other can learn more rapidly than those without any communication.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74024-7_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-77002-2_43,Generalization and Transfer Learning in Noise-Affected Robot Navigation Tasks,Progress in Artificial Intelligence,10.1007/978-3-540-77002-2_43,Springer,2007-01-01,"When a robot learns to solve a goal-directed navigation task with reinforcement learning, the acquired strategy can usually exclusively be applied to the task that has been learned. Knowledge transfer to other tasks and environments is a great challenge, and the transfer learning ability crucially depends on the chosen state space representation. This work shows how an agent-centered qualitative spatial representation can be used for generalization and knowledge transfer in a simulated robot navigation scenario. Learned strategies using this representation are very robust to environmental noise and imprecise world knowledge and can easily be applied to new scenarios, offering a good foundation for further learning tasks and application of the learned policy in different contexts.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-77002-2_43,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-4-431-35873-2_6,Adaptive Routing System by Intelligent Environment with Media Agents,Distributed Autonomous Robotic Systems 6,10.1007/978-4-431-35873-2_6,Springer,2007-01-01,"In this paper, we consider a distributed robotic system that includes special agents that convey the information. We address the issue of selecting one course from two;a long one-way detour or a short two-way path on which traffic jams may occur. We consider a system in which the environment, instead of mobile agents, learns feasible parameters for task execution. To correct problems with this system and improve it we introduce media agents that carry data for the learning. They adjust information flow. We formulate the system and evaluate its performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-4-431-35873-2_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74262-3_15,Anticipating Rewards in Continuous Time and Space: A Case Study in Developmental Robotics,Anticipatory Behavior in Adaptive Learning Systems,10.1007/978-3-540-74262-3_15,Springer,2007-01-01,"This paper presents the first basic principles, implementation and experimental results of what could be regarded as a new approach to reinforcement learning, where agents—physical robots interacting with objects and other agents in the real world—can learn to anticipate rewards using their sensory inputs. Our approach does not need discretization, notion of events, or classification, and instead of learning rewards for the different possible actions of an agent in all the situations, we propose to make agents learn only the main situations worth avoiding and reaching. However, the main focus of our work is not reinforcement learning as such, but modeling cognitive development on a small autonomous robot interacting with an “adult” caretaker, typically a human, in the real world; the control architecture follows a Perception-Action approach incorporating a basic homeostatic principle. This interaction occurs in very close proximity, uses very coarse and limited sensory-motor capabilities, and affects the “well-being” and affective state of the robot. The type of anticipatory behavior we are concerned with in this context relates to both sensory and reward anticipation. We have applied and tested our model on a real robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74262-3_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-68916-4_1,Cybernetic View of Robot Cognition and Perception,Robot Cognition and Navigation,10.1007/978-3-540-68916-4_1,Springer,2007-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-68916-4_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-71431-6_36,Reconfigurable Hardware Evolution Platform for a Spiking Neural Network Robotics Controller,"Reconfigurable Computing: Architectures, Tools and Applications",10.1007/978-3-540-71431-6_36,Springer,2007-01-01,"This paper describes a platform for the hardware evolution of Spiking Neural Network (SNN) based robotics controllers on multiple Field Programmable Analogue Arrays (FPAAs). The SNN robotics controller, evolved using a GA, performs obstacle avoidance and navigation. A robotics simulator is used to evaluate the performance of the evolved hardware SNN. Simulated sonar data is input to FPAA neurons and the SNN returns motor control data to the simulator. Initial results indicate the emergence of effective navigation behavior.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-71431-6_36,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4020-6264-3_10,Modelling non Measurable Processes by Neural Networks: Forecasting Underground Flow Case Study of the Céze Basin (Gard - France),"Advances and Innovations in Systems, Computing Sciences and Software Engineering",10.1007/978-1-4020-6264-3_10,Springer,2007-01-01,"After a presentation of the nonlinear properties of neural networks, their applications to hydrology are described. A neural predictor is satisfactorily used to estimate a flood peak. The main contribution of the paper concerns an original method for visualising a hidden underground flow Satisfactory experimental results were obtained that fitted well with the knowledge of local hydrogeology, opening up an interesting avenue for modelling using neural networks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4020-6264-3_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-73007-1_97,Emerging Behaviors by Learning Joint Coordination in Articulated Mobile Robots,Computational and Ambient Intelligence,10.1007/978-3-540-73007-1_97,Springer,2007-01-01,"A Policy Gradient Reinforcement Learning (RL) technique is used to design the low level controllers that drives the joints of articulated mobile robots: A search in the controller’s parameters space. There is an unknown value function that measures the quality of the controller respect to the parameters of it. The search is orientated by the approximation of the gradient of the value function. The approximation is made by means of the robot experiences and then the behaviors emerge. This technique is employed in a structure that processes sensor information to achieve coordination. The structure is based on a modularization principle in which complex overall behavior is the result of the interaction of individual ‘simple’ components. The simple components used are standard low level controllers (PID) which output is combined, sharing information between articulations and therefore taking integrated control actions. Modularization and Learning are cognitive features, here we endow the robots with this features. Learning experiences in simulated robots are presented as demonstration.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-73007-1_97,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-77002-2_44,Heuristic Q-Learning Soccer Players: A New Reinforcement Learning Approach to RoboCup Simulation,Progress in Artificial Intelligence,10.1007/978-3-540-77002-2_44,Springer,2007-01-01,"This paper describes the design and implementation of a 4 player RoboCup Simulation 2D team, which was build by adding Heuristic Accelerated Reinforcement Learning capabilities to basic players of the well-known UvA Trilearn team. The implemented agents learn by using a recently proposed Heuristic Reinforcement Learning algorithm, the Heuristically Accelerated Q –Learning (HAQL), which allows the use of heuristics to speed up the well-known Reinforcement Learning algorithm Q –Learning. A set of empirical evaluations was conducted in the RoboCup 2D Simulator, and experimental results obtained while playing with other teams shows that the approach adopted here is very promising.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-77002-2_44,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-71441-5_38,Obstacle Recognition and Collision Avoidance of a Fish Robot Based on Fuzzy Neural Networks,Fuzzy Information and Engineering,10.1007/978-3-540-71441-5_38,Springer,2007-01-01,"Detection and recognition of obstacles are the most important concerns for fish robots to avoid collision for path planning as well as natural and smooth movements. The more information about obstacle shapes we obtain, the better control of fish robots we can apply. The method employing only simple distance measuring sensors without cameras is proposed. We use three fixed IR sensors and one IR sensor, which is mounted on a motor shaft to scan a certain range of foreground from the head of a fish robot. The fish robot’s ability to recognize the features of an obstacle is improved to avoid collision based on the fuzzy neural networks. Evident features such as obstacles’ sizes and angles are obtained from the scanned data by a simple distance sensor through neural network training algorithms. Experimental results show the successful path control of the fish robot without hitting on obstacles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-71441-5_38,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-77296-5_13,AI in Locomotion: Challenges and Perspectives of Underactuated Robots,50 Years of Artificial Intelligence,10.1007/978-3-540-77296-5_13,Springer,2007-01-01,"This article discusses the issues of adaptive autonomous navigation as a challenge of artificial intelligence. We argue that, in order to enhance the dexterity and adaptivity in robot navigation, we need to take into account the decentralized mechanisms which exploit physical system-environment interactions. In this paper, by introducing a few underactuated locomotion systems, we explain (1) how mechanical body structures are related to motor control in locomotion behavior, (2) how a simple computational control process can generate complex locomotion behavior, and (3) how a motor control architecture can exploit the body dynamics through a learning process. Based on the case studies, we discuss the challenges and perspectives toward a new framework of adaptive robot control.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-77296-5_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-77296-5_26,A Paradigm Shift in Artificial Intelligence: Why Social Intelligence Matters in the Design and Development of Robots with Human-Like Intelligence,50 Years of Artificial Intelligence,10.1007/978-3-540-77296-5_26,Springer,2007-01-01,"The chapter discusses a recent paradigm shift in the field of Artificial Intelligence regarding the nature of human intelligence and its implications for the design and development of intelligent robots. It will be argued that social intelligence is not a mere ‘add-on’ to intelligent robot behaviour for the practical purpose of enabling the robot to interact smoothly with other robots or people, but that social intelligence might be a stepping stone towards more human-like, embodied artificial intelligence. The argument is supported by discussions in primatology highlighting the social origins of primate intelligence. The chapter also discusses challenges and opportunities provided by socially intelligent robots, with implications for our future.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-77296-5_26,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74771-0_61,Repetitive Motion Planning of Redundant Robots Based on LVI-Based Primal-Dual Neural Network and PUMA560 Example,Life System Modeling and Simulation,10.1007/978-3-540-74771-0_61,Springer,2007-01-01,"A primal-dual neural network based on linear variational inequalities (LVI) is presented in this paper, which is used to solve the repetitive motion planning of redundant robots. To do so, a drift-free criterion is exploited. In addition, the physical constraints such as joint limits and joint velocity limits are incorporated into the problem formulation of such a scheme. The scheme is finally reformulated as a quadratic programming (QP) problem and resolved at the velocity-level. Compared to other computational strategies on inverse kinematics, the LVI-based primal-dual neural network is designed based on the QP-LVI conversion and Karush-Kuhn-Tucker (KKT) conditions. With simple piecewise-linear dynamics and global (exponential) convergence to optimal solutions, it can handle general QP and linear programming (LP) problems in the same inverse-free manner. The repetitive motion planning scheme and the LVI-based primal-dual neural network are simulated based on PUMA560 robot manipulator with effectiveness demonstrated.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74771-0_61,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-72383-7_85,Attention Selection with Self-supervised Competition Neural Network and Its Applications in Robot,Advances in Neural Networks – ISNN 2007,10.1007/978-3-540-72383-7_85,Springer,2007-01-01,"This paper proposes a novel attention selection system with competition neural network supervised by visual memory. As compared with others, this system can not only attend some salient regions randomly according to sensory information but also mainly focus on some learned objects by the visual memory. So it can be applied in robot self-localization or object tracking. The weights of neural networks can be adapted in real time to environment change.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-72383-7_85,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-72383-7_94,Neural Network-Based Robust Tracking Control for Nonholonomic Mobile Robot,Advances in Neural Networks – ISNN 2007,10.1007/978-3-540-72383-7_94,Springer,2007-01-01,"A robust tracking controller with bound estimation based on neural network is proposed to deal with the unknown factors of nonholonomic mobile robot, such as model uncertainties and external disturbances. The neural network is to approximate the uncertainties terms and the interconnection weights of the neural network can be tuned online. And the robust controller is designed to compensate for the approximation error. Moreover, an adaptive estimation algorithm is employed to estimate the bound of the approximation error. The stability of the proposed controller is proven by Lyapunov function. The proposed neural network-based robust tracking controller can overcome the uncertainties and the disturbances. The simulation results demonstrate that the proposed method has good robustness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-72383-7_94,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-72383-7_98,Design of Quadruped Robot Based Neural Network,Advances in Neural Networks – ISNN 2007,10.1007/978-3-540-72383-7_98,Springer,2007-01-01,"The paper proposed a method for a quadruped robot control system based Central Pattern Generator (CPG) and fuzzy neural networks (FNN). The common approach for the control of a quadruped robot includes two methods mainly. One is the CPG that is based the bionics, the other is the dynamic control that is based the model of quadruped robot. The control result of CPG is decided by the gait data of the quadruped and the parameters of the CPG are choosing manually. Modeling a quadruped robot is difficult because it is a high nonlinear system. This paper presents a much simpler method for the control of a quadruped robot. A simple CPG is adopted for a timing oscillator; it generates the motion periodic pattern of legs. The FNN is used to control the joint motion in order to get a desired stable trajectory motion.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-72383-7_98,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-77296-5_3,Fifty Years of AI: From Symbols to Embodiment - and Back,50 Years of Artificial Intelligence,10.1007/978-3-540-77296-5_3,Springer,2007-01-01,"There are many stories to tell about the first fifty years of AI. One story is about AI as one of the big forces of innovation in information technology. It is now forgotten that initially computers were just viewed as calculating machines. AI has moved that boundary, by projecting visions on what might be possible, and by building technologies to realise them. Another story is about the applications of AI. Knowledge systems were still a rarity in the late seventies but are now everywhere, delivered through the web. Knowledge systems routinely deal with financial and legal problem solving, diagnosis and maintenance of power plants and transportation networks, symbolic mathematics, scheduling, etc. The innovative aspects of search engines like Google are almost entirely based on the information extraction, data mining, semantic networks and machine learning techniques pioneered in AI. Popular games like SimCity are straightforward applications of multi-agent systems. Sophisticated language processing capacities are now routinely embedded in text processing systems like Microsoft’s Word. Tens of millions of people use AI technology every day, often without knowing it or without wondering how these information systems can do all these things. In this essay I will focus however on another story: AI as a contributor to the scientific study of mind.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-77296-5_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-68803-7_3,Neural Concepts and Modeling,Neural Preprocessing and Control of Reactive Walking Machines,10.1007/978-3-540-68803-7_3,Springer,2007-01-01,"This chapter presents methods and tools which are to be used throughout this book. It starts with a short introduction to a biological neuron together with an artificial neuron which is followed by the comparison of network structures between feedforward and recurrent neural networks. Then the discrete-time dynamical properties of the single neuron with a recurrent connection are described. Finally, artificial evolution is presented as a tool to develop and optimize neural structures as well as the strength of synapses.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-68803-7_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-72383-7_70,An Occupancy Grids Building Method with Sonar Sensors Based on Improved Neural Network Model,Advances in Neural Networks – ISNN 2007,10.1007/978-3-540-72383-7_70,Springer,2007-01-01,"This paper presents an improved neural network model interpretating sonar readings to build occupancy grids of mobile robot. The proposed model interprets sensor readings in the context of their space neighbors and relevant successive history readings simultaneously. Consequently the presented method can greatly weaken the effects by multiple reflections or specular reflection. The output of the neural network is the probability vector of three possible status(empty, occupancy, uncertainty) for the cell. As for sensor readings integration, three probabilities of cell’s status are updated by the Bayesian update formula respectively, and the final status of cell is defined by Max-Min principle.Experiments performed in lab environment has shown occupancy map built by proposed approach is more consistent, accurate and robust than traditional method while it still could be conducted in real time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-72383-7_70,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-72383-7_95,Enhance Computational Efficiency of Neural Network Predictive Control Using PSO with Controllable Random Exploration Velocity,Advances in Neural Networks – ISNN 2007,10.1007/978-3-540-72383-7_95,Springer,2007-01-01,"NNPC has been used widely to control nonlinear systems. However traditional gradient decent algorithm (GDA) needs a large computational cost, so that NNPC is not acceptable for systems with rapid dynamics. To apply NNPC in fast control of mobile robots, the paper proposes an improved optimization technique, particle swarm optimization with controllable random exploration velocity (PSO-CREV), to replace of GDA in NNPC. Therefore for one cycle of control, PSO-CREV needs less iterations than GDA, and less population size than conventional PSO. Hence the computational cost of NNPC is reduced by using PSO-CREV, so that NNPC using PSO-CREV is more feasible for the control of rapid processes. As an example, a test of trajectory tracking using mobile robots is chosen to compare performance of PSO-CREV with other algorithms to show its advantages, especially on the aspect of computational time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-72383-7_95,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-71541-2_14,Scalability in Evolved Neurocontrollers That Guide a Swarm of Robots in a Navigation Task,Swarm Robotics,10.1007/978-3-540-71541-2_14,Springer,2007-01-01,"Generally speaking, the behavioural strategies of a multi-robot system can be defined as scalable if the performance of the system does not drop by increasing the cardinality of the group. The research work presented in this paper studies the issue of scalability in artificial neural network controllers designed by evolutionary algorithms. The networks are evolved to control homogeneous group of autonomous robots required to solve a navigation task in an open arena. This work shows that, the controllers designed to solve the task, generate navigation strategies which are potentially scalable. However, through an analysis of the dynamics of the single robot controller we identify elements that significantly hinder the scalability of the system. The analysis we present in this paper helps to understand the principles underlying the concepts of scalability in this kind of multi-robot systems and to design more scalable solutions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-71541-2_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-72696-8_1,Intelligent Machines: An Introduction,Innovations in Intelligent Machines - 1,10.1007/978-3-540-72696-8_1,Springer,2007-01-01,"In this chapter, an introduction to intelligent machine is presented. An explanation on intelligent behavior, and the difference between intelligent and repetitive natural or programmed behavior is provided. Some learning techniques in the field of Artificial Intelligence in constructing intelligent machines are then discussed. In addition, applications of intelligent machines to a number of areas including aerial navigation, ocean and space exploration, and humanoid robots are presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-72696-8_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74205-0_5,Gait Parameters Optimization and Real-Time Trajectory Planning for Humanoid Robots,Advanced Intelligent Computing Theories and Applications. With Aspects of Artificial Intelligence,10.1007/978-3-540-74205-0_5,Springer,2007-01-01,"Trajectory planning of humanoid robots not only is required to satisfy kinematic constraints, but also other criteria such as staying balance, having desirable upper and lower postures, having smooth movement etc, is needed to maintain certain properties. In this paper, calculation formulas of driving torque for each joint of humanoid robot are derived based on dynamics equation, mathematic models for gait parameters optimization are established via introducing energy consumption indexes. gait parameters are optimized utilizing genetic algorithm. A new approach for real-time trajectory planning of humanoid robots is proposed based on fuzzy neural network (FNN), Zero Moment Point (ZMP) criteria, B-spline interpolation and inverse displacement analysis model. The minimum energy consumption gait, which similar with human motion, are used to train FNN, b-spline curves are utilized to fit dispersive Center of Gravity (COG) position and body posture datas, based on above models and inverse displacement model, trajectory of COG and desired body posture can be mapped into trajectory of joint space conveniently. Simulation results demonstrate feasibility and effectiveness of above real-time trajectory planning method. Numeric examples are given for illustration.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74205-0_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-77296-5_21,The Man-Machine Interaction: The Influence of Artificial Intelligence on Rehabilitation Robotics,50 Years of Artificial Intelligence,10.1007/978-3-540-77296-5_21,Springer,2007-01-01,"We are leaving in a world where the interaction with intelligent machines is an every day life event. The advances in artificial intelligence had allowed the development of adaptive machines that can modify its internal parameters to adjust their behavior according to the changing environment. One field that has profit from this is rehabilitation and prosthetics. In this respect, is our interest to evaluate the effects that this interaction has on the user. In this study, we use an f-MRI (functional Magnetic Resonance Imaging) device to measure the changes on the motor and sensory cortex of a right hand amputee’s using an EMG controlled Adaptable prosthetic hand with tactile feedback. Our results show the improvement in the adaptation to the prosthetic device, also, our experiments point to a possible modification of the body schema, generating an illusion of belonging of the robot hand to the human body.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-77296-5_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74141-1_1,Cases in Robotic Soccer,Case-Based Reasoning Research and Development,10.1007/978-3-540-74141-1_1,Springer,2007-01-01,"Soccer playing robots are a well established test bed for the development of artificial intelligence for use in real environments. The challenges include perception, decision making and acting in a dynamic environment with only unreliable and partial information. Behaviors and skills for such environments must be optimized by experiences. Case Based Reasoning provides an excellent framework for learning as discussed in this paper.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74141-1_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-49720-2_7,Module-based Autonomous Learning for Mobile Robots,Mobile Robots: The Evolutionary Approach,10.1007/978-3-540-49720-2_7,Springer,2007-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-49720-2_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-73055-2_37,Towards the Automatic Learning of Reflex Modulation for Mobile Robot Navigation,Nature Inspired Problem-Solving Methods in Knowledge Engineering,10.1007/978-3-540-73055-2_37,Springer,2007-01-01,"Reflexes are meant to provide animals with automatic responses for a better adaptation to their niches. In particular, humans have the capability to voluntarily modify these responses in certain situations to attain specific goals. The ability of using past experiences to tune automatic responses (reflexes) has contributed to a better adaptation to our environments and thus, the question arises of applying this to machines. In the robotic arena, imitating animal reflexes has been largely explored through fixed stimuli-behavior schemas included in reactive or hybrid architectures. In this paper we consider the less explored direction of permitting a mobile robot to modify its reflexes according to its experience, i.e. ignoring the reflex of stopping when approaching an obstacle if the robot goal is close. We explore reinforcement learning as a mechanism to automatically learn when and how modulate reflexes over the robot operational life. Advantages of our mechanism are illustrated in simulations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-73055-2_37,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-77296-5_33,Intelligent Mobile Manipulators in Industrial Applications:Experiences and Challenges,50 Years of Artificial Intelligence,10.1007/978-3-540-77296-5_33,Springer,2007-01-01,"This paper describes how industrial applications were targeted and successfully implemented by robotic manipulators that have been developed from studies in embodied artificial intelligent systems. The goal was to design mobile, flexible and self-learning manipulators that allow to perform multiple tasks with very short preparation time, a reasonable working speed and, at the same time, in a human-like manner. The advantages and disadvantages of these solutions compared to traditional industrial robot applications had to be considered continuously to concentrate on the right market segments, applications and customers. Thus, in addition to develop the appropriate requirements of real-time executions, risk analyses and usability, studies were established and implemented in collaboration with scientists, integrators and end customers. Acceptance, impacts of the revolution in personal intelligent robotics as well as challenges to overcome in the future are discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-77296-5_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-71541-2_12,Evolution of Signalling in a Group of Robots Controlled by Dynamic Neural Networks,Swarm Robotics,10.1007/978-3-540-71541-2_12,Springer,2007-01-01,"Communication is a point of central importance in swarms of robots. This paper describes a set of simulations in which artificial evolution is used as a means to engineer robot neuro-controllers capable of guiding groups of robots in a categorisation task by producing appropriate actions. Communicative behaviour emerges, notwithstanding the absence of explicit selective pressure (coded into the fitness function) to favour signalling over non-signalling groups. Post-evaluation analyses illustrate the adaptive function of the evolved signals and show that they are tightly linked to the behavioural repertoire of the agents. Finally, our approach for developing controllers is validated by successfully porting one evolved controller on real robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-71541-2_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74827-4_148,Incremental Evolution of Stigmergy-Based Multi Robot Controllers Through Utility Functions,Knowledge-Based Intelligent Information and Engineering Systems,10.1007/978-3-540-74827-4_148,Springer,2007-01-01,"This paper deals with the problem of jointly designing the behaviors of a group of robots so as to produce a particular desired collaborative behavior in stigmergy-based settings. In this line, the approach followed has its roots on traditional evolutionary behavior based robotics techniques, but instead of trying to evolve the whole controller for a particular complex behavior in one step, an incremental approach is used by combining the results from different evolutionary/learning processes in different settings for the construction of a complete controller architecture. The key aspects when trying to generalize the process of obtaining the controllers from single robots to multi robot systems are discussed in the framework of a set of simple collaborative tasks, focusing the discussion on the utility functions that guide the evolution.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74827-4_148,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74827-4_149,Lattice Independence and Vision Based Mobile Robot Navigation,Knowledge-Based Intelligent Information and Engineering Systems,10.1007/978-3-540-74827-4_149,Springer,2007-01-01,"Strong Lattice Independence implies Affine Independence. Affine Independent sets of vectors define a convex polytope and if this polytope is a good approximation to the convex hull of a set data points, we can use them to represent the data points through their convex coordinates. This representation can be used as a feature extraction or dimensionality reduction method. Morphological Associative Memories (MAM) have been proposed for image denoising and pattern recognition. Recent works show that, by construction, Autoassociative Morphological Memories (AMM) are composed of lattice independent vectors. After a transformation these vectors can be shown to be a good approximation to the data convex hull, and therefore as a candidate set of points for convex coordinate representation of the data. In this paper we present some results on the task of visual landmark recognition for a mobile robot self-localization task improving previous results using AMM.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74827-4_149,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-73055-2_39,Discretization of ISO-Learning and ICO-Learning to Be Included into Reactive Neural Networks for a Robotics Simulator,Nature Inspired Problem-Solving Methods in Knowledge Engineering,10.1007/978-3-540-73055-2_39,Springer,2007-01-01,"Isotropic Sequence Order learning (ISO-learning) and Input Correlation Only learning (ICO-learning) are unsupervised neural algorithms to learn temporal differences. The use of devices implementing this algorithms by simulation in reactive neural networks is proposed. We have applied several modifications to original rules: weights sign restriction, to adequate ISO-learning and ICO-learning devices outputs to the usually predefined kinds of connections (excitatory/inhibitory) used in neural networks, and decay term inclusion for weights stabilization. Original experiments with these algorithms are replicated as accurate as possible with a simulated robot and a discretization of the algorithms. Results are similar to those obtained in original experiments with analogue devices.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-73055-2_39,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-76928-6_36,A Bio-inspired Method for Incipient Slip Detection,AI 2007: Advances in Artificial Intelligence,10.1007/978-3-540-76928-6_36,Springer,2007-01-01,"Few years old children lift and manipulate unfamiliar objects more dexterously than today’s robots. Therefore, it has arisen an interest at the artificial intelligence community to look for inspiration on neurophysiological studies to design better models for the robots. In a human dexterous manipulation a crucial event is the detection of incipient slips. Humans detect the incipient slips based on the responses of their tactile mechanoreceptors. In this paper, we propose a method to detect the incipient slips using artificial neural networks that receive as input simulated human afferent responses. This method is strongly inspired on neurophysiological studies of the afferent responses during the human dexterous manipulation. Finite element analysis was used to model two fingers and an object, and simulated experiments using the proposed method were done. To the best of our knowledge, this is the first time that simulated human afferent signals are combined with finite element analysis and artificial neural networks, to detect the incipient slips.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-76928-6_36,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74690-4_37,SpikeStream: A Fast and Flexible Simulator of Spiking Neural Networks,Artificial Neural Networks – ICANN 2007,10.1007/978-3-540-74690-4_37,Springer,2007-01-01,"SpikeStream is a new simulator of biologically structured spiking neural networks that can be used to edit, display and simulate up to 100,000 neurons. This simulator uses a combination of event-based and synchronous simulation and stores most of its information in databases, which makes it easy to run simulations across an arbitrary number of machines. A comprehensive graphical interface is included and SpikeStream can send and receive spikes to and from real and virtual robots across a network. The architecture is highly modular, and so other researchers can use its graphical editing facilities to set up their own simulation networks or apply genetic algorithms to the SpikeStream databases. SpikeStream is available for free download under the terms of the GPL.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-74690-4_37,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1016/S1672-6529(07)60002-X,A bionic neural network for fish-robot locomotion,Journal of Bionic Engineering,10.1016/S1672-6529(07)60002-X,Springer,2006-12-01,"A bionic neural network for fish-robot locomotion is presented. The bionic neural network inspired from fish neural network consists of one high level controller and one chain of central pattern generators (CPGs). Each CPG contains a nonlinear neural Zhang oscillator which shows properties similar to sine-cosine model. Simulation results show that the bionic neural network presents a good performance in controlling the fish-robot to execute various motions such as startup, stop, forward swimming, backward swimming, turn right and turn left.",http://link.springer.com/openurl/fulltext?id=doi:10.1016/S1672-6529(07)60002-X,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-007-9057-y,"Robots, insects and swarm intelligence",Artificial Intelligence Review,10.1007/s10462-007-9057-y,Springer,2006-12-01,"The aim of this paper is to consider the relationships between robots and insects. To this end, an overview is provided of the two main areas in which insects have been implicated in robotics research. First, robots have been used to provide working models of mechanisms underlying insect behaviour. Second, there are developments in robotics that have been inspired by our understanding of insect behaviour; in particular the approach of swarm robotics. In the final section of the paper, the possibility of achieving “strong swarm intelligence” is discussed. Two possible interpretations of strong swarm intelligence are raised: (1) the emergence of a group mind from a natural, or robot swarm, and (2) that behaviours could emerge from a swarm of artificial robots in the same way as they emerge from a biological swarm. Both interpretations are dismissed as being unachievable in principle. It is concluded that bio-robotic modelling and biological inspiration have made important contributions to both insect and robot research, but insects and robots remain separated by the divide between the living and the purely mechanical.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10462-007-9057-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-006-0106-z,A unified architecture for agent behaviors with selection of evolved neural network modules,Applied Intelligence,10.1007/s10489-006-0106-z,Springer,2006-12-01,"To model complex systems for agent behaviors, genetic algorithms have been used to evolve neural networks which are based on cellular automata. These neural networks are popular tools in the artificial life community. This hybrid architecture aims at achieving synergy between the cellular automata and the powerful generalization capabilities of the neural networks. Evolutionary algorithms provide useful ways to learn about the structure of these neural networks, but the use of direct evolution in more difficult and complicated problems often fails to achieve satisfactory solutions. A more promising solution is to employ incremental evolution that reuses the solutions of easy tasks and applies these solutions to more difficult ones. Moreover, because the human brain can be divided into many behaviors with specific functionalities and because human beings can integrate these behaviors for high-level tasks, a biologically-inspired behavior selection mechanism is useful when combining these incrementally evolving basic behaviors. In this paper, an architecture based on cellular automata, neural networks, evolutionary algorithms, incremental evolution and a behavior selection mechanism is proposed to generate high-level behaviors for mobile robots. Experimental results with several simulations show the possibilities of the proposed architecture.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-006-0106-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-006-9071-3,Path Planning for a Statically Stable Biped Robot Using PRM and Reinforcement Learning,Journal of Intelligent and Robotic Systems,10.1007/s10846-006-9071-3,Springer,2006-11-01,"In this paper path planning and obstacle avoidance for a statically stable biped robot using PRM and reinforcement learning is discussed. The main objective of the paper is to compare these two methods of path planning for applications involving a biped robot. The statically stable biped robot under consideration is a 4-degree of freedom walking robot that can follow any given trajectory on flat ground and has a fixed step length of 200 mm. It is proved that the path generated by the first method produces the shortest smooth path but it also increases the computational burden on the controller, as the robot has to turn at almost all steps. However the second method produces paths that are composed of straight-line segments and hence requires less computation for trajectory following. Experiments were also conducted to prove the effectiveness of the reinforcement learning based path planning method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-006-9071-3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00170-005-0054-5,Part grasping for automated disassembly,The International Journal of Advanced Manufacturing Technology,10.1007/s00170-005-0054-5,Springer,2006-09-01,"A robot grasp synthesis algorithm for automated disassembly is presented. The goal is to select grasping points in each part to be disassembled so that a previously planned disassembly sequence can be performed holding the parts firmly and avoiding collisions. The algorithm is structured in five steps in order to make it general enough to cope with different robot grippers and different geometrical data (2D or 3D). The system is learning based, and behaviour rules are automatically extracted from grasping examples given by the user, using mainly decision trees and nearest neighbour techniques. Some simulation experiments have been carried out and results with a two fingered robot gripper are presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00170-005-0054-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-006-9053-5,A Multiple Models Approach for Adaptation and Learning in Mobile Robots Control,Journal of Intelligent and Robotic Systems,10.1007/s10846-006-9053-5,Springer,2006-09-01,The paper proposes a multiple models based control methodology for the solution of the tracking problem for mobile robots. The proposed method utilizes multiple models of the robot for its identification in an adaptive and learning control framework. Radial Basis Function Networks (RBFNs) are considered for the multiple models in order to exploit the non-linear approximation capabilities of the nets for modeling the kinematic behaviour of the vehicle and for reducing unmodelled tracking errors contributions. The training of the nets and the control performance analysis have been done in a real experimental setup. The experimental results are satisfactory in terms of tracking errors and computational efforts and show the improvement in the tracking performance when the proposed methodology is used for tracking tasks in dynamical uncertain environments.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-006-9053-5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00464-005-0511-0,Initial clinical experience with a partly autonomous robotic surgical instrument server,Surgical Endoscopy And Other Interventional Techniques,10.1007/s00464-005-0511-0,Springer,2006-08-01,"Background The authors believe it would be useful to have surgical robots capable of some degree of autonomous action in cooperation with the human members of a surgical team. They believe that a starting point for such development would be a system for delivering and retrieving instruments during a surgical procedure. Methods The described robot delivers instruments to the surgeon and retrieves the instruments when they are no longer being used. Voice recognition software takes in requests from the surgeon. A mechanical arm with a gripper is used to handle the instruments. Machine-vision cameras locate the instruments after the surgeon puts them down. Artificial intelligence software makes decisions about the best response to the surgeon’s requests. Results A robot was successfully used in surgery for the first time June 16, 2005. The operation involved excision of a benign lipoma. The procedure lasted 31 min, during which time the robot performed 16 instrument deliveries and 13 instrument returns with no significant errors. The average time between verbal request and delivery of an instrument was 12.4 s. Conclusions The described robot is capable of delivering instruments to a surgeon at command and can retrieve them independently using machine vision. This robot, termed a “surgical instrument server,” represents a new class of information-processing machines that will relieve the operating room team of repetitive tasks and allow the members to focus more attention on the patient.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00464-005-0511-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF02915991,A QP Artificial Neural Network inverse kinematic solution for accurate robot path control,Journal of Mechanical Science and Technology,10.1007/BF02915991,Springer,2006-07-01,"In recent decades, Artificial Neural Networks (ANNs) have become the focus of considerable attention in many disciplines, including robot control, where they can be used to solve nonlinear control problems. One of these ANNs applications is that of the inverse kinematic problem, which is important in robot path planning. In this paper, a neural network is employed to analyse of inverse kinematics of PUMA 560 type robot. The neural network is designed to find exact kinematics of the robot. The neural network is a feedforward neural network (FNN). The FNN is trained with different types of learning algorithm for designing exact inverse model of the robot. The Unimation PUMA 560 is a robot with six degrees of freedom and rotational joints. Inverse neural network model of the robot is trained with different learning algorithms for finding exact model of the robot. From the simulation results, the proposed neural network has superior performance for modelling complex robot’s kinematics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF02915991,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-006-9060-6,A Neural Network Adaptive Controller for End-effector Tracking of Redundant Robot Manipulators,Journal of Intelligent and Robotic Systems,10.1007/s10846-006-9060-6,Springer,2006-07-01,"In this paper we propose a neural network adaptive controller to achieve end-effector tracking of redundant robot manipulators. The controller is designed in Cartesian space to overcome the problem of motion planning which is closely related to the inverse kinematics problem. The unknown model of the system is approximated by a decomposed structure neural network. Each neural network approximates a separate element of the dynamical model. These approximations are used to derive an adaptive stable control law. The parameter adaptation algorithm is derived from the stability study of the closed loop system using Lyapunov approach with intrinsic properties of robot manipulators. Two control strategies are considered. First, the aim of the controller is to achieve good tracking of the end-effector regardless the robot configurations. Second, the controller is improved using augmented space strategy to ensure minimum displacements of the joint positions of the robot. Simulation examples are also presented to verify the effectiveness of the proposed approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-006-9060-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-006-9046-4,A Neural-based Model for Fast Continuous and Global Robot Location,Journal of Intelligent and Robotic Systems,10.1007/s10846-006-9046-4,Springer,2006-07-01,"One of the problems in the field of mobile robotics is the estimation of the robot position in an environment. This paper proposes a model for estimating a confidence interval of the robot position in order to compare it with the estimation made by a dead-reckoning system. Both estimations are fused using heuristic rules. The positioning model is very valuable in estimating the current robot position with or without knowledge about the previous positions. Furthermore, it is possible to define the degree of knowledge of the robot previous position, making it possible to adapt the estimation by varying this knowledge degree. This model is based on a one-pass neural network which adapts itself in real time and learns about the relationship between the measurements from sensors and the robot position.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-006-9046-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11063-006-9003-z,A Neural Control System of a Two Joints Robot for Visual Conferencing,Neural Processing Letters,10.1007/s11063-006-9003-z,Springer,2006-06-01,"This paper presents a real time interactive conferencing system that allows people to communicate via animated images. The employed distant cameras act as a remote vision system. The cameras simulate the movement of an observer and return images covering the surrounding view of the pictured person. This paper also describes the neuro-command system that controls a robot with two joints (degrees of freedom) that carries the used camera. This neural system translates the head movements. A methodology from image processing has been adopted for the classification, and facilitation of the phase of neural network learning process.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-006-9003-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-006-9059-z,Modelling the Environment of a Mobile Robot with the Embedded Flow State Machine,Journal of Intelligent and Robotic Systems,10.1007/s10846-006-9059-z,Springer,2006-06-01,"A type of topological approach to mobile robot navigation is discussed and experimentally evaluated. The environment as experienced by a moving robot is treated as a dynamical system. Simple types of reactive behavior are supplemented with eventual decisions to switch between them. When switching criteria are defined, the system may be described in the form similar to a finite state machine. Since it is embedded in the environment and dependent on the sensory flow of the robot, we introduce the term “Embedded flow state machine” (EFSM). We implemented it with a recurrent neural network, trained on a sequence of sensory contents and actions. One of the main virtues of this approach is that no explicit localization is required, since the recurrent neural network holds the state implicitly. The EFSM is applicable to multi-step prediction of sensory information and the travelled distances between decision points, given a sequence of decisions at decision points. Thus, the optimal path to a specified goal can be sought. One of the main issues is, for how many steps ahead the prediction is reliable enough. In other words, is it feasible to perform environment modelling and path planning in this manner? The approach is tested on a miniature mobile robot, equipped with proximity sensors and a color video camera. Decision ‘points,’ where deviations from the wall-following behavior are allowed, are based on color object recognition. In the case of an experimental environment of medium complexity, this approach was successful.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-006-9059-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10044-006-0025-y,An empirical study of machine learning techniques for affect recognition in human–robot interaction,Pattern Analysis and Applications,10.1007/s10044-006-0025-y,Springer,2006-05-01,"Given the importance of implicit communication in human interactions, it would be valuable to have this capability in robotic systems wherein a robot can detect the motivations and emotions of the person it is working with. Recognizing affective states from physiological cues is an effective way of implementing implicit human–robot interaction. Several machine learning techniques have been successfully employed in affect-recognition to predict the affective state of an individual given a set of physiological features. However, a systematic comparison of the strengths and weaknesses of these methods has not yet been done. In this paper, we present a comparative study of four machine learning methods—K-Nearest Neighbor, Regression Tree (RT), Bayesian Network and Support Vector Machine (SVM) as applied to the domain of affect recognition using physiological signals. The results showed that SVM gave the best classification accuracy even though all the methods performed competitively. RT gave the next best classification accuracy and was the most space and time efficient.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10044-006-0025-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-007-9063-0,The state of play in machine/environment interactions,Artificial Intelligence Review,10.1007/s10462-007-9063-0,Springer,2006-05-01,"Due to the breadth of the subject, it is no longer possible to provide a review of all of the work being carried out in the field of Artificial Intelligence. However, a more localised review of research taking place in the overlap between engineering, AI and psychology can be meaningfully performed. We show here that while there have been marked successes in the past few years, there is an identifiable set of ‘classic’ problems that remain to be solved, and which largely direct the work ongoing in this area. This review aims to discuss the directions being taken at the current time, in particular the developing and maturing possibilities provided by neural networks and evolutionary computation, and by the use of our knowledge of the mind in developing artificial agents capable of mimicking our abilities to interact with the environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10462-007-9063-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-007-9048-z,Artificial intelligence and natural magic,Artificial Intelligence Review,10.1007/s10462-007-9048-z,Springer,2006-04-01,"Robotics with AI is part of a long tradition that has run from ancient times that treated the precursors of robots, the automata, as part of Natural Magic or conjury. Deception is an integral part of AI and robotics; in some ways they form a science of illusion. There are many robot tasks, such as caring for the elderly, minding children, doing domestic chores and being companionable, that involve working closely with humans and so require some illusion of animacy and thought. We discuss how the natural magic of robotics is assisted by the cultural myth of AI together with innate human predispositions such as zoomorphism, the willing suspension of disbelief and a tendency to interpret AI devices as part of the social world. This approach provides a justifiable way of meeting the goals of AI and robotics provided that researchers do not allow themselves to be deceived by their own illusions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10462-007-9048-z,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-006-9035-7,Methodology of Concept Control Synthesis to Avoid Unmoving and Moving Obstacles (II),Journal of Intelligent and Robotic Systems,10.1007/s10846-006-9035-7,Springer,2006-03-01,"Dynamic path generation problem of robot in environment with other unmoving and moving objects is considered. Generally, the problem is known in literature as find path or robot motion planning. In this paper we apply the behavioral cloning approach to design the robot controller. In behavioral cloning, the system learns from control traces of a human operator. The task for the given problem is to find a controller not only in the form of the explicit mathematical expression. So RBF neural network is used also. The goal is to apply controller for the mobile robot motion planning in situation with infinite number of obstacles. The advantage of this approach lies in the fact that a complete path can be defined off-line, without using sophisticated symbolical models of obstacles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-006-9035-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-006-9031-y,An Intelligent Controller Improving the Drive System of a Head Platform,Journal of Intelligent and Robotic Systems,10.1007/s10846-006-9031-y,Springer,2006-03-01,In this paper a new approach for steering a binocular head is presented. This approach is based on extracting the expert’s knowledge in order to improve the behaviour of the classical control strategies. This is carried out without inserting new elements in the system. Neuro–Fuzzy techniques have been chosen in order to reach this target. As a result a more friendly robotic system is achieved.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-006-9031-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11023-006-9016-4,The attentional spotlight,Minds and Machines,10.1007/s11023-006-9016-4,Springer,2006-02-01,"One of the interesting and occasionally controversial aspects of Dennett’s career is his direct involvement in the scientific process. This article describes some of Dennett’s participation on one particular project conducted at MIT, the building of the humanoid robot named Cog. One of the intentions of this project, not to date fully realized, was to test Dennett’s multiple drafts theory of consciousness. I describe Dennett’s involvement and impact on Cog from the perspective of a graduate student. I also describe the problem of coordinating distributed intelligent systems, drawing examples from robot intelligence, human intelligence, and the Cog project itself.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11023-006-9016-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-29344-2_18,Trajectory Generation for a Mobile Robot by Reinforcement Learning,Proceedings of the 3rd International Symposium on Autonomous Minirobots for Research and Edutainment (AMiRE 2005),10.1007/3-540-29344-2_18,Springer,2006-01-01,"Q-learning in the Reinforcement Learning (RL) field is the powerful and attractive tool to make robots generate autonomous behavior. But it needs large amount of computational cost because of its discrete state and action. To generated smooth trajectory with less computational cost, we propose two ingredients for Q-learning. We applied Q-learning to the simulated two wheeled robot to generate trajectory for Ball-To-Goal task in robot soccer. …",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-29344-2_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-84628-226-3_3,Robot Docking Based on Omnidirectional Vision and Reinforcement Learning,Research and Development in Intelligent Systems XXII,10.1007/978-1-84628-226-3_3,Springer,2006-01-01,"We present a system for visual robotic docking using an omnidirectional camera coupled with the actor critic reinforcement learning algorithm. The system enables a PeopleBot robot to locate and approach a table so that it can pick an object from it using the pan-tilt camera mounted on the robot. We use a staged approach to solve this problem as there are distinct sub tasks and different sensors used. Starting with random wandering of the robot until the table is located via a landmark, and then a network trained via reinforcement allows the robot to rum to and approach the table. Once at the table the robot is to pick the object from it. We argue that our approach has a lot of potential allowing the learning of robot control for navigation removing the need for internal maps of the environment. This is achieved by allowing the robot to learn couplings between motor actions and the position of a landmark.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-84628-226-3_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11760023_172,Dynamic Tracking Control of Mobile Robots Using an Improved Radial Basis Function Neural Network,Advances in Neural Networks - ISNN 2006,10.1007/11760023_172,Springer,2006-01-01,A novel dynamic control scheme for nonholonomic mobile robots is developed in this paper. The dynamics of mobile robot based on improved radial basis function neural network (IRBFNN) is modeled online by the improved algorithm of resource allocating network (IRAN). The control scheme of mobile robot integrates a velocity controller based on backstepping technology and a torque controller based on the IRBFNN and robust compen-sator. The simulations have shown that the control system is competent for the robust tracking control of mobile robot.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/11760023_172,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11760023_173,Grasping Control of Robot Hand Using Fuzzy Neural Network,Advances in Neural Networks - ISNN 2006,10.1007/11760023_173,Springer,2006-01-01,"In this paper, we propose a grasping control method for robot hand using fuzzy theory and partially- linearized neural network. The robot hand has Double-Octagon Tactile Sensor (D.O.T.S), which has been proposed in our previous papers, to detect grasping force between the grasped object and the robot fingers. Because the measured forces are fluctuant due to the measuring error and vibration of the hand, the tactile information is ambiguous. In order to quickly control the grasping force to prevent the grasped object sliding out off the robot fingers, we apply the possibility theory to deal with the ambiguous problem of the tactile information, and use the partially- linearized neural network (P.L.N.N) to construct a fuzzy neural network. The method proposed in this paper is verified by applying it to practical grasping control of breakable objects, such as eggs, fruits, etc.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11760023_173,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11785231_81,Adaptive Critic Neural Networks for Identification of Wheeled Mobile Robot,Artificial Intelligence and Soft Computing – ICAISC 2006,10.1007/11785231_81,Springer,2006-01-01,"A new applications of adaptive critic identifier for wheeled mobile robot is presented. In this approach the architecture of adaptive critic identifier contains a neural network (NN) based adaptive critic element (ACE) generating the reinforcement signal to tune the associative search element (ASE), which is applied to approximate nonlinear functions of the mobile robot. The proposed system identification that can guarantee tracking performance and stability is derived from the Lyapunov stability theory. Computer simulation have been conducted to illustrate the performance of the proposed solution by a series of experiments on the emulator of wheeled mobile robot Pioneer-2DX.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11785231_81,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11760023_169,Robust Adaptive Neural Networks with an Online Learning Technique for Robot Control,Advances in Neural Networks - ISNN 2006,10.1007/11760023_169,Springer,2006-01-01,"A new robust adaptive neural networks tracking control with online learning controller is proposed for robot systems. A learning strategy and robust adaptive neural networks are combined into a hybrid robust control scheme. The proposed controller deals mainly with external disturbances and nonlinear uncertainty in motion control. A neural network (NN) is used to approximate the uncertainties in a robotic system. Then the disadvantageous effects on tracking performance, due to the approximating error of the NN in robotic system, are attenuated to a prescribed level by an adaptive robust controller. The learning techniques of NN will improve robustness with respect to uncertainty of system, as a result, improving the dynamic performance of robot system. A simulation example demonstrates the effectiveness of the proposed control strategy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11760023_169,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11803089_6,Tracking Control Based on Neural Network for Robot Manipulator,Artificial Intelligence and Neural Networks,10.1007/11803089_6,Springer,2006-01-01,"In this paper, a control algorithm based on neural networks is presented. This control algorithm has been applied to a robot arm which has a highly nonlinear structure. The model based approaches for robot control require high computational time and can result in a poor control performance, if the specific model structure selected does not properly reflect all the dynamics. The control technique proposed here has provided satisfactory results. A decentralized model has been assumed here where a controller is associated with each joint and a separate neural network is used to adjust the parameters of each controller. Neural networks have been used to adjust the parameters of the controllers, being the outputs of the neural networks, the control parameters.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11803089_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11760023_59,An Attention Selection System Based on Neural Network and Its Application in Tracking Objects,Advances in Neural Networks - ISNN 2006,10.1007/11760023_59,Springer,2006-01-01,"In this paper an attention selection system based on neural network is proposed, which combines supervised and unsupervised learning reasonably. A value system and memory tree with update ability are regarded as teachers to adjust the weights of neural network. Both bottom-up and top-down part are to simulate two-stage hypothesis of attention selection in biological vision. The system is able to track objects that it is interested in. Whenever it lost focus on tracked object, it can find the object again in a short time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11760023_59,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11893295_79,Tracking Control of a Mobile Robot with Kinematic Uncertainty Using Neural Networks,Neural Information Processing,10.1007/11893295_79,Springer,2006-01-01,"In this paper, a kinematic controller based on input-output linearization plus neural network (NN) controller is presented for tracking control of a mobile robot with kinematic uncertainty. The NN controller, whose parameters are tuned on-line, can deal with the uncertainty imposed on the kinematics model of mobile robots. The stability of the proposed approach is guaranteed by the Lyapunov theory. Simulation results show the efficiency of the proposed approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11893295_79,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11760023_177,Neural Networks for Mobile Robot Navigation: A Survey,Advances in Neural Networks - ISNN 2006,10.1007/11760023_177,Springer,2006-01-01,"Nowadays, mobile robots have attracted more and more attention from researchers due to their extensive applications. Mobile robots need to have the capabilities of autonomy and intelligence, and they pose a challenge to researchers, which is to design algorithms that allow the robots to function autonomously in unstructured, dynamic, partially observable, and uncertain environments [1]. Navigation is the key to the relative technologies of mobile robots and neural networks are widely used in the field of mobile robot navigation due to their properties such as nonlinear mapping, ability to learn from examples, good generalization performance, massively parallel processing, and capability to approximate an arbitrary function given sufficient number of neurons. This paper surveys the developments in the last few years of the neural networks with applications to mobile robot navigation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11760023_177,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11840541_68,Simbad: An Autonomous Robot Simulation Package for Education and Research,From Animals to Animats 9,10.1007/11840541_68,Springer,2006-01-01,"Simbad is an open source Java 3d robot simulator for scientific and educational purposes. It is mainly dedicated to researchers and programmers who want a simple basis for studying Situated Artificial Intelligence, Machine Learning, and more generally AI algorithms, in the context of Autonomous Robotics and Autonomous Agents. It is is kept voluntarily readable and simple for fast implementation in the field of Research and/or Education. Moreover, Simbad embeds two stand-alone additional packages : a Neural Network library (feed-forward NN, recurrent NN, etc.) and an Artificial Evolution Framework for Genetic Algorithm, Evolutionary Strategies and Genetic Programming. These packages are targeted towards Evolutionary Robotics. The Simbad Package is available from http://simbad.sourceforge.net/ under the conditions of the GPL (GNU General Public Licence).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11840541_68,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11840541_39,Incremental Evolution of Robot Controllers for a Highly Integrated Task,From Animals to Animats 9,10.1007/11840541_39,Springer,2006-01-01,"In this paper we apply incremental evolution for automatic synthesis of neural network controllers for a group of physically connected mobile robots called s-bots . The robots should be able to safely and cooperatively perform phototaxis in an arena containing holes. We experiment with two approaches to incremental evolution, namely behavioral decomposition and environmental complexity increase. Our results are compared with results obtained in a previous study where several non-incremental evolutionary algorithms were tested and in which the evolved controllers were shown to transfer successfully to real robots. Surprisingly, none of the incremental evolutionary strategies performs any better than the non-incremental approach. We discuss the main reasons for this and why it can be difficult to apply incremental evolution successfully in highly integrated tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11840541_39,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-211-33303-7_2,Robotics and artificial intelligence: Jewish ethical perspectives,Medical Technologies in Neurosurgery,10.1007/978-3-211-33303-7_2,Springer,2006-01-01,"In 16th Century Prague, Rabbi Loew created a Golem, a humanoid made of clay, to protect his community. When the Golem became too dangerous to his surroundings, he was dismantled. This Jewish theme illustrates some of the guiding principles in its approach to the moral dilemmas inherent in future technologies, such as artificial intelligence and robotics. Man is viewed as having received the power to improve upon creation and develop technologies to achieve them, with the proviso that appropriate safeguards are taken. Ethically, not-harming is viewed as taking precedence over promoting good. Jewish ethical thinking approaches these novel technological possibilities with a cautious optimism that mankind will derive their benefits without coming to harm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-211-33303-7_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11760023_178,Fault Diagnosis for Mobile Robots with Imperfect Models Based on Particle Filter and Neural Network,Advances in Neural Networks - ISNN 2006,10.1007/11760023_178,Springer,2006-01-01,"Fault detection and diagnosis (FDD) are increasingly important for wheeled mobile robots (WMRs), especially those in unknown environments such as planetary exploration. There are many kinds of fault diagnosis methods available for mobile robots, including multiple model-based approaches, particle filter based approaches, sensor fusion based approaches. Currently, all of these methods are designed for complete models. However, completely modeling a system is difficult, even impossible. In this paper, particle filter and neural network are integrated to diagnose complex systems with imperfect models. Two features are extracted from particles: the sum of sample weights, and the maximal a posteriori probability. These features are further feed to a neural network to decide whether the estimation given by the particle filter is credible or not. An incredible estimation indicates that the true state isn’t included in the state space, i.e. it is a novel state (or an unknown fault). This method preserves the merits of particle filter and can diagnose known faults as well as detect unknown faults. It is testified on a real mobile robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11760023_178,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11881070_61,Humanoid Robot Behavior Learning Based on ART Neural Network and Cross-Modality Learning,Advances in Natural Computation,10.1007/11881070_61,Springer,2006-01-01,"This paper presents a novel robot behavior learning method based on Adaptive Resonance Theory (ART) neural network and cross-modality learning. We introduce the concept of classification learning and propose a new representation of observed behavior. Compared with previous robot behavior learning methods, this method has the property of learning a new behavior while at the same time preserving prior learned behaviors. Moreover, visual information and audio information are integrated to form a unified percept of the observed behavior, which facilitates robot behavior learning. We implement this learning method on a humanoid robot head for behavior learning and experimental results demonstrate the effectiveness of this method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11881070_61,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-29344-2_40,Spiking Neural Network for Behavior Learning of A Mobile Robot,Proceedings of the 3rd International Symposium on Autonomous Minirobots for Research and Edutainment (AMiRE 2005),10.1007/3-540-29344-2_40,Springer,2006-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-29344-2_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-29344-2_38,Self-Organization of Spiking Neural Network Generating Autonomous Behavior in a Miniature Mobile Robot,Proceedings of the 3rd International Symposium on Autonomous Minirobots for Research and Edutainment (AMiRE 2005),10.1007/3-540-29344-2_38,Springer,2006-01-01,"Purpose of this study is to develop self-organization algorithm of spiking neural network applicable to autonomous robots. We first formulated a spiking neural network model whose inputs and outputs were analog. We then implemented it into a miniature mobile robot Khepera. In order to see whether or not a solution(s) for the given task exists with the spiking neural network, the robot was evolved with the genetic algorithm (GA) in an environment. The robot acquired the obstacle-avoidance and navigation task successfully, exhibiting the presence of the solution. Then, a self-organization algorithm based on the use-dependent synaptic potentiation and depotentiation was formulated and implemented into the robot. In the environment, the robot gradually organized the network and the obstacle avoidance behavior was formed. The time needed for the training was much less than with genetic evolution, approximately one fifth (1/5).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-29344-2_38,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-37256-1_64,Fuzzy Sliding Mode Controller with RBF Neural Network for Robotic Manipulator Trajectory Tracking,Intelligent Control and Automation,10.1007/978-3-540-37256-1_64,Springer,2006-01-01,"This paper proposes a fuzzy sliding mode controller with radial basis function neural network (RBFNN) for trajectory tracking of robot manipulator. The main problem of sliding mode controllers is that a whole knowledge of the system dynamics and system parameters is required to compute the equivalent control. In this paper, a RBFNN is proposed to compute the equivalent control. Computer simulations of three link robot manipulator for trajectory tracking indicate that the proposed method is a good candidate for trajectory control applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-37256-1_64,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11802372_33,Multiagent Reinforcement Learning for a Planetary Exploration Multirobot System,Agent Computing and Multi-Agent Systems,10.1007/11802372_33,Springer,2006-01-01,"In a planetary rover system called “SMC rover”, the motion coordination between robots is a key problem to be solved. Multiagent reinforcement learning methods for multirobot coordination strategy learning are investigated. A reinforcement learning based coordination mechanism is proposed for the exploration system. Four-robot climbing a slope is studied in detail as an instance. The actions of the robots are divided into two layers and realized respectively, which simplified the complexity of the climbing task. A Q-Learning based multirobot coordination strategy mechanism is proposed for the climbing mission. An OpenGL 3D simulation platform is used to verify the strategy and the learning results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11802372_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-0-387-34733-2_19,Trading off Impact and Mutation of Knowledge by Cooperatively Learning Robots,Biologically Inspired Cooperative Computing,10.1007/978-0-387-34733-2_19,Springer,2006-01-01,"We present a socially inspired approach that allows agents in Multi-Agent Systems to speed up their own learning process through communication. Thereby, they are able to trade off impact of knowledge by mutation dependent on the recent performance of the interacting agents. This is inspired by social interaction of humans, where the opinions of experts have greater impact on the overall opinion and are incorporated more exactly than those of newbies. The approach is successfully evaluated in a simulation in which mobile robots have to accomplish a task while taking care of timely recharging their resources.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-0-387-34733-2_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11750321_38,Grey Reinforcement Learning for Incomplete Information Processing,Theory and Applications of Models of Computation,10.1007/11750321_38,Springer,2006-01-01,"New representation and computation mechanisms are key approaches for learning problems with incomplete information or in large probabilistic environments. In this paper, traditional reinforcement learning (RL) methods are combined with grey theory and a novel grey reinforcement learning (GRL) framework is proposed to solve complex problems with incomplete information. Typical example of mobile robot navigation is given out to evaluate the performance and practicability of GRL. Related issues are also briefly discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11750321_38,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11780519_22,Simultaneous Learning to Acquire Competitive Behaviors in Multi-agent System Based on Modular Learning System,RoboCup 2005: Robot Soccer World Cup IX,10.1007/11780519_22,Springer,2006-01-01,"The existing reinforcement learning approaches have been suffering from the policy alternation of others in multiagent dynamic environments. A typical example is a case of RoboCup competitions since other agent behaviors may cause sudden changes in state transition probabilities of which constancy is needed for the learning to converge. The keys for simultaneous learning to acquire competitive behaviors in such an environment are – a modular learning system for adaptation to the policy alternation of others, and – an introduction of macro actions for simultaneous learning to reduce the search space. This paper presents a method of modular learning in a multiagent environment, by which the learning agents can simultaneously learn their behaviors and adapt themselves to the situations as consequences of the others’ behaviors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11780519_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11802372_28,Teamwork Formation for Keepaway in Robotics Soccer (Reinforcement Learning Approach),Agent Computing and Multi-Agent Systems,10.1007/11802372_28,Springer,2006-01-01,"In this paper, we discuss guidelines for a reward design problem that defines when and what amount of reward should be given to the agents, within the context of reinforcement learning approach. We take keepaway soccer as a standard task of multiagent domain which requires skilled teamwork. The difficulties of designing reward for good teamwork are due to its features as follows: i) since it is a continuing task which has no explicit goal, it is hard to tell when reward should be given to the agents, ii) since it is a multiagent cooperative task, it is hard to make a fair share of the reward for each agent’s contribution. Through some experiments, we show that reward design have a major effect on the agent’s behavior, and introduce the reward function that makes agents perform keepaway successfully.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11802372_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/3-540-32834-3_14,A Machine Learning Method for Improving Task Allocation in Distributed Multi-Robot Transportation,Complex Engineered Systems,10.1007/3-540-32834-3_14,Springer,2006-01-01,"Machine learning is a means of automatically generating solutions that perform better than those that are hand-coded by human programmers. We present a general behavior-based algorithm that uses reinforcement learning to improve the spatiotemporal organization of a homogeneous group of robots. In this algorithm each robot applies the learning at the level of individual behavior selection. We demonstrate how the interactions within the group affect the individual learning in a way that produces group-level effects, such as lane-formation and task-specialization, and improves group performance. We also present a model of multi-robot task allocation as resource distribution through vacancy chains, a distribution method common in human and animal societies, and an algorithm for multi-robot task allocation based on that model. The model predicts the task allocation achieved by our algorithm and highlights its limitations. We present experimental results that validate our model and show that our algorithm outperforms pre-programmed solutions. Last, we present an extension of our algorithm that makes it sensitive to differences in robot performance levels.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-32834-3_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11780519_37,A Fuzzy Touch to R-MCL Localization Algorithm,RoboCup 2005: Robot Soccer World Cup IX,10.1007/11780519_37,Springer,2006-01-01,"In this work, a novel method called Fuzzy Reverse Monte Carlo Localization (Fuzzy R-MCL) for global localization of autonomous mobile agents in the robotic soccer domain is proposed to overcome the uncertainty in the sensors, environment and the motion model. R-MCL is a hybrid method based on both Markov Localization(ML) and Monte Carlo Localization(MCL) where the ML module finds the region where the robot should be and MCL predicts the geometrical location with high precision by selecting samples in this region. In this work, a fuzzy approach is embedded in this method, to improve flexibility, accuracy and robustness. In addition to using Fuzzy membership functions in modeling the uncertainty of the grid cells and samples, different heuristics are used to enable the adaptation of the method to different levels of noise and sparsity. The method is very robust and fast and requires less computational power and memory compared to similar approaches and is accurate enough for high level decision making which is vital for robot soccer.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11780519_37,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/0-387-34224-9_31,Applying AI to Cooperating Agricultural Robots,Artificial Intelligence Applications and Innovations,10.1007/0-387-34224-9_31,Springer,2006-01-01,"We consider the experimental development of collaborating robots able to work within fields of crops. Specifically we investigate how AI principles can be applied to this agricultural domain and how the user should be involved in such a system. To support collaboration between agents a representation of responsibilities and dependencies is necessary. This is done by introducing groups and roles, from MAS theory, that the agent must adhere to, formalised by the Agent-Group-Role (AGR) model. To enable a human user to influence the system we adopt the principles declared by the VOWELS paradigm. We then show that the AGR model and the VOWELS paradigm, enable us to solve two practical agricultural problems, and lastly we argue that the obtained results can be transferred to other domains, such as pervasive computing.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/0-387-34224-9_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/1-84628-231-4_24,The Optimization of What?,Intelligent Decision-making Support Systems,10.1007/1-84628-231-4_24,Springer,2006-01-01,"This chapter traces the impact of decision support methods, including those based on Artificial Intelligence concepts, from the beginning, through to the present, and concludes with proposals for the future of the profession. Most of the readers of this book are engaged in the creation of models, systems, data and knowledge bases and methodologies. These are all worthwhile tasks, and some of them are seriously complicated and tricky to do. Our goal in this chapter is to encourage colleagues to move up a gear. Since the start in 1965, members of our profession have solved several thousand problems for organizations. The next job is to tackle more worldclass issues. We have the skills and the tools to do this. The executives we work with are more computer aware than they were in the 1960s. We ourselves know more about the need for social acceptance than before. The chapter pencils in the history of the DSS concept from the start, then reviews the problems we are collectively tackling now, before moving on to consider the global scale of the challenges that lie ahead.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/1-84628-231-4_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-0-387-33532-2_35,A Biologically Inspired Approach Toward Autonomous Real-World Robots,Complex Systems Science in Biomedicine,10.1007/978-0-387-33532-2_35,Springer,2006-01-01,"We present an approach inspired by biological principles to design the control system for an eight-legged walking robot. The approach is based on two biological control primitives: central pattern generators and coupled reflexes. By using these mechanisms we can achieve omnidirectional walking and smooth gait transitions in a high-degree-of-freedom (14) walking machine. Additionally, the approach allows us to freely mix rhythmic activity with posture changes of the robot without reducing forward speed. This approach has proved to be extremely successful on rough terrain and has been evaluated in real-world tests over a variety of different substrates.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-0-387-33532-2_35,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11840541_16,Dynamic Generation and Switching of Object Handling Behaviors by a Humanoid Robot Using a Recurrent Neural Network Model,From Animals to Animats 9,10.1007/11840541_16,Springer,2006-01-01,"The present study describes experiments on a ball handling behavior learning that is realized by a small humanoid robot with a dynamic neural network model, the recurrent neural network with parametric bias (RNNPB). The present experiments show that after the robot learned different types of behaviors through direct human teaching, the robot was able to switch between two types of behaviors based on the ball motion dynamics. We analyzed the parametric bias (PB) space to show that each of the multiple dynamic structures acquired in the RNNPB corresponds with taught multiple behavior patterns and that the behaviors can be switched by adjusting the PB values.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11840541_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11893295_96,Mobile Robot Control Using Fuzzy-Neural-Network for Learning Human Behavior,Neural Information Processing,10.1007/11893295_96,Springer,2006-01-01,"The knowledge of human walking behavior has primary importance for mobile agent in order to operate in the human shared space, with minimal disturb of other humans. This paper introduces such an observation and learning framework, which can acquire the human walking behavior from observation of human walking, using CCD cameras of the Intelligent Space. The proposed behavior learning framework applies Fuzzy-Neural Network(FNN) to approximate observed human behavior, with observation data clustering in order to extract important training data from observation. Preliminary experiment and results are shown to demonstrate the merit of the introduced behavior.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11893295_96,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/4-431-28576-8_1,The NASA Smart Probe for Real-time Tissue Identification: Potential Applications in Neurosurgery,Minimally Invasive Neurosurgery and Multidisciplinary Neurotraumatology,10.1007/4-431-28576-8_1,Springer,2006-01-01,"It has been well-documented over the last 10 years that optical spectroscopy can identify tissue in real time, e.g. normal versus cancerous tissue in the breast, and white versus gray matter in the brain [ 1 – 3 ]. A light scattering spectroscopy probe has been shown to be at least as accurate asmif not more accurate thanma well-trained pathologist’s review of tissue specimens [4]. However, both the operating room and outer space represent ""hostile"" environments where the redundancy of multiple sensors is essential for reliable tissue identification. The NASA Smart Probe Project utilizes neural network and fuzzy logic algorithms to integrate data from multiple microsensors in real time for tissue identification (Fig 1).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/4-431-28576-8_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-37256-1_29,Adaptive Depth Control for Autonomous Underwater Vehicles Based on Feedforward Neural Networks,Intelligent Control and Automation,10.1007/978-3-540-37256-1_29,Springer,2006-01-01,This paper studies the design and application of the neural network based adaptive control scheme for autonomous underwater vehicle’s (AUV’s) depth control system that is an uncertain nonlinear dynamical one with unknown nonlinearities. The unknown nonlinearity is approximated by a feedforward neural network whose parameters are adaptively adjusted online according to a set of parameter estimation laws for the purpose of driving the AUV to cruise at the preset depth. The Lyapunov synthesis approach is used to develop the adaptive control scheme. The overall control system can guarantee that the tracking error converges in the small neighborhood of zero and all adjustable parameters involved are uniformly bounded. Simulation examples are given to illustrate the design procedure and the applicability of the proposed method. The results indicate that the proposed method is suitable for practical applications.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-37256-1_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11785231_76,Gait Synthesis and Modulation for Quadruped Robot Locomotion Using a Simple Feed-Forward Network,Artificial Intelligence and Soft Computing – ICAISC 2006,10.1007/11785231_76,Springer,2006-01-01,"This paper describes a technique for statically stable gait synthesis for a quadruped robot using a simple Feed Forward Neural Networks (FFNN). A common approach for gait synthesis based on neural networks, is to use an implementation with Continuous Time Recurrent Neural Network (CTRNN) of arbitrary complex architecture as pattern generator for rhythmic limb motion. The preferred training method is implemented using genetic algorithms (GAs). However, to achieve the desired trajectory becomes an obstacle during the training process. This paper presents a much more simpler process converting a statically stable gait into actuator’s space via inverse kinematics; the training of the network is done with those references. By doing so, the training problem becomes a spatio-temporal machine learning problem. It is described a solution for trajectory generation combining a simple oscillator model with a Multilayer Feedforward Neural Network (MFNN) to generate the desired trajectory.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11785231_76,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11760023_174,Position Control Based on Static Neural Networks of Anthropomorphic Robotic Fingers,Advances in Neural Networks - ISNN 2006,10.1007/11760023_174,Springer,2006-01-01,"A position neurocontroller for robot manipulators with a tendon-driven transmission system has been developed allowing to track desired trajectories and reject external disturbances. The main problem to control tendons proceeds from the different dimensions between the joint and the tendon spaces. In order to solve this problem we propose a static neural network in cascade with a torque resolutor. The position controller is built as a parametric neural network by using basis functions obtained directly from the finger structure. This controller insure that the tracking error converges to zero and the weights of the network are bounded. The implementation has been improved partitioning the neural network into subnets and using the Kronecker product. Both control and weight updating laws have been designed by means of a Lyapunov energy function. In order to improve the computational efficient of the neural network, this has been split up into subnets to compensate inertial, Coriolis/centrifugal and gravitational effects. The NN weights are initialised at zero and tuned on-line with no ”off-line learning phase”. This scheme has been applied to an anthropomorphic robotic finger with a transmission system based on tendons.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11760023_174,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/4-431-31381-8_21,A Behaviour Network Concept for Controlling Walking Machines,Adaptive Motion of Animals and Machines,10.1007/4-431-31381-8_21,Springer,2006-01-01,"The high complexity of the mechanical system and the difficult task of walking itself makes the task of designing the control for legged robots a diffcult one. Even if the implementation of parts of the desired functionality, like posture control or basic swing/stance movement, can be solved by the usage of classical engeneering approaches, the control of the overall system tends to be very unflexible. This paper introduces a new method to combine apects of classical robot control and behaviour based control. Inspired by the activation patterns in the brain and the spinal cord of animals we propose a behaviour network architecture using special signals like activity or target rating to influencce and coordinate the behaviours. The general concept of a single behaviour as well as their interaction within the network is described. This architecture is tested on the four-legged walking machine BISAM and experimental results are presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/4-431-31381-8_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/4-431-31381-8_18,Towards Emulating Adaptive Locomotion of a Quadrupedal Primate by a Neuro-musculo-skeletal Model,Adaptive Motion of Animals and Machines,10.1007/4-431-31381-8_18,Springer,2006-01-01,"A neuro-musuculo-skeletal model of a quadrupedal primate is constructed in order to elucidate the adaptive nature of primate locomotion by the means of simulation. The model is designed so as to spontaneously induce locomotion adaptive to environment and to its body structure, due to dynamic interaction between convergent dynamics of a recurrent neural network and passive dynamics of a body system. The simulation results show that the proposed model can generate a stepping motion natural to its body structure while maintaining its posture against an external perturbation. The proposed framework for the integrated neuro-control of posture and locomotion may be extended for understanding the adaptive mechanism of primate locomotion.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/4-431-31381-8_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/11788485_5,Plans and Planning in Smart Homes,Designing Smart Homes,10.1007/11788485_5,Springer,2006-01-01,"In this chapter, we review the use (and uses) of plans and planning in Smart Homes. Plans have several applications within Smart Homes, including: sharing task execution with the home’s inhabitants, providing task guidance to inhabitants, and to identifying emergencies. These plans are not necessarily generated automatically, nor are they always represented in a human-readable form. The chapter ends with a discussion of the research issues surrounding the integration of plans and planning into Smart Homes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11788485_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-34783-6_7,A Self-Tuning Controller for Teleoperation System using Evolutionary Learning Algorithms in Neural Networks,"Computational Intelligence, Theory and Applications",10.1007/3-540-34783-6_7,Springer,2006-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-34783-6_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11840817_92,Position Control Based on Static Neural Networks of Anthropomorphic Robotic Fingers,Artificial Neural Networks – ICANN 2006,10.1007/11840817_92,Springer,2006-01-01,"A dynamic neurocontroller for positioning robot manipulators with a tendon-driven transmission system has been developed allowing to track desired trajectories and reject external disturbances. The controller is characterised as providing motor torques rather than joint torques. In this sense, the redundant problem regarded with the tendon-driven transmission systems is solved using neural networks that are able to learned the linear transformation that maps motor torques into joint torques. The neurocontroller not only learn the dynamics associated with the robot manipulator but also the parameters attached to the transmission system such as pulley radii. A theorem relying on the Lyapunov theory has been developed, guaranteeing the uniformly ultimately bounded stability of the whole system and providing both the control laws and weight updating laws.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11840817_92,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/3-540-34319-9_19,Neural Networks,Embedded Robotics,10.1007/3-540-34319-9_19,Springer,2006-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-34319-9_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11881070_57,Neurocontroller Via Adaptive Learning Rates for Stable Path Tracking of Mobile Robots,Advances in Natural Computation,10.1007/11881070_57,Springer,2006-01-01,"In this paper, we present a neurocontroller via adaptive learning rates (ALRs) for stable path tracking of mobile robots. The self recurrent wavelet neural networks (SRWNNs) are employed as two neurocontrollers for the control of the mobile robot. Since the SRWNN combines the advantages such as the multi-resolution of the wavelet neural network and the information storage of the recurrent neural network, it can easily cope with the unexpected change of the system. Specially, the ALR algorithm in the gradient-descent method is extended for the multi-input multi-output system and is applied to train the parameters of the SRWNN controllers. The ALRs are derived from the discrete Lyapunov stability theorem, which are used to guarantee the stable path tracking of mobile robots. Finally, through computer simulations, we demonstrate the effectiveness and stability of the proposed controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11881070_57,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00170-004-2229-x,A new force distribution calculation model for high-quality production processes,The International Journal of Advanced Manufacturing Technology,10.1007/s00170-004-2229-x,Springer,2006-01-01,"Industrial robots have been introduced to the belt grinding of free-form surfaces in order to obtain high-quality products and high-efficiency. One of the critical problems of high-precision belt grinding is to compute the force distribution in the contact area between the workpiece and elastic grinding wheel. The finite element method (FEM) is the traditional way to solve such a contact problem. However, the FEM model is too time-consuming. Normally, a single calculation takes several minutes on a powerful PC, which is unacceptable for real-time simulations and on-line robot control. A new model based on a neural network (NN) technique is developed instead of the FEM model to calculate the force distribution. The new model approximates the old FEM model with an acceptable tolerance but can be executed much faster than FEM model. With this new model, real-time simulation and on-line robot control of grinding processes can be further conducted.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00170-004-2229-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/0-387-28111-8_1,Genetic Programming: Theory and Practice,Genetic Programming Theory and Practice III,10.1007/0-387-28111-8_1,Springer,2006-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/0-387-28111-8_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11840817_91,Morphological Neural Networks and Vision Based Mobile Robot Navigation,Artificial Neural Networks – ICANN 2006,10.1007/11840817_91,Springer,2006-01-01,"Morphological Associative Memories (MAM) have been proposed for image denoising and pattern recognition. We have shown that they can be applied to other domains, like image retrieval and hyperspectral image unsupervised segmentation. In both cases the key idea is that Morphological Autoassociative Memories (MAAM) selective sensitivity to erosive and dilative noise can be applied to detect the morphological independence between patterns. The convex coordinates obtained by linear unmixing based on the sets of morphological independent patterns define a feature extraction process. These features may be useful either for pattern classification. We present some results on the task of visual landmark recognition for a mobile robot self-localization task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11840817_91,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-84628-405-2_7,Example Applications of Fuzzy Reasoning and Neural Networks in Robot Control,Robot Motion and Control,10.1007/978-1-84628-405-2_7,Springer,2006-01-01,"Most typical tasks met in the area of robotics — control of robot manipulators and mobile robots — are performed with use of mathematical models of these devices and their environment. For some time, there have appeared attempts of implementation of artificial intelligence methods in robot control. The paper presents two such applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-84628-405-2_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-005-0344-x,Neural network approach to acquiring free-gait motion of quadruped robots in obstacle avoidance,Artificial Life and Robotics,10.1007/s10015-005-0344-x,Springer,2005-12-01,"In obstacle avoidance by a legged mobile robot, it is not necessary to avoid all of the obstacles by turning only, because it can climb or stride over some of them, depending on the obstacle configuration and the state of the robot, unlike a wheel-type or a crawler-type robot. It is thought that mobility efficiency to a destination is improved by crawling over or striding over obstacles. Moreover, if robots have many legs, like 4-legged or 6-legged types, then the robot's movement range is affected by the order of the swing leg. In this article a neural network (NN) is used to determine the action of a quadruped robot in an obstacle-avoiding situation by using information about the destination, the obstacle configuration, and the robot's self-state. To acquire a free gait in static walking, the order of the swing leg is realized using an alternative NN whose inputs are the amount of movement and the robot's self-state. The design parameters of the former NN are adjusted by a genetic algorithm (GA) off-line.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-005-0344-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-005-9012-6,Design of Adaptive Robot Control System Using Recurrent Neural Network,Journal of Intelligent and Robotic Systems,10.1007/s10846-005-9012-6,Springer,2005-11-01,"The use of a new Recurrent Neural Network (RNN) for controlling a robot manipulator is presented in this paper. The RNN is a modification of Elman network. In order to solve load uncertainties, a fast-load adaptive identification is also employed in a control system. The weight parameters of the network are updated using the standard Back-Propagation (BP) learning algorithm. The proposed control system is consisted of a NN controller, fast-load adaptation and PID-Robust controller. A general feedforward neural network (FNN) and a Diagonal Recurrent Network (DRN) are utilised for comparison with the proposed RNN. A two-link planar robot manipulator is used to evaluate and compare performance of the proposed NN and the control scheme. The convergence and accuracy of the proposed control scheme is proved.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-005-9012-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-005-5137-x,A Reinforcement Learning Algorithm in Cooperative Multi-Robot Domains,Journal of Intelligent and Robotic Systems,10.1007/s10846-005-5137-x,Springer,2005-08-01,"Reinforcement learning has been widely applied to solve a diverse set of learning tasks, from board games to robot behaviours. In some of them, results have been very successful, but some tasks present several characteristics that make the application of reinforcement learning harder to define. One of these areas is multi-robot learning, which has two important problems. The first is credit assignment, or how to define the reinforcement signal to each robot belonging to a cooperative team depending on the results achieved by the whole team. The second one is working with large domains, where the amount of data can be large and different in each moment of a learning step. This paper studies both issues in a multi-robot environment, showing that introducing domain knowledge and machine learning algorithms can be combined to achieve successful cooperative behaviours.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-005-5137-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10015-004-0334-4,Application of a neural network to the generation of a robot arm trajectory,Artificial Life and Robotics,10.1007/s10015-004-0334-4,Springer,2005-07-01,"We propose a neural network model generating a robot arm trajectory. The developed neural network model is based on a recurrent-type neural network (RNN) model calculating the proper arm trajectory based on data acquired by evaluation functions of human operations as the training data. A self-learning function has been added to the RNN model. The proposed method is applied to a 2-DOF robot arm, and laboratory experiments were executed to show the effectiveness of the proposed method. Through experiments, it is verified that the proposed model can reproduce the arm trajectory generated by a human. Further, the trajectory of a robot arm is successfully modified to avoid collisions with obstacles by a self-learning function.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10015-004-0334-4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1631/jzus.2005.A0549,Neural network and genetic algorithm based global path planning in a static environment,Journal of Zhejiang University-SCIENCE A,10.1631/jzus.2005.A0549,Springer,2005-06-01,Mobile robot global path planning in a static environment is an important problem. The paper proposes a method of global path planning based on neural network and genetic algorithm. We constructed the neural network model of environemntal information in the workspace for a robot and used this model to establish the relationship between a collision avoidance path and the output of the model. Then the two-dimensional coding for the path via-points was converted to one-dimensional one and the fitness of both the collision avoidance path and the shortest distance are integrated into a fitness function. The simulation results showed that the proposed method is correct and effective.,http://link.springer.com/openurl/fulltext?id=doi:10.1631/jzus.2005.A0549,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11023-005-4734-6,Of Robots and Believing,Minds and Machines,10.1007/s11023-005-4734-6,Springer,2005-05-01,"Discussion about the application of scientific knowledge in robotics in order to build people helpers is widespread. The issue herein addressed is philosophically poignant, that of robots that are “people”. It is currently popular to speak about robots and the image of Man. Behind this lurks the dialogical mind and the questions about the significance of an artificial version of it. Without intending to defend or refute the discourse in favour of ‘recreating’ Man, a lesser familiar question is brought forth: “and what if we were capable of creating a very convincible replica of man (constructing a robot-person), what would the consequences of this be and would we be satisfied with such technology?” Thorny topic; it questions the entire knowledge foundation upon which strong AI/Robotics is positioned. The author argues for improved monitoring of technological progress and thus favours implementing weaker techniques.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11023-005-4734-6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10994-005-0460-9,Evolving Soccer Keepaway Players Through Task Decomposition,Machine Learning,10.1007/s10994-005-0460-9,Springer,2005-05-01,"Complex control tasks can often be solved by decomposing them into hierarchies of manageable subtasks. Such decompositions require designers to decide how much human knowledge should be used to help learn the resulting components. On one hand, encoding human knowledge requires manual effort and may incorrectly constrain the learner’s hypothesis space or guide it away from the best solutions. On the other hand, it may make learning easier and enable the learner to tackle more complex tasks. This article examines the impact of this trade-off in tasks of varying difficulty. A space laid out by two dimensions is explored: (1) how much human assistance is given and (2) how difficult the task is. In particular, the neuroevolution learning algorithm is enhanced with three different methods for learning the components that result from a task decomposition. The first method, coevolution, is mostly unassisted by human knowledge. The second method, layered learning, is highly assisted. The third method, concurrent layered learning, is a novel combination of the first two that attempts to exploit human knowledge while retaining some of coevolution’s flexibility. Detailed empirical results are presented comparing and contrasting these three approaches on two versions of a complex task, namely robot soccer keepaway, that differ in difficulty of learning. These results confirm that, given a suitable task decomposition, neuroevolution can master difficult tasks. Furthermore, they demonstrate that the appropriate level of human assistance depends critically on the difficulty of the problem.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10994-005-0460-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-32391-0_34,Improving the Robustness of Reinforcement Learning for a Multi-Robot System Environment,Soft Computing as Transdisciplinary Science and Technology,10.1007/3-540-32391-0_34,Springer,2005-01-01,"We have been developing a new reinforcement learning called BRL, which is especially effective to multi-robot systems (MRS). BRL has a unique feature that it not only learns in the learning space but also changes the segmentation of the learning space simultaneously. BRL has been proved to be clearly effective than the other standard RL algorithms to MRS problems where the learning environment is naturally dynamic. However, we have also noticed that MRS needs the more robustness for the learning mechanism as the complexity level increases. In this paper, BRL is extended to improve the robustness against the dynamics in a learning environment by showing a way of overcoming the unwanted feature of over-fitting. Computer simulations are conducted to illustrate the robust performance of the proposed technique.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-32391-0_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-30501-9_43,Recurrent Neural Network for Robot Path Planning,Parallel and Distributed Computing: Applications and Technologies,10.1007/978-3-540-30501-9_43,Springer,2005-01-01,"A novel model of organized neural network is shown to be very effective for path planning and obstacle avoidance in an unknown map which is represented by topologically ordered neurons. With the limited information of neighbor position and distance of the target position, robot will autonomously provide a proper path with free-collision and no redundant exploring in the process of exploring. The computer simulation will illustrate the performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-30501-9_43,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/11504634_4,Continuous Reinforcement Learning Algorithm for Skills Learning in an Autonomous Mobile Robot,Machine Learning and Robot Perception,10.1007/11504634_4,Springer,2005-01-01,"In the last years, one of the main challenges in robotics is to endow the robots with a grade of intelligence in order to allow them to extract information from the environment and use that knowledge to carry out their tasks safely. The intelligence allows the robots to improve their survival in the real world. Two main characteristics that every intelligent system must have are [1]:",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11504634_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-211-27389-1_27,Applying Neural Network to Inverse Kinematic Problem for 6R Robot Manipulator with Offset Wrist,Adaptive and Natural Computing Algorithms,10.1007/3-211-27389-1_27,Springer,2005-01-01,"An Artificial Neural Network (ANN) using backpropagation algorithm is applied to solve inverse kinematics problems of industrial robot manipulator. 6R robot manipulator with offset wrist was chosen as industrial robot manipulator because geometric feature of this robot does not allow to solve inverse kinematics problems analytically. In other words, there is no closed form solution for this problem. As the number of neurons at hidden layer is varied between 4 and 32, the robot joint angles ( θ _1 θ _2… θ _6) were predicted with average errors of 8.9°, 7.8°, 8.3°, 13°, 8.5°, and 10.5° for the 1^st, 2^nd, 3^rd, 4^th and 6^th joint, respectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-211-27389-1_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11539117_40,Adaptive Neural Network Control for Multi-fingered Robot Hand Manipulation in the Constrained Environment,Advances in Natural Computation,10.1007/11539117_40,Springer,2005-01-01,"This note presents a robust adaptive neural network (NN) control scheme for multi-fingered robot hand manipulation system in the constrained environment to achieve arbitrarily small motion and force tracking errors. The controllers consist of the model-based controller, the NN controller and the robust controller. The model-based controller deals with the nominal dynamics of the manipulation system. The NN handles the unstructured dynamics and external disturbances. The NN weights are tuned online, without the offline learning phase. The robust controller is introduced to compensate for the effects of residual uncertainties. An adaptive law is developed so that no priori knowledge of the bounds for residual uncertainties is required. Most importantly, the exponential convergence properties for motion and force tracking are achieved.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11539117_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11551188_10,Making Use of Unelaborated Advice to Improve Reinforcement Learning: A Mobile Robotics Approach,Pattern Recognition and Data Mining,10.1007/11551188_10,Springer,2005-01-01,"Reinforcement Learning (RL) is thought to be an appropriate paradigm for acquiring control policies in mobile robotics. However, in its standard formulation ( tabula rasa ) RL must explore and learn everything from scratch, which is neither realistic nor effective in real-world tasks. In this article we use a new strategy, called Supervised Reinforcement Learning (SRL), that allows the inclusion of external knowledge within this type of learning. We validate it by learning a wall-following behaviour and testing it on a Nomad 200 robot. We show that SRL is able to take advantage of multiple sources of knowledge and even from partially erroneous advice, features that allow a SRL agent to make use of a wide range of prior knowledge without the need for a complex or time-consuming elaboration.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11551188_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11589990_195,Bio-inspired Control of Dexterous Manipulation,AI 2005: Advances in Artificial Intelligence,10.1007/11589990_195,Springer,2005-01-01,"Robots successfully manipulate objects in controlled environments. However, they fail in unknown environments. Few years old children lift and manipulate unfamiliar objects more dexterously than today’s robots. Therefore, roboticists are looking for inspiration on neurophysiological studies to improve their robotics control models. We present an artificial intelligence control model for dexterous manipulation, and a grip and load force control algorithm, strongly inspired on neurophysiological studies of the human manipulation process.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11589990_195,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-005-3509-x,An application of artificial intelligence to medical robotics,Journal of Intelligent and Robotic Systems,10.1007/s10846-005-3509-x,Springer,2005-01-01,"In this paper an application of Artificial Intelligence (AI) to Medical Robotics is described. Namely, a specific AI technique is employed to generate a sequence of operations understandable by the control system of a robot which is to perform a semi-automatic surgical task. According to this technique, a planner is implemented to translate the “natural” language of the surgeon into the robotic sequence that should be executed by the robot. A robotic simulator has been implemented in order to test the planned sequence in a virtual environment. The planned sequence is then to be input to the medical robotic system, which will execute the surgical operation. The work described in this paper features a high level of originality, since no similar applications of AI to medical robotics could be found in the scientific literature.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-005-3509-x,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:DOItmp_0558_030750,Visual Robot Detection in RoboCup Using Neural Networks,RoboCup 2004: Robot Soccer World Cup VIII,DOItmp_0558_030750,Springer,2005-01-01,Robot recognition is a very important point for further improvements in game-play in RoboCup middle size league. In this paper we present a neural recognition method we developed to find robots using different visual information. Two algorithms are introduced to detect possible robot areas in an image and a subsequent recognition method with two combined multi-layer perceptrons is used to classify this areas regarding different features. The presented results indicate a very good overall performance of this approach.,http://link.springer.com/openurl/pdf?id=doi:DOItmp_0558_030750,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11556114_31,Probabilistic Techniques for Mobile Robot Navigation,Spatial Information Theory,10.1007/11556114_31,Springer,2005-01-01,"In recent years, probabilistic techniques have enabled novel and innovative solutions to some of the most important problems in mobile robotics. Major challenges in the context of probabilistic algorithms for mobile robot navigation lie in the questions of how to deal with highly complex state estimation problems and how to control the robot so that it efficiently carries out its task. In this talk I will discuss both aspects and present techniques currently being developed in my group regarding the problem of controlling a robot to efficiently learn a map of an unknown environment. I then will describe how a team of mobile robots can be coordinated to effectively explore unknown environments. Additionally, I will present probabilistic approaches to learn three-dimensional models from range data as well as techniques for classifying places based on range and vision data. For all algorithms I will present experimental results, which have been obtained with mobile robots in real-world environments as well as in simulation. I will conclude the presentation with a discussion of open issues and potential directions for future research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11556114_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11427469_31,A Neural Network Based on Biological Vision Learning and Its Application on Robot,Advances in Neural Networks – ISNN 2005,10.1007/11427469_31,Springer,2005-01-01,"This paper proposes a neural network called “Hierarchical Overlapping Sensory Mapping (HOSM)”, motivated by the structure of receptive fields in biological vision. To extract the features from these receptive fields, a method called Candid covariance-free Incremental Principal Component Analysis (CCIPCA) is used to automatically develop a set of orthogonal filters. An application of HOSM on a robot with eyes shows that the HOSM algorithm can pay attention to different targets and get its cognition for different environments in real time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11427469_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11550907_66,Comparison of Neural Network Robot Models with Not Inverted and Inverted Inertia Matrix,Artificial Neural Networks: Formal Models and Their Applications – ICANN 2005,10.1007/11550907_66,Springer,2005-01-01,"The mathematical model of an industrial robot is usually described in the form of Lagrange-Euler equations, Newton-Euler equations or generalized d’Alambert equations. However, these equations require the physical parameters of a robot that are difficult to obtain. In this paper, two methods for calculation of a Lagrange-Euler model of robot using neural networks are presented and compared. The proposed network structure is based on an approach where either a not inverted or inverted inertia matrix is calculated. The presented models show good performance for different sets of data.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11550907_66,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11596448_19,Gait Control for Biped Robot Using Fuzzy Wavelet Neural Network,Computational Intelligence and Security,10.1007/11596448_19,Springer,2005-01-01,"A new reference trajectory of walking on the ground for a five-link biped robot, considering both the SSP and the DSP, is developed firstly. And a fuzzy wavelet neural network controller to generate walking gaits to follow the reference trajectories is presented subsequently. Furthermore, an error compensation algorithm is presented for high accuracy. The reference trajectories are designed by solving the coefficients of time polynomial functions of the trajectories of the hip and the swing tip, through the constraint equations. The FWN controller is trained as inverse kinematic model of the biped robot by backpropagation algorithm offline. Simulation results show that the FWN controller can generate the gaits following the reference trajectories as close as possible, and the error compensation algorithm can decrease the error rapidly by iterative calculation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11596448_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11427469_46,A Neural Network Based Method for Shape Measurement in Steel Plate Forming Robot,Advances in Neural Networks – ISNN 2005,10.1007/11427469_46,Springer,2005-01-01,"Shape measurement is one of the critical problems in manufacturing robot systems. The point coordinates that we get change distinctly, because different objects to be processed own various shape forms. So it is difficult for traditional methods to get original accurate shape information. It always affects the processing results of manufacturing robot systems. According to the shipbuilding requirements, this paper proposes a dynamic and intelligent shape measurement method, which is based on the fuzzy reasoning (FR) and neural network (NN) method. FR is used to judge the relation of measured points. As the input of the NN, the fitted coordinate and the possibility of the rim point can be got. It has been demonstrated effective in Dalian Shipbuilding manufacturing robot system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11427469_46,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11427469_42,Research on the Calibration Method for the Heading Errors of Mobile Robot Based on Evolutionary Neural Network Prediction,Advances in Neural Networks – ISNN 2005,10.1007/11427469_42,Springer,2005-01-01,"Fiber optic gyros (FOG) is the important sensor for measuring the heading of mobile robot. Combined with measured data of E-Core RD1100 interferometric FOG made by American KVH company, the paper analyses the common calibration for the heading errors of mobile robot caused by the drift of FOG, and uses the method of evolutionary neural networks prediction to compensate it. By the experiments of mobile robot prototype, the paper also proves this method can reduce the error influence of FOG on the heading of mobile robot and enhance the localization precision of mobile robot navigation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11427469_42,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11589990_97,A Facial Control Method Considering Internal Emotion of Sensibility Robot,AI 2005: Advances in Artificial Intelligence,10.1007/11589990_97,Springer,2005-01-01,"This paper presents a method that enable a domestic robot to show emotions with its facial expressions. The previous methods using built-in facial expressions were able to show only scanty face. To express faces showing complex emotion, mixed emotions and different strengths of emotions, more facial expressions are needed. We have therefore developed a system that converts emotions into “Ifbot” robot’s facial expressions automatically. They are created from emotion parameters , which represent its emotions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11589990_97,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11539902_89,Adaptive Inverse Control of an Omni-Directional Mobile Robot,Advances in Natural Computation,10.1007/11539902_89,Springer,2005-01-01,"The omni-directional mobile robot developed by Shanghai Jiaotong University was introduced. The inverse kinematics and dynamics of the robot were modeled for decoupled control simulation. An adaptive inverse control (AIC) scheme incorporating Dynamic neural network (DNN) controller and conventional feedback controller was presented. Finally, linear and circular trajectories following simulation results demonstrate that the AIC can decouple the dynamic control of the robot motion in the plane to direct rotational speed control of independent wheels, and precise trajectory following is achieved.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11539902_89,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11504894_81,Self-organizing Radial Basis Function Network Modeling for Robot Manipulator,Innovations in Applied Artificial Intelligence,10.1007/11504894_81,Springer,2005-01-01,"Intelligent and adaptive approach to model two links manipulator system with self-organizing radial basis function (RBF) network is presented in this paper. The self-organizing algorithm that enables the RBF neural network to be structured automatically and on-line is developed, and with this proposed scheme, the centers and widths of RBF neural network as well as the weights are to be adaptively determined. Based on the fact that a 3-layered RBF neural network has the capability that represents the nonlinear input-output map of any nonlinear function to a desired accuracy, the input output mapping of the two link manipulator using the proposed RBF neural network is shown analytically through experimental results without knowing the information of the system in advance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11504894_81,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11550822_73,Fast Color-Based Object Recognition Independent of Position and Orientation,Artificial Neural Networks: Biological Inspirations – ICANN 2005,10.1007/11550822_73,Springer,2005-01-01,"Small mobile robots typically have little on-board processing power for time-consuming vision algorithms. Here we show how they can quickly extract very dense yet highly useful information from color images. A single pass through all pixels of an image serves to segment it into color-dependent regions and to compactly represent it by a short list of the average hues, saturations and color intensities of its regions; all other information is discarded. Experiments with two image databases show that in 90 % of all cases the remaining information is sufficient for a simple weighted voting algorithm to recognize objects shown in query images, independently of position and orientation and partial occlusions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11550822_73,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11539117_97,Quantum Reinforcement Learning,Advances in Natural Computation,10.1007/11539117_97,Springer,2005-01-01,"A novel quantum reinforcement learning is proposed through combining quantum theory and reinforcement learning. Inspired by state superposition principle, a framework of state value update algorithm is introduced. The state/action value is represented with quantum state and the probability of action eigenvalue is denoted by probability amplitude, which is updated according to rewards. This approach makes a good tradeoff between exploration and exploitation using probability and can speed up learning. The results of simulated experiment verified its effectiveness and superiority.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11539117_97,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-32274-0_17,Combining Planning with Reinforcement Learning for Multi-robot Task Allocation,Adaptive Agents and Multi-Agent Systems II,10.1007/978-3-540-32274-0_17,Springer,2005-01-01,"We describe an approach to the multi-robot task allocation (MRTA) problem in which a group of robots must perform tasks that arise continuously, at arbitrary locations across a large space. A dynamic scheduling algorithm is derived in which proposed plans are evaluated using a combination of short-term lookahead and a value function acquired by reinforcement learning. We demonstrate that this dynamic scheduler can learn not only to allocate robots to tasks efficiently, but also to position the robots appropriately in readiness for new tasks (tactical awareness), and conserve resources over the long run (strategic awareness).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-32274-0_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-30549-1_25,A Dynamic Allocation Method of Basis Functions in Reinforcement Learning,AI 2004: Advances in Artificial Intelligence,10.1007/978-3-540-30549-1_25,Springer,2005-01-01,"In this paper, we propose a dynamic allocation method of basis functions, an Allocation/Elimination Gaussian Softmax Basis Function Network (AE-GSBFN), that is used in reinforcement learning. AE-GSBFN is a kind of actor-critic method that uses basis functions. This method can treat continuous high-dimensional state spaces, because basis functions required only for learning are dynamically allocated, and if an allocated basis function is identified as redundant, the function is eliminated. This method overcomes the curse of dimensionality and avoids a fall into local minima through the allocation and elimination processes. To confirm the effectiveness of our method, we used a maze task to compare our method with an existing method, which has only an allocation process. Moreover, as learning of continuous high-dimensional state spaces, our method was applied to motion control of a humanoid robot. We demonstrate that the AE-GSBFN is capable of providing better performance than the existing method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-30549-1_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11539902_88,Hexagon-Based Q-Learning for Object Search with Multiple Robots,Advances in Natural Computation,10.1007/11539902_88,Springer,2005-01-01,"This paper presents the hexagon-based Q-leaning for object search with multiple robots. We set up an experimental environment with five small mobile robots, obstacles, and a target object. The robots were out to search for a target object while navigating in a hallway where some obstacles were placed. In this experiment, we used three control algorithms: a random search, an area-based action making (ABAM) process to determine the next action of the robots, and hexagon-based Q-learning to enhance the area-based action making process.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11539902_88,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11427469_45,Abnormal Movement State Detection and Identification for Mobile Robots Based on Neural Networks,Advances in Neural Networks – ISNN 2005,10.1007/11427469_45,Springer,2005-01-01,"Movement state estimation plays an important role in navigating and movement controlling for wheeled mobile robots (WMRs), especially those in unknown environments such as planetary exploration. When exploring in unknown environments, mobile robot suffers from many kinds of abnormal movement state, such as baffled by an obstacle, slipping, among others. This paper employs neural network method to detect abnormal movement states. Specifically, it exploits the kinematics of the normal and abnormal movement states of the monitored robot. Several residuals are exploited and four probabilistic neural networks are used to classify the residuals. Simulation experiments show that the methods can detect and identify most abnormal movement states.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11427469_45,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-31182-3_57,Neural Networks for the Control of Soccer Robots,"Computational Intelligence, Theory and Applications",10.1007/3-540-31182-3_57,Springer,2005-01-01,"In 1995 robot soccer was introduced with the purpose to develop intelligent, cooperative multi-robot (agents) systems. Robot soccer provides a good opportunity to test control strategies and methods of Multi-Agent-Systems. From the scientific viewpoint a soccer robot is an intelligent, autonomous agent which should carry out its task in cooperative, coordinated, and communicative way with other agents. The group behavior of agents and the behavior of a single agent should be explored. One of the single agent’s behaviors is the motion control. The desired velocity of each wheel is generated and sent to the robot comparing the desired and actual position of the robot. The mostly used motion controller today is the digital PID-controller. In this paper as a “modern”, intelligent control algorithm a neural network will be introduced and tested.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-31182-3_57,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-29461-9_53,Learning of the Dynamic Walk of an Under-Actuated Bipedal Robot: Improvement of the Robustness by Using CMAC Neural Networks,Climbing and Walking Robots,10.1007/3-540-29461-9_53,Springer,2005-01-01,"In this paper, we propose a new control strategy based on the use of the neural network CMAC in order to control the under-actuated robot RABBIT. This control strategy is very easy to implement on-line and robust. The first result of the experimental validation is presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-29461-9_53,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-32256-6_56,Robots from Nowhere,RoboCup 2004: Robot Soccer World Cup VIII,10.1007/978-3-540-32256-6_56,Springer,2005-01-01,"In this study, a new method called Reverse Monte Carlo Localization (R-MCL) for global localization of autonomous mobile agents in the robotic soccer domain is proposed to overcome the uncertainty in the sensors, environment and the motion model. This is a hybrid method based on both Markov Localization(ML) and Monte Carlo Localization(MCL) where the ML module finds the region where the robot should be and MCL predicts the geometrical location with high precision by selecting samples in this region. The method is very robust and fast and requires less computational power and memory compared to similar approaches and is accurate enough for high level decision making which is vital for robot soccer.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-32256-6_56,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-32391-0_93,Multiple Mobile Robots Navigation in a Cluttered Environment using Neuro-Fuzzy Controller,Soft Computing as Transdisciplinary Science and Technology,10.1007/3-540-32391-0_93,Springer,2005-01-01,"The development of techniques for a navigation of multiple mobile robots is abroad topic, covering a large spectrum of different technologies and applications. Neural networks and fuzzy logic control techniques can improve real-time control performance for a mobile robot due to their high robustness and error-tolerance ability. This paper proposes a neuro-fuzzy (NF) controller, which integrates the transparency of the fuzzy logic with the learning capability of neural networks is developed for multiple mobile robots navigation in an unknown environment. The neuro-fuzzy controller developed in this research consists of a neural network pre-processor followed by a fuzzy logic controller. The former is structured using multi-layer perceptron (MLP) or local model network (LMN). Practical results reflect the soundness of the proposed scheme.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-32391-0_93,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-004-3027-2,A Proposed Hybrid Recurrent Neural Control System for Two Co-operating Robots,Journal of Intelligent and Robotic Systems,10.1007/s10846-004-3027-2,Springer,2005-01-01,"This paper discusses a model refernce adaptive (MRAC) position/force controller using proposed neural networks for two co-operating planar robots. The proposed neural network is a recurrent hybrid network. The recurrent networks have feedback connections and thus an inherent memory for dynamics, which makes them suitable for representing dynamic systems. A feature of the networks adopted is their hybrid hidden layer, which includes both linear and nonlinear neurons. On the other hand, the results of the case of a single robot under position control alone are presented for comparison. The results presented show the superior ability of the proposed neural network based model reference adaptive control scheme at adapting to changes in the dynamics parameters of robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-004-3027-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/11521082_11,A Spiking Neural Network Model of Multi-modal Language Processing of Robot Instructions,Biomimetic Neural Learning for Intelligent Robots,10.1007/11521082_11,Springer,2005-01-01,"Presented is a spiking neural network architecture of human language instruction recognition and robot control. The network is based on a model of a leaky Integrate-And-Fire (lIAF) spiking neurone with Active Dendrites and Dynamic Synapses (ADDS) [1,2,3]. The architecture contains several main modules associating information across different modalities: an auditory system recognising single spoken words, a visual system recognising objects of different colour and shape, motor control system for navigation and motor control and a working memory. The main focus of this presentation is the working memory module whose function is sequential processing of word from a language instruction, task and goal representation and cross-modal association of objects and actions. We test the model with a robot whose goal is to recognise and execute language instructions. The work demonstrates the potential of spiking neurons for processing spatio-temporal patterns and the experiments present spiking neural networks as a paradigm which can be applied for modelling sequence detectors at word level for robot instructions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11521082_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11427469_44,A Neural Network-Based Camera Calibration Method for Mobile Robot Localization Problems,Advances in Neural Networks – ISNN 2005,10.1007/11427469_44,Springer,2005-01-01,"To navigate reliably in indoor environments, a mobile robot has to know where it is. The methods for pose (position and orientation) estimation can be roughly divided into two classes: methods for keeping track of the robot’s pose and methods for global pose estimation [1]. In this paper, a neural network-based camera calibration method is presented for the global localization of mobile robots with monocular vision. In order to localize and navigate the robot using vision information, the camera has to be first calibrated. We calibrate the camera using the neural network based method, which can simplify the tedious calibration process and does not require specialized knowledge of the 3D geometry and computer vision. The monocular vision is used to initialize and recalibrate the robot’s pose, and the extended Kalman filter is adopted to keep track of the mobile robot’s pose.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11427469_44,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/11521082_17,MaximumOne: An Anthropomorphic Arm with Bio-inspired Control System,Biomimetic Neural Learning for Intelligent Robots,10.1007/11521082_17,Springer,2005-01-01,"In this paper we present our bio-mimetic artificial arm and the simulation results on its low level control system. In accordance with the general view of the Biorobotics field we try to replicate the structure and the functionalities of the natural limb. The control system is organized in a hierarchical way, the low level control reproduces the human spinal reflexes and the high level control the circuits present in the cerebral motor cortex and the cerebellum. Simulation show how the system controls the single joint position reducing the stiffness during the movement.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11521082_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/3-540-32364-3_4,Evolving Controllers for Miniature Robots,Evolvable Machines,10.1007/3-540-32364-3_4,Springer,2005-01-01,"In the previous sections we have seen how the evolutionary computations algorithms were successfully used to evolve many types of controllers for Khepera robot. It was used to evolve neural network synaptic weights in the obstacle avoidance behavior of experiment 1 and the battery recharging behavior of experiment 3. We have also seen how it can evolve the architecture of the neural network along with the synaptic weights as in the experiment of evolving light seeking behavior. Alternatively, it can evolve the learning rules and learning rate necessary for training the neural network synaptic weights. Other types of controllers were successfully evolved too, such as fuzzy logic controllers and computer programs. Many other experiments are conducted using evolutionary computations on different robotic platforms recently. In fact, evolutionary computation is a very promising approach for designing controllers for mobile robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-32364-3_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11579427_103,Gait Synthesis Based on FWN and PD Controller for a Five-Link Biped Robot,MICAI 2005: Advances in Artificial Intelligence,10.1007/11579427_103,Springer,2005-01-01,"A new reference walking trajectory for a planar five-link biped, considering both the SSP and the DSP, is presented firstly. A new combined controller to generate walking gaits following the reference trajectory is designed subsequently. The controller of five-link biped is consisted of PD controller and a fuzzy wavelet neural network controller. The scalable and shiftable coefficients of the wavelet function and weights of the network can be acquired by training the network by back-propagation algorithm online. The simulation results of the reference trajectory show that the proposed reference trajectory have good stability, repeatability and continuity during both SSP and the DSP, and when given the different initial conditions, the compatible trajectories can be achieved correspondingly. The simulation results of the trained controller show that the controller can generate the walking gaits to track the reference trajectory as close as possible.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11579427_103,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11579427_115,Stable Task Space Neuro Controller for Robot Manipulators Without Velocity Measurements,MICAI 2005: Advances in Artificial Intelligence,10.1007/11579427_115,Springer,2005-01-01,In this work a stable task space neuro algorithm for set-point control of robot manipulators with uncertain parameters is proposed. A depart from current approaches is the fact that a Wavelet Neural Network with on-line real-time learning seeks to explicitly compensate both the unknown gravity terms and the mismatch between the true and the estimated Jacobian matrix and the fact that it does not need velocity measurements. Linear position filtering is used to estimated the robot joint velocity in the control law and the properties of the Wavelet Neural Network are employed for avoiding velocity measurements in the learning rule. It is shown that all the closed loop signals are uniformly ultimately bounded. Experimental results in a two degrees of freedom robot are presented to evaluate the proposed controller.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/11579427_115,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11553090_31,Whisker-Based Texture Discrimination on a Mobile Robot,Advances in Artificial Life,10.1007/11553090_31,Springer,2005-01-01,"Sensing in the dark is a useful but challenging task both for biological agents and robots. Rats and mice use whiskers for the active exploration of their environment. We have built a robot equipped with two active whisker arrays and tested whether they can provide reliable texture information. While it is relatively easy to classify data recorded at a specified distance and angle to the object, it is more challenging to achieve texture discrimination on a mobile robot. We used a standard neural network classifier to show that it is in principle possible to discriminate textures using whisker sensors even under real-world conditions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11553090_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11553090_28,Self-assembly on Demand in a Group of Physical Autonomous Mobile Robots Navigating Rough Terrain,Advances in Artificial Life,10.1007/11553090_28,Springer,2005-01-01,"Consider a group of autonomous, mobile robots with the ability to physically connect to one another (self-assemble). The group is said to exhibit functional self-assembly if the robots can choose to self-assemble in response to the demands of their task and environment [15]. We present the first robotic controller capable of functional self-assembly implemented on a real robotic platform. The task we consider requires a group of robots to navigate over an area of unknown terrain towards a target light source. If possible, the robots should navigate to the target independently. If, however, the terrain proves too difficult for a single robot, the robots should self-assemble into a larger group entity and collectively navigate to the target. We believe this to be one of the most complex tasks carried out to date by a team of physical autonomous robots. We present quantitative results confirming the efficacy of our controller. This puts our robotic system at the cutting edge of autonomous mobile multi-robot research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11553090_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/11521082_1,Towards Biomimetic Neural Learning for Intelligent Robots,Biomimetic Neural Learning for Intelligent Robots,10.1007/11521082_1,Springer,2005-01-01,"We present a brief overview of the chapters in this book that relate to the development of intelligent robotic systems that are inspired by neuroscience concepts. Firstly, we concentrate on the research of the MirrorBot project which focuses on biomimetic multimodal learning in a mirror neuron-based robot. This project has made significant developments in biologically inspired neural models using inspiration from the mirror neuron system and modular cerebral cortex organisation of actions for use in an intelligent robot within an extended ‘pick and place’ type scenario. The hypothesis under investigation in the MirrorBot project is whether a mirror neuron-based cell assembly model can produce a life-like perception system for actions. Various models were developed based on principles such as cell assemblies, associative neural networks, and Hebbian-type learning in order to associate vision, language and motor concepts. Furthermore, we introduce the chapters of this book from other researchers who attended our AI-workshop on NeuroBotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11521082_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/11521082_5,A Hybrid Architecture Using Cross-Correlation and Recurrent Neural Networks for Acoustic Tracking in Robots,Biomimetic Neural Learning for Intelligent Robots,10.1007/11521082_5,Springer,2005-01-01,Audition is one of our most important modalities and is widely used to communicate and sense the environment around us. We present an auditory robotic system capable of computing the angle of incidence (azimuth) of a sound source on the horizontal plane. The system is based on some principles drawn from the mammalian auditory system and using a recurrent neural network (RNN) is able to dynamically track a sound source as it changes azimuthally within the environment. The RNN is used to enable fast tracking responses to the overall system. The development of a hybrid system incorporating cross-correlation and recurrent neural networks is shown to be an effective mechanism for the control of a robot tracking sound sources azimuthally.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/11521082_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11494669_85,Pruning Neural Networks for a Two-Link Robot Control System,Computational Intelligence and Bioinspired Systems,10.1007/11494669_85,Springer,2005-01-01,"Two-link robot arm model is extensively used in literatures for that it is simple enough to simulate conveniently, yet contains all the nonlinear terms arising in general n-link manipulators. And neural networks are reported to be computationally efficient compared with traditional PID control and adaptive control. However, when a neural network is applied, one of the key step is to choose the optimal number of neurons. In this paper, a relative large number of neurons are initially used, which is pruned during the training. The conic sector theory is introduced in the design of this robust neural control system, which aims at providing guaranteed boundedness for both the input-output(I/O) signals and the weights of the neural network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11494669_85,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-32256-6_21,Visual Robot Detection in RoboCup Using Neural Networks,RoboCup 2004: Robot Soccer World Cup VIII,10.1007/978-3-540-32256-6_21,Springer,2005-01-01,Robot recognition is a very important point for further improvements in game-play in RoboCup middle size league. In this paper we present a neural recognition method we developed to find robots using different visual information. Two algorithms are introduced to detect possible robot areas in an image and a subsequent recognition method with two combined multi-layer perceptrons is used to classify this areas regarding different features. The presented results indicate a very good overall performance of this approach.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-32256-6_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-29461-9_72,From Passive to Active Dynamic 3D Bipedal Walking — An Evolutionary Approach,Climbing and Walking Robots,10.1007/3-540-29461-9_72,Springer,2005-01-01,"Applying an evolutionary algorithm, we first develop the morphology of a simulated passive dynamic bipedal walking device, able to walk down a shallow slope. Using the resulting morphology and adding minimal motor and sensory equipment, a neural controller is evolved, enabling the walking device to walk on a flat surface with minimal energy consumption. The applied evolutionary algorithm fixes neither the size nor the structure of the artificial neural network. Especially, it is able to generate recurrent networks, small enough to be analyzed with respect to their behavior relevant inner dynamics. An example of such a controller is given which realizes also minimal energy consumption.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-29461-9_72,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-004-0424-1,Neural networks for the EMOBOT robot control architecture,Neural Computing & Applications,10.1007/s00521-004-0424-1,Springer,2004-12-01,"Within the EMOBOT approach to adaptive behaviour, the task of learning to control the behaviour is one of the most interesting challenges. Learned action selection between classically implemented control mechanisms, with respect to internal values and sensor readings, provides a way to modulate a variety of behavioural capabilities. To demonstrate the potential of the learning emotional controller, we chose a 10-5-12 MLP to implement the σ , α controller of the EMOBOT. Since no teacher vector is available for the chosen task, the neural network is trained with a reinforcement strategy. The emotion-value-dependent reinforcement signal, together with the output of the network, is the basis with which to compute an artificial teacher vector. Then, the established gradient descent method (backpropagation of error) is applied to train the neural network. First results obtained by extensive simulations show that a still unrevealed richness in behaviour can be realised when using the neural-network-based learning emotional controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-004-0424-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF02990433,A robust control with a neural network structure for uncertain robot manipulator,KSME International Journal,10.1007/BF02990433,Springer,2004-11-01,"A robust position control with the bound function of neural network structure is proposed for uncertain robot manipulators. The uncertain factors come from imperfect knowledge of system parameters, payload change, friction, external disturbance, and etc. Therefore, uncertainties are often nonlinear and time-varying. The neural network structure presents the bound function and does not need the concave property of the bound function. The robust approach is to solve this problem as uncertainties are included in a model and the controller can achieve the desired properties in spite of the imperfect modeling. Simulation is performed to validate this law for four-axis SCARA type robot manipulator.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF02990433,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00170-003-1585-2,Visual feedback control of a robot in an unknown environment (learning control using neural networks),The International Journal of Advanced Manufacturing Technology,10.1007/s00170-003-1585-2,Springer,2004-10-01,"In this paper, a visual feedback control approach based on neural networks is presented for a robot with a camera installed on its end-effector to trace an object in an unknown environment. First, the one-to-one mapping relations between the image feature domain of the object to the joint angle domain of the robot are derived. Second, a method is proposed to generate a desired trajectory of the robot by measuring the image feature parameters of the object. Third, a multilayer neural network is used for off-line learning of the mapping relations so as to produce on-line the reference inputs for the robot. Fourth, a learning controller based on a multilayer neural network is designed for realizing the visual feedback control of the robot. Last, the effectiveness of the present approach is verified by tracing a curved line using a 6-degrees-of-freedom robot with a CCD camera installed on its end-effector. The present approach does not necessitate the tedious calibration of the CCD camera and the complicated coordinate transformations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00170-003-1585-2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10676-004-3422-1,The responsibility gap: Ascribing responsibility for the actions of learning automata,Ethics and Information Technology,10.1007/s10676-004-3422-1,Springer,2004-09-01,"Traditionally, the manufacturer/operator of a machine is held (morally and legally) responsible for the consequences of its operation. Autonomous, learning machines, based on neural networks, genetic algorithms and agent architectures, create a new situation, where the manufacturer/operator of the machine is in principle not capable of predicting the future machine behaviour any more, and thus cannot be held morally responsible or liable for it. The society must decide between not using this kind of machine any more (which is not a realistic option), or facing a responsibility gap, which cannot be bridged by traditional concepts of responsibility ascription.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10676-004-3422-1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/B:JINT.0000039014.41797.dc,A Hybrid Intelligent Active Force Controller for Articulated Robot Arms Using Dynamic Structure Neural Network,Journal of Intelligent and Robotic Systems,10.1023/B:JINT.0000039014.41797.dc,Springer,2004-06-01,"The key feature of this paper is the application of a robotic control concept – Active Force Control (AFC). In this type of control, the unknown friction effect of the robotic arm may be compensated by the AFC method. AFC involves the direct measurement of the acceleration and force quantities and therefore, the process of estimating the system ‘disturbance’ due to friction becomes instantaneous and purely algebraic. However, the AFC strategy is very practical provided a good estimation of the inertia matrix of articulated robot arm is acquired. A dynamic structure neural network – Growing Multi-experts Network (GMN) is developed to estimate the robot inertia matrix. The growing and pruning mechanism of GMN ensures the optimum size of the network that results in an excellent generalization capability of the network. Active Force Control (AFC) in conjunction with GMN successfully reduces the velocity and position tracking errors in spite of robot joint friction. The embedded GMN is capable of coupling the inertia matrix estimation on-line that clearly enhances the performance of AFC controller. The robustness and effectiveness of the new hybrid neural network-based AFC scheme are demonstrated clearly with regard to two link articulated robot and a simulated two-degree of freedom Puma 560 robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/B:JINT.0000039014.41797.dc,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/B:APIN.0000021413.05467.20,Combining Intelligent Techniques for Sensor Fusion,Applied Intelligence,10.1023/B:APIN.0000021413.05467.20,Springer,2004-05-01,"Mobile robots rely on sensor data to build a representation of their environment. However, sensors usually provide incomplete, inconsistent or inaccurate information. Sensor fusion has been successfully employed to enhance the accuracy of sensor measures. This work proposes and investigates the use of Artificial Intelligence techniques for sensor fusion. Its main goal is to improve the accuracy and reliability of the distance measure between a robot and an object in its work environment, based on measures obtained from different sensors. Several Machine Learning algorithms are investigated to fuse the sensors data. The best model generated by each algorithm is called estimator. It is shown that the employment of estimators based on Artificial Intelligence can improve significantly the performance achieved by each sensor alone. The Machine Learning algorithms employed have different characteristics, causing the estimators to have different behaviors in different situations. Aiming to achieve an even more accurate and reliable behavior, the estimators are combined in committees. The results obtained suggest that this combination can further improve the reliability and accuracy of the distances measured by the individual sensors and estimators used for sensor fusion.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/B:APIN.0000021413.05467.20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/B:JIMS.0000018034.76366.b8,Neural network-based robot visual positioning for intelligent assembly,Journal of Intelligent Manufacturing,10.1023/B:JIMS.0000018034.76366.b8,Springer,2004-04-01,"A fundamental task in robotic assembly is the pick and place operation. Generally, this operation consists of three subtasks; guiding the robot to the target and positioning the manipulator in an appropriate pose, picking up the object and moving the object to a new location. In situations where the pose of the target may vary in the workspace, sensory feedback becomes indispensable to guide the robot to the object. Ideally, local image features must be clearly visible and un-occluded in multiple views of the object. In reality, this may not be always the case. Local image features are often are often rigidly constrained to a particular target and may require specialized feature localization algorithms. We present a visual positioning system that addresses feature extraction issues for a class of objects that have smooth or curved surfaces. In this work, the visual sensor consists of an arm mounted camera and a grid pattern projector that produces images with local surface description of the target. The projected pattern is always visible in the image and it is sensitive to variations in the object’s pose. A set of low-order geometric moments globally characterizes the observed pattern, eliminating the need for feature localization and overcoming the point correspondence problem. A neural network then learns the complex relationship between the robot’s pose displacements and the observed variations in the image features. After training, visual feedback guides the robot to the target from any arbitrary location in the workspace. Its applicability using a five degrees of freedom (DOF) industrial robot is demonstrated.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/B:JIMS.0000018034.76366.b8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-003-0395-7,An information-theoretic landscape analysis of neuro-controlled embodied organisms,Neural Computing & Applications,10.1007/s00521-003-0395-7,Springer,2004-04-01,"Recently, there has been a lot of interest in evolving controllers for both physically simulated creatures as well as for real physical robots. However, a range of different ANN architectures are used for controller evolution, and, in the majority of the work conducted, the choice of the architecture used is made arbitrarily. No fitness landscape analysis was provided for the underlying fitness landscape of the controller’s search space. As such, the literature remains largely inconclusive as to which ANN architecture provides the most efficient and effective space for searching the range of possible controllers through evolutionary methods. This represents the motivation for this paper where we compare the search space for four different types of ANN architecture for controller evolution through an information-theoretic analysis of the fitness landscape associated with each type of architecture.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-003-0395-7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-27835-1_19,A Study on Designing Robot Controllers by Using Reinforcement Learning with Evolutionary State Recruitment Strategy,Biologically Inspired Approaches to Advanced Information Technology,10.1007/978-3-540-27835-1_19,Springer,2004-01-01,"Recently, much attention has been focused on utilizing reinforcement learning (RL) for designing robot controllers. However, as the state spaces of these robots become continuous and high dimensional, it results in time-consuming process. In order to adopt the RL for designing the controllers of such complicated systems, not only adaptability but also computational efficiencies should be taken into account. In this paper, we introduce an adaptive state recruitment strategy which enables a learning robot to rearrange its state space conveniently according to the task complexity and the progress of the learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-27835-1_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-30221-6_5,Machine Learning for Autonomous Robots,KI 2004: Advances in Artificial Intelligence,10.1007/978-3-540-30221-6_5,Springer,2004-01-01,"Although Reinforcement Learning methods have meanwhile been successfully applied to a wide range of different application scenarios, there is still a lack of methods that would allow the direct application of reinforcement learning to real systems. The key capability of such learning systems is the efficency with respect to the number of interactions with the real system. Several examples are given that illustrate recent progress made in that direction.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-30221-6_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:DOItmp_0558_027028,A Genetic Approach to Optimizing the Values of Parameters in Reinforcement Learning for Navigation of a Mobile Robot,Neural Information Processing,DOItmp_0558_027028,Springer,2004-01-01,"Reinforcement learning is a learning framework that is especially suited for obstacle avoidance and navigation of autonomous mobile robots, because supervised signals, hardly available in the real world, can be dispensed with. We have to determine, however, the values of parameters in reinforcement learning without prior information. In the present paper, we propose to use a genetic algorithm with inheritance for their optimization. We succeed in decreasing the average number of actions needed to reach a given goal by about 10-40% compared with reinforcement learning with non-optimal parameters, and in obtaining a nearly shortest path.",http://link.springer.com/openurl/pdf?id=doi:DOItmp_0558_027028,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:DOItmp_0558_024809,A Study on Designing Robot Controllers by Using Reinforcement Learning with Evolutionary State Recruitment Strategy,Biologically Inspired Approaches to Advanced Information Technology,DOItmp_0558_024809,Springer,2004-01-01,"Recently, much attention has been focused on utilizing reinforcement learning (RL) for designing robot controllers. However, as the state spaces of these robots become continuous and high dimensional, it results in time-consuming process. In order to adopt the RL for designing the controllers of such complicated systems, not only adaptability but also computational efficiencies should be taken into account. In this paper, we introduce an adaptive state recruitment strategy which enables a learning robot to rearrange its state space conveniently according to the task complexity and the progress of the learning.",http://link.springer.com/openurl/pdf?id=doi:DOItmp_0558_024809,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-30217-9_98,Natural Policy Gradient Reinforcement Learning for a CPG Control of a Biped Robot,Parallel Problem Solving from Nature - PPSN VIII,10.1007/978-3-540-30217-9_98,Springer,2004-01-01,"Motivated by the perspective that animals’ rhythmic movements such as locomotion are controlled by neural circuits called central pattern generators (CPGs), motor control mechanisms by CPG have been studied. As an autonomous learning framework for a CPG controller, we previously proposed a reinforcement learning (RL) method called the CPG-actor-critic method. In this article, we propose a natural policy gradient learning algorithm for the CPG-actor-critic method, and applied our RL to an automatic control problem by a biped robot simulator. Computer simulations show that our RL makes the biped robot walk stably on various terrain.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-30217-9_98,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-28648-6_6,Reinforcement Learning and ART2 Neural Network Based Collision Avoidance System of Mobile Robot,Advances in Neural Networks - ISNN 2004,10.1007/978-3-540-28648-6_6,Springer,2004-01-01,"In view of the collision avoidance problem of multi-moving-obstacles in path planning of mobile robot, we present a solution based on reinforcement learning and ART2 (Adaptive Resonance Theory 2) neural network as well as the method of rule-based collision avoidance. The simulation experiment shows that the solution is of good flexibility and can solve the problem on random moving obstacles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-28648-6_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:DOItmp_0558_015110,Calculation of Model of the Robot by Neural Network with Robot Joint Distinction,Artificial Intelligence and Soft Computing - ICAISC 2004,DOItmp_0558_015110,Springer,2004-01-01,There is presented the design of the feedforward neural network for calculation of coefficients of the robot model. Proposed method distinguishes the degrees of freedom and improves the performance of the network using information about the control signals. A numerical example for calculation of the neural network model of Puma 560 robot is presented.,http://link.springer.com/openurl/pdf?id=doi:DOItmp_0558_015110,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:DOItmp_0558_015108,Artificial Intelligence of the Decision Unit of a Mobile Robot,Artificial Intelligence and Soft Computing - ICAISC 2004,DOItmp_0558_015108,Springer,2004-01-01,"In this paper, it is indicated that the decision unit of mobile robot should be performed in the form of a hardware which owns some features of intelligence. For this reason, the synthesis of the decision unit should be executed in such a way in order to achieve these features in its logical structure. In the paper, the process of robot moving, over the plane with obstacles, is treated as an extensive game with the nature. In this game the decision unit chooses its moving strategies in the same manner as a human being in the identical situation. The synthesis of a symbolic expression representing the game tree, performing by the computer, is introduced. In the symbolic expression some features of intelligence are taken into consideration. It is shown that this symbolic expression is transformed by the computer into another symbolic expressions which unequivocally indicates on the logical structure of the hardware playing the role of the decision unit.",http://link.springer.com/openurl/pdf?id=doi:DOItmp_0558_015108,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-30499-9_178,A Genetic Approach to Optimizing the Values of Parameters in Reinforcement Learning for Navigation of a Mobile Robot,Neural Information Processing,10.1007/978-3-540-30499-9_178,Springer,2004-01-01,"Reinforcement learning is a learning framework that is especially suited for obstacle avoidance and navigation of autonomous mobile robots, because supervised signals, hardly available in the real world, can be dispensed with. We have to determine, however, the values of parameters in reinforcement learning without prior information. In the present paper, we propose to use a genetic algorithm with inheritance for their optimization. We succeed in decreasing the average number of actions needed to reach a given goal by about 10-40% compared with reinforcement learning with non-optimal parameters, and in obtaining a nearly shortest path.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-30499-9_178,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-30132-5_150,Some Emergences of Mobiligence in the Pursuit Game,Knowledge-Based Intelligent Information and Engineering Systems,10.1007/978-3-540-30132-5_150,Springer,2004-01-01,"In this paper, we have proposed a realization of the mobiligence by constructing a pursuit game. The pursuit game has been used as a benchmark problem of a multi-agent system by many researchers. A “purpose-oriented Q-nets” is used for constructing the intelligence for mobile agents in this study. In the Q-nets, one evaluation function is to capture the prey and the other is to evaluate how the agents go back to the nest to charge energy. This configuration is designed to realize the self sufficiency of the hunter agents. The numerical experiments using Khepera Simulator well verifies that our proposed system shows some emergent behaviors of “mobiligence”.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-30132-5_150,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:DOItmp_0558_027027,A Dual Neural Network for Bi-criteria Torque Optimization of Redundant Robot Manipulators,Neural Information Processing,DOItmp_0558_027027,Springer,2004-01-01,"A dual neural network is presented for the bi-criteria joint torque optimization of kinematically redundant manipulators, which balances between the total energy consumption and the torque distribution among the joints. Joint torque limits are also incorporated simultaneously into the proposed optimization scheme. The dual neural network has a simple structure with only one layer of neurons and is proven to be globally exponentially convergent to the optimal solution. The effectiveness of dual neural network for this problem is demonstrated by simulation with the PUMA560 manipulator.",http://link.springer.com/openurl/pdf?id=doi:DOItmp_0558_027027,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-24844-6_122,Calculation of Model of the Robot by Neural Network with Robot Joint Distinction,Artificial Intelligence and Soft Computing - ICAISC 2004,10.1007/978-3-540-24844-6_122,Springer,2004-01-01,There is presented the design of the feedforward neural network for calculation of coefficients of the robot model. Proposed method distinguishes the degrees of freedom and improves the performance of the network using information about the control signals. A numerical example for calculation of the neural network model of Puma 560 robot is presented.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-24844-6_122,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-28648-6_2,Full-DOF Calibration-Free Robotic Hand-Eye Coordination Based on Fuzzy Neural Network,Advances in Neural Networks - ISNN 2004,10.1007/978-3-540-28648-6_2,Springer,2004-01-01,"This paper studies coordination control for an uncalibrated single eye-in-hand robotic system to track an object in 3-D space with simultaneous translations and rotations. A set of object features is properly defined to derive an invertible nonlinear visual mapping model from visual feedback to robot control. A novel fuzzy neural network is proposed to realize the nonlinear mapping model effectively, which is essential to implement six-degree-of-freedom control of robot hand. Simulation results show the performance of the proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-28648-6_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-28648-6_1,Application of RBFNN for Humanoid Robot Real Time Optimal Trajectory Generation in Running,Advances in Neural Networks - ISNN 2004,10.1007/978-3-540-28648-6_1,Springer,2004-01-01,"In this paper, a method for trajectory generation in running is proposed with Radial Basis Function Neural Network, which can generate a series of joint trajectories to adjust humanoid robot step length and step time based on the sensor information. Compared with GA, RBFNN use less time to generate new trajectory to deal with sudden obstacles after thorough training. The performance of the proposed method is validated by simulation of a 28 DOF humanoid robot model with ADAMS.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-28648-6_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:DOItmp_0558_023952,Networked Intelligent Robots by Ontological Neural Networks,Knowledge-Based Intelligent Information and Engineering Systems,DOItmp_0558_023952,Springer,2004-01-01,"Now day, various types of information device and system, pet robot and so on, are created and cover up human life. But still now, systems are promoted by human and are developed by human. Systems can’t build interaction between human. And an agent processes information all by oneself, and can’t utilize relationship with human or other agents. We consider the informational aspects of intimacy (recognition technology, and communication and sharing). Therefore, We focus on ontology technology. The agent created the ontology from observed human motion and situation, and communication with human or other agents use ontology.",http://link.springer.com/openurl/pdf?id=doi:DOItmp_0558_023952,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-24844-6_120,Artificial Intelligence of the Decision Unit of a Mobile Robot,Artificial Intelligence and Soft Computing - ICAISC 2004,10.1007/978-3-540-24844-6_120,Springer,2004-01-01,"In this paper, it is indicated that the decision unit of mobile robot should be performed in the form of a hardware which owns some features of intelligence. For this reason, the synthesis of the decision unit should be executed in such a way in order to achieve these features in its logical structure. In the paper, the process of robot moving, over the plane with obstacles, is treated as an extensive game with the nature. In this game the decision unit chooses its moving strategies in the same manner as a human being in the identical situation. The synthesis of a symbolic expression representing the game tree, performing by the computer, is introduced. In the symbolic expression some features of intelligence are taken into consideration. It is shown that this symbolic expression is transformed by the computer into another symbolic expressions which unequivocally indicates on the logical structure of the hardware playing the role of the decision unit.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-24844-6_120,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-28633-2_142,An Intelligent Robot Navigation System Based on Neuro-Fuzzy Control,PRICAI 2004: Trends in Artificial Intelligence,10.1007/978-3-540-28633-2_142,Springer,2004-01-01,Controlling mobile robot navigation system that operates in an unknown and uncertain environment is a difficult operation. Much of this difficulty is due to environmental inconsistencies and sensor inadequacies. We present a new neurofuzzy controller that controls the navigation system of a mobile robot to move safely in an unknown environment in presence of obstacles. Training data is accumulated from robot’s sensors to generate a set of fuzzy rules that govern the robot navigation system on-line.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-28633-2_142,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-30182-0_4,Model Based Intelligent Control of a 3-Joint Robotic Manipulator: A Simulation Study Using Artificial Neural Networks,Computer and Information Sciences - ISCIS 2004,10.1007/978-3-540-30182-0_4,Springer,2004-01-01,"Recently, there has been a great deal of interest in intelligent control of robotic manipulators. Artificial neural network (ANN) is a widely used intelligent technique on this way. Using ANN, these controllers learn about the systems to be online controlled by them. In this paper, a neural network controller was designed using traditional generalized predictive control algorithm (GPC). The GPC algorithm, which belongs to a class of digital control methods and known as Model Based Predictive Control, require long computational time and can result in a poor control performance in robot control. Therefore, to reduce the process time, in other words, to avoid from the highly mathematical computational structure of GPC, a neural network was designed for a 3-Joint robot. The performance of the designed control system was shown to be successful using the simulation software, which includes the dynamics and kinematics of the robot model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-30182-0_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-30499-9_177,A Dual Neural Network for Bi-criteria Torque Optimization of Redundant Robot Manipulators,Neural Information Processing,10.1007/978-3-540-30499-9_177,Springer,2004-01-01,"A dual neural network is presented for the bi-criteria joint torque optimization of kinematically redundant manipulators, which balances between the total energy consumption and the torque distribution among the joints. Joint torque limits are also incorporated simultaneously into the proposed optimization scheme. The dual neural network has a simple structure with only one layer of neurons and is proven to be globally exponentially convergent to the optimal solution. The effectiveness of dual neural network for this problem is demonstrated by simulation with the PUMA560 manipulator.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-30499-9_177,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:DOItmp_0558_024349,Intelligent Robot Control with Personal Digital Assistants Using Fuzzy Logic and Neural Network,Knowledge-Based Intelligent Information and Engineering Systems,DOItmp_0558_024349,Springer,2004-01-01,"To control the mobile robot system with wired controller by manual is so easy but user must keep the status and movement of mobile robot all the time. It is more efficient to control the mobile robot with remote controller by automatically. The user does not need to know the current status of the robot or where it is. In this paper, we propose the intelligent robot control technique for mobile robot using the wireless and remote controller, personal digital assistants (PDA) that has an intelligent navigation algorithm such as fuzzy logic and neural network. With the proposed technique, the mobile robot can trace human at regular intervals by the remote control method with PDA without user’s manual command. The mobile robot can recognize the distances between it and human whom the robot must follow with both multi-ultrasonic sensors and PC-camera and then, can decide the direction and velocity of itself to keep the given regular distances. The proposed PDA control system, which is intelligent and remote, can make user be free from the observation of the mobile robot to control the robot properly.",http://link.springer.com/openurl/pdf?id=doi:DOItmp_0558_024349,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-30134-9_79,Intelligent Robot Control with Personal Digital Assistants Using Fuzzy Logic and Neural Network,Knowledge-Based Intelligent Information and Engineering Systems,10.1007/978-3-540-30134-9_79,Springer,2004-01-01,"To control the mobile robot system with wired controller by manual is so easy but user must keep the status and movement of mobile robot all the time. It is more efficient to control the mobile robot with remote controller by automatically. The user does not need to know the current status of the robot or where it is. In this paper, we propose the intelligent robot control technique for mobile robot using the wireless and remote controller, personal digital assistants (PDA) that has an intelligent navigation algorithm such as fuzzy logic and neural network. With the proposed technique, the mobile robot can trace human at regular intervals by the remote control method with PDA without user’s manual command. The mobile robot can recognize the distances between it and human whom the robot must follow with both multi-ultrasonic sensors and PC-camera and then, can decide the direction and velocity of itself to keep the given regular distances. The proposed PDA control system, which is intelligent and remote, can make user be free from the observation of the mobile robot to control the robot properly.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-30134-9_79,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-28648-6_4,"Fuzzy Neural Networks Observer for Robotic Manipulators Based on H
                     _ ∞  Approach",Advances in Neural Networks - ISNN 2004,10.1007/978-3-540-28648-6_4,Springer,2004-01-01,"This paper presents an observer for robotic systems using FNN method to estimate the joint velocities of a robot, and then H _ ∞  approach is embedded to attenuate the effect of external distributes and parametric uncertainties of the robotic systems. Then a simulation example of 2-DOF robotic systems is given at last, from the simulation results, we can see the well performance of the designed observer and the estimation errors of the joint velocities are negligible.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-28648-6_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4020-2651-5_43,Touch-EE-to-Grasp-AI,Microelectronics Education,10.1007/978-1-4020-2651-5_43,Springer,2004-01-01,This paper reports on a summer school that was run for highschool students. In order to provide a fair overview of typical studies in electrical engineering (EE) this first summer school was offering several lectures in the field of new artificial intelligence and robotics. The topics were taught on various levels ranging from technical basics to high-level programming. An informal evaluation has indicated that the chosen topics were suitable for the summer school’s goals and that the attendees might be interested in starting their studies in EE.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4020-2651-5_43,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-25940-4_56,Autonomous Robot Controllers Capable of Acquiring Repertoires of Complex Skills,RoboCup 2003: Robot Soccer World Cup VII,10.1007/978-3-540-25940-4_56,Springer,2004-01-01,"Due to the complexity and sophistication of the skills needed in real world tasks, the development of autonomous robot controllers requires an ever increasing application of learning techniques. To date, however, learning steps are mainly executed in isolation and only the learned code pieces become part of the controller. This approach has several drawbacks: the learning steps themselves are undocumented and not executable. In this paper, we extend an existing control language with constructs for specifying control tasks, process models, learning problems, exploration strategies, etc. Using these constructs, the learning problems can be represented explicitly and transparently and, as they are part of the overall program implementation, become executable. With the extended language we rationally reconstruct large parts of the action selection module of the agilo 2001 autonomous soccer robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-25940-4_56,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-39925-4_8,Exploring Organizational-Learning Oriented Classifier System in Real-World Problems,Applications of Learning Classifier Systems,10.1007/978-3-540-39925-4_8,Springer,2004-01-01,"Learning Classifier Systems (LCSs) [12, 13, 14] are often compared with Reinforcement Learning (RL) [21]. Such comparisons suggest that many theoretical analyses have been studied in the context of RL, while few in the context of LCSs. However, LCSs are applied to many real-world problems, while RL is rarely applied. Examples of LCSs include aircraft maneuvers [10, 19], the controller or action planning of a physical robot [7, 20], trading in the stock market [17], electric power distribution networks [26], data mining from a large clinical database [11], the Wisconsin breast cancer dataset [29], and others [6]. These examples show the great advantage of LCSs in comparison with RL.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-39925-4_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-25940-4_30,A Humanoid Approaches to the Goal – Reinforcement Learning Based on Rhythmic Walking Parameters,RoboCup 2003: Robot Soccer World Cup VII,10.1007/978-3-540-25940-4_30,Springer,2004-01-01,"This paper presents a method for generating vision-based humanoid behaviors by reinforcement learning with rhythmic walking parameters. The walking is stabilized by a rhythmic motion controller such as CPG or neural oscillator. The learning process consists of two stages: the first one is building an action space with two parameters (a forward step length and a turning angle) so that infeasible combinations of them are inhibited. The second one is reinforcement learning with the constructed action space and the state space consisting of visual features and posture parameters to find feasible action. The method is applied to a situation of the RoboCupSoccer Humanoid league, that is, to reach the ball and to shoot it into the goal. Instructions by human are given to start up the learning process and the rest is completely self-learning in real situations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-25940-4_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-0-85729-338-1_27,Improving Robot Manipulator Performance with Adaptive Neuro-Control,Adaptive Computing in Design and Manufacture VI,10.1007/978-0-85729-338-1_27,Springer,2004-01-01,"An adaptive controller that modifies its characteristics to deal with new situations, in a timely and accurate way, would be a valuable improvement on many existing industrial plant controllers. Furthermore, if such a controller could effectively be “strapped around” the existing controller then there could be many opportunities for performance enhancement of systems already “out in the field”. The new situations that this adaptive controller would need to deal with could arise from time variations in the plant’s characteristics due to wear and tear, or from learning, on-line, about unforeseen new parts of the plant’s operational envelope. The universal approximation abilities of neural networks, combined with permanently active on-line learning, yield powerful features that can be used to great advantage in creating adaptive controllers for such applications. Together they allow accurate control strategies to be developed for these types of plant without the need for a mathematical model. Furthermore, neuro-control algorithms can learn about these dynamical features using signals from the plant that are normally easily obtained. Multi-axis revolute-jointed robot manipulators are good examples of this class of plant. In order to illustrate some of the important advantages of these methodologies, and to inform the reader about some of the important characteristics of these adaptive structures, we review some of our recently reported experiments in applying an on-line learning neuro-control approach to joint level trajectory control of two different industrial robots. In each case, the neuro-controllers are used to enhance performance of the existing PID controllers. This paper is mainly concerned with highlighting these features via the experimental results. However, when a controller learns on-line whilst acting as part of a plant’s closed-loop controller, it is crucial that a careful and rigorous approach is adopted. A strict theoretical basis that guarantees the whole system’s stability is required. To set the experimental work in context therefore, we briefly review our on-line learning neuro-control method, which is used for both sets of experiments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-0-85729-338-1_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-30132-5_149,Networked Intelligent Robots by Ontological Neural Networks,Knowledge-Based Intelligent Information and Engineering Systems,10.1007/978-3-540-30132-5_149,Springer,2004-01-01,"Now day, various types of information device and system, pet robot and so on, are created and cover up human life. But still now, systems are promoted by human and are developed by human. Systems can’t build interaction between human. And an agent processes information all by oneself, and can’t utilize relationship with human or other agents. We consider the informational aspects of intimacy (recognition technology, and communication and sharing). Therefore, We focus on ontology technology. The agent created the ontology from observed human motion and situation, and communication with human or other agents use ontology.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-30132-5_149,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-28645-5_25,Heuristically Accelerated Q–Learning: A New Approach to Speed Up Reinforcement Learning,Advances in Artificial Intelligence – SBIA 2004,10.1007/978-3-540-28645-5_25,Springer,2004-01-01,"This work presents a new algorithm, called Heuristically Accelerated Q –Learning (HAQL), that allows the use of heuristics to speed up the well-known Reinforcement Learning algorithm Q –learning. A heuristic function $\mathcal{H}$ that influences the choice of the actions characterizes the HAQL algorithm. The heuristic function is strongly associated with the policy: it indicates that an action must be taken instead of another. This work also proposes an automatic method for the extraction of the heuristic function $\mathcal{H}$ from the learning process, called Heuristic from Exploration. Finally, experimental results shows that even a very simple heuristic results in a significant enhancement of performance of the reinforcement learning algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-28645-5_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-662-05642-4_15,Robots and Rule-Following,Alan Turing: Life and Legacy of a Great Thinker,10.1007/978-3-662-05642-4_15,Springer,2004-01-01,"Turing was probably the first person to advocate the pursuit of robotics as a route to Artificial Intelligence and Wittgenstein the first to argue that, without the appropriate history, no machine could be intelligent. Wittgenstein anticipated much recent theorizing about the mind, including aspects of connectionist theories of mind and the situated cognition approach in AI. Turing and Wittgenstein had a wary respect for each other and there is significant overlap in their work, in both the philosophy of mathematics and the philosophy of AI. Both took (what would now be called) an externalist stance with respect to machine intelligence. But whereas Turing was concerned only with behaviour, Wittgenstein emphasized in addition history and environment. I show that Wittgenstein’s externalist analysis of psychological capacities entails that most, even all, future “artificially intelligent” computers and robots will not use language, possess concepts, or reason. The argument tells, not against AI, but only against AI’s traditional and romantic goal of building an artificial “res cogitans” — as first embraced by Turing and now exemplified in the work of Brooks and others on cognitive robotics. This argument supports the stance of the growing number of AI researchers whose aim is to produce, not thinking and understanding machines, but high-performance “advanced information processing systems.”",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-662-05642-4_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/1-4020-8151-0_6,Evolutionary Robot Behaviors Based on Natural Selection and Neural Network,Artificial Intelligence Applications and Innovations,10.1007/1-4020-8151-0_6,Springer,2004-01-01,"The methodology of artificial evolution based on the traditional fitness function is argued to be inadequate for constructing the entities with behaviors novel to their designers. Evolutionary emergence via natural selection(without an explicit fitness function) is a promising way. This paper primarily considers the question of what to evolve, and focuses on the principles of developmental modularity based on neural networks. The connection weight values of this neural network are encoded as genes, and the fitness individuals are determined using a genetic algorithm. In paper we has created and described an artificial world containing autonomous organisms for developing and testing some novel ideas. Experimental results through simulation have demonstrated that the developmental system is well suited to long-term incremental evolution. Novel emergent strategies are identified both from an observer’s perspective and in terms of their neural mechanisms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/1-4020-8151-0_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-24677-0_45,Open-End Human Robot Interaction from the Dynamical Systems Perspective: Mutual Adaptation and Incremental Learning,Innovations in Applied Artificial Intelligence,10.1007/978-3-540-24677-0_45,Springer,2004-01-01,"This paper describes interactive learning between human subjects and robot using the dynamical systems approach. Our research concentrated on the navigation system of a humanoid robot and human subjects whose eyes were covered. We used the recurrent neural network (RNN) for the robot control. We used a “consolidation-learning algorithm” as a model of hippocampus in brain. In this method, the RNN was trained by both a new data and the rehearsal outputs of the RNN, not to damage the contents of current memory. The proposed method enabled the robot to improve the performance even when learning continued for a long time (open-end). The dynamical systems analysis of RNNs supports these differences.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-24677-0_45,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-28633-2_70,Using Context to Solve the Correspondence Problem in Simultaneous Localisation and Mapping,PRICAI 2004: Trends in Artificial Intelligence,10.1007/978-3-540-28633-2_70,Springer,2004-01-01,"We present a method for solving the correspondence problem in Simultaneous Localisation and Mapping (SLAM) in a topological map. The nodes in the topological map are a representation for each local space the robot visits. The approach is feature based – a neural network algorithm is used to learn a signature from a set of features extracted from each local space representation. Newly encountered local spaces are classified by the neural network as to how well they match the signatures of the nodes in the topological network. Of equal importance as the correspondence problem is its dual, that of perceptual aliasing which occurs when parts of the environment which appear the same are in fact different. It manifests itself as false positive matches from the neural network classification. Our approach to solving this aspect of the problem is to use the context provide by nodes in the neighbourhood of the (mis)matched node. When neural network classification indicates a correspondence then subsequent local spaces the robot visits should also match nodes in the topological map where appropriate.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-28633-2_70,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-25940-4_14,Echo State Networks for Mobile Robot Modeling and Control,RoboCup 2003: Robot Soccer World Cup VII,10.1007/978-3-540-25940-4_14,Springer,2004-01-01,"Applications of recurrent neural networks (RNNs) tend to be rare because training is difficult. A recent theoretical breakthrough [Jae01b] called Echo State Networks (ESNs) has made RNN training easy and fast and makes RNNs a versatile tool for many problems. The key idea is training the output weights only of an otherwise topologically unrestricted but contractive network. After outlining the mathematical basics, we apply ESNs to two examples namely to the generation of a dynamical model for a differential drive robot using supervised learning and secondly to the training of a respective motor controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-25940-4_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-30220-9_9,AIS Based Robot Navigation in a Rescue Scenario,Artificial Immune Systems,10.1007/978-3-540-30220-9_9,Springer,2004-01-01,"An architecture for a robot control is proposed which is based on the requirements from the RoboCup and AAAI Rescue Robot Competition. An artificial immune system comprises the core component. The suitability of this architecture for the competition and related scenarios, including the modelling of the environment, was verified by simulation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-30220-9_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-39935-3_20,Robot Manipulator Control via Recurrent Neural Networks,Neural Information Processing: Research and Development,10.1007/978-3-540-39935-3_20,Springer,2004-01-01,"This chapter presents the application of neural networks to robot manipulator control. The main methodologies, on which the approach is based, are recurrent neural networks and the recent introduced technique of inverse optimal control for nonlinear systems. The proposed controller structure is composed of a neural identifier and a control law defined by using the inverse optimal control approach. The proposed new control scheme is applied via simulations to control a robot manipulator model where friction terms are included.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-39935-3_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF02703810,Evolutionary robotics—A review,Sadhana,10.1007/BF02703810,Springer,2003-12-01,"In evolutionary robotics, a suitable robot control system is developed automatically through evolution due to the interactions between the robot and its environment. It is a complicated task, as the robot and the environment constitute a highly dynamical system. Several methods have been tried by various investigators to solve this problem. This paper provides a survey on some of these important studies carried out in the recent past.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF02703810,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-003-0383-y,Navigating mobile robots with a modular neural architecture,Neural Computing & Applications,10.1007/s00521-003-0383-y,Springer,2003-12-01,"Neural architectures have been proposed to navigate mobile robots within several environment definitions. In this paper a new neural modular constructive approach to navigate mobile robots in unknown environments is presented. The problem, in its basic form, consists of defining and executing a trajectory to a pre-defined goal while avoiding all obstacles, in an unknown environment. Some crucial issues arise when trying to solve this problem, such as an overflow of sensorial information and conflicting objectives. Most neural network (NN) approaches to this problem focus on a monolithic system, i.e., a system with only one neural network that receives and analyses all available information, resulting in conflicting training patterns, long training times and poor generalisation. The work presented in this article circumvents these problems by the use of a constructive modular NN. Navigation capabilities were proven with the NOMAD 200 mobile robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-003-0383-y,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF02481156,Direct-vision-based reinforcement learning in a real mobile robot,Artificial Life and Robotics,10.1007/BF02481156,Springer,2003-09-01,"It was confirmed that a real mobile robot with a simple visual sensor could learn appropriate motions to reach a target object by direct-vision-based reinforcement learning (RL). In direct-vision-based RL, raw visual sensory signals are put directly into a layered neural network, and then the neural network is trained using back propagation, with the training signal being generated by reinforcement learning. Because of the time-delay in transmitting the visual sensory signals, the actor outputs are trained by the critic output at two time-steps ahead. It was shown that a robot with a simple monochrome visual sensor can learn to reach a target object from scratch without any advance knowledge of this task by direct-vision-based RL.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF02481156,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1025597227189,Hybrid Control for Autonomous Mobile Robot Navigation Using Neural Network Based Behavior Modules and Environment Classification,Autonomous Robots,10.1023/A:1025597227189,Springer,2003-09-01,"A hybrid control architecture combining behavior based reactive navigation and model based environment classification has been developed. It is also hybrid in the sense that both competitive coordination and cooperative coordination are used for the BBC (Behavior Based Control) part. The contributions are as follows. First, a Neural Network (NN) in charge of environment classification has been developed based on 16 prototypes of topological maps roughly describing various local navigation environments. This environment classification NN not only enables the navigator to avoid local minimum points but also eliminates the requirement for prior detailed modeling of the environment since it needs to memorize only “rough” information on local environments encountered along the way that might be sufficient for navigation. Next, an NN based reactive behavior controller will be trained to learn human steering commands for each of the 16 prototype local environments. Third, the modified potential field (MPF) method obtained by adding the free space vector as the third component is used to select a particular reactive behavior in conjunction with the classification NN. Finally, a hybrid control architecture integrating all three of these concepts was developed. It avoids local minimum traps as well as solves the problems of poor obstacle clearance or oscillation. It is robust against sensor noise and adaptive to dynamic environments. This hybrid architecture is also amenable to easy addition of new behaviors due to the modularity of the BBC architecture. The effectiveness of the proposed architecture has been verified through both computer simulation and an actual robot called MORIS (MObile Robot as an Intelligent System).",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1025597227189,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF02481153,Feature extraction method for a robot map using neural networks,Artificial Life and Robotics,10.1007/BF02481153,Springer,2003-09-01,"Many map-building algorithms using ultrasonic sensors have been developed for mobile robot applications. In indoor environments, the ultrasonic sensor system gives some uncertain data. To compensate for this effect, a new feature extraction method using neural networks is proposed. A new, effective representation of the target is defined, and the reflection wave data patterns are learnt using neural networks. As a consequence, the targets are classified as planes, corners, or edges, which all frequently occur in indoor environments. We constructed our own robot system for the experiments which were carried out to show the performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF02481153,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1025059919437,Application of a Near-Optimal Reinforcement Learning Controller to a Robotics Problem in Manufacturing: A Hybrid Approach,Fuzzy Optimization and Decision Making,10.1023/A:1025059919437,Springer,2003-09-01,"Optimization theory provides a framework for determining the best decisions or actions with respect to some mathematical model of a process. This paper focuses on learning to act in a near-optimal manner through reinforcement learning for problems that either have no model or the model is too complex. One approach to solving this class of problems is via approximate dynamic programming. The application of these methods are established primarily for the case of discrete state and action spaces. In this paper we develop efficient methods of learning which act in complex systems with continuous state and action spaces. Monte-Carlo approaches are employed to estimate function values in an iterative, incremental procedure. Derivative-free line search methods are used to obtain a near-optimal action in the continuous action space for a discrete subset of the state space. This near-optimal control policy is then extended to the entire continuous state space via a fuzzy additive model. To compensate for approximation errors, a modified procedure for perturbing the generated control policy is developed. Convergence results under moderate assumptions and stopping criteria are established.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1025059919437,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1026242620248,Adaptive Radial Basis Decomposition by Learning Vector Quantization,Neural Processing Letters,10.1023/A:1026242620248,Springer,2003-08-01,"A method for function approximation in reinforcement learning settings is proposed. The action-value function of the Q-learning method is approximated by the radial basis function neural network and learned by the gradient descent. Those radial basis units that are unable to fit the local action-value function exactly enough are decomposed into new units with smaller widths. The local temporal-difference error is modelled by a two-class learning vector quantization algorithm, which approximates distributions of the positive and of the negative error and provides the centers of the new units. This method is especially convenient in cases of smooth value functions with large local variation in certain parts of the state space, such that non-uniform placement of basis functions is required. In comparison with four related methods, it has the smallest requirements of basis functions when achieving a comparable accuracy.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1026242620248,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1025697810124,A Formal Approach to Agent Design: An Overview of Constraint-Based Agents,Constraints,10.1023/A:1025697810124,Springer,2003-07-01,"Formal models for agent design are important for both practical and theoretical reasons. The Constraint-Based Agent (CBA) design approach includes two formal models: Constraint Nets and Timed ∀-automata. A constraint net models the agents and the environment symmetrically as, possibly hybrid, dynamical systems; a timed ∀-automaton specifies the desired real-time dynamic behaviors of the situated agents. Given a constraint-based specification of the desired behavior, a constraint-based agent can be synthesized as a constraint solver. Using formal modeling and specification, it is also possible to verify complex agents as obeying real-time temporal constraint specifications. This overview paper presents a summary of the development and application of the CBA framework.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1025697810124,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1024172417914,Survey of Intelligent Control Techniques for Humanoid Robots,Journal of Intelligent and Robotic Systems,10.1023/A:1024172417914,Springer,2003-06-01,"This paper focusses on the application of intelligent control techniques (neural networks, fuzzy logic and genetic algorithms) and their hybrid forms (neuro-fuzzy networks, neuro-genetic and fuzzy-genetic algorithms) in the area of humanoid robotic systems. It represents an attempt to cover the basic principles and concepts of intelligent control in humanoid robotics, with an outline of a number of recent algorithms used in advanced control of humanoid robots. Overall, this survey covers a broad selection of examples that will serve to demonstrate the advantages and disadvantages of the application of intelligent control techniques.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1024172417914,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1023926804240,Methodology of Concept Control Synthesis to Avoid Unmoving and Moving Obstacles,Journal of Intelligent and Robotic Systems,10.1023/A:1023926804240,Springer,2003-05-01,"The dynamic path generation problem of robots in environments with other unmoving and moving objects is considered. Generally, the problem is known in the literature as find path or robot motion planning. In this paper, we apply the behavioral cloning approach to design the robot controller. In behavioral cloning, the system learns from control traces of a human operator. The task for the given problem is to find a controller in the form of an explicit mathematical expression. Thus, machine learning programs to induce the operator's trajectories as a set of symbolic constraints are used. Then, mathematical induction to generalize the obtained equations in order to apply them in situ with an infinite number of obstacles is also used. A method to evaluate cloning success is proposed. The typical kind of noise is included.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1023926804240,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:DOItmp_0558_006205,Robotics and AI:  From Intelligent Robots to Neuro-robotics,AI*IA 2003: Advances in Artificial Intelligence,DOItmp_0558_006205,Springer,2003-01-01,"In the last few years robotics has increasingly been recognized and accepted not only as a field for application in industry and services, but also as a potentially ideal application domain for Artificial Intelligence. AI has contributed significantly to the progress of various areas of robotics, particularly those of perception, sensory-motor coordination and intelligent behavior.",http://link.springer.com/openurl/pdf?id=doi:DOItmp_0558_006205,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-45002-3_11,Forward and Bidirectional Planning Based on Reinforcement Learning and Neural Networks in a Simulated Robot,Anticipatory Behavior in Adaptive Learning Systems,10.1007/978-3-540-45002-3_11,Springer,2003-01-01,"Building intelligent systems that are capable of learning, acting reactively and planning actions before their execution is a major goal of artificial intelligence. This paper presents two reactive and planning systems that contain important novelties with respect to previous neural-network planners and reinforcement-learning based planners: (a) the introduction of a new component (”matcher”) allows both planners to execute genuine taskable planning (while previous reinforcement-learning based models have used planning only for speeding up learning); (b) the planners show for the first time that trained neural-network models of the world can generate long prediction chains that have an interesting robustness with regards to noise; (c) two novel algorithms that generate chains of predictions in order to plan, and control the flows of information between the systems’ different neural components, are presented; (d) one of the planners uses backward ”predictions” to exploit the knowledge of the pursued goal; (e) the two systems presented nicely integrate reactive behavior and planning on the basis of a measure of ”confidence” in action. The soundness and potentialities of the two reactive and planning systems are tested and compared with a simulated robot engaged in a stochastic path-finding task. The paper also presents an extensive literature review on the relevant issues.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-45002-3_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-39853-0_46,Robotics and AI: From Intelligent Robots to Neuro-robotics,AI*IA 2003: Advances in Artificial Intelligence,10.1007/978-3-540-39853-0_46,Springer,2003-01-01,"In the last few years robotics has increasingly been recognized and accepted not only as a field for application in industry and services, but also as a potentially ideal application domain for Artificial Intelligence. AI has contributed significantly to the progress of various areas of robotics, particularly those of perception, sensory-motor coordination and intelligent behavior.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-39853-0_46,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-36268-1_1,"Research Robots for Applications in AI, Teleoperation and Entertainment",Experimental Robotics VIII,10.1007/3-540-36268-1_1,Springer,2003-01-01,"Sarcos Research Corporation, and the Center for Engineering Design at the University of Utah, have long been interested in both the fundamental and the applied aspects of robots and other computationally driven machines. We have produced substantial numbers of systems that function as products for commercial applications, and as advanced research tools specifically designed for experimental use. This paper reviews various aspects of the design and control of a number of robot-like machines ranging from our first projects, the Utah Arm and the Utah/MIT Dextrous Hand, to present work on humanoid robots and the Wearable Energetically Autonomous Robot (WEAR). Our systems have been used in: entertainment, operator remotization from hazardous environments, R&D, and medicine. In addition to the robots and their subsystems, extensive work has been devoted to command systems that drive the robots. Command systems have been: play-back supervisors, teleoperation masters, and various higher level approaches based on work from the AI community. Playback interfaces have included motion-capture mechanisms that provide movement-stream information to storage systems configured for later, repeated and coordinated, operation of many robots and associated mechanisms. Play-back command systems use human commands, from an “earlier” time, to command motions that are played out, over and over, mindlessly. Teleoperation “masters”, that operate in real-time with the robot, have ranged from simple motion capture devices, to more complex force reflective exoskeletal masters. Teleoperation interfaces have been composed of complex kinematic structures designed to perform motions compatible with operator movements and are attached via appropriate soft tissue interfaces. The masters emit lower level commands (joint angles) in real-time using the natural intelligence and sensory systems of the operator. AI-based command sources, blend higher level (simple) commands, with system and existing environmental states, to make decisions for the management of the robot. As with the playback systems, AI-based systems are programmed earlier to perform later operations. In the AI case, however, adaptive intelligence and sensory capabilities reside in the robot. Our general design approach has been to begin with the definition of desired objective behaviors, rather than the use of available components with their predefined technical specifications. With the technical specifications of the components necessary to achieve the desired behaviors defined, the components are either acquired, or in most cases, developed and built. The control system, which includes the operation of feedback approaches, acting in collaboration with physical machinery, is then defined and implemented. Control is considered a function of both feedback, and the designed-in performance of the robot’s physical machinery. It has not been true that bad performance from physical machine elements can be simply compensated out via innovative control methods and faster computers. After the completion of many projects we believe that the final frontier(s) of robotics reside at both ends of the brain and brawn spectrum. Both frontiers (barriers) are related to autonomy - intelligence/computation and energy/power. Recently, energetic autonomy has become a major interest at Sarcos and projects are underway to develop appropriate fuel-based servo-actuators to satisfy that need. Our objective is to develop power systems that are capable producing high performance servo-quality actuation for extended operating times without re-energizing the system. At the other end of the spectrum, we are working in collaboration with various groups to supply physical robots capable of operation under the control of advanced AI-based systems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-36268-1_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-44989-2_58,The Evolution of Modular Artificial Neural Networks for Legged Robot Control,Artificial Neural Networks and Neural Information Processing — ICANN/ICONIP 2003,10.1007/3-540-44989-2_58,Springer,2003-01-01,"This paper outlines a system that allows a neural network, which is used to control a robot, to evolve in a structured but open-ended way. The final intention of the research is that, as the network develops, intelligence will eventually emerge. This is accomplished by placing the robot in a developing environment and allowing both this environment and the robot’s body form, sensors and actuators to become more complex and sophisticated as time passes. As this development takes place, neural network modules are added to the control system. The result is that the robot’s complexity and that of the neural network grows with its environment. Results are presented showing the system in operation on a simulated legged robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-44989-2_58,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-017-0317-8_2,Neural Network Approach in Robotics,Intelligent Control of Robotic Systems,10.1007/978-94-017-0317-8_2,Springer,2003-01-01,"Connectionism represents the study of massively parallel networks of simple neuron-like computing units [285],[115]. The computational capabilities of the systems with neural networks are in fact amazing and very promising; they include not only the so-called “ intelligent functions” such as logical reasoning, learning, pattern recognition, formation of associations or abstraction from examples, but also the ability to acquire the most skillful performance in the control of complex dynamic systems. They also evaluate a large number of sensors with different modalities, providing noisy and sometimes inconsistent information.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-017-0317-8_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:DOItmp_0558_001437,Forward and Bidirectional Planning Based on Reinforcement Learning and Neural Networks in a Simulated Robot,Anticipatory Behavior in Adaptive Learning Systems,DOItmp_0558_001437,Springer,2003-01-01,"Building intelligent systems that are capable of learning, acting reactively and planning actions before their execution is a major goal of artificial intelligence. This paper presents two reactive and planning systems that contain important novelties with respect to previous neural-network planners and reinforcement-learning based planners: (a) the introduction of a new component (”matcher”) allows both planners to execute genuine taskable planning (while previous reinforcement-learning based models have used planning only for speeding up learning); (b) the planners show for the first time that trained neural-network models of the world can generate long prediction chains that have an interesting robustness with regards to noise; (c) two novel algorithms that generate chains of predictions in order to plan, and control the flows of information between the systems’ different neural components, are presented; (d) one of the planners uses backward ”predictions” to exploit the knowledge of the pursued goal; (e) the two systems presented nicely integrate reactive behavior and planning on the basis of a measure of ”confidence” in action. The soundness and potentialities of the two reactive and planning systems are tested and compared with a simulated robot engaged in a stochastic path-finding task. The paper also presents an extensive literature review on the relevant issues.",http://link.springer.com/openurl/pdf?id=doi:DOItmp_0558_001437,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-7908-1775-1_5,Biologically Inspired Neural Network Approaches to Real-time Collision-free Robot Motion Planning,Biologically Inspired Robot Behavior Engineering,10.1007/978-3-7908-1775-1_5,Springer,2003-01-01,"In this chapter, a framework, based on biologically inspired neural networks, is proposed for real-time collision-free robot motion planning in a nonstationary environment. Each neuron in the topologically organized neural network is characterized by a shunting equation. The developed algorithms can be applied to point mobile robots, manipulation robots, car-like mobile robots, and multi-robot systems. The real-time optimal robot motion is planned through the dynamic neural activity landscape without explicitly searching over the free workspace or the collision paths, without any prior knowledge of the dynamic environment, without any learning procedures, and without any local collision checking procedures at each step of robot movement. Therefore the proposed algorithms are computationally efficient. The computational complexity linearly depends on the neural network size. The system stability is guaranteed by qualitative analysis and the Lyapunov stability theory. The effectiveness and efficiency of the proposed approaches are demonstrated by simulation and comparison studies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7908-1775-1_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-7908-1902-1_106,Neural Network Reactive Navigation and Control of Wheeled Mobile Robot,Neural Networks and Soft Computing,10.1007/978-3-7908-1902-1_106,Springer,2003-01-01,"A neural net real-time obstacle avoidance and control approach for mobile robot has been developed and numerically implemented. A collision-free path is calculated using an efficient neural net motion planer. The output of the navigation level is fed into a neural net tracking controller that takes into account the complete dynamics of the mobile robot. The proposed neural reactive navigation approach is based on the coordination of elementary behaviors. To avoid the convex obstacles the neural navigator fuses a ‘reaching the middle of a collision-free space’ behavior and a ‘goal-seeking’ behavior. A ‘wall-following’ behavior was conducted too, which can be applied to avoid the concave obstacles. The structure of the neural-net controller for nonholonomic mobile robot is derived using a filtered error approach. The effectiveness of the proposed method is numerically verified by a series of experiments on the emulator of wheeled mobile robot Pioneer-2DX.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7908-1902-1_106,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45105-6_59,Integration of Genetic Programming and Reinforcement Learning for Real Robots,Genetic and Evolutionary Computation — GECCO 2003,10.1007/3-540-45105-6_59,Springer,2003-01-01,"We propose an integrated technique of genetic programming (GP) and reinforcement learning (RL) that allows a real robot to execute real-time learning. Our technique does not need a precise simulator because learning is done with a real robot. Moreover, our technique makes it possible to learn optimal actions in real robots. We show the result of an experiment with a real robot AIBO and represents the result which proves proposed technique performs better than traditional Q-learning method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-45105-6_59,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-36553-2_29,Evolving Reinforcement Learning-Like Abilities for Robots,Evolvable Systems: From Biology to Hardware,10.1007/3-540-36553-2_29,Springer,2003-01-01,"In [ 8 ] Yamauchi and Beer explored the abilities of continuous time recurrent neural networks (CTRNNs) to display reinforcementlearning like abilities. The investigated tasks were generation and learning of short bit sequences. This “learning” came about without modifications of synaptic strengths, but simply from internal dynamics of the evolved networks. In this paper this approach will be extended to two embodied agent tasks, where simulated robots have acquire and retain “knowledge” while moving around different mazes. The evolved controllers are analyzed and the results are discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-36553-2_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-017-0317-8_1,Intelligent Control in Contemporary Robotics,Intelligent Control of Robotic Systems,10.1007/978-94-017-0317-8_1,Springer,2003-01-01,"Modern technological systems are characterized by poor system and subsystem models, high dimensionality of the decision space, distributed sensors and decision makers, high noise levels, multiple subsystems, levels, timescales and/or performance criteria, complex information patterns, overwhelming amount of data and stringent performance requirements. Hence, contemporary research in technological systems is oriented towards multi-disciplinary studies based on the synthesis and application of various control and management paradigms needed for efficient realization of the complex technological system goals and requirements and coping at the same time with all the mentioned problems and constraints.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-017-0317-8_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4471-0025-6_4,Robot Learning: Making Sense of Raw Sensor Data,Mobile Robotics: A Practical Introduction,10.1007/978-1-4471-0025-6_4,Springer,2003-01-01,"This chapter introduces fundamental concepts of robot learning and machine learning, discusses commonly used mechanisms such as reinforcement learning and connectionist approaches, and presents three case studies of mobile robots that can learn.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-0025-6_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-39205-X_44,Towards a Line-Crawling Robot Obstacle Classification System: A Rough Set Approach,"Rough Sets, Fuzzy Sets, Data Mining, and Granular Computing",10.1007/3-540-39205-X_44,Springer,2003-01-01,"The basic contribution of this paper is the presentation of two methods that can be used to design a practical robot obstacle classification system based on data mining methods from rough set theory. These methods incorporate recent advances in rough set theory related to coping with the uncertainty in making obstacle classification decisions either during the operation of a mobile robot. Obstacle classification is based on the evaluation of data acquired by proximity sensors connected to a line-crawling robot useful in inspecting power transmission lines. A fairly large proximity sensor data set has been used as means of benchmarking the proposed classification methods, and also to facilitate comparison with other published studies of the same data set. Using 10-fold cross validated paired t-test, this paper compares the rough set classification learning method with the Waikato Environment for Knowledge Analysis (WEKA) classification learning method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-39205-X_44,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:DOItmp_0558_009078,"Convolutional Neural Networks 
 for Image Processing: 
 An Application in Robot Vision",AI 2003: Advances in Artificial Intelligence,DOItmp_0558_009078,Springer,2003-01-01,"Convolutional neural networks (CNNs) represent an interesting method for adaptive image processing, and form a link between general feed-forward neural networks and adaptive filters. Two dimensional CNNs are formed by one or more layers of two dimensional filters, with possible non-linear activation functions and/or down-sampling. CNNs possess key properties of translation invariance and spatially local connections (receptive fields). We present a description of the convolutional network architecture, and an application to practical image processing on a mobile robot. A CNN is used to detect and characterize cracks on an autonomous sewer inspection robot. The filter sizes used in all cases were 4x4, with non-linear activations between each layer. The number of feature maps used in the three hidden layers was, from input to output, 4, 4, 4. The network was trained using a dataset of 48x48 sub-regions drawn from 30 still image 320x240 pixel frames sampled from a pre-recorded sewer pipe inspection video. 15 frames were used for training and 15 for validation of network performance. Although development of a CNN system for civil use is on-going, the results support the notion that data-based adaptive image processing methods such as CNNs are useful for image processing, or other applications where the input arrays are large, and spatially / temporally distributed. Further refinements of the CNN architecture, such as the implementation of separable filters, or extensions to three dimensional (ie. video) processing, are suggested.",http://link.springer.com/openurl/pdf?id=doi:DOItmp_0558_009078,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/3-540-36155-3_1,Introduction,Interaction Control of Robot Manipulators,10.1007/3-540-36155-3_1,Springer,2003-01-01,"In this introductory chapter, the problem of controlling a robot manipulator which performs six-degrees-of-freedom (six-DOF) tasks requiring interaction with the environment is described. The difference between the well-assessed operational space approach and the task space approach pursued here is explained. A detailed classification of different control problems in the task space framework is carried out and, finally, a brief description of the experimental setup adopted to validate all the algorithms presented through the book is reported.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-36155-3_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-44869-1_22,Multimodule Artificial Neural Network Architectures for Autonomous Robot Control Through Behavior Modulation,Artificial Neural Nets Problem Solving Methods,10.1007/3-540-44869-1_22,Springer,2003-01-01,"In this paper we consider one of the big challenges when constructing modular behavior architectures for the control of real systems, that is, how to decide which module or combination of modules takes control of the actuators in order to implement the behavior the robot must perform when confronted with a perceptual situation. The problem is addressed from the perspective of combinations of ANNs, each implementing a behavior, that interact through the modulation of their outputs. This approach is demonstrated using a three way predator-prey-food problem where the behavior of the individual should change depending on its energetic situation. The behavior architecture is incrementally evolved.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-44869-1_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-7908-1767-6_1,Where is Knowledge in Robotics? Some Methodological Issues on Symbolic and Connectionist Perspectives of AI,Autonomous Robotic Systems,10.1007/978-3-7908-1767-6_1,Springer,2003-01-01,"In this chapter we consider a number of methodological issues to which little importance is normally attributed in robotics but which we consider essential to the development of integrated methods of soft and hard Computing and to the understanding of the artificial intelligence ( AI ) purpose and fundamentals. The basic conjecture in this chapter is that knowledge always remains at the knowledge level and in the external observer’s domain. To the robot only pass the formai model underlying these models of knowledge. Consequently, there are neither essential differences between symbolic and connectionist techniques nor between soft and hard Computing. They are different inferences and problem-solving-methods ( PSMs ) that belong to a library and that are selected to be used in a sequential or concurrent manner according to the suitability for decomposing the task under consideration, until we arrive to the level of inferential primitives solved in terms of data and relations specifie of the application domain. The distinctive characteristics of hard and soft Computing methods are related to the balance between knowledge and data available in advance, the granularity of the model or the necessity and capacity of learning in real time. Nevertheless, in ail these cases the knowledge (the meaning of the entities and relations of the model) always is outside the robot, at the knowledge level, the “house” of models. In many publications, the robotic programs are described without including âny distinction between levels and domains of description of a calculus. As a resuit, it is generally difficult to determine what the robot actually performs, which knowledge has been represented, and which is artificially injected during the human interpretation of the robots behavior. In order to make clear this methodological issues we consider the taxonomy of levels introduced by Marr [1] and Newell [2] (Knowledge, Symbols, and Hardware) put on the top of the two domains of description of a calculus (the domain proper of each level and that of the observer external to the computation of the level). Then, we describe the usual approach to modeling and reduction of models from the knowledge to the symbol level and finally we illustrate the analogies and differences between different models and reduction processes including the opera-tional stage, either symbolic, connectionist, probabilistic or fuzzy. In ail the cases our conviction is that most of the work must be made by modeling tasks and PSMs at the knowledge level, where it is crystal clear that soft and hard Computing are complementary and ready to be integrated.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7908-1767-6_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-7908-1775-1_10,Modular Neural Architectures for Robotics,Biologically Inspired Robot Behavior Engineering,10.1007/978-3-7908-1775-1_10,Springer,2003-01-01,"The learning of sensory-motor functions have motivated important research works that emphasize a major demand: the combination of multiple neural networks to implement complex functions. A review of a number of works presents some implementations in robotics, describing the purpose of the modular architecture, its structure, and the learning technique that was applied. The second part of the chapter presents an original approach to this problem of network training, proposed by our group. Based on a bi-directional architecture, multiple networks can be trained online with simple local learning rules, while the robotic systems interact with their environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7908-1775-1_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-36553-2_31,Hardware Implementation of a Genetic Controller and Effects of Training on Evolution,Evolvable Systems: From Biology to Hardware,10.1007/3-540-36553-2_31,Springer,2003-01-01,"This article describes an FPGA (Field Programmable Gate Array) based hardware implementation of a genetic controller to be applied for the evolution of an Artificial Neural Network (ANN) [ 3 ] for collision-free navigation task of mobile robots. The adaptive nature of ANN enables it to train itself while the robot interacts with the environment. In addition to online training, the genetic evolution in neuron bits will be examined in an experiment to understand the interaction between evolution and lifetime adaptation of the ANN. The concept of chromosome for navigation task, design techniques of various blocks inside the GA controller will be elaborately described here.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-36553-2_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-662-05099-6_19,Neural Networks,Embedded Robotics,10.1007/978-3-662-05099-6_19,Springer,2003-01-01,"The artificial neural network (ANN), often simply called neural network (NN), is a processing model loosely derived from biological neurons [Gurney 2002]. Neural networks are often used for classification problems or decision making problems that do not have a simple or straightforward algorithmic solution. The beauty of a neural network is its ability to learn an input to output mapping from a set of training cases without explicit programming, and then being able to generalize this mapping to cases not seen previously.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-662-05099-6_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-44869-1_28,From Continuous Behaviour to Discrete Knowledge,Artificial Neural Nets Problem Solving Methods,10.1007/3-540-44869-1_28,Springer,2003-01-01,"Neural networks have proven to be very powerful techniques for solving a wide range of tasks. However, the learned concepts are unreadable for humans. Some works try to obtain symbolic models from the networks, once these networks have been trained, allowing to understand the model by means of decision trees or rules that are closer to human understanding. The main problem of this approach is that neural networks output a continuous range of values, so even though a symbolic technique could be used to work with continuous classes, this output would still be hard to understand for humans. In this work, we present a system that is able to model a neural network behaviour by discretizing its outputs with a vector quantization approach, allowing to apply the symbolic method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-44869-1_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-39432-7_36,Adaptive Coupling and Intersubjectivity in Simulated Turn-Taking Behaviour,Advances in Artificial Life,10.1007/978-3-540-39432-7_36,Springer,2003-01-01,"Turn-taking behaviour is simulated with a coupled agents system. Each agent is modelled as a mobile robot with two wheels. A recurrent neural network is used to produce the motor outputs and to hold the internal dynamics. Agents are developed to take turns on a two dimensional arena by causing the network structures to evolve. Turn-taking is established using either regular or chaotic behaviour of the agents. It is found that chaotic turn-takers are more sensitive to the adaptive inputs from the other agent. On the other hand, regular turn-takers are comparatively insensitive to noisy inputs due to their restricted dynamics. From various observations, including turn-taking with virtual agents, we claim that the chaotic turn-taking agents become less robust when coping with virtual agents but at the same time, those agents are more adaptable to each other than the regular turn-taking agents. All these findings are discussed and compared with Trevarthen’s double monitor experiments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-39432-7_36,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-36605-9_54,Exploring the T-Maze: Evolving Learning-Like Robot Behaviors Using CTRNNs,Applications of Evolutionary Computing,10.1007/3-540-36605-9_54,Springer,2003-01-01,"This paper explores the capabilities of continuous time recurrent neural networks (CTRNNs) to display reinforcement learning-like abilities on a set of T-Maze and double T-Maze navigation tasks, where the robot has to locate and “remember” the position of a reward-zone. The “learning” comes about without modifications of synapse strengths, but simply from internal network dynamics, as proposed by [ 12 ]. Neural controllers are evolved in simulation and in the simple case evaluated on a real robot. The evolved controllers are analyzed and the results obtained are discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-36605-9_54,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-44989-2_130,Indirect Differentiation of Function for a Network of Biologically Plausible Neurons,Artificial Neural Networks and Neural Information Processing — ICANN/ICONIP 2003,10.1007/3-540-44989-2_130,Springer,2003-01-01,"This paper introduces a new method to model differentiation of biologically plausible neurons, introducing the capability for indirectly defining the characteristics for a network of spiking neurons. Due to its biological plausibility and greater potential for computational power, a spiking neuron model is employed as the basic functional unit in our system. The method for designing the architecture (network design, communication structure, and neuron functionality) for networks of spiking neurons has been purely a manual process. In this paper, we propose a new design for the differentiation of a network of spiking neurons, such that these networks can be indirectly specified, thus enabling a method for the automatic creation of a network for a predetermined function. In this manner, the difficulties associated with the manual creation of these networks are overcome, and opportunity is provided for the utilization of these networks more readily for applications. Thus, this paper provides a new method for indirectly constructing these powerful networks, such as could be easily linked to an evolutionary system or other optimization algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-44989-2_130,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-36216-6_14,Evolutionary Dynamics Identification of Multi-Link Manipulators Using Runge-Kutta-Gill RBF Networks,Soft Computing in Measurement and Information Acquisition,10.1007/978-3-540-36216-6_14,Springer,2003-01-01,"This chapter discusses a method for the identification of dynamics and control of a multilink industrial robot manipulator using Runge-Kutta-Gill neural networks (RKGNNs). RKGNNs are used to identify an ordinary differential equation of the dynamics of the robot manipulator. A structured function neural network (NN) with subnetworks to represent the components of the dynamics is used in the RKGNNs. The subnetworks consist of shape adaptive radial basis function (RBF) NNs. An evolutionary algorithm is used to optimize the shape parameters and the weights of the RBFNNs. Due to the fact that the RKGNNs can accurately grasp the changing rates of the states, this method can effectively be used for long-term prediction of the states of the robot manipulator dynamics. Unlike in conventional methods, the proposed method can even be used without input torque information because a torque network is part of the function network. This method can be proposed as an effective option for the dynamics identification of manipulators with high degrees-of-freedom, as opposed to the derivation of dynamic equations and making additional hardware changes as in the case of statistical parameter identification such as linear leastsquares method. Experiments were carried out using a sevenlink industrial manipulator.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-36216-6_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-017-0317-8_5,Hybrid Intelligent Approaches in Robotics,Intelligent Control of Robotic Systems,10.1007/978-94-017-0317-8_5,Springer,2003-01-01,"Although fuzzy logic can encode expert knowledge in a direct and easy way using rules with linguistic labels, it often takes a lot of time to design and tune the membership functions which quantitatively define these linguistic labels. Wrong membership functions can lead to poor controller performance and possible instability. An excellent solution is to apply learning techniques by neural networks, which can be used to design membership functions automatically, simultaneously reducing development time and costs and improving the system performance. These combined neuro-fuzzy networks can learn faster than neural networks. They also provide a connectionist architecture that is easy for VLSI implementation to perform the functions of a conventional fuzzy logic controller with distributed learning abilities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-017-0317-8_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-45135-8_10,Towards a Life-Long Learning Soccer Agent,RoboCup 2002: Robot Soccer World Cup VI,10.1007/978-3-540-45135-8_10,Springer,2003-01-01,"One problem in robotic soccer (and in robotics in general) is to adapt skills and the overall behavior to a changing environment and to hardware improvements. We applied hierarchical reinforcement learning in an SMDP framework learning on all levels simultaneously. As our experiments show, learning simultaneously on the skill level and on the skill selection level is advantageous since it allows for a smooth adaption to a changing environment. Furthermore, the skills we trained turn also out to be quite competitive when run on the real robotic players of the players of our CS Freiburg team.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-45135-8_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-45210-2_41,Inverse Kinematics for Humanoid Robots Using Artificial Neural Networks,Computer Aided Systems Theory - EUROCAST 2003,10.1007/978-3-540-45210-2_41,Springer,2003-01-01,"The area of inverse kinematics of robots, mainly manipulators, has been widely researched, and several solutions exist. The solutions provided by analytical methods are specific to a particular robot configuration and are not applicable to other robots. Apart from this drawback, legged robots are inherently redundant because they need to have real humanoid configurations. This degree of redundancy makes the development of an analytical solution for the inverse kinematics practically unapproachable. For this reason, our proposed method considers the use of artificial neural networks to solve the inverse kinematics of the articulated chain that represents the robot’s legs. Since the robot should always remain stable and never fall, the learning set presented to the artificial neural network can be conveniently filtered to eliminate the undesired robot configurations and reduce the training process complexity.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-45210-2_41,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-7908-1775-1_6,Self-Adapting Neural Networks for Mobile Robots,Biologically Inspired Robot Behavior Engineering,10.1007/978-3-7908-1775-1_6,Springer,2003-01-01,"In the context of research on intelligence, autonomous agents and in particular mobile robots are to behave on their own without any human control. Unfortunately, the real world exhibits plenty of noise, uncertainties, sudden changes, etc, which all imposes significant challenges on the design of appropriate control architectures. This chapter starts off with an existing controller, known as the distributed adaptive control architecture and shows how significant improvements can be achieved by incorporating biological mechanisms, such as proprioception. The resulting controller requires much less preprogrammed design knowledge, exhibits more flexible adaptation capabilities, and is more fault tolerant with respect to environmental changes and sensor failures as its predecessors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7908-1775-1_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-24581-0_55,Convolutional Neural Networks for Image Processing: An Application in Robot Vision,AI 2003: Advances in Artificial Intelligence,10.1007/978-3-540-24581-0_55,Springer,2003-01-01,"Convolutional neural networks (CNNs) represent an interesting method for adaptive image processing, and form a link between general feed-forward neural networks and adaptive filters. Two dimensional CNNs are formed by one or more layers of two dimensional filters, with possible non-linear activation functions and/or down-sampling. CNNs possess key properties of translation invariance and spatially local connections (receptive fields). We present a description of the convolutional network architecture, and an application to practical image processing on a mobile robot. A CNN is used to detect and characterize cracks on an autonomous sewer inspection robot. The filter sizes used in all cases were 4x4, with non-linear activations between each layer. The number of feature maps used in the three hidden layers was, from input to output, 4, 4, 4. The network was trained using a dataset of 48x48 sub-regions drawn from 30 still image 320x240 pixel frames sampled from a pre-recorded sewer pipe inspection video. 15 frames were used for training and 15 for validation of network performance. Although development of a CNN system for civil use is on-going, the results support the notion that data-based adaptive image processing methods such as CNNs are useful for image processing, or other applications where the input arrays are large, and spatially / temporally distributed. Further refinements of the CNN architecture, such as the implementation of separable filters, or extensions to three dimensional (ie. video) processing, are suggested.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-24581-0_55,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-7908-1767-6_16,Robot Vision Using Cellular Neural Networks,Autonomous Robotic Systems,10.1007/978-3-7908-1767-6_16,Springer,2003-01-01,We show how Cellular Neural Networks (CNNs) can provide the necessary image processing to guide an autonomous mobile robot in a maze made of black lines on a light surface. The system consists of a fuzzy controller performing the elementary navigation tasks fed by the result of processing the image only by CNN techniques. We use this solution to make some considerations on more difficult problems such as curved or dashed line following and obstacle avoidance.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7908-1767-6_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1021386708994,The March of the robot dogs,Ethics and Information Technology,10.1023/A:1021386708994,Springer,2002-12-01,"Following the success of Sony Corporation's`AIBO,' robot cats and dogs are multiplyingrapidly. ``Robot pets'' employing sophisticatedartificial intelligence and animatronictechnologies are now being marketed as toys andcompanions by a number of large consumerelectronics corporations. It is often suggested in popular writing aboutthese devices that they could play a worthwhilerole in serving the needs of an increasinglyaging and socially isolated population. Robotcompanions, shaped like familiar householdpets, could comfort and entertain lonely olderpersons. This goal is misguided and unethical. While there are a number of apparent benefitsthat might be thought to accrue from ownershipof a robot pet, the majority and the mostimportant of these are predicated on mistaking, at a conscious or unconscious level,the robot for a real animal. For an individualto benefit significantly from ownership of arobot pet they must systematically deludethemselves regarding the real nature of theirrelation with the animal. It requiressentimentality of a morally deplorable sort. Indulging in such sentimentality violates a(weak) duty that we have to ourselves toapprehend the world accurately. The design andmanufacture of these robots is unethical in sofar as it presupposes or encourages thisdelusion. The invention of robot pets heralds thearrival of what might be called ``ersatzcompanions'' more generally. That is, ofdevices that are designed to engage in andreplicate significant social and emotionalrelationships. The advent of robot dogs offersa valuable opportunity to think about the worthof such companions, the proper place of robots in society and the value we should place on ourrelationships with them.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1021386708994,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF02828245,The intellectualized architecture of the autonomous micro-mobile robot based-behavior,Wuhan University Journal of Natural Sciences,10.1007/BF02828245,Springer,2002-12-01,"Given the difficulty in hand-coding task schemes, an intellectualized architecture of the autonomous micro-mobile robot based-behavior for fault-repair was presented. Integrating the reinforcement learning and the group behavior evolution simulating the human’s learning and evolution, the autonomous micro-mobile robot will automatically generate the suited actions satisfied the environment. However, the designer only devises some basic behaviors, which decreases the workload of the designer and cognitive deficiency of the robot to the environment. The results of simulation have shown that the architecture endows micro robot with the ability of learning, adaptation and robustness, also with the ability of accomplishing the given task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF02828245,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1021309224128,Neural computing increases robot adaptivity,Natural Computing,10.1023/A:1021309224128,Springer,2002-12-01,"The limited adaptivity of current robots is preventing their widespreadapplication. Since the biological world offers a full range of adaptive mechanisms working at different scales, researchers have turned to it for inspiration. Among the several disciplines trying to reproduce these mechanisms artificially, this paper concentrates on the field of Neural Networks and its contributions to attain sensorimotor adaptivity in robots. Essentially this type of adaptivity requires tuning nonlinear mappings on the basis of input-output information. After briefly reviewing the fundamentals of neural computing, the paper describes several experimental robotic systems relying on the following adaptive mappings: inverse kinematics, inverse dynamics, visuomotor and force-control mappings. Finally, the main trends in the evolution of neural computing are highlighted, followed by some remarks drawn from the surveyed robotic applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1021309224128,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF02481323,Supervised learning technique for a mobile robot controller in a visual line tracking task,Artificial Life and Robotics,10.1007/BF02481323,Springer,2002-09-01,"This article deals with the development of learning methods for an intelligent control system for an autonomous mobile robot. On the basis of visual servoing, an approach to learning the skill of tracking colored guidelines is proposed. This approach utilizes a robust and adaptive image processing method to acquire features of the colored guidelines and convert them into the controller input. The supervised learning procedure and the neural network controller are discussed. The method of obtaining the learning data and training the neural network are described. Experimental results are presented at the end of the article.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF02481323,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1015742406259,A Self-Organizing Context-Based Approach to the Tracking of Multiple Robot Trajectories,Applied Intelligence,10.1023/A:1015742406259,Springer,2002-07-01,"We have combined competitive and Hebbian learning in a neural network designed to learn and recall complex spatiotemporal sequences. In such sequences, a particular item may occur more than once or the sequence may share states with another sequence. Processing of repeated/shared states is a hard problem that occurs very often in the domain of robotics. The proposed model consists of two groups of synaptic weights: competitive interlayer and Hebbian intralayer connections, which are responsible for encoding respectively the spatial and temporal features of the input sequence. Three additional mechanisms allow the network to deal with shared states: context units, neurons disabled from learning, and redundancy used to encode sequence states. The network operates by determining the current and the next state of the learned sequences. The model is simulated over various sets of robot trajectories in order to evaluate its storage and retrieval abilities; its sequence sampling effects; its robustness to noise and its tolerance to fault.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1015742406259,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1015775631060,Searching a Scalable Approach to Cerebellar Based Control,Applied Intelligence,10.1023/A:1015775631060,Springer,2002-07-01,"Decades of research into the structure and function of the cerebellum have led to a clear understanding of many of its cells, as well as how learning might take place. Furthermore, there are many theories on what signals the cerebellum operates on, and how it works in concert with other parts of the nervous system. Nevertheless, the application of computational cerebellar models to the control of robot dynamics remains in its infant state. To date, few applications have been realized. The currently emerging family of light-weight robots (Hirzinger, in Proc. Second ecpd Int. Conference on Advanced Robotics, Intelligent Automation and Active Systems , 1996) poses a new challenge to robot control: due to their complex dynamics traditional methods, depending on a full analysis of the dynamics of the system, are no longer applicable since the joints influence each other dynamics during movement. Can artificial cerebellar models compete here?",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1015775631060,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1015762314222,Guest Editorial for Special Issue on Scalable Applications of Neural Networks to Robotics,Applied Intelligence,10.1023/A:1015762314222,Springer,2002-07-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1015762314222,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1015008417172,Reinforcement Learning Agents,Artificial Intelligence Review,10.1023/A:1015008417172,Springer,2002-05-01,"Reinforcement Learning (RL) is learning through directexperimentation. It does not assume the existence of a teacher thatprovides examples upon which learning of a task takes place. Instead, inRL experience is the only teacher. With historical roots on the study ofbiological conditioned reflexes, RL attracts the interest of Engineersand Computer Scientists because of its theoretical relevance andpotential applications in fields as diverse as Operational Research andIntelligent Robotics. Computationally, RL is intended to operate in a learning environmentcomposed by two subjects: the learner and a dynamic process. Atsuccessive time steps, the learner makes an observation of the processstate, selects an action and applies it back to the process. Its goal isto find out an action policy that controls the behavior of the dynamicprocess, guided by signals (reinforcements) that indicate how badly orwell it has been performing the required task. These signals are usuallyassociated to a dramatic condition – e.g., accomplishment of a subtask(reward) or complete failure (punishment), and the learner tries tooptimize its behavior by using a performance measure (a function of thereceived reinforcements). The crucial point is that in order to do that,the learner must evaluate the conditions (associations between observedstates and chosen actions) that led to rewards or punishments. Starting from basic concepts, this tutorial presents the many flavorsof RL algorithms, develops the corresponding mathematical tools, assesstheir practical limitations and discusses alternatives that have beenproposed for applying RL to realistic tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1015008417172,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1015522622034,A New Conceptual Approach to the Design of Hybrid Control Architecture for Autonomous Mobile Robots,Journal of Intelligent and Robotic Systems,10.1023/A:1015522622034,Springer,2002-05-01,"A detailed analysis and comparison of various control architectures is presented in order to meet the challenging design requirements targeted. All the present advanced control systems have certain advantages and disadvantages compared with each other. Due to the lack of an optimal control system with desired capabilities, such a control system has been the focus of recent robotics research programs. The new approach proposed in this paper is a hybrid control system that takes the advantages of various control structure types thereby integrating them in a way that results in an overall increase in synergy. The proposed control architecture presents a new approach to the design of supervisory control system that utilizes reactive, deliberative, distributed and centralised control approaches, and uses fuzzy logic as well as modular hierarchical structure. The architecture carries out supervision, modification and execution of commands generated by the centralised command arbitration module by conducting fuzzy logic integration of activated behaviours from distributed, independent asynchronous decision making processes that takes information from the user, sensory system and task description, thus providing goal-oriented, real-time responsive and tele-operable control system architecture. The resulting control system was experimented on and it was observed that not only was the response time sufficiently short, but also it exhibited robustness, flexibility, adaptability, portability and expandability.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1015522622034,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1015221832567,Gait Adaptation in a Quadruped Robot,Autonomous Robots,10.1023/A:1015221832567,Springer,2002-05-01,"A newborn foal can learn to walk soon after birth through a process of rapid adaptation acting on its locomotor controller. It is proposed here that this kind of adaptation can be modeled as a distributed system of adaptive modules (AMs) acting on a distributed system of adaptive oscillators called Adaptive Ring Rules (ARRs), augmented with appropriate and simple reflexes. It is shown that such a system can self-program through interaction with the environment. The adaptation emerges spontaneously as several discrete stages: Body twisting, short quick steps, and finally longer, coordinated stepping. This approach is demonstrated on a quadrupedal robot. The result is that the system can learn to walk several minutes after inception.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1015221832567,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11802-002-0038-0,Incorporation of perception-based information in robot learning using fuzzy reinforcement learning agents,Journal of Ocean University of Qingdao,10.1007/s11802-002-0038-0,Springer,2002-04-01,"Robot learning in unstructured environments has been proved to be an extremely challenging problem, mainly because of many uncertainties always present in the real world. Human beings, on the other hand, seem to cope very well with uncertain and unpredictable environments, often relying on perception-based information . Furthermore, humans beings can also utilize perceptions to guide their learning on those parts of the perception-action space that are actually relevant to the task. Therefore, we conduct a research aimed at improving robot learning through the incorporation of both perception-based and measurement-based information. For this reason, a fuzzy reinforcement learning (FRL) agent is proposed in this paper. Based on a neural-fuzzy architecture, different kinds of information can be incorporated into the FRL agent to initialise its action network, critic network and evaluation feedback module so as to accelerate its learning. By making use of the global optimisation capability of GAs (genetic algorithms), a GA-based FRL (GAFRL) agent is presented to solve the local minima problem in traditional actor-critic reinforcement learning. On the other hand, with the prediction capability of the critic network, GAs can perform a more effective global search. Different GAFRL agents are constructed and verified by using the simulation model of a physical biped robot. The simulation analysis shows that the biped learning rate for dynamic balance can be improved by incorporating perception-based information on biped balancing and walking evaluation. The biped robot can find its application in ocean exploration, detection or sea rescue activity, as well as military maritime activity.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11802-002-0038-0,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF02481210,Path planning of a mobile robot by optimization and reinforcement learning,Artificial Life and Robotics,10.1007/BF02481210,Springer,2002-03-01,"At AROB5, we proposed a solution to the path planning of a mobile robot. In our approach, we formulated the problem as a discrete optimization problem at each time step. To solve the optimization problem, we used an objective function consisting of a goal term, a smoothness term, and a collision term. While the results of our simulation showed the effectiveness of our approach, the values of the weights in the objective function were not given by any theoretical method. This article presents a theoretical method using reinforcement learning for adjusting the weight parameters. We applied Williams' learning algorithm, episodic REINFORCE, to derive a learning rule for the weight parameters. We verified the learning rule by some experiments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF02481210,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF02481209,Evolutionary robot controllers with competitive and cooperative neural networks,Artificial Life and Robotics,10.1007/BF02481209,Springer,2002-03-01,"This article describes a new approach for control systems for an autonomous mobile robot by using sandwiches of two different types of neural network. One is a neural network with competition and cooperation, and is used for recognizing sensor information where synaptic coupling are fixed. The second is a neural network with adaptive synaptic couplings corresponding to a genotype in a creature, and used for self-learning for the wheel controls. In a computer simulation model, we were successful in obtaining four types of robot with good performance when going along a wall. The model also showed robustness in a real environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF02481209,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1014643811186,Neural Network Controller against Environment: A Coevolutive approach to Generalize Robot Navigation Behavior,Journal of Intelligent and Robotic Systems,10.1023/A:1014643811186,Springer,2002-02-01,"In this paper, a new coevolutive method, called Uniform Coevolution, is introduced to learn weights of a neural network controller in autonomous robots. An evolutionary strategy is used to learn high-performance reactive behavior for navigation and collisions avoidance. The introduction of coevolutive over evolutionary strategies allows evolving the environment, to learn a general behavior able to solve the problem in different environments. Using a traditional evolutionary strategy method, without coevolution, the learning process obtains a specialized behavior. All the behaviors obtained, with/without coevolution have been tested in a set of environments and the capability of generalization is shown for each learned behavior. A simulator based on a mini-robot Khepera has been used to learn each behavior. The results show that Uniform Coevolution obtains better generalized solutions to examples-based problems.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1014643811186,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1014603028024,Robust Adaptive Dead Zone Technology for Fault-Tolerant Control of Robot Manipulators Using Neural Networks,Journal of Intelligent and Robotic Systems,10.1023/A:1014603028024,Springer,2002-02-01,"In this paper, a multi-layered feed-forward neural network is trained on-line by robust adaptive dead zone scheme to identify simulated faults occurring in the robot system and reconfigure the control law to prevent the tracking performance from deteriorating in the presence of system uncertainty. Consider the fact that system uncertainty can not be known a priori , the proposed robust adaptive dead zone scheme can estimate the upper bound of system uncertainty on line to ensure convergence of the training algorithm, in turn the stability of the control system. A discrete-time robust weight-tuning algorithm using the adaptive dead zone scheme is presented with a complete convergence proof. The effectiveness of the proposed methodology has been shown by simulations for a two-link robot manipulator.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1014603028024,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45683-X_85,A Wrapper-Based Approach to Robot Learning Concepts from Images,PRICAI 2002: Trends in Artificial Intelligence,10.1007/3-540-45683-X_85,Springer,2002-01-01,This work is about the building of a lexicon of shared symbols between a Pioneer 2DX mobile robot and its human interlocutors. This lexicon contains words corresponding to objects seen in the environment. The difficulty relies in grounding these symbols with the actual data provided by the camera of the robot with respect to the learning scenario shown in figure,http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-45683-X_85,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45712-7_57,TCS Learning Classifier System Controller on a Real Robot,Parallel Problem Solving from Nature — PPSN VII,10.1007/3-540-45712-7_57,Springer,2002-01-01,"To date there have been few implementation of Holland’s Learning Classifier System (LCS) on real robots. The paper introduces a Temporal Classifier System (TCS), an LCS derived from Wilson’s ZCS. Traditional LCS have the ability to generalise over the state action-space of a reinforcement learning problem using evolutionary techniques. In TCS this generalisation ability can also be used to determine the state divisions in the state space considered by the LCS. TCS also implements components from Semi-Mark- Decision Process (SMDP) theory to weight the influence of time on the reward functions of the LCS. A simple light-seeking task on a real robot platform using TCS is presented which demonstrates desirable adaptive characteristics for the use of LCS on real robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-45712-7_57,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45622-8_3,Spatiotemporal Abstraction of Stochastic Sequential Processes,"Abstraction, Reformulation, and Approximation",10.1007/3-540-45622-8_3,Springer,2002-01-01,"Probabilistic finite state machines have become a popular modeling tool for representing sequential processes , ranging from images and speech signals to text documents and spatial and genomic maps. In this paper, I describe two hierarchical abstraction mechanisms for simplifying the (estimation) learning and (control) optimization of complex Markov processes: spatial decomposition and temporal aggregation. I present several approaches to combining spatial and temporal abstraction, drawing upon recent work of my group as well as that of others. I show how spatiotemporal abstraction enables improved solutions to three difficult sequential estimation and decision problems: hidden state modeling and control, learning parallel plans, and coordinating with multiple agents.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-45622-8_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4471-0123-9_1,Diagnosis and Control for Multi-agent Systems Using Immune Networks,Soft Computing and Industry,10.1007/978-1-4471-0123-9_1,Springer,2002-01-01,"Soft computing (SC) is an evolving collection of methodologies, i.e., fuzzy, neuro, and evolutionary computing. Chaotic computing and immune systems are added later to enhance the soft computing capabilities. The fusion of SC components creates new functions i.e. flexible knowledge representation (symbol and pattern), acquisition and inference (tractability, machine intelligent quotient), and robust and low cost product. Among them immune systems are very suitable for control and diagnosis of multi-agent systems (large-scale and complex systems) that interact among human beings, environment and artificial objects corresponding to the usage of complex interactions among antibodies and antigens in the immune systems. This paper describes novel sensor fault diagnosis for an uninterruptible power supply control system and new decision making of a robot in a changeable environment using immune networks. Simulation studies show that the proposed methods are feasible and promising for control and diagnosis of large-scale and complex dynamical systems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-0123-9_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-4-431-65941-9_46,Neural Networks (NN) Using Genetic Algorithms (GA) and Gradient Back-Propagation (GBP) for an Intelligent Obstacle Avoidance Behavior,Distributed Autonomous Robotic Systems 5,10.1007/978-4-431-65941-9_46,Springer,2002-01-01,"To ensure more autonomy and intelligence with real-time processing capabilities for the obstacle avoidance behavior of Intelligent Autonomous Vehicles (IAV), the use of Neural Networks (NN) is necessary to bring this behavior near to that of humans in the recognition, learning, adaptation, reasoning and decision-making, and action. In this paper, three (03) supervised learning algorithms namely Gradient Back-Propagation (GBP), Genetic Algorithms (GA) and GA-GBP are suggested to train a NN to learn spatial obstacle avoidance situations. A synthesis of the suggested NN/GBP, NN/GA and NN/GA-GBP is presented where their results and performances are discussed. Finally, a Field-Programmable Gate Array (FPGA) architecture, characterized by its high flexibility and compactness, is suggested for the NN implementation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-4-431-65941-9_46,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12064-001-0018-8,Behavior reuse and virtual sensors in the evolution of complex behavior architectures,Theory in Biosciences,10.1007/s12064-001-0018-8,Springer,2001-12-01,"In this paper we discuss some of the new work we have been carrying out with the objective of making evolutionarily obtained behavior based architectures and modules for autonomous robots more standardized and interchangeable. The architectures contemplated here are based on a multiple behavior structure where all of the modules, as well as their interconnections, are automatically obtained through evolutionary processes. The main objective of this line of research is to obtain procedures that permit producing behavior based controllers that work on real robots operating in real environments as independently of the platform as possible. In this particular paper we will concentrate on different aspects regarding the inclusion of virtual sensors as a way to make improved use of the capabilities of the different platforms and on the reuse of behavior modules. This reuse will be contemplated within the same behavioral architecture and from the point of view of transferring behavior modules from one platform to a different one.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12064-001-0018-8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12064-001-0017-9,Self-organized acquisition of situated behaviors,Theory in Biosciences,10.1007/s12064-001-0017-9,Springer,2001-12-01,The paper aims at a systematic approach to the self-organization of behavior. It is rooted in the ideas of situated artificial intelligence and introduces situated behavior as the target for the self-organization procedure. Based on a quantitative measure of behavioral situatedness a learning dynamics is introduced which enables the controller to sustain the situatedness of the agent. The principle is demonstrated with Khepera robots in a number of different environmental conditions.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12064-001-0017-9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1012459627968,Evolution of Plastic Control Networks,Autonomous Robots,10.1023/A:1012459627968,Springer,2001-11-01,"Evolutionary Robotics is a powerful method to generate efficient controllers with minimal human intervention, but its applicability to real-world problems remains a challenge because the method takes long time and it requires software simulations that do not necessarily transfer smoothly to physical robots. In this paper we describe a method that overcomes these limitations by evolving robots for the ability to adapt on-line in few seconds. Experiments show that this method require less generations and smaller populations to evolve, that evolved robots adapt in a few seconds to unpredictable change-including transfers from simulations to physical robots- and display non-trivial behaviors. Robots evolved with this method can be dispatched to other planets and to our homes where they will autonomously and quickly adapt to the specific properties of their environments if and when necessary.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1012459627968,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF02481463,Control system for the Khepera robot by a neural network with competition and cooperation,Artificial Life and Robotics,10.1007/BF02481463,Springer,2001-09-01,"This article describes a new approach to control systems for a mobile robot Khepera by using a neural network with competition and cooperation as the processing unit for the robot sensors. Competition makes only one neuron active, while cooperation keeps them all active. In our research, we find that the Khepera controlled by this neural network can maintain a smoother trajectory than when it is controlled by the output values of its own sensors, especially in noisy environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF02481463,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF02481348,Self-adaptation in classifier system controllers,Artificial Life and Robotics,10.1007/BF02481348,Springer,2001-06-01,"The use and benefits of self-adaptive mutation operators are well known within evolutionary computing. In this paper, we begin by examining the use of self-adaptive mutation in learning classifier systems with the aim of improving their performance as controllers for autonomous mobile robots. We implement the operator in a zeroth level classifier system, and examine its performance in two animat environments. It is shown that although no significant increase in performance is seen over results presented in the literature using a fixed rate of mutation, the operator adapts to an appropriate rate regadless of the initial range. The same concept is then applied to the learning rate parameter, but results show that a modification must be made to produce stable/effective controllers. Finally, results from a fully self-adaptive system are presented, with marked benefits being found in a nonstationary environment.",http://link.springer.com/openurl/pdf?id=doi:10.1007/BF02481348,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1011286308522,The CAM-Brain Machine (CBM): An FPGA Based Tool for Evolving a 75 Million Neuron Artificial Brain to Control a Lifesized Kitten Robot,Autonomous Robots,10.1023/A:1011286308522,Springer,2001-05-01,"This article introduces the “CAM-Brain Machine” (CBM), an FPGA based piece of hardware which implements a genetic algorithm (GA) to evolve a cellular automata (CA) based neural network circuit module, of approximately 1,000 neurons, in about a second, i.e., a complete run of a GA, with 10,000s of circuit growths and performance evaluations. Up to 65,000 of these modules, each of which is evolved with a humanly specified function, can be downloaded into a large RAM space, and interconnected according to humanly specified artificial brain architectures. This RAM, containing an artificial brain with up to 75 million neurons, is then updated by the CBM at a rate of 130 billion CA cells per second. Such speeds should enable real time control of robots and hopefully the birth of a new research field that we call “brain building.” The first such artificial brain, to be built in 2000 and beyond, will be used to control the behaviors of a life sized robotkitten called “Robokitty.”",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1011286308522,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1011394317088,The Construction of ‘Reality’ in the Robot: Constructivist Perspectives on Situated Artificial Intelligence and Adaptive Robotics,Foundations of Science,10.1023/A:1011394317088,Springer,2001-03-01,"This paper discusses different approaches incognitive science and artificial intelligenceresearch from the perspective of radicalconstructivism, addressing especially theirrelation to the biologically based theories ofvon Uexküll, Piaget as well as Maturana andVarela. In particular recent work in ‘New AI’ and adaptive robotics on situated and embodiedintelligence is examined, and we discuss indetail the role of constructive processes asthe basis of situatedness in both robots andliving organisms.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1011394317088,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008113324758,Evaluation of a Low-cost MEMS Accelerometer for Distance Measurement,Journal of Intelligent and Robotic Systems,10.1023/A:1008113324758,Springer,2001-03-01,"This paper gives an evaluation of a low-cost MEMS accelerometer. The accelerometer is intended for the distance measurement of a mobile robot or platform in short duration. The distance traveled is obtained by double integration of the sensor signal with time. Bias offset drift exhibited in the acceleration signal is accumulative and the accuracy of the distance measurement can deteriorate with time due to the integration. This problem can be fixed by periodic recalibration with the help of external measurements on position, velocity and attitude. These external signals can be calculated by an inertial system. A Kalman filter can use the differences between these values to provide an optimum estimate of the system error. The random bias drift of the accelerometer was found by experiment to be 2.5 mg. The bias drift rate due to temperature was 0.108 μg/s when the accelerometer was placed at room temperature. With proper compensation on gravitation, the accelerometer can be a viable solution as a short duration distance-measuring device for a mobile robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008113324758,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008194912825,Fuzzy and Recurrent Neural Network Motion Control among Dynamic Obstacles for Robot Manipulators,Journal of Intelligent and Robotic Systems,10.1023/A:1008194912825,Springer,2001-02-01,"An integration of fuzzy controller and modified Elman neural networks (NN) approximation-based computed-torque controller is proposed for motion control of autonomous manipulators in dynamic and partially known environments containing moving obstacles. The fuzzy controller is based on artificial potential fields using analytic harmonic functions, a navigation technique common used in robot control. The NN controller can deal with unmodeled bounded disturbances and/or unstructured unmodeled dynamics of the robot arm. The NN weights are tuned on-line, with no off-line learning phase required. The stability of the closed-loop system is guaranteed by the Lyapunov theory. The purpose of the controller, which is designed as a neuro-fuzzy controller, is to generate the commands for the servo-systems of the robot so it may choose its way to its goal autonomously, while reacting in real-time to unexpected events. The proposed scheme has been successfully tested. The controller also demonstrates remarkable performance in adaptation to changes in manipulator dynamics. Sensor-based motion control is an essential feature for dealing with model uncertainties and unexpected obstacles in real-time world systems.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008194912825,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-7091-6230-9_41,Recurrent Neural Networks in a Mobile Robot Navigation Task,Artificial Neural Nets and Genetic Algorithms,10.1007/978-3-7091-6230-9_41,Springer,2001-01-01,"Recurrent neural networks are applied to the forward modeling of the sensory-motor flow of a miniature mobile robot. It is shown that the robot is able to predict the sensory flow a few steps ahead, which suffices for simple environments. The proposed method requires mainly topological information (little geometrical information is used), simplifying the problem considerably.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7091-6230-9_41,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45723-2_58,Cellular Neural Networks for Mobile Robot Vision,Bio-Inspired Applications of Connectionism,10.1007/3-540-45723-2_58,Springer,2001-01-01,"We show how Cellular Neural Networks are capable of providing the necessary signal processing to guide an autonomous mobile robot in a maze drawn on the floor. In this way, a non-trivial navigation task is obtained by very simple hardware, making real autonomous operation feasible. An autonomous line-following robot was first simulated and then implemented by simulating the CNN with a DSP.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-45723-2_58,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45324-5_32,Path Planning of a Mobile Robot as a Discrete Optimization Problem and Adjustment of Weight Parameters in the Objective Function by Reinforcement Learning,RoboCup 2000: Robot Soccer World Cup IV,10.1007/3-540-45324-5_32,Springer,2001-01-01,"In a previous paper, we proposed a solution to path planning of a mobile robot. In our approach, we formulated the problem as a discrete optimization problem at each time step. To solve the optimization problem we, used an objective function consisting of a goal term, a smoothness term and a collision term. This paper presents a theoretical method using reinforcement learning for adjusting weght parameters in the objective functions. However, the conventional Q-learning method cannot be applied to a non-Markov decision process. Thus, we applied William’s learning algorithm, REINFORCE, to derive an updating rule for the weight parameters. This is a stochasic hill-climbing method to maximize a value function. We verified the updating rule by experiment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-45324-5_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45324-5_34,"A Quadratic Programming Formulation of a Moving Ball Interception and Shooting Behaviour, and its Application to Neural Network Control",RoboCup 2000: Robot Soccer World Cup IV,10.1007/3-540-45324-5_34,Springer,2001-01-01,"A desirable elementary behaviour for a robot soccer player is the moving ball interception and shooting behaviour, but generating smooth, fast motion for a mobile robot in a changing environment is a difficult problem. We address this problem by formulating the specifications of this behaviour as a quadratic programming optimisation problem, and by training a neural network controller on the exact solution computed off-line by a quadratic programming problem optimiser. We present experimental results showing the validity of the approach and discuss potential applications of this approach in the context of reinforcement learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-45324-5_34,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45723-2_59,Learning to Predict Variable-Delay Rewards and Its Role in Autonomous Developmental Robotics,Bio-Inspired Applications of Connectionism,10.1007/3-540-45723-2_59,Springer,2001-01-01,"Researchers in the new field of “developmental robotics” propose to provide robots with so-called developmental programs. Similar to the development of human infants, robots might use those programs to interact with humans and their environment for extended periods of time, and become smarter autonomously. In this paper we show how a neural network model developed by neuroscientists can be used by an autonomous robot to learn by trial-and-error when considering rewards delivered at arbitrary times, as would be the case of developmental robots interacting with humans in the real world.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-45723-2_59,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/3-540-44597-8_37,Using a Time-Delay Actor-Critic Neural Architecture with Dopamine-Like Reinforcement Signal for Learning in Autonomous Robots,Emergent Neural Computational Architectures Based on Neuroscience,10.1007/3-540-44597-8_37,Springer,2001-01-01,"Neuroscientists have identifed a neural substrate of predic- tion and reward in experiments with primates. The so-called dopamine neurons have been shown to code an error in the temporal prediction of rewards. Similarly, artificial systems can “learn to predict#x201D; by the so-called temporal-difference (TD) methods. Based on the general resemblance between the effective reinforcement term of TD models and the response of dopamine neurons, neuroscientists have developed a TD-learning time-delay actor-critic neural model and compared its per- formance with the behavior of monkeys in the laboratory. We have used such a neural network model to learn to predict variable-delay rewards in a robot spatial choice task similar to the one used by neuroscientists with primates. Such architecture implementing TD-learning appears as a promising mechanism for robotic systems that learn from simple human teaching signals in the real world.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-44597-8_37,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45720-8_43,Two Dimensional Evaluation Reinforcement Learning,"Connectionist Models of Neurons, Learning Processes, and Artificial Intelligence",10.1007/3-540-45720-8_43,Springer,2001-01-01,"To solve the problem of tradeoff between exploration and exploitation actions in reinforcement learning, the authors have proposed two-dimensional evaluation reinforcement learning, which distinguishes between reward and punishment evaluation forecasts. The proposed method use the difference between reward evaluation and punishment evaluation as a factor for determining the action and the sum as a parameter for determining the ratio of exploration to exploitation. In this paper we described an experiment with a mobile robot searching for a path and the subsequent conflict between exploration and exploitation actions. The results of the experiment prove that using the proposed method of reinforcement learning using the tw o dimensions of reward and punishment can generate a better path than using the conventional reinforcement learning method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-45720-8_43,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-44811-X_55,nBrains A New Type of Robot Brain,Advances in Artificial Life,10.1007/3-540-44811-X_55,Springer,2001-01-01,"The design and implementation of a possible alternative to Artificial Neural Networks (ANNs) for agent control is described. This alternative, known as the nBrain, uses the phase-space representation as the inspiration for a controller. The agent progresses to different states due to the presence of attractors in phase space, whose locations are set by the robot’s genome. Several experiments with simulated agents are described. The experiments were successful in that tasks which have been performed by ANNs in the past were successfully accomplished by nBrains under evolution. The possible advantages and disadvantages of nBrains over ANNs are discussed, and directions for future work are presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-44811-X_55,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-44811-X_84,Evolving Lives: The Individual Historical Dimension in Evolution,Advances in Artificial Life,10.1007/3-540-44811-X_84,Springer,2001-01-01,Some benefits of a dialogue between evolutionary robotics and developmental ethology are presented with discussion of how developmental models might inform approaches to evolution. Notions of the importance of historical processes in adaptation are outlined and parallels between evolution and ontogeny as sources of change examined.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-44811-X_84,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-1361-2_4,Developing Rational Agents,Human and Machine Perception 3,10.1007/978-1-4615-1361-2_4,Springer,2001-01-01,"An agent is a system that interacts with an environment continually and without human assistance in order to carry out a predefined task. We are interested in developing artificial agents that act rationally, in the sense that they are able to maximize a suitable utility function. In this chapter, we describe the main problems underlying the realization of rational agents and present commonly adopted mathematical models. In particular, we consider the case in which the environment can be modeled as a finite state stochastic process and address the problem of developing agents that can learn to act rationally through their own experience.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-1361-2_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45723-2_61,Sequence Learning in Mobile Robots Using Avalanche Neural Networks,Bio-Inspired Applications of Connectionism,10.1007/3-540-45723-2_61,Springer,2001-01-01,This paper describes the implementation of a neural network for sequence learning that is based on a neurocomputational theory of learning. The network is implemented on a physical mobile robot in order to learn to reproduce sequences of motor actions. At the onset of a conditioned stimulus the robot is presented with a sequence of visual stimuli that produce reactive motor actions of different duration. Initial results show that after learning the robot can approximate the motor sequence with no visual stimulation.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-45723-2_61,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-44692-3_53,Positioning of Flexible Boom Structure Using Neural Networks,Computer Analysis of Images and Patterns,10.1007/3-540-44692-3_53,Springer,2001-01-01,"Deflection compensation of flexible boom structures in robot positioning is becoming an important part of machine automation. Positioning is usually done using tables containing the magnitude of the deflection with inverse kinematics solutions of a rigid manipulator. In this paper, a method for locating the tip of a flexible manipulator using machine vision and a method for positioning the tip of a flexible manipulator using neural networks are proposed. A machine vision system was used in the data collection phase to locate the boom tip and the collected data was used to train MLP-networks. The developed methods improve the accuracy of manipulator positioning, and it can be integrated in the control system of the manipulator. The methods have been tested in real-time laboratory environment, and the results were promising. During the testing, the locating and the positioning were noticed to function as required, yielding reliable results with sufficient computation times.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-44692-3_53,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-0269-4_24,Acquiring Information from Books,Research and Development in Intelligent Systems XVII,10.1007/978-1-4471-0269-4_24,Springer,2001-01-01,"People need a vast amount of knowledge in order to live in an advanced technological society. Most of this has to be obtained from others by believing what they say and what they have written. Androids and sophisticated AI systems would also have to be able to learn in this way. This obvious fact tends to be overlooked by AI researchers (such as Pollock and Brooks) involved in the design of androids. They concentrate almost exclusively on belief-formation by means of perception. However, before we can program the ability to learn from others into an android we need to have a better understanding of human belief-acquisition. Elsewhere I have proposed a two-stage model of belief-acquisition. In the first stage we do acquire beliefs by means of our senses, but also from other people. In this latter case we make use of a defeasible rule, ‘Believe what you hear or read’. The second stage consists in the use of a sophisticated critical methodology in order to carefully assess a small number of our beliefs. In this paper I develop one part of this model in more detail. I look at the factors that cause us to override the defeasible rule to believe others in the situation when we are reading statements found in a book. This turns out to be far more complicated than may at first sight appear.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-0269-4_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45118-8_33,First Results in the Coordination of Heterogeneous Robots for Large-Scale Assembly,Experimental Robotics VII,10.1007/3-540-45118-8_33,Springer,2001-01-01,"While many multi-robot systems rely on fortuitous cooperation between agents, some tasks, such as the assembly of large structures, require tighter coordination. We present a general software architecture for coordinating heterogeneous robots that allows for both autonomy of the individual agents as well as explicit coordination. This paper presents recent results with three robots with very different configurations. Working as a team, these robots are able to perform a high-precision docking task that none could achieve individually.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-45118-8_33,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-44811-X_60,Mobile Robot Control Based on Boolean Logic with Internal Memory,Advances in Artificial Life,10.1007/3-540-44811-X_60,Springer,2001-01-01,"The purpose of this paper is to explore the effect of adding known amounts of memory to pure reactive systems in a variety of tasks. Using a finite state machine approach, we construct controllers for a simulated robot for five tasks—obstacle avoidance, wall following, exploration, and box pushing—with two sensor configurations using evolutionary computation techniques, and compare the performance of stateless and memory-based controllers. For obstacle avoidance and exploration no significant difference is observed; for wall-following and box pushing, stateless controllers are significantly worse than memory-based but increasing amounts of memory give no significant increase in performance. The need for memory in these cases reflects a need to discriminate sensorimotor contexts to effectively perform the task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-44811-X_60,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s005000000053,Neuro-fuzzy gait synthesis with reinforcement learning for a biped walking robot,Soft Computing,10.1007/s005000000053,Springer,2000-12-01," A reinforcement learning-based neuro-fuzzy gait synthesizer, which is based on the GARIC (Generalized Approximate Reasoning for Intelligent Control) architecture, is proposed for the problem of biped dynamic balance. We modify the GARIC architecture to enable it to generate the trunk trajectory in both sagittal and frontal plane. The proposed gait synthesizer is trained by reinforcement learning that uses a multi-valued scalar signal to evaluate the degrees of failure or success for the biped locomotion by means of the ZMP (Zero Moment Point). It can form the initial dynamic balancing gait from linguistic rules, which are obtained from human intuitive balancing knowledge and biomechanics studies, and accumulate dynamic balancing knowledge through reinforcement learning, and thus constantly improve its gait during walking. The feasibility of the proposed method is verified through a 5-link biped robot simulation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s005000000053,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008311207953,"Animals, Zombanimals, and the Total Turing Test","Journal of Logic, Language and Information",10.1023/A:1008311207953,Springer,2000-10-01,"Alan Turing devised his famous test (TT) through a slight modificationof the parlor game in which a judge tries to ascertain the gender of twopeople who are only linguistically accessible. Stevan Harnad hasintroduced the Total TT, in which the judge can look at thecontestants in an attempt to determine which is a robot and which aperson. But what if we confront the judge with an animal , and arobot striving to pass for one, and then challenge him to peg which iswhich? Now we can index TTT to a particular animal and its syntheticcorrelate. We might therefore have TTT_rat, TTT_cat,TTT_dog, and so on. These tests, as we explain herein, are abetter barometer of artificial intelligence (AI) than Turing's originalTT, because AI seems to have ammunition sufficient only to reach thelevel of artificial animal, not artificial person.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008311207953,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008918401478,A Gesture Based Interface for Human-Robot Interaction,Autonomous Robots,10.1023/A:1008918401478,Springer,2000-09-01,"Service robotics is currently a highly active research area in robotics, with enormous societal potential. Since service robots directly interact with people, finding “natural” and easy-to-use user interfaces is of fundamental importance. While past work has predominately focussed on issues such as navigation and manipulation, relatively few robotic systems are equipped with flexible user interfaces that permit controlling the robot by “natural” means. This paper describes a gesture interface for the control of a mobile robot equipped with a manipulator. The interface uses a camera to track a person and recognize gestures involving arm motion. A fast, adaptive tracking algorithm enables the robot to track and follow a person reliably through office environments with changing lighting conditions. Two alternative methods for gesture recognition are compared: a template based approach and a neural network approach. Both are combined with the Viterbi algorithm for the recognition of gestures defined through arm motion (in addition to static arm poses). Results are reported in the context of an interactive clean-up task, where a person guides the robot to specific locations that need to be cleaned and instructs the robot to pick up trash.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008918401478,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008914200569,Acquiring Mobile Robot Behaviors by Learning Trajectory Velocities,Autonomous Robots,10.1023/A:1008914200569,Springer,2000-09-01,"The development of robots that learn from experience is a relentless challenge confronting artificial intelligence today. This paper describes a robot learning method which enables a mobile robot to simultaneously acquire the ability to avoid objects, follow walls, seek goals and control its velocity as a result of interacting with the environment without human assistance. The robot acquires these behaviors by learning how fast it should move along predefined trajectories with respect to the current state of the input vector. This enables the robot to perform object avoidance, wall following and goal seeking behaviors by choosing to follow fast trajectories near: the forward direction, the closest object or the goal location respectively. Learning trajectory velocities can be done relatively quickly because the required knowledge can be obtained from the robot's interactions with the environment without incurring the credit assignment problem. We provide experimental results to verify our robot learning method by using a mobile robot to simultaneously acquire all three behaviors.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008914200569,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008158209668,A Neural Net Predictive Control for Telerobots with Time Delay,Journal of Intelligent and Robotic Systems,10.1023/A:1008158209668,Springer,2000-09-01,"This paper extends the Smith Predictor feedback control structure to unknown robotic systems in a rigorous fashion. A new recurrent neural net predictive control (RNNPC) strategy is proposed to deal with input and feedback time delays in telerobotic systems. The proposed control structure consists of a local linearized subsystem and a remote predictive controller. In the local linearized subsystem, a recurrent neural network (RNN) with on-line weight tuning algorithm is employed to approximate the dynamics of the time-delay-free nonlinear plant. The remote controller is a modified Smith predictor for the local linearized subsystem which provides prediction and maintains the desirable tracking performance. Stability analysis is given in the sense of Lyapunov. The result is an adaptive compensation scheme for unknown telerobotic systems with time delays, uncertainties, and external disturbances. A simulation of a two-link robotic manipulator is provided to illustrate the effectiveness of the proposed control strategy.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008158209668,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008154109686,A Neural Network Approach to the Frictionless Grasping Problem,Journal of Intelligent and Robotic Systems,10.1023/A:1008154109686,Springer,2000-09-01,"This article presents a heuristic technique used for solving linear complementarity problems(LCP). Determination of minimum forces needed to firmly grasp an object by a multifingered robot gripper for different external force and finger positions is our proposed application. The contact type is assumed to be frictionless. The interaction in the gripper–object system is formulated as an LCP. A numerical algorithm (Lemke) is used to solve the problem [3]. Lemke is a direct deterministic method that finds exact solutions under some constraints. Our proposed neural network technique finds almost exact solutions in solvable positions, and very good solutions for positions that Lemke fails to find solutions. A new adaptive technique is used for training the neural network and it is compared with the standard technique. Mathematical analysis for the convergence of the proposed technique is presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008154109686,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008920117364,Real-time Collision-free Path Planning of Robot Manipulators using Neural Network Approaches,Autonomous Robots,10.1023/A:1008920117364,Springer,2000-08-01,"In this paper, a novel neural network approach to real-time collision-free path planning of robot manipulators in a nonstationary environment is proposed, which is based on a biologically inspired neural network model for dynamic trajectory generation of a point mobile robot. The state space of the proposed neural network is the joint space of the robot manipulators, where the dynamics of each neuron is characterized by a shunting equation or an additive equation. The real-time robot path is planned through the varying neural activity landscape that represents the dynamic environment. The proposed model for robot path planning with safety consideration is capable of planning a real-time “comfortable” path without suffering from the “too close” nor “too far” problems. The model algorithm is computationally efficient. The computational complexity is linearly dependent on the neural network size. The effectiveness and efficiency are demonstrated through simulation studies.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008920117364,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF03037589,Interactive learning and management of visual information via human-like software robot,New Generation Computing,10.1007/BF03037589,Springer,2000-06-01,"To achieve smooth real-world interaction between people and computers, we developed a system that displays a three-dimensional computer-graphic human-like image from the waist up (anthropomorphic software robot: hereinafter “robot”) on the display, that interactively sees and hears, and that has fine and detailed control functions such as facial expressions, line of sight, and pointing at targets with its finger. The robot visually searches and identifies persons and objects in real space that it has learned in advance (registered space, which was our office in this case), manages the history information of the places and times it found objects and/or persons, and tells the user, indicating their three-dimensional positions with line of sight and its finger. It interactively learns new objects and persons with line of with their names and owners. By using this function, the robot can engage in simple dialogue (do a task) with the user.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF03037589,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008942012299,Multiagent Systems: A Survey from a Machine Learning Perspective,Autonomous Robots,10.1023/A:1008942012299,Springer,2000-06-01,"Distributed Artificial Intelligence (DAI) has existed as a subfield of AI for less than two decades. DAI is concerned with systems that consist of multiple independent entities that interact in a domain. Traditionally, DAI has been divided into two sub-disciplines: Distributed Problem Solving (DPS) focuses on the information management aspects of systems with several components working together towards a common goal; Multiagent Systems (MAS) deals with behavior management in collections of several independent entities, or agents. This survey of MAS is intended to serve as an introduction to the field and as an organizational framework. A series of general multiagent scenarios are presented. For each scenario, the issues that arise are described along with a sampling of the techniques that exist to deal with them. The presented techniques are not exhaustive, but they highlight how multiagent systems can be and have been used to build complex systems. When options exist, the techniques presented are biased towards machine learning approaches. Additional opportunities for applying machine learning to MAS are highlighted and robotic soccer is presented as an appropriate test bed for MAS. This survey does not focus exclusively on robotic systems. However, we believe that much of the prior research in non-robotic MAS is relevant to robotic MAS, and we explicitly discuss several robotic MAS, including all of those presented in this issue.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008942012299,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008104122177,Obstacle Avoidance Using the Human Operator Experience for a Mobile Robot,Journal of Intelligent and Robotic Systems,10.1023/A:1008104122177,Springer,2000-04-01,"In this paper, a neuro-fuzzy technique has been used to steer a mobile robot. The neuro-fuzzy approach provides a good way to capture the information given by a human. In this manner, it has been possible to obtain the rules and membership functions automatically whereas a fuzzy approach needs to make a prior definition of the rules and membership functions. In order to apply the neuro-fuzzy strategy, two mobile robots have been developed. However, in this paper only the smallest one has been considered. Similar results are obtained for the biggest one. The results of the approach are satisfactory, avoiding the obstacles when the mobile robot is steered to the target.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008104122177,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF02839001,Robotics,Resonance,10.1007/BF02839001,Springer,2000-03-01,"In this part of the article, the robot that was introduced in Part is expanded, by imparting to it some intelligence — explaining how the robot functioning is controlled. A brief description of the measurements involved is also discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF02839001,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1017248626916,Editorial: Advanced Robot Control Techniques and Applications,Journal of Intelligent and Robotic Systems,10.1023/A:1017248626916,Springer,2000-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1017248626916,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45327-X_50,Essex Wizards’99 Team Description,RoboCup-99: Robot Soccer World Cup III,10.1007/3-540-45327-X_50,Springer,2000-01-01,"This paper describes the Essex Wizards team participated in the RoboCup’99 simulator league. It is mainly concentrated on a multi-threaded implementation of simulated soccer agents to achieve real-time performance. Simulated robot agents work at three distinct phases: sensing, thinking and acting. POSIX threads are adopted to implement them concurrently. The issues of decision-making and co-operation are also addressed",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-45327-X_50,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45327-X_97,The Team Description of Osaka University “Trackies-99”,RoboCup-99: Robot Soccer World Cup III,10.1007/3-540-45327-X_97,Springer,2000-01-01,"This is the team description of Osaka University “Trackies” for RoboCup-99. We have worked two issues for our new team. First, we have changed our robot system from a remote controlled vehicle to a self-contained robot. The other, we have proposed a new learning method based on a Q-learning method so that a real robot can aquire a bhevior by reinforcement learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-45327-X_97,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-4-431-67919-6_38,Ultrafast Neural Network Training for Robot Learning from Uncertain Data,Distributed Autonomous Robotic Systems 4,10.1007/978-4-431-67919-6_38,Springer,2000-01-01,"A capability for learning from uncertain data has been a major and perennial requirement for many real-life robotic applications. In that context, a new methodology for ultrafast learning using neural networks is presented. It requires only a single iteration to train a feed-forward network with near-optimal results. Uncertainty reduction algorithms are also incorporated in a natural and optimal fashion. As such, this methodology is intended to become an essential building block for future architectures of intelligent systems. Its application to multi-robot observation of multiple moving targets is illustrated.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-4-431-67919-6_38,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-0765-1_27,To Learn or To Be Taught? Design Issues Towards Cognitive Robotics,Robotics Research,10.1007/978-1-4471-0765-1_27,Springer,2000-01-01,"This paper discusses the teaching methods as one of the external learning structure for the cognitive robotics with three different topics. The first one deals with a trade-off between self-learning and teaching by coping with cross perceptual aliasing problem caused by the state space difference between the learner and the teacher. The second one argues about the teaching by showing an exact motion methods from a viewpoint of the internal observer with less a priori knowledge from the external observer’s viewpoint such as global positioning or kinematic parameters of its own body. The third one argues about the internal structure to cope with less instructions, that is, teaching by showing only the visual target Finally, we summarize these issues from a viewpoint of the internal observer toward cognitive robotics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-0765-1_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008945119734,Robot Awareness in Cooperative Mobile Robot Learning,Autonomous Robots,10.1023/A:1008945119734,Springer,2000-01-01,"Most of the straight-forward learning approaches in cooperative robotics imply for each learning robot a state space growth exponential in the number of team members. To remedy the exponentially large state space, we propose to investigate a less demanding cooperation mechanism—i.e., various levels of awareness—instead of communication. We define awareness as the perception of other robots locations and actions. We recognize four different levels (or degrees) of awareness which imply different amounts of additional information and therefore have different impacts on the search space size (Θ(0), Θ(1), Θ(N), o(N),^1 where N is the number of robots in the team). There are trivial arguments in favor of avoiding binding the increase of the search space size to the number of team members. We advocate that, by studying the maximum number of neighbor robots in the application context, it is possible to tune the parameters associated with a Θ(1) increase of the search space size and allow good learning performance. We use the cooperative multi-robot observation of multiple moving targets (CMOMMT) application to illustrate our method. We verify that awareness allows cooperation, that cooperation shows better performance than a purely collective behavior and that learned cooperation shows better results than learned collective behavior.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008945119734,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-7908-1844-4_45,Mobile Robot Control Using BP Based Adaptive Critics,The State of the Art in Computational Intelligence,10.1007/978-3-7908-1844-4_45,Springer,2000-01-01,"The paper presents results of experimental analysis of backpropagation and adaptive critic based control architecture. A number of experiments were performed with the application of a given method for mobile robot navigation. The number of variations of actor and critic neural networks were tested, and results show the ability of algorithm to deal with as many as six layers of units in networks. Observed ability of algorithm to deal with very big learning rates and simple experimental method for stabilization of algorithm are also discussed in the paper.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7908-1844-4_45,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45255-9_40,Parallelization of Neural Networks Using PVM,Recent Advances in Parallel Virtual Machine and Message Passing Interface,10.1007/3-540-45255-9_40,Springer,2000-01-01,"We use Neural Networks (NN) in order to design control architectures for autonomous mobile robots. With PVM, it is possible to spawn different parts of a NN on different workstations. Specific message passing functions using PVM are included into the NN architecture. A graphical interface helps the user spawning the NN architecture and monitors the messages exchanged between the different subparts of the NN. The message passing mechanism is efficient for real time applications. We show an example of image processing used for robot control.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-45255-9_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45327-X_44,Multiple Reward Criterion for Cooperative Behavior Acquisition in a Multiagent Environment,RoboCup-99: Robot Soccer World Cup III,10.1007/3-540-45327-X_44,Springer,2000-01-01,"An extended value function is discussed in the context of multiple behavior coordination, especially in a dynamically changing multiagent environment. Unlike the traditional weighted sum of several reward functions, we define a vectorized value function which evaluates the current action strategy by introducing a discounted matrix to integrate several reward functions. Owing to the extension of the value function, the learning robot can estimate the future multiple rewards from the environment appropriately not suffering from the weighting problem. The proposed method is applied to a simplified soccer game. Computer simulations are shown and a discussion is given.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-45327-X_44,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45327-X_12,Path Tracking Control of Non-holonomic Car-Like Robot with Reinforcement Learning,RoboCup-99: Robot Soccer World Cup III,10.1007/3-540-45327-X_12,Springer,2000-01-01,"This paper investigates the use of reinforcement learning in solving the path-tracking problem for car-like robots. The reinforcement learner uses a case-based function approximator, to extend the standard reinforcement learning paradigm to handle continuous states. The learned controller performs comparable to the best traditional control functions in both simulation and also in practical driving.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-45327-X_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-40044-3_2,Learning a Navigation Task in Changing Environments by Multi-task Reinforcement Learning,Advances in Robot Learning,10.1007/3-540-40044-3_2,Springer,2000-01-01,"This work is concerned with practical issues surrounding the application of reinforcement learning to a mobile robot. The robot’s task is to navigate in a controlled environment and to collect objects using its gripper. Our aim is to build a control system that enables the robot to learn incrementally and to adapt to changes in the environment. The former is known as multi-task learning, the latter is usually referred to as continual ‘lifelong’ learning. First, we emphasize the connection between adaptive state-space quantisation and continual learning. Second, we describe a novel method for multi-task learning in reinforcement environments. This method is based on constructive neural networks and uses instance-based learning and dynamic programming to compute a task-dependent agent-internal state space. Third, we describe how the learning system is integrated with the control architecture of the robot. Finally, we investigate the capabilities of the learning algorithm with respect to the transfer of information between related reinforcement learning tasks, like navigation tasks in different environments. It is hoped that this method will lead to a speed-up in reinforcement learning and enable an autonomous robot to adapt its behaviour as the environment changes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-40044-3_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4471-3392-6_4,Robot Learning: Making Sense of Raw Sensor Data,Mobile Robotics: A Practical Introduction,10.1007/978-1-4471-3392-6_4,Springer,2000-01-01,"This chapter introduces fundamental concepts of robot learning and machine learning, discusses commonly used mechanisms such as reinforcement learning and connectionist approaches, and presents three case studies of mobile robots that can learn.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-3392-6_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-0765-1_28,Learning Robot Behaviour and Skills Based on Human Demonstration and Advice: The Machine Learning Paradigm,Robotics Research,10.1007/978-1-4471-0765-1_28,Springer,2000-01-01,"Service robots require easy programming methods allowing the unexperienced human user to easily integrate motion and perception skills or complex problem solving strategies. To achieve this goal, robots should learn from operators how and what to do considering hard- and software constraints. Various approaches modelling the man-machine skill transfer have been proposed. Systems following the Programming by Demonstration (PbD) paradigm that were developed within the last decade are getting closer to this goal. However, most of these systems lack the possibility for the user to supervise and influence the process of program generation after the initial demonstration was performed. In this paper a principle learning methodology is discussed, which allows to transfer human skills and to supervise the learning process including subsymbolic and symbolic task knowledge. Here, several existing approaches will be discussed and compared to each other. Moreover, a system approach is presented, integrating the overall process of skill transfer from a human to a robotic manipulation system. One major goal is to modify information gained by the demonstration in that way that different target systems are supported. The resulting PbD-system yields towards a hybrid learning approach in robotics to support natural programming based on human demonstrations and user advice.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-0765-1_28,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-7908-1844-4_46,Computational Intelligence Controllers for Lego Robots — Comparison Study,The State of the Art in Computational Intelligence,10.1007/978-3-7908-1844-4_46,Springer,2000-01-01,The paper deals with a comparsion of selected controllers for an intelligent parking procedure. Conventional fuzzy controller and BP neural networks were tested for Lego-mindstorm robot control. The results show that BP controller seem to be a very satisfactory approach if the control task is starting from the area of trained paths. Also BP control is smoother and fuzzy control depends on the enhancement of membership functions within the fuzzy controller. The project was done on the Lego-mindststorm conventional kit and the development of control strategies was done in C language and downloaded to RCX brick.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7908-1844-4_46,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-0509-1_16,Building Maps of Workspace for Autonomous Mobile Robots Using Self-Organizing Neural Networks,Soft Computing in Industrial Applications,10.1007/978-1-4471-0509-1_16,Springer,2000-01-01,"This paper presents a new method of building maps of workspace for autonomous mobile robots using self-organizing neural networks. By this method, the topological maps of the workspace can be self-organized from the relative distance data between a robot and walls on the workspace only using ultrasonic distance sensors. However, when the shape of the workspace is complicated, an unsuitable map with dead nodes or dead links may be generated. In this paper, we consider the cause of the problem, and we propose a new building maps algorithm which consists of two learning stages.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-0509-1_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-010-0870-9_58,Self-Supervised and Supervised Acquisition of Smooth Sensory-Motor Competences in Mobile Robots,"Prerational Intelligence: Adaptive Behavior and Intelligent Systems Without Symbols and Logic, Volume 1, Volume 2 Prerational Intelligence: Interdisciplinary Perspectives on the Behavior of Natural and Artificial Systems, Volume 3",10.1007/978-94-010-0870-9_58,Springer,2000-01-01,"This article presents results of experiments in autonomous competence acquisition in mobile robots, in which associations between incoming sensor signals and corresponding motor responses are stored in an artificial neural network. The learning process is either autonomous (i.e., self-supervised), or supervised by a human operator and, due to the type of network used, fast.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-010-0870-9_58,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4471-0785-9_2,Identification of Dynamical Systems Using Recurrent High-Order Neural Networks,Adaptive Control with Recurrent High-order Neural Networks,10.1007/978-1-4471-0785-9_2,Springer,2000-01-01,"The use of multilayer neural networks for pattern recognition and for modeling of “static” systems is currently well-known (see, for example, [1]). Given pairs of input-output data (which may be related by an unknown algebraic relation, a so-called “static” function) the network is trained to learn the particular input-output map. Theoretical work by several researchers, including Cybenko [16], and Funahashi [24], have proven that, even with one hidden layer, neural networks can approximate any continuous function uniformly over a compact domain, provided the network has a sufficient number of units, or neurons. Recently, interest has been increasing towards the usage of neural networks for modeling and identification of dynamical systems. These networks, which naturally involve dynamic elements in the form of feedback connections, are known as recurrent neural networks .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-0785-9_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-4285-8_9,Do it with rhythm,Studies on the Structure of Time,10.1007/978-1-4615-4285-8_9,Springer,2000-01-01,"The theme of this workshop is time. In this paper we will examine the role of time, and the ability to measure time, in certain very simple forms of animal cognition and behavior.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-4285-8_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-40044-3_3,Toward Seamless Transfer from Simulated to Real Worlds: A Dynamically—Rearranging Neural Network Approach,Advances in Robot Learning,10.1007/3-540-40044-3_3,Springer,2000-01-01,"In the field of evolutionary robotics artificial neural networks are often used to construct controllers for autonomous agents, because they have useful properties such as the ability to generalize or to be noise-tolerant. Since the process to evolve such controllers in the real-world is very time-consuming, one usually uses simulators to speed up the evolutionary process. By doing so a new problem arises: The controllers evolved in the simulator show not the same fitness as those in the real-world. A gap between the simulated and real environments exists. In order to alleviate this problem we introduce the concept of neuromodulators, which allows to evolve neural networks which can adjust not only the synaptic weights, but also the structure of the neural network by blocking and/or activating synapses or neurons. We apply this concept to a peg-pushing problem for K hepera ™ and compare our method to a conventional one, which evolves directly the synaptic weights. Simulation and real experimental results show that the proposed approach is highly promising.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-40044-3_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45327-X_10,A Segmentation System for Soccer Robot Based on Neural Networks,RoboCup-99: Robot Soccer World Cup III,10.1007/3-540-45327-X_10,Springer,2000-01-01,An innovative technique for segmentation of color images is proposed. The technique implements an approach based on thresholding of the hue histogram and a feed-forward neural network that learns to recognize the hue ranges of meaningful objects. A new function for detecting valleys of the histogram has been devised and tested. A novel blurring algorithm for noise reduction that works effectively when used over hue image has been employed. The reported experimental results show that the technique is reliable and robust even in presence of changing environmental conditions. Extended experimentation has been carried on the framework of the Robot Soccer World Cup Initiative (RoboCup).,http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-45327-X_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-7908-1856-7_4,A Simulation Environment for the Manipulation of Naturally Variable Objects,Future Directions for Intelligent Systems and Information Sciences,10.1007/978-3-7908-1856-7_4,Springer,2000-01-01,"One area where the use of robots has been impractical up to the present time, is where the objects they handle are of an irregular shape. Robots are now very effective in manufacturing industries where their precision operations can be preprogrammed to produce machined parts of known dimensions to required tolerances. However, it is difficult to use robot arms to manipulate objects that are irregular and unpredictable. For example, in the food processing industry it is necessary to carry out operations such as shelling seafood, or filleting fish. The major problems are caused by inconsistencies in size, shape and texture. This work describes the possibility of using adaptive robot controllers to learn the correct operations by trial and error. The adaptive element is provided by a modified CM AC neural network, which implements a kind of reinforcement learning to gradually improve the robots actions. Rather than build a physical robot to carry out such a task, it was felt that a cheaper and more effective approach would be to create a realistic computer simulation environment in which to test out these ideas. This avoids spending a large amount of effort trying to maintain a real robot, which may eventually turn out to be inadequate to successfully execute the tasks required of it. By building an effective model, we may learn about the desired characteristics of such a robot and at the same time have a re-useable system with which we may tackle similar problems. We describe the system basics and our current progress towards these goals.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7908-1856-7_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-0519-0_29,An Evolutionary Neural Network Controller for Intelligent Active Force Control,Evolutionary Design and Manufacture,10.1007/978-1-4471-0519-0_29,Springer,2000-01-01,"In this paper, we examine the capability of an Evolutionary Neural Network Controller (ENNC) in estimating the inertia matrix of the two-arm rigid robot. The accurate estimation of the inertia matrix is very important in the active force control loop to calculate the disturbance torques which need to be compensated in order to control a robot subjected to unknown external forces. The proposed algorithm is a modification of the EPNET algorithm proposed by Xin Yao, where we emphasise the use of crossover to explore different offsprings which do not posses strong behavioural links to their parents but still perform better than them. At the same time, the mutation operations described in EPNET, i.e. hybrid training, node deletion and node addition, are still used to maintain the behavioural link between the strong parents and their offsprings. Therefore, the introduction of the crossover will create a kind of ‘survival competition’ scenario between the different offsprings. In addition, this algorithm also includes the evolution of transfer (activation) functions, which play an important role in the design of the neural network. The best offspring, which represents the optimum number of nodes and types of transfer functions, is selected as the optimum neural network design for the specified problem. Then, the selected network is once again trained using back propagation with adaptive learning rate and momentum to ensure global error convergence. Finally, The fast evolutionary programming (FEP) method, which is based on the Gaussian distribution and directional mutation scheme, is incorporated to fine tune the network parameters at the end of the training session.The trained network is implemented for the active force control problem of the two-arm robot with unknown external forces. Simulation is programmed in MATLAB/SIMULINK using the Neural Network and Geatbx toolboxes. Results show significant improvement in the performance of the evolving neural network as compared to the non-evolving network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-0519-0_29,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-7908-1856-7_3,Evolving ANN Controllers for Smart Mobile Robots,Future Directions for Intelligent Systems and Information Sciences,10.1007/978-3-7908-1856-7_3,Springer,2000-01-01,Abstract In this work we present an overview of the application of evolution for obtaining autonomous robot controllers. It concentrates on controllers for behavior based robots implemented through Artificial Neural Networks. Specific approaches for taking into account temporal relationships are presented as well as a methodology for the progressive implementation of controllers comprising multiple behaviors. In addition we will consider the problem of transferring simulation results to real robots and the conditions that must be met for this process to be effective. Some examples of the application of these techniques to simple problems are included.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7908-1856-7_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF02481184,Cognitive robotics: a new approach to artificial intelligence,Artificial Life and Robotics,10.1007/BF02481184,Springer,1999-12-01,"This paper describes a research program about how to achieve artificial intelligence by building robots. It is part of the behavior-oriented AI approach, but differs in some of its hypotheses and methodological approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF02481184,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008195720685,Stable Neuro-Adaptive Control for Robots with the Upper Bound Estimation on the Neural Approximation Errors,Journal of Intelligent and Robotic Systems,10.1023/A:1008195720685,Springer,1999-09-01,"An indirect adaptive control approach is developed in this paper for robots with unknown nonlinear dynamics using neural networks (NNs). A key property of the proposed approach is that the actual joint angle values in the control law are replaced by the desired joint angles, angle velocities and accelerators, and the bound on the NN reconstruction errors is assumed to be unknown. Main theoretical results for designing such a neuro-controller are given, and the control performance of the proposed controller is verified with simulation studies.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008195720685,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008946111617,Artificial Neural Networks for Robot Learning—Guest Editors' Introduction,Autonomous Robots,10.1023/A:1008946111617,Springer,1999-07-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008946111617,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008984312527,Repeatability of Real World Training Experiments: A Case Study,Autonomous Robots,10.1023/A:1008984312527,Springer,1999-06-01,"We present a case study of reinforcement learning on a real robot that learns how to back up a trailer and discuss the lessons learned about the importance of proper experimental procedure and design. We identify areas of particular concern to the experimental robotics community at large. In particular, we address concerns pertinent to robotics simulation research, implementing learning algorithms on real robotic hardware, and the difficulties involved with transferring research between the two.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008984312527,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF02481253,Learning control of autonomous robots using an instance-based classifier generator in continuous state space,Artificial Life and Robotics,10.1007/BF02481253,Springer,1999-06-01,"A classifier system for the reinforcement learning control of autonomous mobile robots is proposed. The classifier system contains action selection, rules reproduction, and credit assignment mechanisms. An important feature of the classifier system is that it operates with continuous sensor and action spaces. The system is applied to the control of mobile robots. The local controllers use independent classifiers specified at the wheel-level. The controllers work autonomously, and with respect to each other represent dynamic systems connected through the external environment. The feasibility of the proposed system is tested in an experiment with a Khepera robot. It is shown that some patterns of global behavior can emerge from locally organized classifiers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF02481253,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1018631315677,A Multilayer Perceptrons Model for the Stability of a Bipedal Robot,Neural Processing Letters,10.1023/A:1018631315677,Springer,1999-06-01,"A neural network model is proposed as a means of controlling the dynamical equilibrium of a walking bipedal robot. As a criterion to determine the stability of such a robot in relation with the organization of the sensorimotor system, we have been making use of the ZMP (Zero Momentum Point). Simulations are used to check the convergence of the algorithm. In the generalization phase, it is shown that the neural network has the ability to stabilise the robot for motions which have not previously been learned. An extended model is proposed, which seeks to closely inspect the physiology of the cerebellar cortex.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1018631315677,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s005210050017,Nonlinear Black Box Modelling – Fuzzy Networks versus Neural Networks,Neural Computing & Applications,10.1007/s005210050017,Springer,1999-05-01,"Fuzzy networks and neural networks offer two different approaches of nonlinear black box modelling. Efficient identification methods have been developed to calculate the parameters for a given structure and have been applied successfully in many examples. But the applications proposed in the literature usually miss the comparison of the alternative method, so that the selection of the more suitable approach for a given task is difficult. This paper aims to ease the decision for one of the two methodologies by considering one well-known high quality approximator of each network type, and presenting a fair comparison. For this purpose, two mathematical and three complex technical examples of nonlinear systems are considered. Generally, fuzzy networks and neural networks face the problem of overtraining causing poor validation/generalisation results. A modification of the established identification methods is proposed as a significant improvement for both approaches.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s005210050017,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s005210050014,Neural Networks for Mobile Robot Localisation using Infra-Red Range Sensing,Neural Computing & Applications,10.1007/s005210050014,Springer,1999-05-01,"For a robot to be fully autonomous whilst mobile, it is necessary for it to be able to determine its position in its environment. Most of the work on this problem has concentrated on using geometrical techniques which are typically implemented as part of a Kalman filter cycle. This paper examines the possibility of using a neural network to assist in the task of estimating the position of the robot. This is beneficial because it does not require beacons to be placed in the environment or the use of an explicit map of the environment. It does not require knowledge of the previous estimate of the robot’s position. In this paper, Radial Basis Function networks and Multi-Layer Perceptrons are trained to estimate the functional relationship between preprocessed range sensor data and the position of the robot. This approach is assessed using both simulated and real range data.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s005210050014,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008093719860,Neural Network Force Control for Industrial Robots,Journal of Intelligent and Robotic Systems,10.1023/A:1008093719860,Springer,1999-03-01,"In this paper, we present a hierarchical force control framework consisting of a high level control system based on neural network and the existing motion control system of a manipulator in the low level. Inputs of the neural network are the contact force error and estimated stiffness of the contacted environment. The output of the neural network is the position command for the position controller of industrial robots. A MITSUBISHI MELFA RV-M1 industrial robot equipped with a BL Force/Torque sensor is utilized for implementing the hierarchical neural network force control system. Successful experiments for various contact motions are carried out. Additionally, the proposed neural network force controller together with the master/slave control method are used in dual-industrial robot systems. Successful experiments are carried out for the dual-robot system handling an object.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008093719860,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008012519312,Multi-Layer Hierarchical Rule Learning in Reactive Robot Control Using Incremental Decision Trees,Journal of Intelligent and Robotic Systems,10.1023/A:1008012519312,Springer,1999-02-01,"This paper presents a new approach to the intelligent navigation of a mobile robot. The hybrid control architecture described combines properties of purely reactive and behaviour-based systems, providing the ability both to learn automatically behaviours from inception, and to capture these in a distributed hierarchy of decision tree networks. The robot is first trained in the simplest world which has no obstacles, and is then trained in successively more complex worlds, using the knowledge acquired in the previous worlds. Each world representing the perceptual space is thus directly mapped on a unique rule layer which represents in turn the robot action space encoded in a distinct decision tree. A major advantage of the current implementation, compared with the previous work, is that the generated rules are easily understood by human users. The paper demonstrates that the proposed behavioural decomposition approach provides efficient management of complex knowledge, and that the learning mechanism is able to cope with noise and uncertainty in sensory data.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008012519312,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/BFb0110566,Development of an application platform for mobile robots,Progress in system and robot analysis and control design,10.1007/BFb0110566,Springer,1999-01-01,"The experimental platform specified in this paper provides a promising basis for training and experimenting within the development of an intelligent and autonomous mobile robot with high manoeuvre and manipulate features. The main goal of this Platform should be the formulation of a requirement specifications for a autonomous mobile robot in a clinical environment. It comprises powerful systems such as a Robot Cell, a Simulation and Off-line Programming Station, a stereolithography system a Neural Networks Simulator, 2D and 3D Sensor Systems and telecommunication systems. During the undertaken research work, some systems have been identified as unsuited to perform the intended tasks, i.e. the 2D and 3D Sensor Systems. Other systems were integrated, such as the stereolithography system to quickly realise prototype parts for robots and the integration of the Fischertechnik mobile robot. Current Applications within the MobiNet Project will show the reliability of the current status of the Application Platform. The main focus for our research will be on the integration of the RP Module / Simulation module in the Application Platform. The second goal of the platform is to provide project partner with systems for their work or for training courses within the MobiNet project.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BFb0110566,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/BFb0098213,Structure adaptation in artificial neural networks through adaptive clustering and through growth in state space,Foundations and Tools for Neural Modeling,10.1007/BFb0098213,Springer,1999-01-01,"There is a growing evidence that the human brain follows an environmentally-guided neural circuit building that increases its learning flexibility. Similarly, it has been shown that artificial neural networks with dynamic topologies attempt to overcome the problem of determining the appropriate topology to optimally solve a given application. This paper presents a modular structure-adaptable artificial neural network architecture for autonomous control systems consisting of an unsupervised learning network, a reinforcement learning module and a planning module. Finally, we present an extension of the state representation of the environment by introducing short-term memories to deal with the problem of partial observability in the real-world.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BFb0098213,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-46695-9_36,On Understanding Global Behavior of Teams in Robot Soccer Simulators,Advanced Topics in Artificial Intelligence,10.1007/3-540-46695-9_36,Springer,1999-01-01,An approach is investigated to identify an invariant in the team’s behavior in order to characterize the global behavior of a robot soccer team. The existence of such an invariant confirmed by computational evidence is reported in this paper. The invariant is being studied with the view of using it as a possible means for developing intelligent strategies in robot soccer. ...,http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-46695-9_36,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-5239-0_6,Learning Sensor-Based Navigation,Making Robots Smarter,10.1007/978-1-4615-5239-0_6,Springer,1999-01-01,"A mobile robot that uses reinforcement learning to acquire reactive navigation skills is presented. The basic skills needed for reaching a goal while avoiding obstacles are encoded as sensation-action associations in a modular Neural Net. The robot has no a priori knowledge of either the environment or the effect of its actions, and learns on-line using only raw sensory data collected as it moves. The experimental results show that a few trials suffice for the robot to navigate efficiently in a real environment of moderate complexity.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-5239-0_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/BFb0098211,Training higher order Gaussian synapses,Foundations and Tools for Neural Modeling,10.1007/BFb0098211,Springer,1999-01-01,"In this article we present an algorithm that permits training networks that include gaussian type higher order synapses. This algorithm is an extension of the classical backpropagation algorithm. Higher order synapses permit carrying out tasks using simpler networks than traditionally employed. The key to this simplicity is in the structure of the synapses: a gaussian with three trainable parameters. The fact that it is a function and consequently presents a variable output depending on its inputs and that it possesses more than one trainable parameter that allows it to implement non linear processing functions on its inputs, endows the networks with a large capacity for learning and generalization. We present two examples where these capacities are shown. The first one is a target tracking module for a the visual system of a real robot and the second one is an image classification system working on real images.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BFb0098211,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/BFb0100519,Applying evolution strategies to neural networks robot controller,Engineering Applications of Bio-Inspired Artificial Neural Networks,10.1007/BFb0100519,Springer,1999-01-01,"In this paper an evolution strategy (ES) is introduced, to learn weights of a neural network controller in autonomous robots. An ES is used to learn high-performance reactive behavior for navigation and collisions avoidance. The learned behavior is able to solve the problem in different environments; so, the learning process has proven the ability to obtain a specialized behavior. All the behaviors obtained have been tested in a set of environment and the capability of generalization is showed for each learned behavior. No subjective information about “how to accomplish the task” has been included in the fitness function. A simulator based on mini-robot Khepera has been used to learn each behavior.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BFb0100519,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-0811-5_27,A Hybrid Framework for Indoor Robot Navigation,Neural Nets WIRN VIETRI-98,10.1007/978-1-4471-0811-5_27,Springer,1999-01-01,"This paper introduces a hybrid system for modeling, learning and recognition of sequences of “states” in indoor robot navigation. States are broadly defined as local relevant situations (in the real world) in which the robot happens to be during the navigation. The hybrid is based on parallel Recurrent Neural Networks trained to perform a-posteriori state probability estimates of an underlying Hidden Markov Model given a sequence of sensory (e.g. sonar) observations. The approach is suitable for navigation and for map learning. Encouraging experiments of recognition of noisy sequences acquired by a mobile robot equipped with 16 sonars are presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-0811-5_27,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008058131402,Learning Complex Tasks Using a Stepwise Approach,Journal of Intelligent and Robotic Systems,10.1023/A:1008058131402,Springer,1999-01-01,"This paper explores a stepwise learning approach based on a system's decomposition into functional subsystems. Two case studies are examined: a visually guided robot that learns to track a maneuvering object, and a robot that learns to use the information from a force sensor in order to put a peg into a hole. These two applications show the features and advantages of the proposed approach: i) the subsystems naturally arise as functional components of the hardware and software; ii) these subsystems are building blocks of the robot behavior and can be combined in several ways for performing various tasks; iii) this decomposition makes it easier to check the performances and detect the cause of a malfunction; iv) only those subsystems for which a satisfactory solution is not available need to be learned; v) the strategy proposed for coordinating the optimization of all subsystems ensures an improvement at the task-level; vi) the overall system's behavior is significantly improved by the stepwise learning approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008058131402,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1006567623867,Connectionist Learning in Behaviour-Based Mobile Robots: A Survey,Artificial Intelligence Review,10.1023/A:1006567623867,Springer,1998-12-01,This paper is a survey of some recentconnectionist approaches to the design and developmentof behaviour-based mobile robots. The research isanalysed in terms of principal connectionist learningmethods and neurological modeling trends. Possibleadvantages over conventionally programmed methods areconsidered and the connectionist achievements to dateare assessed. A realistic view is taken of theprospects for medium term progress and someobservations are made concerning the direction thismight profitably take.,http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1006567623867,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF02471176,HOJO-brain for motion control of robots and biological systems,Artificial Life and Robotics,10.1007/BF02471176,Springer,1998-12-01,"The purpose of this research was to propose and develop a control method in the robotic and biomedical fields which is configured by a robotic/biological simulator, an analytical control frame which has phase sequences, sensory feedback, and an artificial central pattern generator (CPG) which is constructed by a recurrent neural network (RNN) and a genetic algorithm (GA). We call such a controller a “HOJO-brain”, which means a supplementary brain for motion control. We applied this method in the robotic and biomedical fields. In the robotic field, the HOJO-brain was applied to a 5-DOF legged-locomotion robot and a 32-DOF humanoid simulation model consisting of antagonistic muscles. In the biomedical field, it was applied to animals as the FES (functional electrical stimulation) controller. This FES control system with a HOJO-brain has the potential to give more effective and emergent motion control to severely physically handicapped people such as quadraplegics. With computer simulations and simple experiments using animals, we abtained performance indices which confirmed the fine adaptability and emergence for motion control.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF02471176,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008083631190,Reinforcement Learning and Robust Control for Robot Compliance Tasks,Journal of Intelligent and Robotic Systems,10.1023/A:1008083631190,Springer,1998-10-01,"The complexity in planning and control of robot compliance tasks mainly results from simultaneous control of both position and force and inevitable contact with environments. It is quite difficult to achieve accurate modeling of the interaction between the robot and the environment during contact. In addition, the interaction with the environment varies even for compliance tasks of the same kind. To deal with these phenomena, in this paper, we propose a reinforcement learning and robust control scheme for robot compliance tasks. A reinforcement learning mechanism is used to tackle variations among compliance tasks of the same kind. A robust compliance controller that guarantees system stability in the presence of modeling uncertainties and external disturbances is used to execute control commands sent from the reinforcement learning mechanism. Simulations based on deburring compliance tasks demonstrate the effectiveness of the proposed scheme.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008083631190,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008022430399,Velocity Estimation for Robot Manipulators Using Neural Network,Journal of Intelligent and Robotic Systems,10.1023/A:1008022430399,Springer,1998-10-01,"In robot manipulators, optical incremental encoders are widely used as the transducers to monitor joint position and velocity information. With incremental encoder, positional information is determined as discrete data relative to a reference (home) position. However, velocity information can only be deduced by processing the position data. In this paper, a method of using a neural network to estimate the velocity information of robotic joint from discrete position versus time data is proposed and evaluated. The architecture of the neural net and the training methodology are presented and discussed. This approach is then applied to estimate the joint velocity of a SCARA robot while performing an electronic component assembly task. Based on computer simulations, comparison of the accuracy of the neural network estimator with two other well established velocity estimation algorithms are made. The neural net approach can maintain good performance even in the presence of measurement noises.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008022430399,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008077807191,Neural and Neurofuzzy FELA Adaptive Robot Control Using Feedforward and Counterpropagation Networks,Journal of Intelligent and Robotic Systems,10.1023/A:1008077807191,Springer,1998-10-01,"In this paper, the application of neural networks and neurofuzzy systems to the control of robotic manipulators is examined. Two main control structures are presented in a comparative manner. The first is a Counter Propagation Network-based Fuzzy Controller (CPN-FC) which is able to self-organize and correct on-line its rule base. The self-tuning capability of the fuzzy logic controller is attained by taking advantage of the structural equivalence between the fuzzy logic controller and a counterpropagation network. The second control structure is a more familiar neural adaptive controller based on a feedforward (MLP) network. The neural controller learns the inverse dynamics of the robot joints, and gradually eliminates the model uncertainties and disturbances. Both schemes cooperate with the computed torque control algorithm, and in that way the reduction of their complexity is achieved. The ability of adaptive fuzzy systems to compete with neural networks in difficult control problems is demonstrated. A sufficient set of numerical results is included.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008077807191,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1007554531242,Bayesian Landmark Learning for Mobile Robot Localization,Machine Learning,10.1023/A:1007554531242,Springer,1998-10-01,"To operate successfully in indoor environments, mobile robots must be able to localize themselves. Most current localization algorithms lack flexibility, autonomy, and often optimality, since they rely on a human to determine what aspects of the sensor data to use in localization (e.g., what landmarks to use). This paper describes a learning algorithm, called BaLL, that enables mobile robots to learn what features/landmarks are best suited for localization, and also to train artificial neural networks for extracting them from the sensor data. A rigorous Bayesian analysis of probabilistic localization is presented, which produces a rational argument for evaluating features, for selecting them optimally, and for training the networks that approximate the optimal solution. In a systematic experimental study, BaLL outperforms two other recent approaches to mobile robot localization.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1007554531242,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF02471168,Learning model for adaptive behaviors as an organized group of swarm robots,Artificial Life and Robotics,10.1007/BF02471168,Springer,1998-09-01,"This paper describes a novel organizational learning model for multiple adaptive robots. In this model, robots acquire their own appropriate functions through local interactions among their neighbors, and get out of deadlock situations without explicit control mechanisms or communication methods. Robots also complete given tasks by forming an organizational structure, and improve their organizational performance. We focus on the emergent processes of collective behaviors in multiple robots, and discuss how to control these behaviors with only local evaluation functions, rather than with a centralized control system. Intensive simulations of truss construction by multiple robots gave the following experimental results: (1) robots in our model acquire their own appropriate functions and get out of deadlock situations without explicit control mechanisms or communication methods; (2) robots form an organizational structure which completes given tasks in fewer steps than are needed with a centralized control mechanism.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF02471168,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008858222277,Module-Based Reinforcement Learning: Experiments with a Real Robot,Autonomous Robots,10.1023/A:1008858222277,Springer,1998-07-01,"The behavior of reinforcement learning (RL) algorithms is best understood in completely observable, discrete-time controlled Markov chains with finite state and action spaces. In contrast, robot-learning domains are inherently continuous both in time and space, and moreover are partially observable. Here we suggest a systematic approach to solve such problems in which the available qualitative and quantitative knowledge is used to reduce the complexity of learning task. The steps of the design process are to: (i) decompose the task into subtasks using the qualitative knowledge at hand; (ii) design local controllers to solve the subtasks using the available quantitative knowledge, and (iii) learn a coordination of these controllers by means of reinforcement learning. It is argued that the approach enables fast, semi-automatic, but still high quality robot-control as no fine-tuning of the local controllers is needed. The approach was verified on a non-trivial real-life robot task. Several RL algorithms were compared by ANOVA and it was found that the model-based approach worked significantly better than the model-free approach. The learnt switching strategy performed comparably to a handcrafted version. Moreover, the learnt strategy seemed to exploit certain properties of the environment which were not foreseen in advance, thus supporting the view that adaptive algorithms are advantageous to nonadaptive ones in complex environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008858222277,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008862423185,Learning from Innate Behaviors: A Quantitative Evaluation of Neural Network Controllers,Autonomous Robots,10.1023/A:1008862423185,Springer,1998-07-01,"The aim was to investigate a method of developing mobile robot controllers based on ideas about how plastic neural systems adapt to their environment by extracting regularities from the amalgamated behavior of inflexible (nonplastic) innate subsystems interacting with the world. Incremental bootstrapping of neural network controllers was examined. The objective was twofold. First, to develop and evaluate the use of prewired or innate robot controllers to bootstrap backpropagation learning for Multilayer Perceptron (MLP) controllers. Second, to develop and evaluate a new MLP controller trained on the back of another bootstrapped controller. The experimental hypothesis was that MLPs would improve on the performance of controllers used to train them. The performances of the innate and bootstrapped MLP controllers were compared in eight experiments on the tasks of avoiding obstacles and finding goals. Four quantitative measures were employed: the number of sensorimotor loops required to complete a task; the distance traveled; the mean distance from walls and obstacles; the smoothness of travel. The overall pattern of results from statistical analyses of these quantities supported the hypothesis; the MLP controllers completed the tasks faster, smoother, and steered further from obstacles and walls than their innate teachers. In particular, a single MLP controller incrementally bootstrapped by a MLP subsumption controller was superior to the others.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008862423185,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1007945702881,An Application Platform for the Development and Experimental Validation of Mobile Robots for Health Care Purposes,Journal of Intelligent and Robotic Systems,10.1023/A:1007945702881,Springer,1998-07-01,"This paper describes an Application Platform for the development and testing of mobile robot units. Within this platform, various applications addressing different aspects of robot development are composed into an experimental environment. The Application Platform comprises modules such as a Neural Networks Simulator, a simulation and off-line programming system, optical sensor components, a rapid prototyping system, and an experimental workcell. Each of these modules is described in detail including its integration with the other modules. In conclusion, the potential use of this platform for health care tasks is indicated.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1007945702881,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008870625003,Training a Vision Guided Mobile Robot,Autonomous Robots,10.1023/A:1008870625003,Springer,1998-07-01,"This paper presents the design, implementation and evaluation of a trainable vision guided mobile robot. The robot, CORGI, has a CCD camera as its only sensor which it is trained to use for a variety of tasks. The techniques used for training and the choice of natural light vision as the primary sensor makes the methodology immediately applicable to tasks such as trash collection or fruit picking. For example, the robot is readily trained to perform a ball finding task which involves avoiding obstacles and aligning with tennis balls. The robot is able to move at speeds up to 0.8 ms^-1 while performing this task, and has never had a collision in the trained environment. It can process video and update the actuators at 11 Hz using a single $20 microprocessor to perform all computation. Further results are shown to evaluate the system for generalization across unseen domains, fault tolerance and dynamic environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008870625003,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008006308260,A Neural Approach for the Control of Piezoelectric Micromanipulation Robots,Journal of Intelligent and Robotic Systems,10.1023/A:1008006308260,Springer,1998-07-01,"Micromanipulation has become an issue of primary importance in industry and biomedicine, since human manual capabilities are restricted to certain tolerances. The manipulation of biological cells or the assembly of a complete microsystem composed of different microcomponents are examples of the application of piezoelectric-driven microrobots. An automated microrobot-based micromanipulation desktop-station is developed by an interdisciplinary group at the University of Karlsruhe. The process of assembly takes place in the field of view of a light optical microscope. This paper focuses on motion control problems of the microrobots. The ability of an intelligent microsystem to adapt itself to the process requirements is of great importance, especially for assembly robots. The microrobots must be able to operate in a partially defined environment and to ensure reasonable behaviour in unpredicted situations. A neural control concept based on a reference model approach is proposed as a solution. It is shown, that the neural controller is able to learn the desired behaviour. It considerably outperforms an analytically designed linear controller. This is demonstrated both in simulation and in the real environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008006308260,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008850021368,Rapid Concept Learning for Mobile Robots,Autonomous Robots,10.1023/A:1008850021368,Springer,1998-07-01,"Concept learning in robotics is an extremely challenging problem: sensory data is often high dimensional, and noisy due to specularities and other irregularities. In this paper, we investigate two general strategies to speed up learning, based on spatial decomposition of the sensory representation, and simultaneous learning of multiple classes using a shared structure. We study two concept learning scenarios: a hallway navigation problem, where the robot has to induce features such as “opening” or “wall”. The second task is recycling, where the robot has to learn to recognize objects, such as a “trash can”. We use a common underlying function approximator in both studies in the form of a feedforward neural network, with several hundred input units and multiple output units. Despite the high degree of freedom afforded by such an approximator, we show the two strategies provide sufficient bias to achieve rapid learning. We provide detailed experimental studies on an actual mobile robot called PAVLOV to illustrate the effectiveness of this approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008850021368,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF03037313,Evolvable hardware: A robot navigation system testbed,New Generation Computing,10.1007/BF03037313,Springer,1998-06-01,"Recently there has been great interest in the design and study of evolvable systems based on Artificial Life principles in order to monitor and control the behavior of physically embedded systems such as mobile robots, plants and intelligent home devices. At the same time new integrated circuits called software-reconfigurable devices have been introduced which are able to adapt their hardware almost continuously to changes in the input data or processing. When the configuration phase and the execution phase are concurrent, the software-reconfigurable device is called evolvable hardware (EHW). This paper examines an evolutionary navigation system for a mobile robot using a Boolean function approach implemented on gate-level evolvable hardware (EHW). The task of the mobile robot is to reach a goal represented by a colored ball while avoiding obstacles during its motion. We show that the Boolean function approach using dedicated evolution rules is sufficient to build the desired behavior and its hardware implementation using EHW allows to decrease the learning time for on-line training. We demonstrate the effectiveness of the generalization ability of the Boolean function approach using EHW due to its representation and evolution mechanism. The results show that the evolvable hardware configuration learned off-line in a simple environment creates a robust robot behavior which is able to perform the desired behaviors in more complex environments and which is insensitive to the gap between the real and simulated world.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF03037313,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1007976516339,Path Planning for Robots by Stochastic Optimization Methods,Journal of Intelligent and Robotic Systems,10.1023/A:1007976516339,Springer,1998-06-01,"The problem of adaptive trajectory planning for robots under stochastic uncertainty is considered, where new information about the robots and their environment is presented on-line. Solving the problem numerically by means of spline approximation and by applying the method of neural networks, the optimal control can be calculated in real-time. Some numerical results are presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1007976516339,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008874222544,Fractal Fitness Landscape and Loss of Robustness in Evolutionary Robot Navigation,Autonomous Robots,10.1023/A:1008874222544,Springer,1998-05-01,"An autonomous robot “Khepera” was simulated with a sensory-motor model, which evolves in the genetic algorithm (GA) framework, with the fitness evaluation in terms of the navigation performance in a maze course. The sensory-motor model is a developed neural network decoded from a graph-represented chromosome, which is evolved in the GA process with several genetic operators. It was found that the fitness landscape is very rugged when it is observed at the starting point of the course. A hypothesis for this ruggedness is proposed, and is supported by the measurement of fractal dimension. It is also observed that the performance is sometimes plagued by “Loss of Robustness,” after the robot makes major evolutionary jumps. Here, the robustness is quantitatively defined as a ratio of the averaged fitness of the evolved robot navigating in perturbed environments over the fitness of the evolved robot in the referenced environment. Possible explanation of robustness loss is the over-adaptation occurred in the environment where the evolution was taken place. Testing some other possibilities for this loss of robustness, many simulation experiments were conducted which smooth out the discrete factors in the model and environment. It was found that smoothing the discrete factors does not solve the loss of robustness. An effective method for maintaining the robustness is the use of averaged fitness over different navigation conditions. The evolved models in the simulated environment were tested by down-loading the models into the real Khepera robot. It is demonstrated that the tendency of fitness values observed in the simulation were adequately regenerated.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008874222544,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008826306614,"Automation of an Industrial Fork Lift Truck, Guided by Artificial Vision in Open Environments",Autonomous Robots,10.1023/A:1008826306614,Springer,1998-05-01,"Mobile robots capable of moving autonomously in more or less structured environments are being increasingly employed in the automation of certain industrial processes. Along these lines, the authors constructed a platform, on the base of a commercial industrial truck, provided with sufficient autonomy to carry out tasks within an industrial environment (VIA: Autonomous Industrial Vehicle). One of the sensor systems used in the truck is a system of artificial vision which enables it to move on asphalted surfaces both in open environments (roads) and closed ones, seeking the markings which most easily allow it to determine the path marked in the images. The system for following roads is capable of following painted lines, determining the sides of the road by texture analysis or determining the minimum width of the road for the robot to pass, according to the circumstances. A model of the road predicts its situation and enables a decision to be made on whether the information provided by the algorithm is reliable or not. At the same time, a neural network is trained with the results obtained by any of the previous algorithms, in such a way that when the training process converges the network takes over the steering of the truck. The vision system, composed of a CCD colour camera and a “frame grabber” installed in a PCI slot of a Pentium 120 PC, provides a path every 100 ms, which allows the industrial truck to be steered at its maximum speed of 10 m/s.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008826306614,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1007440607681,Module-Based Reinforcement Learning: Experiments with a Real Robot,Machine Learning,10.1023/A:1007440607681,Springer,1998-04-01,"The behavior of reinforcement learning (RL) algorithms is best understood in completely observable, discrete-time controlled Markov chains with finite state and action spaces. In contrast, robot-learning domains are inherently continuous both in time and space, and moreover are partially observable. Here we suggest a systematic approach to solve such problems in which the available qualitative and quantitative knowledge is used to reduce the complexity of learning task. The steps of the design process are to: i) decompose the task into subtasks using the qualitative knowledge at hand; ii) design local controllers to solve the subtasks using the available quantitative knowledge and iii) learn a coordination of these controllers by means of reinforcement learning. It is argued that the approach enables fast, semi-automatic, but still high quality robot-control as no fine-tuning of the local controllers is needed. The approach was verified on a non-trivial real-life robot task. Several RL algorithms were compared by ANOVA and it was found that the model-based approach worked significantly better than the model-free approach. The learnt switching strategy performed comparably to a handcrafted version. Moreover, the learnt strategy seemed to exploit certain properties of the environment which were not foreseen in advance, thus supporting the view that adaptive algorithms are advantageous to non-adaptive ones in complex environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1007440607681,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1007444708590,Learning from Innate Behaviors: A Quantitative Evaluation of Neural Network Controllers,Machine Learning,10.1023/A:1007444708590,Springer,1998-04-01,"The aim was to investigate a method of developing mobile robot controllers based on ideas about how plastic neural systems adapt to their environment by extracting regularities from the amalgamated behavior of inflexible (non-plastic) innate s ubsystems interacting with the world. Incremental bootstrapping of neural network controllers was examined. The objective was twofold. First, to develop and evaluate the use of prewired or innate robot controllers to bootstrap backpropagation learning for Multi-Layer Perceptron (MLP) controllers. Second, to develop and evaluate a new MLP controller trained on the back of another bootstrapped controller. The experimental hypothesis was that MLPs would improve on the performance of controllers used to train them. The performances of the innate and bootstrapped MLP controllers were compared in eight experiments on the tasks of avoiding obstacles and finding goals. Four quantitative measures were employed: the number of sensorimotor loops required to complete a task; the distance traveled; the mean distance from walls and obstacles; the smoothness of travel. The overall pattern of results from statistical analyses of these quantities su pported the hypothesis; the MLP controllers completed the tasks faster, smoother, and steered further from obstacles and walls than their innate teachers. In particular, a single MLP controller incrementally bootstrapped by a MLP subsumption controller was superior to the others.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1007444708590,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1007405111315,Training a Vision Guided Mobile Robot,Machine Learning,10.1023/A:1007405111315,Springer,1998-04-01,"This paper presents the design, implementation and evaluation of a trainable vision guided mobile robot. The robot, CORGI, has a CCD camera as its only sensor which it is trained to use for a variety of tasks. The techniques used for train ing and the choice of natural light vision as the primary sensor makes the methodology immediately applicable to tasks such as trash collection or fruit picking. For example, the robot is readily trained to perform a ball finding task which involves avoiding obstacles and aligning with tennis balls. The robot is able to move at speeds up to 0.8 ms^-1 while performing this task, and has never had a collision in the trained environment. It can process video and update the actuators at 11 Hz using a single $20 microprocessor to perform all computation. Further results are shown to evaluate the system for generalization across unseen domains, fault tolerance and dynamic environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1007405111315,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1007432422702,Rapid Concept Learning for Mobile Robots,Machine Learning,10.1023/A:1007432422702,Springer,1998-04-01,"Concept learning in robotics is an extremely challenging problem: sensory data is often high-dimensional, and noisy due to specularities and other irregularities. In this paper, we investigate two general strategies to speed up learning, based on spatial decomposition of the sensory representation, and simultaneous learning of multiple classes using a shared structure. We study two concept learning scenarios: a hallway navigation problem, where the robot has to induce features such as “opening” or “wall”. The second task is recycling, where the robot has to learn to recognize objects, such as a “trash can”. We use a common underlying function approximator in both studies in the form of a feedforward neural network, with several hundred input units and multiple output units. Despite the high degree of freedom afforded by such an approximator, we show the two strategies provide sufficient bias to achieve rapid learning. We provide detailed experimental studies on an actual mobile robot called PAVLOV to illustrate the effectiveness of this approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1007432422702,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1007904418265,Robot Control Optimization Using Reinforcement Learning,Journal of Intelligent and Robotic Systems,10.1023/A:1007904418265,Springer,1998-03-01,"Conventional robot control schemes are basically model-based methods. However, exact modeling of robot dynamics poses considerable problems and faces various uncertainties in task execution. This paper proposes a reinforcement learning control approach for overcoming such drawbacks. An artificial neural network (ANN) serves as the learning structure, and an applied stochastic real-valued (SRV) unit as the learning method. Initially, force tracking control of a two-link robot arm is simulated to verify the control design. The simulation results confirm that even without information related to the robot dynamic model and environment states, operation rules for simultaneous controlling force and velocity are achievable by repetitive exploration. Hitherto, however, an acceptable performance has demanded many learning iterations and the learning speed proved too slow for practical applications. The approach herein, therefore, improves the tracking performance by combining a conventional controller with a reinforcement learning strategy. Experimental results demonstrate improved trajectory tracking performance of a two-link direct-drive robot manipulator using the proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1007904418265,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s003780050018,Neural network control for a fire-fighting robot,Software - Concepts & Tools,10.1007/s003780050018,Springer,1998-03-01,"The paper discusses the development of an associative, neural network as an on-line algorithm to train and control a fire-fighting robot. Learning is externally supervised with encoded target actions. The robot acquires basic navigation skills as well as the ability to detect a fire and to extinguish it.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s003780050018,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF01413713,An offset error compensation method for improving ANN accuracy when used for position control of precision machinery,Neural Computing & Applications,10.1007/BF01413713,Springer,1998-03-01,"Artificial Neural Networks (ANNs) have recently become the focus of considerable attention in many disciplines, including robot control, where they can be used as a general class of nonlinear models to solve highly nonlinear control problems. Feedforward neural networks have been widely applied for modelling and control purposes. One of the ANN applications in robot control is for the solution of the inverse kinematic problem, which is important in path planning of robot manipulators. This paper proposes an iterative approach and an offset error compensation method to improve the accuracy of the inverse kinematic solutions by using an ANN and a forward kinematic model of a robot. The offset error compensation method offers potential to generate accurately the inverse solution for a class of problems which have an easily obtained forward model and a complicated solution .",http://link.springer.com/openurl/pdf?id=doi:10.1007/BF01413713,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-7091-6492-1_2,A Modular Reinforcement Learning Architecture for Mobile Robot Control,Artificial Neural Nets and Genetic Algorithms,10.1007/978-3-7091-6492-1_2,Springer,1998-01-01,The paper presents a way of extending complementary reinforcement backpropagation learning (CRBP) to modular architectures using a new version of the gating network approach in the context of reactive navigation tasks for a simulated mobile robot. The gating network has partially recurrent connections to enable the co-ordination of reinforcement learning across both modules successive time steps. The experiments reported explore the possibility that architectures based on this approach can support concurrent acquisition of different reactive navigation related competences while the robot pursues light-seeking goals.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7091-6492-1_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-49240-2_3,Modular Reinforcement Learning: An Application to a Real Robot Task,Learning Robots,10.1007/3-540-49240-2_3,Springer,1998-01-01,"The behaviour of reinforcement learning (RL) algorithms is best understood in completely observable, finite state- and action-space, discrete-time controlled Markov-chains. Robot-learning domains, on the other hand, are inherently infinite both in time and space, and moreover they are only partially observable. In this article we suggest a systematic design method whose motivation comes from the desire to transform the task-to-be-solved into a finite-state, discrete-time, “approximately” Markovian task, which is completely observable too. The key idea is to break up the problem into subtasks and design controllers for each of the subtasks. Then operating conditions are attached to the controllers (together the controllers and their operating conditions which are called modules) and possible additional features are designed to facilitate observability. A new discrete time-counter is introduced at the “module-level” that clicks only when a change in the value of one of the features is observed. The approach was tried out on a real-life robot. Several RL algorithms were compared and it was found that a model-based approach worked best. The learnt switching strategy performed equally well as a handcrafted version. Moreover, the learnt strategy seemed to exploit certain properties of the environment which could not have been seen in advance, which predicted the promising possibility that a learnt controller might overperform a handcrafted switching strategy in the future.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-49240-2_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008216530547,Developing Mobile Robot Wall-Following Algorithms Using Genetic Programming,Applied Intelligence,10.1023/A:1008216530547,Springer,1998-01-01,"This paper demonstrates the use of genetic programming (GP) for the development of mobile robot wall-following behaviors. Algorithms are developed for a simulated mobile robot that uses an array of range finders for navigation. Navigation algorithms are tested in a variety of differently shaped environments to encourage the development of robust solutions, and reduce the possibility of solutions based on memorization of a fixed set of movements. A brief introduction to GP is presented. A typical wall-following robot evolutionary cycle is analyzed, and results are presented. GP is shown to be capable of producing robust wall-following navigation algorithms that perform well in each of the test environments used.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008216530547,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-7091-6492-1_98,Virtual Table Tennis and the Design of Neural Network Players,Artificial Neural Nets and Genetic Algorithms,10.1007/978-3-7091-6492-1_98,Springer,1998-01-01,"This paper discusses the design of a virtual table-tennis environment, and the design of neural network based controllers to play in that environment. The motivation behind the work is to provide an interesting and entertaining forum in which to carry out research on adaptive control and planning problems that stretch the limits of current neural network paradigms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7091-6492-1_98,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-7908-1882-6_3,Reinforcement Learning of a Six-Legged Robot to Walk and Avoid Obstacles,Soft Computing for Intelligent Robotic Systems,10.1007/978-3-7908-1882-6_3,Springer,1998-01-01,Walking machine high potential for off-road or hostile environment mobility necessits an adaptive and versatile control systeme in order to avoid the difficulties of complex and unpredictible behaviour modelling.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7908-1882-6_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-7908-1882-6_7,Neural Reinforcement Learning for Robot Navigation,Soft Computing for Intelligent Robotic Systems,10.1007/978-3-7908-1882-6_7,Springer,1998-01-01,Reinforcement Learning (RL) is an attractive approach for robot learning since it allows an agent to learn a given behavior from an evaluation of the wanted behavior. This measure correspond to a qualitative evaluation of the agent behavior. An agent means here a simulated system in a virtual world or a real agent interacting with a real world. The agent perceives situations of the world with its sensors and acts in the world with its motors. Figure 1 illustrates what we mean by an agent in this chapter. Experiments in learning an obstacle-avoidance behavior of the robot Khepera are presented. It is shown that neural RL is more suitable in real world applications.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7908-1882-6_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-1599-1_174,Reinforcement Learning of Collision-free Motions for a Robot Arm with a Sensing Skin,ICANN 98,10.1007/978-1-4471-1599-1_174,Springer,1998-01-01,"Sensory information is fundamental for autonomous robots that face unknown environments. On-line sensing allows a robot arm to modify its motion in real time to cope better with the environment. Reactive systems (e.g., [1]) are appropriate to generate on-line motions from local sensory data. A reactive controller can be implemented automatically by using artificial neural networks and reinforcement learning (RL) [2,3,4]. RL allows a neural network to acquire reaction rules while the robot arm interacts with its environment. We have previously demonstrated the feasibility of RL to acquire sensor-based reaching strategies for simulated multi-link planar manipulators [5]. In this paper, we extend this work to a real manipulator, namely a Zebra ZERO, that has a whole-arm sensing skin with sonar proximity sensors (see Fig. 1a). We describe a neural reactive controller that learns goal-oriented obstacle-avoiding motion strategies for such a manipulator in unknown 3D environments. The controller is made up of two main modules: a reinforcement-based action generator (AG) and a goal vector generator (GG). The AG uses local sensory data and position information to determine an appropriate deviation from the goal vector given by the GG. The task of collision-free reaching can be decomposed into two sequential subtasks: Negotiate Obstacles (NO subtask) and Move to Goal position (MG subtask). When the robot arm is not near the goal position and detects an obstacle in its way to the goal, the best strategy is to focus on negotiating the obstacle—moving along an efficient trajectory is not so important.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-1599-1_174,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-64473-3_65,Development of self-learning vision-based mobile robots for acquiring soccer robots behaviors,RoboCup-97: Robot Soccer World Cup I,10.1007/3-540-64473-3_65,Springer,1998-01-01,"An input generalization problem is one of the most important ones in applying reinforcement learning to real robot tasks. To cope with this problem, we propose a self-partitioning state space algorithm which can make non-uniform quantization of the multidimensional continuous state space. This method recursively splits its continuous state space into some coarse spaces called tentative states. It begins by supposing that such tentative states are regarded as the states for Q-learning. It collects Q values and statistical evidence regarding immediate rewards r and Q values within this tentative state space. When it finds out that a tentative state is relevant by the statistical test on minimum description length criterion, it partitions this coarse space into finer spaces. These procedures can make non-uniform quantization of the state space. Our method can be applied to non-deterministic domain because Q-learning is used to find out the optimal policy for accomplishing the given task. To show that our algorithm has generalization capability, we apply our method to two tasks in which a soccer robot shoots a ball into a goal and prevent a ball from entering a goal. To show the validity of this method, the experimental results for computer simulation and a real robot are shown.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-64473-3_65,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-72198-4_10,Development of Self-Learning Vision-Based Mobile Robots for Acquiring Soccer Robots Behaviors,Distributed Autonomous Robotic Systems 3,10.1007/978-3-642-72198-4_10,Springer,1998-01-01,"An input generalization problem is one of the most important ones in applying reinforcement learning to real robot tasks. To cope with this problem, we propose a self-partitioning state space algorithm which can make non-uniform quantization of the multidimensional continuous state space. This method recursively splits its continuous state space into some coarse spaces called tentative states based on the relevance test for immediate reward r and discounted future reward Q which are collected during Q-learning process. When it finds out that a tentative state is relevant by the statistical test on a minimum description length (hereafter, MDL), it partitions this coarse space into finer spaces. To show that our algorithm has generalization capability, we apply our method to two tasks in which a soccer robot shoots a ball into a goal and prevent a ball from entering a goal. To show the validity of this method, the experimental results for computer simulation and a real robot are shown.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-72198-4_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-1599-1_178,Embedding Knowledge in Reinforcement Learning,ICANN 98,10.1007/978-1-4471-1599-1_178,Springer,1998-01-01,"In almost all real systems where reinforcement learning is applied, it is found that a knowledge free approach doesn’t work. The basic RL algorithms must sufficiently be biased to achieve a satisfactory performance within a bounded time. This bias takes different forms. In this paper, in addition to reflex rules [6], environment (domain) knowledge is embedded into the learner. Environment knowledge gives leverage to the adaptive state space construction algorithm by splitting key states quickly. The learner is tested on a B21 robot for a goal reaching task. Experimental results show that after few trials the robot has indeed learned the right situation action rules that unfold its path.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-1599-1_178,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-1580-9_31,Vision-based Behavior Learning and Development for Emergence of Robot Intelligence,Robotics Research,10.1007/978-1-4471-1580-9_31,Springer,1998-01-01,"This paper focuses on two issues on learning and development; a problem of state-action space construction, and a scaling-up problem. The former is mainly related to sensory-motor mapping and its abstraction, and we show two our methods for the state and action space construction for reinforcement learning. For the latter issue, we attempt to define the environmental complexity based on the relationships between observations and self motions. Based on this view, we introduce a method which can cope with the complexity of multi-agent environment by a combination of a state vector estimation process and a reinforcement learning process based on the estimated vectors. As example tasks in our work, we adopt the domain of soccer robots, RoboCup [1]. Computer simulations and real robot experiments are given.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-1580-9_31,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-49240-2_7,Continual Robot Learning with Constructive Neural Networks,Learning Robots,10.1007/3-540-49240-2_7,Springer,1998-01-01,"In this paper, we present an approach for combining reinforcement learning, learning by imitation, and incremental hierarchical development. We apply this approach to a realistic simulated mobile robot that learns to perform a navigation task by imitating the movements of a teacher and then continues to learn by receiving reinforcement. The behaviours of the robot are represented as sensation-action rules in a constructive high-order neural network. Preliminary experiments are reported which show that incremental, hierarchical development, bootstrapped by imitative learning, allows the robot to adapt to changes in its environment during its entire lifetime very efficiently, even if only delayed reinforcements are given.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-49240-2_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-69115-4_21,Cellular Neural Networks for Navigation of a Mobile Robot,Rough Sets and Current Trends in Computing,10.1007/3-540-69115-4_21,Springer,1998-01-01,"This paper summarizes applications of cellular neural networks to autonomous mobile robot navigation tasks, which have been developed at the Institute of Fundamental Technological Research. They include map building, path planning and self-positioning of an indoor robot equipped with a laser range sensor. Efficiency of navigation based on cellular neural networks has been experimentally verified in a variety of natural, partially structured environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-69115-4_21,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-1599-1_64,GripSee: A Robot for Visually-Guided Grasping,ICANN 98,10.1007/978-1-4471-1599-1_64,Springer,1998-01-01,"We have designed an anthropomorphic robot system at our institute as a research platform and demonstrator for the next generation of service robots. GripSee is a visually guided robot which is endowed with a number of skills based on different neural network architectures. The skills include the interpretation of human gestures, localization and recognition of objects, planning and generation of grasping movements, and automatic calibration of the eye-hand coordination. This paper gives an overview of the system and reports on our experiences in applying diverse neural network architectures in a real robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-1599-1_64,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-7091-6492-1_3,Timing without Time — An Experiment in Evolutionary Robotics,Artificial Neural Nets and Genetic Algorithms,10.1007/978-3-7091-6492-1_3,Springer,1998-01-01,"Hybrids of genetic algorithms and artificial neural networks can be used successfully in many robotics applications. The approach to this is known as evolutionary robotics . Evolutionary robotics is advantageous because it gives a semi-automatic procedure to the development of a task-fulfilling control system for real robots. It is disadvantageous to some extent because of its great time consumption. Here, I will show how the time consumption can be reduced dramatically by using a simulator before transferring the evolved neural network control systems to the real robot. Secondly, the time consumption is reduced by realizing what are the sufficient neural network controllers for specific tasks. It is shown in an evolutionary robotics experiment with the Khepera robot, that a simple 2 layer feedforward neural network is sufficient to solve a robotics task that seemingly would demand encoding of time, for example in the form of recurrent connections or time input. The evolved neural network controllers are sufficient for exploration and homing behaviour with a very exact timing, even though the robot (controller) has no knowledge about time itself.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7091-6492-1_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-64957-3_70,Blurred vision: Simulation-reality transfer of a visually guided robot,Evolutionary Robotics,10.1007/3-540-64957-3_70,Springer,1998-01-01,"This paper investigates the evolution of robot controllers utilising only visual environment input data, capable of performing a hard task , playing football, in the real world. The techniques of minimal simulation , where the robot controller is forced to ignore certain features through making those features unreliable , are used to construct a noisy simulated environment for a robot with an onboard vision system. Robot control structures evolved in this simulation are then transferred on to a real robot, where the behaviours shown in simulation are displayed in the real world. In the experiment presented, finding a tennis ball and pushing it towards a goal, good controllers capable of performing the same behaviours in simulation and in the real world, are evolved only once sufficient unreliability is incorporated into the simulation. The success in evolving in simulation a robot controller incorporating only distal visual environment input data and displaying the same behaviours in both simulation and the real world, goes some way to addressing the argument that evolution is suitable only for toy problems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-64957-3_70,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-7091-6492-1_1,Obstacle Identification by an Ultrasound Sensor Using Neural Networks,Artificial Neural Nets and Genetic Algorithms,10.1007/978-3-7091-6492-1_1,Springer,1998-01-01,"This paper presents a method for obstacle recognition to be used by a mobile robot. Data are made of range measurements issued from a phased array ultrasonic sensor, characterized by a narrow beam width and an electronically controlled scan. Different methods are proposed: a simulation study using a neural network, and a signal analysis using an image representation. Finally, a solution combining both approaches has been validated.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7091-6492-1_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-7091-6492-1_5,Evolving Neural Controllers for Robot Manipulators,Artificial Neural Nets and Genetic Algorithms,10.1007/978-3-7091-6492-1_5,Springer,1998-01-01,"We examine here the feasibility of using evolutionary techniques to produce controllers for a standard robot arm. The main advantage of our technique of solving path planning problems is that the neural network (once trained) can be used for the same robot, with a variety of start and target positions. The genetic algorithm learns, and encodes implicitly, the calibration parameters of both the robot and the overhead camera, as well as the inverse kinematics of the robot. The results show that the evolved neural network controllers are reusable and allow multiple start and target positions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7091-6492-1_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-64574-8_416,Supervised reinforcement learning: Application to a wall following behaviour in a mobile robot,Tasks and Methods in Applied Artificial Intelligence,10.1007/3-540-64574-8_416,Springer,1998-01-01,"In this work we describe the design of a control approach in which, by way of supervised reinforcement learning, the learning potential is combined with the previous knowledge of the task in question, obtaining as a result rapid convergence to the desired behaviour as well as an increase in the stability of the process. We have tested the application of our approach in the design of a basic behaviour pattern in mobile robotics, such as that of wall following. We have carried out several experiments obtaining goods results which confirm the utility and advantages derived from the use of our approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-64574-8_416,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/BFb0113000,An anthropomorphic model of sensory-motor co-ordination of manipulation for robots,Experimental Robotics V,10.1007/BFb0113000,Springer,1998-01-01,"This paper investigates the problem of artificial perception related to manipulation tasks in robotics. The proposed approach is based on biological models of perception and sensory-motor co-ordination in humans and aims at devising anthropomorphic solutions to the problems of perception, learning and control in robotics. In particular, our approach involves the integration of different sensory modalities and the interpretation of sensory data aimed at the control of robot behaviour. We consider as sensory modalities, in relation to manipulation tasks, vision and haptic perception, i.e. the integration of tactile proprioceptive and exteroceptive data. The experimental part of this work is aimed at investigating some aspects of the proposed anthropomorphic model of perception in manipulation by means of anthropomorphic visual and tactile sensors on a robotic manipulator and a pantilt head, and a processing module based on neural network computational models integrated with the reinforcement learning paradigm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BFb0113000,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-72198-4_3,Robust Collision Avoidance in Multi-Robot Systems - Implementation onto Real Robots -,Distributed Autonomous Robotic Systems 3,10.1007/978-3-642-72198-4_3,Springer,1998-01-01,"In this paper, we discuss robust collision avoidance in multi-robot systems. It is important for a robot to acquire adaptive behaviors for avoiding robots and obstacles in complicated environments. As we reported previously, the reinforcement learning is useful for such kind of purposes. It was, however, found that it is difficult to implement the learning method onto real robots because the method requires large size of memory storage. In this paper, the multi-layered learning is introduced to reduce the required memory size. By dividing a learning curriculum into multiple layers, the number of expected situations can be limited and the learning process itself can be structured. It is shown that real robot is able to successfully avoid collision to other robots and obstacles in a complicated situation, based on the proposed learning procedure.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-72198-4_3,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-49240-2_2,Q-Learning with Adaptive State Space Construction,Learning Robots,10.1007/3-540-49240-2_2,Springer,1998-01-01,"In this paper, we propose Q-learning with adaptive state space construction. This provides an efficient method to construct the state space suitable for Q-learning to accomplish the task in continuous sensor space. In the proposed algorithm, a robot starts with single state covering whole sensor space. A new state is generated incrementally by segmenting a sub-region of the sensor space or combining the existing states. The criterion for incremental segmentation and combination is derived from Q-learning algorithm. Simulation results show that the proposed algortithm is able to construct the sensor space effectively to accomplish the task. The resulting state space reveals the sensor space in a Voronoi tessellation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-49240-2_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-49240-2_4,Analysis and Design of Robot’s Behavior: Towards a Methodology,Learning Robots,10.1007/3-540-49240-2_4,Springer,1998-01-01,We introduce a methodology to design reinforcement based control architectures for autonomous robots. It aims at systematizing the behavior analysis and the controller design. The methodology has to be seen as a conceptual framework in which a number of methods are to be defined. In this paper we use some more or less known methods to show the feasibility of the methodology. The postman-robot case study illustrates how the proposed methodology is applied.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-49240-2_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-64957-3_74,Off-line model-free and on-line model-based evolution for tracking navigation using evolvable hardware,Evolutionary Robotics,10.1007/3-540-64957-3_74,Springer,1998-01-01,"Recently there has been great interest in the idea that evolvable systems based on the principles of Artificial Life can be used to continuously and autonomously adapt the behavior of physically embedded systems such as mobile robots, plants and intelligent home devices. At the same time, we have seen the introduction of evolvable hardware (EHW): new integrated circuits that are able to adapt their hardware autonomously and almost continuously to changes in the environment [11]. This paper describes how a navigation system for a physical mobile robot can be evolved using a Boolean function approach implemented on evolvable hardware. The task of the mobile robot is to track a moving target represented by a colored ball, while avoiding obstacles during its motion. Our results show that a dynamic Boolean function approach is sufficient to produce this navigation behavior. Although the classical model-free evolution method is often infeasible in the real world due to the number of possible interactions with the environment, we demonstrate that a model-based evolution method can reduce the interactions with the real world by a factor of 250, thus allowing us to apply the evolution process on-line and to obtain an adaptive tracking-avoiding system, provided the implementation can be accelerated by the utilization of evolvable hardware.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-64957-3_74,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-64473-3_69,Vision-based robot learning towards RoboCup: Osaka University “Trackies“,RoboCup-97: Robot Soccer World Cup I,10.1007/3-540-64473-3_69,Springer,1998-01-01,"The authors have applied reinforcement learning methods to real robot tasks in several aspects. We selected a skill of soccer as a task for a vision-based mobile robot. In this paper, we explain two of our method; (1)learning a shooting behavior, and (2)learning a shooting with avoiding an opponent. These behaviors were obtained by a robot in simulation and tested in a real environment in RoboCup-97. We discuss current limitations and future work along with the results of RoboCup-97.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-64473-3_69,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-7908-1882-6_5,Intelligent Optimal Design of CMAC Neural Network for Robot Manipulators,Soft Computing for Intelligent Robotic Systems,10.1007/978-3-7908-1882-6_5,Springer,1998-01-01,"This chapter presents the application of quadratic optimization for motion control to feedback control of robotic systems using Cerebellar Model Arithmetic Computer (CMAC) neural networks. Explicit solutions to the Hamilton-Jacobi-Bellman (H-J-B) equation for optimal control of robotic systems are found by solving an algebraic Riccati equation. It is shown how CMAC can cope with nonlinearities through optimization with no preliminary off-line learning phase required. The adaptive learning algorithm is derived from Lyapunov stability analysis, so that both system tracking stability and error convergence can be guaranteed in the closed-loop system. The filtered tracking error or critic gain and the Lyapunov function for the nonlinear analysis are derived from the user input in terms of a specified quadratic performance index. Simulation results on a two-link robot manipulator show the satisfactory performance of the proposed control schemes even in the presence of large modeling uncertainties and external disturbances.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7908-1882-6_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4471-3427-5_4,Neural Network Control of a Simple Mobile Robot,Concepts for Neural Networks,10.1007/978-1-4471-3427-5_4,Springer,1998-01-01,"In recent years researchers in the Department of Cybernetics have been developing simple mobile robots capable of exploring their environment on the basis of the information obtained from a few simple sensors. These robots are used as the test bed for exploring various behaviours of single and multiple organisms: the work is inspired by considerations of natural systems. That part of the work which involves neural networks and related techniques is discussed. These neural networks are used both to process the sensor information and to develop the strategy used to control the robot. Here the robots, their sensors, and the neural networks used are all described.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-3427-5_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-64473-3_46,RoboCup: A challenge problem for AI and robotics,RoboCup-97: Robot Soccer World Cup I,10.1007/3-540-64473-3_46,Springer,1998-01-01,"RoboCup is an attempt to foster AI and intelligent robotics research by providing a standard problem where wide range of technologies can be integrated and examined. The first RoboCup competition was held at IJCAI-97, Nagoya. In order for a robot team to actually perform a soccer game, various technologies must be incorporated including: design principles of autonomous agents, multi-agent collaboration, strategy acquisition, real-time reasoning, robotics, and sensorfusion. RoboCup is a task for a team of multiple fast-moving robots under a dynamic environment. Although RoboCup's final target is a world cup with real robots, RoboCup offers a software platform for research on the software aspects of RoboCup. This paper describes technical challenges involved in RoboCup, rules, and simulation environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-64473-3_46,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4471-3427-5_5,A Connectionist Approach to Spatial Memory and Planning,Concepts for Neural Networks,10.1007/978-1-4471-3427-5_5,Springer,1998-01-01,"This chapter describes the design and testing of a biologically inspired vision-based model of spatial memory. Three theories of biological spatial memory are discussed. The Topological Network-map theory is translated into general principles, and two forms of connectionist implementation of these principles are discussed. This is followed by a discussion of planning and map-learning experiments performed with a robot. These experiments reveal problems with the implementation of the view-graph principle. The causes of these problems are discussed and solutions proposed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-3427-5_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-5473-8_17,Recurrent Neuro-Fuzzy Models of Complex Systems,"Uncertainty Analysis in Engineering and Sciences: Fuzzy Logic, Statistics, and Neural Network Approach",10.1007/978-1-4615-5473-8_17,Springer,1998-01-01,This chapter introduces a neuro-fuzzy system in which the rule consequents are recurrent neural networks. Recurrent neuro-fuzzy systems have the potential to model nonlinear dynamic systems using a small number of rules. Other advantages include their proven capability of approximating dynamic systems and a two stage learning algorithm which minimizes pitfalls of recurrent hackpropagation variants.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-5473-8_17,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-64957-3_63,Running across the reality gap: Octopod locomotion evolved in a minimal simulation,Evolutionary Robotics,10.1007/3-540-64957-3_63,Springer,1998-01-01,"This paper describes experiments in which neural network control architectures were evolved in minimal simulation for an octopod robot. The robot is around 30cm long and has 4 infra red sensors that point ahead and to the side, various bumpers and whiskers, and ten ambient light sensors positioned strategically around the body. Each of the robot's eight legs is controlled by two servo motors, one for movement in the horizontal plane, and one for movement in the vertical plane, which means that the robots motors have a total of sixteen degrees of freedom. The aim of the experiments was to evolve neural network control architectures that would allow the robot to wander around its environment avoiding objects using its infra-red sensors and backing away from objects that it hits with its bumpers. This is a hard behaviour to evolve when one considers that in order to achieve any sort of coherent movement the controller has to control not just one or two motors in a coordinated fashion but sixteen. Moreover it is an extremely difficult set-up to simulate using traditional techniques since the physical outcome of sixteen motor movements is rarely predictable in all but the simplest cases. The evolution of this behaviour in a minimal simulation, with perfect transference to reality, therefore, provides essential evidence that complex motor behaviours can be evolved in simulations built according to the theory and methodology of minimal simulations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-64957-3_63,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-64957-3_61,Evolutionary robotics: A survey of applications and problems,Evolutionary Robotics,10.1007/3-540-64957-3_61,Springer,1998-01-01,"This paper reviews evolutionary approaches to the automatic design of real robots exhibiting a given behavior in a given environment. Such a methodology has been successfully applied to various wheeled and legged robots, and to numerous behaviors including wall-following, obstacle-avoidance, light-seeking, arena cleaning and target seeking. Its potentialities and limitations are discussed in the text and directions for future work are outlined.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-64957-3_61,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1007932011161,"The Development, Control and Operation of an Autonomous Robotic Excavator",Journal of Intelligent and Robotic Systems,10.1023/A:1007932011161,Springer,1998-01-01,"The excavation of foundations, general earthworks and earth removal tasks are activities which involve the machine operator in a series of repetitive operations, suggesting opportunities for the automation through the introduction of robotic technologies with subsequent improvements in machine utilisation and throughput. The automation of the earth removal process is also likely to provide a number of other benefits such as a reduced dependence on operator skills and a lower operator work load, both of which might be expected to contribute to improvements in quality and, in particular, the removal of the need for a local operator when working in hazardous environments. The Lancaster University Computerised Intelligent Excavator or LUCIE has demonstrated the achievement of automated and robotic excavation through the implementation of an integrated, real-time, artificial intelligence based control system utilising a novel form of motion control strategy for movement of the excavator bucket through ground. Having its origins in the systematic observation of a range of machine operators of differing levels of expertise, the control strategy as evolved enables the autonomous excavation of a high quality rectangular trench in a wide variety of types and conditions of ground and the autonomous removal of obstacles such as boulders along the line of that trench. The paper considers the development of the LUCIE programme since its inception and sets out in terms of the machine kinematics the evolution and development of the real-time control strategy from an implementation on a one-fifth scale model of a back-hoe arm to a full working system on a JCB801 360° tracked excavator.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1007932011161,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-1273-0_69,An Exploratory Robot Controller which Adapts to Unknown Environments and Damaged Sensors,Field and Service Robotics,10.1007/978-1-4471-1273-0_69,Springer,1998-01-01,"In this paper we describe an adaptive mobile robot control system that enables a multi-sensor robot to learn reactive behaviours by interacting with the environment. The controller is particularly suitable for exploratory robots due to its ability to adapt to unknown environments and recover from partial sensor damage. Learning is based on the robot learning a map between sensors and trajectory velocities so at any instant the robot becomes capable of realising how fast it should move along its predefined trajectories. Behaviours are performed by selecting trajectories based on their velocity and closeness to a preset behaviour criteria. Unlike reinforcement learning, the map can be obtained relatively quickly by extracting knowledge directly form the environment via the sensors thereby avoiding the credit assignment problem. We demonstrate the effectiveness of this approach to robot learning by using a Yamabico mobile robot to firstly acquire goal seeking behaviour and then recover from damage inflicted on its sensors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-1273-0_69,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/10692710_2,An Autonomous Agent Architecture and the Locomotion Problem,Advances in Artificial Intelligence,10.1007/10692710_2,Springer,1998-01-01,"This paper presents a three level architecture for an autonomous agent and its application to the navigation problem in an unknown environment. The architecture is structured in three levels, called, reactive, instinctive and cognitive. The reactive level is based on a feed-forward symbolic neural network. The instinctive level is based on a set of predefined behaviors selected by a fuzzy classifier according to the perceived situation. Finally, the cognitive level is supported by symbolic production rules that determine the global behavior of the agent. In this sense, the three levels are responsible by behaviors of increasing complexity. The main characteristics of the architecture are: heterogeneity, hierarchic assembly, behavior-oriented design and biological plausibility. Some examples are also presented, that show the behavior robustness of the proposed architecture in a simulated environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/10692710_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/BFb0026611,Million module neural systems evolution,Artificial Evolution,10.1007/BFb0026611,Springer,1998-01-01,"This position paper discusses the evolution of multi-module neural net systems, where the number of neural net modules is up to ten million (i.e. an “artificial brain”). ATR's “CAM-Brain” Project [de Garis 1993, 1996] has progressed to the point where it is technically possible (using a new FPGA (Field Programmable Gate Array) based evolvable hardware (EHW or E-Hard) system to be completed by the spring of 1998 [Korkin & de Garis 1997]) to begin to evolve and build an artificial brain containing 10,000 neural net modules. This development raises the prospect that within a few years these numbers will rapidly increase. This paper introduces some issues that such massive system-building will generate. The immediate question is “What should we evolve?” This paper presents some suggested evolvable system targets containing N neural net modules, where N = 100; 1000; 10,000; 100,000; 1,000,000; 10,000,000 with an emphasis on the N = 100 case, for purposes of illustration. The issues involved are not only of a conceptual and evolutionary engineering nature, but (when N is large) economic, managerial and even political as well.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BFb0026611,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-7908-1882-6_4,Neural Networks for Visual Servoing in Robotics,Soft Computing for Intelligent Robotic Systems,10.1007/978-3-7908-1882-6_4,Springer,1998-01-01,This chapter introduces an application of artificial neural network techniques to robotic control. Arm movements are controlled using visual features. The neurocontroller adapts on-line without any prior knowledge of the system geometry.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7908-1882-6_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1007960328527,Cognitive Architecture for Robust Adaptive Control of Robots in a Team,Journal of Intelligent and Robotic Systems,10.1023/A:1007960328527,Springer,1997-09-01,"The objective of this paper is to present a cognitive architecture thatutilizes three different methodologies for adaptive, robust control ofrobots behaving intelligently in a team. The robots interact within a worldof objects, and obstacles, performing tasks robustly, while improving theirperformance through learning. The adaptive control of the robots has beenachieved by a novel control system. The Tropism-based cognitive architecturefor the individual behavior of robots in a colony is demonstrated throughexperimental investigation of the robot colony. This architecture is basedon representation of the likes and dislikes of the robots. It is shown thatthe novel architecture is not only robust, but also provides the robots withintelligent adaptive behavior. This objective is achieved by utilization ofthree different techniques of neural networks, machine learning, and geneticalgorithms. Each of these methodologies are applied to the tropismarchitecture, resulting in improvements in the task performance of the robotteam, demonstrating the adaptability and robustness of the proposed controlsystem.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1007960328527,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1007916529436,Robust Practical Point Stabilization of a Nonholonomic Mobile Robot Using Neural Networks,Journal of Intelligent and Robotic Systems,10.1023/A:1007916529436,Springer,1997-09-01,"A control structure that makes possible the integration of a kinematiccontroller and a neural network (NN) computed-torque controller fornonholonomic mobile robots is presented. A combined kinematic/torque controllaw is developed and stability is guaranteed by Lyapunov theory. Thiscontrol algorithm is applied to the practical point stabilization problemi.e., stabilization to a small neighborhood of the origin. The NN controllercan deal with unmodeled bounded disturbances and/or unstructured unmodeleddynamics in the vehicle. On-line NN weight tuning algorithms that do notrequire off-line learning yet guarantee small tracking errors and boundedcontrol signals are utilized.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1007916529436,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1007952109871,Synthesis of Neural Networks and PID Control for Performance Improvement of Industrial Robots,Journal of Intelligent and Robotic Systems,10.1023/A:1007952109871,Springer,1997-09-01,"In this article, an approach for improving the performance of industrialrobots using multilayer feedforward neural networks is presented. Thecontroller based on this approach consists of two main components: a PIDcontrol and a neural network. The function of the neural network is tocomplement the PID control for the specific purpose of improving theperformance of the system over time. Analytical and experimental resultsconcerning this synthesis of neural networks and PID control are presented.The analytical results assert that the performance of PID-controlledindustrial robots can be improved through proper utilization of the learningand generalization ability of neural networks. The experimental results,obtained through actual implementation using a commercial industrial robot,demonstrate the effectiveness of such control synthesis for practicalapplications. The results of this work suggest that neural networks could beadded to existing PID-controlled industrial robots for performanceimprovement.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1007952109871,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1007904210780,A Stable Neuro-Adaptive Controller for Rigid Robot Manipulators,Journal of Intelligent and Robotic Systems,10.1023/A:1007904210780,Springer,1997-09-01,"In this paper a controller based on neural networks is proposed toachieve output trajectory tracking of rigid robot manipulators. Neuralnetworks used here are one hidden layer ones so that their outputs dependlinearly on the parameters. Our method uses a decomposed connectioniststructure. Each neural network approximate a separate element of thedynamical model. These approximations are used to perform an adaptive stablecontrol law. The controller is based on direct adaptive techniques and theLyapunov approach is used to derive the adaptation laws of the nets’parameters. By using an intrinsic physical property of the manipulator, thesystem is proved to be stable. The performance of the controller depends onthe quality of the approximation, i.e. on the inherent reconstruction errorsof the exact functions.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1007904210780,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1007900125801,Stable Sampled-data Adaptive Control of Robot Arms Using Neural Networks,Journal of Intelligent and Robotic Systems,10.1023/A:1007900125801,Springer,1997-09-01,"Stable neural network-based sampled-data indirect and direct adaptivecontrol approaches, which are the integration of a neural network (NN)approach and the adaptive implementation of the discrete variable structurecontrol, are developed in this paper for the trajectory tracking control ofa robot arm with unknown nonlinear dynamics. The robot arm is assumed tohave an upper and lower bound of its inertia matrix norm and its states areavailable for measurement. The discrete variable structure control servestwo purposes, i.e., one is to force the system states to be within the stateregion in which neural networks are used when the system goes out of neuralcontrol; and the other is to improve the tracking performance within the NNapproximation region. Main theory results for designing stable neuralnetwork-based sampled data indirect and direct adaptive controllers aregiven, and the extension of the proposed control approaches to the compositeadaptive control of a flexible-link robot is discussed. Finally, theeffectiveness of the proposed control approaches is illustrated throughsimulation studies.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1007900125801,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.3758/BF03204811,Robot-resident neural networks: A step beyond computer simulation,"Behavior Research Methods, Instruments, & Computers",10.3758/BF03204811,Springer,1997-06-01,"A simple, commercially available robot platform is presented in this paper with suggested modifications for adding a neural network controller and a better sensory system. The robot, called HexWalker, is a six-legged, servo-driven, battery-powered platform. We found this platform easy to modify with both hardware and software changes. The software changes can be programmed from a standard PC and downloaded into the EEROMS of the robot. This robot provides a tangible model of sensory/motor integration which is useful in both teaching and research.",http://link.springer.com/openurl/pdf?id=doi:10.3758/BF03204811,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1007933917719,Human-Machine Collaboration in Robotics: Integrating Virtual Tools with a Collision Avoidance Concept using Conglomerates of Spheres,Journal of Intelligent and Robotic Systems,10.1023/A:1007933917719,Springer,1997-04-01,"This paper describes how virtual tools that represent real robot end-effectors are used in conjunction with a generalized conglomerate-of-spheres approach to collision avoidance in such a way that telerobotic trajectory planning can be accomplished using simple gesture phrases such as ‘put that there while avoiding that’. In this concept, an operator (or set of collaborators) need not train for cumbersome telemanipulation on several multiple-link robots, nor do robots need a priori knowledge of operator intent and exhaustive algorithms for evaluating every aspect of a detailed environment model. The human does what humans do best during task specification, while the robot does what machines do best during trajectory planning and execution. Four telerobotic stages were implemented to demonstrate this strategic supervision concept that will facilitate collaborative control between humans and machines. In the first stage, virtual reality tools are selected from a ‘toolbox’ by the operator(s) and then these virtual tools are computationally interwoven into the live video scene with depth correlation. Each virtual tool is a graphic representation of a robot end-effector (gripper, cutter, or other robot tool) that carries tool-use attributes on how to perform a task. An operator uses an instrumented glove to virtually retrieve the disembodied tool, in the shared scene, and place it near objects and obstacles while giving key-point gesture directives, such as ‘cut there while avoiding that’. Collaborators on a network may alter the plan by changing tools or tool positioning to achieve preferred results from their own perspectives. When parties agree, from wherever they reside geographically, the robot(s) create and execute appropriate trajectories suitable to their own particular links and joints. Stage two generates standard joint-interpolated trajectories, and later creates potential field trajectories if necessary. Stage three tests for collisions with obstacles identified by the operator and modeled as conglomerates of spheres. Stage four involves automatic grasping (or cutting etc.) once the robot camera acquires a close-up view of the object during approach. In this paper particular emphasis is placed on the conglomerate-of-spheres approach to collision detection as integrated with the virtual tools concept for a Puma 560 robot by the Virtual Tools and Robotics Group in the Computer Integrated Manufacturing Laboratory at The Pennsylvania State University (Penn State).",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1007933917719,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008819414322,Reinforcement Learning in the Multi-Robot Domain,Autonomous Robots,10.1023/A:1008819414322,Springer,1997-03-01,"This paper describes a formulation of reinforcement learning that enables learning in noisy, dynamic environments such as in the complex concurrent multi-robot learning domain. The methodology involves minimizing the learning space through the use of behaviors and conditions, and dealing with the credit assignment problem through shaped reinforcement in the form of heterogeneous reinforcement functions and progress estimators. We experimentally validate the approach on a group of four mobile robots learning a foraging task.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008819414322,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008855018923,Cooperative Mobile Robotics: Antecedents and Directions,Autonomous Robots,10.1023/A:1008855018923,Springer,1997-03-01,"There has been increased research interest in systems composed of multiple autonomous mobile robots exhibiting cooperative behavior. Groups of mobile robots are constructed, with an aim to studying such issues as group architecture, resource conflict, origin of cooperation, learning, and geometric problems. As yet, few applications of cooperative robotics have been reported, and supporting theory is still in its formative stages. In this paper, we give a critical survey of existing works and discuss open problems in this field, emphasizing the various theoretical issues that arise in the study of cooperative robotics. We describe the intellectual heritages that have guided early research, as well as possible additions to the set of existing motivations.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008855018923,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF01414102,A solution to the end-effector position optimisation problem in robotics using neural networks,Neural Computing & Applications,10.1007/BF01414102,Springer,1997-03-01,"The paper presents an original application of the Hopfield-type neural network to a robotics optimisation problem. The robot considered features an arm composed of three revolute joints, the last of which is the end-effector. The robot is planar as the movement of the end-effector is limited to one plane. The mechanical characteristics of the actuators in the joints, the accuracy of the angle position sensors, and dimensional errors in the mechanical elements which make up the end-effector all contribute towards an end-effector positioning error along an assigned trajectory. The computational complexity of the algorithmic solution to the minimisation of this error is at times incompatible with certain particularly critical industrial applications. To reduce the calculation time, the author presents a neural approach based on a Hopfield-type model. A detailed definition of the neural approach is given, its capacity for solving the problem is demonstrated, and the computational complexity is analysed. This analysis shows the drastic computational reduction provided by the neural approach as compared with an algorithmic solution to the problem of end-effector position optimisation .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF01414102,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4757-6451-2_4,Reinforcement Learning in the Multi-Robot Domain,Robot Colonies,10.1007/978-1-4757-6451-2_4,Springer,1997-01-01,"This paper describes a formulation of reinforcement learning that enables learning in noisy, dynamic environments such as in the complex concurrent multi-robot learning domain. The methodology involves minimizing the learning space through the use of behaviors and conditions, and dealing with the credit assignment problem through shaped reinforcement in the form of heterogeneous reinforcement functions and progress estimators. We experimentally validate the approach on a group of four mobile robots learning a foraging task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4757-6451-2_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-7091-2666-0_38,Application of Neural Networks for Control of Robot Manipulators-Simulation and Implementation,ROMANSY 11,10.1007/978-3-7091-2666-0_38,Springer,1997-01-01,"Several approaches to using neural networks for solving the kinematics, dynamics, motion planning and control problems in robotics applications have been proposed in past years. In the literature some applications of neural networks in kinematics are presented [3, 6, 7, 14, 17] and motion planning [7,14,17]. The use of neural networks for control of robotic manipulators motion has been proposed in the number of papers [1, 5, 7, 9, 10, 11, 12, 19, 22]. In this paper the problem of the trajectory tracking is considered. The desired trajectory for the motion of a manipulator is generated by the path planner. Having the desired trajectory with the initial and final positions of the centerpoint of the end-effector, controllers need to be constructed for the actuators that make the end-effector follow the specified trajectory as closely as possible.This is achieved by determining the torques acting on the joint shafts or inputs to the joint actuators so that the system follows the desired trajectory with minimal tracking error. The dynamic model of the general manipulator represents a multiple-inputmultiple-output (MIMO) system, in which equations are nonlinear and coupled. We consider two alternatives of control of such systems: the classical control and the intelligent one. One class of intelligent control is control scheme based on neural networks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7091-2666-0_38,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1007992700881,Impedance Control with On-Line Neural Network Compensator for Dual-Arm Robots,Journal of Intelligent and Robotic Systems,10.1023/A:1007992700881,Springer,1997-01-01,"A controller design strategy of dual-arm robots is proposed in this paper. The controller consists of a central controller and three force controllers. The central controller is used to calculate each arm’s force command according to the desired object motion. A force controller is used in each arm to track the commanding force. Another force controller is used to track the desired contact force between the manipulated object and its environment. The force controller can be partitioned into three parts. The computed torque method is used to linearize and decouple the dynamics of a manipulator. An impedance controller is then added to regulate the mechanical impedance between the manipulator and its environment. In order to track a reference force signal, an on-line neural network is used to compensate the effect of unknown parameters of the manipulator and environment. The simulation results are reported to show the performance of the neural network compensator.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1007992700881,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/BFb0020242,Incremental acquisition of local networks for the control of autonomous robots,Artificial Neural Networks — ICANN'97,10.1007/BFb0020242,Springer,1997-01-01,"This paper proposes an incremental learning approach to control autonomous robots based on local networks. This approach integrates different learning techniques in a conceptually simple architecture. The robot does not learn from scratch, but uses two types of bias: builtin reflexes (domain knowledge) and advice. The robot adds a new unit to the neural network whenever it uses the reflexes or receives an advice. This unit is integrated into a topology preserving map and associates a region around the current situation to either the computed reflex or the advice. The resulting reaction rule is then tuned by means of reinforcement learning and self-organizing rules. Experimental results show that the robot TESEO rapidly learns suitable behavioral strategies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BFb0020242,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4757-6451-2_1,Cooperative Mobile Robotics: Antecedents and Directions,Robot Colonies,10.1007/978-1-4757-6451-2_1,Springer,1997-01-01,"There has been increased research interest in systems composed of multiple autonomous mobile robots exhibiting cooperative behavior. Groups of mobile robots are constructed, with an aim to studying such issues as group architecture, resource conflict, origin of cooperation, learning, and geometric problems. As yet, few applications of cooperative robotics have been reported, and supporting theory is still in its formative stages. In this paper, we give a critical survey of existing works and discuss open problems in this field, emphasizing the various theoretical issues that arise in the study of cooperative robotics. We describe the intellectual heritages that have guided early research, as well as possible additions to the set of existing motivations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4757-6451-2_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-63173-9_50,Memory-based neural network and its application to a mobile robot with evolutionary and experience learning,Evolvable Systems: From Biology to Hardware,10.1007/3-540-63173-9_50,Springer,1997-01-01,"Use of the neural network in pattern recognition problem has many beneficial aspects, including advantages in learning, generalization, and robustness. However, the use of neural networks also has drawbacks. Problems encountered during the use of neural networks include an extended learning period and the inability of the users to process data. In an attempt to overcome these disadvantages, we propose a memory-based implementation of neural networks. Our method realizes neural network-like properties such as learning, generalization and robustness and is free from the weak points of the neural network. In our approach, training data are stored in a memory in the form of distributed manner by the use of several random number tables. On-line learning can be realized easily in our approach. This method was applied to a behavior-learning mobile robot. This robot acquires instinctive behavior by evolutionary method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-63173-9_50,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-0951-8_18,Proposal of a Darwin-Neural Network for a Robot Implementation,Neural Nets WIRN VIETRI-96,10.1007/978-1-4471-0951-8_18,Springer,1997-01-01,"The objective of this work is the proposal of a Darwin-neural network that simulates an automaton with an adaptive behavior. We describe the environmental framework within the automaton can move, the areas the automaton is made of, the network dynamic, the transfer function that characterizes the state transition of neurons, the learning algorithm and the overall behavior of the network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-0951-8_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-7091-2666-0_19,Gait Control Method of Robot and Biological Systems by Use of Hojo-Brain,ROMANSY 11,10.1007/978-3-7091-2666-0_19,Springer,1997-01-01,"The purpose of this research is to propose and develop a new control method in the robotic field and the bio-medical field, which is configured by the robotic/biological simulator, analytical motion mode, sensory feedback and the artificial CPG which is constructed by recurrent neural network (RNN) and genetic algorithm (GA). We call such controller “HOJO-Brain”, which means supplementary brain for motion control. We apply this method in the robotic field and the bio-medical field. In the robotic field, this HOJO-Brain is applied to a 5-DOF legged locomotion robot. In the bio-medical field, this HOJO-Brain is applied to animals as the FES (Functional ElectroStimulation) controller. This FES control system with HOJO-Brain would have a possibility to realize more effective and emergent motion control for severely physically handicapped persons such as the quadriplegia. By the computer simulations and the simple actual experiments using animals, we could confirm the fine adaptivity and emergence for the motion control. This HOJO-Brain strategy might be regarded as essential for the total motion control.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7091-2666-0_19,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/BFb0032595,Integration of Self-Organizing Feature Maps and reinforcement learning in robotics,Biological and Artificial Computation: From Neuroscience to Technology,10.1007/BFb0032595,Springer,1997-01-01,"In this paper we describe a hybrid approach to solve a real-world robotic task with uncertainty. The solution is based on the integration of unsupervised learning of task features and reinforcement learning of the correspondence between situations and actions. We seek for inspiration in the behavior of people performing manipulation tasks. The proposed approach clearly separates the programmed skills from the learned knowledge. A real-world example is presented which shows how the robot, starting from a pure random strategy, improves its performance and becomes more skillful with the task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BFb0032595,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/BFb0020249,Force feedback control of an assembly robot by neural networks,Artificial Neural Networks — ICANN'97,10.1007/BFb0020249,Springer,1997-01-01,"This paper presents the control of a non linear dynamic system by a neural network controller. This approach based on a feedforward neural network doesn't need any mathematical model of the system. The architecture and the stability of this controller are first analyzed, then an implementation on a flexible assembly cell including a parallel robot is presented. Experimental results of a peg in a hole insertion task show that the proposed hybrid neural controller exhibits better perfomances than the classical external hybrid force position controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BFb0020249,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-6325-9_4,Neural Network Vision for Robot Driving,Intelligent Unmanned Ground Vehicles,10.1007/978-1-4615-6325-9_4,Springer,1997-01-01,"Autonomous navigation is a difficult problem for traditional vision and robotic techniques, primarily because of the noise and variability associated with real world scenes. Autonomous navigation systems based on traditional image processing and pattern recognition techniques often perform well under certain conditions, but have problems with others. Part of the difficulty stems from the fact that the processing performed by these systems remains fixed across various environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-6325-9_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-63173-9_59,From some tasks to biology and then to hardware,Evolvable Systems: From Biology to Hardware,10.1007/3-540-63173-9_59,Springer,1997-01-01,In this paper a class of some tasks which should be realized by the hardware is characterized. On the basis of that characterization the hypothesis of organization of such a part human brain that realizes these tasks is determined. Then on the basis of that hypothesis a formal model of hardware which models the mentioned part of brain is derived. The transformation of the formal model of such a hardware into its logical structure is shown.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-63173-9_59,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/BFb0032597,Implementation of a basic reactive behavior in mobile robotics through artificial neural networks,Biological and Artificial Computation: From Neuroscience to Technology,10.1007/BFb0032597,Springer,1997-01-01,"In this work we describe the design and implementation in a Nomad200 mobile robot of a reactive behavior aimed at wall following. A detailed analysis of the application domain has allowed us to modularize the design, conjugating in its. synthesis the potential of artificial neural networks for sensorial abstraction with other decision modules. We have carried out several experiments both in simulated and in real environments, obtaining very good results in different and unfavorable situations, which proves the robustness and flexibility of the system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BFb0032597,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-7091-2668-4_2,Neural Networks for Rapid Learning in Computer Vision and Robotics,"Learning, Networks and Statistics",10.1007/978-3-7091-2668-4_2,Springer,1997-01-01,"One of the major thrusts for the success of neural networks in many areas was the development of learning algorithms that allow to capture implicit knowledge that is only available in the form of examples such that it can be generalized and applied to new situations, usually “inputs” to a suitably trained net.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7091-2668-4_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-011-5498-7_4,Control of Robotic Manipulators Using Neural Networks — A Survey,Methods and Applications of Intelligent Control,10.1007/978-94-011-5498-7_4,Springer,1997-01-01,Neural networks offer an exciting alternative for modeling and control of nonlinear systems. Neural networks trained with back propagation learning algorithms are capable of learning to control an unknown plant by extracting the necessary information from the plant. The purpose of this chapter is to provide an overview of the research being done in the area of neural network approaches to control of robotic manipulators. Applications of some neural network architectures in robot control are surveyed. The strengths and weaknesses of current approaches are identified and key areas for future research are discussed.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-011-5498-7_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00240650,Sonar-based mobile robot navigation through supervised learning on a neural net,Autonomous Robots,10.1007/BF00240650,Springer,1996-12-01,"For mobile robot navigation in an unknown and changing environment, a reactive approach is both simple to implement and fast in response. A neural net can be trained to exhibit such a behaviour. The advantage is that, it relates the desired motion directly to the sensor inputs, obviating the need of modeling and planning. In this work, a feedforward neural net is trained to output reactive motion in response to ultrasonic range inputs, with data generated artificially on the computer screen. We develop input and output representations appropriate to this problem. A purely reactive robot, being totally insensitive to context, often gets trapped in oscillations in front of a wide object. To overcome this problem, we introduce a notion of memory into the net by including context units at the input layer. We describe the mode of training for such a net and present simulated runs of a point robot under the guidance of the trained net in various situations. We also train a neural net for the navigation of a mobile robot with a finite turning radius. The results of the numerous test runs of the mobile robot under the control of the trained neural net in simulation as well as in experiments carried out in the laboratory, are reported in this paper.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00240650,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00571697,A neural network controller for flexible-link robots,Journal of Intelligent and Robotic Systems,10.1007/BF00571697,Springer,1996-12-01,"The object in this paper is to achieve tracking control of a partially unknown flexible-link robot arm. It is shown how to stabilize the internal dynamics by selecting a physically meaningful modified performance output for tracking; this output is the slow portion of the link-tip motions. That is, the tracking requirement is relaxed so that the internal dynamics are controllable through a boundary layer correction. The controller is composed of singular-perturbation based fast control and an outer-loop slow control. The slow subsystem is controlled by a neural network (NN) for feedback linearization, plus a PD outer-loop for tracking, and a robustifying term to assure the closed-loop stability. No off-line learning or training is needed for the NN. Tracking and stability are proven using Lyapunov techniques that yield a novel modified NN weight tuning algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00571697,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00339662,Planning of collision-free paths for a reconfigurable dual manipulator equipped mobile robot,Journal of Intelligent and Robotic Systems,10.1007/BF00339662,Springer,1996-11-01,"In this paper, we study the problem of finding a collision-free path for a mobile robot which possesses manipulators. The task of the robot is to carry a polygonal object from a starting point to a destination point in a possibly culttered environment. In most of the existing research on robot path planning, a mobile robot is approximated by a fixed shape, i.e., a circle or a polygon. In our task planner, the robot is allowed to change configurations for avoiding collision. This path planner operates using two algorithms: the collision-free feasible configuration finding algorithm and the collision-free path finding algorithm. The collision-free feasible configuration finding algorithm finds all collision-free feasible configurations for the robot when the position of the carried object is given. The collision-free path finding algorithm generates some candidate paths first and then uses a graph search method to find a collision-free path from all the collision-free feasible configurations along the candidate paths. The proposed algorithms can deal with a cluttered environment and is guaranteed to find a solution if one exists.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00339662,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00339665,Perception-based learning for motion in contact in task planning,Journal of Intelligent and Robotic Systems,10.1007/BF00339665,Springer,1996-11-01,"This paper presents a new approach to error detection during motion in contact under uncertainty for robotic manufacturing tasks. In this approach, artificial neural networks are used for perception-based learning. The six force-and-torque signals from the wrist sensor of a robot arm are fed into the network. A self-organizing map is what learns the different contact states in an unsupervised way. The method is intended to work properly in complex real-world manufacturing environments, for which existent approaches based on geometric analytical models may not be feasible, or may be too difficult. It is used for different tasks involving motion in contact, particularly the peg-in-hole insertion task, and complex insertion or extraction operations in a flexible manufacturing system. Several real examples for these cases are presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00339665,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00127677,"Collaborative Research Centre “Situated Artificial Communicators” at the University of Bielefeld, Germany",Artificial Intelligence Review,10.1007/BF00127677,Springer,1996-08-01,"The Collaborative Research Centre “Situated Artificial Communicators” (SFB 360) is employed in modelling that which a person performs when, with a partner, he cooperatively solves a simple assembly task in a certain situation. Acoustic perception of the spoken word, visual perception of the partner and the objects and processes involved in the situation, understanding of that perceived, the formulation of own utterances, e.g. instructions to the partner, and the planning and performance of actions belong to these intelligence abilities. The theme of the Collaborative Research Centre SFB 360, in which Linguistics, Cognitive Science and Artificial Intelligence are closely entwined, is unique in this form. The scientific headquarters at the University of Bielefeld, in North Rhine Westphalia, Germany, has succeeded in entering a field of research which, in the trend of the growing importance of intelligent information systems, is a decisive factor for technical innovation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00127677,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00245422,A real-time planning algorithm for obstacle avoidance of redundant robots,Journal of Intelligent and Robotic Systems,10.1007/BF00245422,Springer,1996-07-01,"A computationally efficient, obstacle avoidance algorithm for redundant robots is presented in this paper. This algorithm incorporates the neural networks and pseudodistance function D _p in the framework of resolved motion rate control. Thus, it is well suited for real-time implementation. Robot arm kinematic control is carried out by the Hopfield network. The connection weights of the network can be determined from the current value of Jacobian matrix at each sampling time, and joint velocity commands can be generated from the outputs of the network. The obstacle avoidance task is achieved by formulating the performance criterion as D _p> d _min ( d _min represents the minimal distance between the redundant robot and obstacles). Its calculation is only related to some vertices which are used to model the robot and obstacles, and the computational times are nearly linear in the total number of vertices. Several simulation cases for a four-link planar manipulator are given to prove that the proposed collision-free trajectory planning scheme is efficient and practical.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00245422,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1018276705188,Performance Improvement of Robot Continuous-Path Operation through Iterative Learning Using Neural Networks,Machine Learning,10.1023/A:1018276705188,Springer,1996-05-01,"In this article, an approach to improving the performance of robot continuous-path operation is proposed. This approach utilizes a multilayer feedforward neural network to compensate for model uncertainty associated with the robotic operation. Closed-loop stability and performance are analyzed. It is shown that the closed-loop system is stable in the sense that all signals are bounded: it is further proved that the performance of the closed-loop system is improved in the sense that certain error measure of the closed-loop system decreases as the network learning process is iterated. These analytical results are confirmed by computer simulation. The effectiveness of the proposed approach is demonstrated through a laboratory experiment.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1018276705188,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00309655,Back-propagation neural networks for identification and control of a direct drive robot,Journal of Intelligent and Robotic Systems,10.1007/BF00309655,Springer,1996-05-01,"A neural approach is proposed to estimate parameters in dynamics of a direct drive robot. Before the estimation, the input-output data for identification are generated in a sequential and term-by-term manner first. Then a two-layer neural network for parameter identification is proposed, in which the back-propagation training method is used to adjust the weights between neurons. The goal is to find the weights that minimize the root-mean-square error between the identification data and output of the network. With the estimated dynamics, existing trajectory-tracking algorithms, such as the well-known computed-torque method, can then be applied to make the robot move along a desired trajectory.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00309655,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00117444,Performance improvement of robot continuous-path operation through iterative learning using neural networks,Machine Learning,10.1007/BF00117444,Springer,1996-05-01,"In this article, an approach to improving the performance of robot continuous-path operation is proposed. This approach utilizes a multilayer feedforward neural network to compensate for model uncertainty associated with the robotic operation. Closed-loop stability and performance are analyzed. It is shown that the closed-loop system is stable in the sense that all signals are bounded; it is further proved that the performance of the closed-loop system is improved in the sense that certain erro measure of the closed-loop system decreases as the network learning process is iterated. These analytical results are confirmed by computer simulation. The effectiveness of the proposed approach is demonstrated through a laboratory experiment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00117444,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1018237008823,Purposive Behavior Acquisition for a Real Robot by Vision-Based Reinforcement Learning,Machine Learning,10.1023/A:1018237008823,Springer,1996-05-01,"This paper presents a method of vision-based reinforcement learning by which a robot learns to shoot a ball into a goal. We discuss several issues in applying the reinforcement learning method to a real robot with vision sensor by which the robot can obtain information about the changes in an environment. First, we construct a state space in terms of size, position, and orientation of a ball and a goal in an image, and an action space is designed in terms of the action commands to be sent to the left and right motors of a mobile robot. This causes a state-action deviation problem in constructing the state and action spaces that reflect the outputs from physical sensors and actuators, respectively. To deal with this issue, an action set is constructed in a way that one action consists of a series of the same action primitive which is successively executed until the current state changes. Next, to speed up the learning time, a mechanism of Learning from Easy Missions (or LEM) is implemented. LEM reduces the learning time from exponential to almost linear order in the size of the state space. The results of computer simulations and real robot experiments are given.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1018237008823,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00117447,Purposive behavior acquisition for a real robot by vision-based reinforcement learning,Machine Learning,10.1007/BF00117447,Springer,1996-05-01,"This paper presents a method of vision-based reinforcement learning by which a robot learns to shoot a ball into a goal. We discuss several issues in applying the reinforcement learning method to a real robot with vision sensor by which the robot can obtain information about the changes in an environment. First, we construct a state space in terms of size, position, and orientation of a ball and a goal in an image, and an action space is designed in terms of the action commands to be sent to the left and right motors of a mobile robot. This causes a “state-action deviation” problem in constructing the state and action spaces that reflect the outputs from physical sensors and actuators, respectively. To deal with this issue, an action set is constructed in a way that one action consists of a series of the same action primitive which is successively executed until the current state changes. Next, to speed up the learning time, a mechanism of Learning from Easy Missions (or LEM) is implemented. LEM reduces the learning time from exponential to almost linear order in the size of the state space. The results of computer simulations and real robot experiments are given.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00117447,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1018274104280,Real-World Robotics: Learning to Plan for Robust Execution,Machine Learning,10.1023/A:1018274104280,Springer,1996-05-01,"In executing classical plans in the real world, small discrepancies between a planner's internal representations and the real world are unavoidable. These can conspire to cause real-world failures even though the planner is sound and, therefore, proves that a sequence of actions achieves the goal. Permissive planning, a machine learning extension to classical planning, is one response to this difficulty. This paper describes the permissive planning approach and presents GRASPER, a permissive planning robotic system that learns to robustly pick up novel objects.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1018274104280,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00117442,Real-world robotics: Learning to plan for robust execution,Machine Learning,10.1007/BF00117442,Springer,1996-05-01,"In executing classical plans in the real world, small discrepancies between a planner's internal representations and the real world are unavoidable. These can conspire to cause real-world failures even though the planner is sound and, therefore, “proves” that a sequence of actions achieves the goal. Permissive planning, a machine learning extension to classical planning, is one response to this difficulty. This paper describes the permissive planning approach and presents GRASPER, a permissive planning robotic system that learns to robustly pick up novel objects.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00117442,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00117445,Learning controllers for industrial robots,Machine Learning,10.1007/BF00117445,Springer,1996-05-01,"One of the most significant cost factors in robotics applications is the design and development of real-time robot control software. Control theory helps when linear controllers have to be developed, but it doesn't sufficiently support the generation of non-linear controllers, although in many cases (such as in compliance control), nonlinear control is essential for achieving high performance. This paper discusses how Machine Learning has been applied to the design of (non-)linear controllers. Several alternative function approximators, including Multilayer Perceptrons (MLP), Radial Basis Function Networks (RBFNs), and Fuzzy Controllers are analyzed and compared, leading to the definition of two major families: Open Field Function Approximators and Locally Receptive Field Function Approximators. It is shown that RBFNs and Fuzzy Controllers bear strong similarities, and that both have a symbolic interpretation. This characteristic allows for applying both symbolic and statistic learning algorithms to synthesize the network layout from a set of examples and, possibly, some background knowledge. Three integrated learning algorithms, two of which are original, are described and evaluated on experimental test cases. The first test case is provided by a robot KUKA IR-361 engaged into the “peg-into-hole” task, whereas the second is represented by a classical prediction task on the Mackey-Glass time series. From the experimental comparison, it appears that both Fuzzy Controllers and RBFNs synthesised from examples are excellent approximators, and that, in practice, they can be even more accurate than MLPs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00117445,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1018228822027,Learning Controllers for Industrial Robots,Machine Learning,10.1023/A:1018228822027,Springer,1996-05-01,"One of the most significant cost factors in robotics applications is the design and development of real-time robot control software. Control theory helps when linear controllers have to be developed, but it doesn't sufficiently support the generation of non-linear controllers, although in many cases (such as in compliance control), nonlinear control is essential for achieving high performance. This paper discusses how Machine Learning has been applied to the design of (non-)linear controllers. Several alternative function approximators, including Multilayer Perceptrons (MLP), Radial Basis Function Networks (RBFNs), and Fuzzy Controllers are analyzed and compared, leading to the definition of two major families: Open Field Function Approximators and Locally Receptive Field Function Approximators. It is shown that RBFNs and Fuzzy Controllers bear strong similarities, and that both have a symbolic interpretation. This characteristic allows for applying both symbolic and statistic learning algorithms to synthesize the network layout from a set of examples and, possibly, some background knowledge. Three integrated learning algorithms, two of which are original, are described and evaluated on experimental test cases. The first test case is provided by a robot KUKA IR-361 engaged into the peg-into-hole task, whereas the second is represented by a classical prediction task on the Mackey-Glass time series. From the experimental comparison, it appears that both Fuzzy Controllers and RBFNs synthesised from examples are excellent approximators, and that, in practice, they can be even more accurate than MLPs.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1018228822027,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00437603,Impedance control with on-line neural-network compensator for robot contact tasks,Journal of Intelligent and Robotic Systems,10.1007/BF00437603,Springer,1996-04-01,"In this paper, a force-tracking impedance controller with an on-line neural-network compensator is shown to be able to track a reference force in the presence of unknown environmental dynamics. The controller can be partitioned into three parts. The computed torque method is used to linearize and decouple the dynamics of a manipulator. An impedance controller is then added to regulate the mechanical impedance between the manipulator and its environment. In order to track a reference force signal, an on-line neural network is used to compensate the effect of unknown parameters of the manipulator and environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00437603,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00437601,Artificial neural network based robot control: An overview,Journal of Intelligent and Robotic Systems,10.1007/BF00437601,Springer,1996-04-01,The current thrust of research in robotics is to build robots which can operate in dynamic and/or partially known environments. The ability of learning endows the robot with a form of autonomous intelligence to handle such situations. This paper focuses on the intersection of the fields of robot control and learning methods as represented by artificial neural networks. An in-depth overview of the application of neural networks to the problem of robot control is presented. Some typical neural network architectures are discussed first. The important issues involved in the study of robotics are then highlighted. This paper concentrates on the neural network applications to the motion control of robots involved in both non-contact and contact tasks. The current state of research in this area is surveyed and the strengths and weakness of the present approaches are emphasized. The paper concludes by indentifying areas which need future research work.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00437601,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4613-0471-5_1,Introduction,Recent Advances in Robot Learning,10.1007/978-1-4613-0471-5_1,Springer,1996-01-01,"This special issue contains seven papers on robot learning written by leading researchers in the field. As the selection of papers illustrates, the field of robot learning is both active and diverse. A variety of machine learning methods, ranging from inductive logic programming to reinforcement learning, is being applied to many subproblems in robot perception and control, often with objectives as diverse as parameter calibration or concept formation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4613-0471-5_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00435721,A neural network based adaptive robot controller,Journal of Intelligent and Robotic Systems,10.1007/BF00435721,Springer,1996-01-01,Neural network based adaptive controllers have been shown to achieve much improved accuracy compared with traditional adaptive controllers when applied to trajectory tracking in robot manipulators. This paper describes a new Recursive Prediction Error technique for estimating network parameters which is more computationally efficient. Results show that this neural controller suppresses disturbances accurately and achieves very small errors between commanded and actual trajectories.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00435721,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-1021-7_67,Hybrid Robots Consisting of Mechanical Parts and Living Organisms for Microrobot Application,Robotics Research,10.1007/978-1-4471-1021-7_67,Springer,1996-01-01,"Structure of a 1 mm long microrobot that is our final goal may be different from that of a conventional robot due to scale effects. For example, rotational joints do not work well in microrobots because friction becomes dominant compared to gravity. Since insects have obtained suitable structures and functions for their scale through natural selection, they are good models for microrobots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-1021-7_67,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4613-0471-5_4,Performance Improvement of Robot Continuous-Path Operation through Iterative Learning Using Neural Networks,Recent Advances in Robot Learning,10.1007/978-1-4613-0471-5_4,Springer,1996-01-01,"In this article, an approach to improving the performance of robot continuous-path operation is proposed. This approach utilizes a multilayer feedforward neural network to compensate for model uncertainty associated with the robotic operation. Closed-loop stability and performance are analyzed. It is shown that the closed-loop system is stable in the sense that all signals are bounded; it is further proved that the performance of the closed-loop system is improved in the sense that certain error measure of the closed-loop system decreases as the network learning process is iterated. These analytical results are confirmed by computer simulation. The effectiveness of the proposed approach is demonstrated through a laboratory experiment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4613-0471-5_4,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4613-0471-5_7,Purposive Behavior Acquisition for a Real Robot by Vision-Based Reinforcement Learning,Recent Advances in Robot Learning,10.1007/978-1-4613-0471-5_7,Springer,1996-01-01,"This paper presents a method of vision-based reinforcement learning by which a robot learns to shoot a ball into a goal. We discuss several issues in applying the reinforcement learning method to a real robot with vision sensor by which the robot can obtain information about the changes in an environment. First, we construct a state space in terms of size, position, and orientation of a ball and a goal in an image, and an action space is designed in terms of the action commands to be sent to the left and right motors of a mobile robot. This causes a “state-action deviation” problem in constructing the state and action spaces that reflect the outputs from physical sensors and actuators, respectively. To deal with this issue, an action set is constructed in a way that one action consists of a series of the same action primitive which is successively executed until the current state changes. Next, to speed up the learning time, a mechanism of Learning from Easy Missions (or LEM) is implemented. LEM reduces the learning time from exponential to almost linear order in the size of the state space. The results of computer simulations and real robot experiments are given.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4613-0471-5_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-009-1716-3_2,"Collaborative Research Centre “Situated Artificial Communicators” at the University of Bielefeld, Germany",Integration of Natural Language and Vision Processing,10.1007/978-94-009-1716-3_2,Springer,1996-01-01,"The Collaborative Research Centre “Situated Artificial Communicators” (SFB 360) is employed in modelling that which a person performs when, with a partner, he cooperatively solves a simple assembly task in a certain situation. Acoustic perception of the spoken word, visual perception of the partner and the objects and processes involved in the situation, understanding of that perceived, the formulation of own utterances, e.g. instructions to the partner, and the planning and performance of actions belong to these intelligence abilities. The theme of the Collaborative Research Centre SFB 360, in which Linguistics, Cognitive Science and Artificial Intelligence are closely entwined, is unique in this form. The scientific headquarters at the University of Bielefeld, in North Rhine Westphalia, Germany, has succeeded in entering a field of research which, in the trend of the growing importance of intelligent information systems, is a decisive factor for technical innovation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-009-1716-3_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-60923-7_30,Multiagent coordination with learning classifier systems,Adaption and Learning in Multi-Agent Systems,10.1007/3-540-60923-7_30,Springer,1996-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-60923-7_30,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-61732-9_52,Programming by demonstration: A machine learning approach to support skill acquision for robots,Artificial Intelligence and Symbolic Mathematical Computation,10.1007/3-540-61732-9_52,Springer,1996-01-01,"Programming by Demonstration (PbD) is a programming method that allows to add new functionalities to a system by simply showing the desired task or skill in form of few examples. In the domain of robotics this paradigm offers the potential to reduce the complexity of robot task programming and to make programming more ”natural”. In case of programming an assembly task PbD allows with the help of a video or a laser camera and a data glove the automatic generation the necessary robot program for the assembly task. In addition, the demonstration of the task with few different assembly situations and strategies may achieve a generalized assembly function for all possible variants of the class. In order to realize such a PbD system at least two major problems have to be solved. First, the sensor data trace of a demonstration has to be interpreted and transformed into a high-level situation-action representation. This task is not yet well understood nor solved in general. Second, if a generalization is required, induction algorithms must be applied to the sensor data trace, to find the most general user-intended robot function from only few examples. In this paper mainly the second problem is focused. The described experimental PbD environment consists of an industrial robot, a 6D space mouse used as input device, and some sensors. Various data can be recorded during a demonstration for further processing in the PbD system implemented on a workstation. The objective is to exploit the possibilities of integrating learning and clustering algorithms for automated robot programming. In particular it is investigated how human interaction with the PbD system as well as user-initiated dialogs can support inductive learning to acquire generalized assembly programs and skills.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-61732-9_52,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-009-1639-5_5,Language and Vision: A Single Perceptual Mechanism?,Integration of Natural Language and Vision Processing,10.1007/978-94-009-1639-5_5,Springer,1996-01-01,"Independent work on cognitive models of visual perception and of perception of lexical items reveals a common framework underlying the two sets of cognitive mechanisms posited. From these two classes of model — one visual and the other linguistic — a unifying structure has been extracted. The integrated model is presented, discussed, and some general implications for the notion of unified theories of visual and linguistic perception are considered. In particular, we are able to demonstrate a similar structuring of contextual, or top-down, information, and a similar pattern of interplay between serial and parallel processes as well as between top-down and bottom-up information. In addition, several common problems, such as the role of ‘value’ parameters in perception, are identified.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-009-1639-5_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4613-0471-5_2,Real-World Robotics: Learning to Plan for Robust Execution,Recent Advances in Robot Learning,10.1007/978-1-4613-0471-5_2,Springer,1996-01-01,"In executing classical plans in the real world, small discrepancies between a planner’s internal representations and the real world are unavoidable. These can conspire to cause real-world failures even though the planner is sound and, therefore, “proves” that a sequence of actions achieves the goal. Permissive planning, a machine learning extension to classical planning, is one response to this difficulty. This paper describes the permissive planning approach and presents GRASPER, a permissive planning robotic system that learns to robustly pick up novel objects.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4613-0471-5_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/BFb0013966,Neural network applications in sensor fusion for an autonomous mobile robot,Reasoning with Uncertainty in Robotics,10.1007/BFb0013966,Springer,1996-01-01,"In this article, we propose a generic architecture for sensor data fusion and argue that the central issue in such an approach is the choice of a suitable representation of the robot's environment. We argue that for the navigation task a robot-centered discrete probabilistic representation (an occupancy grid) is a suitable choice. If such a representation is used, the two key problems are how to transform such representations upon robot motion and how to represent the sensor's error characteristics (the sensor model) in such a representation. For both these problems, solutions are suggested by the application of neural network theory, and it is argued that these neural networks are the best available alternatives.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BFb0013966,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-61108-8_40,An artificial life approach for the synthesis of autonomous agents,Artificial Evolution,10.1007/3-540-61108-8_40,Springer,1996-01-01,"This paper describes an evolutionary process producing dynamical neural networks used as “brains” for autonomous agents. The main concepts used: genetic algorithms, morphogenesis process, artificial neural networks and artificial metabolism, illustrate our conviction that some fundamental principles of nature may help to design processes from which emerge artificial autonomous agents. The evolutionary process presented here is applied to a simulated autonomous robot. The resulting neural networks are then embedded on a real mobile robot. We emphasize the role of the artificial metabolism and the role of the environment which appear to be the motors of evolution. The first results observed are encouraging and motivate a deeper investigation of this research area.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-61108-8_40,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-1021-7_32,Perception and Manipulation in Robotics: Neural Network Approaches,Robotics Research,10.1007/978-1-4471-1021-7_32,Springer,1996-01-01,Learning and adaptation are the core paradigms of intelligent control concepts which enable to increase skilled manipulation and to achieve higher levels of autonomy. Data approximation and representation techniques like neural networks enhance or replace conventional model based approaches. We apply neural networks in two significant fields of robotics research: Perception and Manipulation. This paper provides an overview of neural network applications in robotics we developed in our lab.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-1021-7_32,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-61093-6_6,Evolvable Hardware and its application to pattern recognition and fault-tolerant systems,Towards Evolvable Hardware,10.1007/3-540-61093-6_6,Springer,1996-01-01,"This paper describes Evolvable Hardware (EHW) and its applications to pattern recognition and fault-torelant systems. EHW can change its own hardware structure to adapt to the environment whenever environmental changes (including hardware malfunction) occur. EHW is implemented on a PLD(Programmable Logic Device)-like device whose architecture can be altered by re-programming the architecture bits. Through genetic algorithms, EHW finds the architecture bits which adapt best to the environment, and changes its hardware structure accordingly. Two applications are described: the the pattern recognitionsystem and the V-shape ditch tracer with fault-tolerant circuit. First we show the exclusive-OR circuit can be learned by EHW successfully. Then the pattern recognition system with EHW is described. The objective is to take the place of neural networks, solving its weakness such as readability of learned results and the execution speed. The results show that EHW works as a hard-wired pattern recognizer with such the robustness as neural nets. The second application is the V-shape ditch tracer as part of a prototypical welding robot. EHW works as the backup of the control logic circuit for the tracing, although the EHW is not given any information about the circuit. Once a hardware error occurs, EHW takes over the malfunctioning circuit.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-61093-6_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4613-0471-5_5,Learning Controllers for Industrial Robots,Recent Advances in Robot Learning,10.1007/978-1-4613-0471-5_5,Springer,1996-01-01,"One of the most significant cost factors in robotics applications is the design and development of real-time robot control software. Control theory helps when linear controllers have to be developed, but it doesn’t sufficiently support the generation of non-linear controllers, although in many cases (such as in compliance control), nonlinear control is essential for achieving high performance. This paper discusses how Machine Learning has been applied to the design of (non-)linear controllers. Several alternative function approximators, including Multilayer Perceptrons (MLP), Radial Basis Function Networks (RBFNs), and Fuzzy Controllers are analyzed and compared, leading to the definition of two major families: Open Field Function Approximators and Locally Receptive Field Function Approximators. It is shown that RBFNs and Fuzzy Controllers bear strong similarities, and that both have a symbolic interpretation. This characteristic allows for applying both symbolic and statistic learning algorithms to synthesize the network layout from a set of examples and, possibly, some background knowledge. Three integrated learning algorithms, two of which are original, are described and evaluated on experimental test cases. The first test case is provided by a robot KUKA IR-361 engaged into the “peg-into-hole” task, whereas the second is represented by a classical prediction task on the Mackey-Glass time series. From the experimental comparison, it appears that both Fuzzy Controllers and RBFNs synthesised from examples are excellent approximators, and that, in practice, they can be even more accurate than MLPs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4613-0471-5_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00993591,The parti-game algorithm for variable resolution reinforcement learning in multidimensional state-spaces,Machine Learning,10.1007/BF00993591,Springer,1995-12-01,"Parti-game is a new algorithm for learning feasible trajectories to goal regions in high dimensional continuous state-spaces. In high dimensions it is essential that neither planning nor exploration occurs uniformly over a state-space. Parti-game maintains a decision-tree partitioning of state-space and applies techniques from game-theory and computational geometry to efficiently and adaptively concentrate high resolution only on critical areas. The current version of the algorithm is designed to find feasible paths or trajectories to goal regions in high dimensional spaces. Future versions will be designed to find a solution that optimizes a real-valued criterion. Many simulated problems have been rested, ranging from two-dimensional to nine-dimensional state-spaces, including mazes, path planning, non-linear dynamics, and planar snake robots in restricted spaces. In all cases, a good solution is found in less than ten trials and a few minutes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00993591,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1022656217772,The Parti-game Algorithm for Variable Resolution Reinforcement Learning in Multidimensional State-spaces,Machine Learning,10.1023/A:1022656217772,Springer,1995-12-01,"Parti-game is a new algorithm for learning feasible trajectories to goal regions in high dimensional continuous state-spaces. In high dimensions it is essential that neither planning nor exploration occurs uniformly over a state-space. Parti-game maintains a decision-tree partitioning of state-space and applies techniques from game-theory and computational geometry to efficiently and adaptively concentrate high resolution only on critical areas. The current version of the algorithm is designed to find feasible paths or trajectories to goal regions in high dimensional spaces. Future versions will be designed to find a solution that optimizes a real-valued criterion. Many simulated problems have been tested, ranging from two-dimensional to nine-dimensional state-spaces, including mazes, path planning, non-linear dynamics, and planar snake robots in restricted spaces. In all cases, a good solution is found in less than ten trials and a few minutes.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1022656217772,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF01258354,Diagnostic neural adaptive control of drifting systems,Journal of Intelligent and Robotic Systems,10.1007/BF01258354,Springer,1995-11-01,"A hierarchical network of neural network planning and control is employed to successfully accomplish a task such as grasping in a cluttered real world environment. In order for the individual robot joint controllers to follow their specific reference commands, information is shared with other neural network controllers and planners within the hierarchy. Each joint controller is initialized with weights that will acceptably control given a change in any of several crucial parameters across a broad operating range. When increased accuracy is needed as parameters drift, the diagnostic node fuzzy supervisor interprets the controller network's diagnostic outputs and transitions the weights to a closest fit specific child controller. Future reference commands are in turn influenced by the diagnostic outputs of every robot joint neural network controller. The neural network controller and diagnostics are demonstrated for linear and nonlinear plants.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF01258354,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00849041,Language and vision: A single perceptual mechanism?,Artificial Intelligence Review,10.1007/BF00849041,Springer,1995-10-01,"Independent work on cognitive models of visual perception and of perception of lexical items reveals a common framework underlying the two sets of cognitive mechanisms posited. From these two classes of model — one visual and the other linguistic — a unifying structure has been extracted. The integrated model is presented, discussed, and some general implications for the notion of unified theories of visual and linguistic perception are considered. In particular, we are able to demonstrate a similar structuring of contextual, or top-down, information, and a similar pattern of interplay between serial and parallel processes as well as between top-down and bottom-up information. In addition, several common problems, such as the role of ‘value’ parameters in perception, are identified.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00849041,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF01262965,Neural net robot controller: Structure and stability proofs,Journal of Intelligent and Robotic Systems,10.1007/BF01262965,Springer,1995-10-01,"A multilayer neural net (NN) controller for a general serial-link robot arm is developed. The structure of the NN controller is derived using a filtered error approach. It is argued that standard backpropagation tuning, when used for real-time closed-loop control, can yield unbounded NN weights if: (1) the net can not exactly reconstruct a certain required control function, (2) there are bounded unknown disturbances in the robot dynamics, or (3) the robot arm has more than one link (i.e. nonlinear case). On-line weight tuning algorithms including correction terms to backpropagation, plus an added robustifying signal, guarantee tracking as well as bounded weights. The correction terms involve a second-order forward-propagated wave in the backprop network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF01262965,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF01418982,Discrete event modeling of visually guided behaviors,International Journal of Computer Vision,10.1007/BF01418982,Springer,1995-03-01,"When visual behaviors are combined to provide a specific functionality needed for a task, the combination is often based on heuristic rules. In this article we show that by adopting the Discrete-Event Systems (DES) formalism for describing the interaction between visual behaviors it is possible to provide systems that have well-defined properties in terms of observability and controllability. The method is in particular suited for describing the coupling between action and perception. An introduction to the use of DES is provided and it is demonstrated how DES are used for modeling behaviors and controlling a mobile robot equipped with a binocular camera head and some additional sensors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF01418982,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00993825,A reply to Towell's book review of Neural Network Perception for Mobile Robot Guidance,Machine Learning,10.1007/BF00993825,Springer,1995-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00993825,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-59497-3_281,Neural approaches to robot control: Four representative applications,From Natural to Artificial Neural Computation,10.1007/3-540-59497-3_281,Springer,1995-01-01,"This paper reviews neural network techniques for achieving adaptivity in both manipulator and mobile robots. It is structured in two parts. First, the different learning approaches are classified according to the amount of training information they require: quantitative (supervised approaches), qualitative (reinforcement-based approaches) and none (unsupervised approaches). Afterwards, the adequacy of each approach for solving specific problems in robot control is illustrated through four working industrial prototypes developed by the authors in the frame of two Esprit projects. The problems tackled are the inverse kinematics and inverse dynamics of robot manipulators, visual robot positioning and mobile robot navigation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-59497-3_281,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-59496-5_327,Evaluation of learning performance of situated embodied agents,Advances in Artificial Life,10.1007/3-540-59496-5_327,Springer,1995-01-01,"This paper discusses the complexities of designing and evaluating Alife learning systems using physical robots interacting in complex, dynamic environments. We use the learning data from two different implemented multi-robot learning systems to illustrate the difficulties with traditional “objective” methods of evaluation. We then describe the methods we used to evaluate the behavior of such learning systems in order to preserve its dynamics and demonstrate their effect on the performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-59496-5_327,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-7091-7535-4_23,From the Chromosome to the Neural Network,Artificial Neural Nets and Genetic Algorithms,10.1007/978-3-7091-7535-4_23,Springer,1995-01-01,A proposal for a model of morphogenesis process taking inspiration from biology is presented in this paper. This process uses a chromosome as a production system to create an artificial neural network. It starts with a single cell containing the chromosome. Cells can divide and establish connections among them. Both structure and weights of the neural network are defined by the morphogenesis process. An application to a neural network driving an autonomous mobile robot is presented which exhibits encouraging first results.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7091-7535-4_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-017-0663-6_23,Identification of Constrained Robot Dynamics Using Dynamic Neural Networks,Advances in Stochastic Modelling and Data Analysis,10.1007/978-94-017-0663-6_23,Springer,1995-01-01,"It is nowadays well known that neural networks can model nonlinear dynamical systems. This paper solves an identification problem of a robot manipulator which is moving on a constraint surface, by using dynamical neural networks. More explicitly we use Differential/Algebraic Recurrent High Order Neural Networks (D/A-RHONNs) with a learning algorithm which is based on Lyapunov stability theory. The network consists of a combination of differential algebraic equations, and this property makes it effective in identifying nonlinear differential/algebraic systems. Simulation results demonstrate the applicability of the approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-017-0663-6_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00993824,"Neural network perception for mobile robot guidance by Dean A. Pomerleau. Kluwer Academic Publishers, 1993",Machine Learning,10.1007/BF00993824,Springer,1995-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00993824,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1022878708705,"
              Book Review:
              Neural Network Perception For Mobile Robot Guidance
              by Dean A. Pomerleau. Kluwer Academic Publishers, 1993
            ",Machine Learning,10.1023/A:1022878708705,Springer,1995-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1022878708705,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1022830825544,"A Reply to Towell's Book Review of Neural Network Perception for Mobile Robot Guidance
",Machine Learning,10.1023/A:1022830825544,Springer,1995-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1022830825544,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-3087-1_25,A visually guided robot and a neural network join to grasp slanted objects,Neural Networks: Artificial Intelligence and Industrial Applications,10.1007/978-1-4471-3087-1_25,Springer,1995-01-01,"In this paper we introduce a method for model-free monocular visual guidance of a robot arm. The robot arm, with a single camera in its end-effector, should be positioned above a target, with a changing pan and tilt, which is placed against a textured background. It is shown that a trajectory can be planned in visual space by using components of the optic flow, and this trajectory can be translated to joint torques by a self-learning neural network. No model of the robot, camera, or environment is used. The method reaches a high grasping accuracy after only a few trials.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-3087-1_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-79629-6_5,An Introduction to Reinforcement Learning,The Biology and Technology of Intelligent Autonomous Agents,10.1007/978-3-642-79629-6_5,Springer,1995-01-01,"This paper surveys the historical basis of reinforcement learning and some of the current work from a computer scientist’s point of view. It is an outgrowth of a number of talks given by the authors, including a NATO Advanced Study Institute and tutorials at AAAI’94 and Machine Learning’94. Reinforcement learning is a popular model of the learning problems that are encountered by an agent that learns behavior through trial-and-error interactions with a dynamic environment. It has a strong family resemblance to work in psychology, but differs considerably in the details and in the use of the word “reinforcement.” It is appropriately thought of as a class of problems, rather than as a set of techniques. The paper addresses a variety of subproblems in reinforcement learning, including exploration vs. exploitation, learning from delayed reinforcement, learning and using models, generalization and hierarchy, and hidden state. It concludes with a survey of some practical systems and an assessment of the practical utility of current reinforcement-learning systems",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-79629-6_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-0-387-34904-6_23,Virtual Prototyping Using Graphical Simulation and Advanced Programming Techniques,Virtual Prototyping,10.1007/978-0-387-34904-6_23,Springer,1995-01-01,"This paper presents a practical approach towards Virtual Prototyping. The fields of application are One-of-a-Kind products and industrial prototypes. The first example is taken from the problem area of typically high complex capital goods being virtually modelled and simulated prior to the real setting-up. The strategy of complimentarily developing both, the prototype’s mechanics and its functionality and the issues of concurrent and distributed team-work are characterised. Enabling technologies for the iterative setting-up of the real prototype are described with reference to practical experience. The second example is the virtual and the touchable prototyping of sheet metal parts, incorporating the FEM simulation of the process as well as the closed prototyping chain for a fast verification of the results. An enabling technology is the triangulation of parametric CAD surface models, a technique to represent random solid bodies as a polyedrical mesh, from which “real” and “virtual” prototypers will equally profit. The possibility to include surface data acquired by 3D measurement systems is also discussed. As a conclusion, the modelling of process chains is seen as an adequate approach to achieve better clarity in production as well as in the product development, describing actions and streams in between them. Their addition leads to a reference model for rapid product development and One-of-a-Kind Production, providing an abstract view of the various process chains in a neutral and logical manner. This is a necessity to reach the aim of production in the end of this century: “make just what is needed when it is needed”.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-0-387-34904-6_23,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-59497-3_278,A hierarchical neural network for mobile visual tracking with a robot head,From Natural to Artificial Neural Computation,10.1007/3-540-59497-3_278,Springer,1995-01-01,"Active vision and visual feedback intend to solve some of the problems arising in the development of robots with increasing autonomy. The so-called robot heads are excellent devices to implement and experiment the visual percepcion needed by these advanced robots. This paper presents some results obtained by using a robot head with two degrees of freedom for the automatic visual detection and tracking of mobiles. First a general description and setup of the problem is made, afterwards, a hierarchical neural network arquitecture for the solution of the visual tracking problem is proposed and described. Finally, the experimental results obtained with this novel solution are discussed and compared with the conventional recursive least-squares algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-59497-3_278,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-59496-5_338,Essential dynamical structure in learnable autonomous robots,Advances in Artificial Life,10.1007/3-540-59496-5_338,Springer,1995-01-01,"This paper studies the essential dynamical structure that arises in two different classes of learning of the sensory-based navigation, namely skill-based learning and model-based learning . In skill-based learning a robot learns navigational skills for a fixed navigational task such as homing , while in model-based learning a robot learns a model of the environment, then conducts planning on the model to reach an arbitrary goal. We formulated that the former is achieved by learning the state-action map, and the latter does by learning the forward model of the environment, using recurrent neural learning scheme. The analysis of the dynamical structure from the coupling of the internal neural dynamics and the environment showed that generation of the global attractor is crucial for both learning cases. Experiments were conducted using a mobile robot with a laser range sensor, which verified our assertions in a simple obstacle environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-59496-5_338,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-011-0305-3_11,Neural Networks in Robot Control,"Artificial Intelligence in Industrial Decision Making, Control and Automation",10.1007/978-94-011-0305-3_11,Springer,1995-01-01,"Neural nets (NNs) are large scale systems involving a large number of special type nonlinear processors called “neurons” [1–4]. Biological neurons are nerve cells that have a number of internal parameters called synaptic weights. The human brain consists of over ten million neurons. The weights are adjusted adaptively according to the task under execution such that to improve the overall system performance. Here we are dealing with artificial NNs the neurons of which are characterized by a state , a list of weighted inputs from other neurons, and an equation governing their dynamic operation. The NN weights can take new values through a learning process which is accomplished by the minimization of a certain objective function through the step-by-step adjustment of the weights. The optimal values of the weights are stored as the strengths of the neurons’ inteconnections. The NN approach to computation is suitable for problems for which more conventional computation approaches are not effective. Such problems involve systems or processes that cannot be modelled with concise and accurate mathematical expressions, typical examples being machine vision, speech and patern recognition, control systems and robotic systems. The implementation of NNs was made possible by the recent developments in fast parallel architectures (VLSI, electrooptical, and other). The principal features of NNs are: associative storage and retrieval signal regularity extraction convergence rate independent of number of nodes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-011-0305-3_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4471-3244-8_8,Robot Manipulator Control Using Neural Networks,"Neural Networks for Identification, Prediction and Control",10.1007/978-1-4471-3244-8_8,Springer,1995-01-01,The control of a multi-input-multi-output (MIMO) plant is a difficult problem when the plant is nonlinear and time-varying and there are dynamic interactions between the plant variables. A good example of such a plant is an articulated robot with two or more joints handling a changeable load.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-3244-8_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00872474,Reinforcement learning of iterative behaviour with multiple sensors,Applied Intelligence,10.1007/BF00872474,Springer,1994-10-01,"Reinforcement learning allows an agent to be both reactive and adaptive, but it requires a simple yet consistent representation of the task environment. In robotics this representation is the product of perception. Perception is a powerful simplifying mechanism because it ignores much of the complexity of the world by mapping multiple world states to each of a few representational states. The constraint of consistency conflicts with simplicity, however. A consistent representation distinguishes world states that have distinct utilities, but perception systems with sufficient acuity to do this tend to also make many unnecessary distinctions. In this paper we discuss reinforcement learning and the problem of appropriate perception. We then investigate a method for dealing with the problem, called the Lion algorithm [1], and show that it can be used to reduce complexity by decomposing perception. The Lion algorithm does not allow iterative rules to be learned, and we describe modifications that overcome this limitation. We present experimental results that demonstrate their effectiveness in further reducing complexity. Finally, we mention some related research, and conclude with suggestions for further work.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00872474,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00993274,Neural network-based vision for precise control of a walking robot,Machine Learning,10.1007/BF00993274,Springer,1994-05-01,"This article describes a connectionist vision system for the precise control of a robot designed to walk on the exterior of the space station. The network learns to use video camera input to determine the displacement of the robot's gripper relative to a hole in which the gripper must be inserted. Once trained, the network's output is used to control the robot, with a resulting factor of five fewer missed gripper insertions than occur when the robot walks without sensor feedback. The neural network visual feedback techniques described could also be applied in domains such as manufacturing, where precise robot positioning is required in an uncertain environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00993274,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1022617321232,Neural Network-Based Vision for Precise Control of a Walking Robot,Machine Learning,10.1023/A:1022617321232,Springer,1994-05-01,"This article describes a connectionist vision system for the precise control of a robot designed to walk on the exterior of the space station. The network learns to use video camera input to determine the displacement of the robot's gripper relative to a hole in which the gripper must be inserted. Once trained, the network's output is used to control the robot, with a resulting factor of five fewer missed gripper insertions than occur when the robot walks without sensor feedback. The neural network visual feedback techniques described could also be applied in domains such as manufacturing, where precise robot positioning is required in an uncertain environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1022617321232,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF01276703,Connectionist approaches to the control of manipulation robots at the executive hierarchical level: An overview,Journal of Intelligent and Robotic Systems,10.1007/BF01276703,Springer,1994-05-01,"One of the most interesting and important properties of connectionist systems is their ability to control sophisticated manipulation robots, i.e. to produce a large number of efficient control commands in real-time. This paper represents an attempt to give a comprehensive report of the basic principles and concepts of connectionism in robotics, with an outline of a number of recent algorithms used in learning control of a manipulation robot. A major concern in this paper is the application of neural networks for off-line and on-line learning of kinematic and dynamic relations used in robot control at the executive hierarchical level.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF01276703,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF03037343,An artificial brain ATR's CAM-Brain Project aims to build/evolve an artificial brain with a million neural net modules inside a trillion cell Cellular Automata Machine,New Generation Computing,10.1007/BF03037343,Springer,1994-03-01,"ATR's Evolutionary Systems Department aims to build (i.e. grow/evolve) an artificial brain by the year 2001. This artificial brain should initially contain thousands of interconnected artificial neural network modules, and be capable of controlling approximately 1000 “behaviors” in a “robot kitten”. The name given to this research project is “CAM-Brain”, because the neural networks (based on cellular automata) will be grown inside special hardware called Cellular Automata Machines (CAMs). Using a family of CAMs, each with its own processor to measure the performance quality or fitness of the evolved neural circuits, will allow the neural modules and their interconnections to be grown/evolved at electronic speeds. State of the art in CAM design is about 10 to the power 9 or 10 cells. Since a neural module of about 15 connected neurons can fit inside a cube of 100 cells on a side (1 million cells), a CAM which is specially adapted for CAM-Brain could contain thousands of interconnected modules, i.e. an artificial brain.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF03037343,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00735340,Building brains for bodies,Autonomous Robots,10.1007/BF00735340,Springer,1994-03-01,"We describe a project to capitalize on newly available levels of computational resources in order to understand human cognition. We are building an integrated physical system including vision, sound input and output, and dextrous manipulation, all controlled by a continuously operating large scale parallel MIMD computer. The resulting system will learn to “think” by building on its bodily experiences to accomplish progressively more abstract tasks. Past experience suggests that in attempting to build such an integrated system we will have to fundamentally change the way artificial intelligence, cognitive science, linguistics, and philosophy think about the organization of intelligence. We expect to be able to better reconcile the theories that will be developed with current work in neuroscience.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00735340,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00735344,Development of cutaneo-motor coordination in an autonomous robotic system,Autonomous Robots,10.1007/BF00735344,Springer,1994-03-01,"The capability of autonomously discovering relations between perceptual data and motor actions is crucial for the development of robust adaptive robotic systems intended to operate in an unknown environment. In the case of robotic tactile perception, a proper interaction between contact sensing and motor control is the basic step toward the execution of complex motor procedures such as grasping and manipulation. In this paper the autonomous development of cutaneo-motor coordination is investigated in the case of a robotic finger mounted on a robotic manipulator, for a particular class of micromovements. A neural network architecture linking changes in the sensed tactile pattern with the motor actions performed is described and experimental results are analyzed. Examples of application of the developed sensory-motor coordination in the generation of motor control procedures for the estimate of surface curvature are considered.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00735344,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-4-431-68275-2_9,Rule Generation and Generalization by Inductive Decision Tree and Reinforcement Learning,Distributed Autonomous Robotic Systems,10.1007/978-4-431-68275-2_9,Springer,1994-01-01,"In this paper, we attempt to construct a planning mechanism composed of distributed agents for autonomous vehicle navigation in an unknown workspace. Each agent decides a direction that the vehicle should move without any communication to the other agents, by only observing the workspace and the other agents. The agent includes the reinforcement learning mechanism for generating rules for the navigation. However, the rules depend on a state observation method. For generalizing the rules, an inductive decision tree is introduced to the agent. In a new workspace, the agent plans a path efficiently by learning a specific rule to the new workspace, and using the generalized rules. Some computational simulations have been carried out for verifying the proposed agent.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-4-431-68275-2_9,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/BFb0027599,Reinforcement learning of assembly robots,Experimental Robotics III,10.1007/BFb0027599,Springer,1994-01-01,"This paper presents a new approach to learning a compliance control law for robotic assembly tasks. In this approach, a task performance index of assembly operations is defined and the adaptive reinforcement learning algorithm [1] is applied for real-time learning. A simple box palletizing task is used as an example, where a robot is required to move a rectangular part to the corner of a box. In the experiment, the robot is initially provided with only predetermined velocity command to follow the nominal trajectory. However, at each attempt, the box is randomly located and the part is randomly oriented within the grasp of the end-effector. Therefore, compliant motion control is required to guide the part to the corner of the box while avoiding excessive reaction forces caused by the collision with a wall. After repeating failures in performing the task, the robot can successfully learn force feedback gains to modify its nominal motion. Our results show that the new learning method can be used to learn a compliance control law effectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BFb0027599,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF01257950,An iterative learning scheme for motion control of robots using neural networks: A case study,Journal of Intelligent and Robotic Systems,10.1007/BF01257950,Springer,1993-12-01,"In this paper, an iterative learning controller using neural networks has been studied for the motion control of robotic manipulators. Simulations of a two-link robot have demonstrated that the proposed control scheme for robotic manipulators can greatly reduce tracking errors after a few trials. Our modification of the original back-propagation algorithm is employed in the neural network, resulting in a much faster learning rate. The results of simulation have also shown that the proposed iterative learning controller has a faster rate of convergence and better robustness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF01257950,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF01469344,Trackability as a cue for potential obstacle identification and 3-D description,International Journal of Computer Vision,10.1007/BF01469344,Springer,1993-12-01,"In many man-made environments, obstacles in the path of a mobile robot can be characterized as shallow , that is, they have relatively small extent in depth compared to the distance from the camera. We present a framework for segmenting shallow structures from their background over a sequence of images. Shallowness is first quantified as affine describability . This is embedded in a tracking system within which hypothesized model structures undergo a cycle of prediction and model-matching. Structures emerge either as shallow or nonshallow based on their affine trackability . Two major contributions of this work are (i) aggregate object tracking based on 3-D motion and structure constraints in constrast with traditional primitive feature tracking based on image motion heuristics, and (ii) use of temporal behavior for object segmentation and 3-D reconstruction.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF01469344,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00872133,A comparison of failure-handling approaches for planning systems—Replanning vs. recovery,Applied Intelligence,10.1007/BF00872133,Springer,1993-12-01,"A planning process formulates action assignments for various agents to accomplish a goal statement. In a real situation, unexpected environmental changes (called failures) may invalidate the preformulated plan. When a failure occurs, effective and efficient handling procedures must be taken to prevent irreversible damages. A failure-handling mechanism is a key component in a fault-tolerant system, which makes autonomous operation possible. There are two basic approaches to failure handling—replanning and recovery. In the replanning approach, the currently failure-encountered state is treated as a new initial state, and a brand-new plan is derived from scratch. On the other hand, the recovery approach preserves the applicable components of the original plan and makes necessary adjustments to the preserved plan components to fit the new state. This article presents a method of achieving recovery and compares its performance with replanning. In general, the recovery approach provides a better response time, and the replanning approach sometimes provides a better plan quality.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00872133,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF01257949,Applications of neural networks for coordinate transformations in robotics,Journal of Intelligent and Robotic Systems,10.1007/BF01257949,Springer,1993-12-01,"The use of artificial neural networks is investigated for application to trajectory control problems in robotics. The relative merits of position versus velocity control is considered and a control scheme is proposed in which neural networks are used as static maps (trained off-line) to compute the inverse of the manipulator Jacobian matrix. A proof of the stability of this approach is offered, assuming bounded errors in the static map. A representative two-link robot is investigated using an artificial neural network which has been trained to compute the components of the inverse of the Jacobian matrix. The controller is implemented in the laboratory and its performance compared to a similar controller with the analytical inverse Jacobian matrix.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF01257949,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF01748631,Controlling a robot's position using neural networks,The International Journal of Advanced Manufacturing Technology,10.1007/BF01748631,Springer,1993-07-01,"In order to fully utilise the power of robots in factories, robot process capability (RPC) must be considered and improved. To improve the RPC in on-line processing by applying robot learning, the counterpropagation network was modified in this research. With two layers, the counterpropagation network was modified to control a robot's gross and fine motions. For the first layer, the network serves as a sensor-signal generator to control the gross motion. For the second layer, the network serves as a fine motion adjuster. Also, each layer can be separated functionally. By controlling both the gross and the fine motions, the RPC can then be improved. The modified two-layer counterpropagation network control scheme was validated by computer simulation and physical implementation on a RS-2200 robot system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF01748631,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF01748632,A formulation for collision identification and distance calculation in motion planning using neural networks,The International Journal of Advanced Manufacturing Technology,10.1007/BF01748632,Springer,1993-07-01,"The collision identification and object-to-object distance calculation play an important role in the motion planning for robots and manufacturing facilities. A formulation for collision identification and distance calculation in motion planning, using neural networks, is presented. The method calculates the distances between the vertices of an object and the given polyhedral obstacles using the modified Hamming net. This formulation is derived from the homogeneous geometric transformations. The method can be used to identify collision between the vertices of a moving object and the obstacles, to calculate the distance and interference between the moving object and the obstracle, and to find the optimal direction for collision removal. The parallel computation formulation is simple in form, and can be extended to line-to-object and object-to-object collision identification and distance calculation. The method can considerably decrease required computation time, and has the potential for being applied to on-line trajectory planning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF01748632,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-3184-5_8,"Real Robots, Real Learning Problems",Robot Learning,10.1007/978-1-4615-3184-5_8,Springer,1993-01-01,"The weaknesses of existing learning techniques, and the variety of knowledge necessary to make a robot perform efficiently in the real world, suggest that many concurrent, complementary, and redundant learning methods are necessary. We propose a division of learning styles into four main types based on the amount of built-in structure and the type of information being learned. Using this classification, we discuss the effectiveness of various learning methodologies when applied in a real robot context.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-3184-5_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-7091-7533-0_101,Circuits of Production Rule GenNets,Artificial Neural Nets and Genetic Algorithms,10.1007/978-3-7091-7533-0_101,Springer,1993-01-01,"A year ago, the author evolved a simulated artificial creature (biot, i.e. biological robot), called LIZZY, which consisted of fully connected neural network modules (called GenNets), whose weights were evolved such that each GenNet performed some desired behavior, such as making the biot walk straight ahead, turn clockwise or anticlockwise, peck, or mate [de Garis 1990, 1991, 1993]. Other such GenNets were evolved to detect sinusoidal frequencies, or signal strengths, or signal strength differences, etc. However, the middle layer, between the detector and the motion GenNets, was implemented with traditional symbolic production rules, for reasons of computer simulation speed. Every time a GenNet was added to the system, simulation speed dropped. This paper “completes” the above work, by proposing a model which shows how a circuit of production-rule-GenNets (i.e. GenNets which behave like production rules), can be evolved which implements the middle or “decisional” layer, which takes signals outputted from the detector GenNets, and then decides which motion GenNet should be switched on. This work takes a first step towards the evolution of whole nervous systems, where circuits of GenNet modules (of appropriate types) are evolved to give a biot a total behavioral performance repertoire.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7091-7533-0_101,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/BFb0019005,On discontinuous Q-Functions in reinforcement learning,GWAI-92: Advances in Artificial Intelligence,10.1007/BFb0019005,Springer,1993-01-01,"This paper considers the application of reinforcement learning to path finding tasks in continuous state space in the presence of obstacles. We show that cumulative evaluation functions (as Q-Functions [28] and V-Functions [4]) may be discontinuous if forbidden regions (as implied by obstacles) exist in state space. As the infinite number of states requires the use of function approximators such as backpropagation nets [16, 12, 24], we argue that these discontinuities imply severe difficulties in learning cumulative evaluation functions. The discontinuities we detected might also explain why recent applications of reinforcement learning systems to complex tasks [12] failed to show desired performance. In our conclusion, we outline some ideas to circumvent the problem.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BFb0019005,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-3192-0_1,Introduction,Neural Network Perception for Mobile Robot Guidance,10.1007/978-1-4615-3192-0_1,Springer,1993-01-01,"A truly autonomous robot must sense its environment and react appropriately. Previous mobile robot perception systems have relied on hand-coded algorithms for processing sensor information. In this book I describe techniques which enable artificial neural networks (ANNs) to learn the visual processing required for mobile robot guidance. The power and flexibility of these techniques are demonstrated in two domains, wheeled vehicle navigation, and legged robot foot positioning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-3192-0_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-56798-4_223,On-line performance enhancement of a behavioral neural network controller,New Trends in Neural Computation,10.1007/3-540-56798-4_223,Springer,1993-01-01,"We present a method to enhance the performance of a neural nework controller which learns to coordinate the behaviors of a real-time, autonomous mobile robot. The enhancement is achieved by defining several measures to evaluate the performance of the neural network controller. If the performance is adequate, we use the outputs of the neural network controller, otherwise we use a heuristic controller which is based on a rule-based methodology. Both, the neural network and heuristic controllers have been described elsewhere. The system is designed so that it exhibits the advantages of both controllers and minimizes their drawbacks. The implementation has been tested with OPMOR, a simulation environment for mobile robots and several results are presented. Portions of this work have been performed under the EEC ESPRIT 2483 PANORAMA Project.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-56798-4_223,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-2063-6_64,A Self-Organizing Neural Network for Robot Motion Planning,ICANN ’93,10.1007/978-1-4471-2063-6_64,Springer,1993-01-01,"The robot motion planning problem asks for determining a collision-free path for a robot moving amidst a fixed set of obstacles. In this paper we present an approach that combines an extended Kohonen network and deterministic techniques to solve this problem. The network constructs a graph of possible motions of the robot, which is then searched for a shortest path connecting given source and goal configurations. The method has been implemented and, compared to existing methods, achieved better results in typical planar motion planning problems. It can also be easily generalized to higherdimensional spaces.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-2063-6_64,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-7091-7533-0_64,EVOLVABLE HARDWARE Genetic Programming of a Darwin Machine,Artificial Neural Nets and Genetic Algorithms,10.1007/978-3-7091-7533-0_64,Springer,1993-01-01,"For the past three years, the author has been dreaming of the possibility of building machines which are capable of evolution, called “Darwin Machines”. As a result of several brain storming sessions with some colleagues in electrical engineering, the author now realizes that hardware devices are on the market today, which use “software configurable hardware” technologies that the author believes can be used to build Darwin Machines within a year or two. This paper suggests there are at least two approaches to be taken. The first approach uses “software configurable hardware” chips, e.g. FPGAs (Field Programmable Gate Arrays), HDPLDs (High Density Programmable Logic Devices), or possibly a new generation of chips based on the ideas that FPGAs etc embody. The second approach uses a special hardware device called a “hardware accelerator” which accelerates the simulation in software of digital hardware devices containing up to several hundred thousand gates. Darwin Machines will be essential if artificial nervous systems are to be evolved for biots (i.e. biological robots) which consist of thousands of evolved neural network modules (called GenNets). The evolution time of 1000-GenNet biots will need to be reduced by many orders of magnitude if they are to be built at all. It is for this reason that Darwin Machines may prove to be a breakthrough in biotic design. When molecular scale technologies come on line in the late 1990s, the Darwin Machine approach will probably be the only way to build self assembling, self testing molecular scale devices.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-7091-7533-0_64,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/BFb0031462,A basic concept of super rabbit,RoManSy 9,10.1007/BFb0031462,Springer,1993-01-01,"We have performed a basic research on a jumping robot — Super Rabbit — like a rabbit or a kangaroo aiming a dynamical walking robot. Normally, linear quadratic [LQ] control method has been used to the linear or linearized system. We propose the control method with the artificial neural network [ANN] and the modern control theory to realize more effective and stable control for the nonlinear system such as a one-legged locomotion robot. We have got a posture controller [LQ + ANN] for this super rabbit to take a dynamic stepping or jumping through the simulation after solving the equation of this system dynamics, Riccati equation and the neural network dynamics. Furthermore, we have proposed to incorporate a rhythm pattern generator using neural network corresponding to the animal (or biological) nervous system into the robot system, i.e., ""Rabbit robot"". Many animals including human learn the rhythmical motion pattern and generate these motion pattern unconsciously such as walking or jumping. This rhythm/central pattern generator [CPG] exists in the spinal cord or higher level central nervous system. In this paper, we also propose to incorporate CPG constructed with the ANN into the robot system to realize a self-organized learning mechanism. This super rabbit consists of a rigid body and foot. Each part is connected with a rotatable joint corresponding to the ankle. The torque around the ankle, which is given by the motor system, makes the super rabbit jump forward or backward. The motion of this robot consists of four modes. Mode_1 is the neutral state. Mode_2 is the beginning of jumping or stepping, when the center of gravity moves back or forth corresponding to the body angle. The velocity vector to take a step is generated by the torque around the ankle. Mode_3 is the jumping state in the air. Mode_4 is the posture control state at landing. The posture in the air (Mode_3) is detected by the optical sensor incorporated to the foot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BFb0031462,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-3184-5_5,Rapid Task Learning for Real Robots,Robot Learning,10.1007/978-1-4615-3184-5_5,Springer,1993-01-01,"For learning to be useful on real robots, whatever algorithm is used must converge in some “reasonable” amount of time. If each trial step takes on the order of seconds, a million steps would take several months of continuous run time. In many cases such extended runs are neither desirable nor practical. In this chapter we discuss how learning can be speeded up by exploiting properties of the task, sensor configuration, environment, and existing control structure.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-3184-5_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-3180-7_5,Application of Self-Organizing Neural Networks for Mobile Robot Environment Learning,Neural Networks in Robotics,10.1007/978-1-4615-3180-7_5,Springer,1993-01-01,"The application of the Kohonen self-organizing topology preserving neural network for learning and developing a minimal representation for the open environment for mobile robot navigation is presented in this paper. The input to the algorithm is the coordinates of randomly selected points in the open environment. No specific knowledge of the size, number, and shape of the obstacles is needed by the network. The parameter selection for the network is discussed and two illustrative examples are presented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-3180-7_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-3180-7_10,Modeling of Robot Dynamics by Neural Networks with Dynamic Neurons,Neural Networks in Robotics,10.1007/978-1-4615-3180-7_10,Springer,1993-01-01,"This paper presents a new method of modeling the complex nonlinear dynamics of a robotic system by the use of neural networks. The networks introduced here are neural nets with dynamic neurons, whose dynamics are distributed over all the network nodes. The nets are trained by the distributed dynamic back propagation algorithm. Networks with dynamic neurons are shown to perform much better than static nets in learning and predicting the nonlinear robot dynamics without any prior knowledge of the robot to be modeled.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-3180-7_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-3180-7_1,Learning Global Topological Properties of Robot Kinematic Mappings for Neural Network-based Configuration Control,Neural Networks in Robotics,10.1007/978-1-4615-3180-7_1,Springer,1993-01-01,"We examine the topology of the kinematics mapping and propose methods for resolving redundancy and the multiplicity of disjoint pre-image manifolds, resulting in a global regularization of the ill-posed inverse problem.. Reasonable assumptions about the kinematic mapping, based on the physical properties of a robot arm, are exploited to learn the global topology of the mapping. Heuristic algorithms are applied to the wristless Puma 560 and the 3-link planar arm. We show that the disjoint pre-image manifolds in the configuration space, each. corresponding to one of the multiple solution branches, can be identified with a high degree of precision by a combination of nearest-neighbor clustering with an adaptive classifier. We also show that one-dimensional pre-image manifolds may be parameterized in a consistent manner with topology-preserving neural networks. Thus the kinematic mapping can be globally regularized, and both the forward and inverse mappings can be completely learned. A non-linear function approximator such as a neural network can then be used to provide a solution to the inverse kinematics problem, allowing configuration control at a logical level.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-3180-7_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-3180-7_12,Parameter Learning and Compliance Control Using Neural Networks,Neural Networks in Robotics,10.1007/978-1-4615-3180-7_12,Springer,1993-01-01,"Many robotic systems would, in the future, be required to operate in environments that are highly uncertain and possessing means of self-actuation. In [ 30 ], the shortcomings of current control methods in dealing with such applications were elucidated, and a new robust control approach based on terminal sliding modes was introduced. In this paper, the problem of identifying uncertain environments for stable contact control is considered. For the purpose, neural networks originally developed using terminal attractor dynamics [ 37 ] are utilized. The specific learning rule [ 4 ], and the adjoint operator solutions to error propagation are motivated elsewhere [ 3 ]. In the sequel, neural networks are used for learning the dynamics of environment that a robot establishes contact with. In particular, system parameters are identified under the assumption that environment dynamics have a fixed nonlinear structure. A robotics research arm, placed in contact with a single dof electromechanical environment dynamics emulator, is commanded to move through a desired trajectory. The command is implemented using a compliant control strategy, where specified motion is biased with a compliance signal, generated based upon the error between desired and actual forces. The desired force is computed using neural network identified parameters, and desired motion trajectory. Results of compliance control experiments performed on robot hardware are described in detail, along with relevant discussions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-3180-7_12,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-3180-7_6,A Neural Network Based Inverse Kinematics Solution In Robotics,Neural Networks in Robotics,10.1007/978-1-4615-3180-7_6,Springer,1993-01-01,"This paper presents a new scheme to solve the inverse kinematics problem in Robotics by using the optimizability of the Hopfield network and the concept of the sliding mode control. Attention is given to the quality of the solution, to accommodating the redundant robots, and to the feasibility of using this scheme for Cartesian position control.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-3180-7_6,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-3180-7_16,Control of Grasping in Robot Hands by Neural Networks and Expert Systems,Neural Networks in Robotics,10.1007/978-1-4615-3180-7_16,Springer,1993-01-01,"Biologically-based approaches to the development of control techniques for multifingered robot hands are reviewed. Conventional algorithmic control is contrasted with control based on knowledge-based systems and neural networks. The development of an expert system for grasp control, which includes consideration of both object geometry and task, is described in detail. The chapter includes descriptions of neural network applications to the prediction of grasping in both human and robot hands.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-3180-7_16,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-3184-5_2,Knowledge-Based Training of Artificial Neural Networks for Autonomous Robot Driving,Robot Learning,10.1007/978-1-4615-3184-5_2,Springer,1993-01-01,"Many real world problems require a degree of flexibility that is difficult to achieve using hand programmed algorithms. One such domain is vision-based autonomous driving. In this task, the dual challenges of a constantly changing environment coupled with a real time processing constrain make the flexibility and efficiency of a machine learning system essential. This chapter describes just such a learning system, called ALVINN (Autonomous Land Vehicle In a Neural Network). It presents the neural network architecture and training techniques that allow ALVINN to drive in a variety of circumstances including single-lane paved and unpaved roads, multilane lined and unlined roads, and obstacle-ridden on-and off-road environments, at speeds of up to 55 miles per hour.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-3184-5_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-2063-6_50,Neural Networks for Robot Eye-Hand Coordination,ICANN ’93,10.1007/978-1-4471-2063-6_50,Springer,1993-01-01,"In this paper learning the eye-hand coordination with Artificial Neural Networks is discussed as well the requirements and relevance to its practical application. A system to position an endeffector in 3D to grasp objects with an eye-in-hand camera system is presented both in simulation and in practice. The accuracy is discussed in relation to the number of learning samples and the adaptation period. In particular when objects have to be tracked high demands are encountered for the vision system. A vision system is presented which is able to detect moving targets in a cluttered dynamically changing environment, based on a multi-resolution scale. In is shown that also dynamic visual information can be used to control the robot acceleration.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-2063-6_50,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/BFb0036138,Intelligent robot gripper for general purposes,Experimental Robotics II,10.1007/BFb0036138,Springer,1993-01-01,"In the past many different robot grippers have been developed to grasp one or a few specific objects. Those grippers are well suited for continuous work in structured environments and are thus employed for most of todays industrial applications. Some researchers, on the other hand, have focused their attention on sophisticated general purpose grippers with the dexterousness and kinematics similar to the human hand. This approach leads to mechanically refined but usually heavy and expensive grippers, which may be difficult to mount on a robot wrist. This paper presents another approach to the design and development of general purpose grippers. The basic idea is to integrate various taskdependent sensors with a mechanically still fairly simple gripper and combine it with an appropriate control software involving artificial-intelligence methods. This approach has led to the construction of the “COR-Gripper”* described in this paper. The gripper consists of three independent, parallel fingers and includes a force & torque sensor, tactile sensors as well as optical and ultrasonic proximity-sensors. It is currently mounted on a Puma 560, which is coupled to a vision system. The control-software is a combination of classical algorithms and AI-methods, such as neural networks. The latter is used to calculate the optimal finger-positions for grasping objects of arbitrary shape.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BFb0036138,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-58021-5_14,Robustness and Fault Tolerance Issues In Artificial Neural Network Based Robotic Control Applications,"Intelligent Systems: Safety, Reliability and Maintainability Issues",10.1007/978-3-642-58021-5_14,Springer,1993-01-01,"In control theory, in order to meet certain performance objectives with less precise advanced knowledge of system dynamics, it is necessary to develop control algorithms with high levels of autonomy. Learning control systems are good examples of such highly autonomous controllers. Within this class of controllers, neurologically inspired control algorithms have been gaining much attention in recent years. Artificial Neural Network (ANN) based control algorithms have been successfully applied for the tracking control of nonlinear systems with unknown or changing dynamics [ 1 , 2 , 3 ]. There is also much research on the stability properties of these, rather unconventional, control algorithms [ 4 , 5 ]. Performance of ANN based controllers is mainly due to these networks’ remarkable capabilities of approximating arbitrary nonlinear functions over compact spaces. Fault tolerance is also another much pronounced property of ANNs [ 6 ].",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-58021-5_14,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00248015,Design of a torque controller for the adept-2 robot,Journal of Intelligent and Robotic Systems,10.1007/BF00248015,Springer,1992-12-01,"The ability to command actuator torque is necessary to perform research into robot control. Commercial manipulators using direct-drive actuators offer high performance, but do not allow specification of actuator torque. We experimentally characterize the motors in an Adept-2 manipulator, and develop a linearizing and decoupling controller which allows torque specification. Torque ripple is 13%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00248015,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF01473901,Learning optimization for CPN-based training in robot positioning control,Journal of Intelligent Manufacturing,10.1007/BF01473901,Springer,1992-08-01,"Artificial neural net (ANN) models have been applied to the inverse kinematic problem for controlling robot positions. The selection of ANN training parameters, however, is an important yet complicated step which has to be taken before an ANN model for robot positioning control can be implemented effectively. The objective of this research is to utilize the counterpropagation network (CPN) for inverse kinematic mapping and obtain the best performance possible by systematic adjustment of network parameters. Taguchi statistical methods, efficient methods for analyzing the capability and accuracy of a system, have been used in this study. The working envelope of the robot simulated in this research is 150×150×60 mm^3. The optimal accuracy and standard deviation determined by this research are 2.62 mm and 1.2 mm, respectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF01473901,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00247423,Camera-robot transform for vision-guided tracking in a manufacturing work cell,Journal of Intelligent and Robotic Systems,10.1007/BF00247423,Springer,1992-06-01,"The problem of camera calibration from the perspective of hand-eye integration (henceforth referred to as the Camera-Robot (CR) problem), is addressed in this paper. Mapping results obtained from a least-squares fit using pseudo-inverse technique and a three layer neural network are compared. The calibration matrix is developed to map the image coordinates of an IRI D256 vision processor equipped with a CCD camera directly on to the coordinates for an IBM 7540 SCARA manipulator. One transformation is obtained by performing a least-squares fit using pseudo-inverse technique on a set of one hundred data points which relates two-dimensional (2D) image coordinates to corresponding twodimensional robot coordinates. The CR problem is also approached by using the same data points on a neural network. The results not only demonstrate the ability of neural networks to &#x2018;learn&#x2019; the transformation to a reasonable accuracy, but also from the basis for a relatively simple method of adaptive self-calibration of robot-vision systems. In a broader sense, the proposed method can be used to calibrate a variety of robotic sensors that are typically used in a flexible manufacturing environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00247423,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1022684924132,A Reinforcement Connectionist Approach to Robot Path Finding in Non-Maze-Like Environments,Machine Learning,10.1023/A:1022684924132,Springer,1992-05-01,"This paper presents a reinforcement connectionist system which finds and learns the suitable situation-action rules so as to generate feasible paths for a point robot in a 2D environment with circular obstacles. The basic reinforcement algorithm is extended with a strategy for discovering stable solution paths. Equipped with this strategy and a powerful codification scheme, the path-finder (i) learns quickly, (ii) deals with continuous-valued inputs and outputs, (iii) exhibits good noise-tolerance and generalization capabilities, (iv) copes with dynamic environments, and (v) solves an instance of the path finding problem with strong performance demands.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1022684924132,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00992702,A reinforcement connectionist approach to robot path finding in non-maze-like environments,Machine Learning,10.1007/BF00992702,Springer,1992-05-01,"This paper presents a reinforcement connectionist system which finds and learns the suitable situation-action rules so as to generate feasible paths for a point robot in a 2D environment with circular obstacles. The basic reinforcement algorithm is extended with a strategy for discovering stable solution paths. Equipped with this strategy and a powerful codification scheme, the path-finder (i) learns quickly, (ii) deals with continuous-valued inputs and outputs, (iii) exhibits good noise-tolerance and generalization capabilities, (iv) copes with dynamic environments, and (v) solves an instance of the path finding problem with strong performance demands.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00992702,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-349-12433-6_20,Applications of Back Propagation Neural Networks to Robot Position Control,Proceedings of the Twenty-Ninth International Matador Conference,10.1007/978-1-349-12433-6_20,Springer,1992-01-01,A method using neural network techniques for solving picking-up problems for robotic manipulators is presented in this article. An error back propagation network is used twice to process an image of a randomly placed object in order to find the gripping point and to obtain the required joint angles of the robot arms. Techniques of probabilistic and periodic coding are employed to improve generalisation ability of the network.,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-1-349-12433-6_20,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4471-2003-2_10,Neural Network Control of Robot Arm Tracking Movements,Neural Network Applications,10.1007/978-1-4471-2003-2_10,Springer,1992-01-01,"This paper describes a neural network based controller for tracking moving objects with a two-joint robot arm. The neural network consists of a single layer neural map containing pairs of cells, and two output neurons. The inputs to the network are the position of the hand, and the position and velocity of the object relative to the hand. The outputs from the network are the torques to be applied to the two joints. The network learns the mapping between joint torques and hand movements by making random movements of the arm. During learning, the delta rule is used to adjust the weights of the connections between the neural map and the output neurons. The model has been tested by computer simulation of a system consisting of the control network, a two joint arm with inertia and damping, and a randomly moving object. In the simulation, the neural network controller tracks objects with position and velocity errors of the order of 0.5 percent of the range of movement of the arm. This technique can be applied to a wide range of tracking control problems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-2003-2_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-3618-5_8,A Reinforcement Connectionist Approach to Robot Path Finding in Non-Maze-Like Environments,Reinforcement Learning,10.1007/978-1-4615-3618-5_8,Springer,1992-01-01,"This paper presents a reinforcement connectionist system which finds and learns the suitable situation-action rules so as to generate feasible paths for a point robot in a 2D environment with circular obstacles. The basic reinforcement algorithm is extended with a strategy for discovering stable solution paths. Equipped with this strategy and a powerful codification scheme, the path-finder (i) learns quickly, (ii) deals with continuous-valued inputs and outputs, (iii) exhibits good noise-tolerance and generalization capabilities, (iv) copes with dynamic environments, and (v) solves an instance of the path finding problem with strong performance demands.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-3618-5_8,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-663-09834-8_49,Robot Control Based on Neural Networks,"Proceedings of the Sixth European Conference on Mathematics in Industry August 27–31, 1991 Limerick",10.1007/978-3-663-09834-8_49,Springer,1992-01-01,"The multibody system approach leads to a well approved model for a robot. Its numerical simulation, however, cannot always meet real-time demands. Therefore a control based on feed-forward neural nets is studied. Numerical simulations with a 2-D robot in domains with obstacles are discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-663-09834-8_49,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-77750-9_15,Research in Advanced Educational Technology: Two Methods,New Directions in Educational Technology,10.1007/978-3-642-77750-9_15,Springer,1992-01-01,"We describe two ways of working which use advanced technology for educational purposes. The first part of the text is devoted to the description of an ITS (Intelligent Tutoring System) for algebraic manipulation. The focus is on the possibilities offered to solve problems, to deliver rich explanations and to encode declarative pedagogical knowledge. The second part is devoted to the extension of the turtle microworld we have developed. We describe our micro-robotics approach and the pedagogical use of driving micro-robots. The focus is on the need for a good definition of pedagogical goals before use of devices. The tools we have designed are presented according to precise goals. The conclusion shows that we need work in two complementary ways: ITS can be useful to support the learning of procedures, micro-worlds for learning basic concepts. More, we have not to conform to fashion and claim ITS as the only way for advanced educational technology (even if we think this way as a very interesting one!). Deeper work on advanced physical learning environments (micro-worlds in the sense of the floor turtle by Papert) is useful because a lot of things cannot be taught otherwise.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-77750-9_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-011-2526-0_5,Non-Geometrical Parameters Identification for Robot Kinematic Calibration by use of Neural Network Techniques,Robotic Systems,10.1007/978-94-011-2526-0_5,Springer,1992-01-01,"This paper presents a new technique for the calibration of robots based on a neural network approach for the identification of non-geometrical errors. Identification of geometrical errors is not a problem any more since several methods have been presented recently. The remaining problem is the identification of the non-geometrical errors. Non-geometrical errors modeling is a very complex and heavy process. The originality of this paper is the use of a neural network approach avoiding explicit modeling of this kind of errors. Simulations have been carried out on a robot with 6 degrees of freedom. Finally, two compensation algorithms are presented, based on the improved knowledge of the model: the first one is based on the construction of false target, the second one compensates directly into the joint space.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-011-2526-0_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-84837-7_5,Control Applications,Industrial Applications of Neural Networks,10.1007/978-3-642-84837-7_5,Springer,1992-01-01,The control task started with an overview of the application of neural networks in control to aid the choice of suitable demonstrator projects. The generalised application was chosen to provide insights into a wide range of technical problems based on: motor sensor interaction signal classification sensor fusion control.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-84837-7_5,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-011-2648-9_13,Introduction to Robotics and Computer Vision,Teleoperation: Numerical Simulation and Experimental Validation,10.1007/978-94-011-2648-9_13,Springer,1992-01-01,"This introduction is intended to provide a fundamental knowledge of Computer Vision Science; the first part describes some useful and basic notions of mathematical transforms (Fourier), image sampling, digitizing and filtering techniques. Then, definitions of image segmentation and restoration, figure extraction and object classification are given as well as notions of optical flux, artificial neural networks and workspace representation. The second part deals with practical applications such as robot navigation and object recognition in a scene.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-011-2648-9_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF01471108,Automatic generation of assembly plans from topological assembly drawings,Journal of Intelligent Manufacturing,10.1007/BF01471108,Springer,1991-08-01,"An automatic understanding system MAD-READER based on the techniques of image processing, pattern recognition, and artificial intelligence has been developed for mechanical engineering drawings. The principles of the system are presented, which include the methods and techniques of recognition and understanding for topological assembly drawings (TAD). A rule-based generator GEN-PLAN is devised to generate directly assembly plans from TAD assembly drawings. A variety of TAD assembly drawings has been used for testing the generator. So far, GEN-PLAN has been used to recognize TAD assembly drawings which consist of 31 part symbols, and generate their assembly plans. The present generator has shown favorable results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF01471108,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00360578,"Other bodies, other minds: A machine incarnation of an old philosophical problem",Minds and Machines,10.1007/BF00360578,Springer,1991-02-01,"Any attempt to explain the mind by building machines with minds must confront the other-minds problem: How can we tell whether any body other than our own has a mind when the only way to know is by being the other body? In practice we all use some form of Turing Test: If it can do everything a body with a mind can do such that we can't tell them apart, we have no basis for doubting it has a mind. But what is “everything” a body with a mind can do? Turing's original “pen-pal” version of the Turing Test (the TT) only tested linguistic capacity, but Searle has shown that a mindless symbol-manipulator could pass the TT undetected. The Total Turing Test (TTT) calls instead for all of our linguistic and robotic capacities; immune to Searle's argument, it suggests how to ground a symbol manipulating system in the capacity to pick out the objects its symbols refer to. No Turing Test, however, can guarantee that a body has a mind. Worse, nothing in the explanation of its successful performance requires a model to have a mind at all. Minds are hence very different from the unobservables of physics (e.g., superstrings); and Turing Testing, though essential for machine-modeling the mind, can really only yield an explanation of the body.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00360578,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/BFb0029741,Genetic programming artificial nervous systems artificial embryos and embryological electronics,Parallel Problem Solving from Nature,10.1007/BFb0029741,Springer,1991-01-01,"This paper shows that it is possible to build hyper-complex systems such as an artificial nervous system or an artificial embryo, despite the fact that their interactions or dynamics are (probably) too complicated to be analyzed. Genetic Programming (GP) is ""applied evolution"", i.e. using the Genetic Algorithm (GA) [GOLDBERG 1989] to evolve hyper-complex systems. Future work using the GP paradigm will probably lead to electronic circuits being ""grown"" in (and having their functionality tested in) special hardware called ""Darwin Machines"", thus creating a new field called ""Embryonics"" (i.e. Embryological Electronics).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BFb0029741,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/BFb0035924,Neural network design for mobile robot control following a contour,Artificial Neural Networks,10.1007/BFb0035924,Springer,1991-01-01,"The aim of this work was to prove the application feasibility of connectionist paradigm for autonomous mobile robot control. During its movement, the robot perceives the environment by means of ultrasound sensors, hence the information that will be given to the Neural Network is a bidimentional continuous type. The Network must be able to determine from this information the different situations the robot could be and send the proper orders to the driving and steering robot's system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BFb0035924,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-84338-9_11,Artificial Neural Networks In Manufacturing,CAD/CAM Robotics and Factories of the Future ’90,10.1007/978-3-642-84338-9_11,Springer,1991-01-01,"The topic of artificial neural networks (ANN) has received a great deal of attention among various groups of scientists and engineers as an alternative method of solving either intractable or “fuzzy” problems. In the area of manufacturing, ANN have been applied to vision systems, robot path planning, pattern recognition of data trends for use in analyzing production systems, and some recent research has been attempting to use ANN for feature recognition to facilitate CAD/CAM. This paper will highlight the scope of recent research accomplishments using ANN in manufacturing. Specific research in the control of a Molecular Beam Epitaxy process for growing thin film materials for semiconductors, and the design of a manufacturing system for Group Technology will be examined in closer detail. To conclude the examination of ANN in manufacturing, future trends and research areas will be discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-84338-9_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-3994-0_7,Asics for Prototyping of Pulse-Density Modulated Neural Networks,VLSI Design of Neural Networks,10.1007/978-1-4615-3994-0_7,Springer,1991-01-01,"Two alternative ways are presented for creating dedicated neural hardware realizations based on pulse-density modulation. The first approach emphasizes fast prototyping of neural systems in a conventional digital microprocessor environment. It uses an ASIC cell library in combination with a Sea-Of-Gates template to produce testable integrated neural circuits with off-chip learning. Typical single-chip network sizes range from 18 neurons with 846 synapses to 110 neurons with 550 synapses. Larger network sizes can be obtained by concatenation. The second approach is based on an ASIC processor, which can be programmed for a variety of biologically plausible neuron models with flexible topology (i.e. it possesses programmable and learnable membrane potential, synaptic weights, delays, threshold, and transfer function). Each chip possesses furthermore its own communication hardware to realize global communications through fault-tolerant interconnection multiplexing.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-3994-0_7,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-75530-9_13,Report on the Group Discussion about Neural Networks in Robotics,Sensor-Based Robots: Algorithms and Architectures,10.1007/978-3-642-75530-9_13,Springer,1991-01-01,"The discussion developed around the following four topics: advancements that have led to the resurgence of neural netwok (NN), operations that NN are best suited for, main applications, and key problems that need to be solved.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-75530-9_13,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-76465-3_15,Intelligent Cooperation for Robotics,Expert Systems and Robotics,10.1007/978-3-642-76465-3_15,Springer,1991-01-01,"The use of Multi Agent Systems as a Distributed Artificial Intelligence paradigm for Robotics is the principal aim of our present work. In order to make different Intelligent Systems to cooperate in solving non trivial tasks, special architectures need to be designed. New functionalities are attached to each particular Agent suitable for Robotics, enabling cooperation at the Knowledge and Intelligence Levels. Each Agent is implemented by means of a set of different specialized processes. Besides the Intelligent Systems itself, a Monitor, an Acquaintance plus Self-knowledge Modules and a Communication Module, are fundamental modules that make it possible for different Agents to cooperate by exchanging competences, information and results. Which kind of knowledge to represent, either static or dynamic, involving the overall system, how to represent it, to share it, to maintain it and to infer upon it are subjects that have been adressed and several conclusions have already been drawn. An Assembly Robotics testbed is being used for that purpose, and several Intelligent Agents developed such as: An High Level Planner, a World Descriptor and an Object Identifier. Each one of these Intelligent Systems, incorporating its own reasoning capabilities (therefore considered as Scmi-autonomous Agents), has been enhanced with several modules according to the previously referred architecture. We claim Robotics to be a good example for Intelligent Systems cooperation and we intend to apply the aforementioned principles to different classes of Robotics applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-76465-3_15,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-84574-1_39,"Shortest Paths in 3-Space, Voronoi Diagrams with Barriers, and Related Complexity and Algebraic Issues",Fundamental Algorithms for Computer Graphics,10.1007/978-3-642-84574-1_39,Springer,1991-01-01,"We consider the problem of computing the shortest path under the Euclidean metric between source and goal points in 3-space while avoiding clashes with polyhedral obstacles. This can be thought as the ultimate version of the notorious TRAVELING SALESMAN problem in terms of generality and is known as the FINDPATH problem in artificial intelligence and robotics. We show that this problem is solved using algebraic elimination techniques in a straightforward yet very inefficient manner. We then introduce a Voronoi-based strategy for solving the subproblem of determining the sequence of obstacle edges through which the shortest path passes. This is based upon a natural extension of Franklin’s “Partitioning the plane to calculate minimal paths to any goal around obstructions” [Tech. Rep., ECSE Dept., Rensselaer Polytechnic Inst., Troy, NY, Nov. 1982] to 3-space. In 3-space, a very desirable feature of the plane partitions disappears making the space partitions complicated. For this case, we suggest an approximation technique.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-84574-1_39,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-011-3812-3_10,Neural Networks and Robot Vision,Microprocessors in Robotic and Manufacturing Systems,10.1007/978-94-011-3812-3_10,Springer,1991-01-01,"Traditionally robot vision and robot control applications are written in imperative languages, such as Fortran, Pascal, Modula or C. Since the development of Artificial Intelligence techniques, specialized robot languages emerged. The upper layers of robot languages are: programmed in declarative languages, such as Lisp and Prolog. Recently, neural computing has become a third exciting programming alternative which complements the other programming styles. Neural programming paradigms apply to both robot vision and robot control. In this chapter the basic neural network techniques applicable to robot vision are explored. Among these are pattern recognition, blurred image restoration and unsupervised classification. It is likely that a judicious blend of these techniques will be used in complex scene analysis. Neural networks are characterized by an interconnection structure and a learning rule. These offer a wealth of combinations for each particular application. Therefore the major neural network models are analyzed and compared.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-011-3812-3_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-011-2560-4_22,Robot Identification using Dynamical Neural Networks,Engineering Systems with Intelligence,10.1007/978-94-011-2560-4_22,Springer,1991-01-01,"It is nowadays well known that neural networks can model very efficiently complex nonlinear systems. This paper solves the identification problem of a robotic manipulator using dynamical neural networks. More explicitly a dynamic, distributed backpropagation network with two hidden layers and a novice algorithm are used. The network includes dynamic el-ements in its neurons, and this property makes it effective in identifying dynamic nonlinear systems. Simulation results demonstrate the applicability of the approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-011-2560-4_22,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF01471189,A guide to the design offuzzy control systems for manufacturing processes,Journal of Intelligent Manufacturing,10.1007/BF01471189,Springer,1990-12-01,"While classical control theory has been demonstrated to be highly successful in many manufacturing technology applications, there are shortcomings when applied to processes that require the intuitive skills of a human operator. Fuzzy logic technique can be a significant aid in enabling machine systems to imitate the control stategy of an operator and so achieve an efficient control function. Commencing with the basic principles of fuzzy logic theory, the paper provides a practical guide to the design techniques used to establish fuzzy controller. An example of a welding robot to achieve an irregular weld path profile is used to illustrate the procedure.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF01471189,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00368972,Neural networks in robotics: A survey,Journal of Intelligent and Robotic Systems,10.1007/BF00368972,Springer,1990-03-01,"The purpose of this paper is to provide an overview of the research being done in neural network approaches to robotics, outline the strengths and weaknesses of current approaches, and predict future trends in this area.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00368972,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-3692-5_10,An Ultrasonic Robot Eye Using Neural Networks,Acoustical Imaging,10.1007/978-1-4615-3692-5_10,Springer,1990-01-01,"Object recognition is an important aspect in the development of a robot eye system. The use of television cameras has been investigated, however no particularly effective method has been developed. We are developing a new method based on ultrasonic recognition and report some recent experimental results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-3692-5_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00238695,Neurocontroller design via supervised and unsupervised learning,Journal of Intelligent and Robotic Systems,10.1007/BF00238695,Springer,1989-06-01,In this paper we study the role of supervised and unsupervised neural learning schemes in the adaptive control of nonlinear dynamic systems. We suggest and demonstrate that the teacher's knowledge in the supervised learning mode includes a-priori plant sturctural knowledge which may be employed in the design of exploratory schedules during learning that results in an unsupervised learning scheme. We further demonstrate that neurocontrollers may realize both linear and nonlinear control laws that are given explicitly in an automated teacher or implicitly through a human operator and that their robustness may be superior to that of a model based controller. Examples of both learning schemes are provided in the adaptive control of robot manipulators and a cart-pole system.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00238695,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4684-6237-1_1,Setting the scene,Intelligent robotics,10.1007/978-1-4684-6237-1_1,Springer,1989-01-01,"Robotics is one of those high-technology subjects that tend to suffer from an exaggerated or distorted public image. A news item about a line of welding robots in a car factory will often have a commentary that hints at dire consequences for the work-force, the car industry and even the human race. Why do robots provoke this type of response when, for example, the installation of a new type of machine tool, that might have a greater effect on productivity, goes virtually unnoticed? There are at least two reasons for this — superficial simplification and emotional appeal.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4684-6237-1_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/BFb0043256,Neural network models for the learning control of dynamical systems with application to robotics,Advances in Computing and Control,10.1007/BFb0043256,Springer,1989-01-01,"In this paper, two new brain-like control methodologies have been suggested. The significance of the designs rests in the novelty and simplicity of their architectures. The methodologies have several promising attributes that make them very feasible solutions to current problems in system control. First of all, the controllers mimic the functions of the cerebellum for the learning and control of voluntary movements. That is, these controllers learn the inverse-dynamics of the system by repeated trials of a given task, hence allowing the dynamic systems to track trained trajectories almost perfectly. But above that, with these controllers, systems can perform untrained trajectories quite satisfactorily. The schemes also have good adaptation capabilities which allow the controllers to respond to unexpected disturbances. Another advantage of these methodologies is that the algorithms do not require the knowledge of the system parameters, and they are robust with respect to parameter variation and disturbances under a variety of tasks. Finally, they have parallel processing capabilities which make them fast and fault tolerant. Moreover, the parallel processing property of these architectures makes them highly suitable for the integration of a multitude of sensory information into the motion controller networks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BFb0043256,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-4-431-68293-6_2,"Artificial Intelligence, Natural Language, and Simulation for Human Animation",State-of-the-art in Computer Animation,10.1007/978-4-431-68293-6_2,Springer,1989-01-01,"An approach to the higher-level specification and execution of animation is described. Natural language is used to augment the animation process since verbs and their modifiers (temporal, adverbial, and spatial) offer a rich and succinct vocabulary for task control. A simulation system based on human performance models and expert systems is used to produce animation control sequences. Interactive systems assist an animator or human factors engineer to graphically simulate the task-oriented activities of several human agents. The overall organization of this project and some specific components will be discussed, including: the JACK interactive graphics interface, various human factors analyses, real-time constraint-based inverse kinematic positioning, strength models, dynamic simulation, constraint-based temporal planning, artificial intelligence task definitions, and natural language specification of tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-4-431-68293-6_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4613-1691-6_1,Introduction,Machine Learning of Robot Assembly Plans,10.1007/978-1-4613-1691-6_1,Springer,1988-01-01,"This book describes an experiment involving the application of a recently developed machine-learning technique, explanation-based learning , to the robot retraining problem . Explanation-based learning permits a system to acquire generalized problem-solving knowledge on the basis of a single observed problem-solving example. The description of the design and implementation of this experimental computer program serves as a vehicle for discussing issues related to this particular type of learning. This work clarifies and extends the corpus of knowledge so that explanation-based learning can be successfully applied to real-world problems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4613-1691-6_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-73890-6_93,Application of Artificial Intelligence and Robotics to Mining,Robotics and Factories of the Future ’87,10.1007/978-3-642-73890-6_93,Springer,1988-01-01,"Artificial Intelligence (Al) and Robotics technology have recently taken on an international flavour and become a significant topic in engineering research. Robotics has a great potential for assisting in the complex task of extracting and processing minerals from the ground. Just as the advent of computer technology has made a significant impact on computer aided design and planning, the advent of robotics will make a significant impact on the mining industry. This paper will provide an overview of the rapidly evolving fields of artificial intelligence and robotics. The development of new theories and techniques and the potential of both these fields in mine design and planning are examined. A selection of areas for engineering applications of interest to the Canadian mining community are described.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-73890-6_93,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-83625-1_2,A Geometric Modeler for an Automatic Robot Programming System,CAD Based Programming for Sensory Robots,10.1007/978-3-642-83625-1_2,Springer,1988-01-01,"Because of the increasing complexity of computer vision and robotic software along with the need of powerful representations of the real world, solid modelers are now considered of primary importance. In particular, the automatic synthesis of part-mating programs from CAD-based descriptions requires to reason on both numerical and symbolical representations of the real environment. In this paper we describe some concepts and modeling tools which we have developped within the scope of the SHARP project. Because of the reasoning aspect of planning, this model should fulfil three requirements: a quantitative description, a qualitative one and a control of physical properties.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-83625-1_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-83539-1_24,Some Collision Avoidance Problems in the Plane,Theoretical Foundations of Computer Graphics and CAD,10.1007/978-3-642-83539-1_24,Springer,1988-01-01,"Spurred by developments in spatial planning in robotics, computer graphics, and VLSI layout, considerable attention has been devoted recently to the problem of moving sets of objects, such as line segments and polygons in the plane or polyhedra in three dimensions, without allowing collisions between the objects. One class of such problems considers the separability of sets of objects under different kinds of motions and various definitions of separation. This paper surveys this new area of research in a tutorial fashion, presents new results, and provides a list of open problems and suggestions for further research for the case of two dimensions only.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-83539-1_24,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-83325-0_18,Object Identification and Automatic Learning,Real-Time Object Measurement and Classification,10.1007/978-3-642-83325-0_18,Springer,1988-01-01,"Object Identification architectures as component of a more global automated robotics system are proposed. A. I. based techniques, CAD utilization for object learning and development of integrated environments for fast and robust prototyping are strongly suggested as a way of developing integrated test beds for checking new models. A description of a vision based working prototype implemented in Prolog-2 and Padl-2 is presented. Actual and future working lines ar discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-83325-0_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF03037463,Linearity and plan generation,New Generation Computing,10.1007/BF03037463,Springer,1987-09-01,"In Ref. 3) a new linearity concept for proofs was introduced and its application to plan generation was proposed. An examination of these ideas revealed some troublespots which are discussed in this paper. Furthermore, three qualifications of the original linearity concept are presented which attempt to overcome these difficulties.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF03037463,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF03037438,A deductive solution for plan generation,New Generation Computing,10.1007/BF03037438,Springer,1986-06-01,"A new deductive method for solving robot problems is presented in this paper. The descriptions of initial and goal situations are given by logical formulas. The primitive actions are described by rules, i. e. logical formulas as well. Altogether this results in a problem description like in logic programming or in program synthesis. A solution is generated by a proof of this description like in program synthesis, except that here proofs have to be strictly linear. This restriction is the clue of our solution; it can be easily added as an option to any theorem prover such as one based on the connection method used hereafter. In fact this restriction speeds up the proof search considerably. At the same time our approach offers an elegant solution of the frame problem.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF03037438,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-9893-0_2,Robots and artificial intelligence: parallel developments,Decision and Intelligence,10.1007/978-1-4615-9893-0_2,Springer,1986-01-01,"Despite the curious historical fact that computers and robots have undergone a totally separate development until the late 1970s, writers on the future of computers foresaw the completely automated factory as being merely a matter of advancing the calculating performance of computational machinery. The potential for such progress was clearly foreseen as an improvement in the ‘intelligence’ of the task carried out by the computer. But in which way can a computer be said to be intelligent? This question comes into focus when the logical power of a computer is made to mesh with the mechanical power of a robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-9893-0_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4684-7329-2_2,Robots and artificial intelligence: parallel developments,Decision and Intelligence,10.1007/978-1-4684-7329-2_2,Springer,1986-01-01,"Despite the curious historical fact that computers and robots have undergone a totally separate development until the late 1970s, writers on the future of computers foresaw the completely automated factory as being merely a matter of advancing the calculating performance of computational machinery. The potential for such progress was clearly foreseen as an improvement in the ‘intelligence’ of the task carried out by the computer. But in which way can a computer be said to be intelligent? This question comes into focus when the logical power of a computer is made to mesh with the mechanical power of a robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4684-7329-2_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF01078638,Self-training algorithms for an integral robot in a complex environment,Cybernetics,10.1007/BF01078638,Springer,1986-01-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF01078638,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-011-6768-0_11,Robotics and Artificial Intelligence,Fundamentals of Robot Technology,10.1007/978-94-011-6768-0_11,Springer,1986-01-01,"As remarked in Chapter 1, AI is a subject with ill-defined boundaries. Its name (coined in 1956 by John McCarthy) has never seemed entirely satisfactory and there are variants such as ‘machine intelligence’, but nobody has been able to think of a universally acceptable alternative and so the original term has stuck.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-011-6768-0_11,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF03037076,Formal theories of knowledge in AI and robotics,New Generation Computing,10.1007/BF03037076,Springer,1985-12-01,"Although the concept of knowledge plays a central role in artificial intelligence, the theoretical foundations of knowledge representation currently rest on a very limited conception of what it means for a machine to know a proposition. In the current view, the machine is regarded as knowing a fact if its state either explicitly encodes the fact as a sentence of an interpreted formal language or if such a sentence can be derived from other encoded sentences according to the rules of an appropriate logical system. We contrast this conception, the interpreted-symbolic-structure approach, with another, the situated-automata approach, which seeks to analyze knowledge in terms of relations between the state of a machine and the state of its environment over time using logic as a metalanguage in which the analysis is carried out.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF03037076,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF01070615,Algorithms for automatic modeling of the external environment of a mobile robot,Cybernetics,10.1007/BF01070615,Springer,1985-07-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF01070615,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF01070614,A decentralized system for planning and controlling the activity of a team of mobile robots,Cybernetics,10.1007/BF01070614,Springer,1985-07-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF01070614,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00244288,An overview of automated reasoning and related fields,Journal of Automated Reasoning,10.1007/BF00244288,Springer,1985-03-01,"This article provides an overview of automated reasoning and of the various fields for which it is relevant. It takes the form of a collection of articles, each covering some field and each written by an expert in that field. A field is introduced, its elements reviewed, the current state of the art given, the basic problems discussed, and the various goals listed. Although individually the goals of each field present a wide spectrum, collectively the fields share the interest of automating the process known as reasoning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00244288,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4613-2533-8_2,Artificial Intelligence for Smart Robots,Smart Robots,10.1007/978-1-4613-2533-8_2,Springer,1985-01-01,"Artificial intelligence, also sometimes referred to as machine intelligence or heuristic programming, is an emerging technology that has recently attracted considerable publicity. Many applications are now under development. One simple view of artificial intelligence is that it is concerned with devising computer programs to make computers smarter. Thus, research in artificial intelligence is focused on developing computational approaches to intelligent behavior. This effort has two goals: making machines more useful and understanding intelligence. This chapter is primarily concerned with the first goal.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4613-2533-8_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-9882-4_41,Hexapod Walking Robots with Artificial Intelligence Capabilities,Theory and Practice of Robots and Manipulators,10.1007/978-1-4615-9882-4_41,Springer,1985-01-01,"The potential usefulness of walking robots for work, maintenance and exploration in difficult environments is well acknowledged. For effective performing of these tasks, walkers have to become fully robotic, i.e. to be implemented with high-level software by using artificial intelligence concepts and techniques, concurrently with well-designed mechanics and intermediate software levels for control and sensing. The four-level control architecture we devised for our first six-legged prototype (see Ro Man Sy’81) was found to be efficient, easily modifiable and extensible. However, we find it useful to add to the existing structure (level, 1; leg, 2; gait generation, 3; plan interpreter, 4; intelligence and plan generation) a 1.5 ‘Tonus’ level for effector tonicity and leg adjustment according to terrain constraints. The hardware is tending toward a full multi-microprocessor organization. A significant feature of our approach is the existence at level 3 of an interpreter for our socialized walking robot plan language LP 4.5, designed to be automatically generated by the upper level; gaits are among the primitives of LP 4.5, which makes it easy to program the robot. As implemented now, with a rotating ultrasonic telemeter, the robot is able to exhibit such autonomous behaviours as following edges, escaping, explorating an unknown universe, etc. Paddle driving is also possible under plan control. An equilibrium sensing organ allows the maintenance of the platform horizontal on uneven ground. Methods experimented for producing level-4 intelligent behaviours on a difficult terrain include heuristic graph-search procedures (e.g. A*) and multi-level expert system advanced techniques. A stronger prototype, which carries a payload of 40 kg, has been built. The mechanical design is similar with Cartesian two-motors planar legs exhibiting lateral compliances; however, the leg mechanism is directly Cartesian, without the original triangle-and-pantograph system of the first prototype. The computer systems are compatible. This heavier robot can bear complex sensing systems and perform quasi-real-scale terrain experiments, such as feasibility studies for plant maintenance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-9882-4_41,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-009-6340-5_10,Artificial Intelligence and Industrial Robots: An Automatic end for Utopian Thought?,Nineteen Eighty-Four: Science Between Utopia and Dystopia,10.1007/978-94-009-6340-5_10,Springer,1984-01-01,"Ideas of artificial men or thinking machines have pervaded legend and literature from the earliest times (1). It is perhaps only in the last twenty years or so, however, that technologies such as industrial robots and artificial intelligence have been developed which appear to have the potential to realize these ideas (2). The expression of such ideas and reactions to them have been diverse, embracing both the brightest Utopian and darkest dystopian themes, and discussions are found in many different contexts, ranging from myth to critiques of current technology.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-009-6340-5_10,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-82153-0_1,State of the Art and Predictions for Artificial Intelligence and Robotics,Robotics and Artificial Intelligence,10.1007/978-3-642-82153-0_1,Springer,1984-01-01,"The term robot conjures up a vision of a mechanical man—that is, some android as viewed in Star Wars or other science fiction movies. The industrial robot has no resemblance to these Star Wars figures. In reality, robots are largely constrained and defined by what we have so far managed to do with them.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-82153-0_1,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-82153-0_2,Artificial Intelligence and Robotics,Robotics and Artificial Intelligence,10.1007/978-3-642-82153-0_2,Springer,1984-01-01,"Robotics is that field concerned with the connection of perception to action. Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how that knowledge should be represented; and how that knowledge should be used Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and object oriented reasoning. Object-oriented reasoning includes reasoning about space, path-planning, uncertainty, fitting, and friction. We concluded with three examples that illustrate the kinds of reasoning or problem solving abilities we would like to endow robots with.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-82153-0_2,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF01069333,Knowledge representations in robot artificial intelligence systems,Cybernetics,10.1007/BF01069333,Springer,1979-03-01,,http://link.springer.com/openurl/pdf?id=doi:10.1007/BF01069333,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-7566-5_25,A Critical Review of Learning Control Research,Pattern Recognition and Machine Learning,10.1007/978-1-4615-7566-5_25,Springer,1971-01-01,"In designing an optimal control system, if the a priori information required is unknown or incompletely known, one possible approach is to design a controller which is capable of estimating the unknown information during its operation and determining the optimal control action on the basis of the estimated information. If the estimated information gradually approaches the true information as time proceeds, then the controller designed will approach the optimal controller; and, consequently, the performance of the control system is gradually improved. Because of the gradual improvement of performance due to the improvement of the estimated unknown information, this class of control systems has been called learning control systems. Design techniques proposed for learning control systems include: (1) trainable controllers using pattern classifiers, (2) reinforcement learning algorithms, (3) Bayesian estimation, (4) stochastic approximation, and (5) stochastic automata models. A survey of these techniques can be found in [1]. A general formulation using stochastic approximation has been treated extensively in [2, 3]. Practical applications include spacecraft control systems, the control of valve actuators, power systems, and production processes. In addition, several nonlinear learning algorithms have recently been proposed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4615-7566-5_25,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-99976-5_18,The Relevance of Robot Research to Artificial Intelligence,Theoretical Approaches to Non-Numerical Problem Solving,10.1007/978-3-642-99976-5_18,Springer,1970-01-01,"A major review of research in artificial intelligence (Feigenbaum, 1968) recently stated that “The intensive effort being invested on the development of computer-controlled hand-eye and eye-cart devices is … the most unexpected occurrence in A.I. research in the 1963-68 period.” This paper takes the contrary view, which is that interest in the development of such robot-like devices is both a natural consequence of past developments, and a necessary stimulant to future research in the evolution of artificial intelligence and non-numerical problem solving.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-99976-5_18,springer,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
