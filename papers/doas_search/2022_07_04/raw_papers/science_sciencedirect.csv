id,type,publication,publisher,publication_date,database,title,url,abstract,query_name,query_value
10.1016/j.ijepes.2022.108291,Journal,International Journal of Electrical Power and Energy Systems,scopus,2022-11-01,sciencedirect,Density-based clustering algorithm for associating transformers with smart meters via GPS-AMI data,https://api.elsevier.com/content/abstract/scopus_id/85130630920,"The ongoing deployment of Distributed Energy Resources, while bringing benefits, introduces significant challenges to the electric utility industry, especially in the distribution grid. These challenges call for closer monitoring through state estimation, where real-time topology recovery is the basis for accurate modeling. Previous methods either ignore geographical information, which is important in connectivity identification or are based on an ideal assumption of an isolated sub-network for topology recovery, e.g., within one transformer. This requires field engineers to identify the association, which is costly and may contain errors. To solve these problems, we propose a density-based topology clustering method that leverages both voltage domain data and the geographical space information to segment datasets from a large utility customer pool, after which other topology reconstruction methods can carry over. Specifically, we show how to use voltage and GPS information to infer associations within one transformer area, i.e., to identify the meter-transformer connectivity. To give a guarantee, we show a theoretic bound for our clustering method, providing the ability to explain the performance of the machine learning method. The proposed algorithm has been validated by IEEE test systems and Duquesne Light Company in Pittsburgh, showing outstanding performance. A utility implementation is also demonstrated.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patcog.2022.108832,Journal,Pattern Recognition,scopus,2022-10-01,sciencedirect,Learning a deep dual-level network for robust DeepFake detection,https://api.elsevier.com/content/abstract/scopus_id/85131788667,"Face manipulation techniques, especially DeepFake techniques, are causing severe social concerns and security problems. When faced with skewed data distributions such as those found in the real world, existing DeepFake detection methods exhibit significantly degraded performance, especially the AUC score. In this paper, we focus on DeepFake detection in real-world situations. We propose a dual-level collaborative framework to detect frame-level and video-level forgeries simultaneously with a joint loss function to optimize both the AUC score and error rate at the same time. Our experiments indicate that the AUC loss boosts imbalanced learning performance and outperforms focal loss, a state-of-the-art loss function to address imbalanced data. In addition, our multitask structure enables mutual reinforcement of frame-level and video-level detection and achieves outstanding performance in imbalanced learning. Our proposed method is also more robust to video quality variations and shows better generalization ability in cross-dataset evaluations than existing DeepFake detection methods. Our implementation is available online at https://github.com/PWB97/Deepfake-detection.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.infsof.2022.106961,Journal,Information and Software Technology,scopus,2022-10-01,sciencedirect,Find potential partners: A GitHub user recommendation method based on event data,https://api.elsevier.com/content/abstract/scopus_id/85131450587,"Context:
                  GitHub has attracted much popularity among a large number of software developers around the world and introduced the social function follow to strengthen the relationship among developers. Like other social networks, GitHub users usually follow others who are popular in the community, co-workers, or friends in real life. However, according to our investigation, more than half of GitHub users prefer to follow recently like-minded developers other than their traditional networks for communicating with timely feedback, discovering niche repositories, and attracting more active contributors to cooperate, while these users are hard to find.
               
                  Objective:
                  Our objective in this paper is to leverage recent activities-Event Data of GitHub users and conduct a recommendation approach to help them match some recently like-minded developers to follow or reach out.
               
                  Methods:
                  As a first step, we conduct one empirical research—an online survey to investigate and analyze the opinions of GitHub users whether they are willing to follow others with similar recent events and which kind of events they will focus on during the follow process. Regarding the results from our survey, we partition 12 types of events focused by participants into three Event sets of Communication, Exploration, and Cooperation. As a second step, we collect Event Data of 12,713 GitHub users who participated in repositories written in python and build a time-based multi-dimensional recommendation approach based on a calculating vector-similarity method, a clustering approach, and a deep learning model.
               
                  Results and Conclusion:
                  The experimental results show that our approach achieves an improvement of 607.64%, 564.59%, and 599.19% on average compared with two baselines in terms of 
                        
                           P
                           r
                           e
                           c
                           i
                           s
                           i
                           o
                           n
                           @
                           N
                        
                     , 
                        
                           R
                           e
                           c
                           a
                           l
                           l
                           @
                           N
                        
                     , and 
                        
                           F
                           1
                           −
                           S
                           c
                           o
                           r
                           e
                           @
                           N
                        
                     . Such a series of experiments have proved that our method is effective and feasible.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patcog.2022.108828,Journal,Pattern Recognition,scopus,2022-10-01,sciencedirect,Classification for high-dimension low-sample size data,https://api.elsevier.com/content/abstract/scopus_id/85131426270,"High-dimension and low-sample-size (HDLSS) data sets have posed great challenges to many machine learning methods. To deal with practical HDLSS problems, development of new classification techniques is highly desired. After the cause of the over-fitting phenomenon is identified, a new classification criterion for HDLSS data sets, termed tolerance similarity, is proposed to emphasize maximization of within-class variance on the premise of class separability. Leveraging on this criterion, a novel linear binary classifier, termed No-separated Data Maximum Dispersion classifier (NPDMD), is designed. The main idea of the NPDMD is to spread samples of two classes in a large interval in the respective positive or negative space along the projecting direction when the distance between the projection means for two classes is large enough. The salient features of the proposed NPDMD are: (1) The NPDMD operates well on HDLSS data sets; (2) The NPDMD solves the objective function in the entire feature space to avoid the data-piling phenomenon. (3) The NPDMD leverages on the low-rank property of the covariance matrix for HDLSS data sets to accelerate the computation speed. (4) The NPDMD is suitable for different real-word applications. (5) The NPDMD can be implemented readily using Quadratic Programming. Not only theoretical properties of the NPDMD have been derived, but also a series of evaluations have been conducted on one simulated and six real-world benchmark data sets, including face classification and mRNA classification. Experimental results and comprehensive studies demonstrate the superiority of the NPDMD in terms of correct classification rate, mean within-group correct classification rate and the area under the ROC curve.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.energy.2022.124588,Journal,Energy,scopus,2022-09-15,sciencedirect,Energy conservation for existing cooling and lighting loads,https://api.elsevier.com/content/abstract/scopus_id/85133809340,"Energy consumption by cooling and lighting loads can be significantly reduced if real time information on the occupancy is applied in their control. To meet this goal smart cooling and lighting devices, which have built-in sensors and controllers and which make decisions on individual basis, are being developed. However, it appears that no attempt has yet been taken for auto-operation of the huge number of already existent so called “non smart” air conditioning (AC) and lighting loads considering the count and location of occupants. A good deal of research has been reported in literature on the line of deploying or improving occupant detecting sensors/cameras, processing the captured images and developing high performance occupant identification (only detection or detection and counting) algorithms. Those were focused on locating users and surveillance in a building. A comparison of those works reveals that cameras combined with faster RCNN (Region based Convolutional Neural Network) algorithm can best identify the occupants. However, none of the works reported any prototyping considering occupancy with or without other ambient conditions such as comfort level, temperature, humidity and luminance for cooling load set point temperature update and/or lighting load control. Furthermore, the way the existing cooling and lighting loads can be made amenable to occupancy sensitive operation for energy saving in a noninvasive way is not yet reported. The novelties and contributions of the present paper are on bridging the gaps viz. (i) prototyping using traditional cooling and lighting loads of any brand already existent in a space for achieving occupancy sensitive energy saving, (ii) developing a model using the total count of occupants in a space along with ambient temperature and humidity for update of the set point temperature of cooling loads such that energy will be saved while the occupants will feel comfort, (iii) generation of ON/OFF commands in real time for lighting loads considering zone wise location of occupants along with the difference between ambient and required luminance in a zone, (iv) auto transmission of the updated set point temperature and on/off commands wirelessly from a common GUI (Graphical User Interface) respectively to the cooling and lighting loads without requiring any “hand held remote”, and (v) noninvasive implementation i.e. no need to modify or open the existing cooling and lighting loads at all and fixing any gadget inside these. The method proposed has been implemented on 3 traditional split type AC units of different brands and 16 composite units of LED (Light Emitting Diode) tube lights already existent in a lab. Compared with the manual mode of control which is insensitive to occupancy, the proposed method shows an energy saving in the range of 12.7%–36.15% for cooling loads while in the range of 35%–87.5% for lighting loads as the occupancy varies from high to low. The main economic and commercial impact of the present research is avoiding or postponing the replacement of the huge number of existing cooling and lighting devices by their smart counterparts which is often unaffordable for the entities in many countries.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jpowsour.2022.231736,Journal,Journal of Power Sources,scopus,2022-09-15,sciencedirect,A convolutional neural network model for battery capacity fade curve prediction using early life data,https://api.elsevier.com/content/abstract/scopus_id/85133568910,"Early prediction of battery performance degradation trends can facilitate research of new materials and cell designs, rapid deployment of batteries in real-world applications, timely replacement of batteries in critical applications, and even the secondary use market. In this study, we design a convolutional neural network model to predict the entire battery capacity fade curve – a critical indicator of battery performance degradation – using first 100 cycles of data (∼ three weeks of testing). We use the discharge voltage-capacity curves as input to the model and automate the feature extraction process through the convolutional layers of the network. Our approach can predict the per cycle capacity fade rate and rollover cycle (knee point) in the capacity fade curve, which indicate the onset of rapid capacity decay. On the publicly available graphite/LiFePO4 battery dataset, optimized networks predict the capacity fade curves, rollover cycle, and end of life with 3.7% (worst-case), 19%, and 17% mean absolute percentage errors, respectively.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2022.117196,Journal,Expert Systems with Applications,scopus,2022-09-15,sciencedirect,A simple modelling strategy for integer order and fractional order interval type-2 fuzzy PID controllers with their simulation and real-time implementation,https://api.elsevier.com/content/abstract/scopus_id/85129066364,"This paper presents a simple approach to the mathematical modelling of the Integer Order (IO) and Fractional Order (FO) Interval Type-2 Fuzzy Proportional Integral Derivative (IT2FPID) controllers. In this approach, the control effort produced by the IT2FPID controller is obtained by combining the individual control efforts generated by the Interval Type-2 Fuzzy Proportional (IT2FP), Interval Type-2 Fuzzy Integral (IT2FI), and Interval Type-2 Fuzzy Derivative (IT2FD) controllers. The analytical structures of each of the IT2FPID components are unveiled using one-dimensional (1D) input space and without using any AND or OR operator. To the best of the authors’ knowledge, such a strategy was never used and is completely new for the modelling of the IT2FPID controllers. Properties, computational issues, and design guidelines of the newly obtained controllers are discussed, and their applicability is delineated using five simulation examples and one experimental case study. A chemical reactor plant, two fractional order plants, a nonlinear plant, and a Twin Rotor Multi Input Multi Output System (TRMS) are considered in the simulation study. The experimental study is conducted on an unstable nonlinear Magnetic Levitation System (MLS). Moreover, to exhibit the usefulness of the newly derived controllers, simulation and real-time results are also compared with the existing results available in the literature. As the proposed controllers are plant model-free, they can be used for other control applications also.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmapro.2022.07.009,Journal,Journal of Manufacturing Processes,scopus,2022-09-01,sciencedirect,AMS-Net: Attention mechanism based multi-size dual light source network for surface roughness prediction,https://api.elsevier.com/content/abstract/scopus_id/85134221510,"Real-time and efficient surface roughness measurement is very essential for machining. Previously proposed non-contact roughness prediction methods usually use surface roughness images taken by a single light source. However, different light sources have a different reflection feature on the same roughness surface. A novel surface roughness prediction method of deep learning network model is proposed in this paper which is based on channel and spatial attention mechanisms, and embedded into the multi-size parallel framework (AMS-Net) for dual light sources. The network uses two branches which extract the features of surface roughness implied in images taken under different light sources. In each branch, the multi-size parallel convolution module (MSP) is constructed to extract parallel imagery pertaining to multi-size feature information of images with different roughness. In order to better fuse the surface roughness images taken by the dual light sources, the dual light source spatial attention module (DSA) and dual light source channel attention module (DCA) are proposed to project the space and channel respectively, while interacting with the roughness feature map from the MSP module. The dual light source roughness data set is built by white light and red laser for microimaging in this paper. Comparison experiments are implemented with other popular classification deep learning models. The results of experiment show the proposed novel AMS-Net network that achieves the best classification accuracy.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compeleceng.2022.108177,Journal,Computers and Electrical Engineering,scopus,2022-09-01,sciencedirect,Multi-feature embedded learning SVM for cloud detection in remote sensing images,https://api.elsevier.com/content/abstract/scopus_id/85133490273,"To improve remote sensing image transmission efficiency, we propose a cloud detection method using a multi-feature embedded learning support vector machine (SVM) to address cloud coverage occupying channel transmission bandwidth. Specifically, we first consider the imaging and physical properties of the clouds to construct a multi-feature space of cloud and non-cloud samples, which mainly includes five valuable features of grayscale, geometry, contrast, correlation, and angular second moment. Subsequently, we regard cloud detection (CDRSI) of remote sensing images as a binary classification problem, and construct a classifier by using multi-feature embedded learning SVM. Finally, the CDRSI is implemented by image block operations. Additionally, we build a large-scale real-world Remote Sensing Image Cloud Detection Benchmark (RSICDB) including 1520 images, where 790 non-cloud images and 430 cloud images are used as training datasets, 150 of which as test samples with the corresponding 150 mask results. Experimental results demonstrate that the proposed method can detect clouds with higher accuracy and robustness than compared methods.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.dyepig.2022.110547,Journal,Dyes and Pigments,scopus,2022-09-01,sciencedirect,Photochromic and luminescent materials for the development of Chemical Artificial Intelligence,https://api.elsevier.com/content/abstract/scopus_id/85133479311,"Artificial Intelligence (AI) is an interdisciplinary research line that aims to devise intelligent machines. Chemical Artificial Intelligence (CAI) focuses on designing intelligent chemical systems, primarily in wetware. This work shows that intelligent chemical systems can be implemented by devising neural surrogates that, by interplaying, can give rise to synchronization phenomena analogous to those of real neurons in the brain. When the signals employed in the communication are UV–visible radiations, the artificial neuron models can be implemented through photochromic and luminescent compounds, as this work demonstrates. Furthermore, this article describes how photochromic and luminescent materials contribute to processing Fuzzy logic, which is a good model of human power to compute by using words. Perspectives on how photoswitchable materials will be employed in further developments of CAI are outlined.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.techfore.2022.121778,Journal,Technological Forecasting and Social Change,scopus,2022-09-01,sciencedirect,A metaverse assessment model for sustainable transportation using ordinal priority approach and Aczel-Alsina norms,https://api.elsevier.com/content/abstract/scopus_id/85132442768,"Metaverse comes from the meta-universe, and it is the integration of physical and digital space into a virtual universe. Metaverse technologies will change the transportation system as we know it. Preparations for the transition of the transportation systems into the world of metaverse are underway. This study considers four alternative metaverses: auto-driving algorithm testing for training autonomous driving artificial intelligence, public transportation operation and safety, traffic operation, and sharing economy applications to obtain sustainable transportation. These alternatives are evaluated on thirteen sub-criteria, grouped under four main aspects: efficiency, operation, social and health, and legislation and regulation. A novel Rough Aczel–Alsa (RAA) function and the Ordinal Priority Approach (OPA) method are used in the assessment model. We also present a case study to demonstrate the applicability and exhibit the efficacy of the assessment framework in prioritizing the metaverse implementation alternatives.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2022.03.039,Journal,Future Generation Computer Systems,scopus,2022-09-01,sciencedirect,Towards automatic model specialization for edge video analytics,https://api.elsevier.com/content/abstract/scopus_id/85129734933,"The number of cameras deployed to the edge of the network increases by the day, while emerging use cases, such as smart cities or autonomous driving, also grow to expect images to be analyzed in real-time by increasingly accurate and complex neural networks. Unfortunately, state-of-the-art accuracy comes at a computational cost rarely available in the edge cloud. At the same time, due to strict latency constraints and the vast amount of bandwidth edge cameras generate, we can no longer rely on offloading the task to a centralized cloud. Consequently, there is a need for a meeting point between the resource-constrained edge cloud and accurate real-time video analytics. If state-of-the-art models are too expensive to run on the edge, and lightweight models are not accurate enough for the use cases in the edge, one solution is to demand less from the lightweight model and specialize it in a narrower scope of the problem, a technique known as model specialization. By specializing a model to the context of a single camera, we can boost its accuracy while keeping its computational cost constant. However, this also involves one training per camera, which quickly becomes unfeasible unless the entire process is fully automated. In this paper, we present and evaluate COVA (Contextually Optimized Video Analytics), a framework to assist in the automatic specialization of models for video analytics in edge cloud cameras. COVA aims to automatically improve the accuracy of lightweight models by specializing them to the context to which they will be deployed. Moreover, we discuss and analyze each step involved in the process to understand the different trade-offs that each one entails. Using COVA, we demonstrate that the whole pipeline can be effectively automated by leveraging large neural networks used as teachers whose predictions are used to train and specialize lightweight neural networks. Results show that COVA can automatically improve pre-trained models by an average of 21% mAP on the different scenes of the VIRAT dataset.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ssci.2022.105806,Journal,Safety Science,scopus,2022-09-01,sciencedirect,Pedestrian-vehicle interaction severity level assessment at uncontrolled intersections using machine learning algorithms,https://api.elsevier.com/content/abstract/scopus_id/85129520161,"As a consequence of the rapid growth of vehicular traffic, there is an increase in interactions between vehicles and pedestrians. The severity of these interactions varies with pedestrian, vehicle and roadway geometric characteristics. In the absence of real crash data, Surrogate Safety Measures (SSMs) are used to analyse the pedestrian-vehicle (P-V) interactions. The present study is intended to propose threshold risk indicator (RI) values for severe P-V interactions using both pedestrian and vehicle characteristics. A multilinear regression (MLR) P-V interaction model was developed using SPSS (Statistical Package for the Social Sciences) software. Videography method was used to collect traffic data from two 4-legged uncontrolled intersections. Pedestrian and vehicular data were extracted from the video using DataFromSky viewer software and risk indicator was calculated using post encroachment time and approaching vehicular speed. The interactions between pedestrians and vehicles were classified as normal conflicts and severe conflicts based on visual observations during the data extraction process. Python interface with support vector machines (SVM) algorithm was used to get threshold RI values for various pedestrian (gender and speed) and vehicle (type) characteristics.
                  From SVM results, it was observed that the threshold RI value for severe interactions decreases as the pedestrian crossing speed increases for the same vehicle and pedestrian characteristics. MLR results showed that pedestrian gender, age and speed, vehicle type and speed, interaction location and crossing position have a significant effect on RI. The results can be used to evaluate pedestrian-vehicle interaction severity level at an uncontrolled intersection.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jclepro.2022.132403,Journal,Journal of Cleaner Production,scopus,2022-08-20,sciencedirect,Smart peer-to-peer and transactive energy sharing architecture considering incentive-based demand response programming under joint uncertainty and line outage contingency,https://api.elsevier.com/content/abstract/scopus_id/85131436387,"Due to the widespread deployment of distributed energy resources, renewable energies and battery energy storage, the peer to peer (P2P) energy trading schematic has gained the staple attention for improving the energy efficiency and energy flexibility of power grids. This is while, smart demand response programming (DRP) is considered as the bridge between these two indicators of smart grid. Moreover, the subtle point of proliferating P2P schematics is the regulation towards the maximization of social welfare leading to economic profitability of customers and owner’s of microgrid and, eventually, reduction of pollutant emission of fossil fuels. Also, uncertainty, aroused by electrical consumption and renewable energy resources, is the core of every considerations, which has to be dealt with intelligent algorithms for strengthening the stability of transactions. On the other hand, compatibility with upper grid’s regulations, i.e. power loss and voltage deviation, along with determining fair price of energy trading are the subjects of P2P-based tactics. Therefore, this paper proposes a P2P-based transactive energy sharing architecture, as two stage mixed integer non-linear programming, using smart DRP integrated with machine learning approach, i.e. radial basis neural network. Firstly, the uncertainty of electrical demand and renewable energies are relaxed through short term forecasting. Doing so, the day-ahead transactions of peers are obtained based on their energy management objective, targeting the energy reliability of customers, which energy not supplied criterion has to be equal to zero. Then, participation of customers in DRP, cost of customers, revenue of microgrid’s owner and transactions of real time programming are optimally acquired based on Pareto front technique. Also, the simulations are conducted on IEEE 85 bus test system to realize the considerations. The results convey that the profitability of customers and owners is tied with the implementation of smart DRP and accurate forecasting of uncertain variables. In addition, the maximum improvements towards maximizing the revenue of owners and minimizing the cost of customers take place at hours which the electrical consumption is shifted from peaks to off-peaks and mid-peaks, certifying the performance of proposed methodology.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2022.05.031,Journal,Neurocomputing,scopus,2022-08-14,sciencedirect,Enhancing real-world adversarial patches through 3D modeling of complex target scenes,https://api.elsevier.com/content/abstract/scopus_id/85130316923,"Adversarial examples have proven to be a concerning threat to deep learning models, particularly in the image domain. While many studies have examined adversarial examples in the real world, most of them relied on 2D photos of the attack scene. As a result, the attacks proposed may have limited effectiveness when implemented in realistic environments with 3D objects or varied conditions. Some studies on adversarial learning have used 3D objects, however in many cases, other researchers are unable to replicate the real-world evaluation process. In this study, we present a framework that uses 3D modeling to craft adversarial patches for an existing real-world scene. Our approach uses a 3D digital approximation of the scene to simulate the real world. With the ability to add and manipulate any element in the digital scene, our framework enables the attacker to improve the adversarial patch’s impact in real-world settings. We use the framework to create a patch for an everyday scene and evaluate its performance using a novel evaluation process that ensures that our results are reproducible in both the digital space and the real world. Our evaluation results show that the framework can generate adversarial patches that are robust to different settings in the real world.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compag.2022.107179,Journal,Computers and Electronics in Agriculture,scopus,2022-08-01,sciencedirect,Weed detection in paddy field using an improved RetinaNet network,https://api.elsevier.com/content/abstract/scopus_id/85133903032,"Weeds are one of the main hazards affecting the yield and quality of rice. In farmland ecosystem, weeds compete with rice for resources such as light, water, soil and space, and also cause plant disease by providing habitats for pests, resulting in a decline in yield of rice. Spraying herbicides is used most frequently due to their lower cost than manual weeding and they can effectively control a varieties of weeds. Precise spraying application may utilise intelligent technology to precisely limit the weed growth at specific locations and control the consumption of herbicides, which not only has lower cost and risk for the environment but also increases the economic benefits of agricultural products. The target of this work is to use deep learning model to perform weed detection in rice crop images and to achieve accurate real-time detection and low machine cost resulting in widely used in practice. For this purpose, a dataset of rice and weeds for object detection is established by means of on-site shooting and crawling of images on the web, which contains rice and eight categories of weeds. However, the overlap between crops and weeds poses a great challenge to weed detection. To overcome this challenge, this paper proposed a model named WeedDet based on RetinaNet, which improves the feature extraction ability of the backbone, feature pyramid network and detection head to deal with the complex information in the image, respectively. And the structure of feature pyramid and detection head are lightened to improve speed of detection. The specific implementation methods are as follows: Firstly, we propose Det-ResNet to reduce the loss of detailed information and improve the feature extraction ability of detailed textures by modifying the initial convolution structure of ResNet. In addition, the improved feature pyramid network fuses the features extracted by Det-ResNet with higher efficiency without loss of accuracy. Secondly, we propose Efficient Retina Head (ERetina-Head) with thin feature maps (small channel number feature maps) and large separable convolution, which not only saves memory and computation, but also pooling more powerful feature maps during training and inference. Finally, we combine Smooth
                        L
                     
                     1 loss and GIoU loss to calculate the regression loss. In addition, Varifocal loss is used to unify the classification and quality evaluation branches in training. Our network achieves a high mAP of 94.1% and the frame rate of 24.3 fps, which is 5.5% mAP and 5.6 fps higher than the baseline RetinaNet. Experiments show that fps of WeedDet (24.3) is second only to YOLOv3 (26.3) while the mAP is 9.9% (0.941 vs 0.842) higher than YOLOv3, and the mAP is also higher than other models, verifying the effectiveness and efficiency of the model.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ecmx.2022.100261,Journal,Energy Conversion and Management: X,scopus,2022-08-01,sciencedirect,Multi-objective optimization of turbocharger turbines for low carbon vehicles using meanline and neural network models,https://api.elsevier.com/content/abstract/scopus_id/85133274528,"Due to slow turnover of the global vehicle parc internal combustion engines will remain a primary means of motive power for decades, so the automotive industry must continue to improve engine thermal efficiency to reduce 
                        
                           
                              
                                 CO
                              
                              
                                 2
                              
                           
                        
                      emissions, since savings will be compounded over the long lifetime of millions of vehicles. Turbochargers are a proven efficiency technology (most new vehicles are turbocharged) but are not optimally designed for real-world driving. The aim of this study was to develop a framework to optimize turbocharger turbine design for competing customer objectives: minimizing fuel consumption (and thus 
                        
                           
                              
                                 CO
                              
                              
                                 2
                              
                           
                        
                      emissions) over a representative drive cycle, while minimizing transient response time. This is achieved by coupling engine cycle, turbine meanline, and neural network inertia models within a genetic algorithm-based optimizer, allowing aerodynamic and inertia changes to be accurately reflected in drive cycle fuel consumption and transient performance. Exercising the framework for the average new passenger car across a drive cycle representing the Worldwide harmonized Light vehicles Test Procedure reveals the trade-off between competing objectives and a turbine design that maintains transient response while minimizing fuel consumption due to a 3 percentage-point improvement in turbine peak efficiency, validated by experiment. This optimization framework is fast to execute, requiring only eight turbine geometric parameters, making it a commercially viable procedure that can refine existing or optimize tailor-made turbines for any turbocharged application (whether gasoline, diesel, or alternatively fuelled), but if applied to turbocharged gasoline cars in the EU would lead to lifetime 
                        
                           
                              
                                 CO
                              
                              
                                 2
                              
                           
                        
                     
                     savings of 
                        
                           >
                        
                     
                     290,000 tonnes per production year, and millions of tonnes if deployed worldwide.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.simpa.2022.100319,Journal,Software Impacts,scopus,2022-08-01,sciencedirect,AI-SocialDisaster: An AI-based software for identifying and analyzing natural disasters from social media,https://api.elsevier.com/content/abstract/scopus_id/85132430699,"AI-SocialDisaster is a decision support system for identifying and analyzing natural disasters like earthquakes, floods, bushfires using social media feeds. It captures real-time social media messages and then uses Natural Language Processing (NLP) based algorithms like entity detection, category classification, and sentiment analysis to identify and locate various natural disasters. Moreover, using Artificial Intelligence (AI) based algorithms like anomaly detection, regression, and clustering, AI-SocialDisaster generates AI-based insights for disaster planners and strategists. The software can be accessed through Windows, iOS, and Android apps from a wide range of devices including mobiles, tablets, and desktops. AI-SocialDisaster is available at https://github.com/DrSufi/DisasterAI.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cie.2022.108302,Journal,Computers and Industrial Engineering,scopus,2022-08-01,sciencedirect,Multi-strategy hybrid heuristic algorithm for single container weakly heterogeneous loading problem,https://api.elsevier.com/content/abstract/scopus_id/85132231873,"Three-dimensional single container weakly heterogeneous loading problem is one of the most classical tasks which has various applications in manufacture and logistics industry. Solving this problem could improve transportation efficiency to bring great benefit to shipping customers. During the last two decades, many heuristic, meta-heuristic and hybrid algorithms have been proposed to maximize container volume utilization to reduce the waste of container space significantly. Despite their success in many real-world applications, it is still a challenging task to recommend satisfactory loading levels within a limited time frame when clients approach for options of different combinations of shipping items. In this paper, we propose a novel multi-strategy hybrid heuristic algorithm to achieve timely planning for clients in a required short time frame. In specific, a probabilistic model is used to combine the strength of two optimization strategies, i.e. an ant colony method and a constructive greedy method, to speed up the optimization process and ensure better convergence. In addition, a tree pruning strategy is designed to further improve the efficiency of the hybrid heuristic algorithm. Extensive experiments demonstrate the effectiveness of our method in terms of both volume utilization rate and algorithm processing speed compared to state-of-the-art methods. Based on the comparison results by using BR dataset, we achieved averagely 94.31% volume utilization rate and 50.16 s processing speed, which is the best performance by considering both algorithm effectiveness and efficiency. Further, our proposed method has been deployed in a real business case to provide plan solutions to individual customer shipping requests and achieved high customer satisfaction rate.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.tra.2022.05.024,Journal,Transportation Research Part A: Policy and Practice,scopus,2022-08-01,sciencedirect,A new curb lane monitoring and illegal parking impact estimation approach based on queueing theory and computer vision for cameras with low resolution and low frame rate,https://api.elsevier.com/content/abstract/scopus_id/85131413326,"The rapid development of the internet of things (IoT), sensing technologies, and machine learning and deep learning techniques, along with the growing variety and volume of data, have yielded new perspectives on how novel technologies can be applied to obtain new sources of curb data to achieve cost-effective curb management. This study presents a new computer vision–based data acquisition and analytics approach for curb lane monitoring and illegal parking impact assessment. The proposed “rank, detect, and quantify impacts” system consists of three main modules: 1) hotspot identification based on rankings generated by local spatial autocorrelation analysis, 2) curb lane occupancy estimation leveraging traffic cameras and computer vision techniques, and 3) illegal parking traffic impact quantification using an M/M/∞ queueing model. To demonstrate the feasibility and validity of the proposed approach, it was tested and empirically validated using field data collected from three case study sites in Midtown Manhattan, New York City (NYC)—one of the most complex urban transportation networks in the world. Different types of curb lane occupancy, including parking and bus lanes, and different frequencies of illegal parking (high, moderate, low) were investigated. The proposed method was proven to be effective even for low resolution and discontinuous video feeds obtained from publicly available traffic cameras. All three case study sites achieved good detection accuracy (86% to 96%) for parking and bus lane occupancy, and acceptable precision and recall in detecting illegal parking events. The queueing model was also proven to effectively quantify link travel time with the appearance of illegal parking events of different frequencies. The proposed “rank, detect, and quantify impacts” system is friendly for large-scale real-time implementation and is highly scalable to help evaluate the impact of other modes such as bike or mobility-on-demand (MOD) services. It can also be easily adopted by other cities to provide transportation agencies with effective data collection and innovative curb space management strategies.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cose.2022.102778,Journal,Computers and Security,scopus,2022-08-01,sciencedirect,Everything you control is not everything: Achieving intention-concealed visit on social networks,https://api.elsevier.com/content/abstract/scopus_id/85131216276,"With the flourishment of Artificial Intelligence (AI), the quality of services on online social networks (OSNs) has improved tremendously. Through the introduction of AI into OSNs, providers enhance the users experience. However, the risk of data misuse has also been magnified. And there has been a trend towards users’ mistrust when it comes to sharing their true intention on OSN platforms, primarily because of privacy concerns. In this paper, we propose an effective intention-concealing visitation framework named Aviv, which acts as a credible and private third-party where it generates artificial intention-concealed browsing (AICB trajectories) for users to conceal their true intentions. The browsing trajectory is a sequence composed of blogs, bloggers, news, or a mixture containing visitable content. Specifically, Aviv first extracts accessible graphs composed of visitable contents from applied OSN platforms. Then an elaborate and personalized divert scoring process is conducted to measure optional decoy visits’ effectiveness. Finally, using the divert scoring values, elaborate and personalized decoy visits are picked out, Aviv composes AICB trajectories with true intentions and picked decoy visits. Aviv is implemented as a credible private third-party and tested on a real OSN, the performance evaluation results show that Aviv is effective and efficient.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2022.05.078,Journal,Information Sciences,scopus,2022-08-01,sciencedirect,Poly-linear regression with augmented long short term memory neural network: Predicting time series data,https://api.elsevier.com/content/abstract/scopus_id/85131073262,"Until recently, the supply chain sector, which had been getting by with scattered spreadsheets, phone conversations, and even paper-based records until recently, was exposed for its antiquated methods during the epidemic. As a result, businesses have undergone a decade of digital change in only a few months, with the epidemic driving them to replace antiquated procedures with AI, machine learning, and data science technology. The supply chain sector has reached a point in its AI adoption where the technology is solid and powerful enough to improve decision-making significantly. For example, predictive analytics (e.g., time series forecasting) is already a proven benefit. Such technology is smart enough to recognise irregularities and learn how a stock market will move in real-time. With the advancement of digital innovation, researchers have focused on deep learning (DL) models to get a more accurate and unbiased estimation. Consequently, this paper presents a novel DL approach for time series prediction using a combination of poly-linear regression with Long Short-Term Memory (LSTM) and data augmentation. It is consequently named Poly-linear Regression with Augmented Long Short Term Memory Neural Network (PLR-ALSTM-NN). The proposed DL model can be exploited to predict the future financial markets more accurately than existing state-of-the-art neural networks and machine learning tools. In order to make the model a more generic one, it is first validated on four financial market time-series datasets and then also implemented on a supply chain time-series dataset to predict sales data. LSTM, with its feedback connections, can process an entire series of data as well as single data points and statistical regression establishes the strength and character of the relationship between some dependent and independent variables. After doing experimental validations and based on the long-term and short-term predicted data, the suitability of the proposed PLR-ALSTM-NN is well-grounded against a few recent and advanced state-of-the-art machine learning, and DL approaches.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.chemosphere.2022.134585,Journal,Chemosphere,scopus,2022-08-01,sciencedirect,Simultaneous determination of 16 urinary metabolites of organophosphate flame retardants and organophosphate pesticides by solid phase extraction and ultra performance liquid chromatography coupled to tandem mass spectrometry,https://api.elsevier.com/content/abstract/scopus_id/85128525379,"Organophosphate flame retardants (OPFRs) and organophosphate pesticides (OPPs), pertaining to organophosphate esters, are ubiquitous in environment and have been verified to pose noticeable risks to human health. To evaluate human exposures to OPFRs and OPPs, a fast and sensitive approach based on a solid phase extraction (SPE) followed by the ultra-high-performance liquid chromatography coupled to tandem mass spectrometry (UPLC-MS/MS) detection has been developed for the simultaneous analysis of multiple organophosphorus metabolites in urine. The method allows the identification and quantification of ten metabolites of the most common OPFRs and all six dialkylphosphates (DAPs) of OPPs concerning the population exposure characteristics. The method provided good linearities (R2 = 0.998–0.999), satisfactory method detection limits (MDLs) (0.030–1.129 ng/mL) and only needed a small volume (200 μL) of urine. Recovery rates ranged 73.4–127.1% at three spiking levels (2, 10 and 25 ng/mL urine), with both intra- and inter-day precision less than 14%. The good correlations for DAPs in a cross-validation test with a previous gas chromatography-mass spectrometry (GC-MS) method and a good inter-laboratory agreement for several OPFR metabolites in a standard reference material (SRM 3673) re-enforced the precision and validity of our method. Finally, the established method was successfully applied to analyze 16 organophosphorus metabolites in 35 Chinese children's urine samples. Overall, by validating the method's sensitivity, accuracy, precision, reproducibility, etc., data reliability and robustness were ensured; and the satisfactory pilot application on real urine samples demonstrated feasibility and acceptability of this method for being implemented in large population-based studies.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2022.117125,Journal,Expert Systems with Applications,scopus,2022-08-01,sciencedirect,An embedded toolset for human activity monitoring in critical environments,https://api.elsevier.com/content/abstract/scopus_id/85128232717,"In many working and recreational activities, there are scenarios where both individual and collective safety have to be constantly checked and properly signaled, as occurring in dangerous workplaces or during pandemic events like the recent COVID-19 disease. From wearing personal protective equipment to filling physical spaces with an adequate number of people, it is clear that a possibly automatic solution would help to check compliance with the established rules. Based on an off-the-shelf compact and low-cost hardware, we present a deployed real use-case embedded system capable of perceiving people’s behavior and aggregations and supervising the appliance of a set of rules relying on a configurable plug-in framework. Working on indoor and outdoor environments, we show that our implementation of counting people aggregations, measuring their reciprocal physical distances, and checking the proper usage of protective equipment is an effective yet open framework for monitoring human activities in critical conditions.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ssci.2022.105766,Journal,Safety Science,scopus,2022-08-01,sciencedirect,Industrial internet of things and unsupervised deep learning enabled real-time occupational safety monitoring in cold storage warehouse,https://api.elsevier.com/content/abstract/scopus_id/85127200076,"Occupational safety and health (OSH) has always been a big concern in the labor-intensive warehouse industry, especially under peculiar circumstances like a low temperature. Accordingly, this paper aims to propose a framework of a smart system using the Industrial Internet of Things (IIoT) and digital twin (DT) technologies to realize real-time occupational safety monitoring in the warehouse and ensure synchronized cyber-physical spaces for information traceability and visibility. The unsupervised deep neural structure of stacked auto-encoder (SAE) is designed to identify abnormal stationary from human motion status, which is perceived as a sign of potential accident. The model is developed to automatically update online by cooperating with calibration samples so as to keep in accordance with the evolution of surroundings. The Bluetooth low energy (BLE) and a log-distance path loss model are used to fulfill indoor localization in order for managers to promptly respond to an incident on site. Besides, some intelligent services are enabled to promote the efficiency of safety management. A real-life case study is carried out in an air cargo cold storage warehouse to illustrate the viability and rationality of the proposed system and methods. The elaboration of the implementation is envisioned to facilitate replication and reproduction effectively. The impact of learning features concerned with distance and vibration on the performance of anomaly detection has also been analyzed by experiments. The insights and lessons gained in this study hold the promise of providing a reference or sparking new ideas for researchers and practitioners to meet similar needs in practice.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2022.02.024,Journal,Future Generation Computer Systems,scopus,2022-08-01,sciencedirect,Dynamic and adaptive fault-tolerant asynchronous federated learning using volunteer edge devices,https://api.elsevier.com/content/abstract/scopus_id/85126594978,"The number of devices, from smartphones to IoT hardware, interconnected via the Internet is growing all the time. These devices produce a large amount of data that cannot be analyzed in any data center or stored in the cloud, and it might be private or sensitive, thus precluding existing classic approaches. However, studying these data and gaining insights from them is still of great relevance to science and society. Recently, two related paradigms try to address the above problems. On the one hand, edge computing (EC) suggests to increase processing on edge devices. On the other hand, federated learning (FL) deals with training a shared machine learning (ML) model in a distributed (non-centralized) manner while keeping private data locally on edge devices. The combination of both is known as federated edge learning (FEEL). In this work, we propose an algorithm for FEEL that adapts to asynchronous clients joining and leaving the computation. Our research focuses on adapting the learning when the number of volunteers is low and may even drop to zero. We propose, implement, and evaluate a new software platform for this purpose. We then evaluate its results on problems relevant to FEEL. The proposed decentralized and adaptive system architecture for asynchronous learning allows volunteer users to yield their device resources and local data to train a shared ML model. The platform dynamically self-adapts to variations in the number of collaborating heterogeneous devices due to unexpected disconnections (i.e., volunteers can join and leave at any time). Thus, we conduct comprehensive empirical analysis in a static configuration and highly dynamic and changing scenarios. The public open-source platform enables interoperability between volunteers connected using web browsers and Python processes. We show that our platform adapts well to the changing environment getting a numerical accuracy similar to today’s configurations using a given number of homogeneous (hardware and software) computers as a static platform for learning. We demonstrate the fault-tolerance of the platform in self-recovering from unexpected disconnections of volunteer devices. We then prove that EC, coupled with FL, can lead to scientific tools that can be practical involving real users for final competitive numerical results in real problems for science and society.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aej.2021.11.027,Journal,Alexandria Engineering Journal,scopus,2022-08-01,sciencedirect,Automated object detection on aerial images for limited capacity embedded device using a lightweight CNN model,https://api.elsevier.com/content/abstract/scopus_id/85119478871,"With the growing demand for geospatial data, challenging aerial images with high spatial, spectral, and temporal resolution achieve excellent development. Currently, deep Convolutional Neural Network (CNN) structures are applied widely for object detection. Nevertheless, existing deep CNN-based models consist of complex network structures and require immense amounts of graphics processing unit (GPU) computation power with high energy consumption. Thus, achieving efficient real-time object detection for limited memory and processing capacity embedded device is a major challenge. This paper proposes a feasible and lightweight object detection model based on deep CNN where a mobile inverted bottleneck module is adopted in the backbone structure. Moreover, an enhanced spatial pyramid pooling is adopted to increase the receptive field in the network by concatenating the multi-scale local region features. The experimental results demonstrated that the proposed model achieved higher average precision and required the smallest memory storage compared to previous works. Moreover, the proposed model offers the best trade-offs in terms of detection accuracy, model size, and detection time which has excellent potential to be deployed on limited capacity embedded device.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2022.108827,Journal,Knowledge-Based Systems,scopus,2022-07-19,sciencedirect,Application of domain-adaptive convolutional variational autoencoder for stress-state prediction,https://api.elsevier.com/content/abstract/scopus_id/85129750653,"Applying data-driven methods such as deep learning in material mechanics is challenging because producing a sufficiently large, labeled dataset is costly resource-wise. This paper outlines a new approach to overcoming this difficulty by transferring knowledge from a source domain of finite-element-analysis data to a target domain of real-world test-specimen images so that a model capable of accurate and robust predictions in both domains may be constructed. To achieve this transfer of knowledge, discrepancy-based unsupervised domain adaptation is adopted into a convolutional variational autoencoder structure. To evaluate the proposed approach, a four-point bending experiment was conducted on 6061 aluminum alloy and 316 stainless steel to produce 550 unlabeled target-domain data images. The same bending situation was analyzed using the finite-element method implemented in the commercial software package ABAQUS to produce 6000 labeled, source-domain data images. The proposed domain-adaptive convolutional variational autoencoder was trained using the maximum mean discrepancy method on the target- and the source-domain data. The predictions using the domain-adapted convolutional variational autoencoder were relatively more accurate than those using the model trained only on the source domain. It is expected that the proposed approach can address the scarcity of labeled data in various applications of material mechanics and provide a base technology for the development of various data-driven approaches.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2022.108742,Journal,Knowledge-Based Systems,scopus,2022-07-08,sciencedirect,Investigating the informativeness of technical indicators and news sentiment in financial market price prediction,https://api.elsevier.com/content/abstract/scopus_id/85129221558,"Real-time market prediction tool tracking public opinion in specialized newsgroups and informative market data persuades investors of financial markets. Previous works mainly used lexicon-based sentiment analysis for financial markets prediction, while recently proposed transformer-based sentiment analysis promise good results for cross-domain sentiment analysis. This work considers temporal relationships between consecutive snapshots of informative market data and mood time series for market price prediction. We calculate the sentiment mood time series via the probability distribution of news embedding generated through a BERT-based transformer language model fine-tuned for financial domain sentiment analysis. We then use a deep recurrent neural network for feature extraction followed by a dense layer for price regression. We implemented our approach as an open-source API for real-time price regression. We build a corpus of financial news related to currency pairs in foreign exchange and Cryptocurrency markets. We further augment our model with informative technical indicators and news sentiment scores aligned based on news release timestamp. Results of our experiments show significant error reduction compared to the baselines. Our Financial News and Financial Sentiment Analysis RESTFul APIs are available for public use.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.remn.2021.12.001,Journal,Revista Espanola de Medicina Nuclear e Imagen Molecular,scopus,2022-07-01,sciencedirect,"Survey of the Radioguided Surgery Working Group (GTCRG-RGSWG) of the Spanish Society of Nuclear Medicine and Molecular Imaging (SEMNIM): Radioguided localization of non-palpable breast lesions with or without indication for selective sentinel node biopsy: ROLL, SNOLL and <sup>125</sup>I seeds",https://api.elsevier.com/content/abstract/scopus_id/85132240142,"Objetivo
                  Conocer el estado actual de la técnica de localización radioguiada de lesiones no palpables de mama con o sin indicación de biopsia selectiva de ganglio centinela —ROLL, SNOLL y semillas de 125I— mediante la realización de una encuesta nacional elaborada por el Grupo de Trabajo de Cirugía Radioguiada (GTCRG) de la Sociedad Española de Medicina Nuclear e Imagen Molecular (SEMNIM).
               
                  Material y métodos
                  En octubre del 2020 se envió la encuesta, en formato digital, a los distintos servicios de Medicina Nuclear de nuestra geografía. Se dio un tiempo de respuesta de 2meses con prórroga de 15 días. Se ha obtenido el número de procedimientos ROLL/SNOLL de cada centro y la metodología utilizada, recogiendo importantes detalles técnicos. Además, se ha incluido un apartado específico sobre las semillas de 125I. Los resultados se volcaron de forma automática en una hoja de cálculo Excel 2007 para su posterior análisis con el mismo programa.
               
                  Resultados
                  La encuesta fue contestada por 55 centros; 21 utilizan arpón mientras que los 34 restantes emplean distintas técnicas de cirugía radioguiada (CRG) para la localización de lesiones no palpables de mama, desglosando los resultados en 13apartados. La dosis de trazador habitualmente utilizada es de 111 MBq para la técnica ROLL y de 222 MBq para la técnica SNOLL, con un volumen de 0,2ml. El protocolo más habitual es el de 2días. El 26% de los centros que realiza CRG utiliza semillas de 125I tanto para la detección de lesiones mamarias como de ganglios sospechosos/patológicos, siendo el tiempo entre la implantación y la extirpación es de unos 3 días, con posterior control radiológico en la mayoría de los casos.
               
                  Conclusión
                  La encuesta pone de manifiesto la relevancia de la cirugía radioguiada en el manejo de los pacientes con cáncer de mama en las diferentes etapas de la enfermedad, con disparidad en la implementación de las nuevas técnicas y herramientas, que responde a las múltiples realidades asistenciales de los servicios de Medicina Nuclear.
               
                  Objective
                  To know the current status of the technique of radioguided localisation of non-palpable breast lesions with or without indication for selective sentinel node biopsy -ROLL, SNOLL and 125I seeds- by conducting a national survey developed by the Working Group on Radioguided Surgery (GTCRG) of the Spanish Society of Nuclear Medicine and Molecular Imaging (SEMNIM).
               
                  Material and methods
                  In October 2020, the form was sent in digital format to the different nuclear medicine services in Spain. A response time of 2months with an overtime of 15 days was given. The number of ROLL/SNOLL procedures in each centre and the methodology used were obtained, including important technical details. In addition, a specific section on 125I seeds was included. The results were automatically downloaded into an Excel 2007 spreadsheet for subsequent analysis with the same program.
               
                  Results
                  The survey was answered by 55 centres; 21 use wire-guided localisation while the remaining 34 use different radioguided surgery techniques (RGS) for the localisation of non-palpable breast lesions, with the results itemized into thirteen sections. The commonly used tracer dose is 111 MBq for the ROLL technique and 222 MBq for the SNOLL technique, with a volume of 0.2ml. The most common protocol is the two-day protocol. 26% of centres performing CRG use 125I seeds for both breast lesion and suspicious/pathological node detection, with the time between implantation and removal being about 3 days, with subsequent radiological control in most cases.
               
                  Conclusion
                  The survey shows the relevance of radioguided surgery in the management of breast cancer patients at different stages of the disease, with disparity in the implementation of new techniques and tools, which responds to the multiple healthcare realities of Nuclear Medicine services.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijdrr.2022.103089,Journal,International Journal of Disaster Risk Reduction,scopus,2022-07-01,sciencedirect,A near-real-time global landslide incident reporting tool demonstrator using social media and artificial intelligence,https://api.elsevier.com/content/abstract/scopus_id/85131668110,"The development of a system that monitors social media continuously for general landslide-related content using a landslide classification model to identify and retain the most relevant information is described and validated. The system harvests photographs in real-time from these data and tags each image as landslide or not-landslide. A training model was developed with input from computer scientists, geologists (landslide specialists) and social media specialists to establish a large image dataset that has then been applied to the live Twitter data stream. The preliminary model was developed by training a convolutional neural network on the dataset. Quantitative verification of the system's performance during a real-world deployment shows that the system can detect landslide reports with Precision = 76%. The demonstrator model is currently running live https://landslide-aidr.qcri.org/service.php; the next stage of development will incorporate stakeholder and user feedback.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compag.2022.107097,Journal,Computers and Electronics in Agriculture,scopus,2022-07-01,sciencedirect,Application of multispectral imaging combined with machine learning models to discriminate special and traditional green coffee,https://api.elsevier.com/content/abstract/scopus_id/85131453324,"Non-destructive techniques aided by machine learning models are widely implemented in food analysis. To discriminate between ‘special’ and ‘traditional’ classes of green coffee beans, an advanced multispectral imaging technique based on reflectance and autofluorescence data was employed in combination with four machine learning algorithms (SVM, RF, XGBoost, and CatBoost). Of the four algorithms, SVM showed superior accuracy (0.96) for the test dataset. Analysis using PCA and SVM algorithms showed that autofluorescence data from excitation/emission combination of 405/500 nm contributed most to the discrimination of special green coffee from the traditional class. Fluorophores that can be linked to green fluorescence, namely catechin, caffeine and 4-hydroxybenzoic, synapic and chlorogenic acids, were found to have a considerable influence on the differentiation of specialty and traditional coffees. Analysis based on multispectral autofluorescence imaging combined with SVM models was proven to be a valuable tool for future applications in the food industry for the non-destructive and real-time classification of special and traditional green coffee.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmsy.2022.05.018,Journal,Journal of Manufacturing Systems,scopus,2022-07-01,sciencedirect,Graph neural network and multi-agent reinforcement learning for machine-process-system integrated control to optimize production yield,https://api.elsevier.com/content/abstract/scopus_id/85131416727,"In this paper, an integrated control framework is proposed for the optimization of the production yield by integrating different levels of a manufacturing system, including system, process, and machine levels. The manufacturing system is modeled as a graph by treating machines as nodes and material flows as links. The graph model enjoys high flexibility and is able to incorporate all relevant real-time information across all levels of the manufacturing system in the dynamic node feature. Since the real-time tool state is essential for decision making, Recursive Bayesian Estimation (RBE) is adopted to reduce the tool state observations through sensors and machine learning models and provide more accurate tool state estimation to be included into the graph node feature. With the graph model, Graph Neural Network (GNN) is applied to process the node features to generate node embedding that reflects both local and global information. For the integrated control purpose, each machine node is then be treated as a distributed agent in Multi-Agent Reinforcement Learning (MARL) that conditions its policy on the node embedding from GNN. State-of-the-art GNN and MARL algorithms, namely Graph Attention Network (GAT) and Value Decomposition Actor Critic (VDAC), are implemented to train learnable parameters in GNN-MARL networks to learn the optimal multi-agent policy. Extensive numerical experiments and analysis proves the effectiveness of the proposed integrated control framework.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2022.104554,Journal,Microprocessors and Microsystems,scopus,2022-07-01,sciencedirect,Real-time edge computing on multi-processes and multi-threading architectures for deep learning applications,https://api.elsevier.com/content/abstract/scopus_id/85130597393,"As the computing power of embedded system hardware devices continues to grow, more and more deep learning models have been gradually transplanted into edge devices. Accordingly, a variety of application scenarios have been developed with more complex inference models or multiple models that work together. Moreover, with consideration given to cost, a single edge computing device can integrate multiple input sources and simultaneously complete the application of multiple scenarios. To achieve good performance on edge computing devices, this paper probes into the software architecture design of multi-processes and multi-threading architectures on edge computing device, in order to realize real-time edge computing. In the experiment, multiple face-related deep learning models, namely, face detection, face recognition, age estimation, gender estimation, and emotion estimation, are used to demonstrate the differences between multi-processes and multi-threading on edge computing devices. According to the experimental results, it is known that if the number of central processing unit (CPU) cores and memory space are small, the multi-threading architecture can better improve efficiency; conversely, the multi-processes architecture can be used. The architecture proposed in this paper has reference value, and can improve the execution efficiency of deep learning technology on edge computing, and reduce the cost of deployment.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.dss.2022.113794,Journal,Decision Support Systems,scopus,2022-07-01,sciencedirect,Shedding light on blind spots – Developing a reference architecture to leverage video data for process mining,https://api.elsevier.com/content/abstract/scopus_id/85129825456,"Process mining is one of the most active research streams in business process management. In recent years, numerous methods have been proposed for analyzing structured process data. In many cases, however, only the digitized parts of processes are directly captured by process-aware information systems, whereas manual activities often leave blind spots in the process analysis. While video data can contain valuable process-related information that is not captured in information systems, a standardized approach to extracting event logs from unstructured video data remains lacking. To solve this problem and facilitate the systematic usage of video data in process mining, we have designed the ViProMiRA, a reference architecture that bridges the gap between computer vision and process mining. The various evaluation activities in our design science research process ensure that the proposed ViProMiRA allows flexible, use case-driven, and context-specific instantiations. Our results also show that a prototypical implementation of the ViProMiRA is capable of automatically extracting more than 70% of the process-relevant events from a real-world video dataset in a supervised learning scenario.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ese.2022.100172,Journal,Environmental Science and Ecotechnology,scopus,2022-07-01,sciencedirect,Data augmentation and machine learning techniques for control strategy development in bio-polymerization process,https://api.elsevier.com/content/abstract/scopus_id/85129407681,"Machine learning has been increasingly used in biochemistry. However, in organic chemistry and other experiment-based fields, data collected from real experiments are inadequate and the current coronavirus disease (COVID-19) pandemic has made the situation even worse. Such limited data resources may result in the low performance of modeling and affect the proper development of a control strategy. This paper proposes a feasible machine learning solution to the problem of small sample size in the bio-polymerization process. To avoid overfitting, the variational auto-encoder and generative adversarial network algorithms are used for data augmentation. The random forest and artificial neural network algorithms are implemented in the modeling process. The results prove that data augmentation techniques effectively improve the performance of the regression model. Several machine learning models were compared and the experimental results show that the random forest model with data augmentation by the generative adversarial network technique achieved the best performance in predicting the molecular weight on the training set (with an R2 of 0.94) and on the test set (with an R2 of 0.74), and the coefficient of determination of this model was 0.74.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2022.03.053,Journal,Information Sciences,scopus,2022-07-01,sciencedirect,Distributed parallel deep learning with a hybrid backpropagation-particle swarm optimization for community detection in large complex networks,https://api.elsevier.com/content/abstract/scopus_id/85127499354,"In this paper, a parallel deep learning-based community detection method in large complex networks (CNs) is proposed. First, a CN partitioning method is employed to divide the CN into multiple chunks to improve the efficiency in terms of space and time complexities. Next, the method is integrated with two optimization algorithms: (1) backpropagation (BP), which optimizes deep learning locally within each local chunk of the CN; (2) particle swarm optimization (PSO), which is used to improve the BP optimization involving all CN chunks. PSO utilizes a multi-objective function to improve the effectiveness of the proposed method. In addition, a distributed environment is set up to conduct parallel optimization of the proposed method so that multi-local optimizations could be performed simultaneously. A set of 16 real-world CNs in a range from small to large size are used to verify the effectiveness and efficiency of the method in a benchmark study. The proposed method is implemented in multi-machines with central processing unit (CPU) and graphics processing unit (GPU) devices. The results reveal the effective role of the proposed deep learning with hybrid BP–PSO optimization in detecting communities in large CNs, which requires minimum execution time on both CPU and GPU devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.egyr.2022.01.224,Journal,Energy Reports,scopus,2022-07-01,sciencedirect,Research on anomaly detection of wireless data acquisition in power system based on spark,https://api.elsevier.com/content/abstract/scopus_id/85125473240,"In the era of big data, the network data of power system is more and more complex. Due to the limitation of data storage and processing capacity, the abnormal data detection of power grid terminal information system has the problems of low accuracy and high false alarm rate. The original machine learning algorithm with good detection effect is limited by the processing capacity and storage space of the traditional platform, and the detection effect and efficiency are significantly reduced. This paper takes improving the detection accuracy of abnormal data as the main research target, and designs an abnormal data behavior analysis program based on the Internet of Things under the Spark framework combined with improved Support Vector Machine (SVM) and random forest algorithm. The parallel SA_SVM_RF anomaly data behavior detection model based on Spark is mainly studied and applied to real-time detection. Combined with the respective advantages of Internet of Things technology and machine learning in anomaly data detection, the detection capability and rate of power grid anomaly data detection model are further improved. Experimental tests show that the proposed program is superior to traditional methods in data anomaly detection efficiency and quality, and has certain research significance in the field of power grid security.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.sigpro.2022.108509,Journal,Signal Processing,scopus,2022-07-01,sciencedirect,Low-complexity soft ML detection for generalized spatial modulation,https://api.elsevier.com/content/abstract/scopus_id/85125258890,"Generalized Spatial Modulation (GSM) is a recent Multiple-Input Multiple-Output (MIMO) scheme, which achieves high spectral and energy efficiencies. Specifically, soft-output detectors have a key role in achieving the highest coding gain when an error-correcting code (ECC) is used. Nowadays, soft-output Maximum Likelihood (ML) detection in MIMO-GSM systems leads to a computational complexity that is unfeasible for real applications; however, it is important to develop low-complexity decoding algorithms that provide a reasonable computational simulation time in order to make a performance benchmark available in MIMO-GSM systems. This paper presents three algorithms that achieve ML performance. In the first algorithm, different strategies are implemented, such as a preprocessing sorting step in order to avoid an exhaustive search. In addition, clipping of the extrinsic log-likelihood ratios (LLRs) can be incorporating to this algorithm to give a lower cost version. The other two proposed algorithms can only be used with clipping and the results show a significant saving in computational cost. Furthermore clipping allows a wide-trade-off between performance and complexity by only adjusting the clipping parameter.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2022.02.008,Journal,Future Generation Computer Systems,scopus,2022-07-01,sciencedirect,Hatch: Self-distributing systems for data centers,https://api.elsevier.com/content/abstract/scopus_id/85125223395,"Designing and maintaining distributed systems remains highly challenging: there is a high-dimensional design space of potential ways to distribute a system’s sub-components over a large-scale infrastructure; and the deployment environment for a system tends to change in unforeseen ways over time. For engineers, this is a complex prediction problem to gauge which distributed design may best suit a given environment. We present the concept of self-distributing systems, in which any local system built using our framework can learn, at runtime, the most appropriate distributed design given its perceived operating conditions. Our concept abstracts distribution of a system’s sub-components to a list of simple actions in a reward matrix of distributed design alternatives to be used by reinforcement learning algorithms. By doing this, we enable software to experiment, in a live production environment, with different ways in which to distribute its software modules by placing them in different hosts throughout the system’s infrastructure. We implement this concept in a framework we call Hatch, which has three major elements: (i) a transparent and generalized RPC layer that supports seamless relocation of any local component to a remote host during execution; (ii) a set of primitives, including relocation, replication and sharding, from which to create an action/reward matrix of possible distributed designs of a system; and (iii) a decentralized reinforcement learning approach to converge towards more optimal designs in real time. Using an example of a self-distributing web-serving infrastructure, Hatch is able to autonomously select the most suitable distributed design from among 
                        ≈
                     700,000 alternatives in about 5 min.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jenvman.2022.114939,Journal,Journal of Environmental Management,scopus,2022-06-15,sciencedirect,A hybrid novel framework for flood disaster risk control in developing countries based on smart prediction systems and prioritized scenarios,https://api.elsevier.com/content/abstract/scopus_id/85126907881,"A Decision Support System (DSS) is a highly efficient concept for managing complex objects in nature or human-made phenomena. The main purpose of the present study is related to designing and implementation of real-time monitoring, prediction, and control system for flood disaster management as a DSS. Likewise, the problem of statement in the research is correlated to implementation of a system for different climates of Iran as a unique flood control system. For the first time, this study coupled hydrological data mining, Machine Learning (ML), and Multi-Criteria Decision Making (MCDM) as smart alarm and prevention systems. Likewise, it created the platform for conditional management of floods in Iran's different clusters of climates. According to the KMeans clustering system, which determines homogeneity of the hydrology of a specific region, Iran's rainfall is heterogeneous with 0.61 score, which is approved high efficiency of clustering in a vast country such as Iran with four seasons and different climates. In contrast, the relation of rainfall and flood disaster is evaluated by Nearest Neighbors Classification (NNC), Stochastic Gradient Descent (SGD), Gaussian Process Classifier (GPC), and Neural Network (NN) algorithms which have an acceptable correlation coefficient with a mean of 0.7. The machine learning outputs demonstrated that based on valid data existence problems in developing countries, just with verified precipitation records, the flood disaster can be estimated with high efficiency. In the following, Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) method as a Game Theory (GT) technique ranked the preventive flood damages strategies through three social (Se 1), environmental (Se 2), and economic (Se 3) crises scenarios. The solutions of flood disaster management are collected from literature review, and the opinion approves them of 9 senior experts who are retired from a high level of water resource management positions of Iran. The outcomes of the TOPSIS method proved that National announcement for public-institutional participation for rapid response and funding (G1-2), Establishment of delay structures to increase flood focus time to give the animals in the ecosystem the opportunity to escape to the upstream points and to preserve the habitat (G 2–8), and Granting free national financial resources by government agencies in order to rebuild sensitive infrastructure such as railways, hospitals, schools, etc. to the provincial treasury (G3-10) are selected as the best solution of flood management in Social, Environmental, and Economic crises, respectively. Finally, the collected data are categorized in Social, Environmental, and Economic aspects as three dimensions of Sustainable Development Goals (SDGs) and ranked based on the opinion of 32 experts in the five provinces of present case studies.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jep.2022.115038,Journal,Journal of Ethnopharmacology,scopus,2022-06-12,sciencedirect,"Chemical profiling and unraveling of anti-COVID-19 biomarkers of red sage (Lantana camara L.) cultivars using UPLC-MS/MS coupled to chemometric analysis, in vitro study and molecular docking",https://api.elsevier.com/content/abstract/scopus_id/85126092602,"Ethnopharmacological relevance
                  Red sage (Lantana camara L.) (Verbenaceae) is a widely spread plant that was traditionally used in Brazil, India, Kenya, Thailand, Mexico, Nigeria, Australia and Southeast Asia for treating several ailments including rheumatism and leprosy. Despite its historical role in relieving respiratory diseases, limited studies progressed to the plant’s probable inhibition to respiratory viruses especially after the striking spread of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infections.
               
                  Aim of the study
                  This study aimed to investigate the inhibitory activity of different L. camara cultivars to SARS-CoV-2, that was not previously inspected, and clarify their mechanisms of action in the metabolomics viewpoint, and to determine the biomarkers that are related to such activity using UPLC-MS/MS coupled to in vitro-studies and chemometric analysis.
               
                  Materials and methods
                  Chemical profiling of different cultivars was accomplished via UPLC-MS/MS. Principle component analysis (PCA) and orthogonal projection to latent structures (OPLS) models were built using SIMCA® (multivariate data analysis software). Cytotoxicity and COVID-19 inhibitory activity testing were done followed by TaqMan Real-time RT-PCR (Reverse transcription polymerase chain reaction) assay that aimed to study extracts' effects on RNA-dependent RNA polymerase (RdRp) and E-genes expression levels. Detected biomarkers from OPLS analysis were docked into potential targets pockets to investigate their possible interaction patterns using Schrodinger® suite.
               
                  Results
                  UPLC-MS/MS analysis of different cultivars yielded 47 metabolites, most of them are triterpenoids and flavonoids. PCA plots revealed that inter-cultivar factor has no pronounced effect on the chemical profiles of extracts except for L. camara, cultivar Drap d'or flowers and leaves extracts as well as for L. camara cv Chelsea gem leaves extract. Among the tested extracts, flowers and leaves extracts of L. camara cv Chelsea gem, flowers extracts of L. camara cv Spreading sunset and L. camara cv Drap d'or showed the highest selectivity indices scoring 12.3, 10.1, 8.6 and 7.8, respectively, indicating their relative high safety and efficacy. Leaves and flowers extracts of L. camara cv Chelsea gem, flowers extracts of L. camara cv Spreading sunset and L. camara cv Drap d'or were the most promising inhibitors to viral plaques exhibiting IC50 values of 3.18, 3.67, 4.18 and 5.01 μg/mL, respectively. This was incremented by OPLS analysis that related their promising COVID-19 inhibitory activities to the presence of twelve biomarkers. Inhibiting the expression of RdRp gene is the major mechanism behind the antiviral activity of most extracts at almost all concentration levels. Molecular docking of the active biomarkers against RdRp revealed that isoverbascoside, luteolin-7,4'-O-diglucoside, camarolic acid and lantoic acid exhibited higher docking scores of −11.378, −10.64, −6.72 and −6.07 kcal/mol, respectively, when compared to remdesivir (−5.75 kcal/mol), thus these four compounds can serve as promising anti-COVID-19 candidates.
               
                  Conclusion
                  Flowers and leaves extracts of four L. camara cultivars were recognized as rich sources of phytoconstituents possessing anti-COVID-19 activity. Combination of UPLC-MS/MS and chemometrics is a promising approach to detect chemical composition differences among the cultivars and correlate them to COVID-19 inhibitory activities allowing to pinpoint possible biomarkers. Further in-vitro and in-vivo studies are required to verify their activity.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.chroma.2022.463005,Journal,Journal of Chromatography A,scopus,2022-06-07,sciencedirect,Convolutional neural network for automated peak detection in reversed-phase liquid chromatography,https://api.elsevier.com/content/abstract/scopus_id/85128196704,"Although commercially available software provides options for automatic peak detection, visual inspection and manual corrections are often needed. Peak detection algorithms commonly employed require carefully written rules and thresholds to increase true positive rates and decrease false positive rates. In this study, a deep learning model, specifically, a convolutional neural network (CNN), was implemented to perform automatic peak detection in reversed-phase liquid chromatography (RPLC). The model inputs a whole chromatogram and outputs predicted locations, probabilities, and areas of the peaks. The obtained results on a simulated validation set demonstrated that the model performed well (ROC-AUC of 0.996), and comparably or better than a derivative-based approach using the Savitzky-Golay algorithm for detecting peaks on experimental chromatograms (8.6% increase in true positives). In addition, predicted peak probabilities (typically between 0.5 and 1.0 for true positives) gave an indication of how confident the CNN model was in the peaks detected. The CNN model was trained entirely on simulated chromatograms (a training set of 1,000,000 chromatograms), and thus no effort had to be put into collecting and labeling chromatograms. A potential major drawback of this approach, namely training a CNN model on simulated chromatograms, is the risk of not capturing the actual “chromatogram space” well enough that is needed to perform accurate peak detection in real chromatograms.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.tifs.2022.04.021,Journal,Trends in Food Science and Technology,scopus,2022-06-01,sciencedirect,Augmented/mixed reality technologies for food: A review,https://api.elsevier.com/content/abstract/scopus_id/85129273095,"Background
                  The topic of food is broad and global, thereby representing an influential sector of the economy. Motivated by the advent of Industry 4.0, massive potential exists to implement cutting-edge technologies in the food industry. Recent years have seen a growing interest towards the applications of augmented/mixed reality (AR/MR) in the food sector.
               
                  Scope and approach
                  An extensive search of online journals focusing on Scopus was conducted using terms including ‘augmented reality’, ‘mixed reality’ and ‘food’ in the search fields of Title, Abstract, and Keywords. Full paper reading was implemented and ineligible articles (i.e., non-English-language, review articles, not peer-reviewed and without full paper) were removed.
               
                  Key findings and conclusions
                  Our systematic search resulted in 111 eligible articles, eight of which related to MR technology. There is an overall increasing trend in the number of publications appearing annually since the first relevant publication in 2010. Analysing these publications demonstrates the multidisciplinary nature of this technology which is closely linked to machine learning, computer vision, the Internet of Things (IoT), and artificial intelligence. Our findings also revealed that AR/MR technology is mainly applied in the following areas: dietary assessment, food nutrition and traceability, food sensory science, retail food chain applications, food education and learning, and precision farming. Furthermore, we highlight the limitations and analytical challenges that hinder the application of AR/MR to food-related research, such as the lack of reliable wireless connection and the difficulty in recognizing food objects in a complex environment, while also describing future research needs and directions.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijmedinf.2022.104758,Journal,International Journal of Medical Informatics,scopus,2022-06-01,sciencedirect,Machine learning models for diabetes management in acute care using electronic medical records: A systematic review,https://api.elsevier.com/content/abstract/scopus_id/85127677478,"Background
                  Machine learning (ML) is a subset of Artificial Intelligence (AI) that is used to predict and potentially prevent adverse patient outcomes. There is increasing interest in the application of these models in digital hospitals to improve clinical decision-making and chronic disease management, particularly for patients with diabetes. The potential of ML models using electronic medical records (EMR) to improve the clinical care of hospitalised patients with diabetes is currently unknown.
               
                  Objective
                  The aim was to systematically identify and critically review the published literature examining the development and validation of ML models using EMR data for improving the care of hospitalised adult patients with diabetes.
               
                  Methods
                  The Preferred Reporting Items for Systematic Reviews and Meta Analyses (PRISMA) guidelines were followed. Four databases were searched (Embase, PubMed, IEEE and Web of Science) for studies published between January 2010 to January 2022. The reference lists of the eligible articles were manually searched. Articles that examined adults and both developed and validated ML models using EMR data were included. Studies conducted in primary care and community care settings were excluded. Studies were independently screened and data was extracted using Covidence® systematic review software. For data extraction and critical appraisal, the Checklist for Critical Appraisal and Data Extraction for Systematic Reviews of Prediction Modelling Studies (CHARMS) was followed. Risk of bias was assessed using the Prediction model Risk Of Bias Assessment Tool (PROBAST). Quality of reporting was assessed by adherence to the Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD) guideline. The IJMEDI checklist was followed to assess quality of ML models and the reproducibility of their outcomes. The external validation methodology of the studies was appraised.
               
                  Results
                  Of the 1317 studies screened, twelve met inclusion criteria. Eight studies developed ML models to predict disglycaemic episodes for hospitalized patients with diabetes, one study developed a ML model to predict total insulin dosage, two studies predicted risk of readmission, and one study improved the prediction of hospital readmission for inpatients with diabetes. All included studies were heterogeneous with regard to ML types, cohort, input predictors, sample size, performance and validation metrics and clinical outcomes. Two studies adhered to the TRIPOD guideline. The methodological reporting of all the studies was evaluated to be at high risk of bias. The quality of ML models in all studies was assessed as poor. Robust external validation was not performed on any of the studies. No models were implemented or evaluated in routine clinical care.
               
                  Conclusions
                  This review identified a limited number of ML models which were developed to improve inpatient management of diabetes. No ML models were implemented in real hospital settings. Future research needs to enhance the development, reporting and validation steps to enable ML models for integration into routine clinical care.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.biosystems.2022.104662,Journal,BioSystems,scopus,2022-06-01,sciencedirect,miRNAFinder: A comprehensive web resource for plant Pre-microRNA classification,https://api.elsevier.com/content/abstract/scopus_id/85126988546,"microRNAs (miRNAs) are known as one of the small non-coding RNA molecules that control the expression of genes at the RNA level, while some operate at the DNA level. They typically range from 20 to 24 nucleotides in length and can be found in the plant and animal kingdoms as well as in some viruses. Computational approaches have overcome the limitations of the experimental methods and have performed well in identifying miRNAs. Compared to mature miRNAs, precursor miRNAs (pre-miRNAs) are long and have a hairpin loop structure with structural features. Therefore, most in-silico tools are implemented for pre-miRNA identification. This study presents a multilayer perceptron (MLP) based classifier implemented using 180 features under sequential, structural, and thermodynamic feature categories for plant pre-miRNA identification. This classifier has a 92% accuracy, a 94% specificity, and a 90% sensitivity. We have further tested this model with other small non-coding RNA types and obtained 78% accuracy. Furthermore, we introduce a novel dataset to train and test machine learning models, addressing the overlapping data issue in the positive training and testing datasets presented in PlantMiRNAPred for the classification of real and pseudo-plant pre-miRNAs. The new dataset and the classifier that can be used with any plant species are deployed on a web server freely accessible at 
                        http://mirnafinder.shyaman.me/
                     .",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jece.2022.107500,Journal,Journal of Environmental Chemical Engineering,scopus,2022-06-01,sciencedirect,A review of mechanistic and data-driven models of aerobic granular sludge,https://api.elsevier.com/content/abstract/scopus_id/85126937864,"The advantages of aerobic granular sludge sequencing batch reactors over conventional wastewater treatment methods are propelling the technology forward to full-scale application. The development of simulation models plays an influential role in understanding the process dynamics and predicting the process behavior, which is critical during the transition from laboratory and pilot studies to the design of full-scale plants. Simulation models allow virtual testing with approximate results to guide the expensive real-life implementation. This work reviews the current state of the literature on modeling aerobic granular sludge sequencing batch reactors, focusing on the objectives of the models, modeling methods, and the current trends. The most common modeling approaches were found to adopt mathematical models with many assumptions and process simplifications that were usually adopted from preceding studies. Mathematical modeling provided a fundamental understanding of the micro and macro scale bio-chem-physical processes that simultaneously occur inside aerobic granular sludge reactors. The common conclusion derived from these studies was that mathematical modeling could be overly complicated and computationally demanding when the models were more comprehensive. This review explores the current trend in the literature to develop models that can provide good performance while keeping the modeling objectives in mind. Further, the application of different machine learning and data-driven models is investigated. Finally, this review provides suggestions for future research needed to achieve better comprehensive models for the full aerobic granular sludge process with the fewest assumptions.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.phymed.2022.154059,Journal,Phytomedicine,scopus,2022-06-01,sciencedirect,Discovery of the directionally detoxification effect and chemical mechanism of Ginseng-Fuzi co-decoction based on real-time online filtration electrospray ionization mass spectrometry,https://api.elsevier.com/content/abstract/scopus_id/85126880073,"Background
                  The synergic action of compound prescriptions is an important feature and core advantage of traditional medicine. Ginseng-Fuzi decoction is a classic compatible phytomedicine in China, of which Ginseng can effectively reduce the toxicity of Fuzi in clinical, but the detoxification chemical mechanism is still unclear.
               
                  Purpose
                  Develop a novel method for real-time tracking and monitoring of complex substances in the decoction system of traditional Chinese medicine to uncover the detoxification effect Ginseng on Fuzi and explore the possible chemical reaction mechanism of Ginseng-Fuzi co-decoction.
               
                  Methods
                  A novel real-time monitoring system, online filtration electrospray ionization mass spectrometry, was developed for extremely complex substances analysis in the decoction of traditional medicine compounds to uncover the directionally detoxification effect and the mechanism of compatibility interaction.
               
                  Results
                  Nine key alkaloids and 7 ginsenosides in Ginseng-Fuzi decoction were simultaneously in-situ monitoring in positive ion mode or negative ion mode respectively. Both types of targeted analytes had satisfactory MS signal response for real-time qualitative and quantitative analysis with high precision (RSD < 14.04%) and low LLODs (0.002 ng/ml-10 ng/ml). Through long-term tracking analysis, the exact detoxification and synergistic effect of Ginseng-Fuzi decoction were confirmed as the concentration of main toxic alkaloids decreased (e.g. the content of mesaconitine has been reduced by about 38%) and the main active monoester alkaloids increased obviously. More importantly, the possible molecular mechanism of the detoxification effect of Ginseng compatibility was revealed for the first time, which was the nucleophilic substitution reaction of diester alkaloids catalyzed by fatty acids.
               
                  Conclusion
                  This study revealed the exact effect of co-decoction of Ginseng and Fuzi at the molecular level and the chemical reaction mechanism of fatty acid-catalyzed degradation of toxic diester-type alkaloids. The comprehensive multi-component real-time monitoring strategy for complex traditional medicine compounds developed and implemented here has important demonstration significance for revealing the scientific connotation of the compatibility of compound traditional medicine.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.worlddev.2022.105864,Journal,World Development,scopus,2022-06-01,sciencedirect,Predicting wasteful spending in tree planting programs in Indian Himalaya,https://api.elsevier.com/content/abstract/scopus_id/85125243671,"Tree planting is widely promoted as a cost-effective natural climate solution, yet there are few evaluations of the implementation of tree planting. Our analysis of a unique dataset on tree planting in the Indian Himalayan state of Himachal Pradesh shows that over half of the state’s budget for tree planting is wasted on plantations that are unlikely to survive and/or are poorly designed to achieve the state’s goal of increasing forest cover. Himachal Pradesh (and India more generally) has been identified as a high potential area for natural climate solutions due to high government capacity, adequate funding, and government agencies with extensive planting experience. We combine data on the location and financial outlay for plantations, which allow us to analyze the relationship between plantations and social and biophysical conditions, with a machine learning model, trained on past land cover change, which predicts the likelihood of future tree cover loss in plantation areas. Our finding that even in this high potential area tree planting programs involve considerable wasted expenditure on ineffective plantations raises questions about optimistic assessments of the potential for tree planting to serve as a cost-effective natural climate solution. We suggest deemphasizing the target-based approaches that dominate present policy-making and high-profile scientific publications, which we argue are the cause of wasted expenditures in Himachal Pradesh. Instead policy-makers and scientists interested in natural climate solutions should focus on developing solutions that respond to local biophysical, social, and economic realities, and are implemented through transparent procedures that increase accountability to and reinforce the rights of forest dependent people.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.isatra.2021.06.017,Journal,ISA Transactions,scopus,2022-06-01,sciencedirect,Multi-objective optimization technique for trajectory planning of multi-humanoid robots in cluttered terrain,https://api.elsevier.com/content/abstract/scopus_id/85108514869,"Humanoid robots hold a decent advantage over wheeled robots because of their ability to mimic human exile. The presented paper proposes a novel strategy for trajectory planning in a cluttered terrain using the hybridized controller modeled on the basis of modified MANFIS (multiple adaptive neuro-fuzzy inference system) and MOSFO (multi-objective sunflower optimization) techniques. The controller works in a two-step mechanism. The input parameters, i.e., obstacle distances and target direction, are first fed to the MANFIS controller, which generates a steering angle in both directions of an obstacle to dodge it. The intermediate steering angles are obtained based on the training model. The final steering angle to avoid obstacles is selected based on the direction of the target and additional obstacles in the path. It is further works as input for the MOSFO technique, which provides the ultimate steering angle. Using the proposed technique, various simulations are carried out in the WEBOT simulator, which shows a deviation under 5% when the results are validated in real-time experiments, revealing the technique to be robust. To resolve the complication of providing preference to the robot during deadlock condition in multi-humanoids system, the dining philosopher controller is implemented. The efficiency of the proposed technique is examined through the comparisons with the default controller of NAO based on toques produces at various joints that present an average improvement of 6.12%, 7.05% and 15.04% in ankle, knee and hip, respectively. It is further compared against the existed navigational strategy in multiple robot systems that also displays an acceptable improvement in travel length. In comparison in reference to the existing controller, the proposed technique emerges to be a clear winner by portraying its superiority.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.isatra.2021.06.010,Journal,ISA Transactions,scopus,2022-06-01,sciencedirect,A real-world application of Markov chain Monte Carlo method for Bayesian trajectory control of a robotic manipulator,https://api.elsevier.com/content/abstract/scopus_id/85108508566,"Reinforcement learning methods are being applied to control problems in robotics domain. These algorithms are well suited for dealing with the continuous large scale state spaces in robotics field. Even though policy search methods related to stochastic gradient optimization algorithms have become a successful candidate for coping with challenging robotics and control problems in recent years, they may become unstable when abrupt variations occur in gradient computations. Moreover, they may end up with a locally optimal solution. To avoid these disadvantages, a Markov chain Monte Carlo (MCMC) algorithm for policy learning under the RL configuration is proposed. The policy space is explored in a non-contiguous manner such that higher reward regions have a higher probability of being visited. The proposed algorithm is applied in a risk-sensitive setting where the reward structure is multiplicative. Our method has the advantages of being model-free and gradient-free, as well as being suitable for real-world implementation. The merits of the proposed algorithm are shown with experimental evaluations on a 2-Degree of Freedom robot arm. The experiments demonstrate that it can perform a thorough policy space search while maintaining adequate control performance and can learn a complex trajectory control task within a small finite number of iteration steps.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bdr.2022.100313,Journal,Big Data Research,scopus,2022-05-28,sciencedirect,Real-Time Traffic Speed Estimation for Smart Cities with Spatial Temporal Data: A Gated Graph Attention Network Approach,https://api.elsevier.com/content/abstract/scopus_id/85127306808,"Moving vehicles interact with IoT devices deployed in cities and establish social relationships to provide proactive and intelligent services for smart cities. For example, big-data-driven accurate and timely traffic speed prediction systems play an important role in empowering Intelligent Transportation Systems (ITS) in smart cities. The reason is that it is the foundation of modern traffic management and traffic control. Most of the existing advanced traffic speed prediction models are Spatial-Temporal hybrid models. They improve the predicting accuracy by leveraging Graph Convolutional Network (GCN) and Recurrent Neural Network (RNN) to extract spatial and temporal features from the traffic speed data, respectively. However, these models have complex structures and high computational costs. To improve the accuracy of prediction and reduce the cost of model training, we propose a hybrid model, Spatial-Temporal Gated Graph Attention network (ST-GGAN), based on Graph Attention mechanism (GAT) and Gated Recurrent Unit (GRU). Such a method has a simpler structure, lower computational costs, and higher predicting accuracy. The experimental results show that our model's performance is better than the existing advanced models on a real-world dataset.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2022.100476,Journal,Patterns,scopus,2022-05-13,sciencedirect,Reliance on metrics is a fundamental challenge for AI,https://api.elsevier.com/content/abstract/scopus_id/85129924489,"Through a series of case studies, we review how the unthinking pursuit of metric optimization can lead to real-world harms, including recommendation systems promoting radicalization, well-loved teachers fired by an algorithm, and essay grading software that rewards sophisticated garbage. The metrics used are often proxies for underlying, unmeasurable quantities (e.g., “watch time” of a video as a proxy for “user satisfaction”). We propose an evidence-based framework to mitigate such harms by (1) using a slate of metrics to get a fuller and more nuanced picture; (2) conducting external algorithmic audits; (3) combining metrics with qualitative accounts; and (4) involving a range of stakeholders, including those who will be most impacted.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aca.2021.339411,Journal,Analytica Chimica Acta,scopus,2022-05-08,sciencedirect,A video processing and machine vision-based automatic analyzer to determine sequentially total suspended and settleable solids in wastewater,https://api.elsevier.com/content/abstract/scopus_id/85123884378,"The monitoring of total suspended (TSS) and settleable (SetS) solids in wastewater is essential to maintain the quality parameters for aquatic biota because they can transport pollutants and block light penetration. Determining them by their respective reference methods, however, is laborious, expensive, and time consuming. To overcome this, we developed a new analytical instrument called Solids in Wastewater's Machine Vision-based Automatic Analyzer (SWAMVA), which is equiped with an automatic sampler and a software for real-time digital movie capture to quantify sequentially the TSS and SetS contents in wastewater samples. The machine vision algorithm (MVA) coupled with the Red color plane (derived from color histograms in the Red-Green-Blue (RGB) system) showed the best prediction results with R2 of 0.988 and 0.964, and relative error of prediction (REP) of 6.133 and 9.115% for TSS and SetS, respectively. The constructed models were validated by Analysis of Variance (ANOVA), and the accuracy and precision of the predictions by the t- and F-tests, respectively, at a 0.05 significance level. The elliptical joint confidence region (EJCR) test confirmed the accuracy, while the coefficient of variation (CV) of 6.529 and 10.908% confirmed the good precisions, respectively. Compared with the reference method (Standard Methods For the Examination of Water and Wastewater), the proposed method reduced the analysis volume from 1.5 L to just 15 mL and the analysis time from 12 h to 24 s per sample. Therefore, SWAMVA can be considered an important alternative to the determination of TSS and SetS in wastewater as an automatic, fast, and low-cost analytical tool, following the principles of Green Chemistry and exploiting Industry 4.0 features such as intelligent processing, miniaturization, and machine vision.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.entcom.2022.100493,Journal,Entertainment Computing,scopus,2022-05-01,sciencedirect,Evolving action pre-selection parameters for MCTS in real-time strategy games,https://api.elsevier.com/content/abstract/scopus_id/85129479206,"Real-Time Strategy (RTS) games are well-known for their substantially large combinatorial decision and state spaces, responsible for creating significant challenges for search and machine learning techniques. Exploiting domain knowledge to assist in navigating the expansive decision and state spaces could facilitate the emergence of competitive RTS game-playing agents. Usually, domain knowledge can take the form of expert traces or expert-authored scripts. A script encodes a strategy conceived by a human expert and can be used to steer a search algorithm, such as Monte Carlo Tree Search (MCTS), towards high-value states. However, a script is coarse by nature, meaning that it could be subject to exploitation and poor low-level tactical performance. We propose to perceive scripts as a collection of heuristics that can be parameterized and combined to form a wide array of strategies. The parameterized heuristics mold and filter the decision space in favor of a strategy expressed in terms of parameters. The proposed agent, ParaMCTS, implements several common heuristics and uses NaïveMCTS to search the downsized decision space; however, it requires a preceding manual parameterization step. A genetic algorithm is proposed for use in an optimization phase that aims to replace manual tuning and find an optimal set of parameters for use by EvoPMCTS, the evolutionary counterpart of ParaMCTS. Experimentation results using the 
                        
                           μ
                        
                     RTS testbed show that EvoPMCTS outperforms several state-of-the-art agents across multiple maps of distinct layouts.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.elerap.2022.101143,Journal,Electronic Commerce Research and Applications,scopus,2022-05-01,sciencedirect,A novel textual data augmentation method for identifying comparative text from user-generated content,https://api.elsevier.com/content/abstract/scopus_id/85127219262,"Mining user-generated content on e-commerce platforms and social media is timely and more objective compared with other information access channels for gaining competitive intelligence. Identifying comparative text from large volumes of non-comparative text is an important but challenging task. On one hand, existing methods are time-consuming and not generalizable across different domains. On the other hand, the datasets for the task generally suffer from the severe imbalance issue. To address abovementioned problems, we propose a framework adopting advanced deep learning methods to automatically learn features and a novel textual data augmentation method named TA3S to deal with the data imbalance issue. Specifically, the TA3S method simultaneously considers the syntactic structure and semantic information of comparative text samples. Moreover, in order to support the successful implementation of TA3S, we develop a novel method based on word embedding and label propagation algorithm to distinguish between synonymous and antonymous substitute words. The experiments on two real-world datasets demonstrate the feasibility and effectiveness of our framework, and present that our framework outperforms state-of-the-art methods in identifying comparative text from user-generated content.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jics.2022.100429,Journal,Journal of the Indian Chemical Society,scopus,2022-05-01,sciencedirect,Evaluation of nanomaterials-grafted enzymes for application in contaminants degradation: Need of the hour with proposed IoT synchronized nanosensor fit sustainable clean water technology in en masse,https://api.elsevier.com/content/abstract/scopus_id/85126918775,"Increased water pollution and challenges in ultrafast recognition of water pollutants poses considerable burden to the public health. The issue of providing clean water to rural people is always a daunting yet challenging task wherein building a centralized water treatment system along with proper pipeline to connect dispersed population is not at all feasible. Amongst different water treatment technologies, sustainable nanozyme based materials have made an exceptional contribution towards providing contaminants free potable water to mankind due to its strong activity and sensitivity towards chemical substances thus facilitating use in advanced point-of-use (POU) system. In this article, we have briefly highlighted the way by which silica, carbon and MOF based nano support stabilizes the enzyme with its improved selectivity and sensitivity towards water decontamination. The strength of nanozymes and its potential use in POU devices has also been discussed for future research endeavor. Additionally, development of various nano-chemo-sensors with advanced machine learning approach is an added advantage towards detecting various contaminants from real samples with its implementation in POU devices. We have also proposed the implementing strategies of these nanozyme based water technologies so that early adopters can be given an informed decision about its way of implementation in coming days in India.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2022.106728,Journal,Computer Methods and Programs in Biomedicine,scopus,2022-05-01,sciencedirect,An interactive framework for the detection of ictal and interictal activities: Cross-species and stand-alone implementation,https://api.elsevier.com/content/abstract/scopus_id/85126302582,"Background and objective
                  Despite advances on signal analysis and artificial intelligence, visual inspection is the gold standard in event detection on electroencephalographic recordings. This process requires much time of clinical experts on both annotating and training new experts for this same task. In scenarios where epilepsy is considered, the need for automatic tools is more prominent, as both seizures and interictal events can occur on hours- or days-long recordings. Although other solutions have already been proposed, most of them are not integrated on clinical and basic science environments due to their complexity and required specialization. Here we present a pipeline that arises from coordinated efforts between life-science researchers, clinicians and data scientists to develop an interactive and iterative workflow to train machine-learning tools for the automatic detection of electroencephalographic events in a variety of scenarios.
               
                  Methods
                  The approach consists on a series of subsequent steps covering data loading and configuration, event annotation, model training/re-training and event detection. With slight modifications, the combination of these blocks can cope with a variety of scenarios. To illustrate the flexibility and robustness of the approach, three datasets from clinical (patients of Dravet Syndrome) and basic research environments (mice model of the same disease) were evaluated. From them, and in response to researchers’ daily needs, four real world examples of interictal event detection and seizure classification tasks were selected and processed.
               
                  Results
                  Results show that the current approach was of great aid for event annotation and model development. It was capable of creating custom machine-learning solutions for each scenario with slight adjustments on the analysis protocol, easily accessible to users without programming skills. Final annotator similarity metrics reached values above 80% on all cases of use, reaching 92.3% on interictal event detection on human recordings.
               
                  Conclusions
                  The presented framework is easily adaptable to multiple real world scenarios and the interactive and ease-to-use approach makes it manageable to clinical and basic researches without programming skills. Nevertheless, it is conceived so data scientists can optimize it for specific scenarios, improving the knowledge transfer between these fields.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rser.2022.112128,Journal,Renewable and Sustainable Energy Reviews,scopus,2022-05-01,sciencedirect,"Data-driven probabilistic machine learning in sustainable smart energy/smart energy systems: Key developments, challenges, and future research opportunities in the context of smart grid paradigm",https://api.elsevier.com/content/abstract/scopus_id/85125617590,"The current trend indicates that energy demand and supply will eventually be controlled by autonomous software that optimizes decision-making and energy distribution operations. New state-of-the-art machine learning (ML) technologies are integral in optimizing decision-making in energy distribution networks and systems. This study was conducted on data-driven probabilistic ML techniques and their real-time applications to smart energy systems and networks to highlight the urgency of this area of research. This study focused on two key areas: i) the use of ML in core energy technologies and ii) the use cases of ML for energy distribution utilities. The core energy technologies include the use of ML in advanced energy materials, energy systems and storage devices, energy efficiency, smart energy material manufacturing in the smart grid paradigm, strategic energy planning, integration of renewable energy, and big data analytics in the smart grid environment. The investigated ML area in energy distribution systems includes energy consumption and price forecasting, the merit order of energy price forecasting, and the consumer lifetime value. Cybersecurity topics for power delivery and utilization, grid edge systems and distributed energy resources, power transmission, and distribution systems are also briefly studied. The primary goal of this work was to identify common issues useful in future studies on ML for smooth energy distribution operations. This study was concluded with many energy perspectives on significant opportunities and challenges. It is noted that if the smart ML automation is used in its targeting energy systems, the utility sector and energy industry could potentially save from $237 billion up to $813 billion.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.iot.2022.100511,Journal,Internet of Things (Netherlands),scopus,2022-05-01,sciencedirect,Smart mask – Wearable IoT solution for improved protection and personal health,https://api.elsevier.com/content/abstract/scopus_id/85125502352,"The use of face masks is an important way to fight the COVID-19 pandemic. In this paper, we envision the Smart Mask, an IoT supported platform and ecosystem aiming to prevent and control the spreading of COVID-19 and other respiratory viruses. The integration of sensing, materials, AI, wireless, IoT, and software will help the gathering of health data and health-related event detection in real time from the user as well as from their environment. In the larger scale, with the help of AI-based analysis for health data it is possible to predict and decrease medical costs with accurate diagnoses and treatment plans, where the comparison of personal data to large-scale public data enables drawing up a personal health trajectory, for example. Key research problems for smart respiratory protective equipment are identified in addition to future research directions. A Smart Mask prototype was developed with accompanying user application, backend and heath AI to study the concept.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbusres.2022.02.039,Journal,Journal of Business Research,scopus,2022-05-01,sciencedirect,Multi-target CNN-LSTM regressor for predicting urban distribution of short-term food delivery demand,https://api.elsevier.com/content/abstract/scopus_id/85124904640,"The food delivery market has increased rapidly in the last few years, becoming a well-established reality in the business world and a common feature of urban life. Food delivery platforms provide the end-to-end services that connect restaurants with consumers, including the delivery service to those people ordering food through an online portal. A key component of these platforms is logistics, specifically the logistics of drivers. Ideally, the number of drivers operating in an urban area should be just the right number to serve the demand in that area. Since the demand is extremely dynamic in space and time, the spatial–temporal distribution of drivers remains a challenging problem, partially solved by means of variable incentives in different city areas at different times. In this context, a precise demand prediction would avoid a local lack of drivers in some areas, and an inefficient concentration of drivers in some other areas. For this reason, we propose a deep neural network-based methodology to forecast short-term food delivery demand distribution over urban areas. The study, carried out on a real-world dataset from a food delivery company, focuses on hourly demands and frequent prediction updates. The sequential modeling approach, designed to catch rapid changes and sudden variations beyond the general demand trend, is based on a multi-target CNN-LSTM regressor trained on location-specific time series. The methodology uses a single model for all service areas simultaneously, and a single one-step volume inference for every area at each time update. The results disclose a better performance over baselines (historical estimates for the same time-area) and more traditional statistical approaches (moving averages and univariate time-series forecasting), demonstrating a promising implementation potential within an online delivery platform framework.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jss.2022.111231,Journal,Journal of Systems and Software,scopus,2022-05-01,sciencedirect,Discovering boundary values of feature-based machine learning classifiers through exploratory datamorphic testing,https://api.elsevier.com/content/abstract/scopus_id/85124473834,"Testing has been widely recognised as difficult for AI applications. This paper proposes a set of testing strategies for testing machine learning applications in the framework of the datamorphism testing methodology. In these strategies, testing aims at exploring the data space of a classification or clustering application to discover the boundaries between classes that the machine learning application defines. This enables the tester to understand precisely the behaviour and function of the software under test. In the paper, three variants of exploratory strategies are presented with the algorithms implemented in the automated datamorphic testing tool Morphy. The correctness of these algorithms are formally proved. Their capability and cost of discovering borders between classes are evaluated via a set of controlled experiments with manually designed subjects and a set of case studies with real machine learning models.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijheatmasstransfer.2021.122444,Journal,International Journal of Heat and Mass Transfer,scopus,2022-05-01,sciencedirect,A versatile inversion approach for space/temperature/time-related thermal conductivity via deep learning,https://api.elsevier.com/content/abstract/scopus_id/85122239809,"Identifying the thermophysical properties of unknown material through the measurement of temperature is of great significance in computational heat transfer. Existing numerical algorithms are generally computationally cumbersome and resource demanding. Rapid advances in deep learning (DL) offer an alternative pathway to speed up the inversion process by fully utilizing the parallel computing ability of Graphics Processing Units (GPUs). In this paper, a DL framework is proposed to reconstruct the thermal conductivity related to space, temperature or time. The whole framework consists of a forward data generation module, a denoising module and an inversion module. It is noteworthy that the physics informed neural network (PINN) is employed in the process of generating training data, which avoids the use of commercial software based on traditional methods. In order to simulate the measurement error in practical scenarios, a certain intensity of Gaussian noise is added to the generated data. After denoising by the U-net, the measured temperature is fed to the nonlinear mapping module (NMM) for the inversion of the unknown thermal conductivity. As a result, a well-trained framework can realize high precision real-time inversion even with intensive environmental noise, offering great potential for applications pertaining to the reconstruction of thermophysical properties.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2022.02.006,Journal,Neurocomputing,scopus,2022-04-28,sciencedirect,Infer-AVAE: An attribute inference model based on adversarial variational autoencoder,https://api.elsevier.com/content/abstract/scopus_id/85124379247,"User attributes, such as gender and education, face severe incompleteness in social networks. Attribute inference aims to infer users’ missing attribute labels based on observed data to make this valuable data usable for downstream tasks like user profiling and personalized recommendation. Recently, variational autoencoder (VAE), an end-to-end deep generative model, has shown promising performance by handling the problem in a semi-supervised way. However, VAEs can easily suffer from over-fitting and over-smoothing when applied to attribute inference. Specifically, VAE implemented with multi-layer perceptron (MLP) can only reconstruct input data but fail to infer missing parts. While using the trending graph neural networks (GNNs) as encoder has the problem that GNNs aggregate redundant information from the neighborhood and generate indistinguishable user representations, known as over-smoothing. In this paper, we propose an attribute Inference model based on Adversarial VAE (Infer-AVAE) to cope with these issues. Specifically, to overcome over-smoothing, Infer-AVAE unifies MLP and GNNs in the encoder to learn positive and negative latent representations respectively. Meanwhile, an adversarial network is trained to distinguish the two representations, and GNNs are trained to aggregate less noise for more robust representations through adversarial training. Finally, to relieve over-fitting, mutual information constraint is introduced as a regularizer for the decoder to make better use of auxiliary information in representations and generate outputs not limited by observations. We evaluate our model on four real-world social network datasets, and experimental results demonstrate that our model averagely outperforms baselines by 7.0
                        
                           %
                        
                      in accuracy.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.conbuildmat.2022.127129,Journal,Construction and Building Materials,scopus,2022-04-25,sciencedirect,Determination of pith location along Norway spruce timber boards using one dimensional convolutional neural networks trained on virtual timber boards,https://api.elsevier.com/content/abstract/scopus_id/85126599219,"Knowledge of pith location is needed for modelling of sawn timber and for real time assessment of wood material in the wood working industry. However, the methods that are available and implemented in optical scanner today seldom meet customer requirements on accuracy and/or speed. In the present research data of greyscale images of the four longitudinal sides of board and a one-dimensional convolutional neural network were used to determine pith location along Norway spruce timber boards. A novel stochastic model was developed to generate thousands of virtual timber boards, with photo-realistic surfaces and known pith location, by which the network was trained before it was successfully applied to determine pith location along real boards.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2021.116323,Journal,Expert Systems with Applications,scopus,2022-04-15,sciencedirect,Deep multi-agent reinforcement learning for multi-level preventive maintenance in manufacturing systems[Formula presented],https://api.elsevier.com/content/abstract/scopus_id/85121584320,"Designing preventive maintenance (PM) policies that ensure smooth and efficient production for large-scale manufacturing systems is non-trivial. Recent model-free reinforcement learning (RL) methods shed lights on how to cope with the non-linearity and stochasticity in such complex systems. However, the action space explosion impedes RL-based PM policies to be generalized to real applications. In order to obtain cost efficient PM policies for a serial production line that has multiple levels of PM actions, a novel multi-agent modeling is adopted to support adaptive learning by modeling each machine as cooperative agent. The evaluation of system-level production loss is leveraged to construct the reward function. An adaptive learning framework based on value-decomposition multi-agent actor–critic algorithm is utilized to obtain PM policies. In simulation study, the proposed framework demonstrates its effectiveness by leading other baselines on a comprehensive set of metrics whereas the centralized RL-based methods struggles to converge to stable policies. Our analysis further demonstrates that our multi-agent reinforcement learning based method learns effective PM policies without any knowledge about the environment and maintenance strategies.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jobe.2021.103778,Journal,Journal of Building Engineering,scopus,2022-04-15,sciencedirect,A coupled deep learning-based internal heat gains detection and prediction method for energy-efficient office building operation,https://api.elsevier.com/content/abstract/scopus_id/85121269022,"Occupants' behaviour and the use of electrical equipment can significantly impact the building energy demand. Accurate occupancy and equipment usage information are key to improving the performance of demand-driven control, which can automatically adjust the heating, cooling and ventilation system operation. Employing static schedules is commonly used for the operation of heating, ventilation and air-conditioning systems, while it cannot satisfy the actual requirements due to the dynamic variations within the conditioned spaces. This study introduces a coupled real-time occupancy and equipment usage detection and recognition approach using deep learning and computer vision techniques for efficient building energy controls. The experimental results presented an overall equipment detection and occupancy activity detection accuracy of 78.39% and 93.60%. To investigate the influence of the implementation of the approach on building energy demand, a case study office building was selected to conduct experimental tests and modeled using a building energy simulation tool. Four scenarios with different occupancy and equipment profiles were defined and evaluated. The simulation results showed that heat gains, when employing static profiles were larger than the heat gains predicted when using the deep learning influenced profiles. Up to 53.95% lower heat gains were estimated when using both occupancy and equipment detection approaches than static schedules solely. The results highlighted the importance of monitoring real-time occupancy and electrical equipment usage and the advantages of using deep learning detection techniques to provide data for demand-driven controls, optimising building energy efficiency while maintaining a comfortable indoor environment.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2022.100441,Journal,Patterns,scopus,2022-04-08,sciencedirect,Chemical-induced gene expression ranking and its application to pancreatic cancer drug repurposing,https://api.elsevier.com/content/abstract/scopus_id/85124879639,"Chemical-induced gene expression profiles provide critical information of chemicals in a biological system, thus offering new opportunities for drug discovery. Despite their success, large-scale analysis leveraging gene expressions is limited by time and cost. Although several methods for predicting gene expressions were proposed, they only focused on imputation and classification settings, which have limited applications to real-world scenarios of drug discovery. Therefore, a chemical-induced gene expression ranking (CIGER) framework is proposed to target a more realistic but more challenging setting in which overall rankings in gene expression profiles induced by de novo chemicals are predicted. The experimental results show that CIGER significantly outperforms existing methods in both ranking and classification metrics. Furthermore, a drug screening pipeline based on CIGER is proposed to identify potential treatments of drug-resistant pancreatic cancer. Our predictions have been validated by experiments, thereby showing the effectiveness of CIGER for phenotypic compound screening of precision medicine.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.phro.2022.04.008,Journal,Physics and Imaging in Radiation Oncology,scopus,2022-04-01,sciencedirect,Real-world analysis of manual editing of deep learning contouring in the thorax region,https://api.elsevier.com/content/abstract/scopus_id/85130386622,"Background and purpose
                  User-adjustments after deep-learning (DL) contouring in radiotherapy were evaluated to get insight in real-world editing during clinical practice. This study assessed the amount, type and spatial regions of editing of auto-contouring for organs-at-risk (OARs) in routine clinical workflow for patients in the thorax region.
               
                  Materials and methods
                  A total of 350 lung cancer and 362 breast cancer patients, contoured between March 2020 and March 2021 using a commercial DL-contouring method followed by manual adjustments were retrospectively analyzed. Subsampling was performed for some OARs, using an inter-slice gap of 1–3 slices. Commonly-used whole-organ contouring assessment measures were calculated, and all cases were registered to a common reference shape per OAR to identify regions of manual adjustment. Results were expressed as the median, 10th-90th percentile of adjustment and visualized using 3D renderings.
               
                  Results
                  Per OAR, the median amount of editing was below 1 mm. However, large adjustments were found in some locations for most OARs. In general, enlarging of the auto-contours was needed. Subsampling DL-contours showed less adjustments were made in the interpolated slices compared to simulated no-subsampling for these OARs.
               
                  Conclusion
                  The real-world performance of automatic DL-contouring software was evaluated and proven useful in clinical practice. Specific regions-of-adjustment were identified per OAR in the thorax region, and separate models were found to be necessary for specific clinical indications different from training data. This analysis showed the need to perform routine clinical analysis especially when procedures or acquisition protocols change to have the best configuration of the workflow.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aei.2022.101600,Journal,Advanced Engineering Informatics,scopus,2022-04-01,sciencedirect,Simulation and sensor data fusion for machine learning application,https://api.elsevier.com/content/abstract/scopus_id/85130248837,"The performance of machine learning algorithms depends to a large extent on the amount and the quality of data available for training. Simulations are most often used as test-beds for assessing the performance of trained models on simulated environment before deployment in real-world. They can also be used for data annotation, i.e, assigning labels to observed data, providing thus background knowledge for domain experts. We want to integrate this knowledge into the machine learning process and, at the same time, use the simulation as an additional data source. Therefore, we present a framework that allows for the combination of real-world observations and simulation data at two levels, namely the data or the model level. At the data level, observations and simulation data are integrated to form an enriched data set for learning. At the model level, the models learned from observed and simulated data separately are combined using an ensemble technique. Based on the trade-off between model bias and variance, an automatic selection of the appropriate fusion level is proposed. Our framework is validated using two case studies of very different types. The first is an industry 4.0 use case consisting of monitoring a milling process in real-time. The second is an application in astroparticle physics for background suppression.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aei.2022.101596,Journal,Advanced Engineering Informatics,scopus,2022-04-01,sciencedirect,Ergonomic assessment of office worker postures using 3D automated joint angle assessment,https://api.elsevier.com/content/abstract/scopus_id/85127182413,"Sedentary activity and static postures are associated with work-related musculoskeletal disorders (WMSDs) and worker discomfort. Ergonomic evaluation for office workers is commonly performed by experts using tools such as the Rapid Upper Limb Assessment (RULA), but there is limited evidence suggesting sustained compliance with expert’s recommendations. Assessing postural shifts across a day and identifying poor postures would benefit from automation by means of real-time, continuous feedback. Automated postural assessment methods exist; however, they are usually based on ideal conditions that may restrict users’ postures, clothing, and hair styles, or may require unobstructed views of the participants. Using a Microsoft Kinect camera and open-source computer vision algorithms, we propose an automated ergonomic assessment algorithm to monitor office worker postures, the 3D Automated Joint Angle Assessment, 3D-AJA. The validity of the 3D-AJA was tested by comparing algorithm-calculated joint angles to the angles obtained from manual goniometry and the Kinect Software Development Kit (SDK) for 20 participants in an office space. The results of the assessment show that the 3D-AJA has mean absolute errors ranging from 5.6° ± 5.1° to 8.5° ± 8.1° for shoulder flexion, shoulder abduction, and elbow flexion relative to joint angle measurements from goniometry. Additionally, the 3D-AJA showed relatively good performance on the classification of RULA score A using a Random Forest model (micro averages F1-score = 0.759, G-mean = 0.811), even at high levels of occlusion on the subjects’ lower limbs. The results of the study provide a basis for the development of a full-body ergonomic assessment for office workers, which can support personalized behavior change and help office workers to adjust their postures, thus reducing their risks of WMSDs.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S2589-7500(21)00272-7,Journal,The Lancet Digital Health,scopus,2022-04-01,sciencedirect,Real-world evaluation of rapid and laboratory-free COVID-19 triage for emergency care: external validation and pilot deployment of artificial intelligence driven screening,https://api.elsevier.com/content/abstract/scopus_id/85126685401,"Background
                  Uncertainty in patients' COVID-19 status contributes to treatment delays, nosocomial transmission, and operational pressures in hospitals. However, the typical turnaround time for laboratory PCR remains 12–24 h and lateral flow devices (LFDs) have limited sensitivity. Previously, we have shown that artificial intelligence-driven triage (CURIAL-1.0) can provide rapid COVID-19 screening using clinical data routinely available within 1 h of arrival to hospital. Here, we aimed to improve the time from arrival to the emergency department to the availability of a result, do external and prospective validation, and deploy a novel laboratory-free screening tool in a UK emergency department.
               
                  Methods
                  We optimised our previous model, removing less informative predictors to improve generalisability and speed, developing the CURIAL-Lab model with vital signs and readily available blood tests (full blood count [FBC]; urea, creatinine, and electrolytes; liver function tests; and C-reactive protein) and the CURIAL-Rapide model with vital signs and FBC alone. Models were validated externally for emergency admissions to University Hospitals Birmingham, Bedfordshire Hospitals, and Portsmouth Hospitals University National Health Service (NHS) trusts, and prospectively at Oxford University Hospitals, by comparison with PCR testing. Next, we compared model performance directly against LFDs and evaluated a combined pathway that triaged patients who had either a positive CURIAL model result or a positive LFD to a COVID-19-suspected clinical area. Lastly, we deployed CURIAL-Rapide alongside an approved point-of-care FBC analyser to provide laboratory-free COVID-19 screening at the John Radcliffe Hospital (Oxford, UK). Our primary improvement outcome was time-to-result, and our performance measures were sensitivity, specificity, positive and negative predictive values, and area under receiver operating characteristic curve (AUROC).
               
                  Findings
                  72 223 patients met eligibility criteria across the four validating hospital groups, in a total validation period spanning Dec 1, 2019, to March 31, 2021. CURIAL-Lab and CURIAL-Rapide performed consistently across trusts (AUROC range 0·858–0·881, 95% CI 0·838–0·912, for CURIAL-Lab and 0·836–0·854, 0·814–0·889, for CURIAL-Rapide), achieving highest sensitivity at Portsmouth Hospitals (84·1%, Wilson's 95% CI 82·5–85·7, for CURIAL-Lab and 83·5%, 81·8–85·1, for CURIAL-Rapide) at specificities of 71·3% (70·9–71·8) for CURIAL-Lab and 63·6% (63·1–64·1) for CURIAL-Rapide. When combined with LFDs, model predictions improved triage sensitivity from 56·9% (51·7–62·0) for LFDs alone to 85·6% with CURIAL-Lab (81·6–88·9; AUROC 0·925) and 88·2% with CURIAL-Rapide (84·4–91·1; AUROC 0·919), thereby reducing missed COVID-19 cases by 65% with CURIAL-Lab and 72% with CURIAL-Rapide. For the prospective deployment of CURIAL-Rapide, 520 patients were enrolled for point-of-care FBC analysis between Feb 18 and May 10, 2021, of whom 436 received confirmatory PCR testing and ten (2·3%) tested positive. Median time from arrival to a CURIAL-Rapide result was 45 min (IQR 32–64), 16 min (26·3%) sooner than with LFDs (61 min, 37–99; log-rank p<0·0001), and 6 h 52 min (90·2%) sooner than with PCR (7 h 37 min, 6 h 5 min to 15 h 39 min; p<0·0001). Classification performance was high, with sensitivity of 87·5% (95% CI 52·9–97·8), specificity of 85·4% (81·3–88·7), and negative predictive value of 99·7% (98·2–99·9). CURIAL-Rapide correctly excluded infection for 31 (58·5%) of 53 patients who were triaged by a physician to a COVID-19-suspected area but went on to test negative by PCR.
               
                  Interpretation
                  Our findings show the generalisability, performance, and real-world operational benefits of artificial intelligence-driven screening for COVID-19 over standard-of-care in emergency departments. CURIAL-Rapide provided rapid, laboratory-free screening when used with near-patient FBC analysis, and was able to reduce the number of patients who tested negative for COVID-19 but were triaged to COVID-19-suspected areas.
               
                  Funding
                  The Wellcome Trust, University of Oxford Medical and Life Sciences Translational Fund.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jag.2022.102734,Journal,International Journal of Applied Earth Observation and Geoinformation,scopus,2022-04-01,sciencedirect,A review and meta-analysis of generative adversarial networks and their applications in remote sensing,https://api.elsevier.com/content/abstract/scopus_id/85126636731,"Generative Adversarial Networks (GANs) are one of the most creative advances in Deep Learning (DL) in recent years. The Remote Sensing (RS) community has adopted GANs quickly, and reported successful use in a wide variety of applications. Given a sharp increase in research on GANs in the field of RS, there is a need for an in-depth review of the major technological/methodological advances and new applications. In this regard, we conducted a comprehensive review and meta-analysis of GAN-related RS papers, with the goals of familiarizing the RS community with the potential of GANs and helping researchers further explore RS applications of GANs by untangling challenges common in this field. Our review is based on 231 journal papers that were retrieved and selected through the Web of Science (WoS) database. We reviewed the theories, applications, and challenges of GANs, and highlighted the gaps to explore in future studies. Through the meta-analysis conducted in this study, we observed that image classification (especially urban mapping) has been the most popular application of GANs, potentially due to the wide availability of benchmark datasets. One the other hand, we found that relatively few studies have explored the potential of GANs for analyzing medium spatial-resolution multi-spectral images (e.g., Landsat or Sentinel-2), even though such images are often freely available and useful for a wide range of applications (e.g., urban expansion analysis, vegetation mapping, etc.). In spite of the applications of GANs for different RS processing tasks, there are still several gaps/questions in this field such as: 1) which GAN models/configurations are more suitable for different applications? 2) to what degree can GANs replace real RS data in different applications? Such gaps/questions can be appropriately addressed by, for example, conducting experimental studies on evaluating different GAN models for various RS applications to provide better insights into how/which GAN models can be best deployed. The meta-analysis results presented in this study could be helpful for RS researchers to know the opportunities of using GANs and understand how GANs contribute to the current challenges in different RS applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cma.2022.114778,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2022-04-01,sciencedirect,A comprehensive and fair comparison of two neural operators (with practical extensions) based on FAIR data,https://api.elsevier.com/content/abstract/scopus_id/85126008298,"Neural operators can learn nonlinear mappings between function spaces and offer a new simulation paradigm for real-time prediction of complex dynamics for realistic diverse applications as well as for system identification in science and engineering. Herein, we investigate the performance of two neural operators, which have shown promising results so far, and we develop new practical extensions that will make them more accurate and robust and importantly more suitable for industrial-complexity applications. The first neural operator, DeepONet, was published in 2019 (Lu et al., 2019), and its original architecture was based on the universal approximation theorem of Chen & Chen (1995). The second one, named Fourier Neural Operator or FNO, was published in 2020 (Li et al., 2020), and it is based on parameterizing the integral kernel in the Fourier space. DeepONet is represented by a summation of products of neural networks (NNs), corresponding to the branch NN for the input function and the trunk NN for the output function; both NNs are general architectures, e.g., the branch NN can be replaced with a CNN or a ResNet. According to Kovachki et al. (2021), FNO in its continuous form can be viewed conceptually as a DeepONet with a specific architecture of the branch NN and a trunk NN represented by a trigonometric basis. In order to compare FNO with DeepONet computationally for realistic setups, we develop several extensions of FNO that can deal with complex geometric domains as well as mappings where the input and output function spaces are of different dimensions. We also develop an extended DeepONet with special features that provide inductive bias and accelerate training, and we present a faster implementation of DeepONet with cost comparable to the computational cost of FNO, which is based on the Fast Fourier Transform.
                  We consider 16 different benchmarks to demonstrate the relative performance of the two neural operators, including instability wave analysis in hypersonic boundary layers, prediction of the vorticity field of a flapping airfoil, porous media simulations in complex-geometry domains, etc. We follow the guiding principles of FAIR (Findability, Accessibility, Interoperability, and Reusability) for scientific data management and stewardship. The performance of DeepONet and FNO is comparable for relatively simple settings, but for complex geometries the performance of FNO deteriorates greatly. We also compare theoretically the two neural operators and obtain similar error estimates for DeepONet and FNO under the same regularity assumptions.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2022.104743,Journal,Engineering Applications of Artificial Intelligence,scopus,2022-04-01,sciencedirect,"A comprehensive survey of clustering algorithms: State-of-the-art machine learning applications, taxonomy, challenges, and future research prospects",https://api.elsevier.com/content/abstract/scopus_id/85125128146,"Clustering is an essential tool in data mining research and applications. It is the subject of active research in many fields of study, such as computer science, data science, statistics, pattern recognition, artificial intelligence, and machine learning. Several clustering techniques have been proposed and implemented, and most of them successfully find excellent quality or optimal clustering results in the domains mentioned earlier. However, there has been a gradual shift in the choice of clustering methods among domain experts and practitioners alike, which is precipitated by the fact that most traditional clustering algorithms still depend on the number of clusters provided a priori. These conventional clustering algorithms cannot effectively handle real-world data clustering analysis problems where the number of clusters in data objects cannot be easily identified. Also, they cannot effectively manage problems where the optimal number of clusters for a high-dimensional dataset cannot be easily determined. Therefore, there is a need for improved, flexible, and efficient clustering techniques. Recently, a variety of efficient clustering algorithms have been proposed in the literature, and these algorithms produced good results when evaluated on real-world clustering problems. This study presents an up-to-date systematic and comprehensive review of traditional and state-of-the-art clustering techniques for different domains. This survey considers clustering from a more practical perspective. It shows the outstanding role of clustering in various disciplines, such as education, marketing, medicine, biology, and bioinformatics. It also discusses the application of clustering to different fields attracting intensive efforts among the scientific community, such as big data, artificial intelligence, and robotics. This survey paper will be beneficial for both practitioners and researchers. It will serve as a good reference point for researchers and practitioners to design improved and efficient state-of-the-art clustering algorithms.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2022.106682,Journal,Computer Methods and Programs in Biomedicine,scopus,2022-04-01,sciencedirect,Physiological responses to pain in cancer patients: A systematic review,https://api.elsevier.com/content/abstract/scopus_id/85124477290,"Background and objective
                  Pain is one of the most debilitating symptoms in persons with cancer. Still, its assessment is often neglected both by patients and healthcare professionals. There is increasing interest in conducting pain assessment and monitoring via physiological signals that promise to overcome the limitations of state-of-the-art pain assessment tools. This systematic review aims to evaluate existing experimental studies to identify the most promising methods and results for objectively quantifying cancer patients’ pain experience.
               
                  Methods
                  Four electronic databases (Pubmed, Compendex, Scopus, Web of Science) were systematically searched for articles published up to October 2020.
               
                  Results
                  Fourteen studies (528 participants) were included in the review. The selected studies analyzed seven physiological signals. Blood pressure and ECG were the most used signals. Sixteen physiological parameters showed significant changes in association with pain. The studies were fairly consistent in stating that heart rate, the low-frequency to high-frequency component ratio (LF/HF), and systolic blood pressure positively correlate with the pain.
               
                  Conclusions
                  Current evidence supports the hypothesis that physiological signals can help objectively quantify, at least in part, cancer patients’ pain experience. While there is much more to be done to obtain a reliable pain assessment method, this review takes an essential first step by highlighting issues that should be taken into account in future research: use of a wearable device for pervasive recording in a real-world context, implementation of a big-data approach possibly supported by AI, including multiple stratification factors (e.g., cancer site and stage, source of pain, demographic and psychosocial data), and better-defined recording procedures. Improved methods and algorithms could then become valuable add-ons in taking charge of cancer patients.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aap.2022.106594,Journal,Accident Analysis and Prevention,scopus,2022-04-01,sciencedirect,Artificial intelligence-aided railroad trespassing detection and data analytics: Methodology and a case study,https://api.elsevier.com/content/abstract/scopus_id/85124455242,"The railroad industry plays a principal role in the transportation infrastructure and economic prosperity of the United States, and safety is of the utmost importance. Trespassing is the leading cause of rail-related fatalities and there has been little progress in reducing the trespassing frequency and deaths for the past ten years in the United States. Although the widespread deployment of surveillance cameras and vast amounts of video data in the railroad industry make witnessing these events achievable, it requires enormous labor-hours to monitor real-time videos or archival video data. To address this challenge and leverage this big data, this study develops a robust Artificial Intelligence (AI)-aided framework for the automatic detection of trespassing events. This deep learning-based tool automatically detects trespassing events, differentiates types of violators, generates video clips, and documents basic information of the trespassing events into one dataset. This study aims to provide the railroad industry with state-of-the-art AI tools to harness the untapped potential of video surveillance infrastructure through the risk analysis of their data feeds in specific locations. In the case study, the AI has analyzed over 1,600 h of archival video footage and detected around 3,000 trespassing events from one grade crossing in New Jersey. The data generated from these big video data will potentially help understand human factors in railroad safety research and contribute to specific trespassing proactive safety risk management initiatives and improve the safety of the train crew, rail passengers, and road users through engineering, education, and enforcement solutions to trespassing.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmatprotec.2021.117474,Journal,Journal of Materials Processing Technology,scopus,2022-04-01,sciencedirect,Deep DIC: Deep learning-based digital image correlation for end-to-end displacement and strain measurement,https://api.elsevier.com/content/abstract/scopus_id/85123699938,"Digital image correlation (DIC) has become an industry standard to retrieve accurate displacement and strain measurement in tensile testing and other material characterization. Though traditional DIC offers a high precision estimation of deformation for general tensile testing cases, the prediction becomes unstable at large deformation or when the speckle patterns start to tear. In addition, traditional DIC requires a long computation time and often produces a low spatial resolution output affected by filtering and speckle pattern quality. To address these challenges, we propose a new deep learning-based DIC approach – Deep DIC, in which two convolutional neural networks, DisplacementNet and StrainNet, are designed to work together for end-to-end prediction of displacements and strains. DisplacementNet predicts the displacement field and adaptively tracks a region of interest. StrainNet predicts the strain field directly from the image input without relying on the displacement prediction, which significantly improves the strain prediction accuracy. A new dataset generation method is developed to synthesize a realistic and comprehensive dataset, including the generation of speckle patterns and the deformation of the speckle image with synthetic displacement fields. Though trained on synthetic datasets only, Deep DIC gives highly consistent and comparable predictions of displacement and strain with those obtained from commercial DIC software for real experiments, while it outperforms commercial software with very robust strain prediction even at large and localized deformation and varied pattern qualities. In addition, Deep DIC is capable of real-time prediction of deformation with a calculation time down to milliseconds.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmatprotec.2022.117495,Journal,Journal of Materials Processing Technology,scopus,2022-04-01,sciencedirect,Real-time anomaly detection using convolutional neural network in wire arc additive manufacturing: Molybdenum material,https://api.elsevier.com/content/abstract/scopus_id/85123250275,"Wire arc additive manufacturing (WAAM) has received attention because of its high deposition rate, low cost, and high material utilization. However, quality issues are critical in WAAM because it builds upon arc welding technology, which can result in low precision and poor quality of the melted parts. Hence, anomaly detection is essential for identifying abnormal behaviors and process instability during WAAM to reduce the time and cost of post-process treatment. The relevant studies have been conducted on anomaly detection algorithms using machine learning in fused deposition modeling and laser powder bed fusion; however, they have less investigated the implementation for in situ quality monitoring in WAAM. This work presents a real-time anomaly detection method that uses a convolutional neural network (CNN) in WAAM. The proposed method enables creation of CNN-based models that detect abnormalities by learning from the melt pool image data, which are pre-processed to increase learning performance. A prototype system was implemented to classify melt pool images into “normal” and “abnormal” states, with the latter accounting for balling and bead-cut defects. Experiments were conducted using molybdenum, a cost-intensive and hard-to-machine material. Four CNN-based models were created using MobileNetV2, DenseNet169, Resnet50V2, and InceptionResNetV2. Then, their performances were validated in terms of classification accuracy and processing time. The MobileNetV2 model yielded the best performance with 98 % of classification accuracy and 0.033 s/frame of processing time. This model was also compared with an object detection algorithm named “YOLO”, which yielded 73.5 % of classification accuracy and 0.067 s/frame of processing time.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmatprotec.2021.117476,Journal,Journal of Materials Processing Technology,scopus,2022-04-01,sciencedirect,Correlating in-situ sensor data to defect locations and part quality for additively manufactured parts using machine learning,https://api.elsevier.com/content/abstract/scopus_id/85123196207,"In this work, process monitoring data, including layerwise imagery, multi-spectral emissions, and laser scan vector data, were collected during laser-based powder bed fusion additive manufacturing and correlated to fatigue performance. All parts were X-ray CT scanned post-build, and internal flaws were identified via an automated defect recognition software. Convolutional neural networks were trained to discriminate flaws from nominal build conditions using in situ data modalities only. Trained classifiers were then tested against a previously unseen data set collected from an independent build, and classification performance and metrics for information content provided by each individual modality were formally established. Correlations were drawn between the detected flaw populations and the corresponding fatigue properties, demonstrating that fatigue critical lack-of-fusion flaws can be detected via machine learning of in situ sensor data. The present results also show that, at least from a classification accuracy perspective, flaw detection via ML on process monitoring data is a viable path forward for real-time flaw detection and automated, interlayer repair strategies. However, strategies for extracting and analyzing sensor data in real-time without incurring excessive increases in build time must first be developed. These developments represent necessary components to draw direct correlations between in situ data modalities, internal part quality, and fatigue performance.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2022.01.001,Journal,Information Sciences,scopus,2022-04-01,sciencedirect,SocialLGN: Light graph convolution network for social recommendation,https://api.elsevier.com/content/abstract/scopus_id/85122632184,"Graph Neural Networks have been applied in recommender systems to learn the representation of users and items from a user-item graph. In the state-of-the-art, there are two major challenges in applying Graph Neural Networks to social recommendation: (i) how to accurately learn the representation of users and items from the user-item interaction graph and social graph, and (ii) based on the fact that each user is represented simultaneously by the two graphs, how to integrate the user representations learned from these two graphs. Aiming at addressing these challenges, this paper proposes a new social recommendation system called SocialLGN. In SocialLGN, the representation of each user and item is propagated in the user-item interaction graph with light graph convolutional layers; in the meantime, the user’s representation is propagated in the social graph. Based on this, a graph fusion operation is designed to aggregate user representations during propagation. The weighted sum is applied to combine the representations learned by each layer. Comprehensive experiments are conducted on two real-world datasets, and the result shows that the proposed SocialLGN outperforms the SOTA method, especially in handling the cold-start problem. Our PyTorch implemented model is available via https://github.com/leo0481/SocialLGN.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.conengprac.2021.105046,Journal,Control Engineering Practice,scopus,2022-04-01,sciencedirect,Deep reinforcement learning with shallow controllers: An experimental application to PID tuning,https://api.elsevier.com/content/abstract/scopus_id/85122624409,"Deep reinforcement learning (RL) is an optimization-driven framework for producing control strategies for general dynamical systems without explicit reliance on process models. Good results have been reported in simulation. Here we demonstrate the challenges in implementing a state of the art deep RL algorithm on a real physical system. Aspects include the interplay between software and existing hardware; experiment design and sample efficiency; training subject to input constraints; and interpretability of the algorithm and control law. At the core of our approach is the use of a PID controller as the trainable RL policy. In addition to its simplicity, this approach has several appealing features: No additional hardware needs to be added to the control system, since a PID controller can easily be implemented through a standard programmable logic controller; the control law can easily be initialized in a “safe” region of the parameter space; and the final product—a well-tuned PID controller—has a form that practitioners can reason about and deploy with confidence.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ejor.2021.06.023,Journal,European Journal of Operational Research,scopus,2022-03-16,sciencedirect,"Fairness in credit scoring: Assessment, implementation and profit implications",https://api.elsevier.com/content/abstract/scopus_id/85109424638,"The rise of algorithmic decision-making has spawned much research on fair machine learning (ML). Financial institutions use ML for building risk scorecards that support a range of credit-related decisions. Yet, the literature on fair ML in credit scoring is scarce. The paper makes three contributions. First, we revisit statistical fairness criteria and examine their adequacy for credit scoring. Second, we catalog algorithmic options for incorporating fairness goals in the ML model development pipeline. Last, we empirically compare different fairness processors in a profit-oriented credit scoring context using real-world data. The empirical results substantiate the evaluation of fairness measures, identify suitable options to implement fair credit scoring, and clarify the profit-fairness trade-off in lending decisions. We find that multiple fairness criteria can be approximately satisfied at once and recommend separation as a proper criterion for measuring the fairness of a scorecard. We also find fair in-processors to deliver a good balance between profit and fairness and show that algorithmic discrimination can be reduced to a reasonable level at a relatively low cost. The codes corresponding to the paper are available on GitHub.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.measurement.2022.110819,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2022-03-15,sciencedirect,ChickTrack – A quantitative tracking tool for measuring chicken activity,https://api.elsevier.com/content/abstract/scopus_id/85124237105,"The automatic detection, counting and tracking of individual and flocked chickens in the poultry industry is of paramount to enhance farming productivity and animal welfare. Due to methodological difficulties, such as the complex background of images, varying lighting conditions, and occlusions from e.g., feeding stations, water nipple stations and barriers in the chicken rearing production floor, it is a challenging task to automatically recognize and track birds using computer software. Here, a deep learning model based on You Only Look Once (Yolov5) is proposed for detecting domesticated chickens from videos with varying complex backgrounds. A multiscale feature is being adapted to the Yolov5 network for mapping modules in the counting and tracking of the trajectories of the chickens. The Yolov5 network was trained and tested on our dataset which resulted in an enhanced tracking precision accuracy. Using Kalman Filter, the proposed model was able to track multiple chickens simultaneously with the focus to associate individual chickens across the frames of the video for real time and online applications. By being able to detect the chickens amid diverse background interference and counting them precisely along with tracking the movement and measuring their travelled path and direction, the proposed model provides excellent performance for on-farm applications. Artificial intelligence enabled automatic measurements of chicken behavior on-farm using cameras offers continuous monitoring of the chicken's ability to perch, walk, interact with other birds and the farm environment, as well as the assessment of dustbathing, thigmotaxis, and foraging frequency, which are important indicators for their ability to express natural behaviors. This study highlights the potential of automated monitoring of poultry through the usage of ChickTrack model as a digital tool in enabling science-based animal husbandry practices and thereby promote positive welfare for chickens in animal farming.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.buildenv.2022.108786,Journal,Building and Environment,scopus,2022-03-15,sciencedirect,Decision Support System for technology selection based on multi-criteria ranking: Application to NZEB refurbishment,https://api.elsevier.com/content/abstract/scopus_id/85123838318,"Refurbishing existing building into Near Zero Energy Building (NZEB) is a key objective for the European Union. In order to achieve high rate of conversion, new refurbishment process must allow Decision Makers (DMs) (architects or designers) to sort through an ever increasing list of new technologies while taking into account uncertain preferences from multiple stakeholders.
                  A Decision Support System (DSS) based on Multi-Criteria Decision-Making (MCDM) approaches is proposed. The DSS enables the DMs to browse the solutions space by selecting the relevant criteria, order them by preferences and specify the granularity in the assessment of the technologies regarding each criteria.
                  This DSS is based on a ranking algorithm that operates on multiple types of quantitative (continuous, discrete, or binary) and qualitative (nominative or ordinal) variables from technological and human sources. An online user interface allows the real-time exploration of the solution space. A sensitivity analysis of the algorithm is conducted to expose the influence of the ranking algorithm parameters and to demonstrate the robustness of this algorithm. The proposed DSS is eventually implemented and validated through a use case concerning the choice of insulating materials considering heterogeneous criteria that model sustainable constraints.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.apenergy.2021.118436,Journal,Applied Energy,scopus,2022-03-15,sciencedirect,Atikokan Digital Twin: Machine learning in a biomass energy system,https://api.elsevier.com/content/abstract/scopus_id/85123769129,"The Atikokan Generating Station, operated by Ontario Power Generation, has a 200 MW, biomass-fired tower boiler that operates on a dispatch schedule with a five-minute cycle. The boiler is generally operated in the range of 40–100 MW using two of five burner levels. In order to optimize boiler performance, we propose the implementation of a unique digital twin. Our digital twin abstraction couples Bayesian inference from science-based models and from observations (machine learning) with decision theory to predict operating-variable set points that optimize the physical asset (the boiler) in the presence of uncertainty (artificial intelligence). We focus this paper on the continuous Bayesian machine learning part of the Atikokan Digital Twin; we discuss decision theory in a companion paper. We identify and learn about 12 operational, model, and measured-output parameters and their uncertainties from high-fidelity, science-based simulations of the Atikokan boiler and from the observed measurements at the power plant. Since the goal of the Atikokan Digital Twin is to implement it online in real time, we require fast function evaluations for the quantities of interest extracted from the simulations in the Bayesian analysis. We use Gaussian process regression/interpolation to create accurate, robust surrogate models. We define the Bayesian priors and likelihood function and solve for the posterior distributions of the 12 parameters. We then propagate these distributions (i.e., parameters with uncertainty) into the predicted distributions of 790 quantities of interest to learn about the relative importance of various sources of error including experimental, model, and operating-parameter errors.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2022.100434,Journal,Patterns,scopus,2022-03-11,sciencedirect,scTenifoldKnk: An efficient virtual knockout tool for gene function predictions via single-cell gene regulatory network perturbation,https://api.elsevier.com/content/abstract/scopus_id/85124906786,"Gene knockout (KO) experiments are a proven, powerful approach for studying gene function. However, systematic KO experiments targeting a large number of genes are usually prohibitive due to the limit of experimental and animal resources. Here, we present scTenifoldKnk, an efficient virtual KO tool that enables systematic KO investigation of gene function using data from single-cell RNA sequencing (scRNA-seq). In scTenifoldKnk analysis, a gene regulatory network (GRN) is first constructed from scRNA-seq data of wild-type samples, and a target gene is then virtually deleted from the constructed GRN. Manifold alignment is used to align the resulting reduced GRN to the original GRN to identify differentially regulated genes, which are used to infer target gene functions in analyzed cells. We demonstrate that the scTenifoldKnk-based virtual KO analysis recapitulates the main findings of real-animal KO experiments and recovers the expected functions of genes in relevant cell types.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2022.100440,Journal,Patterns,scopus,2022-03-11,sciencedirect,DAISM-DNN<sup>XMBD</sup>: Highly accurate cell type proportion estimation with in silico data augmentation and deep neural networks,https://api.elsevier.com/content/abstract/scopus_id/85124889392,"Understanding the immune cell abundance of cancer and other disease-related tissues has an important role in guiding disease treatments. Computational cell type proportion estimation methods have been previously developed to derive such information from bulk RNA sequencing data. Unfortunately, our results show that the performance of these methods can be seriously plagued by the mismatch between training data and real-world data. To tackle this issue, we propose the DAISM-DNNXMBD (XMBD: Xiamen Big Data, a biomedical open software initiative in the National Institute for Data Science in Health and Medicine, Xiamen University, China.) (denoted as DAISM-DNN) pipeline that trains a deep neural network (DNN) with dataset-specific training data populated from a certain amount of calibrated samples using DAISM, a novel data augmentation method with an in silico mixing strategy. The evaluation results demonstrate that the DAISM-DNN pipeline outperforms other existing methods consistently and substantially for all the cell types under evaluation in real-world datasets.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rineng.2022.100362,Journal,Results in Engineering,scopus,2022-03-01,sciencedirect,Machine learning based adaptive soft sensor for flash point inference in a refinery realtime process,https://api.elsevier.com/content/abstract/scopus_id/85124665324,"In industrial control processes, certain characteristics are sometimes difficult to measure by a physical sensor due to technical and/or economic limitations. This fact is especially true in the petrochemical industry. Some of those quantities are especially crucial for operators and process safety. This is the case for the automotive diesel Flash Point Temperature (FT). Traditional methods for FT estimation are based on the study of the empirical inference between flammability properties and the denoted target magnitude. The necessary measures are taken indirectly by samples from the process and analyzing them in the laboratory, this process implies time (can take hours from collection to flash temperature measurement) and thus make it very difficult for real-time monitorization, which in fact results in security and economical losses. This study defines a procedure based on Machine Learning modules that demonstrate the power of real-time monitorization over real data from an important international refinery. As input, easily measured values provided in real-time, such as temperature, pressure, and hydraulic flow are used and a benchmark of different regressive algorithms for FT estimation is presented. The study highlights the importance of sequencing preprocessing techniques for the correct inference of values. The implementation of adaptive learning strategies achieves considerable economic benefits in the productization of this soft sensor. The validity of the method is tested in the reality of a refinery. In addition, real-world industrial data sets tend to be unstable and volatile, and the data is often affected by noise, outliers, irrelevant or unnecessary features, and missing data. This contribution demonstrates with the inclusion of a new concept, called an adaptive soft sensor, the importance of the dynamic adaptation of the conformed schemes based on Machine Learning through their combination with feature selection, dimensional reduction, and signal processing techniques. The economic benefits of applying this soft sensor in the refinery's production plant and presented as potential semi-annual savings.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2022.108463,Journal,Applied Soft Computing,scopus,2022-03-01,sciencedirect,Session-based social and dependency-aware software recommendation,https://api.elsevier.com/content/abstract/scopus_id/85124405244,"With the increase of complexity of modern software, social collaborative coding and reuse of open source software packages become more and more popular, which thus greatly enhances the development efficiency and software quality. However, the explosive growth of open source software packages exposes developers to the challenge of information overload. While this can be addressed by conventional recommender systems, they usually do not consider particular constraints of social coding such as social influence among developers and dependency relations among software packages. In this paper, we aim to model the dynamic interests of developers with both social influence and dependency constraints, and propose the Session-based Social and Dependency-aware software Recommendation (SSDRec) model. This model integrates recurrent neural network (RNN) and graph attention network (GAT) into a unified framework. An RNN is employed to model the short-term dynamic interests of developers in each session and two GATs are utilized to capture social influence from friends and dependency constraints from dependent software packages, respectively. Extensive experiments are conducted on real-world datasets and the results demonstrate that our model significantly outperforms the competitive baselines.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2022.103996,Journal,Journal of Biomedical Informatics,scopus,2022-03-01,sciencedirect,Evaluating pointwise reliability of machine learning prediction,https://api.elsevier.com/content/abstract/scopus_id/85123373748,"Interest in Machine Learning applications to tackle clinical and biological problems is increasing. This is driven by promising results reported in many research papers, the increasing number of AI-based software products, and by the general interest in Artificial Intelligence to solve complex problems. It is therefore of importance to improve the quality of machine learning output and add safeguards to support their adoption. In addition to regulatory and logistical strategies, a crucial aspect is to detect when a Machine Learning model is not able to generalize to new unseen instances, which may originate from a population distant to that of the training population or from an under-represented subpopulation. As a result, the prediction of the machine learning model for these instances may be often wrong, given that the model is applied outside its “reliable” space of work, leading to a decreasing trust of the final users, such as clinicians. For this reason, when a model is deployed in practice, it would be important to advise users when the model’s predictions may be unreliable, especially in high-stakes applications, including those in healthcare. Yet, reliability assessment of each machine learning prediction is still poorly addressed.
                  Here, we review approaches that can support the identification of unreliable predictions, we harmonize the notation and terminology of relevant concepts, and we highlight and extend possible interrelationships and overlap among concepts. We then demonstrate, on simulated and real data for ICU in-hospital death prediction, a possible integrative framework for the identification of reliable and unreliable predictions. To do so, our proposed approach implements two complementary principles, namely the density principle and the local fit principle. The density principle verifies that the instance we want to evaluate is similar to the training set. The local fit principle verifies that the trained model performs well on training subsets that are more similar to the instance under evaluation. Our work can contribute to consolidating work in machine learning especially in medicine.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.est.2021.103920,Journal,Journal of Energy Storage,scopus,2022-03-01,sciencedirect,An evaluation of the thermal behaviour of a lithium-ion battery pack with a combination of pattern-based artificial neural networks (PBANN) and numerical simulation,https://api.elsevier.com/content/abstract/scopus_id/85123254933,"Thermal management is an important factor in extending the battery's life time and ensuring the quality of the output current. A numerical evaluation of the effect of varying the configuration of the battery cells and liquid-cooled channels was conducted in this case study. For the first time, a physics-informed neural network is coupled with visual tracking and commercial software for prediction of the thermal behaviour of a battery package. Combination of physics-informed neural network and visual tracking present as pattern-based neural networks (PBANNs). This method was used to predict the surface temperature at several cooling rates (Vinlet=0.1, 0.3, and 0.5 m/s) in response to variations in the surface temperature of the battery. Compared with conventional ANN methods, PBANN can significantly reduce the computational cost of transient case studies. Furthermore, PBANN can be directly coupled with commercial software in real-time. The complexity of coding for numerical simulation could be reduced by this coupling algorithm. Based on the results of this coupling, battery configurations may affect temperature profiles. By distributing cooling tubes evenly, the average temperature of the battery and phase change material (PCM) could be reduced by 25.3%. According to the results, the combination of liquid-cooled and PCM could guarantee that the battery temperature would not exceed the limits.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2021.11.011,Journal,Information Sciences,scopus,2022-03-01,sciencedirect,Survival functions versus conditional aggregation-based survival functions on discrete space,https://api.elsevier.com/content/abstract/scopus_id/85122830123,In this paper we deal with conditional aggregation-based survival functions recently introduced by Boczek et al. (2020). The concept is worth to study because of its possible implementation in real-life situations and mathematical theory as well. The aim of this paper is the comparison of this new notion with the standard survival function. We state sufficient and necessary conditions under which the generalized and the standard survival function equal. The main result is the characterization of the family of conditional aggregation operators (on discrete space) for which these functions coincide.,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rser.2021.111977,Journal,Renewable and Sustainable Energy Reviews,scopus,2022-03-01,sciencedirect,"Performance prediction, optimal design and operational control of thermal energy storage using artificial intelligence methods",https://api.elsevier.com/content/abstract/scopus_id/85121270056,"Capable of storing and redistributing energy, thermal energy storage (TES) shows a promising applicability in energy systems. Recently, artificial intelligence (AI) technique is gradually playing an important role in automation, information retrieval, decision making, intelligent recognition, monitoring and management. With the assistance of AI techniques, TES systems can become more and more reasonable and intelligent, which paves a new path for the researches on TES. In the present review, a comprehensive literature summarization and analysis on the application of AI techniques to TES is presented. Performance prediction, optimal design, control and operation by means of AI for the TES systems with various applications are discussed and compared. This review shows that AI-based prediction models, like artificial neural network and support vector machine, can accurately estimate the TES performance and the properties of TES materials in a very fast fashion. AI-based optimization algorithms, such as genetic algorithm, particle swarm optimization, and teaching-learning-based optimization are able to optimize the design and operation of the TES systems towards the objectives like higher system efficiency, cost savings, more renewable energy utilization and less environmental impacts. Fuzzy logic can be utilized to properly design and control the TES systems where uncertain and imprecise factors are inevitably present. General strategies of the AI-based TES performance modelling and the completely AI-based design and control of the TES are summarized, while the main limitations are that AI cannot be used to directly unveil the unknown physical mechanism of the TES and that the lack of the comprehensive TES performance database hinders the real-world implementation. On the way to completely intelligent TES systems, further investigations on the enhancement of adaptation and self-improvement capability are necessary. In addition, the potential research topics are pointed out for the future development and deployment referring to the needs of the future smart energy system, intelligent and zero energy building, and smart home.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.adhoc.2021.102757,Journal,Ad Hoc Networks,scopus,2022-03-01,sciencedirect,Deep embedded median clustering for routing misbehaviour and attacks detection in ad-hoc networks,https://api.elsevier.com/content/abstract/scopus_id/85120863584,"Due to the properties of ad-hoc networks, it appears that designing sophisticated defence schemes with more computing capital is impossible in most situations. Recently, an inconsistency in the ad-hoc design of intrusion detection in the network has gotten a lot of coverage, with these intrusion detection techniques operating in either cluster-based or host-based configurations. The host and cluster-based systems have advantages and disadvantages, such as the network preserve security in case of delay in replacing a cluster head. Many detection systems in these networks use a supervised learning method to learn from shared routing knowledge. Deep learning is the trending supervised learning method which is been suggested for many applications, due to its deep feature extraction and classification capability. The deep learning method is best suitable to resolve the problems of the ad hoc network. But due to its limitation of supervised learning nature, more research finds are needed before implementation. These intelligence methods need a massive labeled dataset to self-train and take a decision in real-time. Also, these methods will be vulnerable to new attacks. To address the issues posed, the deep learning approach requires a technique of incorporating unsupervised learning behaviours. This paper proposes and highlights the methodology - Deep Embedded Median Clustering (DEMC), which performs two-phase operations (1) Organization of latent feature space (2) K-median clustering to cluster the Z with Kullback–Leibler divergence as the objective function. Many researchers suggested various methodologies for better anomaly detection in the network, but the knowledge gap and the possibilities for a better solution still exist. This study explores the new possibility and potential of an unsupervised learning technique that works with the nature of deep learning for analyzing and detecting anomalies and intrusion in ad hoc networks. The test to check the DEMC ability has been organized, and the findings are tabulated for analysis.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patrec.2021.10.014,Journal,Pattern Recognition Letters,scopus,2022-03-01,sciencedirect,Adversarial learning and decomposition-based domain generalization for face anti-spoofing,https://api.elsevier.com/content/abstract/scopus_id/85119451640,"Face anti-spoofing (FAS) plays a critical role in the face recognition community for securing the face presentation attacks. Many works have been proposed to regard FAS as a domain generalization problem for robust deployment in real-world scenarios. However, existing methods focus on extracting intrinsic spoofing cues to improve the generalization ability, yet neglect to train a robust classifier. In this paper, we propose a framework to improve the generalization ability of face anti-spoofing in two folds:) a generalized feature space is obtained via aggregation of all live faces while dispersing each domain’s spoof faces; and) a domain agnostic classifier is trained through low-rank decomposition. Specifically, a Common Specific Decomposition for Specific (CSD-S) layer is deployed in the last layer of the network to select common features while discarding domain-specific ones among multiple source domains. The above-mentioned two components are integrated into an end-to-end framework, ensuring the generalization ability to unseen scenarios. The extensive experiments demonstrate that the proposed method achieves state-of-the-art results on four public datasets, including CASIA-MFSD, MSU-MFSD, Replay-Attack, and OULU-NPU.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.resconrec.2021.106022,Journal,"Resources, Conservation and Recycling",scopus,2022-03-01,sciencedirect,Using computer vision to recognize composition of construction waste mixtures: A semantic segmentation approach,https://api.elsevier.com/content/abstract/scopus_id/85118570774,"Timely and accurate recognition of construction waste (CW) composition can provide yardstick information for its subsequent management (e.g., segregation, determining proper disposal destination). Increasingly, smart technologies such as computer vision (CV), robotics, and artificial intelligence (AI) are deployed to automate waste composition recognition. Existing studies focus on individual waste objects in well-controlled environments, but do not consider the complexity of the real-life scenarios. This research takes the challenges of the mixture and clutter nature of CW as a departure point and attempts to automate CW composition recognition by using CV technologies. Firstly, meticulous data collection, cleansing, and annotation efforts are made to create a high-quality CW dataset comprising 5,366 images. Then, a state-of-the-art CV semantic segmentation technique, DeepLabv3+, is introduced to develop a CW segmentation model. Finally, several training hyperparameters are tested via orthogonal experiments to calibrate the model performance. The proposed approach achieved a mean Intersection over Union (mIoU) of 0.56 in segmenting nine types of materials/objects with a time performance of 0.51 s per image. The approach was found to be robust to variation of illumination and vehicle types. The study contributes to the important problem of material composition recognition, formalizing a deep learning-based semantic segmentation approach for CW composition recognition in complex environments. It paves the way for better CW management, particularly in engaging robotics, in the future. The trained models are hosted on GitHub, based on which researchers can further finetune for their specific applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.apenergy.2021.118336,Journal,Applied Energy,scopus,2022-02-15,sciencedirect,Real-time monitoring of occupancy activities and window opening within buildings using an integrated deep learning-based approach for reducing energy demand,https://api.elsevier.com/content/abstract/scopus_id/85122427364,"Occupancy behaviour in buildings can impact the energy performance and operation of heating, ventilation and air-conditioning (HVAC) systems. HVAC, which uses conventional control strategies or “fixed” setpoint schedules, could not adjust to the conditioned spaces' actual requirements, resulting in building spaces being over or under-conditioned. While the unintended opening of windows can lead to substantial heat loss and consequently raises energy consumption. To optimise building operations, it is necessary to employ solutions such as demand-driven controls, which can monitor the utilisation of indoor spaces and provide the actual thermal comfort requirements of occupants. This study presents a novel vision-based deep learning framework for occupancy activity detection and recognition including the manual window operations in buildings. A region-based Convolutional Neural Network (R-CNN) model was trained and deployed to a camera for real-time detection and recognition. Based on the field experiments conducted within a case study University building, overall accuracy of 85.63% was achieved for occupancy activity detection and 92.20% for window operation detection. Building energy simulation and various scenario-based cases were used to assess the impact of such an approach on the building energy demand and provide insights into how the proposed detection method can enable HVAC systems to respond to dynamic changes within indoor spaces. Results showed that the proposed approach could reduce the over-or under-estimation of occupancy heat gains compared with the use of “fixed” or static profiles. In addition, the approach can help alert building users or managers about windows left open unintentionally, which can reduce unnecessary ventilation heat losses. Furthermore, the approach can also predict the room CO2 concentration and advise occupants about a suitable natural ventilation strategy. The study highlighted the potential of the multi-purpose detection approach, but further development is necessary, including optimisation of the deep learning model, full integration with HVAC controls and further model training and field testing.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engstruct.2021.113824,Journal,Engineering Structures,scopus,2022-02-15,sciencedirect,"Explainable machine learning using real, synthetic and augmented fire tests to predict fire resistance and spalling of RC columns",https://api.elsevier.com/content/abstract/scopus_id/85122261194,"This paper presents the development of systematic machine learning (ML) approach to enable explainable and rapid assessment of fire resistance and fire-induced spalling of reinforced concrete (RC) columns. The developed approach comprises an ensemble of three novel ML algorithms namely; random forest (RF), extreme gradient boosted trees (ExGBT), and deep learning (DL). These algorithms are trained to account for a wide collection of geometric characteristics and material properties, as well as loading conditions to examine fire performance of normal and high strength RC columns by analyzing a comprehensive database of fire tests comprising of over 494 observations. The developed ensemble is also capable of presenting quantifiable insights to ML predictions; thus, breaking free from the notion of “black-box” ML and establishing a solid step towards transparent and explainable ML. Most importantly, this work tackles the scarcity of available fire tests by proposing new techniques to leverage the use of real, synthetic, and augmented fire test observations. The developed ML ensemble has been calibrated and validated for standard and design fire exposures and one-, two-, three- and four-sided fire exposures thus; covering a wide range of practical scenarios present during fire incidents. When fully deployed, the developed ensemble can analyze over 5,000 RC columns in under 60 s; thus, providing an attractive solution for researchers and practitioners. The presented approach can also be easily extended for evaluating fire resistance and spalling of other structural members under varying fire scenarios and loading conditions and hence paves the way to modernize the state of this research area and practice.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ymssp.2021.108284,Journal,Mechanical Systems and Signal Processing,scopus,2022-02-15,sciencedirect,Real-time model calibration with deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85112506465,"The real-time, and accurate inference of model parameters is of great importance in many scientific and engineering disciplines that use computational models (such as a digital twin) for the analysis and prediction of complex physical processes. However, fast and accurate inference for processes of complex systems cannot easily be achieved in real-time with state-of-the-art methods under noisy real-world conditions with the requirement of a real-time response. The primary reason is that the inference of model parameters with traditional techniques based on optimization or sampling often suffers from computational and statistical challenges, resulting in a trade-off between accuracy and deployment time. In this paper, we propose a novel framework for inference of model parameters based on reinforcement learning. The proposed methodology is demonstrated and evaluated on two different physics-based models of turbofan engines. The experimental results demonstrate that the proposed methodology outperforms all other tested methods in terms of speed and robustness, with high inference accuracy.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.comnet.2021.108616,Journal,Computer Networks,scopus,2022-02-11,sciencedirect,LightLog: A lightweight temporal convolutional network for log anomaly detection on the edge,https://api.elsevier.com/content/abstract/scopus_id/85119961419,"Log anomaly detection on edge devices is the key to enhance edge security when deploying IoT systems. Despite the success of many newly proposed deep learning based log anomaly detection methods, handling large-scale logs on edge devices is still a bottleneck due to the limited computational power on these devices to fulfil the real-time processing requirement for accurate anomaly detection. In this work, we propose a novel lightweight log anomaly detection algorithm, named LightLog, to tackle this research gap. In specific, we achieve real-time processing speed on the task via two aspects: (i) creation of a low-dimensional semantic vector space based on word2vec and post-processing algorithms (PPA); and (ii) design of a lightweight temporal convolutional network (TCN) for the detection. These two components significantly reduce the number of parameters and computations of a standard TCN while improving the detection performance. Experimental results show that our LightLog outperforms several benchmarking methods, namely DeepLog, LogAnomaly and RobustLog, by achieving 97.0 F1 score on HDFS Dataset and 97.2 F1 score on BGL with smallest model size. This effective yet efficient method paves the way to the deployment of log anomaly detection on the edge. Our source code and datasets are freely available on https://github.com/Aquariuaa/LightLog.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ajhg.2021.12.008,Journal,American Journal of Human Genetics,scopus,2022-02-03,sciencedirect,PhenoApt leverages clinical expertise to prioritize candidate genes via machine learning,https://api.elsevier.com/content/abstract/scopus_id/85123821072,"In recent years, exome sequencing (ES) has shown great utility in the diagnoses of Mendelian disorders. However, after rigorous filtering, a typical ES analysis still involves the interpretation of hundreds of variants, which greatly hinders the rapid identification of causative genes. Since the interpretations of ES data require comprehensive clinical analyses, taking clinical expertise into consideration can speed the molecular diagnoses of Mendelian disorders. To leverage clinical expertise to prioritize candidate genes, we developed PhenoApt, a phenotype-driven gene prioritization tool that allows users to assign a customized weight to each phenotype, via a machine-learning algorithm. Using the ability to rank causative genes in top-10 lists as an evaluation metric, baseline analysis demonstrated that PhenoApt outperformed previous phenotype-driven gene prioritization tools by a relative increase of 22.7%–140.0% in three independent, real-world, multi-center cohorts (cohort 1, n = 185; cohort 2, n = 784; and cohort 3, n = 208). Additional trials showed that, by adding weights to clinical indications, which should be explained by the causative gene, PhenoApt performance was improved by a relative increase of 37.3% in cohort 2 (n = 471) and 21.4% in cohort 3 (n = 208). Moreover, PhenoApt could assign an intrinsic weight to each phenotype based on the likelihood of its being a Mendelian trait using term frequency-inverse document frequency techniques. When clinical indications were assigned with intrinsic weights, PhenoApt performance was improved by a relative increase of 23.7% in cohort 2 and 15.5% in cohort 3. For the integration of PhenoApt into clinical practice, we developed a user-friendly website and a command-line tool.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ces.2021.117205,Journal,Chemical Engineering Science,scopus,2022-02-02,sciencedirect,"Developments of leak detection, diagnostics, and prediction algorithms in multiphase flows",https://api.elsevier.com/content/abstract/scopus_id/85118896502,"Leak detection, diagnostics, and prediction constitute a crucial phase of the flow assurance risk management process for onshore and offshore pipelines. There are a variety of techniques and algorithms that can be deployed to address each aspect. To date, most review papers have concentrated on steady-state and single-phase flow conditions. The goal of the current review is therefore to carry out a thorough analysis of the available leak detection and diagnosis methods by focusing on (i) multiphase flow and transient flow conditions, (ii) model-based and data-driven techniques, (iii) prediction tools, and (iv) performance measures. Detailed assessment of leak detection methods based on accuracy, complexity, data requirement, and cost of installation are discussed. Data-driven techniques are utterly dependent on qualitative and quantitative data available from pipeline systems. Contrastingly data-driven techniques, model-based techniques require less data to achieve leak detection, provided that a nearly accurate base model is available. Different methodologies and technologies can be combined in order to produce the best detection and diagnosis outputs. In many cases, statistical analysis was combined with the Real Time Transient Method (RTTM), which helped to minimize false alarms. The material in this review can be used as a robust guide for the design of diagnostic systems and further research.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.vrih.2022.01.004,Journal,Virtual Reality and Intelligent Hardware,scopus,2022-02-01,sciencedirect,Virtual-reality-based digital twin of office spaces with social distance measurement feature,https://api.elsevier.com/content/abstract/scopus_id/85124517698,"Background
                  Social distancing is an effective way to reduce the spread of the SARS-CoV-2 virus. Many students and researchers have already attempted to use computer vision technology to automatically detect human beings in the field of view of a camera and help enforce social distancing. However, because of the present lockdown measures in several countries, the validation of computer vision systems using large-scale datasets is a challenge.
               
                  Methods
                  In this paper, a new method is proposed for generating customized datasets and validating deep-learning-based computer vision models using virtual reality (VR) technology. Using VR, we modeled a digital twin (DT) of an existing office space and used it to create a dataset of individuals in different postures, dresses, and locations. To test the proposed solution, we implemented a convolutional neural network (CNN) model for detecting people in a limited-sized dataset of real humans and a simulated dataset of humanoid figures.
               
                  Results
                  We detected the number of persons in both the real and synthetic datasets with more than 90% accuracy, and the actual and measured distances were significantly correlated (r=0.99). Finally, we used intermittent-layer- and heatmap-based data visualization techniques to explain the failure modes of a CNN.
               
                  Conclusions
                  A new application of DTs is proposed to enhance workplace safety by measuring the social distance between individuals. The use of our proposed pipeline along with a DT of the shared space for visualizing both environmental and human behavior aspects preserves the privacy of individuals and improves the latency of such monitoring systems because only the extracted information is streamed.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.comcom.2021.11.011,Journal,Computer Communications,scopus,2022-02-01,sciencedirect,RAN energy efficiency and failure rate through ANN traffic predictions processing,https://api.elsevier.com/content/abstract/scopus_id/85120657977,"In this paper, we focus on the application of ML tools to resource management in a portion of a Radio Access Network (RAN) and, in particular, to Base Station (BS) activation and deactivation, aiming at reducing energy consumption while providing enough capacity to satisfy the variable traffic demand generated by end users. In order to properly decide on BS (de)activation, traffic predictions are needed, and Artificial Neural Networks (ANN) are used for this purpose. Since critical BS (de)activation decisions are not taken in proximity of minima and maxima of the traffic patterns, high accuracy in the traffic estimation is not required at those times, but only close to the times when a decision is taken. This calls for careful processing of the ANN traffic predictions to increase the probability of correct decision. Numerical performance results in terms of energy saving and traffic lost due to incorrect BS deactivations are obtained by simulating algorithms for traffic predictions processing, using real traffic as input. Results suggest that good performance trade-offs can be achieved even in presence of non-negligible traffic prediction errors, if these forecasts are properly processed. The impact of forecast processing for dynamic resource allocation on the BS failure rate is also investigated. Results reveal that conservative approaches better prevent BSs from hardware failure. Nevertheless, the deployment of newer devices, designed for fast dynamic networks, allows the adoption of approaches which frequently activate and deactivate BSs, thus achieving higher energy saving.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.simpat.2021.102446,Journal,Simulation Modelling Practice and Theory,scopus,2022-02-01,sciencedirect,Modelling argumentation in short text: A case of social media debate,https://api.elsevier.com/content/abstract/scopus_id/85120649661,"The technological leaps of artificial intelligence (AI) and the rise of machine learning have triggered significant progress in a plethora of natural language processing (NLP) and natural language understanding tasks. One of these tasks is argumentation mining which has received significant interest in recent years and is regarded as a key domain for future decision-making systems, behaviour modelling, and natural language understanding problems. Until recently, natural language modelling tasks, such as computational argumentation schemes, were often tested in controlled environments, such as persuasive essays, reducing unexpected behaviours that could occur in real-life settings, like a public debate on social media. Additionally, the growing demand for enhancing the trust and the explainability of the AI services has dictated the design and adoption of modelling schemes to increase the confidence in the outcomes of the AI solutions. This paper attempts to explore modelling argumentation in short text and proposes a novel framework for argumentation detection under the name Abstract Framework for Argumentation Detection (AFAD). Moreover, different proof-of-concept implementations are provided to examine the applicability of the proposed framework to very short text developing a rule-based mechanism and compare the results with data-driven solutions. Eventually, a combination of the deployed methods is applied increasing the correct predictions in the minority class on an imbalanced dataset. The findings suggest that the modelling process provides solid grounds for technical research while the hybrid solutions have the potential to be applied to a wide range of NLP-related tasks offering a deeper understanding of human language and reasoning.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.apenergy.2021.118085,Journal,Applied Energy,scopus,2022-02-01,sciencedirect,Ship energy management system development and experimental evaluation utilizing marine loading cycles based on machine learning techniques,https://api.elsevier.com/content/abstract/scopus_id/85120648001,"In order to develop energy management systems for hybrid ship propulsion plants that are truly optimal and robust, it is important that the test conditions in experimental facilities are as close as possible to real world applications. In this context, a framework for the design and experimental evaluation of power-split control systems for ship propulsion is proposed. Using machine learning, data from ship operation are processed and 20 loading patterns are recognized; representative templates are extracted to be used as marine loading cycles in the energy management system development and testing. A ship propulsion model with wave disturbance is utilized to simulate realistic loading scenarios on the experimental facility. A predictive energy management system is presented, that controls the diesel engine and the electric motor/generator based on a strategy that defines the trade-off between fuel consumption and NOx emissions minimization. In addition the propeller load characteristics that are estimated and a speed predictor are utilized to aid the optimization within the 10 s prediction time window. A parametric simulation study is performed for the trade-off evaluation between fuel consumption and NOx emissions reduction potential of the control scheme. Finally, utilizing an extracted loading cycle, the energy management system is experimentally implemented and tested in real-time operation, where it has to cope with environmental disturbance rejection and follow the desired speed profile while performing the power-split control in respect to the fuel to NOx weighting strategy. Based on the experimental results in a hybrid diesel–electric marine powertrain with a 260 kW diesel engine and a 90 kW electric machine, fuel consumption and NOx emissions reduction by 6% and 8.5% respectively, were achieved over the tested profile. In this framework, the capabilities of the energy management system in realistic operation conditions can be exploited and evaluated.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rse.2021.112809,Journal,Remote Sensing of Environment,scopus,2022-02-01,sciencedirect,MethaNet – An AI-driven approach to quantifying methane point-source emission from high-resolution 2-D plume imagery,https://api.elsevier.com/content/abstract/scopus_id/85120521703,"Methane is one of the most important anthropogenic greenhouse gases with a significant impact on the Earth's radiation budget and tropospheric background ozone. Despite a well-constrained global budget, quantification of local and regional methane emissions has proven challenging. Recent advancements in airborne remote sensing instruments such as from the next-generation Airborne Visible/Infrared Imaging Spectrometer (AVIRIS-NG) provide 2-D observations of CH4 plume column enhancements at an unprecedented resolution of 1–5 m over large geographic areas. Quantifying an emission rate from observed plumes is a critical step for understanding local emission distributions and prioritizing mitigation efforts. However, there exists no method that can predict emission rates from detected plumes in real-time without ancillary data reliably. In order to predict methane point-source emissions directly from high resolution 2-D plume images without relying on other local measurements such as background wind speeds, we trained a convolutional neural network model called MethaNet. The training data was derived from large eddy simulations of methane plumes and realistic measurement noise over agricultural, desert and urban environments. Our model has a mean absolute percentage error for predicting unseen plumes under 17%, a significant improvement from previous methods that require wind information. Using MethaNet, a validation against a natural gas controlled-release experiment agrees to within the precision error estimate. Our results support the basis for the applicability of using deep learning techniques to quantify CH4 point sources in an automated manner over large geographical areas, not only for present and future airborne field campaigns but also for upcoming space-based observations in this decade.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cose.2021.102547,Journal,Computers and Security,scopus,2022-02-01,sciencedirect,Jadeite: A novel image-behavior-based approach for Java malware detection using deep learning,https://api.elsevier.com/content/abstract/scopus_id/85120335865,"Java malware exploiting language vulnerabilities has become increasingly prevalent in the recent past. Since Java is a platform-independent language, these security threats open up the opportunity for multi-platform exploitation. Although security researchers continuously develop different approaches for protecting against Java malware programs, the presence of complicated Java malware properties, such as code obfuscation, makes these malware programs fly under the radar. These challenges present the need to develop new approaches that are resilient to such properties. This article presents Jadeite, a novel approach for detecting Java bytecode malware programs using static analysis and recent advancements in the image-based, deep-learning classification space. In particular, Jadeite extracts the Interprocedural Control Flow Graph (ICFG) from a given Java bytecode file and then prunes the ICFG and converts it into an adjacency matrix. Finally, Jadeite constructs a grayscale image from this matrix. We leverage an object detection algorithm in a deep Convolutional Neural Network (CNN) classifier to determine maliciousness. Also, Jadeite extracts an additional set of features from the Java malware program to improve the accuracy of malware classification. These features are consolidated with the extracted images and used as inputs to the CNN classifier. Experimental results demonstrate that Jadeite achieves high accuracy (98.4%) compared to other Java malware detection approaches and is capable of detecting both known and previously-unseen real-world malicious Java programs.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scs.2021.103559,Journal,Sustainable Cities and Society,scopus,2022-02-01,sciencedirect,Assessment of sustainable development objectives in Smart Labs: technology and sustainability at the service of society,https://api.elsevier.com/content/abstract/scopus_id/85120052266,"Sustainable development is the working basis of engineering research and cities are becoming increasingly flexible, inclusive and intelligent. In this context, there is a need for environments that emulate real-life spaces in which cutting-edge technologies can be implemented for subsequent deployment in society. Smart Labs or Living Labs are spaces for innovation, research and experimentation that integrate systems, devices and methodologies focused on people and their environments. The technologies studied and developed in such labs can then be deployed in human spaces to provide intelligence, comfort, health and sustainability. Health and wellness, energy and environment, artificial intelligence, big data and digital rights are some of the disciplines being studied. At the same time, the UN 2030 Agenda provides a comprehensive framework to promote human well-being through the Sustainable Development Goals. In this work, an evaluation model of its indicators in smart environments is performed through a mixed review methodology. The objective of this work is the analysis and implementation of the SDGs in Smart Labs through a literature review and a case study of UJAmI, the smart laboratory of the University of Jaén. The results provide quantitative and qualitative data on the present and future of the smart devices implemented in the UJAmI lab, providing a roadmap for future developments.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jwpe.2021.102452,Journal,Journal of Water Process Engineering,scopus,2022-02-01,sciencedirect,Polyamine-modified polyacrylonitrile fibers for efficient removal of U(VI) from real fluorine-contained low-level radioactive wastewater,https://api.elsevier.com/content/abstract/scopus_id/85119972768,"It is of great significance to develop an adsorbent with high adsorption capacity and excellent resistance to anion and cation interference toward the removal of U(VI). Herein, a novel polyamine-modified polyacrylonitrile-based fiber (PANPA) has been synthesized through hydrothermal method, which can validly remove U(VI) from solution. Combined with mesoscopic, spectral characterization and simulation method, the removal behavior and mechanism of U(VI) from high fluorine uranium-containing wastewater by PANPA are systematically investigated. The results show that, based on the strong coordination principle of polyamine group and UO2
                     2+, PANPA can selectively remove U(VI) from wastewater. In addition, the q
                     
                        max
                      of 459.27 mg g−1 was more than that of many other adsorbent materials. More importantly, PANPA is not affected by high concentration of F−, and exhibits higher distribution coefficient (559,900 mL g−1) and removal efficiency (99.5%) to U(VI) than other coexisting ions in real wastewater. Furthermore, the column experiment was also implemented to remove U(VI). The results indicate that PANPA is a promising material to effectively remove U(VI) from real wastewater produced during the fabrication of nuclear fuel elements.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.inffus.2021.09.004,Journal,Information Fusion,scopus,2022-02-01,sciencedirect,Multimodal Earth observation data fusion: Graph-based approach in shared latent space,https://api.elsevier.com/content/abstract/scopus_id/85115401406,"Multiple and heterogenous Earth observation (EO) platforms are broadly used for a wide array of applications, and the integration of these diverse modalities facilitates better extraction of information than using them individually. The detection capability of the multispectral unmanned aerial vehicle (UAV) and satellite imagery can be significantly improved by fusing with ground hyperspectral data. However, variability in spatial and spectral resolution can affect the efficiency of such dataset's fusion. In this study, to address the modality bias, the input data was projected to a shared latent space using cross-modal generative approaches or guided unsupervised transformation. The proposed adversarial networks and variational encoder-based strategies used bi-directional transformations to model the cross-domain correlation without using cross-domain correspondence. It may be noted that an interpolation-based convolution was adopted instead of the normal convolution for learning the features of the point spectral data (ground spectra). The proposed generative adversarial network-based approach employed dynamic time wrapping based layers along with a cyclic consistency constraint to use the minimal number of unlabeled samples, having cross-domain correlation, to compute a cross-modal generative latent space. The proposed variational encoder-based transformation also addressed the cross-modal resolution differences and limited availability of cross-domain samples by using a mixture of expert-based strategy, cross-domain constraints, and adversarial learning. In addition, the latent space was modelled to be composed of modality independent and modality dependent spaces, thereby further reducing the requirement of training samples and addressing the cross-modality biases. An unsupervised covariance guided transformation was also proposed to transform the labelled samples without using cross-domain correlation prior. The proposed latent space transformation approaches resolved the requirement of cross-domain samples which has been a critical issue with the fusion of multi-modal Earth observation data. This study also proposed a latent graph generation and graph convolutional approach to predict the labels resolving the domain discrepancy and cross-modality biases. Based on the experiments over different standard benchmark airborne datasets and real-world UAV datasets, the developed approaches outperformed the prominent hyperspectral panchromatic sharpening, image fusion, and domain adaptation approaches. By using specific constraints and regularizations, the network developed was less sensitive to network parameters, unlike in similar implementations. The proposed approach illustrated improved generalizability in comparison with the prominent existing approaches. In addition to the fusion-based classification of the multispectral and hyperspectral datasets, the proposed approach was extended to the classification of hyperspectral airborne datasets where the latent graph generation and convolution were employed to resolve the domain bias with a small number of training samples. Overall, the developed transformations and architectures will be useful for the semantic interpretation and analysis of multimodal data and are applicable to signal processing, manifold learning, video analysis, data mining, and time series analysis, to name a few.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.comcom.2021.10.037,Journal,Computer Communications,scopus,2022-01-15,sciencedirect,SAAS parallel task scheduling based on cloud service flow load algorithm,https://api.elsevier.com/content/abstract/scopus_id/85120359168,"In cloud platform applications, the user’s goal is to obtain high-quality application services, while the service provider’s goal is to obtain revenue by performing the tasks submitted by the user. The platform built by the service provider’s application resources needs to improve the mapping between service requests and resources to achieve higher value. Through the current situation of resource management in the cloud environment, it is found that many task scheduling and resource allocation algorithms are still affected by factors such as the diversity, dynamics, and multiple constraints of resources and tasks. This paper focuses on Software as a Service (SaaS) applications’ task scheduling and resource configuration in a dynamic and uncertain cloud environment. It is a challenging online scheduling problem to automatically and intelligently allocate user task requests that continually reach SaaS applications to appropriate resources for execution. To this end, a real-time task scheduling method based on deep reinforcement learning is proposed, which automatically and intelligently allocates user task requests that continually reach SaaS applications to appropriate resources for execution. In this way, the limited virtual machine resources rented by SaaS providers can be used in a balanced and efficient manner. In the experiment, by comparing with other five task scheduling algorithms, it is proved that the algorithm proposed in this paper not only improves the execution efficiency of better deploying workflow in IaaS public cloud, but also makes the resources provided by SaaS are used in a balanced and efficient manner.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.apacoust.2021.108439,Journal,Applied Acoustics,scopus,2022-01-15,sciencedirect,"CAMNet: A controllable acoustic model for efficient, expressive, high-quality text-to-speech",https://api.elsevier.com/content/abstract/scopus_id/85116891718,"Spoken language is becoming one of the key components of human–machine interaction, both to send information to the machine – e.g. voice control – and to receive from it – e.g. virtual assistants. In this scenario, text-to-speech (TTS) models have become an essential artificial intelligence capacity. Even though this interaction can be based on neutral style speech, generating speech with different styles, pitches and speaking rates may improve user experience. With this in view, this paper presents CAMNet, a controllable acoustic model for efficient, expressive, high-quality TTS. CAMNet is based on deep convolutional TTS (DCTTS), a state-of-art acoustic model which is efficient and produces neutral speech. DCTTS was first adapted to generate Bark cepstrum acoustic features in order to integrate well with the LPCNet (linear prediction coefficient) neural vocoder and to remove the reduction factor which demanded the presence of an upsampling network before the vocoder – i.e. the CAMNet output can be directly fed into LPCNet. Next, style transfer functionality was added by means of a novel characterisation of the prosodic information from the Bark cepstrum acoustic features and a new approach to inject this information into the convolutional layers. Finally, controllability is provided via a variational auto-encoder module which creates a smoothed disentangled latent space which allows interpolation and extrapolation of reference styles as well as independent and simultaneous control of two generative factors: pitch and speaking rate. Moreover, this controllability is implemented using a simple offset-based approach. To sum up, CAMNet is an efficient acoustic model which provides a simple but consistent controllability on coarse-grained expression, pitch and speaking rate while still providing high-quality synthesised speech.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.saa.2021.120347,Journal,Spectrochimica Acta - Part A: Molecular and Biomolecular Spectroscopy,scopus,2022-01-15,sciencedirect,Rapid discrimination of Curcuma longa and Curcuma xanthorrhiza using Direct Analysis in Real Time Mass Spectrometry and Near Infrared Spectroscopy,https://api.elsevier.com/content/abstract/scopus_id/85115004546,"This study describes a newly developed method for the fast and straightforward differentiation of two turmeric species using Direct Analysis in Real Time mass spectrometry and miniaturized Near Infrared spectroscopy. Multivariate analyses (PCA and LDA) were performed on the mass spectrometric data, thus creating a powerful model for the discrimination of Curcumalonga and Curcumaxanthorrhiza. Cross-validation of the model revealed correctness-scores of 100% with 20-fold as well as leave-one-out validation techniques. To further estimate the models prediction power, seven retail samples of turmeric powder were analyzed and assorted to a species. Looking for a fast, non-invasive, cost-efficient and laboratory independent method, miniaturized NIR spectrometers offer an alternative for quality control of turmeric species. However, different technologies implemented to compensate for their small size, lead to different applicability of these spectrometers. Therefore, we investigated the three handheld spectrometers microPHAZIR, MicroNIR 2200 and MicroNIR 1700ES for their application in spice analysis in hyphenation to PCA, LDA and ANN methods used for the discriminant analysis. While microPHAZIR proved to be the most valuable device for differentiating C.longa and C.xanthorrhiza, MicroNIR 1700ES offered the worst results. These findings are interpreted on the basis of a quantum chemical simulation of the NIR spectrum of curcumin as the representative constituent. It was found that the information accessible to MicroNIR 1700ES that is relevant to the analyzed constituents is located in the spectral region prone to interferences with the matrix, likely limiting the performance of this spectrometer in this analytical scenario.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2021.10.004,Journal,Neurocomputing,scopus,2022-01-11,sciencedirect,A CNN-based policy for optimizing continuous action control by learning state sequences,https://api.elsevier.com/content/abstract/scopus_id/85118138176,"Continuous action control is widespread in real-world applications. It controls an agent to take action in continuous space for transiting from one state to another until achieving the desired goal. The optimization of continuous action control is an important issue, which aims to find the optimal policy for the agent to achieve the desired goal with the lowest consumption in continuous action space. A useful tool for this issue is reinforcement learning where an optimal policy is learned for the agent by maximizing the cumulative reward of the state transitions. When updating the policy at each state, most existing reinforcement learning methods consider only the one-step transition of this state. However, for each state in continuous action control, the recognizable information is usually hidden in the sequence of its previous states, thus these methods cannot learn the policy effectively enough for continuous action control. In this paper, we propose a new policy, called convolutional deterministic policy, to solve this problem. Enlightened from the convolutional neural networks used in natural language processing, our convolutional deterministic policy uses convolutional neural networks to learn the recognizable information in the state sequences. Then for each collected state, we update the convolutional deterministic policy by not only the recognizable information in the one-step transition of this state but also the recognizable information in the sequence of its previous states. As a result, our convolutional deterministic policy can make the agent take better action. Based on an effective reinforcement learning method, TD3, the implementation of our convolutional deterministic policy is in CTD3. The theoretical analysis and the experiment illustrate that our CTD3 can learn the policy not only better than but also faster than the existing RL methods for continuous action control. The source code can be downloaded from https://github.com/grcai.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2021.107624,Journal,Knowledge-Based Systems,scopus,2022-01-10,sciencedirect,Manifold-based aggregation clustering for unsupervised vehicle re-identification,https://api.elsevier.com/content/abstract/scopus_id/85118363031,"Most vehicle re-identification (V-reID) approaches are based on supervised learning methods which require a considerable amount of tedious and impractical annotations. In this paper, we propose a novel unsupervised V-reID approach based on Manifold-based Aggregation Clustering (MAC) with the unknown number of clusters. The proposed MAC is implemented by alternatively conducting two modules, i.e., deep feature learning module and aggregation clustering module. Specifically, deep feature learning module is responsible for training a convolutional neural network to encourage deep features to be close to the centroids of corresponding clusters which are yielded by an aggregation clustering mechanism based on manifold distance in the feature space. Moreover, the classification-agglomeration loss and manifold-based seeds searching criterion are proposed to improve the discriminative power of the learned features and deal with the problem of varied visual appearance respectively. Note that both annotations and even the certain number of vehicle identities are unknown for the proposed method, which is totally consistent with the real-world unsupervised V-reID condition. Extensive experiments on VehicleID and Veri-776 benchmark datasets show that the proposed method outperforms the state-of-the-art unsupervised V-reID approaches.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.matpr.2020.12.864,Journal,Materials Today: Proceedings,scopus,2022-01-01,sciencedirect,Real time analysis of unmask face detection in human skin using tensor flow package and IoT algorithm,https://api.elsevier.com/content/abstract/scopus_id/85132649170,"In covid19, security provided by Indian government, due to severe virus speed to sudden death. This proposed method solved face detection, mask detection and thermal value monitoring for security purpose. We need amount of testing and need tests 50000/day to measure count of infection. Government produces a report that maintain social distancing, wearing mask when in outside and proper testing. Most people do not serious to wearing mask. We focused the counting of Unmask-persons using opencv and MTCNN algorithm. Faces conditions are changing due to various atmospheric season and light vision. The MTCNN algorithm adjusted video streaming data with Mask detection accuracy at >90%. A database stored in Excel file or send Emergency message to email or buzzer kept on, when unmask visit at any places like that shopping complex, hotel, hospital, Traffic areas and temple. MTCNN- Multi-Task Convolutional Neural Network algorithm solved facial recognition problems. We have proposed the algorithm for Mask detection and Thermals value detection using Pycharm-python and implemented in Raspberry pi4. Support Vector Machine (SVM) supported tasks of MTCNN and stored in database. The outcome of the system is Alert through monitor and SMS to officials Government persons, when capturing unmasked persons visit in live streaming video using Opencv – Python.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.matpr.2021.04.011,Journal,Materials Today: Proceedings,scopus,2022-01-01,sciencedirect,Analysis and fast feature selection technique for real-time face detection materials using modified region optimized convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85132612708,"For face-related applications like face recognition and face verification, face detection is vital. Law enforcement agencies extensively use face recognition applications for the detection of known offenders. Security cameras are increasingly deployed everywhere, and these cameras’ captured data can be used for tagging offenders. This is done by offering the face detection system with input images, which are then processed. Later on, attempts will be done to tag the security cameras’ captured data with this processed input data. Effective utilization of deep learning techniques in order to efficiently carry out this task. Computer vision’s various tasks have been taken over by deep Convolutional Neural Networks (CNNs). Of late, the key paradigms for face detection are the region-based CNN (R-CNN) detection models due to their quicker processing speed and progressively better performance. Nevertheless, the huge feature set causes these models’ to be inefficient for real-time face detection. A Grammatical Evolution (GE) Region-Based Fully Conventional Neural Network (R-FCN) for face detection has been proposed in this work in which the GE heuristics are utilized for tuning the hyper-parameters. The WIDER face dataset and Face Detection Dataset and Benchmark (FDDB) dataset were employed for conducting the assessments. In comparison to other advanced paradigms, the proposed technique’s superiority is evident from the experiments conducted.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.matpr.2022.04.388,Journal,Materials Today: Proceedings,scopus,2022-01-01,sciencedirect,"Evaluation of strain measurements using ZnS: Mn, Cu as mechanoluminescent material and strain gauge sensor",https://api.elsevier.com/content/abstract/scopus_id/85132601395,"Structural health monitoring (SHM) is emerging as a significant aspect in structural engineering. Predominantly, civil engineering structures have become more reliant on SHM. Advanced sensors and smart materials are the prominent technologies for applying Structural Health Monitoring. Numerous techniques for damage detection of the structures in the field of civil engineering. In this paper, we have introduced innovative smart material, Mechanoluminescent material that enables real-time continuous monitoring and damage detection of the structures. The most prominent ML (Mechanoluminescent material) Mn (Manganese) or Cu (Copper) doped ZnS (Zinc sulphide) crystal is studied because they exhibit the brightest luminescent emission. The present investigation aims to evaluate the strain measurements using ML material and compare the readings with the strain gauge sensor obtained in the Arduino Integrated Development Environment Software (IDE). An experimental approach has been done to produce ML material and to understand the fundamental ML phenomenon. At present, many researchers have developed ML material for the implementation to real-social infrastructure. If success leads the ML material will be a new step for development of modified sensor channel that could monitor a structure for actual impacts with the existence of stress levels acting on it.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2022.03.068,Conference Proceeding,Procedia Computer Science,scopus,2022-01-01,sciencedirect,The Security Concerns on Cyber-Physical Systems and Potential Risks Analysis Using Machine Learning,https://api.elsevier.com/content/abstract/scopus_id/85132207250,"The use of engineering to drive down costs and improve productivity has been an ongoing business exercise since the first Industrial Revolution. The term Cyber-Physical System is a wide range of different computing technologies embedded with the next-generation engineered systems into the physical world. Connected Cyber-Physical Systems (CPS) improve the lives of people and increase industry and manufacturing efficiency. It is affecting many branches of life such as transportation, healthcare and medicine, the environment, and energy. Industry 4.0 integrates humans, machines, and data to provide a holistic and interlinked approach to manufacturing, hence, increasing privacy concerns. For example, Autonomous Vehicles (AV) can be driven without a pilot and those systems can be hacked if there is a breach in the system. Nowadays, most of the systems are interconnected to the internet and nothing can be considered fully safe. Therefore, with this increase of security threats and privacy concerns, there is a need to assess and evaluate the trade-off between enhancements and improvements in manufacturing and the possible threats and security risks in the context of Cyber-Physical Systems. We need to bridge the gaps and overcome some of these limitations. In this work, we studied the security concerns emerging from interconnected Cyber-Physical systems, devices, and services in Industry 4.0. To identify security vulnerabilities, we have chosen the energy dataset because energy is the key point of every Cyber-Physical system so aimed to show the importance of energy, and the K-Means algorithm implemented which is an advanced Machine Learning and potential risks detected.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2022.01.388,Conference Proceeding,Procedia Computer Science,scopus,2022-01-01,sciencedirect,Real-time Detection of Worker's Emotions for Advanced Human-Robot Interaction during Collaborative Tasks in Smart Factories,https://api.elsevier.com/content/abstract/scopus_id/85127826978,"Human-robot collaboration (HRC) has become increasingly popular in modern assembly systems because of the flexibility of human capabilities and the precision and efficiency of the fellow robot. However, previous research has identified challenges to achieve a genuine and natural human-robot interaction, one being the real-time robot behavior adaptation depending on the worker’s emotions revealed by facial or body signals. Human emotional state recognition has been widely explored in the fields of human–machine interaction and affective computing, but a practical implementation of the technology in real-time during a collaborative task hides complexities and challenges. In this paper, the authors tested and compared twelve different models, all based on Deep Learning and Convolutional Neural Networks (CNN), to recognize emotions using the datasets CK+ and Fer2013. DeepFace algorithm resulted to be the most accurate and was further tested on real subjects in working and industry-like contexts to determine the actual validity and necessary modifications for a possible large-scale industrial application. A discussion about all the main challenges to face for a practical application of this technology on field is presented.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/bs.adcom.2022.02.001,Book Series,Advances in Computers,scopus,2022-01-01,sciencedirect,Exploring the edge AI space: The industry use cases,https://api.elsevier.com/content/abstract/scopus_id/85127675740,"Now, edge devices, through a plethora of technological innovations and disruptions, are being stuffed with more memory, storage and networking capacities and processing capability. Thereby, edge devices are joining in mainstream computing. That is, the centralized and consolidated computing moves over to edge devices to be decentralized and disaggregated. AI libraries are being deployed in IoT edge devices to do proximate and real-time data processing. This is termed as on-device intelligence. Such a strategically sound shift is to bring forth a dazzling array of advancements and automations not only for business houses but also for common people in their everyday assignments. This chapter is to throw some light on the theoretical and the practical aspect of the edge AI paradigm.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2022.02.192,Conference Proceeding,Procedia CIRP,scopus,2022-01-01,sciencedirect,An IIoT approach for edge intelligence in production environments using machine learning and knowledge graphs,https://api.elsevier.com/content/abstract/scopus_id/85127513501,"The mining industries need novel solutions to reduce production stoppages. Predictive maintenance solutions and especially the hardware components, cannot operate properly under such harsh conditions, as high concentration of dust and other chemical material may lead into fault sensor measurements. This study presents a solution for condition monitoring and predictive maintenance and productions status monitoring for assets operating in harsh operating environments. First, an edge device is connected to multiple sensors monitoring critical parameters related to the operating conditions of an asset. In particular, the device is in charge of data collection, filtering and smart data generation for further analysis and processing. At a later stage, the collected data are pushed to a cloud platform where predictive analytics, as well as production status analytics, are estimated. The condition monitoring and predictive maintenance component utilizes machine learning in order to estimate the Remaining Useful Life of the monitored asset(s). The production status component utilizes knowledge graphs that are populated with data provided by the edge device. The combination of these two components aims to provide meaningful insight to field personnel supporting them in decision making and production supervision. A prototype IIoT system has been implemented and tested in a use case related to an aluminium producing company with its results demonstrating the applicability of the proposed solutions for real-world application.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.disamonth.2022.101351,Journal,Disease-a-Month,scopus,2022-01-01,sciencedirect,CC group of chemokines and associated gene expression of transcription factors: Deciphering immuno-pathogenetic aspect of oral submucous fibrosis,https://api.elsevier.com/content/abstract/scopus_id/85127325566,"Background
                  Oral submucous fibrosis (OSMF) is a chronic disease with significantly increasing malignant transformation rate. To date the pathogenesis of OSMF has been considered to be associated with areca nut constituents and their action on fibroblasts. However, fibrosis is also associated with immunological factors such as chemokines. In-depth analysis of such factors is the need of the hour in OSMF to better understand the pathogenesis so that effective therapeutic strategies can be developed in the future.
               
                  Materials and method
                  Clinically diagnosed cases of OSMF (n=21) and healthy individuals (n=10) were enrolled in the present study. Chemokines such as CCL2, CCL3, CCL4, CCL5, CCL11, CCL17, CCL28, CXCL1, CXCL5, CXCL8, CXCL9, CXCL10, and CXCL11 were assessed using the chemokine bead array in conjunction with the flow cytometry, along with real-time PCR (RT-PCR). The transcription factors CREB, NF-κB and NFAT5 were also studied for their expressions. The analysis of pg/ml (picogram/milliliter) values was done by using LEGENDplex™ Data Analysis Software.
               
                  Results
                  The results obtained demonstrated early phase transient increase in CXCL-11, CCL20, CXCL9, CCL3, CCL2, CXCL10 and CXCL8. However, the expression of CCL3, CXCL10 and CXCL8 was higher in the late stage as compared to the early stage. The relative gene expression of CREB, NF-κB, NFAT5 were upregulated in the late stage of OSMF when compared to normal.
               
                  Conclusion
                  Distinctive sets of chemokine expression during the early and late stages of OSMF suggest a unique pattern of disease progression playing an important role in the pathogenesis.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neurenf.2022.02.005,Journal,Neuropsychiatrie de l'Enfance et de l'Adolescence,scopus,2022-01-01,sciencedirect,Autism as a neurodevelopmental consciousness disorder according to the Internal structure of autistic thought hypothesis (FISPA),https://api.elsevier.com/content/abstract/scopus_id/85126268537,"L’hypothèse du Fonctionnement interne de la structure de pensée autistique (FISPA) propose une interprétation théorique unifiante de la condition de l’autisme, qui résulterait essentiellement de l’altération précoce du développement neurologique de la conscience. Ainsi, la condition de l’autisme serait associée à un déficit persistant dans la capacité à traiter les informations de façon consciente et intégrée. L’hypothèse du FISPA fut élaborée à partir de l’expertise expérientielle d’une personne autiste, Brigitte Harrisson et d’observations cliniques faites auprès de personnes autistes. Dans cet article, l’hypothèse sera décrite et étayée en s’appuyant sur des recherches en neurosciences et en sciences cognitives. Le présent article aborde les répercussions des atypies de la connectivité fonctionnelle chez les personnes autistes sur le développement de systèmes neuronaux fonctionnels et intégrateurs, soit l’espace de travail neuronal global et le réseau par défaut. Ces irrégularités affecteraient la capacité à traiter de façon consciente et intégrée les informations provenant de soi et de l’environnement, et ce, dès la naissance. L’hypothèse du FISPA soutient qu’une cascade développementale s’ensuivrait, laquelle aurait des répercussions sur la perception ainsi que sur la conceptualisation du corps et des émotions. Il est avancé dans le présent article qu’afin de compenser ce trouble du développement de la conscience et d’avoir accès à soi en temps direct, la personne autiste pourrait devoir déployer des efforts cognitifs continus et parfois présenter certains mouvements répétitifs. La variabilité des manifestations autistiques apparentes, telles que les mouvements stéréotypés, pourrait être liée au niveau de développement de la conscience de chaque personne autiste. L’hypothèse présentée dans le présent article permet donc une compréhension de l’évolution typique des manifestations autistiques.
               
                  The Internal Structure of Autistic Thought hypothesis (referred to throughout this article as the FISPA hypothesis, FISPA being the French acronym for Fonctionnement interne de la structure de pensée autistique) proposes a unifying theoretical interpretation of the condition of autism resulting from the early alteration of the neurological development of consciousness. The condition of autism, therefore, could be associated with a persistent deficit in the ability to process information in a conscious and integrated way. The FISPA hypothesis was developed from the experiential expertise of an autistic person, Brigitte Harrisson, as well as from clinical observations made with autistic people. In this article, the hypothesis will be described and supported by research in neuroscience and cognitive science. This article discusses the impact of functional connectivity atypias in people with autism on the development of functional and integrative neural systems, namely the global neuronal workspace and the default mode network. These irregularities may affect, from birth, a person's ability to process information about themselves and their environment in a conscious and integrated manner. The FISPA hypothesis holds that a developmental cascade would ensue, which would have repercussions on perception as well as on the conceptualization of both the body and emotions. This article argues that in order to compensate for this disorder of the development of consciousness and in order to have access to themselves in real time, an individual with autism may be required to deploy continuous cognitive efforts and therefore may occasionally present certain repetitive movements. The variability of these apparent autistic manifestations, such as stereotypical movements, could be related to the level of development of consciousness of each autistic person. The hypothesis presented in this article therefore allows an understanding of the typical evolution of autistic manifestations.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.fmre.2021.12.005,Journal,Fundamental Research,scopus,2022-01-01,sciencedirect,AI-aided on-chip nucleic acid assay for smart diagnosis of infectious disease,https://api.elsevier.com/content/abstract/scopus_id/85122505591,"Global pandemics such as COVID-19 have resulted in significant global social and economic disruption. Although polymerase chain reaction (PCR) is recommended as the standard test for identifying the SARS-CoV-2, conventional assays are time-consuming. In parallel, although artificial intelligence (AI) has been employed to contain the disease, the implementation of AI in PCR analytics, which may enhance the cognition of diagnostics, is quite rare. The information that the amplification curve reveals can reflect the dynamics of reactions. Here, we present a novel AI-aided on-chip approach by integrating deep learning with microfluidic paper-based analytical devices (µPADs) to detect synthetic RNA templates of the SARS-CoV-2 ORF1ab gene. The µPADs feature a multilayer structure by which the devices are compatible with conventional PCR instruments. During analysis, real-time PCR data were synchronously fed to three unsupervised learning models with deep neural networks, including RNN, LSTM, and GRU. Of these, the GRU is found to be most effective and accurate. Based on the experimentally obtained datasets, qualitative forecasting can be made as early as 13 cycles, which significantly enhances the efficiency of the PCR tests by 67.5% (∼40 min). Also, an accurate prediction of the end-point value of PCR curves can be obtained by GRU around 20 cycles. To further improve PCR testing efficiency, we also propose AI-aided dynamic evaluation criteria for determining critical cycle numbers, which enables real-time quantitative analysis of PCR tests. The presented approach is the first to integrate AI for on-chip PCR data analysis. It is capable of forecasting the final output and the trend of qPCR in addition to the conventional end-point Cq calculation. It is also capable of fully exploring the dynamics and intrinsic features of each reaction. This work leverages methodologies from diverse disciplines to provide perspectives and insights beyond the scope of a single scientific field. It is universally applicable and can be extended to multiple areas of fundamental research.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ebiom.2021.103774,Journal,eBioMedicine,scopus,2022-01-01,sciencedirect,Accuracy and ease-of-use of seven point-of-care SARS-CoV-2 antigen-detecting tests: A multi-centre clinical evaluation,https://api.elsevier.com/content/abstract/scopus_id/85121647709,"Background
                  Antigen-detecting rapid diagnostic tests (Ag-RDTs) for SARS-CoV-2 are important diagnostic tools. We assessed clinical performance and ease-of-use of seven Ag-RDTs in a prospective, manufacturer-independent, multi-centre cross-sectional diagnostic accuracy study to inform global decision makers.
               
                  Methods
                  Unvaccinated participants suspected of a first SARS-CoV-2 infection were recruited at six sites (Germany, Brazil). Ag-RDTs were evaluated sequentially, with collection of paired swabs for routine reverse transcription polymerase chain reaction (RT-PCR) testing and Ag-RDT testing. Performance was compared to RT-PCR overall and in sub-group analyses (viral load, symptoms, symptoms duration). To understandusability a System Usability Scale (SUS) questionnaire and ease-of-use (EoU) assessment were performed.
               
                  Findings
                  7471 participants were included in the analysis. Sensitivities across Ag-RDTs ranged from 70·4%-90·1%, specificities were above 97·2% for all Ag-RDTs but one (93·1%).Ag-RDTs, Mologic, Bionote, Standard Q, showed diagnostic accuracy in line with WHO targets (> 80% sensitivity, > 97% specificity). All tests showed high sensitivity in the first three days after symptom onset (≥87·1%) and in individuals with viral loads≥ 6 log10SARS-CoV2 RNA copies/mL (≥ 88·7%). Usability varied, with Rapigen, Bionote and Standard Q reaching very good scores; 90, 88 and 84/100, respectively.
               
                  Interpretation
                  Variability in test performance is partially explained by variable viral loads in population evaluated over the course of the pandemic. All Ag-RDTs reach high sensitivity early in the disease and in individuals with high viral loads, supporting their role in identifying transmission relevant infections. For easy-to-use tests, performance shown will likely be maintained in routine implementation.
               
                  Funding
                  Ministry of Science, Research and Arts, State of Baden-Wuerttemberg, Germany, internal funds from Heidelberg University Hospital, University Hospital Charité − Universitätsmedizin Berlin, UK Department of International Development, WHO, Unitaid.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ergon.2021.103234,Journal,International Journal of Industrial Ergonomics,scopus,2022-01-01,sciencedirect,Industrial intelligence in the care of workers’ mental health: A review of status and challenges,https://api.elsevier.com/content/abstract/scopus_id/85120173556,"Mental health is a current concern because people worldwide have been committed to disorders that impair lives as a whole, affecting emotional states, behaviors, and body responses. These disorders decrease worker's productivity, impact industries economically, and cause serious psycho-physical conditions. However, technological advances have leveraged the industry to a novel phase where digitalization and automation provide a new reality. Hence, this industrial transformation may contribute to assists human beings in the workplace with a focus on mental health. This article presents a systematic literature review to investigate studies regarding technologies employed in the care of worker's mental health and the industrial role in this scenario. Three general, three focused, and three descriptive questions highlight the academic progress of industrial concern on mental health, implemented systems and cases, and research challenges. As a result, the review discussed 31 studies, extracted from an initial corpus of 25269, ranging from January 2010 to November 2020. The studies approached stress as the most frequent mental issue in the industry and Support Vector Machine (SVM) as the most used machine learning algorithm, where biomarkers presented the primary data extractors to deal with this theme. Moreover, information fusion methods improved the accuracy of specific cases. However, a growing interest in mental health care has emerged only in recent years, and several challenges require efforts before applying systems in real industrial environments.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2021.104514,Journal,Engineering Applications of Artificial Intelligence,scopus,2022-01-01,sciencedirect,Instance-based defense against adversarial attacks in Deep Reinforcement Learning,https://api.elsevier.com/content/abstract/scopus_id/85118104144,"Deep Reinforcement Learning systems are now a hot topic in Machine Learning for their effectiveness in many complex tasks, but their application in safety-critical domains (e.g., robot control or self-autonomous driving) remains dangerous without mechanism to detect and prevent risk situations. In Deep RL, such risk is mostly in the form of adversarial attacks, which introduce small perturbations to sensor inputs with the aim of changing the network-based decisions and thus cause catastrophic situations. In the light of these dangers, a promising line of research is that of providing these Deep RL algorithms with suitable defenses, especially when deploying in real environments. This paper suggests that this line of research could be greatly improved by the concepts from the existing research field of Safe Reinforcement Learning, which has been postulated as a family of RL algorithms capable of providing defenses against many forms of risks. However, the connections between Safe RL and the design of defenses against adversarial attacks in Deep RL remain largely unexplored. This paper seeks to explore precisely some of these connections. In particular, this paper proposes to reuse some of the concepts from existing Safe RL algorithms to create a novel and effective instance-based defense for the deployment stage of Deep RL policies. The proposed algorithm uses a risk function based on how far a state is from the state space known by the agent, that allows identifying and preventing adversarial situations. The success of the proposed defense has been evaluated in 4 Atari games.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bspc.2021.103245,Journal,Biomedical Signal Processing and Control,scopus,2022-01-01,sciencedirect,Prototype design for bidirectional control of stepper motor using features of brain signals and soft computing tools,https://api.elsevier.com/content/abstract/scopus_id/85117841558,"The brain-computer interface (BCI) plays a significant role in supporting specially-abled people to control devices with the brain signals or electroencephalogram (EEG). The proper functioning of BCI systems requires classification algorithms to distinguish between different tasks based on the features extracted from EEG. Motivated by the requirement of designing a reliable BCI with reduced memory and computational cost, this work proposes an EEG controlled stepper motor drive-based aiding device. The drive system is executed in real-time based on the processing and classification of EEG. The scheme initiates with the extraction of discriminatory features from raw time-domain EEG signals using higher-order statistics (HOS) and phase locking value (PLV).
                  Further, with extracted feature vector, the present study contemplates the operation of backpropagation neural network (BPNN), k-Nearest neighbours (k-NN), and support vector machine (SVM). Signal classification by SVM in conjugation with nonlinear principal component analysis (NLPCA) is implemented to reduce the feature vector dimension. Average classification accuracy of 82.70% and 80.46% is achieved using NLPCA with SVM for PLV and HOS features. The classifier output is utilized to spin the stepper motor clockwise and anticlockwise as needed. The control of stepper motor uses the classifier output and hence the brain signals are implemented on a laboratory-developed digital test bench comprising of TI TMS320F28379D launchpad DSP board and MITSUMI stepper motor. The validation of the proposed scheme for different signals reflects its effectiveness in combining the software and hardware aspects required for realizing an actual BCI system for real-time settings.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.dss.2021.113665,Journal,Decision Support Systems,scopus,2022-01-01,sciencedirect,A constraint programming model for making recommendations in personal process management: A design science research approach,https://api.elsevier.com/content/abstract/scopus_id/85115634506,"Decision-making in everyday life has an essential role in effectively completing personal tasks and processes. The complexity of these processes and the resulting cognitive load of managing them may vary significantly. To decrease the cognitive load created by such decision-making efforts and to obtain better outcomes, recommendation systems carry significant potential. In order to investigate the benefits provided by decision support systems (DSS) in personal process management (PPM), we first build a constraint programming (CP) model and a prototype context-aware-mobile application employing this CP model. Then, we evaluate the application and the model via two exemplary real-world scenarios. The scenarios form the core of the experiments conducted with 50 participants. We compare the participants’ planning performances with and without the PPM system with quantitative metrics such as planning times and scenario objective values. In addition, System Usability Scale (SUS) questionnaires and open-ended questions provide qualitative evaluation results. Throughout the study, we apply the Design Science Research methodology to rigorously conduct research activities by proof of concept, proof of use, and proof of value. The empirical results clearly show that our proposed model for PPM is effective, and the developed prototype solution generates positive participant comments as well as a high SUS score. Overall, the prototype PPM system with CP implementation leads to better planning in less time in the planning phase, and it lets the user do fast replanning in the execution phase, which is invaluable in dynamically changing situations such as daily activities.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.postharvbio.2021.111741,Journal,Postharvest Biology and Technology,scopus,2022-01-01,sciencedirect,Multi-output 1-dimensional convolutional neural networks for simultaneous prediction of different traits of fruit based on near-infrared spectroscopy,https://api.elsevier.com/content/abstract/scopus_id/85115232057,"In spectral data predictive modelling of fresh fruit, often the models are calibrated to predict multiple responses. A common method to deal with such a multi-response predictive modelling is the partial least-squares (PLS2) regression. Recently, deep learning (DL) has shown to outperform partial least-squares (PLS) approaches for single fruit traits prediction. The DL can also be adapted to perform multi-response modelling. This study presents an implementation of DL modelling for multi-response prediction for spectral data of fresh fruit. To show this, a real NIR data set related to SSC and MC measurements in pear fruit was used. Since DL models perform better with larger data sets, a data augmentation procedure was performed prior to data modelling. Furthermore, a comparative study was also performed between two of the most used DL architectures for spectral analysis, their multi-output and single-output variants and a classic baseline model using PLS2. A key point to note that all the DL modelling presented in this study is performed using novel automated optimisation tools such as Bayesian optimisation and Hyperband. The results showed that DL models can be easily adapted by changing the output of the fully connected layers to perform multi-response modelling. In comparison to the PLS2, the multi-response DL model showed ∼13 % lower root mean squared error (RMSE), showing the ease and superiority of handling multi-response by DL models for spectral calibration.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.energy.2021.121873,Journal,Energy,scopus,2022-01-01,sciencedirect,Real-time optimal energy management of microgrid with uncertainties based on deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85115035192,"Microgrid (MG) is an effective way to integrate renewable energy into power system at the consumer side. In the MG, the energy management system (EMS) is necessary to be deployed to realize efficient utilization and stable operation. To help the EMS make optimal schedule decisions, we proposed a real-time dynamic optimal energy management (OEM) based on deep reinforcement learning (DRL) algorithm. Traditionally, the OEM problem is solved by mathematical programming (MP) or heuristic algorithms, which may lead to low computation accuracy or efficiency. While for the proposed DRL algorithm, the MG-OEM is formulated as a Markov decision process (MDP) considering environment uncertainties, and then solved by the PPO algorithm. The PPO is a novel policy-based DRL algorithm with continuous state and action spaces, which includes two phases: offline training and online operation. In the training process, the PPO can learn from historical data to capture the uncertainty characteristic of renewable energy generation and load consumption. Finally, the case study demonstrates the effectiveness and the computation efficiency of the proposed method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.dss.2021.113653,Journal,Decision Support Systems,scopus,2022-01-01,sciencedirect,AI-based industrial full-service offerings: A model for payment structure selection considering predictive power,https://api.elsevier.com/content/abstract/scopus_id/85114151068,"Artificial Intelligence and servitization reshape the way that manufacturing companies derive value. Aiming to sustain competitive advantage and intensify customer loyalty, full-service providers offer the use of their products as a service to achieve continuous revenues. For this purpose, companies implement AI classification algorithms to enable high levels of service at controllable costs. However, traditional asset sellers who become service providers require previously atypical payment structures, as classic payment methods involving a one-time fee for production costs and profit margins are unsuitable. In addition, a low predictive power of the implemented classification algorithm can lead to misclassifications, which diminish the achievable level of service and the intended net present value of the resultant service. While previous works focus solely on the costs of such misclassifications, our decision model highlights implications for payment structures, service levels, and – ultimately – the net present value of such data-driven service offerings. Our research suggests that predictive power can be a major factor in selecting a suitable payment structure and the overall design of service level agreements. Therefore, we compare common payment structures for data-driven services and investigate their relationship to predictive power. We develop our model using a design science methodology and iteratively evaluate our results using a four-step approach that includes interviews with industry experts and the application of our model to a real-world use case. In summary, our research extends the existing knowledge of servitization and data-driven services in the manufacturing industry through a quantitative decision model.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.comnet.2021.108560,Journal,Computer Networks,scopus,2021-12-24,sciencedirect,Distributed scheduling method for multiple workflows with parallelism prediction and DAG prioritizing for time constrained cloud applications,https://api.elsevier.com/content/abstract/scopus_id/85118887015,"Fog computing is an emerging popular paradigm that extends the availability of resources to the network's edge in order to improve the quality metrics of existing Cloud-based applications. However, scheduling workflow applications with time-constraints are complex regarding the count of resources, physical topology of clusters, and the structure of the task graph of the workflows. Adding Fog resources to the intricate problem space of Cloud-based scheduling needs even more time-consuming and complicated algorithms. In this paper, a multi-criteria Mamdani fuzzy algorithm is proposed to analyze the workflow graphs with the assistance of a Long-Short Term Memory neural network parallelism prediction module. The group-based priority assignment schema performed by the fuzzy inference system assigns a priority value to workflows to indicate the relative precedence of requests. Distributed schedulers then send the workflows to target sites according to their current workloads. The whole process is performed in a decentralized manner to prevent any bottlenecks. We have used an extensive software simulation study to compare the proposed algorithm in real workloads with two recent and notable algorithms. The simulation results confirm the proposed algorithm's superiority in fulfilling time-constraints, resource utilization, and overall application scheduling success rate.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2021.107504,Journal,Knowledge-Based Systems,scopus,2021-12-05,sciencedirect,Diacritics generation and application in hate speech detection on Vietnamese social networks,https://api.elsevier.com/content/abstract/scopus_id/85115945453,"One of the challenging problems in text processing is diacritics generation where one needs to generate diacritic marks for non-accented text. With an ever increasing amount of informal text without accents such as short text messages, emails or blog posts on social media, a software system which is capable of generating diacritic marks accurately is very useful and necessary in many situations. This paper presents an approach to improve the accuracy of diacritics generation for Vietnamese text. We propose two novel deep learning models which leverage a plausible conceptual representation for the phonetic structure of Vietnamese syllables. Experimental results on real-world datasets show that our models achieve a significant improvement as compared to the state-of-the-art methods for diacritics generation. We also demonstrate that the proposed models can be applied efficiently to improve the accuracy of hate speech detection on Vietnamese social networks.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mtcomm.2021.102786,Journal,Materials Today Communications,scopus,2021-12-01,sciencedirect,Prediction of welding residual stress and deformation in electro-gas welding using artificial neural network,https://api.elsevier.com/content/abstract/scopus_id/85122803791,"Evaluating the welding residual stress and deformation in a reasonable and reliable way is the perquisite of ensuring the quality of weldments. Therefore, in this paper, an artificial neural network model is developed for the prediction of welding residual stress and deformation produced in Electro-gas welding using C++ language. The plate thickness, groove angle, groove clearance, welding current, cooling type and the welding material have been considered as the input parameters, the residual stress and deformation as output parameters in the structure of the model. The comparison between the neural network predictions and finite element analysis results indicates that the established neural network model is sufficiently accurate and efficient in predicting the residual stress and deformation. Additionally, a human-computer interaction interface software based on Qt environment is designed and implemented, aiming to obtain the prediction results in real time.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.softx.2021.100854,Journal,SoftwareX,scopus,2021-12-01,sciencedirect,MicroVIP: Microscopy image simulation on the Virtual Imaging Platform,https://api.elsevier.com/content/abstract/scopus_id/85119052033,"MicroVIP is an open source software that assembles, in a unified web-application running on distributed computing resources, simulators of the main fluorescent microscopy imaging modalities (with existing codes or newly developed). MicroVIP provides realistic simulated images including several sources of noise (microfluidic blur effect, diffraction, Poisson noise, camera read out noise). MicroVIP also includes a module which simulates single cells with fluorescent markers and a module to analyze the simulated images with textural and pointillist feature spaces. MicroVIP is shown to be of value for supervised machine learning. It allow to automatically generate large sets of training images and virtual instrumentation to optimize the optical parameters before realizing real experiments.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compeleceng.2021.107570,Journal,Computers and Electrical Engineering,scopus,2021-12-01,sciencedirect,A social media-based over layer on the edge for handling emergency-related events,https://api.elsevier.com/content/abstract/scopus_id/85118991700,"Online Social Networks (OSNs), together with messaging services are tools for the exchange of entertainment-related information. However, they represent virtual environments capable of providing relevant information related to emergency or criminal events. Thanks to the simple way of using OSNs in combination to modern ubiquitous Internet of Things (IoT) smart devices, the generation and exploitation of such information is made available to users in real-time even more easily. Unfortunately, its reuse has not been taken into consideration yet due to the lack of specific models and related software tools. In this context, the paper presents a social media-based over layer for supporting the monitoring, detection, computation and information sharing of social media information related to emergency scenarios centered on smartphones and text mining techniques. The proposal is assessed through two different case studies, by evaluating the performances of different classifiers and by showing the logic of the functionalities of the related apps.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compeleceng.2021.107567,Journal,Computers and Electrical Engineering,scopus,2021-12-01,sciencedirect,Predicting activities of daily living via temporal point processes: Approaches and experimental results,https://api.elsevier.com/content/abstract/scopus_id/85118746684,"Activity Prediction is foreseeing the following activity people are going to execute. This is a crucial task in smart home environments, i.e., in order to facilitate the daily routines of elderly people with or without special needs. In this paper, we focused on Activity Daily Living prediction and we proposed a novel activity prediction technique based on the combination of Marked Temporal Point Processes and Neural Networks. Experiments on real and synthetic smart space datasets have shown that our approach is able to conveniently represent and predict daily living activities in an unsupervised way. We evaluated its performance and compared its results with state-of-the-art methods providing freely available implementations. Noticeably, the proposed approach outperforms the best concurrent algorithm by obtaining an improvement of F1-score of 60% (on average of the considered datasets).",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.pss.2021.105371,Journal,Planetary and Space Science,scopus,2021-12-01,sciencedirect,Terrain classification-based rover traverse planner with kinematic constraints for Mars exploration,https://api.elsevier.com/content/abstract/scopus_id/85118490703,"In Mars exploration mission, the rover path planning is essential to ensure the safety and efficiency of the rover traverse. At present, traverse planning deployed Mars rovers requires experienced geologists and planetary scientists to spend a lot of time on surface-topography analysis. To a large extent, this is a costly and time-consuming manual process. Meanwhile, traditional optimal search algorithms (A∗ and Dijkstra) can search for a globally optimal path, but the path found does not satisfy the nonholonomic constraint of the vehicle, thus not directly drivable. The Terrain Classification-based Rover Traverse Planner (TCRTP), introduced in this article, is an automated algorithm that uses deep learning-based terrain classification as the guide to generate the optimal traverses with kinematic constraints. TCRTP combines the terrain classification with nonholonomic constraints, and it can quickly and accurately obtain the global optimal solution under the heuristic function. We also propose modifications of the cost function for path optimization to improve the smoothness of the solution. This algorithm plans forward and reverse movement, and penalizes reverse driving and changing the direction of movement. The TCRTP algorithm is easy to be extended, and the optimization traversal under multiple missions can be realized by adding traffic constraints, such as terrain roughness, elevation changes and so on. The TCRTP-based rover allows for real-time and frequent planning, and the addition of terrain constraints ensures the safety of the planned route. Our planner, combined with computer vision, shows the potential to reduce operator workloads and explore future planetary space.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jneumeth.2021.109371,Journal,Journal of Neuroscience Methods,scopus,2021-12-01,sciencedirect,Development of deep learning models for microglia analyses in brain tissue using DeePathology™ STUDIO,https://api.elsevier.com/content/abstract/scopus_id/85116054792,"Background
                  Interest in artificial intelligence-driven analysis of medical images has seen a steep increase in recent years. Thus, our paper aims to promote and facilitate the use of this state-of-the-art technology to fellow researchers and clinicians.
               
                  New method
                  We present custom deep learning models generated in DeePathology™ STUDIO without the need for background knowledge in deep learning and computer science underlined by practical suggestions.
               
                  Results
                  We describe the general workflow in this commercially available software and present three real-world examples how to detect microglia on IBA1-stained mouse brain sections including their differences, validation results and analysis of a sample slide.
               
                  Comparison with existing methods
                  Deep-learning assisted analysis of histological images is faster than classical analysis methods, and offers a wide variety of detection possibilities that are not available using methods based on staining intensity.
               
                  Conclusions
                  Reduced researcher bias, increased speed and extended possibilities make deep-learning assisted analysis of histological images superior to traditional analysis methods for histological images.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cma.2021.114121,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2021-12-01,sciencedirect,A virtual model architecture for engineering structures with Twin Extended Support Vector Regression (T-X-SVR) method,https://api.elsevier.com/content/abstract/scopus_id/85114715295,"A machine learning aided virtual model architecture framework is presented. With great computational stability and preserved convexity features, the Twin Extended Support Vector Regression (T-X-SVR) method is adopted to imitate the underpinned and sophisticated constitutive relationship between the systematic inputs and outcomes in real-world applications. Various numerical simulations can be implemented on the virtual model with greatly reduced computational costs. The multi-type information from heterogeneous sources and multifarious engineering applications are supported by the proposed framework. For the virtual model aided numerical analysis with the multi-type information, fuzzy-valued probabilistic distributional characteristics of the bounds of the concerned structural responses are estimated. The capability of the modularity feature of the virtual model improves the operational flexibility which makes the implementation of such advance technique more user friendly. To demonstrate the applicability and computational efficiency of the proposed framework, three practical engineering stimulated problems (i.e., the mechanical dynamic system, multiphysics with heat transfer and gas flow interaction, and the expansion process of a biomedical stent with both material and geometry nonlinearities), involving multi-type information (i.e., random parameters and fuzzy sets), are fully investigated through the proposed virtual model architecture framework.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.talanta.2021.122780,Journal,Talanta,scopus,2021-12-01,sciencedirect,A real-world approach to identifying animal bones and Lower Pleistocene fossils by laser induced breakdown spectroscopy,https://api.elsevier.com/content/abstract/scopus_id/85111807121,"Archaeological sites often contain accumulations of remains derived from different independent events produced by different agents. Thus, in Palaeolithic sites, it is normal to find alternating occupations between humans and carnivores. The faunal assemblages at these sites usually include hundreds or thousands of bone fragments, which are very difficult to associate them to specific individuals since there are no currently available techniques able to do it in a straightforward and cost-effective way. In this work we present a methodology that allows us to characterise the anatomical remains of a bone accumulation and relate them all back to the specific individuals to which they belong. In order to provide a real world application, we have used a selection of animal bones from different individuals belonging to deer and sheep (fed in a controlled way using the same diet). On the other hand, fossilized faunal remains have also been analysed to verify if these fossilized bones keep some of the fingerprinting of the animal from which they come from. For this purpose, we have developed a protocol using Laser Induced Breakdown Spectroscopy (LIBS) together with Neural Networks (NN) implemented here to discriminate and reassemble deer and sheep bones from different individuals, which we subsequently applied for these proposes to fossilized material. To the best of our knowledge, this is the first time that this technique has been applied for individual fingerprinting to actuality and fossil samples. The elemental composition of bones provides enough information to get a correct discrimination of different individuals. The spectral correlation has exceeded 95 %. and all individuals were correctly classified to the individual from which they come from. There have been no instances of false positives or false negatives in our tests or applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2021.06.033,Journal,Future Generation Computer Systems,scopus,2021-12-01,sciencedirect,Detecting malicious behavior in social platforms via hybrid knowledge- and data-driven systems,https://api.elsevier.com/content/abstract/scopus_id/85109435960,"Among the wide variety of malicious behavior commonly observed in modern social platforms, one of the most notorious is the diffusion of fake news, given its potential to influence the opinions of millions of people who can be voters, consumers, or simply citizens going about their daily lives. In this paper, we implement and carry out an empirical evaluation of a version of the recently-proposed NetDER architecture for hybrid AI decision-support systems with the capability of leveraging the availability of machine learning modules, logical reasoning about unknown objects, and forecasts based on diffusion processes. NetDER is a general architecture for reasoning about different kinds of malicious behavior such as dissemination of fake news, hate speech, and malware, detection of botnet operations, prevention of cyber attacks including those targeting software products or blockchain transactions, among others. Here, we focus on the case of fake news dissemination on social platforms by three different kinds of users: non-malicious, malicious, and botnet members. In particular, we focus on three tasks: (i) determining who is responsible for posting a fake news article, (ii) detecting malicious users, and (iii) detecting which users belong to a botnet designed to disseminate fake news. Given the difficulty of obtaining adequate data with ground truth, we also develop a testbed that combines real-world fake news datasets with synthetically generated networks of users and fully-detailed traces of their behavior throughout a series of time points. We designed our testbed to be customizable for different problem sizes and settings, and make its code publicly available to be used in similar evaluation efforts. Finally, we report on the results of a thorough experimental evaluation of three variants of our model and six environmental settings over the three tasks. Our results clearly show the effects that the quality of knowledge engineering tasks, the quality of the underlying machine learning classifier used to detect fake news, and the specific environmental conditions have on smart policing efforts in social platforms.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2021.115498,Journal,Expert Systems with Applications,scopus,2021-12-01,sciencedirect,Real-time human pose estimation on a smart walker using convolutional neural networks,https://api.elsevier.com/content/abstract/scopus_id/85109217957,"Rehabilitation is important to improve quality of life for mobility-impaired patients. Smart walkers are a commonly used solution that should embed automatic and objective tools for data-driven human-in-the-loop control and monitoring. However, present solutions focus on extracting few specific metrics from dedicated sensors with no unified full-body approach. We investigate a general, real-time, full-body pose estimation framework based on two RGB+D camera streams with non-overlapping views mounted on a smart walker equipment used in rehabilitation. Human keypoint estimation is performed using a two-stage neural network framework. The 2D-Stage implements a detection module that locates body keypoints in the 2D image frames. The 3D-Stage implements a regression module that lifts and relates the detected keypoints in both cameras to the 3D space relative to the walker. Model predictions are low-pass filtered to improve temporal consistency. A custom acquisition method was used to obtain a dataset, with 14 healthy subjects, used for training and evaluating the proposed framework offline, which was then deployed on the real walker equipment. An overall keypoint detection error of 3.73 pixels for the 2D-Stage and 44.05 mm for the 3D-Stage were reported, with an inference time of 26.6 ms when deployed on the constrained hardware of the walker. We present a novel approach to patient monitoring and data-driven human-in-the-loop control in the context of smart walkers. It is able to extract a complete and compact body representation in real-time and from inexpensive sensors, serving as a common base for downstream metrics extraction solutions, and Human-Robot interaction applications. Despite promising results, more data should be collected on users with impairments, to assess its performance as a rehabilitation tool in real-world scenarios.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.livsci.2021.104700,Journal,Livestock Science,scopus,2021-11-01,sciencedirect,A review of deep learning algorithms for computer vision systems in livestock,https://api.elsevier.com/content/abstract/scopus_id/85118744270,"In livestock operations, systematically monitoring animal body weight, biometric body measurements, animal behavior, feed bunk, and other difficult-to-measure phenotypes is manually unfeasible due to labor, costs, and animal stress. Applications of computer vision are growing in importance in livestock systems due to their ability to generate real-time, non-invasive, and accurate animal-level information. However, the development of a computer vision system requires sophisticated statistical and computational approaches for efficient data management and appropriate data mining, as it involves massive datasets. This article aims to provide an overview of how deep learning has been implemented in computer vision systems used in livestock, and how such implementation can be an effective tool to predict animal phenotypes and to accelerate the development of predictive modeling for precise management decisions. First, we reviewed the most recent milestones achieved with computer vision systems and the respective deep learning algorithms implemented in Animal Science studies. Then, we reviewed the published research studies in Animal Science which used deep learning algorithms as the primary analytical strategy for image classification, object detection, object segmentation, and feature extraction. The great number of reviewed articles published in the last few years demonstrates the high interest and rapid development of deep learning algorithms in computer vision systems across livestock species. Deep learning algorithms for computer vision systems, such as Mask R-CNN, Faster R-CNN, YOLO (v3 and v4), DeepLab v3, U-Net and others have been used in Animal Science research studies. Additionally, network architectures such as ResNet, Inception, Xception, and VGG16 have been implemented in several studies across livestock species. The great performance of these deep learning algorithms suggests an improved predictive ability in livestock applications and a faster inference. However, only a few articles fully described the deep learning algorithms and their implementation. Thus, information regarding hyperparameter tuning, pre-trained weights, deep learning backbone, and hierarchical data structure were missing. We summarized peer-reviewed articles by computer vision tasks (image classification, object detection, and object segmentation), deep learning algorithms, animal species, and phenotypes including animal identification and behavior, feed intake, animal body weight, and many others. Understanding the principles of computer vision and the algorithms used for each application is crucial to develop efficient systems in livestock operations. Such development will potentially have a major impact on the livestock industry by predicting real-time and accurate phenotypes, which could be used in the future to improve farm management decisions, breeding programs through high-throughput phenotyping, and optimized data-driven interventions.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.conbuildmat.2021.124915,Journal,Construction and Building Materials,scopus,2021-11-01,sciencedirect,Prediction models for low-temperature creep compliance of asphalt mixtures containing reclaimed asphalt pavement (RAP),https://api.elsevier.com/content/abstract/scopus_id/85115205905,"The low-temperature creep compliances (D(t)) of asphalt mixture is one of the necessary parameters to predict the depth and amount of low-temperature cracks. Level 3 analysis in Mechanistic-Empirical Pavement Design Guide (MEPDG) software uses asphalt binder properties parameters and mixture volumetric properties to predict D(t) when the real laboratorial data is not available. However, some parameters in the model may not be routinely measured in Superpave system, which restricts the use of the prediction model. In addition, new additives and recycling materials such as reclaimed asphalt pavement (RAP) have been extensively used in recent years and shown to have significant effect on the low-temperature cracking resistance of asphalt mixture. However, the effects have not been considered in the existing D(t) prediction models. Hence, the objective of this study is to develop models with significantly high accuracy to predict the D(t) of asphalt mixtures containing RAP. A total of 1890 sets of data points were collected from three different research projects. A Pearson correlation analysis was carried out to select the input parameters which are most influential to D(t). Two prediction models (i.e., multiple linear regression and artificial neural network (ANN) models) were proposed. A comprehensive analysis on the prediction accuracy and reasonability of the proposed models was conducted. The results showed that the proposed models had much better prediction performance with high accuracy than the existing models. The comparisons between the proposed models with the existing models confirmed that it is necessary to take the new additives and recycling materials into account in developing D(t) prediction models.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.biopsych.2021.06.023,Journal,Biological Psychiatry,scopus,2021-11-01,sciencedirect,Toward Generalizable and Transdiagnostic Tools for Psychosis Prediction: An Independent Validation and Improvement of the NAPLS-2 Risk Calculator in the Multisite PRONIA Cohort,https://api.elsevier.com/content/abstract/scopus_id/85114259062,"Background
                  Transition to psychosis is among the most adverse outcomes of clinical high-risk (CHR) syndromes encompassing ultra-high risk (UHR) and basic symptom states. Clinical risk calculators may facilitate an early and individualized interception of psychosis, but their real-world implementation requires thorough validation across diverse risk populations, including young patients with depressive syndromes.
               
                  Methods
                  We validated the previously described NAPLS-2 (North American Prodrome Longitudinal Study 2) calculator in 334 patients (26 with transition to psychosis) with CHR or recent-onset depression (ROD) drawn from the multisite European PRONIA (Personalised Prognostic Tools for Early Psychosis Management) study. Patients were categorized into three risk enrichment levels, ranging from UHR, over CHR, to a broad-risk population comprising patients with CHR or ROD (CHR|ROD). We assessed how risk enrichment and different predictive algorithms influenced prognostic performance using reciprocal external validation.
               
                  Results
                  After calibration, the NAPLS-2 model predicted psychosis with a balanced accuracy (BAC) (sensitivity, specificity) of 68% (73%, 63%) in the PRONIA-UHR cohort, 67% (74%, 60%) in the CHR cohort, and 70% (73%, 66%) in patients with CHR|ROD. Multiple model derivation in PRONIA–CHR|ROD and validation in NAPLS-2–UHR patients confirmed that broader risk definitions produced more accurate risk calculators (CHR|ROD-based vs. UHR-based performance: 67% [68%, 66%] vs. 58% [61%, 56%]). Support vector machines were superior in CHR|ROD (BAC = 71%), while ridge logistic regression and support vector machines performed similarly in CHR (BAC = 67%) and UHR cohorts (BAC = 65%). Attenuated psychotic symptoms predicted psychosis across risk levels, while younger age and reduced processing speed became increasingly relevant for broader risk cohorts.
               
                  Conclusions
                  Clinical-neurocognitive machine learning models operating in young patients with affective and CHR syndromes facilitate a more precise and generalizable prediction of psychosis. Future studies should investigate their therapeutic utility in large-scale clinical trials.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cie.2021.107621,Journal,Computers and Industrial Engineering,scopus,2021-11-01,sciencedirect,Deep deterministic policy gradient algorithm for crowd-evacuation path planning,https://api.elsevier.com/content/abstract/scopus_id/85113275288,"In existing evacuation methods, the large number of pedestrians and the complex environment will affect the efficiency of evacuation. Therefore, we propose a hierarchical evacuation method based on multi-agent deep reinforcement learning (MADRL) to solve the above problem. First, we use a two-level evacuation mechanism to guide evacuations, the crowd is divided into leaders and followers. Second, in the upper level, leaders perform path planning to guide the evacuation. To obtain the best evacuation path, we propose the efficient multi-agent deep deterministic policy gradient (E-MADDPG) algorithm for crowd-evacuation path planning. E-MADDPG algorithm combines learning curves to improve the fixed experience pool of MADDPG algorithm and uses high-priority experience playback strategy to improve the sampling strategy. The improvement increases the learning efficiency of the algorithm. Meanwhile we extract pedestrian motion trajectories from real motion videos to reduce the state space of algorithm. Third, in the bottom layer, followers use the relative velocity obstacle (RVO) algorithm to avoid collisions and follow leaders to evacuate. Finally, experimental results illustrate that the E-MADDPG algorithm can improve path planning efficiency, while the proposed method can improve the efficiency of crowd evacuation.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2021.107792,Journal,Applied Soft Computing,scopus,2021-11-01,sciencedirect,Sentiment classification using attention mechanism and bidirectional long short-term memory network,https://api.elsevier.com/content/abstract/scopus_id/85112745936,"We propose a sentiment classification method for large scale microblog text based on the attention mechanism and the bidirectional long short-term memory network (SC-ABiLSTM). We use an experimental study to compare our proposed method with baseline methods using real world large-scale microblog data. Comparing the accuracy of the baseline methods to the accuracy of our model, we demonstrate the efficacy of our proposed method. While sentiment classification of social media data has been extensively studied, the main novelty of our study is the implementation of the attention mechanism in a deep learning network for analyzing large scale social media data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.actaastro.2021.08.002,Journal,Acta Astronautica,scopus,2021-11-01,sciencedirect,Improved orbit predictions using two-line elements through error pattern mining and transferring,https://api.elsevier.com/content/abstract/scopus_id/85112129954,"As the sole orbit data source of space objects for public access, the NORAD catalog provides the basic orbital information in the form of two-line element (TLE) for various space tasks. But the accuracy of orbit prediction (OP) using TLE with the analytical Simplified General Perturbations-4 (SGP4) propagator drops quickly with time, especially for low orbits, significantly limiting the capability of TLEs for advanced space situational awareness (SSA) applications. To enhance the TLE performance over long-duration OP, this paper proposes a data-driven method for improved TLE-based orbit predictions through mining and transferring the orbit error patterns. Two state-of-the-art learning methods, the gradient boosting decision tree (GBDT) and convolutional neural networks (CNN), are applied to model the underlying error patterns, and then the learned models are used as an error corrector to modify the future orbit predictions. Experimental results demonstrate that the time-varying orbit error patterns in the past can be captured by the developed learning framework. As a result, the accuracy of orbit predictions over the future 14 days can be improved by more than 75% in the along-track direction and 90% in the cross-track and radial directions, when the model-predicted errors are used. It also shows that the error pattern learning and application process is computationally efficient, and it could be implemented for near real-time applications. This study demonstrates the promising potential of machine learning (ML)/deep learning (DL) for enhanced SSA capability with the publicly available TLEs.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.apenergy.2021.117504,Journal,Applied Energy,scopus,2021-11-01,sciencedirect,Deep reinforcement learning control of electric vehicle charging in the presence of photovoltaic generation,https://api.elsevier.com/content/abstract/scopus_id/85111920114,"In recent years, the importance of electric mobility has increased in response to climate change. The fast-growing deployment of electric vehicles (EVs) worldwide is expected to decrease transportation-related 
                        
                           C
                           
                              
                                 O
                              
                              
                                 2
                              
                           
                        
                      emissions, facilitate the integration of renewables, and support the grid through demand–response services. Simultaneously, inadequate EV charging patterns can lead to undesirable effects in grid operation, such as high peak-loads or low self-consumption of solar electricity, thus calling for novel methods of control. This work focuses on applying deep reinforcement learning (RL) to the EV charging control problem with the objectives to increase photovoltaic self-consumption and EV state of charge at departure. Particularly, we propose mathematical formulations of environments with discrete, continuous, and parametrized action spaces and respective deep RL algorithms to resolve them. The benchmarking of the deep RL control against naive, rule-based, deterministic optimization, and model-predictive control demonstrates that the suggested methodology can produce consistent and employable EV charging strategies, while its performance holds a great promise for real-time implementations.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.actaastro.2021.07.012,Journal,Acta Astronautica,scopus,2021-11-01,sciencedirect,"A review of space surgery - What have we achieved, current challenges, and future prospects",https://api.elsevier.com/content/abstract/scopus_id/85110745640,"Major surgical events/incidents onboard are rare but can be catastrophic to any mission. National Aeronautics and Space Administration (NASA) uses the Integrated Medical Model (IMM) to develop an integrated, quantified, evidence-based decision support tool useful for crew health and mission planners to assess risk and design medical systems. In 2017, the IMM of the NASA Human Research Program included a list of 100 medical conditions that could be anticipated during space flight. Of those conditions, 27 are expected to need surgical treatment. Consequently, there has been a continuing interest in surgical capabilities for exploration space flight. The surgical system capabilities aboard all space stations and analogue flights have been designed and implemented with an emphasis on stabilisation, medical evacuation, and ATLS capabilities. However, with future missions to the Moon and Mars, evacuation is not a possibility and astronauts will need to troubleshoot, adapt, and self-administer complex surgical care autonomously.
                  This narrative review aims to examine the published work on surgical care in space, discuss the inherent challenges, and identify scope for future studies. The review evaluates and analyses results from several landmark experiments covering important technical aspects such as basic surgical skills, laparoscopic surgery, robotic surgery, and tele surgery. Relevant studies for the review were identified from the MEDLINE, PubMed, and EMBASE databases. Eligible studies were published between 1960 and June 2021 and were identified using the terms “space surgery”, “microgravity”, “zero gravity”, “weightlessness”, “parabolic flight”, “neutral buoyancy”, and “spaceflight”. Only articles in English were selected and references cited in the selected publications were followed up and included where appropriate. Documents available in the public domain and/or archives of National Space agencies were also included. The search yielded a total of 86 hits including review articles, commentaries, studies, meeting summaries and technical reports submitted to National Space agencies. Results were then filtered for eligible papers relevant to this narrative review. Challenges on a long-duration mission will be unique, unlike anything we have faced so far in the last 60 years of space travel. Despite the progress in space surgery in the last 40 years, there are several challenges to achieving a fully functional surgical care system on any mission outside Low Earth Orbit. The microgravity environment presents unique challenges related to altered physiology as well as mechanics and techniques pertinent to surgical care. Some of the challenges include but are not limited to crew selection, role of prophylactic surgery, adaptation to zero gravity, lack of ground support, training and maintenance of surgical skills and limitation of weight and volume for hardware. Ultrasound imaging, 3D printing and AI-based surgical assistance coupled with robotic surgery have shown promise, but their real efficacy and functionality remains to be tested.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.talanta.2021.122608,Journal,Talanta,scopus,2021-11-01,sciencedirect,"PIXE based, Machine-Learning (PIXEL) supported workflow for glass fragments classification",https://api.elsevier.com/content/abstract/scopus_id/85109431731,"This paper presents a structured workflow for glass fragment analysis based on a combination of Elemental Analysis using PIXE and Machine Learning tools, with the ultimate goal of standardizing and helping forensic efforts. The proposed workflow was implemented on glass fragments received from the Israeli DIFS (Israeli Police Force's Division of Identification and Forensic Sciences) that were collected from various vehicles, including glass fragments from different manufacturers and years of production. We demonstrate that this workflow can produce models with high (>80%) accuracy in identifying glass fragment's origins and provide a test-case demonstrating how the model can be applied in real-life forensic events. We provide a standard, reproducible methodology that can be used in many forensic domains beyond glass fragments, for example, Gun Shot Residue, flammable liquids, illegal substances, and more.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.renene.2021.05.155,Journal,Renewable Energy,scopus,2021-11-01,sciencedirect,A deep learning approach towards the detection and recognition of opening of windows for effective management of building ventilation heat losses and reducing space heating demand,https://api.elsevier.com/content/abstract/scopus_id/85107941088,"Building ventilation accounts for up to 30% of the heat loss in commercial buildings and 25% in industrial buildings. To effectively aid the reduction of energy consumption in the building sector, the development of demand-driven control systems for heating ventilation and air-conditioning (HVAC) is necessary. In countries with temperate climates such as the UK, many buildings depend on natural ventilation strategies such as openable windows, which are useful for reducing overheating prevalence during the summer. The manual opening and adjustment of windows by occupants, particularly during the heating season, can lead to substantial heat loss and consequent energy consumption. This could also result in the unnecessary or over ventilation of the space, or the fresh air is more than what is required to ensure adequate air quality. Furthermore, energy losses build up when windows are left open for extended periods. Hence, it is important to develop control strategies that can detect and recognise the period and amount of window opening in real-time and at the same time adjust the HVAC systems to minimise energy wastage and maintain indoor environment quality and thermal comfort. This paper presents a vision-based deep learning framework for the detection and recognition of manual window operation in buildings. A trained deep learning model is deployed into an artificial intelligence-powered camera. To assess the proposed strategy's capabilities, building energy simulation was used with various operation profiles of the opening of the windows based on various scenarios. Initial experimental tests were conducted within a university lecture room with a south-facing window. Deep learning influenced profile (DLIP) was generated via the framework, which uses real-time window detection and recognition data. The generated DLIP were compared with the actual observations, and the initial detection results showed that the method was capable of identifying windows that were opened and had an average accuracy of 97.29%. The results for the three scenarios showed that the proposed strategy could potentially be used to help adjust the HVAC setpoint or alert the occupants or building managers to prevent unnecessary heating demand. Further developments include enhancing the framework ability to detect multiple window opening types and sizes and the detection accuracy by optimising the model.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jhlste.2020.100275,Journal,"Journal of Hospitality, Leisure, Sport and Tourism Education",scopus,2021-11-01,sciencedirect,Industry 4.0 technologies in tourism education: Nurturing students to think with technology,https://api.elsevier.com/content/abstract/scopus_id/85092173436,"The Industry 4.0 revolution is bringing major transformations in the tourism systems design suitable for technologically oriented consumers. Indeed, methods and technologies introduced by Big Data, Automation, Virtual and augmented reality, Robotics and ICT well fit with the Tourism 4.0 paradigm. However, tourism students are not yet trained on techniques, issues and methods related to the Industry 4.0 framework.
                  Hence, relying on a careful examination of the literature on tourism market trends linked to the offer of innovative technological services, we identified conceptual, methodological, technological and practical skills to be developed in an academic curriculum for Tourism Science students. Learning path were focused on: i) processes of data acquisition from social media, ii) data analysis using Machine Learning techniques and iii) data design into significant elements useful to implement communication systems in the tourism field.
               
                  Results
                  showed that the most of participants achieved a medium-high evaluation for the implementation of the communication systems, applying appropriately techniques and tools learned along the course. Furthermore, the high percentage of students satisfaction registered in relation to the course, revealed that students enjoyed this experience. Outcomes reflects the acquisition and the awareness of those skills that will enable students to be conscious protagonists of their role in tourism 4.0.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2021.107380,Journal,Knowledge-Based Systems,scopus,2021-10-27,sciencedirect,Hierarchical Social Similarity-guided Model with Dual-mode Attention for session-based recommendation,https://api.elsevier.com/content/abstract/scopus_id/85113609671,"Session-based recommendation models users’ interests in sessions to make recommendations. Many previous studies have shown that users usually have similar interests to their friends, and are easily influenced by friends. However, these studies also tend to ignore the fact that users’ interests may merely be similar to certain friends’ interests in certain aspects. To address the above issues, we propose a novel Hierarchical Social Similarity-guided Model with Dual-mode Attention (HMDA) for Session-based Recommendation. Specifically, we first calculate the item-level similarity between users and their friends to select influential friends. We then compute the aspect-level similarity to explore the aspect difference between users’ interests and friends’ interests. Under the guidance of the item-level and aspect-level similarity, HMDA is capable of effectively and accurately aggregating the social influence exerted by friends on users, and further combining users’ individual interests to enhance recommendation performance. In addition, we design a dual-mode attention mechanism to capture the internal dependence and mutual dependence between the long-term and short-term interests of users. The proposed model is extensively evaluated on three real-world datasets. Experimental results demonstrate that our model outperforms the state-of-the-art baseline methods.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2021.07.045,Journal,Neurocomputing,scopus,2021-10-21,sciencedirect,Pruning and quantization for deep neural network acceleration: A survey,https://api.elsevier.com/content/abstract/scopus_id/85112651139,"Deep neural networks have been applied in many applications exhibiting extraordinary abilities in the field of computer vision. However, complex network architectures challenge efficient real-time deployment and require significant computation resources and energy costs. These challenges can be overcome through optimizations such as network compression. Network compression can often be realized with little loss of accuracy. In some cases accuracy may even improve. This paper provides a survey on two types of network compression: pruning and quantization. Pruning can be categorized as static if it is performed offline or dynamic if it is performed at run-time. We compare pruning techniques and describe criteria used to remove redundant computations. We discuss trade-offs in element-wise, channel-wise, shape-wise, filter-wise, layer-wise and even network-wise pruning. Quantization reduces computations by reducing the precision of the datatype. Weights, biases, and activations may be quantized typically to 8-bit integers although lower bit width implementations are also discussed including binary neural networks. Both pruning and quantization can be used independently or combined. We compare current techniques, analyze their strengths and weaknesses, present compressed network accuracy results on a number of frameworks, and provide practical guidance for compressing networks.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engstruct.2021.112877,Journal,Engineering Structures,scopus,2021-10-15,sciencedirect,Prediction of fire resistance of concrete encased steel composite columns using artificial neural network,https://api.elsevier.com/content/abstract/scopus_id/85111330781,"Concrete encased steel (CES) columns, also known as steel reinforced concrete (SRC) composite columns, exhibit superior fire resistance due to concrete acting as a protection layer for the embedded steel section. While modern design codes have provided design guides for the fire resistance of CES columns, they are only applicable to those made of normal strength concrete. For high strength CES columns, advanced analysis is needed to capture the brittleness of high strength concrete at elevated temperature. In this paper, two methods, namely the artificial neural network (ANN) and the analytical equations, are proposed to predict the fire resistance of axially-loaded CES columns made of high strength concrete. To train the ANN, a finite difference model is developed to compute the temperature field in CES columns and it is used to establish a database containing 15,200 specimens. The cross-sectional dimensions and materials grades of the specimens are carefully selected to cover a wide range of values including those commonly adopted in real-life applications. The inputs of the ANN are identified through an extensive parametric analysis. The selected ANN consists of 7 inputs, 3 outputs and 2 hidden layers and achieves a high determination coefficient R2 value of 0.999. For practical implementation, analytical equations are also derived and achieve high R2 values above 0.953. The predictive power of the ANN and the analytical equations are examined against the observations obtained from actual fire tests, showing reasonable accuracy of prediction. Both methods are simple, of high accuracy and have implicitly accounted for temperature-dependent material degradation, and hence do not require input of temperature-dependent material properties and advanced analysis software.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2021.100348,Journal,Patterns,scopus,2021-10-08,sciencedirect,Grounding deep neural network predictions of human categorization behavior in understandable functional features: The case of face identity,https://api.elsevier.com/content/abstract/scopus_id/85123641622,"Deep neural networks (DNNs) can resolve real-world categorization tasks with apparent human-level performance. However, true equivalence of behavioral performance between humans and their DNN models requires that their internal mechanisms process equivalent features of the stimulus. To develop such feature equivalence, our methodology leveraged an interpretable and experimentally controlled generative model of the stimuli (realistic three-dimensional textured faces). Humans rated the similarity of randomly generated faces to four familiar identities. We predicted these similarity ratings from the activations of five DNNs trained with different optimization objectives. Using information theoretic redundancy, reverse correlation, and the testing of generalization gradients, we show that DNN predictions of human behavior improve because their shape and texture features overlap with those that subsume human behavior. Thus, we must equate the functional features that subsume the behavioral performances of the brain and its models before comparing where, when, and how these features are processed.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.envadv.2021.100089,Journal,Environmental Advances,scopus,2021-10-01,sciencedirect,"A practical study of CITES wood species identification by untargeted DART/QTOF, GC/QTOF and LC/QTOF together with machine learning processes and statistical analysis",https://api.elsevier.com/content/abstract/scopus_id/85118730822,"Illegal logging and trafficking of endangered timber species has attracted the world's major organized crime groups, with associated deforestation and serious social damage. The inability of traditional methodologies and DNA analysis to readily perform wood identification to the species level for monitoring has stimulated research on chemotyping techniques. In this study, simple wood extraction of endangered rosewoods (Dalbergia spp), amenable to use in the field, produced colorful hues that were suggestive of wood species. A more definitive study was conducted to develop wood species identification procedures using high-resolution quadrupole time-of-flight (QTOF) mass spectrometers interfaced with liquid chromatography (LC), gas chromatography (GC), and Direct Analysis in Real Time (DART). The time consuming process of extracting “identifying” mass spectral ions for species identification, contentious due to their ubiquitous nature, was supplanted by application of machine learning processes. The unbiased software mining of raw data from multiple analytical batches, followed by statistical Random Forest analysis, enabled discrimination between both anatomically and chemotypically similar Dalbergia species. Statistical Principal Component Analysis (PCA) scatterplots with 95% confidence ellipses were visually compelling in showing a differential clustering of Dalbergia from other commonly traded and lookalike wood species. The information rich raw data from GC or LC analyses offered a corroborative, legally defensible, and widely available confirmatory tool in the identification of timber species.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmoldx.2021.07.011,Journal,Journal of Molecular Diagnostics,scopus,2021-10-01,sciencedirect,Temporary Regulatory Deviations and the Coronavirus Disease 2019 (COVID-19) PCR Labeling Update Study Indicate What Laboratory-Developed Test Regulation by the US Food and Drug Administration (FDA) Could Look Like,https://api.elsevier.com/content/abstract/scopus_id/85116010045,"The coronavirus disease 2019 (COVID-19) response necessitated innovations and a series of regulatory deviations that also affected laboratory-developed tests (LDTs). To examine real-world consequences and specify regulatory paradigm shifts, legislative proposals were aligned on a common timeline with Emergency Use Authorization (EUA) of LDTs and the US Food and Drug Administration (FDA)-orchestrated severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) labeling update study. The initial EUA adoption by LDT developers shows that the FDA can have oversight over LDTs. We used efficiency-corrected microcosting of our EUA PCR assay to estimate the national cost of the labeling update study to $0.3 to $1.4 million US dollars. Labeling update study performance data showed lower average detection limits in commercial in vitro diagnostic (IVD) assays versus LDTs (32,000 ± 75,000 versus 71,000 ± 147,000 nucleic acid amplification tests/mL; P = 0.04); however, comparison also shows that FDA review of IVD assays and LDTs did not prevent differences between initial and labeling update performance (IVD assay, P < 0.0001; LDT, P = 0.003). The regulatory shifts re-emphasized that both commercial tests and LDTs rely heavily on laboratory competence and procedures; however, lack of performance data on authorized tests, when clinically implemented, precludes assessment of the benefit related to regulatory review. Temporary regulatory deviations during the pandemic and regulatory science tools (ie, reference material) have generated valuable real-world evidence to inform pending legislation regarding LDT regulation.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2021.104820,Journal,Computers in Biology and Medicine,scopus,2021-10-01,sciencedirect,UICPC: Centrality-based clustering for scRNA-seq data analysis without user input,https://api.elsevier.com/content/abstract/scopus_id/85114481229,"scRNA-seq data analysis enables new possibilities for identification of novel cells, specific characterization of known cells and study of cell heterogeneity. The performance of most clustering methods especially developed for scRNA-seq is greatly influenced by user input. We propose a centrality-clustering method named UICPC and compare its performance with 9 state-of-the-art clustering methods on 11 real-world scRNA-seq datasets to demonstrate its effectiveness and usefulness in discovering cell groups. Our method does not require user input. However, it requires settings of threshold, which are benchmarked after performing extensive experiments. We observe that most compared approaches show poor performance due to high heterogeneity and large dataset dimensions. However, UICPC shows excellent performance in terms of NMI, Purity and ARI, respectively. UICPC is available as an R package and can be downloaded by clicking the link https://sites.google.com/view/hussinchowdhury/software.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2021.06.008,Journal,Information Sciences,scopus,2021-10-01,sciencedirect,Discriminative group-sparsity constrained broad learning system for visual recognition,https://api.elsevier.com/content/abstract/scopus_id/85113805302,"Broad Learning System (BLS) is an emerging network paradigm that has received considerable attention in the regression and classification fields. However, there are two deficiencies which seriously hinder its deployment in real applications. The first one is the internal correlations among samples are not fully considered in the modeling process. Second, the strict binary label matrix utilized in BLS provides little freedom for classification. In this paper, to address the above issues, we propose to impose group-sparsity constraints on the class-specific transformed features and label error terms, respectively. The effect is not only the more appropriate margins between data can be preserved, but also the learnt label space can be flexible for recognition. As a result, the obtained projection matrix can show more vital discriminative ability. Further, we employ the alternating direction method of multipliers to solve the resulting optimization problem. Extensive experiments and analysis on diverse benchmark databases are carried out to confirm our proposed model’s superiority in comparison with other competing classification methods.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2021.104318,Journal,Microprocessors and Microsystems,scopus,2021-10-01,sciencedirect,Investigating data representation for efficient and reliable Convolutional Neural Networks,https://api.elsevier.com/content/abstract/scopus_id/85112801148,"Nowadays, Convolutional Neural Networks (CNNs) are widely used as prediction models in different fields, with intensive use in real-time safety-critical systems. Recent studies have demonstrated that hardware faults induced by an external perturbation or aging effects, may significantly impact the CNN inference, leading to prediction failures. Therefore, ensuring the reliability of CNN platforms is crucial, especially when deployed in critical applications. A lot of effort has been made to reduce the memory and energy footprint of CNNs, paving the way to the adoption of approximate computing techniques such as quantization, reduced precision, weight sharing, and pruning. Unfortunately, approximate computing reduces the intrinsic redundancy of CNNs making them more efficient but less resilient to hardware faults. The goal of this work is twofold. First, we assess the reliability of a CNN when reduced bit widths and two different data types (floating- and fixed-point) are used to represent the network parameters (i.e., synaptic weights). Second, we intend to investigate the best compromise between data type, bit-widths reduction, and reliability. The characterization is performed through a fault injection environment built on the darknet open-source framework and targets two CNNs: LeNet-5 and YOLO. Experimental results show that fixed-point data provide the best trade-off between memory footprint reduction and CNN resilience. In particular, for LeNet-5, we achieved a 4X memory footprint reduction at the cost of a slightly reduced reliability (0.45% of critical faults) without retraining the CNN.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jappgeo.2021.104434,Journal,Journal of Applied Geophysics,scopus,2021-10-01,sciencedirect,A convolutional neural network approach to electrical resistivity tomography,https://api.elsevier.com/content/abstract/scopus_id/85112776120,"Electrical resistivity tomography (ERT) is an ill-posed and non-linear inverse problem commonly solved through deterministic gradient-based methods. These algorithms guarantee fast convergence toward the final solution but hinder accurate uncertainty assessments. On the contrary, numerical Markov Chain Monte Carlo algorithms provide accurate uncertainty appraisals but at the expense of a considerable computational effort. In this work, we develop a novel approach to ERT that guarantees an extremely fast inversion process and reliable uncertainty appraisals. The implemented method combines a Discrete Cosine Transform (DCT) reparameterization of data and model spaces with a Convolutional Neural Network. The CNN is employed to learn the inverse non-linear mapping between the DCT-compressed data and the DCT-compressed 2-D resistivity model. The DCT is an orthogonal transformation that here acts as an additional feature extraction technique that reduces the dimensionality of the input and output of the network. The DCT also acts as a regularization operator in the model space that significantly reduces the number of unknown parameters and the ill-conditioning of the inversion procedure, thereby preserving the spatial continuity of the resistivity values in the recovered solution. The estimation of model uncertainties is a key step of geophysical inverse problems and hence we implement a Monte Carlo simulation framework that propagates onto the estimated model the uncertainties related to both noise contamination and network approximation (the so-called modeling error). We first apply the approach to synthetic data to investigate its robustness in case of erroneous assumptions on the noise and model statistics used to generate the training set. Then, we demonstrate the applicability of the method through inverting real data measured along a river embankment. We also demonstrate that transfer learning avoids retraining the network from scratch when the statistical properties of training and target sets are different. Our tests confirm the suitability of the proposed approach, opening the possibility to estimate the subsurface resistivity values and the associated uncertainties in near real-time.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.oceaneng.2021.109680,Journal,Ocean Engineering,scopus,2021-10-01,sciencedirect,Linear reduced order method for design-space dimensionality reduction and flow-field learning in hull form optimization,https://api.elsevier.com/content/abstract/scopus_id/85112742342,"In the earlier stage of hull form optimization design, a series of design variables is usually needed to control the hull shape, so as to find optimal hull forms with better performance. In the surrogate-based hydrodynamic performance optimization for ships, with the increase of the dimensionality of design space, the number of new sample hulls to construct surrogate model needs to be larger, which will bring a large amount of calculation. Through reduced order method, the dimensionality of the optimization design space can be reduced while keeping the deformation range of the original design space to a great extent, for instance, using the linear combination of a smaller number of bases to represent the deformation range. In addition, in the later stage of hull form optimization design, flow field results of the new sample hulls can be fully utilized to do the dimensionality reduction multi-physics field learning. In this paper, the principle of the Proper Orthogonal Decomposition method is used and briefly introduced, the steps of dimensionality reduction of the design space are shown then, and some important problems for the design-space dimensionality reduction in the specific field of hull form optimization, such as retainability of fixed control points, irrelevance of the relative order of data to dimensionality reduction results, and decision of the new design space range after dimensionality reduction, are deep analyzed. Furthermore, taking the resistance optimization of the modified Wigley ship as an example, the specific application and error analysis of the dimensionality reduction method for design-space dimensionality reduction in the earlier stage of hull form optimization and the multi-physics field learning in the later stage of hull form optimization are given, and the applicability and reliability of the method are demonstrated by analyzing the influence of mode order and sample number on reconstruction effect of the hull shape or flow field, and the prediction effect of flow field for not-in-the-database new hull form in detail. Results show that the linear dimensionality reduction method can reduce samples needed for optimization, thus reduce the amount of calculation for the surrogate-based hull form optimization, and be used for quick prediction of multi-physics fields of any new form in the design space. Furthermore, it can not only be applied to the sensitivity analysis or a Pareto frontier selection in comprehensive performance optimization of hull form based on CFD, but also be implemented in the real-time forecast of the flow field and influence analysis of the ship performance when adjusting the hull form (or hull appendages).",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.applthermaleng.2021.117375,Journal,Applied Thermal Engineering,scopus,2021-10-01,sciencedirect,A numerical modelling of a multi-layer LaFeCoSi Active magnetic regenerator by using Artificial Neural Networks,https://api.elsevier.com/content/abstract/scopus_id/85111976602,"One of the main problems in the framework of magnetic refrigeration regards low adiabatic temperature changes that occur in the magnetocaloric materials, which limits the widespread application of this technology. Therefore, the major effort of researchers is focused on the development of multi-layer Active Magnetic Regenerators, which allows to enlarge the temperature span of a magnetic refrigerator. The use of numerical models can help to understand the feasibility of such application with less effort in comparison with the use of experimental facilities. One of the main challenges in designing a numerical model of a multi-layer Active Magnetic Regenerator is the effective incorporation of the magnetocaloric data of different magnetocaloric materials, which are fundamental to correctly optimize the configuration of such a device with the aim to improve its performance. These data are usually obtained experimentally from different measurements and their integration into the numerical model is challenging. Therefore, this work proposes a modified multi-layer Active Magnetic Regenerator numerical model based on Artificial Neural Networks to integrate the magnetocaloric properties of magnetocaloric materials, allowing an easier and a more reliable implementation of the real properties of magnetocaloric materials. The proposed model was tested simulating a four-layer and a seven-layer LaFeCoSi Active Magnetic Regenerator. The use of Artificial Neural Networks to integrate the magnetocaloric properties of magnetocaloric materials into the multi-layer Active Magnetic Regenerator allowed to improve the accuracy of the model in comparison with the commonly used technique (i.e., Curie temperature shift method) when compared to the experimental data. Indeed, the maximum error of the maximum temperature span with zero thermal load was reduced from about 13 K to 6.6 K, for the seven-layer configuration, and from about 4.1 K to 1.0 K, for the four-layer configuration. Furthermore, the new model allows to obtain more reliable simulated data about the effectiveness of each layer of the Active Magnetic Regenerator, providing a more useful tool to discuss about the optimization of its configuration. The results shows that Artificial Neural Networks can be successfully applied for integrating the magnetocaloric properties of magnetocaloric materials into a multi-layer Active Magnetic Regenerator numerical model, improving its performance. They represent an innovative way to address the problem of including magnetocaloric properties into numerical models, opening the way to other possible Machine Learning techniques as alternatives to the usual Curie temperature shifting method used in the literature to date.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2021.107720,Journal,Applied Soft Computing,scopus,2021-10-01,sciencedirect,TDMatcher: A topic-based approach to task-developer matching with predictive intelligence for recommendation,https://api.elsevier.com/content/abstract/scopus_id/85111305283,"Artificial Intelligence is currently gripping the business world, which is the next step on the journey from Big Data to full automation. As crowdsourcing has been widely adopted by more enterprises and developers, the software crowdsourcing platform is able to collect enough data. Therefore, we introduce predictive intelligence to solve complex problems. This provides a bridge between software developers and enterprises: developers look for suitable tasks, whose aim is to gain revenues with respect to their interests and abilities; enterprises look for developers that are able to complete crowdsourcing tasks and/or solve hard problems. One main problem is the prediction challenge, i.e., how to perfectly predict the developers for the software crowdsourcing tasks and make appropriate recommendations. To solve the problem, this paper introduces predictive intelligence and proposes TDMatcher, which can effectively perform task-developer pairs prediction and recommendations for software crowdsourcing. First, we builds a unified model for tasks and developers such that they can be matched in the same domain space. Second, we quantitatively measures the matching degree between tasks and developers. Third, we randomly generates potential matchings between developers and crowdsourcing tasks and then employs an MCMC sampling approach to optimize the whole process. Highly matched task-developer pairs can be achieved in the sampling process. In order to solve the cold-start problem, we constructs a social network for each new developer, which indicates that the developer’s interests/abilities to be modeled We implemented TDMatcher and evaluated it against the state-of-the-art approaches on the real-world dataset. The experimental results clearly demonstrate the superiority of TDMatcher. We measured our proposed TDMatcher through the accuracy, diversity and Harmonic Mean of TDMatcher, and found that: (1) TDMatcher outperforms the state-of-the-arts by 15+% in the prediction accuracy and 30% in diversity; and (2) TDMatcher achieves a balance between accuracy and diversity. We believe that TDMatcher provides crowdsourcing platforms with much more capabilities in finding appropriate developers to complete crowdsourcing tasks or vice versa.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.chaos.2021.111246,Journal,"Chaos, Solitons and Fractals",scopus,2021-10-01,sciencedirect,To restrict or not to restrict? Use of artificial neural network to evaluate the effectiveness of mitigation policies: A case study of Turkey,https://api.elsevier.com/content/abstract/scopus_id/85111261415,"Outbreaks, epidemics or pandemics have increased over the last years, increasing the morbidity and mortality over large geographical areas, as well as causing financial crises and irreversible social changes. Coping with emerging infectious diseases such as Covid-19, different mitigation policies are developed by countries. However, the benefit of each mitigation policy is still not well-explored due to the considerable difference between implementations of policies in each country. The question is which policies play a significant role in controlling Covid-19 transmission. Developing two models used in Artificial Neural Network, this study investigates the impact of mitigation policies or strategies (a combination of policies) by considering different vaccination and mutation scenarios. The former model requires the prediction of reproduction number based on the number of cases reported in previous days; whereas, the latter model is constructed based on the number of people impacted by a mitigation policy or strategy. Although the first model yields more accurate results, it requires the use of historical data; hence, the passage of time during a critical period of fighting against Covid-19. The benefit of the second model is that it can be implemented more quickly by determining a coefficient for each policy or strategy based on the restricted population and/or limited mobility. Testing different scenarios through a real-world example from Turkey, we find mitigation policies or strategies play a significant role in controlling Covid-19; as well as vaccination and mutation scenarios. Our results suggest continuous and predetermined mitigation policies or strategies should be implemented to control the spread of infectious diseases in addition to a successful vaccination program.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jobe.2021.102799,Journal,Journal of Building Engineering,scopus,2021-10-01,sciencedirect,A step-by-step numerical method for optimization of mechanical ventilation in deep underground enclosed parking lots: A case-design study,https://api.elsevier.com/content/abstract/scopus_id/85110290956,"To reduce polluted air, mechanical ventilation (MV) is essential for enclosed parking spaces. The traditional prescriptive design method, the index-based design, cannot guarantee ventilation performance of each fan in the enclosed parking lot. To solve this, the performance-based design approach is the best alternative that specifically addresses performance-related criteria of MV system. In this study of practice-based learning in a real construction project, we proposed a unique design optimization methodology for improving the performance of MV systems using iterative, step-by-step computational fluid dynamics (CFD) simulation. Five numerical simulation levels on seven engineering steps and a techno-economic analysis were utilized. Ultimately, fan selection was based on calculating the airflow and pressure requirements of a MV system and finding a fan of the right design to hedge against the risk of system effect and surging phenomenon. Results showed that a stable fan selection with an error of 5% of the design air flow rate could be implemented by repeating numerical analysis for the performance optimization of the MV system. When the MV design optimization was applied to the reference parking lot, the number of fans could be reduced by 30%, and energy demand of the MV system by at least 16%. Consequently, the annual energy savings was projected to recover the increase in initial investment cost in about 5.8 years. The key contribution of this research is that it overcame the limitations of the traditional index-based design for selecting the optimal fans of MV systems.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2021.107644,Journal,Applied Soft Computing,scopus,2021-10-01,sciencedirect,Production scheduling in industrial mining complexes with incoming new information using tree search and deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85109174667,"Industrial mining complexes have implemented digital technologies and advanced sensors to monitor and gather real-time data about their different operational aspects, starting from the supply of materials from the mineral deposits involved to the products provided to customers. However, technologies are not available to respond in real-time to the incoming new information to adapt the short-term production schedule of a mining complex. A short-term production schedule determines the daily/weekly/monthly sequence of extraction, the destination of materials and utilization of processing streams. This paper presents a novel self-learning artificial intelligence algorithm for mining complexes that learns, from its own experience, to adapt the short-term production scheduling decisions by responding to incoming new information. The algorithm plays the game of short-term production scheduling on its own using a Monte Carlo tree search to train a deep neural network agent that adapts the short-term production schedule with incoming new information. The deep neural network agent evaluates the short-term production scheduling decisions and, in parallel, performs searches using the Monte Carlo tree search to generate experiences. The experiences are then used to train the agent. The agent improves the strength of the tree search, which results in an even stronger self-play to generate better experiences. An application of the proposed algorithm at a real-world copper mining complex shows its exceptional performance to adapt the 13-week short-term production schedule almost in real-time. The adapted production schedule successfully meets the different production requirements and makes better use of the processing capabilities, while also increasing copper concentrate production by 7% and cash flows by 12% compared to the initial production schedule. A video of the proposed algorithm can be found at https://youtu.be/_gSbzxMc_W8.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jobe.2021.102795,Journal,Journal of Building Engineering,scopus,2021-10-01,sciencedirect,A comparative evaluation of semi-active control algorithms for real-time seismic protection of buildings via magnetorheological fluid dampers,https://api.elsevier.com/content/abstract/scopus_id/85107753497,"Semi-active vibration control is considered a powerful method in reducing the dynamic responses of buildings by using additional smart damping devices. In this study, magnetorheological (MR) dampers have been proposed as one of the semi-active control devices to mitigate the structural vibrations and improve the seismic performance of the structures. The performance of the MR dampers strongly depends on implemented controllers. Hence, the main purpose of this paper is to evaluate the efficiency of several semi-active control algorithms related to MR dampers for seismic control of civil building structures. A 5-story test structure is manufactured, and an MR damper is installed between the ground and the first floor. The performance of the semi-active control approach is experimentally evaluated on a shaking table under historical earthquake records. A neural network-based modeling approach is adopted in the inverse MR damper model for the current control. Three different control algorithms, namely Proportional-Integral-Derivative (PID), Sliding Mode (SMC) and Energy-based controller (EBC), are applied to the system in real-time. The shaking tests are also carried out on the structures with different natural frequencies by increasing the number of stories without changing the geometry and material properties of the 5-story building model. The results indicate that the SMC controller is the most effective control algorithm among all controllers in reducing the base shear force by 51%.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2021.05.013,Journal,Neural Networks,scopus,2021-10-01,sciencedirect,Streaming cascade-based speech translation leveraged by a direct segmentation model,https://api.elsevier.com/content/abstract/scopus_id/85107154939,"The cascade approach to Speech Translation (ST) is based on a pipeline that concatenates an Automatic Speech Recognition (ASR) system followed by a Machine Translation (MT) system. Nowadays, state-of-the-art ST systems are populated with deep neural networks that are conceived to work in an offline setup in which the audio input to be translated is fully available in advance. However, a streaming setup defines a completely different picture, in which an unbounded audio input gradually becomes available and at the same time the translation needs to be generated under real-time constraints. In this work, we present a state-of-the-art streaming ST system in which neural-based models integrated in the ASR and MT components are carefully adapted in terms of their training and decoding procedures in order to run under a streaming setup. In addition, a direct segmentation model that adapts the continuous ASR output to the capacity of simultaneous MT systems trained at the sentence level is introduced to guarantee low latency while preserving the translation quality of the complete ST system. The resulting ST system is thoroughly evaluated on the real-life streaming Europarl-ST benchmark to gauge the trade-off between quality and latency for each component individually as well as for the complete ST system.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2021.115081,Journal,Expert Systems with Applications,scopus,2021-10-01,sciencedirect,Utilizing 3D joints data extracted through depth camera to train classifiers for identifying suicide bomber,https://api.elsevier.com/content/abstract/scopus_id/85105277236,"Safety and security of humans is an important concern in every aspect. With the advancement in engineering, sciences, and technology (unfortunately) new methods to harm humans have also been introduced. At the same time, scientists are paying attention to the security aspects by developing new software and hardware gadgets. In comparison to the system level security, the safety/security of human beings is more important. Suicide bombing is one such nuisance that is still an open challenge for the world to detect before it is triggered. This work deals with the identification of a suicide bomber using a 3D depth camera and machine learning techniques. This work utilizes the skeletal data provided by the 3D depth camera to identify a bomber wearing a suicide jacket. The prediction is based on real-time 3D posture data of the body joints obtained through the depth camera. Using a comprehensive experimental design, a dataset is created consisting of 20 joints information obtained from 120 participants. The dataset records this for each of the participants with and without wearing a suicide jacket. Experiments are performed with the suicide jacket bearing 10- to 20-kg weight. Simulations are performed using 3D spatial features of the participants' body in four ways: full body joints (20 joints), upper-half of the body (above the spine base of the skeleton), 20 joints with 15 frames, and 20 joints with 20 frames. It is observed that 15 to 20 frames are sufficient to identify a suspected suicide bomber. The proposed framework utilize four classifiers to identify vulnerability of a subject to be a suicide bomber. Results show that the proposed framework is capable of identifying a suicide bomber with an average accuracy of 92.30%.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cofs.2021.03.014,Journal,Current Opinion in Food Science,scopus,2021-10-01,sciencedirect,Novel digital technologies implemented in sensory science and consumer perception,https://api.elsevier.com/content/abstract/scopus_id/85104656313,"New and emerging digital technologies have been implemented in sensory science, which minimize subjectivity and biases in data acquisition and interpretation compared to traditional methods. These technologies have enabled the incorporation of physiological and emotional responses of panelists elicited by food, beverage, and packaging stimuli through accurate and unbiased information from different sensor technologies. This review focused on recent advances of digital technologies used for sensory science, such as (i) software for sensory science, (ii) integration of biometrics to assess physiological and emotional responses of panelists, (iii) incorporation of virtual, augmented, and mixed reality, and (iv) sensor technology (electronic noses and tongues) for sensory analysis. Rapid data acquisition and results’ interpretation could open the way to automation and implementation of Artificial Intelligence that could revolutionize the food and beverage industries. It also presents a proposed framework for integrating and implementing digital technologies through the food chain from farm/manufacturing facilities to the palate.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rcim.2021.102176,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2021-10-01,sciencedirect,Robotic grasping: from wrench space heuristics to deep learning policies,https://api.elsevier.com/content/abstract/scopus_id/85104603575,"The robotic grasping task persists as a modern industry problem that seeks autonomous, fast implementation, and efficient techniques. Domestic robots are also a reality demanding a delicate and accurate human–machine interaction, with precise robotic grasping and handling. From decades ago, with analytical heuristics, to recent days, with the new deep learning policies, grasping in complex scenarios is still the aim of several works’ that propose distinctive approaches. In this context, this paper aims to cover recent methodologies’ development and discuss them, showing state-of-the-art challenges and the gap to industrial applications deployment. Given the complexity of the related issue associated with the elaborated proposed methods, this paper formulates some fair and transparent definitions for results’ assessment to provide researchers with a clear and standardised idea of the comparison between the new proposals.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.chroma.2021.462459,Journal,Journal of Chromatography A,scopus,2021-09-27,sciencedirect,Magnet integrated fabric phase sorptive extraction of selected endocrine disrupting chemicals from human urine followed by high-performance liquid chromatography – photodiode array analysis,https://api.elsevier.com/content/abstract/scopus_id/85112491924,"In current paper, a new advanced modification of fabric phase sorptive extraction is introduced for the first time. This advantageous configuration that integrates the stirring and extraction mechanism into a single sample preparation device was originated by equally considering the beneficial role of the increase of extraction kinetics and more specifically of diffusion on the extraction efficiency of the equilibrium based microextraction techniques and the need for integrating and unite processes for better promotion and implementation of the principles of Green Analytical Chemistry.
                  The resulted magnet integrated fabric phase sorptive extraction (MI-FPSE) device was the spearhead to develop a new analytical methodology for the determination of selected very common endocrine disrupting chemicals as model analytes in human urine by high-performance liquid chromatography-photodiode array analysis. More specifically, the sol-gel Carbowax 20 M coated on hydrophilic cellulose fabric substrate, MI-FPSE device was efficiently employed for the establishment of a new extraction protocol before the chromatographic determination. The sample preparation workflow was methodically optimized in terms of the elution solvent mixture, the volume of the sample, the extraction and the elution time, the stirring speed during the extraction, the ionic strength, and the pH of the sample matrix. The chromatographic separation was performed on a Spherisorb C18 column and a gradient elution program within 14 minutes. Mobile phase consisted of 0.05 ammonium acetate aqueous solution and acetonitrile. The method was validated towards linearity, sensitivity, selectivity, precision, accuracy, and stability. LOD and LOQ ranged between 1.05-1.80 and 3.5-6.0 ng/mL, while %RSD values were found lower than 9.0% in all cases. The method was efficiently applied to the bioanalysis of real samples. All the chosen EDCs were measured at high detection levels. The new MI-FPSE device has demonstrated its performance superiority as a magnet integrated stand-alone extraction device and could be considered as a significant improvement in the field of analytical/bioanalytical sample preparation.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2021.107302,Journal,Knowledge-Based Systems,scopus,2021-09-27,sciencedirect,A novel deep quantile matrix completion model for top-N recommendation[Formula presented],https://api.elsevier.com/content/abstract/scopus_id/85111890353,"Matrix completion models have been receiving keen attention due to their wide applications in science and engineering. However, the majority of these models assumes a symmetric noise distribution in their completion processes and uses conditional mean to characterize data distribution in a data set, the assumption of which incurs noticeable bias toward outliers. Recognizing the fact that noise distribution tends to be asymmetric in the real-world, this paper proposes a novel Deep Quantile Matrix Completion model, abbreviated as DQMC, which aims to accurately capture noise distribution in a data set by modeling conditional quantile of the data set instead of its conditional mean as traditionally handled by many state-of-the-art methods. Implemented via a deep computing paradigm, the newly proposed model maps a data set from its input space to the latent spaces through a two-branched deep autoencoder network. Such a mapping can effectively capture complex information latent in the data set. The proposed model is empowered by two key designed elements, including: (1) its two-branched deep autoencoder network that provides a flexible computing pathway to attain completion results with a high quality; (2) the introduction of a quantile loss function in combination with the proposed deep network, leading to a new unsupervised learning algorithm for tackling the matrix completion tasks with a superior capability. Comparative experimental results consistently demonstrate the superiority of the proposed DQMC model in conducting the top-N recommendation tasks involving both explicit and implicit rating data sets with respect to a series of state-of-the-art recommendation algorithms.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2021.04.091,Journal,Neurocomputing,scopus,2021-09-24,sciencedirect,Quantum maximum mean discrepancy GAN,https://api.elsevier.com/content/abstract/scopus_id/85107052048,"Generative adversarial network (GAN) has shown profound power in machine learning. It inspires many researchers from other fields to create powerful tools for various tasks, including quantum state preparation, quantum circuit translation, and so on. It is known as classical techniques cannot efficiently simulate the quantum system, and the existing works haven’t investigated the quantum version of maximum mean discrepancy as the metric in learning models and applied it to quantum data. In this paper, we propose a metric named quantum maximum mean discrepancy (qMMD), which can be used to measure the distance between quantum data in Hilbert space. Based on the qMMD, we then design a quantum generative adversarial model, named qMMD-GAN, under the hybrid quantum–classical methods. We also provide the construction of qMMD-GAN that can be easily implemented on a quantum device. We demonstrate the power of our qMMD-GAN by applying it to a crucial real-world application that is generating an unknown quantum state. Our numerical experiments show that qMMD-GAN has a competitive performance compared to existing results. We believe that the hybrid-based models will not only be applied to physics research but provide a new direction for improving classical data processing tasks.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.xpro.2021.100639,Journal,STAR Protocols,scopus,2021-09-17,sciencedirect,Timesias: A machine learning pipeline for predicting outcomes from time-series clinical records,https://api.elsevier.com/content/abstract/scopus_id/85108953840,"The prediction of outcomes is a critical part of the clinical surveillance for hospitalized patients. Here, we present Timesias, a machine learning pipeline which predicts outcomes from real-time sequential clinical data. The strategy implemented in Timesias is the first-place solution in the crowd-sourcing DII (discover, innovate, impact) National Data Science Challenge involving more than 100,000 patients, achieving 0.85 as evaluated by AUROC (area under receiver operator characteristic curve) in predicting the early onset of sepsis status. Timesias is freely available via PyPI and GitHub.
                  For complete details on the use and execution of this protocol, please refer to Guan et al. (2021).",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scitotenv.2021.147539,Journal,Science of the Total Environment,scopus,2021-09-15,sciencedirect,Seasonal dynamics in the number and composition of coliform bacteria in drinking water reservoirs,https://api.elsevier.com/content/abstract/scopus_id/85110295909,"Worldwide, surface waters like lakes and reservoirs are one of the major sources for drinking water production, especially in regions with water scarcity. In recent years, increased numbers of coliform bacteria have been observed in these surface waters. In our monitoring study we analyzed two drinking water reservoirs (Klingenberg and Kleine Kinzig Reservoir) over a two-year period in 2018 and 2019. We detected high numbers of coliform bacteria up to 2.4 × 104 bacteria per 100 ml during summer months, representing an increase of four orders of magnitude compared to winter. Diversity decreased to one or two species that dominated the entire water body, namely Enterobacter asburiae and Lelliottia spp., depending on the reservoir. Interestingly, the same, very closely related strains have been found in several reservoirs from different regions. Fecal indicator bacteria Escherichia coli and enterococci could only be detected in low concentrations. Furthermore, fecal marker genes were not detected in the reservoir, indicating that high concentrations of coliform bacteria were not due to fecal contamination. Microbial community revealed Frankiales and Burkholderiales as dominant orders. Enterobacterales, however, only had a frequency of 0.04% within the microbial community, which is not significantly affected by the extreme change in coliform bacteria number. Redundancy analysis revealed water temperature, oxygen as well as nutrients and metals (phosphate, manganese) as factors affecting the dominant species. We conclude that this sudden increase of coliform bacteria is an autochthonic process that can be considered as a mass proliferation or “coliform bloom” within the reservoir. It is correlated to higher water temperatures in summer and is therefore expected to occur more frequently in the near future, challenging drinking water production.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.anucene.2021.108355,Journal,Annals of Nuclear Energy,scopus,2021-09-15,sciencedirect,Large-scale design optimisation of boiling water reactor bundles with neuroevolution,https://api.elsevier.com/content/abstract/scopus_id/85105888765,"We combine advances in deep reinforcement learning (RL) with evolutionary computation to perform large-scale optimisation of boiling water reactor (BWR) bundles using CASMO4/SIMULATE3 codes; capturing fine details, radial/axial fuel heterogeneity, and real-world constraints. RL constructs neural networks that learn how to assign fuel and poison enrichment by narrowing the search space into the areas where human/physics knowledge demonstrate merit. Evolution strategies diversify the search in these areas, through obtaining guidance from RL candidates. With very efficient/parallel implementation, our optimisation approach is able to solve a coupled multi-zone BWR bundle optimisation with 
                        
                           ~
                        
                     40 constraints. The methodology is applied to a GE14-10×10 bundle, showing the ability of neuroevolution to find 
                        
                           ~
                        
                     100 feasible designs. The optimal bundle has 7 axial zones with non-uniform enrichment radially and axially. The results of this work also demonstrate that our neuroevolution methodology is sufficiently generic to adapt to other assembly and reactor designs with minor adjustments.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.foodchem.2021.129710,Journal,Food Chemistry,scopus,2021-09-15,sciencedirect,Lateral flow immunoassay for the simultaneous detection of fipronil and its metabolites in food samples,https://api.elsevier.com/content/abstract/scopus_id/85103939922,"We developed a sensitive and rapid lateral flow immunochromatographic (LFI) assay for the simultaneous detection of fipronil and its metabolites in eggs and cucumbers using gold nanoparticle (GNP)-labeled monoclonal antibodies (mAbs). Anti-fipronil mAbs (1B6) were produced using two haptens and identified by heterologous indirect competitive enzyme-linked immunosorbent assay (icELISA) with half maximal inhibitory concentration (IC50) and limit of detection (LOD) values of 0.46 ± 0.07 and 0.05 ± 0.01 ng mL−1, respectively. The developed LFI strip showed high sensitivity and specificity in the detection of fipronil with cut-off and visual limit of detection (vLOD) values of 10 and 0.25 ng mL−1, respectively. Furthermore, the application of LFI in the detection of fipronil-spiked egg and cucumber samples was validated by liquid chromatography tandem mass spectrometry (LC-MS/MS). Our developed LFI assay is suitable for detection of fipronil and its metabolites in real samples.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.pmcj.2021.101459,Journal,Pervasive and Mobile Computing,scopus,2021-09-01,sciencedirect,REAM: A Framework for Resource Efficient Adaptive Monitoring of Community Spaces,https://api.elsevier.com/content/abstract/scopus_id/85113273806,"Nowadays, many Internet-of-Things (IoT) devices with rich sensors and actuators are being deployed to monitor community spaces. The data generated by these devices are analyzed and turned into actionable information by analytics operators. In this article, we present a Resource Efficient Adaptive Monitoring (REAM) framework at the edge that adaptively selects workflows of devices and analytics to maintain an adequate quality of information for the applications at hand while judiciously consuming the limited resources available on edge servers. Since community spaces are complex and in a state of continuous flux, developing a one-size-fits-all model that works for all spaces is infeasible. The REAM framework utilizes reinforcement learning agents that learn by interacting with each community space and make decisions based on the state of the environment in each space and other contextual information. We demonstrate the resource-efficient monitoring capabilities of REAM on two real-world testbeds in Orange County, USA and NTHU, Taiwan, where we show that community spaces using REAM can achieve 
                        
                           >
                           90
                           %
                        
                      monitoring accuracy while incurring 
                        
                           ∼
                           50
                           %
                        
                      less resource consumption costs compared to existing static monitoring approaches. We also show REAM’s awareness of network link quality in its decision-making, resulting in a 42% improvement in accuracy over network agnostic approaches.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.clsr.2021.105564,Journal,Computer Law and Security Review,scopus,2021-09-01,sciencedirect,Legal evaluation of the attacks caused by artificial intelligence-based lethal weapon systems within the context of Rome statute,https://api.elsevier.com/content/abstract/scopus_id/85112789421,"Artificial intelligence (AI) as of the level of development reached today has become a scientific reality that is subject to study in the fields of law, political science, and other social sciences besides computer and software engineering. AI systems which perform relatively simple tasks in the early stages of the development period are expected to become fully or largely autonomous in the near future. Thanks to this, AI which includes the concepts of machine learning, deep learning, and autonomy, has begun to play an important role in producing and using smart arms. However, questions about AI-Based Lethal Weapon Systems (AILWS) and attacks that can be carried out by such systems have not been fully answered under legal aspect. More particularly, it is a controversial issue who will be responsible for the actions that an AILWS has committed. In this article, we discussed whether AILWS can commit offense in the context of the Rome Statute, examined the applicable law regarding the responsibility of AILWS, and tried to assess whether these systems can be held responsible in the context of international law, crime of aggression, and individual responsibility. It is our finding that international legal rules including the Rome Statute can be applied regarding the responsibility for the act/crime of aggression caused by AILWS. However, no matter how advanced the cognitive capacity of an AI software, it will not be possible to resort to the personal responsibility of this kind of system since it has no legal personality at all. In such a case, responsibility will remain with the actors who design, produce, and use the system. Last but not least, since no AILWS software does have specific codes of conduct that can make legal and ethical reasonings for today, at the end of the study it was recommended that states and non-governmental organizations together with manifacturers should constitute the necessary ethical rules written in software programs to prevent these systems from unlawful acts and to develop mechanisms that would restrain AI from working outside human control.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.urology.2021.06.008,Journal,Urology,scopus,2021-09-01,sciencedirect,Robot-assisted Magnetic Resonance Imaging-ultrasound Fusion Transperineal Targeted Biopsy,https://api.elsevier.com/content/abstract/scopus_id/85110653934,"Objective
                  To demonstrate the key steps to perform robot-assisted magnetic resonance imaging-ultrasound fusion transperineal prostate biopsy.
               
                  Materials and methods
                  Men with suspicion of prostate cancer underwent 3-Tesla multi-parametric MRI and were assigned a Prostate Imaging Reporting and Data System v2 score (PI-RADS). The prostate outline and suspicious lesions were marked by our radiologist using our software to produce a 3-dimensional prostate MRI model. All biopsies were performed under general anaesthesia and the real-time transrectal ultrasound model is created and subsequently fused with the MRI model using non-rigid software fusion. Transperineal targeted and systematic biopsy were then performed under stereotactic guidance using our robot-assisted prostate biopsy platform. Our clinically significant prostate cancer (Grade group ≥2) detection rates were previously described.
                        1
                     
                  
               
                  Results
                  Out of the 433 patients who underwent targeted and systematic biopsy, clinically-significant cancer detection rate was 46% (85% for PI- RADS 5 vs 38% for PI-RADS 4 vs 16% for PI-RADS 3; P < .001). Our overall complication rate was 13%, out of which the majority were Clavien-Dindo I (99%). The most common complications encountered were urinary retention (10%) and significant gross hematuria requiring bladder irrigation (2%). A higher prostate volume was associated with greater odds of urinary retention (OR 1.4, 95% CI: 1.21-1.65, P < .001 for every 10 mL increase in prostate volume). There was only 1 reported case of mild urinary tract infection.
               
                  Conclusion
                  Robot-assisted transperineal prostate biopsy has established itself as a reliable and accurate method of prostate cancer detection with minimal morbidity.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jstrokecerebrovasdis.2021.105962,Journal,Journal of Stroke and Cerebrovascular Diseases,scopus,2021-09-01,sciencedirect,StrokeWatch: An Instrument for Objective Standardized Real-Time Measurement of Door-to-Needle Times in Acute Ischemic Stroke Treatment,https://api.elsevier.com/content/abstract/scopus_id/85109982805,"Objectives
                  Monitoring critical time intervals in acute ischemic stroke treatment delivers metrics for quality of performance – the door-to-needle time being well-established. To resolve the conflict of self-reporting bias a “StrokeWatch” was designed – an instrument for objective standardized real-time measurement of procedural times.
               
                  Materials and methods
                  An observational, monocentric analysis of patients receiving intravenous thrombolysis for acute ischemic stroke between January 2018 and September 2019 was performed based on an ongoing investigator-initiated, prospective, and blinded endpoint registry. Patient data and treatment intervals before and after introduction of ""StrokeWatch"" were compared.
               
                  Results
                  “StrokeWatch” was designed as a mobile board equipped with three digital stopwatches tracking door-to-needle, door-to-groin, and door-to-recanalization intervals as well as a form for standardized documentation. 118 patients before introduction of “StrokeWatch” (subgroup A) and 53 patients after introduction of “StrokeWatch” (subgroup B) were compared. There were no significant differences in baseline characteristics, procedural times, or clinical outcome. A non-significant increase in patients with door-to-needle intervals of 60 min or faster (93.2 vs 98.1%, p = 0.243) and good functional outcome (mRS d90 ≤ 2, 47.5 vs 58.5%, p = 0.218) as well as a significant increase in reports of delayed arrival of intra-hospital patient transport service (0.8 vs 13.2%, p = 0.001) were observed in subgroup B.
               
                  Conclusions
                  The implementation of StrokeWatch for objective standardized real-time measurement of door-to-needle times is feasible in a real-life setting without negative impact on procedural times or outcome. It helped to reassure a high-quality treatment standard and reveal factors associated with procedural delays.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2021.103830,Journal,Robotics and Autonomous Systems,scopus,2021-09-01,sciencedirect,Visual recognition of gymnastic exercise sequences. Application to supervision and robot learning by demonstration,https://api.elsevier.com/content/abstract/scopus_id/85109177424,"This work presents a novel software architecture to autonomously identify and evaluate the gymnastic activity that people are carrying out. It is composed of three different interconnected layers. The first corresponds to a Multilayer Perceptron (MLP) trained from a set of angular magnitudes derived from the information provided by the OpenPose library. This library works frame by frame, so some postures may be incorrectly detected due to eventual occlusions. The MLP layer makes it possible to accurately identify the posture a person is performing. A second layer, based on a Hidden Markov Model (HMM) and the Viterbi algorithm, filters the incorrect spurious postures. Thus, the accuracy of the algorithm is improved, leading to a precise sequence of postures. A third layer identifies the current exercise and evaluates whether the person is doing it at a correct speed. This layer uses an innovative Modified Levenshtein Distance (MLD), which considers not only the number of operations to transform a given sequence, but also the nature of the elements participating in the comparison. The system works in real time with little delay, thus recognizing sequences of arbitrary length and providing continuous feedback on the exercises being performed. An experiment carried out consisted in reproducing the output of the second layer on an autonomous Pepper robot that can be used in environments where physical exercise is performed, such as a residence for the elderly or others. It has reproduced different exercises previously executed by an instructor so that people can copy the robot. The article analyzes the current situation of the automated gymnastic activities recognition, presents the architecture, the different experiments carried out and the results obtained. The integration of the three components (MLP, HMM and MLD) results in a robust system that has allowed us to improve the results of previous works.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.egyai.2021.100101,Journal,Energy and AI,scopus,2021-09-01,sciencedirect,Development of a Soft Actor Critic deep reinforcement learning approach for harnessing energy flexibility in a Large Office building,https://api.elsevier.com/content/abstract/scopus_id/85109095539,"This research is concerned with the novel application and investigation of ‘Soft Actor Critic’ based deep reinforcement learning to control the cooling setpoint (and hence cooling loads) of a large commercial building to harness energy flexibility. The research is motivated by the challenge associated with the development and application of conventional model-based control approaches at scale to the wider building stock. Soft Actor Critic is a model-free deep reinforcement learning technique that is able to handle continuous action spaces and which has seen limited application to real-life or high-fidelity simulation implementations in the context of automated and intelligent control of building energy systems. Such control techniques are seen as one possible solution to supporting the operation of a smart, sustainable and future electrical grid. This research tests the suitability of the technique through training and deployment of the agent on an EnergyPlus based environment of the office building. The agent was found to learn an optimal control policy that was able to minimise energy costs by 9.7% compared to the default rule-based control scheme and was able to improve or maintain thermal comfort limits over a test period of one week. The algorithm was shown to be robust to the different hyperparameters and this optimal control policy was learnt through the use of a minimal state space consisting of readily available variables. The robustness of the algorithm was tested through investigation of the speed of learning and ability to deploy to different seasons and climates. It was found that the agent requires minimal training sample points and outperforms the baseline after three months of operation and also without disruption to thermal comfort during this period. The agent is transferable to other climates and seasons although further retraining or hyperparameter tuning is recommended.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.adhoc.2021.102562,Journal,Ad Hoc Networks,scopus,2021-09-01,sciencedirect,Developing novel low complexity models using received in-phase and quadrature-phase samples for interference detection and classification in Wireless Sensor Network and GPS edge devices,https://api.elsevier.com/content/abstract/scopus_id/85107952090,"Despite Wireless Sensor Networks (WSNs) significantly developing over the past decade, these networks, like most wireless networks, remain susceptible to malicious interference and spectrum coexistence. Other vulnerabilities arise as WSN applications adopt open standards and typically resource and energy-constrained commercial-off-the-shelf equipment. Deployments include safety-critical applications such as the internet of things, medical, aerospace and space and deep-sea exploration. To manage safety and privacy requirements across such a diverse wireless landscape, security on wireless edge devices needs improvement while maintaining low complexity. This paper improves wireless edge device security by developing a novel intelligent interference diagnostic framework. Received in-phase (I) and quadrature-phase (Q) samples are exclusively utilized to detect modern, subtle and traditional crude jamming attacks. This I/Q sample utilization inherently enables decentralized decision-making, where the low-order features were extracted in a previous study focused on classifying typical 2.4–2.5 GHz wireless signals. The associated optimal intelligent models are leveraged as the foundation for this paper’s work. Initially, Matlab Monte Carlo simulations investigate the ideal case, which incorporates no hardware limitations, identifies the required data type of signal interactions and motivates a hardware investigation. Software-defined radios (SDRs) collect the required live over-the-air I/Q data and transmit matched signal (ZigBee) and continuous-wave interference in developed ZigBee wireless testbeds. Low complexity supervised machine learning models are developed based exclusively on the low-order features and achieve an average accuracy among the developed models above 98%. The designed methodology involves examining ZigBee over-the-air data for artificial jamming and SDR jamming of ZigBee signals transmitted from SDR and commercial (XBee) sources. This approach expands to a legitimate node classification technique and an overall algorithm for wireless edge device interference diagnostic tools. The investigation includes developing Support Vector Machine, XGBoost and Deep Neural Network (DNN) models, where XGBoost is optimal. Adapting the optimized models to global positioning system signals establishes the transferability of the designed methodology. Implementing the designed approaches on a Raspberry Pi embedded device examines a relatively resource-constrained deployment. The primary contribution is the real experimentally validated interference diagnostic framework that enables independent device operation, as no channel assumptions, network-level information or spectral images are required. Developed models exclusively use I/Q data low-order features and achieve high accuracy and generalization to unseen data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scs.2021.103071,Journal,Sustainable Cities and Society,scopus,2021-09-01,sciencedirect,A stochastic machine learning based approach for observability enhancement of automated smart grids,https://api.elsevier.com/content/abstract/scopus_id/85107608455,"This paper develops a machine learning aggregated integer linear programming approach for the full observability of the automated smart grids by positioning of micro-synchrophasor units, taking into account the reconfigurable structure of the distribution systems. The proposed stochastic approach presents a strategy occurring in several stages to micro-synchrophasor unit positioning based on the load level and demand in the system and based on the pre-determined sectionalizing and tie switches. Such a technique can also deploy the zero-injection limitations of the model and reduce the search space of the problem. Moreover, a novel method based on whale optimization method (WOM) is introduced to simultaneously enhance the reliability indices in order to specify the optimum topology for each phase and reduce the costs of power losses and customer interruptions. Although the problem of micro-synchrophasor placement is formulated in an integer linear programming framework, the restructuring technique is resolved on the basis of the WOM heuristic approach. Considering the uncertainty due to the metering devices or forecast errors, a stochastic framework based on point estimation is deployed to handle the uncertainty effects. The simulation and numerical results on a real system verify that the proposed method assures visibility of the distribution network pre and post reconfiguration in the time horizon of the planning. Furthermore, the results show that the system observability can be guaranteed at different load levels even though the system experiences different reconfiguration and topologies.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.sysarc.2021.102183,Journal,Journal of Systems Architecture,scopus,2021-09-01,sciencedirect,Memory-efficient deep learning inference with incremental weight loading and data layout reorganization on edge systems,https://api.elsevier.com/content/abstract/scopus_id/85107073021,"Pattern recognition applications such as face recognition and agricultural product detection have drawn a rapid interest on Cyber–Physical–Social-Systems (CPSS). These CPSS applications rely on the deep neural networks (DNN) to conduct the image classification. However, traditional DNN inference models in the cloud could suffer from network delay fluctuations and privacy leakage problems. In this regard, current real-time CPSS applications are preferred to be deployed on edge-end embedded devices. Constrained by the computing power and memory limitations of edge devices, improving the memory management efficacy is the key to improving the quality of service for model inference. First, this study explored the incremental loading strategy of model weights for the model inference. Second, the memory space at runtime is optimized through data layout reorganization from the spatial dimension. In particular, the proposed schemes are orthogonal to existing models. Experimental results demonstrate that the proposed approach reduced the memory consumption by 61.05% without additional inference time overhead.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2021.107418,Journal,Applied Soft Computing,scopus,2021-09-01,sciencedirect,Development and experimental realization of an adaptive neural-based discrete model predictive direct torque and flux controller for induction motor drive,https://api.elsevier.com/content/abstract/scopus_id/85104714129,"This paper develops a neural network-based discrete predictive direct torque and flux control (NNPDTFC) for induction motor drive with the space vector modulation (SVM) technique. Moreover, this SVM technique with NNPDTFC is implemented to activate the inverter in the two-level operation and the performance is compared with the conventional PI direct torque and flux control (PIDTFC) technique. The PSO based model predictive control incorporated with the neural network is developed here in the NNPDTFC and is analyzed using MATLAB software. Disturbance reduction, simple control, and real-time implementation are the major features of NNPDTFC and it also enhances the transient performance of the motor drive by reducing settling time and peak overshoot. In addition, the flux and the torque ripples are significantly improved using the proposed NNPDTFC technique which is extensively used for the fast dynamic response of the induction motor drives as compared to PIDTFC. In order to show the potentiality of the proposed controller, a prototype controller is developed and validated with the laboratory setup and the control signals are generated for both NNPDTFC and PIDTFC using a low-cost Digital signal processor (DSP) controller which is fed to the induction motor of 3.7 kW capacity in the real-time platform. It is observed that the results with NNPDTFC are not only found to be extremely satisfactory even with the system and parameter uncertainties and external load perturbations but also, it produces enhanced dynamic as well as steady-state performance along with the reduced ripples in the signal flux, torque, and current compared to that of PIDTFC.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.chbr.2021.100146,Journal,Computers in Human Behavior Reports,scopus,2021-08-01,sciencedirect,Intelligent autonomous agents and trust in virtual reality,https://api.elsevier.com/content/abstract/scopus_id/85125679082,"Intelligent autonomous agents (IAA) are proliferating and rapidly evolving due to the exponential growth in computational power and recent advances, for instance, in artificial intelligence research. Ranging from chatbots, over personal virtual assistants and medical decision-aiding systems, to self-driving or self-piloting systems, whether unbeknownst to the users or not, IAA are increasingly integrated into many aspects of daily life. Despite this technological development, many people remain skeptical of such agents. Conversely, others might have excessive confidence in them. Therefore, establishing an appropriate level of trust is crucial to the successful deployment of IAA in everyday contexts. Virtual Reality (VR) is another domain where IAA play a significant role, yet its experiential and immersive character particularly allows for new ways of interaction and tackling trust-related issues. In this article, we provide an overview of the numerous factors involved in establishing trust between users and IAA, spanning scientific disciplines as diverse as psychology, philosophy, sociology, computer science, and economics. Focusing on VR, we discuss the different types and definitions of trust and identify foundational factors classified into three interrelated dimensions: Human-Technology, Human-System, and Interpersonal. Based on this taxonomy, we identify open issues and a research agenda towards facilitating the study of trustful interaction and collaboration between users and IAA in VR settings.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S2589-7500(21)00086-8,Journal,The Lancet Digital Health,scopus,2021-08-01,sciencedirect,Application of Comprehensive Artificial intelligence Retinal Expert (CARE) system: a national real-world evidence study,https://api.elsevier.com/content/abstract/scopus_id/85111153013,"Background
                  Medical artificial intelligence (AI) has entered the clinical implementation phase, although real-world performance of deep-learning systems (DLSs) for screening fundus disease remains unsatisfactory. Our study aimed to train a clinically applicable DLS for fundus diseases using data derived from the real world, and externally test the model using fundus photographs collected prospectively from the settings in which the model would most likely be adopted.
               
                  Methods
                  In this national real-world evidence study, we trained a DLS, the Comprehensive AI Retinal Expert (CARE) system, to identify the 14 most common retinal abnormalities using 207 228 colour fundus photographs derived from 16 clinical settings with different disease distributions. CARE was internally validated using 21 867 photographs and externally tested using 18 136 photographs prospectively collected from 35 real-world settings across China where CARE might be adopted, including eight tertiary hospitals, six community hospitals, and 21 physical examination centres. The performance of CARE was further compared with that of 16 ophthalmologists and tested using datasets with non-Chinese ethnicities and previously unused camera types. This study was registered with ClinicalTrials.gov, NCT04213430, and is currently closed.
               
                  Findings
                  The area under the receiver operating characteristic curve (AUC) in the internal validation set was 0·955 (SD 0·046). AUC values in the external test set were 0·965 (0·035) in tertiary hospitals, 0·983 (0·031) in community hospitals, and 0·953 (0·042) in physical examination centres. The performance of CARE was similar to that of ophthalmologists. Large variations in sensitivity were observed among the ophthalmologists in different regions and with varying experience. The system retained strong identification performance when tested using the non-Chinese dataset (AUC 0·960, 95% CI 0·957–0·964 in referable diabetic retinopathy).
               
                  Interpretation
                  Our DLS (CARE) showed satisfactory performance for screening multiple retinal abnormalities in real-world settings using prospectively collected fundus photographs, and so could allow the system to be implemented and adopted for clinical care.
               
                  Funding
                  This study was funded by the National Key R&D Programme of China, the Science and Technology Planning Projects of Guangdong Province, the National Natural Science Foundation of China, the Natural Science Foundation of Guangdong Province, and the Fundamental Research Funds for the Central Universities.
               
                  Translation
                  For the Chinese translation of the abstract see Supplementary Materials section.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jprocont.2021.06.004,Journal,Journal of Process Control,scopus,2021-08-01,sciencedirect,Online reinforcement learning for a continuous space system with experimental validation,https://api.elsevier.com/content/abstract/scopus_id/85111075597,"Reinforcement learning (RL) for continuous state/action space systems has remained a challenge for nonlinear multivariate dynamical systems even at a simulation level. Implementing such schemes for real-time control is still of a difficulty and remains largely unanswered. In this study, several critical strategies for practical implementation of RL are developed, and a multivariable, multi-modal, hybrid three-tank (HTT) physical process is utilized to illustrate the proposed strategies. A successful real-time implementation of RL is reported. The first step is a meta-heuristic first principles model parameter optimization, where a custom pseudo random binary signal (PRBS) is used to obtain open-loop experimental data. This is followed by in silico asynchronous advantage actor–critic (A3C/A-A2C) based policy learning. In the second step, three different approaches (namely proximal learning, single trajectory learning, and multiple trajectory learning) are utilized to explore the state/action space. In the final step, online learning (A2C) using the best in silico policy on the real process using a socket connection is established. The extent of exploration (EoE, a measure of exploration) is proposed as a parameter for quantifying exploration of the state/action space. While the online sample efficiency of RL application is enhanced, a soft constraint based constrained learning is proposed and validated. With considerations of the proposed strategies, this work demonstrates the possibility of applying RL to solve practical control problems.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2021.103854,Journal,Journal of Biomedical Informatics,scopus,2021-08-01,sciencedirect,"A generalized kernel machine approach to identify higher-order composite effects in multi-view datasets, with application to adolescent brain development and osteoporosis",https://api.elsevier.com/content/abstract/scopus_id/85110205594,"In recent years, a comprehensive study of complex disease with multi-view datasets (e.g., multi-omics and imaging scans) has been a focus and forefront in biomedical research. State-of-the-art biomedical technologies are enabling us to collect multi-view biomedical datasets for the study of complex diseases. While all the views of data tend to explore complementary information of disease, analysis of multi-view data with complex interactions is challenging for a deeper and holistic understanding of biological systems. In this paper, we propose a novel generalized kernel machine approach to identify higher-order composite effects in multi-view biomedical datasets (GKMAHCE). This generalized semi-parametric (a mixed-effect linear model) approach includes the marginal and joint Hadamard product of features from different views of data. The proposed kernel machine approach considers multi-view data as predictor variables to allow a more thorough and comprehensive modeling of a complex trait. We applied GKMAHCE approach to both synthesized datasets and real multi-view datasets from adolescent brain development and osteoporosis study. Our experiments demonstrate that the proposed method can effectively identify higher-order composite effects and suggest that corresponding features (genes, region of interests, and chemical taxonomies) function in a concerted effort. We show that the proposed method is more generalizable than existing ones. To promote reproducible research, the source code of the proposed method is available at.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2021.103848,Journal,Journal of Biomedical Informatics,scopus,2021-08-01,sciencedirect,Face mask detection using deep learning: An approach to reduce risk of Coronavirus spread,https://api.elsevier.com/content/abstract/scopus_id/85109043381,"Effective strategies to restrain COVID-19 pandemic need high attention to mitigate negatively impacted communal health and global economy, with the brim-full horizon yet to unfold. In the absence of effective antiviral and limited medical resources, many measures are recommended by WHO to control the infection rate and avoid exhausting the limited medical resources. Wearing a mask is among the non-pharmaceutical intervention measures that can be used to cut the primary source of SARS-CoV2 droplets expelled by an infected individual. Regardless of discourse on medical resources and diversities in masks, all countries are mandating coverings over the nose and mouth in public. To contribute towards communal health, this paper aims to devise a highly accurate and real-time technique that can efficiently detect non-mask faces in public and thus, enforcing to wear mask. The proposed technique is ensemble of one-stage and two-stage detectors to achieve low inference time and high accuracy. We start with ResNet50 as a baseline and applied the concept of transfer learning to fuse high-level semantic information in multiple feature maps. In addition, we also propose a bounding box transformation to improve localization performance during mask detection. The experiment is conducted with three popular baseline models viz. ResNet50, AlexNet and MobileNet. We explored the possibility of these models to plug-in with the proposed model so that highly accurate results can be achieved in less inference time. It is observed that the proposed technique achieves high accuracy (98.2%) when implemented with ResNet50. Besides, the proposed model generates 11.07% and 6.44% higher precision and recall in mask detection when compared to the recent public baseline model published as RetinaFaceMask detector. The outstanding performance of the proposed model is highly suitable for video surveillance devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijdrr.2021.102397,Journal,International Journal of Disaster Risk Reduction,scopus,2021-08-01,sciencedirect,Twitter chirps for Syrian people: Sentiment analysis of tweets related to Syria Chemical Attack,https://api.elsevier.com/content/abstract/scopus_id/85108873548,"Purpose
                  The sentiment analysis of tweets provides information about peoples’ attitudes and perceptions towards an event. The current study showcases the role of Twitter in a crisis by analyzing the nature of tweets and the sentiments expressed by the Twitter-sphere during and after the “Khan Shaykhun Syria Chemical Attack.""
               
                  Methodology
                  A total of 13,156 tweets posted in English on Twitter during the first 27 days of the attack were downloaded and considered for the study. The content analysis of the tweets was done manually, and accordingly, the sentiments of the tweets were highlighted through eight broader categories. Furthermore, to visualize the positive, negative, and neutral sentiments of the tweets, the Orange Data 
                     M
                     ining Software, a powerful toolkit for machine learning, data mining, and data visualization, was used. VOSviewer (a software tool used for creating maps based on network data and for visualizing and exploring the maps) was also used to visualize the word frequency of the tweets.
               
                  Findings
                  Twitter is primarily used for situational awareness and acts as an emotional, social support system by sharing sentiments. 35.71% of the tweets are associated with ""
                     sharing news and information"" , with just 2.12% ""
                     supporting the government"". People mostly retweet the tweets that “criticize the government,” with an average retweet count of 15.84, followed by the ones “evincing emotions” (12.21). However, tweets that “raise questions” (3.32) and “provide suggestions” (2.51) fail to gain the attention of too many tweeter users, thus having less impact. People mostly like the tweets that “
                     support 
                     government” and “evince emotions,” with such tweets on an average receiving 9.89 and 8.37 likes, respectively. Individuals post a large number of tweets (10,137; 77.05%), followed by news channels (1157; 8.79%) and organizations of varied nature (950; 7.22%). However, 912 (6.93%) tweets are posted by users of anonymous nature. Text and text with images form most tweets contributing to 8061 (61.27%) and 3137 (23.84%) of the total tweet count. However, none of the tweets contain video only, and just 3 (0.02%) tweets embed only images. Text-video and text-image formats are highly re-tweeted and liked. It is evident that 53.70% of the tweets (n = 7065) reflect negative sentiments, while 12.67% (n = 1667) emulate positive sentiments and, 33.63% (n = 4424) showcase a neutral perception about the attack. One can visualize the U.S.A. among the top tweeting countries with the highest percentage of positive sentiments, followed by Canada and Israel. Turkey outscores all the countries in terms of negative tweets, followed by Syria and U.K. However, in terms of neutral tweets, Germany ranks first, followed by Iran and Canada. The tweets pour mainly for the first few days, indicating the concern of users for the victims. Later on, a declining trend of tweets is witnessed. “idlib”, “Syria”, “Syria chemical attack,” and “Assad” are the leading words used more than a thousand times in the tweets.
               
                  Research implications
                  The current study adds to the growing body of knowledge to the existing literature on Twitter and its use to narrowcast situational awareness during crisis episodes. One of the implications of the study is that the news agencies highly exploit the sharing side of Twitter during disasters by communicating real-time and unique information, create situational awareness, and connect to the digital audience. Twitter acts as an emotional outlet that facilitates the mining of condensed varied reactions towards an event to frame disaster response strategies and provides a sociological understanding of social media use during the crisis by the victims and viewers.
               
                  Originality
                  The study represents the sentiments of the Twitter-sphere towards the “Syria Chemical Attack.""",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.isprsjprs.2021.05.019,Journal,ISPRS Journal of Photogrammetry and Remote Sensing,scopus,2021-08-01,sciencedirect,Rapid and large-scale mapping of flood inundation via integrating spaceborne synthetic aperture radar imagery with unsupervised deep learning,https://api.elsevier.com/content/abstract/scopus_id/85108716493,"Synthetic aperture radar (SAR) has great potential for timely monitoring of flood information as it penetrates the clouds during flood events. Moreover, the proliferation of SAR satellites with high spatial and temporal resolution provides a tremendous opportunity to understand the flood risk and its quick response. However, traditional algorithms to extract flood inundation using SAR often require manual parameter tuning or data annotation, which presents a challenge for the rapid automated mapping of large and complex flooded scenarios. To address this issue, we proposed a segmentation algorithm for automatic flood mapping in near-real-time over vast areas and for all-weather conditions by integrating Sentinel-1 SAR imagery with an unsupervised machine learning approach named Felz-CNN. The algorithm consists of three phases: (i) super-pixel generation; (ii) convolutional neural network-based featurization; (iii) super-pixel aggregation. We evaluated the Felz-CNN algorithm by mapping flood inundation during the Yangtze River flood in 2020, covering a total study area of 1,140,300 km2. When validated on fine-resolution Planet satellite imagery, the algorithm accurately identified flood extent with producer and user accuracy of 93% and 94%, respectively. The results are indicative of the usefulness of our unsupervised approach for the application of flood mapping. Meanwhile, we overlapped the post-disaster inundation map with a 10-m resolution global land cover map (FROM-GLC10) to assess the damages to different land cover types. Of these types, cropland and residential settlements were most severely affected, with inundation areas of 9,430.36 km2 and 1,397.50 km2, respectively, results that are in agreement with statistics from relevant agencies. Compared with traditional supervised classification algorithms that require time-consuming data annotation, our unsupervised algorithm can be deployed directly to high-performance computing platforms such as Google Earth Engine and PIE-Engine to generate a large-spatial map of flood-affected areas within minutes, without time-consuming data downloading and processing. Importantly, this efficiency enables the fast and effective monitoring of flood conditions to aid in disaster governance and mitigation globally.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.coastaleng.2021.103919,Journal,Coastal Engineering,scopus,2021-08-01,sciencedirect,Satellite optical imagery in Coastal Engineering,https://api.elsevier.com/content/abstract/scopus_id/85106393729,"This Short Communication provides a Coastal Engineering perspective on present and emerging capabilities of satellite optical imagery, including real-world applications that can now be realistically implemented from the desktop. Significantly, at the vast majority of locations worldwide, satellite remote sensing is currently the only source of information to complement much more limited in-situ instrumentation for land and sea mapping, monitoring and measurement. Less well recognised is that publicly available, routinely sampled and now easily accessible optical imagery covering virtually every position along the world's coastlines already spans multiple decades. In the past five years the common obstacles of (1) limited access to high-performance computing and (2) specialist remote sensing technical expertise, have been largely removed. The emergence of several internet-accessible application programming interfaces (APIs) now enable applied users to access petabytes of satellite imagery along with the necessary tools and processing power to extract, manipulate and analyse information of practical interest. Following a brief overview and timeline of civilian Earth observations from space, satellite-derived shorelines (SDS) and satellite-derived bathymetry (SDB) are used to introduce and demonstrate some of the present real-world capabilities of satellite optical imagery most relevant to coastal professionals and researchers. These practical examples illustrate the use of satellite imagery to monitor and quantify both engineered and storm-induced coastline changes, as well as the emerging potential to obtain seamless topo/bathy surveys along coastal regions. Significantly, timescales of satellite-derived changes at the coast can range from decades to days, with spatial scales of interest extending from individual project sites up to unprecedented regional and global studies. While we foresee the uptake and routine use of satellite-derived information becoming quickly ubiquitous within the Coastal Engineering profession, on-ground observations are – and in our view will remain - fundamentally important. Compared to precision in-situ instrumentation, present intrinsic limitations of satellites are their relatively low rates of revisit and decimetre spatial accuracy. New satellite advances including ‘video from space’ and the potential to combine Earth observation with numerical and data-driven coastal models through assimilation and artificial intelligence are advances that we foresee will have future major impact in Coastal Engineering.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.buildenv.2021.107929,Journal,Building and Environment,scopus,2021-08-01,sciencedirect,MOOSAS – A systematic solution for multiple objective building performance optimization in the early design stage,https://api.elsevier.com/content/abstract/scopus_id/85105785192,"There is great potential for building performance optimization (BPO) in the early design stage, but there is still a lack of methods, algorithms, and tools to support the BPO process in this stage. Through a comprehensive review, this study identified three critical issues that affect the implementation of the BPO process in the early design stage: model integration, real-time performance analysis, and interactive optimization design. This study provides a systematic solution to these three critical issues. In terms of model integration, a feature-based and graph-based 3D building space recognition algorithm is proposed to automatically convert the computer-aided design (CAD model) into a computer-aided engineering model (CAE model). In terms of real-time performance analysis, a simplified physical method, an HPC-accelerated method, and an AI-based method are explored, and a real-time energy modeling module and a real-time daylighting analysis module are developed. In terms of the interactive optimization design, a preference-based multi-objective BPO design algorithm that can consider user preferences is proposed to make full use of the decision-making ability of humans and the computing power of machines and significantly improve the optimization efficiency and result satisfaction. Based on the systematic solution, a multi-objective BPO design software, MOOSAS, is developed. MOOSAS allows real-time performance feedback, dynamic parameter analysis, and interactive optimization, supporting the BPO process in the early design stage. The innovations of this study are as follows: first, this study proposes a systematic solution to the three critical issues of the BPO process, i.e., model integration, real-time performance analysis, and interactive optimization design; second, this study develops a multi-objective BPO design software (MOOSAS) for the early design stage.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bbrc.2020.10.077,Journal,Biochemical and Biophysical Research Communications,scopus,2021-07-30,sciencedirect,"Life, death, and self: Fundamental questions of primitive cognition viewed through the lens of body plasticity and synthetic organisms",https://api.elsevier.com/content/abstract/scopus_id/85095615733,"Central to the study of cognition is being able to specify the Subject that is making decisions and owning memories and preferences. However, all real cognitive agents are made of parts (such as brains made of cells). The integration of many active subunits into a coherent Self appearing at a larger scale of organization is one of the fundamental questions of evolutionary cognitive science. Typical biological model systems, whether basal or advanced, have a static anatomical structure which obscures important aspects of the mind-body relationship. Recent advances in bioengineering now make it possible to assemble, disassemble, and recombine biological structures at the cell, organ, and whole organism levels. Regenerative biology and controlled chimerism reveal that studies of cognition in intact, “standard”, evolved animal bodies are just a narrow slice of a much bigger and as-yet largely unexplored reality: the incredible plasticity of dynamic morphogenesis of biological forms that house and support diverse types of cognition. The ability to produce living organisms in novel configurations makes clear that traditional concepts, such as body, organism, genetic lineage, death, and memory are not as well-defined as commonly thought, and need considerable revision to account for the possible spectrum of living entities. Here, I review fascinating examples of experimental biology illustrating that the boundaries demarcating somatic and cognitive Selves are fluid, providing an opportunity to sharpen inquiries about how evolution exploits physical forces for multi-scale cognition. Developmental (pre-neural) bioelectricity contributes a novel perspective on how the dynamic control of growth and form of the body evolved into sophisticated cognitive capabilities. Most importantly, the development of functional biobots – synthetic living machines with behavioral capacity – provides a roadmap for greatly expanding our understanding of the origin and capacities of cognition in all of its possible material implementations, especially those that emerge de novo, with no lengthy evolutionary history of matching behavioral programs to bodyplan. Viewing fundamental questions through the lens of new, constructed living forms will have diverse impacts, not only in basic evolutionary biology and cognitive science, but also in regenerative medicine of the brain and in artificial intelligence.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.chemolab.2021.104329,Journal,Chemometrics and Intelligent Laboratory Systems,scopus,2021-07-15,sciencedirect,A novel approach for water quality classification based on the integration of deep learning and feature extraction techniques,https://api.elsevier.com/content/abstract/scopus_id/85105292476,"Water quality monitoring plays a vital role in the protection of water resources, environmental management, and decision-making. Artificial intelligence (AI) based on machine learning techniques has been widely used to evaluate and classify water quality for the last two decades. However, traditional machine learning techniques face many limitations, the most important of which is the inability to apply these techniques with big data generated by smart water quality monitoring stations to improve the prediction. Real-time water quality monitoring with high accuracy and efficiency for intelligent water quality monitoring stations requires new and sophisticated techniques based on machine and deep learning techniques. For this purpose, we propose a novel approach based on the integration of deep learning and feature extraction techniques to improve water quality classification. In this paper, was chosen the Tilesdit dam in Bouira (Algeria) as a case study. Moreover, we implemented the advanced deep learning method - Long Short Term Memory Recurrent Neural Networks (LSTM RNNs) to construct an intelligent model for drinking water quality classification. Furthermore, principal component analysis (PCA), linear discriminant analysis (LDA) and independent component analysis (ICA) techniques were used for features extraction and data reduction from original features. Additionally, we used three methods of cross-validation and two methods of the out-of-sample test to estimate the performance of LSTM RNNs model. From the results we found that the integration of LSTM RNNs with LDA, and LSTM RNNs with ICA yields an accuracy of 99.72%, using Random-Holdout technique.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2021.06.077,Conference Proceeding,Procedia Computer Science,scopus,2021-07-01,sciencedirect,Digital transformation as a new paradigm of economic policy,https://api.elsevier.com/content/abstract/scopus_id/85112599973,"This study analyzes the conceptual provisions related to solving problems related to the introduction of digital technologies and the formation of a digital economy based on them, reveals the dynamics of digital transformation and its impact on business processes and the interaction of states, business and civil society in the context of modern economic policy. We reviewed the policy of the Russian state in terms of overcoming both the existing and potential economic consequences of the COVID-19 pandemic based on published expert assessments. Our results confirmed that overcoming the current turbulent state of the digital economy in Russia requires: firstly, the development of digital entrepreneurship or the digital sector as the “core” of the digital economy, where digital technologies are created; secondly, the removal of restrictions on the movement of resources caused by the COVID-19 pandemic, as a result of the consistent implementation of a coordinated strategy for the digitalization of the economy, based on global cooperation in the field of economic policy; third, the process of reproduction of the social product, where production - distribution – exchange - consumption interact, should take place at the level of world standards; fourth, to introduce the “digital style”in economic policy through building technological chains and diversified connections; fifth, to develop artificial intelligence, the essence of which is to“break” the matrix of habitual life in order to launch a large-scale virtual program of a new being of humanity, spurred by the COVID-19 pandemic.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.softx.2021.100773,Journal,SoftwareX,scopus,2021-07-01,sciencedirect,NetCausality: A time-delayed neural network tool for causality detection and analysis,https://api.elsevier.com/content/abstract/scopus_id/85111857161,"The analysis of causality between systems is still an important research activity, which finds application in several fields of science. The software presented is a new tool for causality detection and analysis between time series. The proposed technique is based on time-delayed neural networks (TDNN). The tool is developed in MATLAB and it comprises three main functions. The first one returns the total causality between two or more systems of equations. The second tool is used to find the “time horizon”, id est the time delay at which the influence between the systems occurs. The last function is a causality feature detection to determine the time intervals, in which the mutual coupling is sufficiently strong to have a real influence on the target.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ebiom.2021.103465,Journal,EBioMedicine,scopus,2021-07-01,sciencedirect,A mass spectrometry-based targeted assay for detection of SARS-CoV-2 antigen from clinical specimens,https://api.elsevier.com/content/abstract/scopus_id/85109005451,"Background
                  The COVID-19 pandemic caused by severe acute respiratory syndrome-coronavirus 2 (SARS-CoV-2) has overwhelmed health systems worldwide and highlighted limitations of diagnostic testing. Several types of diagnostic tests including RT-PCR-based assays and antigen detection by lateral flow assays, each with their own strengths and weaknesses, have been developed and deployed in a short time.
               
                  Methods
                  Here, we describe an immunoaffinity purification approach followed a by high resolution mass spectrometry-based targeted qualitative assay capable of detecting SARS-CoV-2 viral antigen from nasopharyngeal swab samples. Based on our discovery experiments using purified virus, recombinant viral protein and nasopharyngeal swab samples from COVID-19 positive patients, nucleocapsid protein was selected as a target antigen. We then developed an automated antibody capture-based workflow coupled to targeted high-field asymmetric waveform ion mobility spectrometry (FAIMS) - parallel reaction monitoring (PRM) assay on an Orbitrap Exploris 480 mass spectrometer. An ensemble machine learning-based model for determining COVID-19 positive samples was developed using fragment ion intensities from the PRM data.
               
                  Findings
                  The optimized targeted assay, which was used to analyze 88 positive and 88 negative nasopharyngeal swab samples for validation, resulted in 98% (95% CI = 0.922–0.997) (86/88) sensitivity and 100% (95% CI = 0.958–1.000) (88/88) specificity using RT-PCR-based molecular testing as the reference method.
               
                  Interpretation
                  Our results demonstrate that direct detection of infectious agents from clinical samples by tandem mass spectrometry-based assays have potential to be deployed as diagnostic assays in clinical laboratories, which has hitherto been limited to analysis of pure microbial cultures.
               
                  Funding
                  This study was supported by DBT/Wellcome Trust India Alliance Margdarshi Fellowship grant IA/M/15/1/502023 awarded to AP and the generosity of Eric and Wendy Schmidt.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jstrokecerebrovasdis.2021.105826,Journal,Journal of Stroke and Cerebrovascular Diseases,scopus,2021-07-01,sciencedirect,Automatic Acute Stroke Symptom Detection and Emergency Medical Systems Alerting by Mobile Health Technologies: A Review,https://api.elsevier.com/content/abstract/scopus_id/85107711467,"Objectives
                  To survey recent advances in acute stroke symptom automatic detection and Emergency Medical Systems (EMS) alerting by mobile health technologies.
               
                  Materials and methods
                  Narrative review
               
                  Results
                  Delayed activation of EMS for stroke symptoms by patients and witnesses deprives patients of rapid access to brain-saving therapies and occurs due to public unawareness of stroke features, cognitive and motor deficits produced by the stroke itself, and sleep onset. A promising emerging approach to overcoming the inherent biologic constraints of patient capacity to self-detect and respond to stroke symptoms is continuous monitoring by mobile health technologies with wireless sensors and artificial intelligence recognition systems. This review surveys 11 sensing technologies - accelerometers, gyroscopes, magnetometers, pressure sensors, touch screen and keyboard input detectors, artificial vision, and artificial hearing; and 10 consumer device form factors in which they are increasingly implemented: smartphones, smart speakers, smart watches and fitness bands, smart speakers/voice assistants, home health robots, smart clothing, smart beds, closed circuit television, smart rings, and desktop/laptop/tablet computers.
               
                  Conclusions
                  The increase in computing power, wearable sensors, and mobile connectivity have ushered in an array of mobile health technologies that can transform stroke detection and EMS activation. By continuously monitoring a diverse range of biometric parameters, commercially available devices provide the technologic capability to detect cardinal language, motor, gait, and sensory signs of stroke onset. Intensified translational research to convert the promise of these technologies to validated, accurate real-world deployments are an important next priority for stroke investigation.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2021.106130,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-07-01,sciencedirect,"Chest x-ray automated triage: A semiologic approach designed for clinical implementation, exploiting different types of labels through a combination of four Deep Learning architectures",https://api.elsevier.com/content/abstract/scopus_id/85107617149,"Background and objectives
                  The multiple chest x-ray datasets released in the last years have ground-truth labels intended for different computer vision tasks, suggesting that performance in automated chest x-ray interpretation might improve by using a method that can exploit diverse types of annotations. This work presents a Deep Learning method based on the late fusion of different convolutional architectures, that allows training with heterogeneous data with a simple implementation, and evaluates its performance on independent test data. We focused on obtaining a clinically useful tool that could be successfully integrated into a hospital workflow.
               
                  Materials and methods
                  Based on expert opinion, we selected four target chest x-ray findings, namely lung opacities, fractures, pneumothorax and pleural effusion. For each finding we defined the most suitable type of ground-truth label, and built four training datasets combining images from public chest x-ray datasets and our institutional archive. We trained four different Deep Learning architectures and combined their outputs with a late fusion strategy, obtaining a unified tool. The performance was measured on two test datasets: an external openly-available dataset, and a retrospective institutional dataset, to estimate performance on the local population.
               
                  Results
                  The external and local test sets had 4376 and 1064 images, respectively, for which the model showed an area under the Receiver Operating Characteristics curve of 0.75 (95%CI: 0.74–0.76) and 0.87 (95%CI: 0.86–0.89) in the detection of abnormal chest x-rays. For the local population, a sensitivity of 86% (95%CI: 84–90), and a specificity of 88% (95%CI: 86–90) were obtained, with no significant differences between demographic subgroups. We present examples of heatmaps to show the accomplished level of interpretability, examining true and false positives.
               
                  Conclusion
                  This study presents a new approach for exploiting heterogeneous labels from different chest x-ray datasets, by choosing Deep Learning architectures according to the radiological characteristics of each pathological finding. We estimated the tool's performance on the local population, obtaining results comparable to state-of-the-art metrics. We believe this approach is closer to the actual reading process of chest x-rays by professionals, and therefore more likely to be successful in a real clinical setting.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jchromb.2021.122760,Journal,Journal of Chromatography B: Analytical Technologies in the Biomedical and Life Sciences,scopus,2021-07-01,sciencedirect,Rapid exposure monitoring of six bisphenols and diethylstilbestrol in human urine using fabric phase sorptive extraction followed by high performance liquid chromatography – photodiode array analysis,https://api.elsevier.com/content/abstract/scopus_id/85106648971,"A novel fabric phase sorptive extraction protocol is developed for rapid exposure monitoring of six bisphenol analogues, including bisphenol A, bisphenol S, bisphenol F, bisphenol E, bisphenol B, bisphenol C, and diethylstilbestrol (DES) from human urine prior to high-performance liquid chromatography-photodiode array analysis.
                  FPSE sample pretreatment protocol ensures the harmonization of the proposed method with the principles of Green Analytical Chemistry (GAC). Among eighteen evaluated FPSE membranes, sol-gel poly (ethylene glycol) (PEG) coated cellulose FPSE membrane resulted in the most efficient extraction. This polar FPSE membrane effectively exploits a number of advantageous features inherent to FPSE including sponge-like porous architecture of the sol-gel sorbent coating, favorable surface chemistry, flexibility and built-in permeability of cellulose fabric substrate, high primary contact surface area for rapid sorbent-analyte interaction, expanded pH, solvent and thermal stability as well as reusability of the FPSE membrane.
                  Optimization was centered on the evaluation of critical parameters, namely the size of the FPSE membrane, the elution solvent mixture, the volume of the sample, the extraction time, the elution time, the kind of the external agitation mechanical stimulus, the ionic strength and the pH of the sample. The chromatographic separation was achieved on a Spherisorb C18 column and a gradient elution program with mobile phase consisted of 0.05 ammonium acetate solution and acetonitrile. The total analysis time was 17.4 min. The developed method was validated in terms of linearity, sensitivity, selectivity, precision, accuracy, stability, and ruggedness. The limits of detection and quantification varied from 0.26–0.62 ng/mL and 0.8–1.9 ng/mL, respectively. The relative recoveries were calculated between 90.6 and 108.8%, while the RSD values were <10% in all cases. The effectiveness of the proposed method was confirmed by its successful implementation in the bioanalysis of real urine samples.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmsy.2021.04.005,Journal,Journal of Manufacturing Systems,scopus,2021-07-01,sciencedirect,LearningADD: Machine learning based acoustic defect detection in factory automation,https://api.elsevier.com/content/abstract/scopus_id/85106283308,"Defect inspection of glass bottles in the beverage industrial is of significance to prevent unexpected losses caused by the damage of bottles during manufacturing and transporting. The commonly used manual methods suffer from inefficiency, excessive space consumption, and beverage wastes after filling. To replace the manual operations in the pre-filling detection with improved efficiency and reduced costs, this paper proposes a machine learning based Acoustic Defect Detection (LearningADD) system. Moreover, to realize scalable deployment on edge and cloud computing platforms, deployment strategies especially partitioning and allocation of functionalities need to be compared and optimized under realistic constraints such as latency, complexity, and capacity of the platforms. In particular, to distinguish the defects in glass bottles efficiently, the improved Hilbert-Huang transform (HHT) is employed to extend the extracted feature sets, and then Shuffled Frog Leaping Algorithm (SFLA) based feature selection is applied to optimize the feature sets. Five deployment strategies are quantitatively compared to optimize real-time performances based on the constraints measured from a real edge and cloud environment. The LearningADD algorithms are validated by the datasets from a real-life beverage factory, and the F-measure of the system reaches 98.48 %. The proposed deployment strategies are verified by experiments on private cloud platforms, which shows that the Distributed Heavy Edge deployment outperforms other strategies, benefited from the parallel computing and edge computing, where the Defect Detection Time for one bottle is less than 2.061 s in 99 % probability.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.measurement.2021.109528,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2021-07-01,sciencedirect,A molecular sensing method integrated with support vector machines to characterize asphalt mixtures,https://api.elsevier.com/content/abstract/scopus_id/85105846445,"Modern and heterogeneous asphalt mixtures are usually produced using various kinds of modifiers such as rubber, polymer, and fiber. These materials are incorporated to improve sustainability and reduce the extent and severity of distresses such as rutting and low-temperature cracking. Currently, there is a lack of a robust real-time method for the identification of these additives in mixtures. In this research, a portable molecular sensing technology is integrated with machine learning (ML) to characterize asphalt binders modified with ground tire rubber (GTR) and asphalt mixtures containing different amounts of recycled materials. A database containing several near-infrared (NIR) spectra for binder and asphalt mixture samples are used to develop the ML-based detection models. The acceptable accuracy reported in this study implies that the proposed integrated NIR and ML approach can be used as a promising tool to differentiate and classify various types of asphalt binders and mixtures. This monitoring and data collection framework can contribute to improved sustainability via accelerating and optimizing the construction material detection and selection process throughout the pavement life. Furthermore, the expensive and cumbersome process of binder extraction and recovery could be avoided using the proposed method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2021.104450,Journal,Computers in Biology and Medicine,scopus,2021-07-01,sciencedirect,A comprehensive review and analysis of supervised-learning and soft computing techniques for stress diagnosis in humans,https://api.elsevier.com/content/abstract/scopus_id/85105598718,"Stress is the most prevailing and global psychological condition that inevitably disrupts the mood and behavior of individuals. Chronic stress may gravely affect the physical, mental, and social behavior of victims and consequently induce myriad critical human disorders. Herein, a review has been presented where supervised learning (SL) and soft computing (SC) techniques used in stress diagnosis have been meticulously investigated to highlight the contributions, strengths, and challenges faced in the implementation of these methods in stress diagnostic models. A three-tier review strategy comprising of manuscript selection, data synthesis, and data analysis was adopted. The issues in SL strategies and the potential possibility of using hybrid techniques in stress diagnosis have been intensively investigated. The strengths and weaknesses of different SL (Bayesian classifier, random forest, support vector machine, and nearest neighbours) and SC (fuzzy logic, nature-inspired, and deep learning) techniques have been presented to obtain clear insights into these optimization strategies. The effects of social, behavioral, and biological stresses have been highlighted. The psychological, biological, and behavioral responses to stress have also been briefly elucidated. The findings of the study confirmed that different types of data/signals (related to skin temperature, electro-dermal activity, blood circulation, heart rate, facial expressions, etc.) have been used in stress diagnosis. Moreover, there is a potential scope for using distinct nature-inspired computing techniques (Genetic Algorithm, Particle Swarm Optimization, Ant Colony Optimization, Whale Optimization Algorithm, Butterfly Optimization, Harris Hawks Optimizer, and Crow Search Algorithm) and deep learning techniques (Deep-Belief Network, Convolutional-Neural Network, and Recurrent-Neural Network) on multimodal data compiled using behavioral testing, electroencephalogram signals, finger temperature, respiration rate, pupil diameter, galvanic-skin-response, and blood pressure. Likewise, there is a wider scope to investigate the use of SL and SC techniques in stress diagnosis using distinct dimensions such as sentiment analysis, speech recognition, handwriting recognition, and facial expressions. Finally, a hybrid model based on distinct computational methods influenced by both SL and SC techniques, adaption, parameter tuning, and the use of chaos, levy, and Gaussian distribution may address exploration and exploitation issues. However, factors such as real-time data collection, bias, integrity, multi-dimensional data, and data privacy make it challenging to design precise and innovative stress diagnostic systems based on artificial intelligence.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2021.104448,Journal,Computers in Biology and Medicine,scopus,2021-07-01,sciencedirect,High precision in microRNA prediction: A novel genome-wide approach with convolutional deep residual networks,https://api.elsevier.com/content/abstract/scopus_id/85105586824,"MicroRNAs (miRNAs) are small non-coding RNAs that have a key role in the regulation of gene expression. The importance of miRNAs is widely acknowledged by the community nowadays and computational methods are needed for the precise prediction of novel candidates to miRNA. This task can be done by searching homologous with sequence alignment tools, but results are restricted to sequences that are very similar to the known miRNA precursors (pre-miRNAs). Besides, a very important property of pre-miRNAs, their secondary structure, is not taken into account by these methods. To fill this gap, many machine learning approaches were proposed in the last years. However, the methods are generally tested in very controlled conditions. If these methods were used under real conditions, the false positives increase and the precisions fall quite below those published. This work provides a novel approach for dealing with the computational prediction of pre-miRNAs: a convolutional deep residual neural network (mirDNN). This model was tested with several genomes of animals and plants, the full-genomes, achieving a precision up to 5 times larger than other approaches at the same recall rates. Furthermore, a novel validation methodology was used to ensure that the performance reported in this study can be effectively achieved when using mirDNN in novel species. To provide fast an easy access to mirDNN, a web demo is available at http://sinc.unl.edu.ar/web-demo/mirdnn/. The demo can process FASTA files with multiple sequences to calculate the prediction scores and generates the nucleotide importance plots.
               
                  Full source code
                  
                     http://sourceforge.net/projects/sourcesinc/files/mirdnn and https://github.com/cyones/mirDNN.
               
                  Contact
                  
                     gstegmayer@sinc.unl.edu.ar.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rser.2021.110969,Journal,Renewable and Sustainable Energy Reviews,scopus,2021-07-01,sciencedirect,Intelligent building control systems for thermal comfort and energy-efficiency: A systematic review of artificial intelligence-assisted techniques,https://api.elsevier.com/content/abstract/scopus_id/85103719088,"Building operations represent a significant percentage of the total primary energy consumed in most countries due to the proliferation of Heating, Ventilation and Air-Conditioning (HVAC) installations in response to the growing demand for improved thermal comfort. Reducing the associated energy consumption while maintaining comfortable conditions in buildings are conflicting objectives and represent a typical optimization problem that requires intelligent system design. Over the last decade, different methodologies based on the Artificial Intelligence (AI) techniques have been deployed to find the sweet spot between energy use in HVAC systems and suitable indoor comfort levels to the occupants. This paper performs a comprehensive and an in-depth systematic review of AI-based techniques used for building control systems by assessing the outputs of these techniques, and their implementations in the reviewed works, as well as investigating their abilities to improve the energy-efficiency, while maintaining thermal comfort conditions. This enables a holistic view of (1) the complexities of delivering thermal comfort to users inside buildings in an energy-efficient way, and (2) the associated bibliographic material to assist researchers and experts in the field in tackling such a challenge. Among the 20 AI tools developed for both energy consumption and comfort control, functions such as identification and recognition patterns, optimization, predictive control. Based on the findings of this work, the application of AI technology in building control is a promising area of research and still an ongoing, i.e., the performance of AI-based control is not yet completely satisfactory. This is mainly due in part to the fact that these algorithms usually need a large amount of high-quality real-world data, which is lacking in the building or, more precisely, the energy sector. Based on the current study, from 1993 to 2020, the application of AI techniques and personalized comfort models has enabled energy savings on average between 21.81 and 44.36%, and comfort improvement on average between 21.67 and 85.77%. Finally, this paper discusses the challenges faced in the use of AI for energy productivity and comfort improvement, and opens main future directions in relation with AI-based building control systems for human comfort and energy-efficiency management.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.petrol.2021.108488,Journal,Journal of Petroleum Science and Engineering,scopus,2021-07-01,sciencedirect,Data-driven machine learning for accurate prediction and statistical quantification of two phase flow regimes,https://api.elsevier.com/content/abstract/scopus_id/85102536455,Two different two-phase flow regimes including slug and dispersed flows are examined through the implementation of system identification methods to attain reduced-order models. The obtained models accurately capture the flow dynamics of the studied regimes. The models also provide state-space frequency by defining the transfer functions. The system identification results are compared with those of the bidirectional neural network to predict the phase fraction of the considered two-phase flows. The result of long short-term memory shows correlations of 91% between the real and predicted phase fractions.,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2021.01.013,Journal,Information Sciences,scopus,2021-07-01,sciencedirect,Attributed community search based on effective scoring function and elastic greedy method,https://api.elsevier.com/content/abstract/scopus_id/85101624086,"In recent years, with the proliferation of rich attribute information available for entities in real-world networks and the increasing demand for more personalized community searches, attributed community search (ACS), an upgraded version of the community search problem, has attracted great attention from the both academic and industry areas. Some algorithms have been proposed to solve this novel research problem. However, they have a deficiency in evaluating the quality of the attributed community structure, which may mislead them and discover less valuable structures. In this paper, we make up for this defect, and propose the SFEG algorithm to better solve the ACS problem. SFEG designs a more effective scoring function to measure the quality of the discovered attributed community structure, and presents an elastic greedy optimization method to quickly maximize the function value to determine the target community with a specific meaning. The extensive experiments conducted on the attributed graph datasets with ground-truth communities show that our algorithm significantly outperforms the state-of-the-art.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.tele.2021.101583,Journal,Telematics and Informatics,scopus,2021-07-01,sciencedirect,Improving evidence-based assessment of players using serious games,https://api.elsevier.com/content/abstract/scopus_id/85101178082,"Serious games are highly interactive systems which can therefore capture large amounts of player interaction data. This data can be analyzed to provide a deep insight into the effect of the game on its players. However, traditional techniques to assess players of serious games make little use of interaction data, relying instead on costly external questionnaires. We propose an evidence-based process to improve the assessment of players by using their interaction data. The process first combines player interaction data and traditional questionnaires to derive and refine game learning analytics variables, which can then be used to predict the effects of the game on its players. Once the game is validated, and suitable prediction models have been built, the prediction models can be used in large-scale deployments to assess players solely based on their interactions, without the need for external questionnaires. We briefly describe two case studies where this combination of traditional questionnaires and data mining techniques has been successfully applied. The evidence-based assessment process proposed radically simplifies the deployment and application of serious games in real class settings.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ymssp.2020.107510,Journal,Mechanical Systems and Signal Processing,scopus,2021-06-16,sciencedirect,Metric-based meta-learning model for few-shot fault diagnosis under multiple limited data conditions,https://api.elsevier.com/content/abstract/scopus_id/85100211264,"The real-world large industry has gradually become a data-rich environment with the development of information and sensor technology, making the technology of data-driven fault diagnosis acquire a thriving development and application. The success of these advanced methods depends on the assumption that enough labeled samples for each fault type are available. However, in some practical situations, it is extremely difficult to collect enough data, e.g., when the sudden catastrophic failure happens, only a few samples can be acquired before the system shuts down. This phenomenon leads to the few-shot fault diagnosis aiming at distinguishing the failure attribution accurately under very limited data conditions. In this paper, we propose a new approach, called Feature Space Metric-based Meta-learning Model (FSM3), to overcome the challenge of the few-shot fault diagnosis under multiple limited data conditions. Our method is a mixture of general supervised learning and episodic metric meta-learning, which will exploit both the attribute information from individual samples and the similarity information from sample groups. The experiment results demonstrate that our method outperforms a series of baseline methods on the 1-shot and 5-shot learning tasks of bearing and gearbox fault diagnosis across various limited data conditions. The time complexity and implementation difficulty have been analyzed to show that our method has relatively high feasibility. The feature embedding is visualized by t-SNE to investigate the effectiveness of our proposed model.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.chemolab.2021.104314,Journal,Chemometrics and Intelligent Laboratory Systems,scopus,2021-06-15,sciencedirect,A scalable approach for the efficient segmentation of hyperspectral images,https://api.elsevier.com/content/abstract/scopus_id/85105360467,"The number of applications of hyperspectral imaging (HSI) is steadily increasing, as technology evolves and cameras become more affordable. However, the volume of data in a hyperspectral image is large (order of Gigabytes) and standard off-the-shelf algorithms for multi-channel image analysis cannot be readily applied, due to the prohibitive computational time and large memory requirements. Therefore, new scalable approaches are required to perform hyperspectral image analysis. In this article we address an efficient methodology for conducting Unsupervised Image Segmentation – one of the basic and most fundamental image analysis operations. In the methodology proposed, unsupervised segmentation is conducted after transforming the spectral and spatial dimensions of the raw hyperspectral image into a more compact representation using multivariate and multiresolution techniques. The clusters identified in the compact image representation are then used to train a discriminative classifier. The classifier is then adapted and transferred for application to the raw image, where it will efficiently label all the original pixels. With the proposed methodology, the computational expensive operations (unsupervised clustering and classifier learning) are minimized, whereas the efficient implementation of the classifier guarantees the analysis at the native resolution. The effectiveness of the proposed methodology was tested on a real case study considering an industrial hyperspectral image capturing the reflectance spectrum for several objects made of different unknown materials. A significant reduction in the computational cost was achieved without compromising the quality of the unsupervised segmentation, demonstrating the potential of the proposed approach.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.chemolab.2021.104325,Journal,Chemometrics and Intelligent Laboratory Systems,scopus,2021-06-15,sciencedirect,Extended Gaussian mixture regression for forward and inverse analysis,https://api.elsevier.com/content/abstract/scopus_id/85104927275,"In molecular, material, and process designs, it is important to perform inverse analysis of the regression models constructed with machine learning using target values of the properties and activities. Although many approaches actually employ a pseudo-inverse analysis, Gaussian mixture regression (GMR) can achieve direct inverse analysis. This paper describes the development and use of extended GMR (EGMR), which offers improved predictive ability over conventional GMR. EGMR includes implementations of both GMR and Bayesian GMR, which is based on a variational Bayesian method. The hyperparameters for each model are optimized, and the choice of model for the specific data is determined, through cross-validation. The effectiveness of the proposed EGMR is verified using numerically simulated datasets, compound datasets, a material dataset, and spectral datasets. These datasets contain real data. The predictive ability of EGMR is found to be greater than or equal to that of GMR in all cases, and the prediction errors can be reduced by more than 30%. Furthermore, it is confirmed that EGMR can perform inverse analysis with high reproducibility, even in the extrapolation region of an objective variable. The Python code for EGMR is available at https://github.com/hkaneko1985/dcekit.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.dib.2021.107127,Journal,Data in Brief,scopus,2021-06-01,sciencedirect,H2020 project CAPTOR dataset: Raw data collected by low-cost MOX ozone sensors in a real air pollution monitoring network,https://api.elsevier.com/content/abstract/scopus_id/85106384559,"The H2020 CAPTOR project deployed three testbeds in Spain, Italy and Austria with low-cost sensors for the measurement of tropospheric ozone (O3). The aim of the H2020 CAPTOR project was to raise public awareness in a project focused on citizen science. Each testbed was supported by an NGO in charge of deciding how to raise citizen awareness according to the needs of each country. The data presented in this document correspond to the raw data captured by the sensor nodes in the Spanish testbed using SGX Sensortech MICS 2614 metal-oxide sensors. The Spanish testbed consisted of the deployment of twenty-five nodes. Each sensor node included four SGX Sensortech MICS 2614 ozone sensors, one temperature sensor and one relative humidity sensor. Each node underwent a calibration process by co-locating the node at an EU reference air quality monitoring station, followed by a deployment in a sub-urban or rural area in Catalonia, Spain. All nodes spent two to three weeks co-located at a reference station in Barcelona, Spain (urban area), followed by two to three weeks co-located at three sub-urban reference stations near the final deployment site. The nodes were then deployed in volunteers' homes for about two months and, finally, the nodes were co-located again at the sub-urban reference stations for two weeks for final calibration and assessment of potential drifts. All data presented in this paper are raw data taken by the sensors that can be used for scientific purposes such as calibration studies using machine learning algorithms, or once the concentration values of the nodes are obtained, they can be used to create tropospheric ozone pollution maps with heterogeneous data sources (reference stations and low-cost sensors).",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S2589-7500(21)00005-4,Journal,The Lancet Digital Health,scopus,2021-06-01,sciencedirect,Health information technology and digital innovation for national learning health and care systems,https://api.elsevier.com/content/abstract/scopus_id/85106359380,"Health information technology can support the development of national learning health and care systems, which can be defined as health and care systems that continuously use data-enabled infrastructure to support policy and planning, public health, and personalisation of care. The COVID-19 pandemic has offered an opportunity to assess how well equipped the UK is to leverage health information technology and apply the principles of a national learning health and care system in response to a major public health shock. With the experience acquired during the pandemic, each country within the UK should now re-evaluate their digital health and care strategies. After leaving the EU, UK countries now need to decide to what extent they wish to engage with European efforts to promote interoperability between electronic health records. Major priorities for strengthening health information technology in the UK include achieving the optimal balance between top-down and bottom-up implementation, improving usability and interoperability, developing capacity for handling, processing, and analysing data, addressing privacy and security concerns, and encouraging digital inclusivity. Current and future opportunities include integrating electronic health records across health and care providers, investing in health data science research, generating real-world data, developing artificial intelligence and robotics, and facilitating public–private partnerships. Many ethical challenges and unintended consequences of implementation of health information technology exist. To address these, there is a need to develop regulatory frameworks for the development, management, and procurement of artificial intelligence and health information technology systems, create public–private partnerships, and ethically and safely apply artificial intelligence in the National Health Service.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.comcom.2021.04.026,Journal,Computer Communications,scopus,2021-06-01,sciencedirect,Adversarial attacks on a lexical sentiment analysis classifier,https://api.elsevier.com/content/abstract/scopus_id/85105035567,"Social media has become a relevant information source for several decision-making processes and for the definition of business strategies. As various sentiment analysis techniques are used to transform collected data into intelligence information, the sentiment classifiers used in these collection environments must be carefully studied and observed before being considered trustful and ready to be installed in decision support systems. An important research area concerns the robustness of sentiment classifiers in view of new adversarial attacks, in which small perturbations may be created by malicious users to deceive the sentiment classifiers, generating a perception different from the one that should be observed in the environment. Thus, it is important to identify and analyze the vulnerabilities of these classifiers under different strategies of adversarial attacks to propose countermeasures that can be used to mitigate such attacks. In this context, this work presents adversarial attacks related to a lexical natural language classifier. Being the target of the attacks, this classifier is used to calculate the sentiment of collected data as posted by users in various social media applications. The results indicate that the found vulnerabilities, if exploited by malicious users in applications that use the same lexical classifier, could invert or cancel the classifiers’ perception, thus generating perceptions that do not correspond to the reality for decision making. This work also proposes some countermeasures that might mitigate the implemented attacks.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scs.2021.102801,Journal,Sustainable Cities and Society,scopus,2021-06-01,sciencedirect,"Smart and sustainable logistics of Port cities: A framework for comprehending enabling factors, domains and goals",https://api.elsevier.com/content/abstract/scopus_id/85104756448,"Digital technologies integrated into port logistics are becoming increasingly decisive among port cities around the world. This growing importance is due to the need for policymakers, urban managers, port authorities, local administrators, shipping companies, couriers, and so on to develop increasingly digitalized and sustainable logistic processes. Therefore, in a global context characterized by intense datafication and globalization of trade, the data-based approach has become a necessary modus operandi to promote smart and sustainable logistics development. This forward-looking model of port logistics uses technologies such as IoT, sensors, cloud computing platforms, Big Data analytics, Artificial Intelligence (AI), GPS tracking systems, radars, drones, real-time monitoring stations, smart grids, and so on in order to collect, process, monitor and analyse data and information concerning the economic, environmental, social and technological sphere of port cities. In this sense, mobile and fixed platforms help logistics operators to optimize the management of flows (e.g., water, waste, emissions, raw materials, people, monetary investments, etc.) in an efficient and digitized manner. The study proposes a systematic literature review of the most recurring themes concerning smart and sustainable logistics initiatives within port cities in order to develop a multidimensional framework capable of holistically integrating the prevailing enabling factors (Ecosystem, Internal Organization, Data and Security, Policy and Regulation, Finance and Funding, and Digital and Technology), domains (Mobility, Environment, Economy, Telecommunications, Safety and Security, Government, and Community) and goals (Sustainable Development and Digitalization) that characterize smart and sustainable logistical development. To this end, the best practices of several pioneering port cities such as Rotterdam, Hamburg, Singapore, Los Angeles, Amsterdam, etc. implemented in partnerships with technology companies such as Cisco, IBM, Huawei and SAP were also analysed. Therefore, the results of this research show that smart and sustainable logistics initiatives in port cities: (a) have the potential to enhance the efficiency of the economic, environmental, social and technological flows; (b) increase the involvement and awareness of stakeholders such as couriers, shippers, shipping companies, citizens, port authorities, municipalities, security officers, gate and terminal personnel, and so on; and (c) provide a detailed overview of the enabling factors, domains and goals that must be activated by port cities to foster a smart and sustainable logistic transition.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.sysarc.2021.102139,Journal,Journal of Systems Architecture,scopus,2021-06-01,sciencedirect,Tracking and analysing social interactions in dairy cattle with real-time locating system and machine learning,https://api.elsevier.com/content/abstract/scopus_id/85104583225,"There is a need for reliable and efficient methods for monitoring the activity and social behaviour in cows, in order to optimise management in modern dairy farms. This research presents an embedded system that could track individual cows using Ultra-wideband technology. At the same time, social interactions between individuals around the feeding area were analysed with a computer vision module. Detections of the dairy cows’ negative and positive interactions were performed on foreground video stream using a Long-term Recurrent Convolution Networks model. The sensor fusion system was implemented and tested on seven dairy cows during 45 days in an experimental dairy farm. The system performance was evaluated at the feeding area. The real-time locating system based on Ultra-wideband technology reached an accuracy with mean error 0.39 m and standard deviation 0.62 m. The accuracy of detecting the affiliative and agonistic social interactions reached 93.2%. This study demonstrates a potential system for monitoring social interactions between dairy cows.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.radonc.2021.03.032,Journal,Radiotherapy and Oncology,scopus,2021-06-01,sciencedirect,"First experience of autonomous, un-supervised treatment planning integrated in adaptive MR-guided radiotherapy and delivered to a patient with prostate cancer",https://api.elsevier.com/content/abstract/scopus_id/85104144940,"Background and purpose
                  Currently clinical radiotherapy (RT) planning consists of a multi-step routine procedure requiring human interaction which often results in a time-consuming and fragmented process with limited robustness. Here we present an autonomous un-supervised treatment planning approach, integrated as basis for online adaptive magnetic resonance guided RT (MRgRT), which was delivered to a prostate cancer patient as a first-in-human experience.
               
                  Materials and methods
                  For an intermediate risk prostate cancer patient OARs and targets were automatically segmented using a deep learning-based software and logical volume operators. A baseline plan for the 1.5 T MR-Linac (20x3 Gy) was automatically generated using particle swarm optimization (PSO) without any human interaction. Plan quality was evaluated by predefined dosimetric criteria including appropriate tolerances. Online plan adaptation during clinical MRgRT was defined as first checkpoint for human interaction.
               
                  Results
                  OARs and targets were successfully segmented (3 min) and used for automatic plan optimization (300 min). The autonomous generated plan satisfied 12/16 dosimetric criteria, however all remained within tolerance. Without prior human validation, this baseline plan was successfully used during online MRgRT plan adaptation, where 14/16 criteria were fulfilled. As postulated, human interaction was necessary only during plan adaptation.
               
                  Conclusion
                  Autonomous, un-supervised data preparation and treatment planning was first-in-human shown to be feasible for adaptive MRgRT and successfully applied. The checkpoint for first human intervention was at the time of online MRgRT plan adaptation. Autonomous planning reduced the time delay between simulation and start of RT and may thus allow for real-time MRgRT applications in the future.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scp.2021.100415,Journal,Sustainable Chemistry and Pharmacy,scopus,2021-06-01,sciencedirect,Green chemistry and coronavirus,https://api.elsevier.com/content/abstract/scopus_id/85104072773,"The novel coronavirus pandemic has rapidly spread around the world since December 2019. Various techniques have been applied in identification of SARS-CoV-2 or COVID-19 infection including computed tomography imaging, whole genome sequencing, and molecular methods such as reverse transcription polymerase chain reaction (RT-PCR). This review article discusses the diagnostic methods currently being deployed for the SARS-CoV-2 identification including optical biosensors and point-of-care diagnostics that are on the horizon. These innovative technologies may provide a more accurate, sensitive and rapid diagnosis of SARS-CoV-2 to manage the present novel coronavirus outbreak, and could be beneficial in preventing any future epidemics. Furthermore, the use of green synthesized nanomaterials in the optical biosensor devices could leads to sustainable and environmentally-friendly approaches for addressing this crisis.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S2214-109X(21)00059-0,Journal,The Lancet Global Health,scopus,2021-06-01,sciencedirect,The injustice of unfit clinical practice guidelines in low-resource realities,https://api.elsevier.com/content/abstract/scopus_id/85103953372,"To end the international crisis of preventable deaths in low-income and middle-income countries, evidence-informed and cost-efficient health care is urgently needed, and contextualised clinical practice guidelines are pivotal. However, as exposed by indirect consequences of poorly adapted COVID-19 guidelines, fundamental gaps continue to be reported between international recommendations and realistic best practice. To address this long-standing injustice of leaving health providers without useful guidance, we draw on examples from maternal health and the COVID-19 pandemic. We propose a framework for how global guideline developers can more effectively stratify recommendations for low-resource settings and account for predictable contextual barriers of implementation (eg, human resources) as well as gains and losses (eg, cost-efficiency). Such development of more realistic clinical practice guidelines at the global level will pave the way for simpler and achievable adaptation at local levels. We also urge the development and adaptation of high-quality clinical practice guidelines at national and subnational levels in low-income and middle-income countries through co-creation with end-users, and we encourage global sharing of these experiences.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.conengprac.2021.104795,Journal,Control Engineering Practice,scopus,2021-06-01,sciencedirect,Predictive power-split system of hybrid ship propulsion for energy management and emissions reduction,https://api.elsevier.com/content/abstract/scopus_id/85103377640,"In this work, an energy management system to address the optimal power-split problem in hybrid ship propulsion is developed. The torque of the diesel engine and the electric machine is regulated based on a predictive strategy with a weighting factor which determines the trade-off between fuel consumption and NOx emissions minimization. The modeling for the controller design is based on first principles and data gathered from the hybrid plant. In addition a disturbance observer is designed to estimate the propeller load characteristics. A neural network model that predicts rotational speed reference within the prediction horizon complements the control system design. It is used along with the observer to calculate the future load demand. A parametric simulation study is performed for the trade-off evaluation between fuel consumption and NOx emissions reduction of the control scheme. The control scheme is experimentally implemented and tested in real-time operation, where it has to cope with environmental disturbance rejection and follow the desired rotational speed reference, while performing the power-split in respect to the fuel to NOx weighting parameter and operate the plant within the desirable constraints.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compeleceng.2021.107121,Journal,Computers and Electrical Engineering,scopus,2021-06-01,sciencedirect,Efficient neural networks for edge devices,https://api.elsevier.com/content/abstract/scopus_id/85103242184,"Due to limited computation and storage resources of industrial internet of things (IoT) edge devices, many emerging intelligent industrial IoT applications based on deep neural networks (DNNs) heavily depend on cloud computing for computation and storage. However, cloud computing faces technical issues in long latency, poor reliability, and weak privacy, resulting in the need for on-device computation and storage. On-device computation is essential for many time-critical industrial IoT applications, which require real-time data processing. In this paper, we review three major research areas for on-device computation, specifically quantization, pruning, and network architecture design. The three techniques could enable a DNN model to be deployed on edge devices for real-time computation and storage, mainly due to the reduction of computation and space complexity. More importantly, these techniques could make DNNs applicable to industrial IoT devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.swevo.2021.100868,Journal,Swarm and Evolutionary Computation,scopus,2021-06-01,sciencedirect,"Major Advances in Particle Swarm Optimization: Theory, Analysis, and Application",https://api.elsevier.com/content/abstract/scopus_id/85102857299,"Over the ages, nature has constantly been a rich source of inspiration for science, with much still to discover about and learn from. Swarm Intelligence (SI), a major branch of artificial intelligence, was rendered to model the collective behavior of social swarms in nature. Ultimately, Particle Swarm Optimization algorithm (PSO) is arguably one of the most popular SI paradigms. Over the past two decades, PSO has been applied successfully, with good return as well, in a wide variety of fields of science and technology with a wider range of complex optimization problems, thereby occupying a prominent position in the optimization field. However, through in-depth studies, a number of problems with the algorithm have been detected and identified; e.g., issues regarding convergence, diversity, and stability. Consequently, since its birth in the mid-1990s, PSO has witnessed a myriad of enhancements, extensions, and variants in various aspects of the algorithm, specifically after the twentieth century, and the related research has therefore now reached an impressive state. In this paper, a rigorous yet systematic review is presented to organize and summarize the information on the PSO algorithm and the developments and trends of its most basic as well as of some of the very notable implementations that have been introduced recently, bearing in mind the coverage of paradigm, theory, hybridization, parallelization, complex optimization, and the diverse applications of the algorithm, making it more accessible. Ease for researchers to determine which PSO variant is currently best suited or to be invented for a given optimization problem or application. This up-to-date review also highlights the current pressing issues and intriguing open challenges haunting PSO, prompting scholars and researchers to conduct further research both on the theory and application of the algorithm in the forthcoming years.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2021.107175,Journal,Applied Soft Computing,scopus,2021-06-01,sciencedirect,A real-time hostile activities analyses and detection system,https://api.elsevier.com/content/abstract/scopus_id/85101111750,"Over recent years, the development of online social media has dramatically changed the way people connect and share information. It is undeniable that social platform has promoted the quickest type of spread for fake stories. Almost all the current online fact-checking sources and researches are concentrating on the validating political content and context. The proposed system in this paper provides a complete visual data analytics methods to assist users in achieving a comprehensive understanding of malicious activities at multiple levels such as adversary’s behavior, victim’s behavior, content, and context level. In this paper, we investigate a variety of datasets from different aspects such as role, vulnerabilities, influential level, and distribution pattern. The proposed method in this paper focuses on automatic fake/hostile activity detection by utilizing a variety of machine learning (ML) techniques, deep learning models, natural language processes (NLP), and social network analysis (SNA) techniques. Different auxiliary models, such as bot detection, user credibility, and text readability, are deployed to generate additional influential features. The classification performance of ten different machine learning algorithms using a variety of well-known datasets is evaluated by utilizing 10-fold cross-validation.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.energy.2021.120109,Journal,Energy,scopus,2021-06-01,sciencedirect,Prediction of solar energy guided by pearson correlation using machine learning,https://api.elsevier.com/content/abstract/scopus_id/85101063162,"Solar energy forecasting represents a key element in increasing the competitiveness of solar power plants in the energy market and reducing the dependence on fossil fuels in economic and social development. This paper presents an approach for predicting solar energy, based on machine and deep learning techniques. The relevance of the studied models was evaluated for real-time and short-term solar energy forecasting to ensure optimized management and security requirements in this field while using an integral solution based on a single tool and an appropriate predictive model. The datasets we used in this study, represent data from 2016 to 2018 and are related to Errachidia which is a semi-desert climate province in Morocco. Pearson correlation coefficient was deployed to identify the most relevant meteorological inputs from which the models should learn. RF and ANN have provided high accuracies against LR and SVR, which have reported very significant errors. ANN has shown good performance for both real-time and short-term predictions. The key findings were compared with Pirapora in Brazil, which is a tropical climate region, to show the quality and reproducibility of the study.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2020.12.080,Journal,Information Sciences,scopus,2021-06-01,sciencedirect,Rumor2vec: A rumor detection framework with joint text and propagation structure representation learning,https://api.elsevier.com/content/abstract/scopus_id/85101056591,"Rumors often yield adverse societal and economic impacts. Therefore, rumor detection has attracted a surge of research interests. Existing methods mainly focus on finding clues from textual contents, which is not quite effective as rumors can be intentionally manipulated. Recent studies have demonstrated that the propagation structure of rumors can significantly improve rumor detection performance. However, propagation-based methods are still limited as the propagation structure is often sparse at an early stage. In this study, we propose Rumor2vec, a novel rumor detection framework with joint text and propagation structure representation learning. First, we present the concept of the union graph to incorporate propagation structures of all tweets to mitigate the sparsity issue. Then, we leverage network embedding to learn representations of nodes in the union graph. Finally, we propose a framework for rumor representation learning and detection. Experimental results on three real-world datasets demonstrate that our proposed framework can achieve better performance than the state-of-the-art approaches. On two Twitter datasets, our method achieves 79.6% and 85.2% accuracies respectively. On the Weibo dataset, our method achieves a 95.1% accuracy. Further experiments on early rumor detection show that our method can identify rumors ahead of other methods by at least 12 h.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bioelechem.2021.107744,Journal,Bioelectrochemistry,scopus,2021-06-01,sciencedirect,The electrochemical immunosensor for detection of prostatic specific antigen using quince seed mucilage-GNPs-SNPs as a green composite,https://api.elsevier.com/content/abstract/scopus_id/85100096246,"Prostatic specific antigen (PSA) is known as a biomarker of prostate cancer. In males, prostate cancer is ranked second as leading cause of death out of more than 200 different cancer types1. As a result, early detection of cancer can cause a significant reduction in mortality. PSA concentration directly is related to prostate cancer, so normal serum concentrations in healthy means are 4 ng and above 10 ng as abnormal concentration. Therefore, PSA determination is important to cancer progression. In this study, a free label electrochemical immunosensor was prepared based on a new green platform for the quantitative detection of the PSA. The used platform was formed from quince seed mucilage containing green gold and silver nanoparticles and synthesized by the green method (using Calendula officinalis L. extract). The quince mucilage biopolymer was used as a sub layer to assemble nanoparticles and increase the electrochemical performance. This nanocomposite was used to increase the antibody loading and accelerate the electron transfer, which can increase the biosensor sensitivity. The antibodies of the PSA biomarker were successfully incubated on the green platform. Under the optimal conditions, the electrochemical impedance spectroscopy (EIS) was proportional to the PSA biomarker concentration from 0.1 pg mL−1 to 100 ng mL−1 with low limit of detection (0.078 pg mL−1). The proposed green immunosensor exhibited high stability and reproducibility, which can be used for the quantitative assay of the PSA biomarker in clinical analyses. The results of real sample analysis presented another tool for the PSA biomarker detection in physiologic models.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2021.103988,Journal,Microprocessors and Microsystems,scopus,2021-06-01,sciencedirect,Computer simulation of urban garden landscape design based on FPGA and neural network,https://api.elsevier.com/content/abstract/scopus_id/85099498199,"Digital Landscape is a combination of the system and the computer software and hardware system of a high simulation model. The author analyzes the application of computer simulation in landscape design and value analysis of a city garden. In the computer-aided design, the importance of digitizing information in the landscape design process, mainly human and the interaction of computer, is reflected in the digital model's creation and multimedia performance, becoming more and more evident. To form a two-dimensional or three-dimensional spatial data, to realize real-time, statistical Analysis, using the human living environment, multi-dimensional, efficient, and humane, and environmental landscape plan to more rational and practical, used the computer simulation techniques. Effective use of urban rainwater, to reduce the flooding of urban areas, it is possible to alleviate the water crisis, the organic combination of rainwater can be used in the course of the construction of the urban landscape as well as make-up landscape, visual beautification has optimized the ecosystem, and from many rainwater utilization functions; These functions in landscape design, rainwater garden, It can be realized the rooftop garden, and the city's green. The construction and sustainable economy and the promotion of the ecological park's social development will positively sign. Suitable for rainwater regulation, water (recovery) is stored—Computer-Aided Design (CAD) green space. Technical measures save of suggestions for practical application of the square: innovation and new of space design, new artificial wetland system, and garden rainwater in the application of the regulation (population) storage system design of the water-saving of these to the sustainable development of such new square of rainwater adjustment (group) storage system design and urban landscape environment. It is useful for the application of technology.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cja.2020.09.011,Journal,Chinese Journal of Aeronautics,scopus,2021-06-01,sciencedirect,Framework and development of data-driven physics based model with application in dimensional accuracy prediction in pocket milling,https://api.elsevier.com/content/abstract/scopus_id/85097765922,"In the manufacturing of thin wall components for aerospace industry, apart from the side wall contour error, the Remaining Bottom Thickness Error (RBTE) for the thin-wall pocket component (e.g. rocket shell) is of the same importance but overlooked in current research. If the RBTE reduces by 30%, the weight reduction of the entire component will reach up to tens of kilograms while improving the dynamic balance performance of the large component. Current RBTE control requires the off-process measurement of limited discrete points on the component bottom to provide the reference value for compensation. This leads to incompleteness in the remaining bottom thickness control and redundant measurement in manufacturing. In this paper, the framework of data-driven physics based model is proposed and developed for the real-time prediction of critical quality for large components, which enables accurate prediction and compensation of RBTE value for the thin wall components. The physics based model considers the primary root cause, in terms of tool deflection and clamping stiffness induced Axial Material Removal Thickness (AMRT) variation, for the RBTE formation. And to incorporate the dynamic and inherent coupling of the complicated manufacturing system, the multi-feature fusion and machine learning algorithm, i.e. kernel Principal Component Analysis (kPCA) and kernel Support Vector Regression (kSVR), are incorporated with the physics based model. Therefore, the proposed data-driven physics based model combines both process mechanism and the system disturbance to achieve better prediction accuracy. The final verification experiment is implemented to validate the effectiveness of the proposed method for dimensional accuracy prediction in pocket milling, and the prediction accuracy of AMRT achieves 0.014 mm and 0.019 mm for straight and corner milling, respectively.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2020.114538,Journal,Expert Systems with Applications,scopus,2021-05-15,sciencedirect,Parallel versus cascaded logistic regression trained single-hidden feedforward neural network for medical data,https://api.elsevier.com/content/abstract/scopus_id/85098990261,"Objective
                  An important step towards a better healthcare system is fast and accurate diagnosis. In the last decade, the application of intelligent systems in healthcare has led to impressive results. The goal of this paper is to extend the LogSLFN (single-hidden layer feedforward neural network trained using logistic regression) algorithm, which has been deployed successfully in the past for the case of a two-class decision problem, to the case of multiple classes. We have considered and statistically analyzed two approaches: a parallel LogSLFN, and a cascaded LogSLFN.
               
                  Materials and methods
                  According to the universal approximation theorem, a single-hidden layer feedforward neural network has the ability to approximate arbitrarily closely continuous functions of several real variables under certain reasonable assumptions. Essentially, a single hidden layer containing a finite fixed number of neurons is sufficient to provide an arbitrarily well approximation to a given training set of inputs and a desired target output represented by a continuous function. Parallel LogSLFN and cascaded LogSLFN are two novel approaches that can be applied to multiple-class decision problems. Both methods are extensions of the LogSLFN, which uses logistic regression to compute the weights between the input and hidden layer of a single-hidden layer feedforward network. No error correction is needed, the weights between the hidden and the output layer being computed using the Moore-Penrose pseudoinverse matrix. The proposed models have been tested on two medical datasets regarding cancer diagnosis and liver fibrosis staging. Experimental results and the subsequent statistical analysis have proved the robustness of the proposed models with other machine learning techniques reported in literature.
               
                  Main findings
                  The experimental results showed that the Parallel approach surpasses the Cascaded one. Still, both models are competitive to the other state-of-the-art techniques.
               
                  Conclusions
                  The LogSFLN algorithm can be successfully extended to multiple-class decision problems. By embedding knowledge extracted from the data into the architecture, we obtained a raise by 20% in accuracy when applied on the liver fibrosis dataset.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2021.103787,Journal,Journal of Biomedical Informatics,scopus,2021-05-01,sciencedirect,Can technological advancements help to alleviate COVID-19 pandemic? a review,https://api.elsevier.com/content/abstract/scopus_id/85104674391,"The COVID-19 pandemic is continuing, and the innovative and efficient contributions of the emerging modern technologies to the pandemic responses are too early and cannot be completely quantified at this moment. Digital technologies are not a final solution but are the tools that facilitate a quick and effective pandemic response. In accordance, mobile applications, robots and drones, social media platforms (such as search engines, Twitter, and Facebook), television, and associated technologies deployed in tackling the COVID-19 (SARS-CoV-2) outbreak are discussed adequately, emphasizing the current-state-of-art. A collective discussion on reported literature, press releases, and organizational claims are reviewed. This review addresses and highlights how these effective modern technological solutions can aid in healthcare (involving contact tracing, real-time isolation monitoring/screening, disinfection, quarantine enforcement, syndromic surveillance, and mental health), communication (involving remote assistance, information sharing, and communication support), logistics, tourism, and hospitality. The study discusses the benefits of these digital technologies in curtailing the pandemic and ‘how’ the different sectors adapted to these in a shorter period. Social media and television’s role in ensuring global connectivity and serving as a common platform to share authentic information among the general public were summarized. The World Health Organization and Governments’ role globally in-line with the prevention of propagation of false news, spreading awareness, and diminishing the severity of the COVID-19 was discussed. Furthermore, this collective review is helpful to investigators, health departments, Government organizations, and policymakers alike to facilitate a quick and effective pandemic response.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cjca.2020.12.009,Journal,Canadian Journal of Cardiology,scopus,2021-05-01,sciencedirect,Digital Health Approaches for the Assessment and Optimisation of Hypertension Care Provision,https://api.elsevier.com/content/abstract/scopus_id/85104335482,"Although many aspects of our lives have been transformed by digital innovation, widespread adoption of digital health advancements within the health care sector in general, and for hypertension care specifically, has been limited. However, it is likely that, over the next decade, material increases in the uptake of digital health innovations for hypertension care delivery will be seen. In this narrative review, we summarise those innovations thought to have the greatest chance for impact in the next decade. These include provision of virtual care combined with home blood pressure (BP) telemonitoring, use of digital registries and protocolised care, leveraging continuous BP measurement to collect vast amounts of individual and population-based BP data, and adoption of digital therapeutics to provide low-cost scalable interventions for patients with or at risk for hypertension. Of these, home BP telemonitoring is likely the most ready for implementation, but it needs to be done in a way that enables efficient guideline-concordant care in a cost-effective manner. In addition, efforts must be focused on implementing digital health solutions in a manner that addresses the major challenges to digital adoption. This entails ensuring that innovations are accessible, usable, secure, validated, evidence based, cost-effective, and integrated into the electronic systems that are already used by patients or providers. Increasing the use of broader digital innovations such as artificial/augmented intelligence, data analytics, and interactive voice response is also critically important. The digital revolution holds substantial promise, but success will depend on the ability of collaborative stakeholders to adopt and implement innovative, usable solutions.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.evopsy.2021.03.006,Journal,Evolution Psychiatrique,scopus,2021-05-01,sciencedirect,"From Digital Identity to Connected Personality, From Augmented Diagnostician to Virtual Caregiver: What Are the Challenges for the Psychology and the Psychiatry of the Future?",https://api.elsevier.com/content/abstract/scopus_id/85104125089,"Objectifs
                  Qui sommes-nous devenus, citoyens, patients, praticiens ? En quoi les moyens de communications et l’informatisation de notre société modifient-ils, intègrent-ils nos identités ? L’intelligence artificielle comprendrait-elle bientôt plus justement l’être humain dont elle s’émanciperait ?
               
                  Matériel et méthodes
                  Cheminons à partir de la lexicologie pour tenter de saisir, via le point de vue de la philosophie, l’identité contemporaine vers la notion d’« identité numérique » dont les incidents psychologiques normaux ou pathologiques entraînent ce que nous définissons « la personnalité numérique ». Puis, posant les bases d’une psychologie de l’identité contemporaine, nous envisageons comment « la psychologie » et « la psychiatrie » actuelles considèrent « la personnalité » du patient et, en retour, comment elles se définissent du point du vue du « praticien en ligne » ou du « chercheur connecté ».
               
                  Résultats
                  En échange de son utilisation « gratuite », l’action de l’internaute sur le Web 2.0 produit du contenu et alimente des bases de données, déclaratives ou non. En perte d’intimité au fur et à mesure que « ses » données ne lui appartiennent plus, l’identité du citoyen se décompose en fonctions des supports digitaux : site de rencontre amical, plateforme de liens amoureux, blog concernant un loisir ou un voyage, etc. Par le même mouvement, l’identité numérique se compose en autre-soi possédant une part d’intelligence artificielle pourvoyeuse de capacité d’existence propre. Plutôt que deux entités parallèlement différentiables, réelle ou augmentée, naît une identité hybride « réalistiquo-virtuelle ». Quelles conséquences normales ou pathologiques chez l’être humain ? Les tendances sociétales post-modernes issues du digital ou y trouvant expression peuvent entraîner, chez un individu donné, une exacerbation des traits de personnalité préalablement existants, voire des symptômes. Parallèlement, il arrive que les moyens de communication moderne deviennent une aide pour expérimenter le monde, majorer l’estime de soi, rêver favorablement ses phantasmes, se confier plus facilement à des « inconnu(e)s », etc. Mais dans tous les cas, chez le sujet souffrant, ou ne souffrant pas, préalablement à sa surexposition, de maladie neuropsychiatrique ou de trouble psychopathologique, il s’avère aujourd’hui scientifiquement documenté que la confrontation numérique accrue induit des atteintes neuropsychiques massives (affaiblissement de la mémoire de travail, des capacités d’attention et de concentration, des aptitudes à construire des opérations cognitives élaborées, etc.). Sur le plan psychopathologique, plutôt que la terminologie de « trouble de l’identité » ou une notion de « co-identités », le terme d’« identité trouble » nous paraît le mieux rendre compte de cette mutation du « moi » où la frontière entre réalité et virtualités s’amenuise : la dissociation prévaut. L’homme post-moderne et ses objets connectés ne font plus qu’un, mais cet « uniforme » apparaît constitué d’un patchwork de confettis identificatoires plus ou moins accolés, sans réelle harmonisation d’ensemble. La personnalité commune se marque d’hyperexpressivité et d’hyperémotivité, au détriment de la possibilité de contrôle des affects et du développement des capacités d’introspection. Contre le risque du vide, tend à se développer une contra-phobie par l’ordiphone, par l’objet lui-même, par la possibilité de contacter en permanence ses proches si nécessaire, et en retour rester toujours « disponible », ce qui alimente une forme d’égocentrisme addictogène. Résulte de ses évolutions, globalement dans la société, un affaiblissement des capacités langagières, et ainsi de réflexion, y compris pour l’espace clinique et scientifique.
               
                  Discussion
                  Pour les domaines de la psychologie et de la psychiatrie, s’associent actuellement deux évolutions : une velléité d’« objectivité-scientificité » et une numérisation de la relation patient–soignant. Du côté de la « science », la médecine objective « factuelle » s’intéresse de plus en plus à la pathologie aux dépens du sujet en souffrance, confondant signe et symptôme, glissant jusqu’à un niveau moléculaire, très en-deçà du patient, vers une psychiatrie ou une psychologie « post-clinique ». Qu’on veuille la promouvoir ou l’anéantir, du côté du clinicien ou du chercheur, la « subjectivité » est devenue un signifiant à la mode pour le domaine de la santé psychique. Ce retour actuel du « subjectif » prospère sur une sorte de peur de la subjectivité depuis la fin de la seconde guerre mondiale qui avait entraîné la nosographie américaine vers les « objectifs » des DSM (Manuel Diagnostique et Statistique des Troubles Psychiques publié par l’American Psychiatric Association depuis 1952). Mais plutôt qu’une connaissance validable, et/ou invariable concernant tel ou tel trouble psychique, le changement, la relativité des entités nosographiques d’une version à l’autre du manuel traduit, en miroir, la subjectivité d’une époque, ce que nous appelons « subjectivité sociétale ». Autant qu’elle témoigne de notre temps, la révolution bio-numérique s’imposera probablement dans une future édition de la nosographie : la validité diagnostique devrait se majorer par la définition précise de marqueurs biologiques et/ou neuroradiologiques, si ceux-ci participent à construire une théorie étiopathogénique des phénomènes psychiques observés. Cette orientation reste toutefois balbutiante : outre l’infime nombre de biomarqueurs identifiés, et surtout utilisables en pratique quotidienne, leurs liens de causalité ou de conséquentialité avec les symptômes ou le processus morbide restent le plus souvent incertains autant qu’ils sont fort divers et interreliés. Le chercheur en neurosciences vise à mesurer et analyser une multitude de données, intégrant en particulier les mimiques et les émotions authentifiables par caméra thermique, les mouvements des segments des corps et dynamiques des regards enregistrables par des capteurs, la standardisation des voix et des discours pour analyse par logiciel informatique de la prosodie, des signifiants employés, de la syntaxe… le tout s’intégrant dans un phénotypage digital de la souffrance. Pourra-t-on bientôt parler, en remplacement du psychologue ou du psychiatre, de « diagnosticien augmenté » ?
               
                  Conclusion
                  Apparaît-il actuellement hasardeux de faire confiance à un thérapeute entièrement virtuel… expérience déjà lancée il y a plus de 50 ans ! L’être humain est un « être de sens », or, selon le modèle de la clinique traumatique, le surgissement du tout-numérique peut entraîner un « effondrement du sens » générateur d’une tendance à la dissociation de la personnalité. Accordant le rétablissement des liens entre émotions, affects, comportements et cognitions, le langage parlé atténue puis fait disparaître la dissociation. Guidée par le praticien, cette parole thérapeutique est parfois qualifiée de « maïeutique », du nom de la science de l’accouchement : elle construit synchroniquement à son essence la pensée, et une prise de conscience de celle-ci, plutôt qu’elle n’en rendrait compte secondairement. Il s’agit d’une réinterprétation causale d’un sens compris ou plutôt « attribué » singulièrement par le sujet, après-coup, le passé revisité dans l’instant noue une synthèse, le hasard est transformé en destin. Le sujet qui parle réélabore son histoire vers une reconstruction sémantique, une densification de ses réseaux de signification. Reconquérant son être par la création d’un discours, de méandres véridiques comme fictionnels, la narration, voire la poétisation, offre l’illusion ponctuelle d’une meilleure cohérence, toujours relative, illusoire La parole thérapeutique et le discours sur celle-ci restent en devenir, inachevés, incertains autant que vivants, caractérisant une « post-psychothérapie », c’est-à-dire une psychothérapie et non pas une technique rééducative qui se trouverait figée dans des objectifs connus à l’avance. Les notions de faits et de réalité sont ici secondaires, non pas au sens de l’objectif, ni même du subjectif, mais du second degré, puis d’autres degrés successifs ou imbriqués portant l’effort intellectuel. Vers l’apaisement, si nous voulions amener la réflexion à son paroxysme, nous pourrions avancer qu’il suffirait de donner « n’importe quel sens », d’en choisir un quel qu’il soit, du côté du patient ou du praticien, sans qu’il ne soit nécessairement le même, témoignage d’une construction intersubjective formellement invalide.
               
                  Objectives
                  Who have we become, as citizens, patients, practitioners? How do the means of communication and the computerization of our society, its digitization, modify and integrate our identities? Can we assume that artificial intelligence will soon have a more accurate understanding of the human being from whom it will have emancipated itself?
               
                  Materials and methods
                  We move from lexicology to try to grasp, from the point of view of philosophy, a contemporary identity that is moving towards the notion of a “digital identity” whose normal or pathological psychological incidents lead to what we define as “the digital personality.” Then, laying the foundations for a contemporary psychology of identity, we consider how current “psychology” and “psychiatry” view the patient's “personality” and, in turn, how they define themselves from the point of view of “the patient,” or, inversely, from the point of view of the “online practitioner” or “connected researcher.”
               
                  Results
                  In exchange for its “free” use, the Internet user's action on Web 2.0 produces content and feeds databases, whether this is declared or not. Users’ privacy is lost, as “their” data no longer belongs to them; and citizens’ identity is broken down into digital media functions: a site for meeting friends, a dating platform, a blog about hobbies or travel, etc. At the same time, digital identity is made up of an other-self, including a part of artificial intelligence that provides capacity for its own existence. Rather than two parallel, differentiable entities, real or augmented, a “realistic-virtual” hybrid identity is born. What are the normal or pathological consequences for humans? Postmodern societal trends emerging from or finding expression in the digital can lead to an exacerbation of previously existing personality traits, or even symptoms, in a given individual. At the same time, it happens that the modern means of communication become an aid to experience the world, to increase self-esteem, to dream favorably about one's fantasies, to confide more easily in “strangers,” etc. But in all cases, in the subject suffering, or not suffering, prior to his overexposure, from a neuropsychiatric disease or a psychopathological disorder, it now turns out to be scientifically documented that the increased numerical confrontation induces massive neuropsychic damage (weakening working memory, attention and concentration skills, skills in constructing sophisticated cognitive operations, etc.). On the psychopathological level, rather than the terminology of “identity disorder” or a notion of “co-identities,” the term “identity elusive"" seems to us to best account for this mutation of the “me” where the border between reality and virtualities is shrinking: dissociation prevails. The postmodern human and its connected objects become one, but this “uniformity” appears to be made up of a patchwork of identifying confetti more or less joined together, without a real overall harmonization. The common personality is marked by hyperexpressiveness and hyperemotivity, to the detriment of the possibility of controlling affects and the development of introspective capacities. Against the risk of a vacuum, a contra-phobia tends to develop through the smartphone, by the object itself, by the possibility of constantly contacting relatives if necessary, and in return always remaining “available,” which fuels a form of addicting self-centeredness. The result of these developments, for society in general, is a weakening of language skills, and thus of reflection, including in the clinical and scientific space.
               
                  Discussion
                  For the areas of psychology and psychiatry, two developments are currently associated: a desire for “objectivity-scientificity” and a digitization of the patient–caregiver relationship. On the side of “science,” objective “factual” medicine is increasingly interested in pathology at the expense of the suffering subject, confusing sign and symptom, sliding down to a molecular level, far below the patient, towards psychiatry or postclinical psychology. Whether we want to promote it or destroy it, on the side of the clinician or the researcher, “subjectivity” has become a fashionable signifier in the field of mental health. This current return of the “subjective” thrives on a kind of fear of subjectivity present since the end of World War II, which had led American nosography towards the “objectives” of the DSM (Diagnostic and Statistical Manual of Mental Disorders, published by the American Psychiatric Association since 1952). But rather than a verifiable and/or invariable knowledge concerning a particular psychic disorder, the changes and the relativity of nosographic entities from one version of the manual to another provides us with a mirror image of the subjectivity of an era, which we propose to call “societal subjectivity.” As much as it is a product of our time, the bio-digital revolution will probably impose itself in a future edition of nosography: the diagnostic validity should be increased by the precise definition of biological and/or neuroradiological markers, if these participate in building an etiopathogenic theory of observed psychic phenomena. This orientation remains in its infancy, however: in addition to the tiny number of identified biomarkers, and above all, those that are usable in daily practice, their causal or consequential links with symptoms or with the morbid process remain most often uncertain, inasmuch as they are diverse and interrelated. The neuroscience researcher aims to measure and analyze a multitude of data, integrating, in particular, mimicry and emotions authenticated by thermal camera; movements of body segments and gaze dynamics recorded by sensors; the standardization of voices and speeches for computer software analysis of prosody, used signifiers, syntax… all of which is integrated into a digital phenotyping of suffering. Will we soon be able to speak, replacing the psychologist or the psychiatrist, of an “augmented diagnostician?”.
               
                  Conclusion
                  Does it currently appear risky to trust an entirely virtual therapist… an experiment already launched more than 50 years ago! The human being is a “being of meaning,” yet, according to the model of trauma, the emergence of the all-digital can lead to a “collapse of meaning,” generating a tendency to personality dissociation. Granting the reestablishment of the links between emotions, affects, behaviors, and cognitions, spoken language attenuates dissociation, then makes it disappear. Guided by the practitioner, this therapeutic word is sometimes qualified as “maieutics,” from the name of the science of childbirth: it builds thought synchronously to its essence, and an awareness of it, rather than nondisclosure, would account for it secondarily. It is a causal reinterpretation of a meaning understood or rather “attributed” singularly by the subject, after the fact: the past revisited in the present moment creates a synthesis, and chance is transformed into fate. The speaking subject re-elaborates her/his story towards a semantic reconstruction, a densification of her/his networks of signification. Reclaiming one's being by the creation of a discourse, of veridical as well as fictional meanders, narration, even poetization, offers the punctual illusion of a better coherence, always relative, illusory… Therapeutic speech and discourse about such speech–these are still being made, unfinished, uncertain, and alive. These are the characteristics of what we could a “post-psychotherapy,” that is, a psychotherapy and not a re-educational technique whose objectives would be fixed and known in advance. The notions of facts and reality are secondary here, not in the sense of the objective, nor even of the subjective, but of the second degree, then of other successive or overlapping degrees that require intellectual effort. Moving towards appeasement, if we wanted to bring the reflection to its paroxysm, we could advance that it would be enough to give “any meaning,” whatever it may be. This would apply both to the patient and to the practitioner, without each party's meaning necessarily being the same: a testimony to a formally invalid intersubjective construction.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.trc.2021.102967,Journal,Transportation Research Part C: Emerging Technologies,scopus,2021-05-01,sciencedirect,Automated eco-driving in urban scenarios using deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85103105894,"Urban settings are challenging environments to implement eco-driving strategies for automated vehicles. It is often assumed that sufficient information on the preceding vehicle pulk is available to accurately predict the traffic situation. Because vehicle-to-vehicle communication was introduced only recently, this assumption will not be valid until a sufficiently high penetration of the vehicle fleet has been reached. Thus, in the present study, we employed Reinforcement Learning (RL) to develop eco-driving strategies for cases where little data on the traffic situation are available.
                  An A-segment electric vehicle was simulated using detailed efficiency models to accurately determine its energy-saving potential. A probabilistic traffic environment featuring signalized urban roads and multiple preceding vehicles was integrated into the simulation model. Only information on the traffic light timing and minimal sensor data were provided to the control algorithm. A twin-delayed deep deterministic policy gradient (TD3) agent was implemented and trained to control the vehicle efficiently and safely in this environment.
                  Energy savings of up to 19% compared with a simulated human driver and up to 11% compared with a fine-tuned Green Light Optimal Speed Advice (GLOSA) algorithm were determined in a probabilistic traffic scenario reflecting real-world conditions. Overall, the RL agents showed a better travel time and energy consumption trade-off than the GLOSA reference.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jogoh.2021.102101,Journal,Journal of Gynecology Obstetrics and Human Reproduction,scopus,2021-05-01,sciencedirect,"Relationship between nuclear DNA fragmentation, mitochondrial DNA damage and standard sperm parameters in spermatozoa of infertile patients with leukocytospermia",https://api.elsevier.com/content/abstract/scopus_id/85101970891,"The association of leukocytospermia with male fertility is still under debate. Our objective was to evaluate the association of leukocytospermia with sperm parameters, mitochondrial DNA (mtDNA) variations, and seminal concentration of several oxidative stress and inflammatory cytokines in Tunisian infertile men. The studied patients were divided into two groups: patients without leukocytospermia (Group 1) and patients with leukocytospermia (Group 2). DNA fragmentation significantly increased in group 2 (31.41 %) compared to group 1 (14.68 %) ; (p < 0.001). A total of 115 nucleotide substitutions in mitochondrial DNA were depicted, among which 113 were previously identified. The number of substitutions was more elevated in group 2. Leukocytospermic group had significantly higher MDA (nmole/mL) levels than patients without leukocytospermia (34±24.43 vs 18.94±15.96 ; p 
                     =0.001), GSH (μg/mL) levels were also higher compared to the control group (126.53±22.87 vs 79.4±19.38 ; p < 0.001), SOD (U/mg of protein) levels were higher but without reaching the statistical significance (89.74±74.85 vs 67.56±37.11 ; p = 0.25) ; whereas seminal CAT (μmole H2O2/min/mg of protein) levels were lower in this group (10.66±14.32 vs 27.35±25.28 ; p = 0.012). No statistically significant differences between the two groups of patients were found in the levels of inflammatory cytokines. However, IL-8 level was positively correlated with DNA fragmentation and negatively correlated with vitality. These findings confirm the association between leukocytospermia and sperm DNA damage.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.image.2021.116200,Journal,Signal Processing: Image Communication,scopus,2021-05-01,sciencedirect,Modelling spatio-temporal ageing phenomena with deep Generative Adversarial Networks,https://api.elsevier.com/content/abstract/scopus_id/85100999804,"Deterioration modelling of ageing phenomena on materials is an actively researched topic in computer graphics and vision, with a wide range of applications in domains such as cultural heritage, game programming, material science and virtual reality. As a result significant progress has been accomplished and existing methods are able to produce visually pleasing results that appear realistic. However, there is a very limited connection to comprehensive measurements that actually capture the ageing process of a material. This paper focuses on this gap, aiming to provide a link between physical measurements and deterioration modelling. Based on extensive measurements of texture and surface geometry of artificially aged reference materials, a Deep Learning (DL) framework is proposed that models spatio-temporal variations on the 3D surface geometry and the 2D colour–image appearance. Concretely, the problem of material degradation over time is formulated as an 2D/3D material-to-material translation problem, where the goal is, given an input material and a target degradation time, to output the degraded material at that time. At the core of the method lies a modified conditional Generative Adversarial Network (cGAN), which maps input materials to degraded materials over time. In order to train and deploy the proposed cGAN model, proper data parameterization and augmentation steps are introduced. As shown through extensive experimentation on real data coming from materials commonly found in artwork and from actual artworks, the proposed approach produces high quality results.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ssci.2021.105190,Journal,Safety Science,scopus,2021-05-01,sciencedirect,Beirut explosion 2020: A case study for a large-scale urban blast simulation,https://api.elsevier.com/content/abstract/scopus_id/85100545374,"In the face of continued global urbanization, cities are challenged to satisfy increasing standards in terms of quality of life, environmental conditions, safety, security, health, economic growth and mobility. The concept of “smart cities” aims at utilising advanced technologies, artificial intelligence and high computational capacity to increase their resilience and improve the services provided to the citizens. Computation-based numerical simulations have been essentially used to estimate the effects of explosion events in urban environments in terms of both structural damage and human casualties. These provide urban planners and decision makers with valuable information for vulnerability assessment and aid developing prevention or mitigation solutions. In this article, we present a framework to generate a 3D large-scale urbanistic finite element model, where the desired geospatial data are extracted from the open-source world map OpenStreetMap. The model is used to simulate blast wave propagation effects in a wide urban area taking into account the reflections at building surfaces via a sophisticated Fluid-Structure interaction technique integrated in the EUROPLEXUS explicit finite element method software. The explosion in the Port of Beirut in Lebanon, which took place on the 4th of August 2020, was remarkable for the large amount of explosive material causing considerable damage to surrounding structures and a high number of deaths and injured. Such characteristics make the event suitable for assessing the performance of the proposed computational approach in a widely exposed (by the blast wave) urban zone.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2021.01.004,Journal,Information Sciences,scopus,2021-05-01,sciencedirect,A Blockchain-based approach for matching desired and real privacy settings of social network users,https://api.elsevier.com/content/abstract/scopus_id/85100433895,"Social networks store a considerable amount of personal data, which are also a source of information for business. To comply with users’ privacy rights, all social networks allow users to select the level of privacy they desire. However, what occurs if the privacy choices of a user are modified unilaterally by the social network? The privacy settings chosen by the user are stored by the social network, which acts as a privileged party, which could tamper with the user’s choices at any time. This paper addresses this problem and proposes a decentralized approach to manage the privacy settings of a user. Any change in the privacy settings of a social network user is validated by a smart contract to ensure that it is compliant with users’ expectations. The proposed solution has been implemented as an Ethereum-based decentralized application to validate the effectiveness of the proposed approach.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2020.12.091,Journal,Information Sciences,scopus,2021-05-01,sciencedirect,Positive opinion maximization in signed social networks,https://api.elsevier.com/content/abstract/scopus_id/85100398765,"Opinion maximization is a kind of optimization method, which leverages a subset of influential nodes in social networks to spread user opinions towards the target product and eventually obtains the largest opinion propagation. The current propagation models on the opinion maximization mainly focus on the activated nodes and the static opinion formation process. However, they neglect the combination between the activated nodes and the dynamic opinion formation process. Moreover, previous studies are more attentive to the positive relationships among users. In the real scenario, negative relationships among users may damage the product reputation. Therefore, in this paper, we study positive opinion maximization by using an Activated Opinion Maximization Framework (AOMF) in signed social networks. The proposed AOMF is composed of three phases: i) the selection of candidate seed nodes, ii) the activated opinion formation process and iii) the determination of seed nodes. We first use an effective heuristic rule to select candidate seed nodes. To model the activation and dynamic opinion formation process of network nodes, we devise the activated opinion formation model based on the multi-stage linear threshold model and the Degroot model. Then, we calculate the opinion propagation of each candidate seed node by using the activated opinion formation model. Based on the candidate seed nodes and the activated opinion formation process, seed nodes are further determined. Finally, experimental results on six social network datasets demonstrate that the proposed method has superior potential opinions and positive ratio than the chosen benchmarks.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2020.114139,Journal,Expert Systems with Applications,scopus,2021-04-15,sciencedirect,A dynamic framework for tuning SVM hyper parameters based on Moth-Flame Optimization and knowledge-based-search,https://api.elsevier.com/content/abstract/scopus_id/85099517458,"In the real world, most of the collections of data are dynamic in nature, i.e. their size may grow with time. This dynamic nature of the data not only reduces the performance of the classifiers but also demands more optimized models for retaining the performance. Due to this, machine learning models developed in a static environment cannot be deployed efficiently to solve the real-world problems. Nowadays, maximum existing works consider only the static behaviour of the data for the training of machine learning models where the size of the collection of training data does not change over time. This paperwork imposes Support Vector Machine (SVM) in a dynamic environment. It has been identified that shifting of the optimum values of two hyper-parameters C (Penalty Parameter) and γ (Kernel Parameter) in the search space is one of the primary reasons for the performance degradation of SVM in dynamic environment. This paper proposes a novel framework that uses a new optimization module Knowledge-Based-Search (KBS) along with Moth –Flame Optimization (MFO) to optimize 
                        
                           C
                        
                      and 
                        
                           γ
                        
                      in a dynamic environment to train SVM efficiently. KBS uses knowledge gathered at various instances of time, which are the bi-products of MFO. MFO in our framework is the base optimization algorithm which works underneath KBS. The experiments have shown that KBS helps in controlling the exponential growth of the time complexity of the optimization process where only MFO is used to optimize 
                        
                           C
                        
                      and
                        
                           γ
                        
                     . Integration of KBS with MFO brings down the time complexity to a large extent. To validate the proposed framework we have used a simulated dynamic environment for profit/loss classification problem for organizations. The experiments have also shown that KBS's integration with MFO outperforms integration of KBS with other modern optimization techniques such as Particle Swarm Optimization (PSO), Multi-Verse Optimization (MVO), Grey-Wolf Optimization (GWO), Cuckoo Search (CS), Whale Optimization Algorithm (WOA), Genetic Algorithm (GA), Fire-Fly Algorithm (FFA) and Salp Swarm Algorithm (SSA).",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2020.114402,Journal,Expert Systems with Applications,scopus,2021-04-15,sciencedirect,Unsupervised feature selection for attributed graphs,https://api.elsevier.com/content/abstract/scopus_id/85097572982,"Many real-world applications generate attributed graphs that contain both link structures and content information associated with nodes. Content information in real networks always contains high dimensional feature space. In recent years, unsupervised feature selection has been widely used in handling high dimensional data without label information. Most existing unsupervised feature selection methods assume that instances in datasets are independent and identically distributed. However, instances in attributed graphs are intrinsically correlated. Considering the wide applications of feature selection in attributed graphs, we propose a new unsupervised feature selection method based on regularized sparse learning. We use pseudo class labels to learn the interdependency from both link and content information, and embed the obtained information into a sparse learning based feature selection framework. In particular, a new regularization term is designed to learn link information, which capture group behavior among the connected instances utilizing latent social dimensions. To solve the proposed feature selection model, we consider both convex and nonconvex cases and design the corresponding algorithms based on the Alternating Direction Method of Multipliers (ADMM) combined with ConCave Convex Procedure (CCCP). Numerical studies are implemented on real-world datasets to validate the advantage of our new method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2021.100225,Journal,Patterns,scopus,2021-04-09,sciencedirect,Machine learning discovery of high-temperature polymers,https://api.elsevier.com/content/abstract/scopus_id/85104127192,"To formulate a machine learning (ML) model to establish the polymer's structure-property correlation for glass transition temperature 
                        
                           
                              T
                              g
                           
                        
                     , we collect a diverse set of nearly 13,000 real homopolymers from the largest polymer database, PoLyInfo. We train the deep neural network (DNN) model with 6,923 experimental 
                        
                           
                              T
                              g
                           
                        
                      values using Morgan fingerprint representations of chemical structures for these polymers. Interestingly, the trained DNN model can reasonably predict the unknown 
                        
                           
                              T
                              g
                           
                        
                      values of polymers with distinct molecular structures, in comparison with molecular dynamics simulations and experimental results. With the validated transferability and generalization ability, the ML model is utilized for high-throughput screening of nearly one million hypothetical polymers. We identify more than 65,000 promising candidates with 
                        
                           
                              T
                              g
                           
                        
                      > 200°C, which is 30 times more than existing known high-temperature polymers (∼2,000 from PoLyInfo). The discovery of this large number of promising candidates will be of significant interest in the development and design of high-temperature polymers.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bioorg.2021.104719,Journal,Bioorganic Chemistry,scopus,2021-04-01,sciencedirect,Flavonoids from Pterogyne nitens as Zika virus NS2B-NS3 protease inhibitors,https://api.elsevier.com/content/abstract/scopus_id/85101244114,"Although the widespread epidemic of Zika virus (ZIKV) and its neurological complications are well-known there are still no approved drugs available to treat this arboviral disease or vaccine to prevent the infection. Flavonoids from Pterogyne nitens have already demonstrated anti-flavivirus activity, although their target is unknown. In this study, we virtually screened an in-house database of 150 natural and semi-synthetic compounds against ZIKV NS2B-NS3 protease (NS2B-NS3p) using docking-based virtual screening, as part of the OpenZika project. As a result, we prioritized three flavonoids from P. nitens, quercetin, rutin and pedalitin, for experimental evaluation. We also used machine learning models, built with Assay Central® software, for predicting the activity and toxicity of these flavonoids. Biophysical and enzymatic assays generally agreed with the in silico predictions, confirming that the flavonoids inhibited ZIKV protease. The most promising hit, pedalitin, inhibited ZIKV NS2B-NS3p with an IC50 of 5 μM. In cell-based assays, pedalitin displayed significant activity at 250 and 500 µM, with slight toxicity in Vero cells. The results presented here demonstrate the potential of pedalitin as a candidate for hit-to-lead (H2L) optimization studies towards the discovery of antiviral drug candidates to treat ZIKV infections.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijar.2021.01.004,Journal,International Journal of Approximate Reasoning,scopus,2021-04-01,sciencedirect,Revealed preference in argumentation: Algorithms and applications,https://api.elsevier.com/content/abstract/scopus_id/85100748656,"Argumentative agents in AI are inspired by how humans reason by exchange of arguments. Given the same set of arguments possibly attacking one another (Dung's AA framework) these agents are bound to accept the same subset of those arguments (aka extension) unless they reason by different argumentation semantics. However humans may not be so predictable, and in this paper we assume that this is because any real agent's reasoning is inevitably influenced by her own preferences over the arguments. Though such preferences are usually unobservable, their effects on the agent's reasoning cannot be washed out. Hence by reconstructing her reasoning process, we might uncover her hidden preferences, which then allow us to predict what else the agent must accept. Concretely we formalize and develop algorithms for such problems as uncovering the hidden argument preference relation of an agent from her expressed opinion, by which we mean a subset of arguments or attacks she accepted from a given AA framework; and uncovering the collective preferences of a group from a dataset of individual opinions. A major challenge we addressed in this endeavor is to deal with “answer sets” of argument preference relations which are generally exponential or even infinite. So we start by developing a compact representation for such answer sets called preference states. Preference revelation tasks are then structured as derivations of preference states from data, and reasoning prediction tasks are reduced to manipulations of derived preference states without enumerating the underlying (possibly infinite) answer sets. We also apply the presented results to two non-trivial problems: learning preferences over rules in structured argumentation with priorities – an open problem so far; and analyzing public polls in apparently deeper ways than existing social argumentation frameworks allow.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.nano.2020.102355,Journal,"Nanomedicine: Nanotechnology, Biology, and Medicine",scopus,2021-04-01,sciencedirect,Endocytosed silver nanoparticles degrade in lysosomes to form secondary nanoparticle structures during expression of autophagy genes in osteogenic cells,https://api.elsevier.com/content/abstract/scopus_id/85100660817,"Silver nanoparticles (AgNPs) are increasingly used in combination with biomaterials, such as bone grafts, to provide antimicrobial properties. Our research focused on the cytotoxic and intracellular uptake mechanism of AgNPs on osteogenic cells, and the affected gene expression of osteoblasts exposed to AgNPs. Osteoblast cells were found to be relatively resistant to AgNP exposure, compared to osteoclasts, with a higher IC50 and fewer adverse morphological features. AgNPs were endocytosed within lysosomes, which resulted in the secondary internal formation of curved AgO nano-chains assemblies within the cytosol. Furthermore, osteoblasts demonstrated an oxidative stress response, with autophagic cell death mechanisms, as indicated from qRT2-PCR analysis, with sustained upregulation of the protective gene Heme Oxygenase 1 reaching 86-fold by 48 hours (10 μg/mL). The internalization and fate of AgNPs in osteogenic cells, and the resulting impact on gene expression over time provide further understanding of the nanotoxicity mechanism of AgNPs.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jnca.2021.102995,Journal,Journal of Network and Computer Applications,scopus,2021-04-01,sciencedirect,Dew computing-inspired health-meteorological factor analysis for early prediction of bronchial asthma,https://api.elsevier.com/content/abstract/scopus_id/85100605135,"Bronchial asthma is one of the most common chronic diseases of childhood and considered as a major health problem globally. The irregularity in meteorological factors has become a primary cause of health severity for the individuals suffering from asthma. In the presented research, a dew-cloud assisted cyber-physical system (CPS) is proposed to analyze the correlation between the meteorological and health parameters of the individuals. The work is primarily focused on determining the health adversity caused by the irregular scale of meteorological factors in real-time. IoT-assisted smart sensors are utilized to capture ubiquitous information from indoor environment that make a vital impact on the health of the individual directly or indirectly. The data is analyzed over the cyber-space to quantify the probable irregular health events by utilizing the data classification efficiency of Weighted-Naïve Bayes modeling technique. Moreover, the relationship between meteorological and health parameters is estimated by utilizing the Adaptive Neuro-Fuzzy Inference System (ANFIS) and calculate a unifying factor over the temporal scale. To validate the monitoring performance, the proposed model is implemented in the four schools of Jalandhar, India. The experimental evaluation of the proposed model acknowledges the performance efficiency through several statistical approaches. Furthermore, the comparative analysis is evaluated with state-of-the-art decision-making algorithms that demonstrate the effectiveness of the proposed solution for the targeted application.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.autcon.2021.103603,Journal,Automation in Construction,scopus,2021-04-01,sciencedirect,A field parameters-based method for real-time wear estimation of disc cutter on TBM cutterhead,https://api.elsevier.com/content/abstract/scopus_id/85100241917,"In hard rock TBM tunneling, the loss caused by disc cutter wear accounts for a large proportion of time and cost for the entire project. However, existing disc cutter wear prediction models mainly focus on predicting cutter consumption before construction and cannot predict the wear of each disc cutter. Moreover, the accurate rock parameters required in these models are challenging to obtain. Hence, these models are not capable of determining which cutter on cutterhead should be replaced during construction. To solve the problems mentioned above, this paper presents a novel field parameters-based method for estimating the wear of each disc cutter in real-time. The proposed method is implemented through the following steps. To begin with, a new health index is constructed and defined as the ratio of the rolling distance of a cutter in a small excavated section to its maximum rolling distance. Then, specific field parameters related to the new health index are analyzed and selected. Thereafter, the mapping model between the new health index and the specific field parameters is established based on a one-dimensional convolutional neural network. Finally, on the basis of the established model, the estimated health indices corresponding to all excavated sections of a disc cutter are accumulated to obtain its health status. The field data obtained from Mumbai metro tunnel was utilized to verify the effectiveness of the proposed method, which demonstrates that the proposed method can estimate the wear of each disc cutter in real-time with average accuracy as high as 87.8% on the test set. Therefore, the proposed method is capable of significantly reducing the time and cost of cutter inspection, replacement, and repair for TBM, thereby improve tunneling efficiency and reduce construction cost.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.petrol.2020.108296,Journal,Journal of Petroleum Science and Engineering,scopus,2021-04-01,sciencedirect,Geological structure-guided hybrid MCMC and Bayesian linearized inversion methodology,https://api.elsevier.com/content/abstract/scopus_id/85100209414,"Seismic inversion is a common method for hydrocarbon reservoir characterization, as it consists of a proven and effective approach to derive elastic properties from reflectivity seismic data. Markov Chain Monte Carlo (MCMC) based seismic inversion approach is a suitable choice to numerically evaluate the posterior uncertainties associated with the inverse solution without assuming linear forward operators, Gaussian, or generalized Gaussian prior models. However, the existing MCMC based seismic inversion approaches are mostly performed trace-by-trace, which means that the spatial coupling of model parameters is not considered. When the results of trace-by-trace based inversion are combined to generate a 2D profile, the final results will be laterally discontinuous. Moreover, the large dimension of the model space causes low convergence efficiency of MCMC-based seismic inversion. To overcome these issues, a geological structure-guided hybrid MCMC and Bayesian linearized inversion (BLI) methodology for seismic inversion is implemented. The geological structure information obtained using plane wave destruction (PWD) is incorporated to the MCMC based inversion algorithm in the form of dips yields more geologically meaningful results. The hybrid MCMC and BLI strategy, which takes advantage of BLI's high efficiency to provide initial configuration for MCMC, is used to improve the convergence of MCMC-based inversion. Additionally, the block coordinate descent (BCD) algorithm is introduced to replace the large-scale matrix solution in geological structure-guided, and consequently reduce memory consumption and time cost. This methodology is validated on a synthetic seismic dataset, as well as on a real case. It has proven to be a reliable approach to obtain acoustic impedance (AI) from post-stack seismic data in an efficient way. It also addresses the uncertainty related with the ill-posed characteristics of the inversion methodology itself.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.actaastro.2021.01.048,Journal,Acta Astronautica,scopus,2021-04-01,sciencedirect,A transfer learning approach to space debris classification using observational light curve data,https://api.elsevier.com/content/abstract/scopus_id/85100001105,"This paper presents a data driven approach to space object characterisation through the application of machine learning techniques to observational light curve data. One-dimensional convolutional neural networks are shown to be effective at classifying the shape of objects from both simulated and real light curve data. To the best of the authors’ knowledge this is the first generalised attempt to classify the shape of space objects using real observational light curve data.
                  It is also demonstrated that transfer learning is successful in improving the overall classification accuracy on real light curve datasets. The authors develop a simulated light curve dataset using a high fidelity three-dimensional ray-tracing software. The simulator takes in a textured geometric model of a Resident Space Object as well as its ephemeris and uses ray-tracing software to generate photo-realistic images of the object that are then processed to extract the light curve. Models that are pre-trained on the simulated dataset and then fine-tuned on the real datasets are shown to outperform models purely trained on the real datasets. This result indicates that transfer learning will allow organisations to effectively utilise deep learning techniques without the requirement to build up large real light curve datasets for training.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cma.2020.113609,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2021-04-01,sciencedirect,The Arithmetic Optimization Algorithm,https://api.elsevier.com/content/abstract/scopus_id/85099194941,"This work proposes a new meta-heuristic method called Arithmetic Optimization Algorithm (AOA) that utilizes the distribution behavior of the main arithmetic operators in mathematics including (Multiplication (
                        M
                     ), Division (
                        D
                     ), Subtraction (
                        S
                     ), and Addition (
                        A
                     )). AOA is mathematically modeled and implemented to perform the optimization processes in a wide range of search spaces. The performance of AOA is checked on twenty-nine benchmark functions and several real-world engineering design problems to showcase its applicability. The analysis of performance, convergence behaviors, and the computational complexity of the proposed AOA have been evaluated by different scenarios. Experimental results show that the AOA provides very promising results in solving challenging optimization problems compared with eleven other well-known optimization algorithms. Source codes of AOA are publicly available at and .",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2020.11.042,Journal,Information Sciences,scopus,2021-04-01,sciencedirect,Information spreading with relative attributes on signed networks,https://api.elsevier.com/content/abstract/scopus_id/85098456560,"During the past years, network dynamics has been widely investigated in various disciplines. As a practical and convenient description for social networks, signed networks have also garnered significant attention. In this work, we study information spreading with relative attributes on signed networks, where edges are assigned positive or negative labels, describing friendly or hostile relationships. We define the attribute of information by a degree that can be either ‘good’ or ‘bad’ and assume that the spreading willingness of the information receiver depends on not only its relation with others but also the attribute of information. A pair-wise potential relation identification algorithm is designed based on the shortest path approach and structural balance theory. Both simulations on randomly signed networks and empirical experiments on real datasets show that the proposed information spreading could be approximately investigated within a local 2-order neighborhood. In addition, the ratio of potential friendly nodes with a target node is consist with network content. Finally, the propagation speed of ‘good’ information would unexpectedly slow down when the ratio of positive edges is larger than an estimated threshold. The presented model could be referred to in real social scenarios, such as product promotion, advertisement media, and rumor mongering.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.envpol.2020.115900,Journal,Environmental Pollution,scopus,2021-04-01,sciencedirect,Understanding the true effects of the COVID-19 lockdown on air pollution by means of machine learning,https://api.elsevier.com/content/abstract/scopus_id/85097107266,"During March 2020, most European countries implemented lockdowns to restrict the transmission of SARS-CoV-2, the virus which causes COVID-19 through their populations. These restrictions had positive impacts for air quality due to a dramatic reduction of economic activity and atmospheric emissions. In this work, a machine learning approach was designed and implemented to analyze local air quality improvements during the COVID-19 lockdown in Graz, Austria. The machine learning approach was used as a robust alternative to simple, historical measurement comparisons for various individual pollutants. Concentrations of NO2 (nitrogen dioxide), PM10 (particulate matter), O3 (ozone) and Ox (total oxidant) were selected from five measurement sites in Graz and were set as target variables for random forest regression models to predict their expected values during the city’s lockdown period. The true vs. expected difference is presented here as an indicator of true pollution during the lockdown. The machine learning models showed a high level of generalization for predicting the concentrations. Therefore, the approach was suitable for analyzing reductions in pollution concentrations. The analysis indicated that the city’s average concentration reductions for the lockdown period were: -36.9 to −41.6%, and −6.6 to −14.2% for NO2 and PM10, respectively. However, an increase of 11.6–33.8% for O3 was estimated. The reduction in pollutant concentration, especially NO2 can be explained by significant drops in traffic-flows during the lockdown period (−51.6 to −43.9%). The results presented give a real-world example of what pollutant concentration reductions can be achieved by reducing traffic-flows and other economic activities.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.adhoc.2020.102360,Journal,Ad Hoc Networks,scopus,2021-03-15,sciencedirect,VOCkit: A low-cost IoT sensing platform for volatile organic compound classification,https://api.elsevier.com/content/abstract/scopus_id/85097468733,"Improvements in small sized sensors allow the easy detection of the presence of Volatile Organic Compounds (VOCs) in the air using easy-to-deploy Internet of Things (IoT) devices. However, classifying what VOC exists in the environment still remains as a complex task. Knowing what VOCs are in the air can help us remove the main cause that vents VOC materials as a way to maintain clean air quality. In this work, we present VOCkit, an IoT sensor kit for non-chemical experts to easily detect and classify different types of VOCs. VOCkit combines miniature chemically-designed fluorometric sensors for recognizing VOCs with an embedded imaging system for classification. Exposing the fluorometric sensors with various VOCs, result in the photophysical property change of fluorescent compounds, which composes the sensors, and the synergistic combination of the changes create unique individual fluorescent color patterns respectively to the VOC material. The fluorescent color change pattern is captured using an embedded camera and the images are processed with machine learning algorithms on the embedded platform for VOC classification. Using 500 fluorometric sensor images collected for five different commonly contactable VOCs, we show the feasibility of VOC classification on small-sized IoT devices. For the VOC types of our interest, our results show a classification accuracy of 97%, implying the potential applicability of VOCkit for real-world usage.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2021.100220,Journal,Patterns,scopus,2021-03-12,sciencedirect,Safe Blues: The case for virtual safe virus spread in the long-term fight against epidemics,https://api.elsevier.com/content/abstract/scopus_id/85102307395,"Viral spread is a complicated function of biological properties, the environment, preventative measures such as sanitation and masks, and the rate at which individuals come within physical proximity. It is these last two elements that governments can control through social-distancing directives. However, infection measurements are almost always delayed, making real-time estimation nearly impossible. Safe Blues is one way of addressing the problem caused by this time lag via online measurements combined with machine learning methods that exploit the relationship between counts of multiple forms of the Safe Blues strands and the progress of the actual epidemic. The Safe Blues protocols and techniques have been developed together with an experimental minimal viable product, presented as an app on Android devices with a server backend. Following initial exploration via simulation experiments, we are now preparing for a university-wide experiment of Safe Blues.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2020.11.066,Journal,Neurocomputing,scopus,2021-03-07,sciencedirect,BayeSuites: An open web framework for massive Bayesian networks focused on neuroscience,https://api.elsevier.com/content/abstract/scopus_id/85098065075,"BayeSuites is the first web framework for learning, visualizing, and interpreting Bayesian networks (BNs) that can scale to tens of thousands of nodes while providing fast and friendly user experience. All the necessary features that enable this are reviewed in this paper; these features include scalability, extensibility, interoperability, ease of use, and interpretability. Scalability is the key factor in learning and processing massive networks within reasonable time; for a maintainable software open to new functionalities, extensibility and interoperability are necessary. Ease of use and interpretability are fundamental aspects of model interpretation, fairly similar to the case of the recent explainable artificial intelligence trend. We present the capabilities of our proposed framework by highlighting a real example of a BN learned from genomic data obtained from Allen Institute for Brain Science. The extensibility properties of the software are also demonstrated with the help of our BN-based probabilistic clustering implementation, together with another genomic-data example.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.medidd.2021.100081,Journal,Medicine in Drug Discovery,scopus,2021-03-01,sciencedirect,Peptides in chemical space,https://api.elsevier.com/content/abstract/scopus_id/85104918401,"Peptides, defined as sequences of amino acids up to approximately 50 residues in length, represent an extremely large reservoir of potentially bioactive compounds, referred to here as the peptide chemical space. Recent advances in computer hardware and software have led to a wide application of computational methods to explore this chemical space. Here, we review different in silico approaches including structure-based design, genetic algorithms, and machine learning. We also review the use of molecular fingerprints to sample virtual libraries and to visualize the peptide chemical space. Finally, we present an overview of the known peptide chemical space in form of an interactive map representing 40,531 peptides collected from eleven open-access peptide and peptide-containing databases, accessible at https://tm.gdb.tools/map4/peptide_databases_tmap/. These peptides are displayed as TMAP (Tree-Map) according to their molecular fingerprint similarity computed using MAP4, a MinHashed atom pair fingerprint well suited to analyze large molecules.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.clineuro.2021.106524,Journal,Clinical Neurology and Neurosurgery,scopus,2021-03-01,sciencedirect,Clinical application of Myelopathy-hand Functional Evaluation System in evaluating the postoperative hand motor function for myelopathy patients,https://api.elsevier.com/content/abstract/scopus_id/85100619463,"Objective
                  Recovery of hand motor function after surgical treatment in myelopathy patients is commonly observed. Accurate evaluation of postoperative hand function contributes to assessing the efficacy of surgical treatment. However, no objective and effective evaluation method has been widely accepted in clinical practice. Therefore, the study aimed to explore the value of Myelopathy-hand Functional Evaluation System (MFES) in assessing the postoperative hand function for myelopathy patients.
               
                  Material and method
                  MFES mainly consist of a pair of wise-gloves and a computer with software. One hundred and thirty myelopathy patients were included and all of them received optimal surgery treatment. The Japanese Orthopaedic Association (JOA) scores were marked at preoperative and at 6 months after surgery. All patients were asked to perform the 10-s grip and release test, and the hand movements were simulated and converted into waveforms by MFES. The waveform parameters were measured and analyzed.
               
                  Results
                  The JOA scores and the number of grip-and-release (G–R) cycles significantly increased after surgery. Correspondingly, the waveforms of ulnar three fingers were significantly higher and narrower, along with the significantly declined average time per cycle in postoperative. The a/b ratio (Wave height/wave width) of five fingers were significantly higher in postoperative than that in preoperative. Based on the improvement rate of a/b, the excellent and good rate of surgical outcomes was 62.30 %, which was significantly higher than that (47.69 %) based on the improvement rate of JOA scores (P = 0.019).
               
                  Conclusion
                  MFES is an effective assessment tool in evaluating the postoperative hand function for myelopathy patients.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ecoinf.2021.101231,Journal,Ecological Informatics,scopus,2021-03-01,sciencedirect,Collect and analysis of agro-biodiversity data in a participative context: A business intelligence framework,https://api.elsevier.com/content/abstract/scopus_id/85100383752,"In France and Europe, farmland represents a large fraction of land cover. The study and assessment of biodiversity in farmland is therefore a major challenge. To monitor biodiversity across wide areas, citizen science programs have demonstrated their effectiveness and relevance. The involvement of citizens in data collection offers a great opportunity to deploy extensive networks for biodiversity monitoring. But citizen science programs come with two issues: large amounts of data to manage and large numbers of participants with heterogeneous skills, needs and expectations about these data. In this article, we offer a solution to these issues, concretized by an information system. The study is based on a real life citizen science program tailored for farmers. This information system provides data and tools at several levels of complexity, to fit the needs and the skills of several users, from citizens with basic IT knowledge to scientists with strong statistical background. The proposed system is designed as follows. First, a data warehouse stores the data collected by citizens. This data warehouse is modelled depending on future data analysis. Secondly, associated with the data warehouse, a standard OLAP tool enables citizens and scientists to explore data. To complete the OLAP tool, we implement and compare four feature selection methods, in order to rank explanatory factors according to their relevance. Finally, for users with extended statistical skills, we use Generalized Linear Mixed Models to explore the temporal dynamics of invertebrate diversity in farmland ecosystems. The proposed system, a combination of business intelligence tools, data mining methods and advanced statistics, offers an example of complete exploitation of data by several user profiles. The proposition is supported by a real life citizen science program, and can be used as a guideline to design information systems in the same field.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.chemphyslip.2021.105049,Journal,Chemistry and Physics of Lipids,scopus,2021-03-01,sciencedirect,Antiviral activity of stearylamine against chikungunya virus,https://api.elsevier.com/content/abstract/scopus_id/85100148703,"Chikungunya, a mosquito-borne disease that causes high fever and severe joint pain in humans, is a profound global threat because of its high rate of contagion and lack of antiviral interventions or vaccines for controlling the infection. The present study was aimed to investigate the antiviral activity of Stearylamine (SA) against Chikungunya virus (CHIKV) in both in vitro and in vivo. The antiviral activity of SA was determined by foci forming unit (FFU) assay, quantitative RT-PCR and cell-based immune-fluorescence assay (IFA). Further in vivo studies were carried out to see the effect of SA treatment in CHIKV infected C57BL/6 mice. The anti-CHIKV activity was evaluated using qRT-PCR in serum and muscle tissues at different time points and by histopathology. In vitro treatment with SA at a concentration of 50 μM showed a reduction of 1.23 ± 0.19 log10 FFU/mL at 16 h and 1.56 ± 0.12 log10 FFU/mL at 24 h posttreatment by FFU assay. qRT-PCR studies indicated that SA treatment at 50μM concentration showed a singnificant reduction of 1.6 ± 0.1 log10 and 1.27 ± 0.12 log10 RNA copies when compared with that of virus control at 16 and 24 h post incubation. Treatments in the C57BL/6 mice model revealed that SA at 20 mg/kg dose per day up to 3, 5 and 7 days, produced stronger inhibition against CHIKV indicating substantially decrease viral loads and inflammatory cell migration in comparison to a dose of 10 mg/kg. This first in vivo study clearly indicates that SA is effective by significantly reducing virus replication in serum and muscles. As a next-generation antiviral therapeutic, these promising results can be translated for the use of SA to rationalize and develop an ideal delivery system alone or in combination against CHIKV.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.berh.2021.101662,Journal,Best Practice and Research: Clinical Rheumatology,scopus,2021-03-01,sciencedirect,Managing patients using telerheumatology: Lessons from a pandemic,https://api.elsevier.com/content/abstract/scopus_id/85100105533,"The coronavirus disease 2019 (COVID-19) pandemic has presented unique challenges to rheumatology provision. Measures to control the pandemic have limited face-to-face contact with rheumatology healthcare professionals. One innovation has been the widespread adoption of telerheumatology to assist in the care of patients with rheumatic and musculoskeletal diseases, building on an existing evidence base in rheumatology. Widespread adoption has only occurred following the COVID-19 pandemic. We discuss the evidence supporting telerheumatology adoption prior to the pandemic, and outline several innovative approaches used to assist in the care of rheumatology patients that have been introduced. Alongside the advantages of these interventions, we discuss the limitations and regulatory challenges. Advances must be balanced, considering wider issues of equity of access, implementation, adoption, and sustainability of telerheumatology post-pandemic. We propose it is not ‘if’, but ‘how’ rheumatologists embrace newer telerheumatology technology, outlining practice points and future research agenda.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2020.103786,Journal,Microprocessors and Microsystems,scopus,2021-03-01,sciencedirect,Student Psychological Management System Based on FPGA Embedded System and Data Mining,https://api.elsevier.com/content/abstract/scopus_id/85099630662,"People are social beings and rarely live and work in detachment and intentionally and unknowingly create and deal with our relationships. Relationships depend primarily on the outcome of our activities and our ability to deal with our actions. From adolescence, each gains information and involvement in getting others and how to proceed in every single situation in daily life. In the existing method based on Convolution neural network and Image Processing system for the Psychological Management system. The drawback of the previous method is uneven communication in Psychological Management. So in the proposed method is based on FPGA (Field Programmable Gate Arrays) and Data Mining. The practice and understanding in communicating and monitoring relationships in our work environment. The whole arrangement of human resource management revolves around this central issue of overseeing relations in the workplace. Utilizing an individual's deep, social, psychological, and intellectual abilities in the planning and implementation from the focus on activity outcomes and emphasis on efforts made by combining the oriental hypothesis of ritual or activity benefit from complimentary brain research from the inadequate approach of the clinical infection model. The data mining method has an incredible guarantee for significant hypnotic commitment, set in real situations, and solves grave results' administrative problems.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.watres.2021.116806,Journal,Water Research,scopus,2021-03-01,sciencedirect,Soft sensor predictor of E. coli concentration based on conventional monitoring parameters for wastewater disinfection control,https://api.elsevier.com/content/abstract/scopus_id/85099446770,"Real-time acquisition of indicator bacteria concentration at the inlet of disinfection unit is a fundamental support to the control of chemical and ultraviolet wastewater disinfection. Culture-based enumeration methods need time-consuming laboratory analyses, which give results after several hours or days, while newest biosensors rarely provide information about specific strains and outputs are not directly comparable with regulatory limits as a consequence of measurement principles.
                  In this work, a novel soft sensor approach for virtual real-time monitoring of E. coli concentration is proposed. Conventional wastewater physical and chemical indicators (chemical oxygen demand, total nitrogen, nitrate, ammonia, total suspended solids, conductivity, pH, turbidity and absorbance at 254 nm) and flowrate were studied as potential predictors of E. coli concentration relying on data collected from three full-scale wastewater treatment plants. Different methods were compared: (i) linear modeling via ordinary least squares; (ii) ridge regression; (iii) principal component regression and partial least squares; (iv) non-linear modeling through artificial neural networks.
                  Linear soft sensors reached some degree of accuracy, but performances of the artificial neural network based models were by far superior. Sensitivity analysis allowed to prioritize the importance of each predictor and to highlight the site-specific nature of the approach, because of the site-specific nature of relationships between predictors and E. coli concentration. In one case study, pH and conductivity worked as good proxy variables when the occurrence of intense rain events caused sharp increases in E. coli concentration. Differently, in other case studies, chemical oxygen demand, total suspended solids, turbidity and absorbance at 254 nm accounted for the positive correlation between low wastewater quality and E. coli concentration. Moreover, sensitivity analysis of artificial neural network models highlighted the importance of interactions among predictors, contributing to 25 to 30% of the model output variance. This evidence, along with performance results, supported the idea that nonlinear families of models should be preferred in the estimation of E. coli concentration.
                  The artificial neural network based soft sensor deployment for control of peracetic acid disinfectant dosage was simulated over a realistic scenario of wastewater quality recorded by on-line sensors over 2 months. The scenario simulations highlighted the significant benefit of an E. coli soft sensor, which provided up to 57% of disinfectant saving.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.radphyschem.2020.109300,Journal,Radiation Physics and Chemistry,scopus,2021-03-01,sciencedirect,Development of a radionuclide identification algorithm based on a convolutional neural network for radiation portal monitoring system,https://api.elsevier.com/content/abstract/scopus_id/85097339486,"At border crossings around the world, plastic scintillator-based radiation portal monitors (RPMs) are employed to detect the presence of illicit radioactive materials in large trailer trucks. However, the RPM system shows a low energy resolution owing to the large size and physical characteristics of plastic scintillators; and thus, the identification of illicit artificial isotopes from naturally occurring radioactive material is difficult. This study aims to develop an advanced algorithm for radionuclide identification with commercial RPMs based on commercial plastic scintillators to reduce the occurrence of frequent nuisance alarms. Subsequently, machine learning models, namely, a convolutional neural network (CNN) was applied. The spectral distributions of energy weighted spectra were used as features of the CNN model. The energy spectra of 137Cs, 60Co, 226Ra, and 40K measured under static and moving conditions were used to implement the identification model. To evaluate the performance of the implemented model, the F-score was used. The trained CNN model correctly identified most of the radionuclides. That is, despite the theoretical Compton edge energies of 60Co and 40K being similar, the spectral distributions of 40K are distinctively different from those of 60Co. The result demonstrates that the CNN model-based identification algorithm performs robust radionuclide identification, thereby reducing the frequency of nuisance alarms at border crossings. Furthermore, considering that the actual cases of cargo passing by the RPMs are becoming more complicated, the algorithm would need to be continuously improved and trained with more complex scenarios in the future.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jep.2020.113541,Journal,Journal of Ethnopharmacology,scopus,2021-03-01,sciencedirect,Identification and characterization of new potent inhibitors of dengue virus NS5 proteinase from Andrographis paniculata supercritical extracts on in animal cell culture and in silico approaches,https://api.elsevier.com/content/abstract/scopus_id/85095777426,"Ethnopharmacological relevance
                  About 2.5 billion peoples are at risk of dengue virus and the majority of people, use traditional plant-based medicines to combat dengue. The whole plant of Andrographis paniculata used traditionally over past decades for health promotion. Andrographolide isolated from Andrographis paniculata is used as natural remedy for the treatment of various diseases in different parts of the world. Andrographolide has been reported to have antiviral activity against hepatitis B virus, hepatitis C virus, herpes simplex virus, influenza virus, chikungunya virus, dengue virus 2 and 4.
               
                  Aim of the study
                  The aim of the present study to isolate the andrographolide from the A. paniculata by supercritical fluid extraction technique and to characterize the isolated compound along with it anti-dengue activity against DENV-2 in vitro and in silico methods.
               
                  Materials and methods
                  Supercritical extraction condition for A. paniculata was standardised to isolate andrographolide compound at definite temperature and pressure on the basis of previous study. The andrographolide was identified by using Ultraviolet–Visible Spectroscopy (UV-VIS), Fourier-Transform Infrared Spectroscopy (FT-IR) and High Performance Thin Layer Chromatography (HPTLC) and Proton Nuclear Magnetic Resonance (1HNMR). The maximum non-toxic dose of isolated andrographolide was detected by MTT assay using a micro plate reader at 595 nm. One hundred (100) copies/ml of the DENV-2 virus was used for antiviral assay in C6/36 cells lines and inhibition of virus due to andrographolide was determined by real-time PCR assay. The purity of isolated andrographolide was determined by Differential Scanning Calorimetry (DSC). The dengue NS5 receptor protein was docked with andrographolide and evaluated on the basis of the total energy and binding affinity score by Auto Dock (V4.2.6) software.
               
                  Results
                  Andrographolide, a diterpene lactone was isolated from the A. paniculata supercritical extract at 40 °C temperature and 15 Mpa pressure. UV spectrophotometer analysis revealed that the curve of andrographolide plant extract was overlapped with reference compound at 228 nm and the similar bands were detected from FT-IR spectroscopy analysis at 3315, 2917, 2849, 1673, 1462 and 1454 cm−
                     1 in isolated and standard andrographolide. HPTLC analysis shows the retention factor (Rf) of A. paniculata extract at 0.74 ± 0.06 as similar to standard andrographolide Rf values. The purity of isolated andrographolide was 99.76%. The maximum non-toxic dose of isolated andrographolide was found as 15.62 μg/ml on the C6/36 cell line calculated by using MTT assay. The andrographolide showed the 97.23% anti-dengue activity against the dengue-2 virus in C6/36 cell lines. Results of molecular docking showed that the interaction between andrographolide and NS5 of dengue protein with the maximum binding energy as −7.35 kcal/mol.
               
                  Conclusions
                  It is concluded that isolated andrographolide from the A. paniculata possess anti-dengue activity against dengue-2 virus as revealed from in vitro and in silico method. Due to lack of the vaccine and anti-viral agents, andrographolide extracted from A. paniculata play a major role to inhibit the dengue replication. Hence, it could be a source for drug design and help to reduce the dengue infection.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rser.2020.110519,Journal,Renewable and Sustainable Energy Reviews,scopus,2021-03-01,sciencedirect,Development of a constraint non-causal wave energy control algorithm based on artificial intelligence,https://api.elsevier.com/content/abstract/scopus_id/85095602765,"The real-time implementation of wave energy control leads to non-causality as the wave load that comes in the next few seconds is used to optimize the control command. The present work tackles non-causality through online forecasting of future wave force using artificial intelligence technique. The past free surface elevation is used to forecast the incoming wave load. A feedforward artificial neural network is developed for the forecasting, which learns to establish the intrinsic link between past free surface elevation and future wave force through machine learning algorithm. With the implementation of the developed online wave force prediction algorithm, a real-time discrete control algorithm taking constraint on response amplitude into account is developed and implemented to a bi-oscillator wave energy converter in the present research. The dynamic response and the wave power extraction are simulated using a state-space hydrodynamic model. It is shown that the developed real-time control algorithm enhances the power capture substantially whereas the motion of the system is hardly increased. The prediction error effect on power extraction is investigated. The reduction of power extraction is mainly caused by phase error, whilst the amplitude error has minimal influence. A link between the power capture efficiency and the constraint on control is also identified.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2020.10.011,Journal,Future Generation Computer Systems,scopus,2021-03-01,sciencedirect,Human action identification by a quality-guided fusion of multi-model feature,https://api.elsevier.com/content/abstract/scopus_id/85094321431,"Human motion recognition has become an active research area in the field of computer vision due to its wide range of implementations in domains of video monitoring, virtual reality, human–machine interaction. Dealing with the problem that the RGB images cannot provide enough depth information, a multi-modal depth neural network based on joint cost function is proposed for human motion recognition. In the architecture, the features of the RGB video frames are extracted by the 3D CNN architecture while the characteristics of human motion recognition in the SSDDI graphics utilizing depth map are extracted by the LSTM. Moreover, the model utilizes joint cost function including the cross-entropy loss and the distance constraint between the feature space of training samples and their center values within each category. The experimental results on the MSR Action 3D datasets suggest that the proposed model demonstrates a higher accuracy rate than do the other competing models.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2020.106734,Journal,Knowledge-Based Systems,scopus,2021-02-28,sciencedirect,Algorithm for detecting anomalous hosts based on group activity evolution,https://api.elsevier.com/content/abstract/scopus_id/85098969811,"Network behavior analysis is an active and challenging research direction in anomalous network traffic detection. With rapidly-increasing popularity of online applications, network traffic volume has grown exponentially. In the meantime, network communication is becoming more complex. Consequently, new interaction patterns of network behaviors, named group activity, need to be investigated. Group activities can be generated by various hosts over the network and changes in group activities usually cannot be captured by traditional anomaly detection methods. Currently, the primary limitation of traditional flow-based methods for network traffic analysis is the lack of a mechanism that studies the social relationship in the interaction patterns between hosts. Besides, existing approaches fail to detect group activities. To overcome these limitations, the paper aims to detect anomalous hosts based on the profile of group activity evolution. We propose a mathematical method to quantify and detect anomalous group activities based on the stability of group activity evolution, which fully captures both the temporal and structural characteristics of network evolution. This anomaly detection algorithm is called GAP (Group Activity Profile), which is a powerful supplement and extension of the traditional method of network behavior analysis. The main contributions of this paper are: (1) the paper introduces a new perspective of the group activity based on network evolution and network behavior anomaly detection; (2) the algorithm is suitable for measuring the changes in group activity evolution and determining whether the current evolution relatively conforms to or deviates from the normal evolution; and (3) this work defines the baseline of the group activity evolution by applying historical characteristics that can significantly reduce the false positive rate, and detect anomalous hosts accurately. The results of experiments conducted on real datasets demonstrate that GAP is capable of detecting anomalous host more effectively than traditional methods. GAP is free of parameters and achieves high scalability, which can effectively identify group activities as well as accurately detect anomalous hosts over time.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.quaint.2020.08.018,Journal,Quaternary International,scopus,2021-02-20,sciencedirect,Characterization of geomorphological features of lunar surface using Chandrayaan-1 Mini-SAR and LRO Mini-RF data,https://api.elsevier.com/content/abstract/scopus_id/85090021453,"The lunar surface comprises complex geomorphological features, which have been formed by the conjunction of processes namely impact cratering and volcanism. Geological features on the Lunar surface can be bifurcated into two main areas named Maria region and the Highland region. Taurus-Littrow valley, which was the Apollo-17 mission landing site, consisting of unique geomorphological characteristics by having a sample size of both Lunar Maria and Highland regions. The dielectric constant is a parameter that gives an approximate distribution of the constituent material of the target area. It is a complex quantity, which indicates a periodic variation of the electric field. The real part of dielectric constant indicates stored energy and the imaginary part indicates dielectric loss factor or the loss of the electric field in the medium due to continuous varying electric field. Planetary surfaces for which determining dielectric constant is an important analysis for most of the space missions, ground measurement is not feasible. This work includes the machine learning-based modeling of dielectric constant for the Apollo 17 landing site the Taurus-Littrow valley. Based on the surface roughness of the study area, two models Gaussian and Exponential have been implemented and compared for the modeled output of the dielectric constant values.The modeling approaches for dielectric characterization of the lunar surface were implemented on NASA's LRO Mini-RF SAR data and Mini-SAR hybrid-pol data of ISRO's Chandrayaan-1 mission. The coefficient of determination (r2) and the root mean square error (RMSE) of the theoretical Gaussian model was 0.995, 0.042 and the Exponential model was 0.948, 0.1349 respectively. When compared with the already calculated values of dielectric constant from Apollo 17 return samples and literature survey, the Gaussian model gives a better variation. Gaussian model was further applied to the Lunar north pole crater namely Hermite-A crater, whose distinctive geomorphological characteristics and location being lunar north pole region, makes it one of the coldest places in the Solar System and a prominent location of water ice deposits.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neuron.2020.11.021,Journal,Neuron,scopus,2021-02-17,sciencedirect,Using deep reinforcement learning to reveal how the brain encodes abstract state-space representations in high-dimensional environments,https://api.elsevier.com/content/abstract/scopus_id/85099151634,"Humans possess an exceptional aptitude to efficiently make decisions from high-dimensional sensory observations. However, it is unknown how the brain compactly represents the current state of the environment to guide this process. The deep Q-network (DQN) achieves this by capturing highly nonlinear mappings from multivariate inputs to the values of potential actions. We deployed DQN as a model of brain activity and behavior in participants playing three Atari video games during fMRI. Hidden layers of DQN exhibited a striking resemblance to voxel activity in a distributed sensorimotor network, extending throughout the dorsal visual pathway into posterior parietal cortex. Neural state-space representations emerged from nonlinear transformations of the pixel space bridging perception to action and reward. These transformations reshape axes to reflect relevant high-level features and strip away information about task-irrelevant sensory features. Our findings shed light on the neural encoding of task representations for decision-making in real-world situations.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jcp.2020.110069,Journal,Journal of Computational Physics,scopus,2021-02-15,sciencedirect,Active- and transfer-learning applied to microscale-macroscale coupling to simulate viscoelastic flows,https://api.elsevier.com/content/abstract/scopus_id/85098854830,"Active- and transfer-learning are applied to microscale dynamics of polymer flows for the multiscale discovery of effective constitutive approximations required in viscoelastic flow simulation. The result is macroscopic rheology directly connected to a microstructural model. Micro and macroscale simulations are adaptively coupled by means of Gaussian process regression (GPR) to run the expensive microscale computations only as necessary. This multiscale method is demonstrated with flows of a polymer solution as a model system. At the microscale level dissipative particle dynamics (DPD) is employed to model the fluid as a suspension of bead-spring micro-structures subjected to steady shear flow. The results yield the non-Newtonian viscosity and the first normal stress difference at strain rates as training data used in a GPR model. DPD parameters are calibrated with respect to experimental data for a real polymer solution. Compliance with these data requires adjustment of the DPD model's cutoff radius, which then becomes a function of the second invariant of the strain rate tensor. The FENE-P model is chosen for the macroscale description using the spectral element method (SEM) to simulate channel flow and flow past a circular cylinder. The DPD results at the lowest possible shear strain rate yield an estimate of the zero-shear rate viscosity, which allows the initiation of the macroscale flow by SEM as a Newtonian fluid. The resulting strain-rate field is surveyed to determine additional shear strain rate sampling points for the DPD system. This new information allows an initial fitting of parameters of the constitutive equation followed by new SEM simulations at the macroscale. Guided by active-learning GPR to select new sampling points, this process continues until convergence is achieved.
                  The effectiveness of this new simulation paradigm for viscoelastic flows is tested with different macroscale operating conditions. The effective closure learned in the channel simulation is then transferred directly to the flow past a circular cylinder at low Reynolds number, where the results show that only two additional DPD simulations are required to achieve a satisfactory constitutive model. With an increase of the Reynolds number, the active-learning scheme automatically detects the inaccuracy of the learned constitutive model, and initiates additional DPD simulations for the extra data needed to once again close the microscale-macroscale coupled system. This new paradigm of active- and transfer-learning for multiscale modeling is readily applicable to other microscale-macroscale coupled simulations of complex fluids and other materials. Furthermore, the coupling between microscale and macroscale solvers can be seamlessly implemented with our open source multiscale universal interface (MUI) library.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.abb.2020.108730,Journal,Archives of Biochemistry and Biophysics,scopus,2021-02-15,sciencedirect,Artificial intelligence in the early stages of drug discovery,https://api.elsevier.com/content/abstract/scopus_id/85098095696,"Although the use of computational methods within the pharmaceutical industry is well established, there is an urgent need for new approaches that can improve and optimize the pipeline of drug discovery and development. In spite of the fact that there is no unique solution for this need for innovation, there has recently been a strong interest in the use of Artificial Intelligence for this purpose. As a matter of fact, not only there have been major contributions from the scientific community in this respect, but there has also been a growing partnership between the pharmaceutical industry and Artificial Intelligence companies. Beyond these contributions and efforts there is an underlying question, which we intend to discuss in this review: can the intrinsic difficulties within the drug discovery process be overcome with the implementation of Artificial Intelligence? While this is an open question, in this work we will focus on the advantages that these algorithms provide over the traditional methods in the context of early drug discovery.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100195,Journal,Patterns,scopus,2021-02-12,sciencedirect,Topic classification of electric vehicle consumer experiences with transformer-based deep learning,https://api.elsevier.com/content/abstract/scopus_id/85100638713,"The transportation sector is a major contributor to greenhouse gas (GHG) emissions and is a driver of adverse health effects globally. Increasingly, government policies have promoted the adoption of electric vehicles (EVs) as a solution to mitigate GHG emissions. However, government analysts have failed to fully utilize consumer data in decisions related to charging infrastructure. This is because a large share of EV data is unstructured text, which presents challenges for data discovery. In this article, we deploy advances in transformer-based deep learning to discover topics of attention in a nationally representative sample of user reviews. We report classification accuracies greater than 91% (F1 scores of 0.83), outperforming previously leading algorithms in this domain. We describe applications of these deep learning models for public policy analysis and large-scale implementation. This capability can boost intelligence for the EV charging market, which is expected to grow to US$27.6 billion by 2027.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2020.08.042,Journal,Information Sciences,scopus,2021-02-08,sciencedirect,Network-based evidential three-way theoretic model for large-scale group decision analysis,https://api.elsevier.com/content/abstract/scopus_id/85090357359,"Social relationships are critical to the group decision-making (GDM) process, especially for large-scale scenarios. Conventional GDM models have several drawbacks when applied to large-scale GDM problems. In this paper, we propose an evidential three-way theoretic model for large-scale group decision analysis based on the introduction of ego networks. A similarity matrix of all individuals is obtained after ego network generation via social network feature extraction. Rough and smooth detection are then conducted in the framework of three-way decisions. Specifically, the degree of organizational influence is analyzed based on the generated basic probability assignments (BPAs), and the individuals are divided into several organizations. After an opinion collection process, preference evolution is implemented via a social influence network (SIN) technique and a fuzzy preference relation (FPR) model. Then, the global final scores of all the alternatives are obtained using an aggregation process. Finally, we conduct a simulation experiment to illustrate the entire procedure. Based on a comparison of related methods, we believe that the proposed method can reasonably solve real-world large-scale group decision-making (LSGDM) problems and has good practicability and effectiveness.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2020.103624,Journal,Microprocessors and Microsystems,scopus,2021-02-01,sciencedirect,FPGA processor and visual keyword matching to optimize feature recognition of tourism resources,https://api.elsevier.com/content/abstract/scopus_id/85102975560,"Confirm information from the web page is a critical issue to support tourism activities. These steps are based on how the analysis and synthesis of a web page article grammatical structure. Semantic structure is a single sentence or a fragment of the marked text. This is a characteristic of developing useful tourist information from a web page to identify the way. Identification, development, and utilization of tourism resources have proved inseparable from the earth sciences. In this case, the literature does not explain Earth's tourism resources' characteristics from a scientific point of almost complete. Still, it is only mentioned in the discussion of the operation of tourism resources and tourism. Machine learning algorithms are used in the proposed architecture, which resembles a field-programmable gate array to achieve. FPGA implementation of a fixed point, comparing classification performance.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.oceaneng.2020.108530,Journal,Ocean Engineering,scopus,2021-02-01,sciencedirect,Prediction and optimisation of fuel consumption for inland ships considering real-time status and environmental factors,https://api.elsevier.com/content/abstract/scopus_id/85098555033,"The information about ships’ fuel consumption is critical for condition monitoring, navigation planning, energy management and intelligent decision-making. Detailed analysis, modelling and optimisation of fuel consumption can provide great support for maritime management and operation and are of significance to water transportation. In this study, the real-time status monitoring data and hydrological data of inland ships are collected by multiple sensors, and a multi-source data processing method and a calculation method for real-time fuel consumption are proposed. Considering the influence of navigational status and environmental factors, including water depth, water speed, wind speed and wind angle, the Long Short-Term Memory (LSTM) neural network is then tailored and implemented to build models for prediction of real-time fuel consumption rate. The validation experiment shows the developed model performs better than some regression models and conventional Recurrent Neural Networks (RNNs). Finally, based on the fuel consumption rate model and the speed over ground model constructed by LSTM, the Reduced Space Searching Algorithm (RSSA) is successfully used to optimise the fuel consumption and the total cost of a whole voyage.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.wneu.2020.10.171,Journal,World Neurosurgery,scopus,2021-02-01,sciencedirect,Attitudes of the Surgical Team Toward Artificial Intelligence in Neurosurgery: International 2-Stage Cross-Sectional Survey,https://api.elsevier.com/content/abstract/scopus_id/85097780896,"Background
                  Artificial intelligence (AI) has the potential to disrupt how we diagnose and treat patients. Previous work by our group has demonstrated that the majority of patients and their relatives feel comfortable with the application of AI to augment surgical care. The aim of this study was to similarly evaluate the attitudes of surgeons and the wider surgical team toward the role of AI in neurosurgery.
               
                  Methods
                  In a 2-stage cross sectional survey, an initial open-question qualitative survey was created to determine the perspective of the surgical team on AI in neurosurgery including surgeons, anesthetists, nurses, and operating room practitioners. Thematic analysis was performed to develop a second-stage quantitative survey that was distributed via social media. We assessed the extent to which they agreed and were comfortable with real-world AI implementation using a 5-point Likert scale.
               
                  Results
                  In the first-stage survey, 33 participants responded. Six main themes were identified: imaging interpretation and preoperative diagnosis, coordination of the surgical team, operative planning, real-time alert of hazards and complications, autonomous surgery, and postoperative management and follow-up. In the second stage, 100 participants responded. Responders somewhat agreed or strongly agreed about AI being used for imaging interpretation (62%), operative planning (82%), coordination of the surgical team (70%), real-time alert of hazards and complications (85%), and autonomous surgery (66%). The role of AI within postoperative management and follow-up was less agreeable (49%).
               
                  Conclusions
                  This survey highlights that the majority of surgeons and the wider surgical team both agree and are comfortable with the application of AI within neurosurgery.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmps.2020.104277,Journal,Journal of the Mechanics and Physics of Solids,scopus,2021-02-01,sciencedirect,Thermodynamics-based Artificial Neural Networks for constitutive modeling,https://api.elsevier.com/content/abstract/scopus_id/85097707935,"Machine Learning methods and, in particular, Artificial Neural Networks (ANNs) have demonstrated promising capabilities in material constitutive modeling. One of the main drawbacks of such approaches is the lack of a rigorous frame based on the laws of physics. This may render physically inconsistent the predictions of a trained network, which can be even dangerous for real applications.
                  Here we propose a new class of data-driven, physics-based, neural networks for constitutive modeling of strain rate independent processes at the material point level, which we define as Thermodynamics-based Artificial Neural Networks (TANNs). The two basic principles of thermodynamics are encoded in the network’s architecture by taking advantage of automatic differentiation to compute the numerical derivatives of a network with respect to its inputs. In this way, derivatives of the free-energy, the dissipation rate and their relation with the stress and internal state variables are hardwired in the architecture of TANNs. Consequently, our approach does not have to identify the underlying pattern of thermodynamic laws during training, reducing the need of large data-sets. Moreover the training is more efficient and robust, and the predictions more accurate. Finally and more important, the predictions remain thermodynamically consistent, even for unseen data. Based on these features, TANNs are a starting point for data-driven, physics-based constitutive modeling with neural networks.
                  We demonstrate the wide applicability of TANNs for modeling elasto-plastic materials, using both hyper- and hypo-plasticity models. Strain hardening and softening are also considered for the hyper-plastic scenario. Detailed comparisons show that the predictions of TANNs outperform those of standard ANNs. Finally, we demonstrate that the implementation of the laws of thermodynamics confers to TANNs high robustness in the presence of noise in the training data, compared to standard approaches.
                  TANNs’ architecture is general, enabling applications to materials with different or more complex behavior, without any modification.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2020.103579,Journal,Microprocessors and Microsystems,scopus,2021-02-01,sciencedirect,Development of cultural tourism platform based on FPGA and convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85097346419,"Data mining can be described as a typical analysis of large datasets to investigate early unknown types, styles, and interpersonal relationships to generate the right decision information. It improves their markets and today to maintain control over whether these companies are forced into the data mining tools and technologies they use to develop and manage tourism products and services in the market. It is falling out of the favorable situation of the travel and tourism industry. Objective work is to provide and display its application in data mining and tourism. Advances in mobile technology provide an opportunity to obtain real-time information of travelers, such as time and space behavior, at the destination they visit. This study analyzed a large-scale mobile phone data set to capture the mobile phone traces of international tourists who visited South Korea. We adopt the trajectory data mining method to understand tourism activities’ spatial structure in three different destinations. The research reveals tourist destinations and multiple “hot spots” (or popular areas) that interact spatially in these places through spatial cluster analysis and sequential pattern mining. Therefore, this article provides the planning of spatial model destinations to integrate important tourism influences, which is based on tourism design. The proposed system is modelled in Field Programmable Gate Array (FPGA) using Xilinx software.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijmedinf.2020.104348,Journal,International Journal of Medical Informatics,scopus,2021-02-01,sciencedirect,Towards effective machine learning in medical imaging analysis: A novel approach and expert evaluation of high-grade glioma ‘ground truth’ simulation on MRI,https://api.elsevier.com/content/abstract/scopus_id/85097334964,"Purpose/objective(s)
                  Gliomas are uniformly fatal brain tumours with significant neurological and quality of life detriment to patients. Improvement in outcomes has remained largely unchanged in nearly 20 years. MRI (magnetic resonance imaging) is often used in diagnosis and management. Machine learning analyses of large-scale MRI data are pivotal in advancing the diagnosis, management and improve outcomes in neuro-oncology. A common challenge to robust machine learning approaches is the lack of large ‘ground truth’ datasets in supervised learning for building classification and prediction models. The creation of these datasets relies on human-expert input and is time-consuming and subjective error-prone, limiting effective machine learning applications. Simulation of mechanistic aspects such as geometry, location and physical properties of brain tumours can generate large-scale ground-truth datasets allowing for comparison of analysis techniques in clinical applications. We aimed to develop a transparent and convenient method for building ‘ground truth’ presentations of simulated glioma lesions on anatomical MRI.
               
                  Materials/methods
                  The simulation workflow was created using the Feature Manipulation Engine (FME®), a data integration platform specializing in the spatial data processing. By compiling and integrating FME’s functions to read, integrate, transform, validate, save, and display MRI data, and experimenting with ways to manipulate the parameters concerning location, size, shape, and signal intensity with the presentations of glioma, we were able to generate simulated appearances of high-grade gliomas on gadolinium-based high-resolution 3D T1-weighted MRI (1 mm3). Data of patients with canonical high-grade tumours were used as real-world tumours for validating the accuracy of the simulation. Twenty raters who are experienced with brain tumour interpretation on MRI independently completed a survey, designed to distinguish simulated and real-world brain tumours. Sensitivity and specificity were calculated for assessing the performance of the approach with the binary classification of simulated vs real-world tumours. Correlation and regression were used in run time analysis, assessing the software toolset’s efficiency in producing different numbers of simulated lesions. Differences in the group means were examined using the non-parametric Kruskal-Wallis test.
               
                  Results
                  The simulation method was developed as an interpretable and useful workflow for the easy creation of tumour simulations and incorporation into 3D MRI. A linear increase in the running time and memory usage was observed with an increasing number of generated lesions. The respondents' accuracy rate ranged between 33.3 and 83.3 %. The sensitivity and specificity were low for a human expert to differentiate simulated lesions from real gliomas (0.43 and 0.58) or vice versa (0.65 and 0.62). The mean scores ranking the real-world gliomas did not differ between the simulated and real tumours.
               
                  Conclusion
                  The reliable and user-friendly software method can allow for robust simulation of high-grade glioma on MRI. Ongoing research efforts include optimizing the workflow for generating glioma datasets as well as adapting it to simulating additional MRI brain changes.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2020.103343,Journal,Microprocessors and Microsystems,scopus,2021-02-01,sciencedirect,Ecological evolution path of smart education platform based on deep learning and image detection,https://api.elsevier.com/content/abstract/scopus_id/85095585894,"Smart environments are becoming a reality in our society, and the number of smart devices integrated into these spaces is overgrowing. End users are being provided a simplified way to handle complex smart features, as the combination of smart elements opens up a wide range of new opportunities to facilitate. This article explores the significant challenges to be overcome in designing an intelligent educational environment for the main characteristics and the personalized support of ecology. To integrate intelligent learning environments into learning ecology and educational environments, innovative applications, and new teaching methods should be implemented to coordinate formal and informal learning. However, despite the increased use of smart learning environments in higher education, at the same time, there is an excellent network that does not define a set of demand models for the development and evaluation of smart learning environment education that considers teaching, evaluation, and design. Deep learning is one of the modern methods that can be used to automate the process of effective intellectual education based on image detection. The deep learning process is based on image discovery. It provides an overview of ecological evaluation based smart education level analysis used image detection. The system that has been proposed here is an intelligent education system that has been customized to provide the resources of the evolution of the ecosystem to the learner to suit their perceptions and education center to start the platform.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2020.103318,Journal,Microprocessors and Microsystems,scopus,2021-02-01,sciencedirect,Enterprise financial cost management platform based on FPGA and neural network,https://api.elsevier.com/content/abstract/scopus_id/85094858518,"At present, the domestic costs of most construction companies are relatively scattered with the cost data of various business agents. Unless it is controlled by an experienced manager, decision-makers cannot have the real-time dynamic cost of a project. In the information age, it is of vital importance to use the information to control the cost of construction projects dynamically. Cost management and the establishment of an information platform are ways to control the platform integrated cost data, operators, computer software and hardware, and corresponding method information, and its core is cost data information. The place for financial cost analysis and decision making is a conceptually rich field where information is a commercial product which is complicated, extensive, and invaluable. In this model, first,a set of extracts from the macro-credit feature space is designed and then, FPGA and neural network (FPGA, NN) models for credit evaluation is built based on these indicators, eventually it is applied scientifically, and reasonably, practically. Several state credit metrics are randomly selected. Our model shows applications that are both practical and competent. Using this model, authorities can analyze local credit conditions, allowing investors to make wise decisions to invest while saving on operating and credit costs. Most importantly, this model can help impulsive local government leaders, businesses, and even everyone to enhance competitiveness and capacities of attractive regions, thereby foster a good atmosphere for a credit culture.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.talanta.2020.121665,Journal,Talanta,scopus,2021-02-01,sciencedirect,Machine learning tools to estimate the severity of matrix effects and predict analyte recovery in inductively coupled plasma optical emission spectrometry,https://api.elsevier.com/content/abstract/scopus_id/85092729485,"Supervised and unsupervised machine learning methods are used to evaluate matrix effects caused by carbon and easily ionizable elements (EIEs) on analytical signals of inductively coupled plasma optical emission spectrometry (ICP OES). A simple experimental approach was used to produce a series of synthetic solutions with varying levels of matrix complexity. Analytical lines (n = 29), with total line energies (E
                     
                        sum
                     ) in the 5.0–15.5 eV range, and non-analyte signals (n = 24) were simultaneously monitored throughout the study. Labeled (supervised learning) and unlabeled (unsupervised learning) data on normalized non-analyte signals (from plasma species) were used to train machine learning models to characterize matrix effect severity and predict analyte recoveries. Dimension reduction techniques, including principal component analysis, uniform manifold approximation and projection and t-distributed stochastic neighborhood embedding, were able to provide visual and quantitative representations that correlated well with observed matrix effects on low-energy atomic and high-energy ionic emission lines. Predictive models, including partial least squares regression and generalized linear models fit with the elastic net penalty, were tuned to estimate analyte recovery error when using the external standard calibration method (EC). The best predictive results were found for high-energy ionic analytical lines, e.g. Zn II 202.548 nm (E
                     
                        sum
                      = 15.5 eV), with accuracy and R2 of 0.970 and 0.856, respectively. Two certified reference materials (CRMs) were used for method validation. The strategy described here may be used for flagging compromising matrix effects, and complement method validation based on addition/recovery experiments and CRMs analyses. Because the data analysis workflows feature signals from plasma-based species, there is potential for developing instrument software capable of alerting users in real time (i.e. before data processing) of inaccurate results when using EC.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jneumeth.2020.109006,Journal,Journal of Neuroscience Methods,scopus,2021-01-15,sciencedirect,Real-Time Point Process Filter for Multidimensional Decoding Problems Using Mixture Models,https://api.elsevier.com/content/abstract/scopus_id/85097710119,"There is an increasing demand for a computationally efficient and accurate point process filter solution for real-time decoding of population spiking activity in multidimensional spaces. Real-time tools for neural data analysis, specifically real-time neural decoding solutions open doors for developing experiments in a closed-loop setting and more versatile brain-machine interfaces. Over the past decade, the point process filter has been successfully applied in the decoding of behavioral and biological signals using spiking activity of an ensemble of cells; however, the filter solution is computationally expensive in multi-dimensional filtering problems. Here, we propose an approximate filter solution for a general point-process filter problem when the conditional intensity of a cell’s spiking activity is characterized using a Mixture of Gaussians. We propose the filter solution for a broader class of point process observation called marked point-process, which encompasses both clustered – mainly, called sorted – and clusterless – generally called unsorted or raw– spiking activity. We assume that the posterior distribution on each filtering time-step can be approximated using a Gaussian Mixture Model and propose a computationally efficient algorithm to estimate the optimal number of mixture components and their corresponding weights, mean, and covariance estimates. This algorithm provides a real-time solution for multi-dimensional point-process filter problem and attains accuracy comparable to the exact solution. Our solution takes advantage of mixture dropping and merging algorithms, which collectively control the growth of mixture components on each filtering time-step. We apply this methodology in decoding a rat’s position in both 1-D and 2-D spaces using clusterless spiking data of an ensemble of rat hippocampus place cells. The approximate solution in 1-D and 2-D decoding is more than 20 and 4,000 times faster than the exact solution, while their accuracy in decoding a rat position only drops by less than 9% and 4% in RMSE and 95% highest probability coverage area (HPD) performance metrics. Though the marked-point filter solution is better suited for real-time decoding problems, we discuss how the filter solution can be applied to sorted spike data to better reflect the proposed methodology versatility.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2020.07.040,Journal,Information Sciences,scopus,2021-01-12,sciencedirect,An efficient approach to identify social disseminators for timely information diffusion,https://api.elsevier.com/content/abstract/scopus_id/85088924471,"In recent years, motivated by many practical applications such as viral marketing, researchers have paid significant attention to the circulation of information on social networks. The influential nodes that can influence the largest part of social networks are an essential topic in social network analysis. Most present solutions address the issue of discovering the influential nodes that could maximize influence effectiveness rather than minimize the cost of the information diffusion. In this paper, we investigate the circulation of emergency information, such as timely production promotion or disaster information, through a social network. These are real-life problems that have a significant effect in a very short time. We focus on how to minimize the total cost for all users in a specific social network to receive such information. We propose an efficient k-best social disseminator discovering algorithm in which the total diffusion cost on spreading timely information for each user in this social network is minimized.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2020.106580,Journal,Knowledge-Based Systems,scopus,2021-01-09,sciencedirect,Hybrid artificial neural network and cooperation search algorithm for nonlinear river flow time series forecasting in humid and semi-humid regions,https://api.elsevier.com/content/abstract/scopus_id/85095736783,"Accurate river flow forecasting is of great importance for the scientific management of water resources system. With the advantages of easy implementation and high flexibility, artificial neural network (ANN) has been widely employed to address the complex hydrological forecasting problem. However, the conventional ANN method often suffers from some defects in practice, like slow convergence and local minimum. In order to enhance the ANN performance, this study proposes a hybrid river flow forecasting method by integrating the novel cooperation search algorithm (CSA) into the learning process of ANN. In other words, the computational parameters of the ANN network (like threshold and linking weights) are iteratively optimized by the CSA method in the feasible state space. The proposed method is applied to the river flow data collected from two real-world hydrological stations in China. Several Quantitative indexes are chosen to compare the performance of the developed models, while the comprehensive analysis between the simulated and observed flow data are conducted. The experimental results show that in different scenarios, the hybrid method based on ANN and CSA always outperforms the control models and yields superior forecasting results during both training and testing phases. In Three Gorges Project, the presented method makes 11.10% and 5.42% improvements in the Nash–Sutcliffe efficiency and Coefficient correlation values of the standard ANN method in the testing phase. Thus, this interesting finding shows that the performance of the artificial intelligence models in river flow time series forecasting can be effectively improved by metaheuristic algorithm with outstanding global search ability.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2020.106535,Journal,Knowledge-Based Systems,scopus,2021-01-09,sciencedirect,Topic sensitive hybrid expertise retrieval system in community question answering services,https://api.elsevier.com/content/abstract/scopus_id/85092942900,"Here, we propose a topic sensitive hybrid expertise retrieval system in community question answering services. We introduce three new expertise signatures: knowledge, reputation, and authority. These signatures consider the questions, and hence, their answerers from a topic sensitive perspective. We estimate the knowledge of an answerer on a new question based on the previously answered subset of questions with similar topic distributions to the new question. The reputation of an answerer, moreover, is derived from the qualities of previously answered questions by the answerer with similar distributions of topics. Furthermore, we propose a topic sensitive authority model. It considers some topic related information associated with questions and the relationships among their answerers. We compare the proposed method with 26 existing methods on 4 real-world datasets using 5 performance measures. It outperforms the comparing algorithms in 91.73% (477 out of 520) cases.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2020.106623,Journal,Knowledge-Based Systems,scopus,2021-01-05,sciencedirect,A multi-objective linear threshold influence spread model solved by swarm intelligence-based methods,https://api.elsevier.com/content/abstract/scopus_id/85097710919,"The influence maximization problem (IMP) is one of the most important topics in social network analysis. It consists of finding the smallest seed of users that maximizes the influence spread in a social network. The main influence spread models are the linear threshold model (LT-model) and the independent cascade model (IC-model). These models have mainly been treated by using the single-objective paradigm which covers just one perspective: maximize the influence spread starting by given seed size, or minimize the seed set to reach a given number of influenced nodes. Sometimes, this minimization problem has been called the least cost influence problem (LCI). In this work, we propose a new optimization model for both perspectives under conflict, through the LT-model, by applying a binary multi-objective approach. Swarm intelligence methods are implemented to solve our proposal on real networks. Results are promising and suggest that the new multi-objective solution proposed can be properly solved in harder instances.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2020.06.047,Journal,Information Sciences,scopus,2021-01-04,sciencedirect,Sequential dynamic event recommendation in event-based social networks: An upper confidence bound approach,https://api.elsevier.com/content/abstract/scopus_id/85088022939,"In recent years, there have been some platforms that have focused on recommending commodities or events to users using event-based social networks (EBSNs). Some studies have attempted to find the optimal recommendation sequence of these items, assuming that the sequence stops once the user accepts one recommendation or the item list runs out. However, in reality, social media platforms will not stop recommending different commodities or social events to users until the user becomes bored and abandons the platform. Since it is 5 to 25 times more difficult to attract a new user than to retain an old one,
                        1
                     
                     
                        1
                        https://hbr.org/2014/10/the-value-of-keeping-the right-customers.
                      it would be helpful if the platform could determine when to stop making recommendations. In this work, we investigate the problem of sequential dynamic event recommendation with feedback (SDERF), where the platform continues recommending events even when the user has accepted one that is satisfactory. We first model the SDERF problem and provide two variants, namely, an online learning model with/without contextual information. Then, we apply an upper confidence bound (UCB) approach with an expected regret polynomial in the number of events and rounds. Finally, we evaluate the performance of our proposed algorithms using both real and synthetic datasets.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-323-90769-9.00004-9,Book,Data Science for COVID-19: Volume 2: Societal and Medical Perspectives,scopus,2021-01-01,sciencedirect,Artificial intelligence-based solutions for COVID-19,https://api.elsevier.com/content/abstract/scopus_id/85130158172,"Witness the coronavirus disease 2019 (COVID-19) virus becoming more deadly. Artificial intelligence (AI) scientists are using social media, the web, and other knowledge machine learning techniques to look for subtle signs that the disease may spread elsewhere. AI is a weapon in the battle against the infectious pandemic that has had impacts on the whole planet since early 2020. It echoes the high hopes of data science to confront the coronavirus in the press and the scientific community. The AI approach is used in the battle for cure, prediction, and pandemic predictors. Improving AI is a good step toward growing such uncertainties, one of the essential data analytics tools built over the past decade or so. Data scientists have approached the task of motivation. The index is growing exponentially as work information surface, beyond the potential of humans to do it alone. AI describes large data models, and this chapter should clarify how this challenge has become one of the ace cards of humanity. Advances in AI software, such as natural language processing, expression understanding, data mining, etc., are used for diagnosis as well as traceability and production of vaccines. AI has supported and contributed to the control of the COVID-19 pandemic. We include an initial overview of the real and potential contribution of AI to the fight against COVID-19 and the existing constraints on these contributions. In this chapter, different technologic solutions using AI for COVID-19 have been discussed.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-824410-4.09991-8,Book,Cognitive Systems and Signal Processing in Image Processing,scopus,2021-01-01,sciencedirect,Cognitive Systems and Signal Processing in Image Processing: A volume in Cognitive Data Science in Sustainable Computing,https://api.elsevier.com/content/abstract/scopus_id/85129675695,Unknown,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-323-85193-0.00012-7,Book,"Microbial Management of Plant Stresses: Current Trends, Application and Challenges",scopus,2021-01-01,sciencedirect,Advances in sensing plant diseases by imaging and machine learning methods for precision crop protection,https://api.elsevier.com/content/abstract/scopus_id/85128582282,"Plant diseases are one of the primary causes of major economic losses in the agriculture industry worldwide. The continuous monitoring of plant health and early detection of pathogens are crucial to reduce the disease spread and help effective disease management. The traditional methods of plant disease management generally rely on the spraying of chemical pesticides in the entire field, irrespective of its real requirement or not. Such blind application of these chemicals leads to undesirable effects on soil chemistry and microbiota. Following the second green revolution utilizing genomic advancements, smart or precision farming is changing the agricultural landscape at a very fast pace across the world. Precision agriculture relies on the implementation of modern-day advanced imaging and information technologies in disease identification. These intelligent and noninvasive methods use near real-time observations to protect crop damages caused by plant diseases. From a huge landscape of precision agriculture, the present chapter concentrates on the imaging-based approaches for biotic stress detection in plants. In this chapter, the machine learning methods including support vector machines, neural networks, and deep learning are also highlighted for the detection of plant diseases. These algorithms help in making smart decisions for the actual requirement and the adequate application of crop protection resources. Both imaging and machine learning methods are powerful and unparalleled tools for sustainable agriculture. They effectively detect biotic stress in plants and can provide data directly from different geographical scales.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-822884-5.00020-9,Book,Big Data in Psychiatry and Neurology,scopus,2021-01-01,sciencedirect,A scalable medication intake monitoring system,https://api.elsevier.com/content/abstract/scopus_id/85128012085,"Poor medication adherence is a global issue, causing adverse health-care problems and economic consequences. Many recent studies have designed and developed medication intake monitoring systems for both directly and indirectly monitoring patients using various sensors and advanced signal processing and machine learning algorithms. However, many studies have failed to deliver a system architecture that can be easily adapted to real-life scenarios with respect to cost, size, wearability, and social acceptance. A modern system architecture for medication intake monitoring must overcome these concerns, providing a practical design that combines hardware and software to accurately identify medication intake. Furthermore, for storing and processing high-frequency sensor data streams from multiple users simultaneously, it is essential to utilize scalable data storage and computing frameworks. In this chapter, we introduce a recently developed smartwatch application and a cloud-based data pipeline. The smartwatch application collects activity sensor data and sound data using embedded inertial sensors and microphones. The cloud-based data pipeline includes distributed data storage, Apache Spark-based distributed computing, and H2O-based distributed machine learning frameworks in order to build a machine learning model that identifies instances of medication intake.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-821229-5.00008-2,Book,Machine Learning and the Internet of Medical Things in Healthcare,scopus,2021-01-01,sciencedirect,Artificial itelligence in medicine,https://api.elsevier.com/content/abstract/scopus_id/85127629358,"Modern lifestyle and the polluted environment are the main causes of different types of diseases. Some diseases are curable through primary medication but some are more severe and require proper medication. In clinical treatment, different categories of medicines such as allopathic, homeopathy, herbal, art therapy, homemade medicine, etc. are applied to cure the diseases. The prediction of an appropriate medicine as per the symptoms of the disease is a challenging task for the clinicians. In this context, intelligent systems could be very helpful to predict the right medicine to the right people. Artificial Intelligence (AI) is a kind of intelligent system that applies different techniques to work with a huge amount of data for real-time analysis and better prediction to attain the required outcome. Also in the medicine industry, the process of discovering new medicines needs several clinical trials and requires approval by the concerned authority to deploy in the market. AI can improve decision-making and assist in the search for better medicines. Machine Learning is another revolution from AI that learns from the preexisting data sets and improves its accuracy in decision-making. This chapter presents a detailed literature survey on different AI techniques, followed by recent developments and applications in the medical industry.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-819742-4.09991-1,Book,"Machine Learning and Data Science in the Power Generation Industry: Best Practices, Tools, and Case Studies",scopus,2021-01-01,sciencedirect,"Machine Learning and Data Science in the Power Generation Industry: Best Practices, Tools, and Case Studies",https://api.elsevier.com/content/abstract/scopus_id/85126829359,Unknown,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.matpr.2021.06.243,Journal,Materials Today: Proceedings,scopus,2021-01-01,sciencedirect,Developing smart devices with automated Machine learning Approach: A review,https://api.elsevier.com/content/abstract/scopus_id/85126176453,"In the current era, Artificial Intelligence is playing a major role in smart devices. Apart from incorporating intelligence in the devices, it has extended its range beyond that. Now new AI development tools such as automated machine learning (AutoML) approach are increasing rapidly because of its performance on smart devices. AutoML is used to design a machine learning model with self-adapting capability which can perform the task in less time with advanced skills. This approach does not need any explicit coding and the data science experts but this can build smart sensor codes that will get executed automatically on the microcontrollers embedded within the IoT devices. Due to these capabilities, the developers can build efficient smart devices with real-time responsiveness, security, and data privacy without the help of machine learning experts. In this paper, we will show how AutoML will be used to create smart de-vices. The objective of this paper is to develop the skills that will help to develop smart edge devices which include planning, design-ing, implementation, and the evaluation of the smart IoT applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.trpro.2021.11.074,Conference Proceeding,Transportation Research Procedia,scopus,2021-01-01,sciencedirect,Quantification of transport offer linked to a Hyperloop European Network,https://api.elsevier.com/content/abstract/scopus_id/85121765941,"Hyperloop is the cutting-egde and environmentally friendly evolution of an idea that has been in people’s minds for more than 200 years, since Medhurst presented the first patents. When ""Hyperloop Alpha"" was published by Elon Musk in August 2013, the most talented and best trained labour force, the most capable financial capital and the bravest governments and institutions, moved forward to make it a reality. This study is supported by a peer-reviewed methodology published in an impact journal by the authors, which has allowed, using artificial intelligence, to characterise the layout of a new Hyperloop network in Europe. Currently, there are no scientific publications that address the transport offer linked to specific networks of this new mode with enough detail and without being self-bias. This research outlines the approach to conduct an operational plan in its exploitation phase, evaluating a specific Hyperloop network across Europe with an extension over 12,000 kilometres. The authors analyse the social and economic benefits of the network, based on GDP and directly connected population, describe its design parameters (radii of curvature, acceleration, deceleration and constant speed zones), outline the potential demand using simple gravity models, propose an annual service calendar with schedules and frequencies differentiated by country, and present the main magnitudes associated with its operation. In addition, the research solves to the main obstacle that the Hyperloop implementation will pose in the future: the number of tubes needed per direction vs. the transport capacity of each capsule or pod.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aiia.2021.11.004,Journal,Artificial Intelligence in Agriculture,scopus,2021-01-01,sciencedirect,Automation and digitization of agriculture using artificial intelligence and internet of things,https://api.elsevier.com/content/abstract/scopus_id/85120995341,"The growing population and effect of climate change have put a huge responsibility on the agriculture sector to increase food-grain production and productivity. In most of the countries where the expansion of cropland is merely impossible, agriculture automation has become the only option and is the need of the hour. Internet of things and Artificial intelligence have already started capitalizing across all the industries including agriculture. Advancement in these digital technologies has made revolutionary changes in agriculture by providing smart systems that can monitor, control, and visualize various farm operations in real-time and with comparable intelligence of human experts. The potential applications of IoT and AI in the development of smart farm machinery, irrigation systems, weed and pest control, fertilizer application, greenhouse cultivation, storage structures, drones for plant protection, crop health monitoring, etc. are discussed in the paper. The main objective of the paper is to provide an overview of recent research in the area of digital technology-driven agriculture and identification of the most prominent applications in the field of agriculture engineering using artificial intelligence and internet of things. The research work done in the areas during the last 10 years has been reviewed from the scientific databases including PubMed, Web of Science, and Scopus. It has been observed that the digitization of agriculture using AI and IoT has matured from their nascent conceptual stage and reached the execution phase. The technical details of artificial intelligence, IoT, and challenges related to the adoption of these digital technologies are also discussed. This will help in understanding how digital technologies can be integrated into agriculture practices and pave the way for the implementation of AI and IoT-based solutions in the farms.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2021.10.504,Conference Proceeding,IFAC-PapersOnLine,scopus,2021-01-01,sciencedirect,Advanced state fuzzy cognitive maps applied on nearly zero energy building model,https://api.elsevier.com/content/abstract/scopus_id/85120711263,"Fuzzy Cognitive Maps method combines the advantages of Fuzzy Logic, such as their human reasoning and linguistic features, with the advantages of Neural Networks, such as their low mathematical calculation requirements, in order to model complex dynamic systems on a wide variety of applications. The system variables and their interconnections are described using a graph and a weight matrix. Application of experts’ knowledge leads towards more realistic system models. In addition, the implementation of state-space theory in combination with learning algorithms, lead to a new generation of Fuzzy Cognitive Maps, the Advanced State Fuzzy Cognitive Maps. All the above are implemented on a nearly Zero Energy Building model, using real weather data and presenting its annual energy response.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.promfg.2021.10.068,Conference Proceeding,Procedia Manufacturing,scopus,2021-01-01,sciencedirect,Demand forecasting methods for spare parts logistics for aviation: A real-world implementation of the Bootstrap method,https://api.elsevier.com/content/abstract/scopus_id/85120651989,"One of the critical issues that an airline faces in its day-to-day operations is a correct prognosis of the necessary quantity of spare parts that are continuously fed into unexpected maintenance operations. Indeed, there is a critical need for accurate forecasting methods to predict the demand of these spare parts in order to minimize the so-called Aircraft-On-Ground situations. This paper describes the real-world implementation of the Bootstrap method and the assessment of its performance with actual data from aviation logistics. The analysis reveals that the Bootstrap method, while not the most accurate in every case, should be preferred over other popular methods in spare parts forecasting for aviation, because is more agile and can address adequately all categories of demand. A simple decision support system is then presented to assist airline materials managers in using the bootstrap method. The system is expandable and can potentially incorporate other forecasting method as well.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-323-85172-5.00018-6,Book,"Electronic Devices, Circuits, and Systems for Biomedical Applications: Challenges and Intelligent Approach",scopus,2021-01-01,sciencedirect,Health monitoring system,https://api.elsevier.com/content/abstract/scopus_id/85120586080,"Electronics have become an essential part of biomedicine. The urge for real-time health monitoring and disease detection at an early stage has created a rapid growth of the market for smart sensors. Biosensors have investigated the prospects of point of care (POC) applications for better management of healthcare, and efforts are being made to make these more efficient. Integrating with micro-electro-mechanical systems (MEMS) and nano-electro-mechanical systems (NEMS) technology has enabled biosensors to be automated and more precise, with higher accuracy data sensing systems. The application of biosensors with POC has increased research related to nanotechnology, advanced functional sensing materials, miniaturized sensing system development, AI, and the internet of things (IoT). Breath analysis is one such form for which biosensors have been used. Diabetes, Parkinson disease, urinary tract infections, lung cancer, kidney disease, pancreas infection, etc., can be detected through breath analysis. This chapter deals with a smart sensor system for diagnosis of diseases, precisely chronologic at an early stage. The sensor system is developing for detecting volatile organic compounds. Sensor arrays are deployed to collect and process electromagnetic or acoustic signals. Health monitoring systems provides a better perception of the patient’s condition, allowing doctors to make the correct diagnosis in real time and enhance curative procedure. IoT integrated with machine learning and artificial intelligence plays a vital role here.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mex.2021.101572,Journal,MethodsX,scopus,2021-01-01,sciencedirect,Methodology for using a Bayesian nonparametric model to uncover universal patterns in color naming,https://api.elsevier.com/content/abstract/scopus_id/85118571924,"Language is an integral part of society which enables communication among its members. To shed light on how words gain their meaning and how their meaning evolves over time, color naming is often used as a case study. The color domain can be defined by a physical space, making it a useful concept for studying denotation of meaning. Though humans can distinguish millions of colors, language provides us with a small, manageable set of terms for categorizing the space. Partitions of the color space vary across different language groups and evolve over time (e.g. new color terms may enter a language). Investigating universal patterns in color naming provides insight into the mechanisms that give rise to the observed data. Recently, computational techniques have been utilized to study this phenomenon. Here, we develop a methodology for transforming a color naming data set—namely, the World Color Survey—which is based on constraints imposed by the stimulus space. This transformed data is used to initialize a nonparametric Bayesian machine learning model in order to implement a culture and theory-independent study of universal color naming patterns across different language groups. All of the methods described are executed by our Python software package called ColorBBDP.
                  • Data from the World Color Survey is transformed from its original format into binary features vectors which can be given as input to the Beta-Bernoulli Dirichlet Process Mixture Model.
                  • This paper provides a specific application of Variational Inference on the Beta-Bernoulli Dirichlet Process Mixture Model towards a color naming data set.
                  • New mathematical measures for performing post-cluster analyses are also detailed in this paper.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2021.09.233,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,A note on the applications of artificial intelligence in the hospitality industry: Preliminary results of a survey,https://api.elsevier.com/content/abstract/scopus_id/85116885410,"Intelligent technologies are widely implemented in different areas of modern society but specific approaches should be applied in services. Basic relationships refer to supporting customers and people responsible for services offering for these customers. The aim of the paper is to analyze and evaluate the state-of-the art of artificial intelligence (AI) applications in the hospitality industry. Our findings show that the major deployments concern in-person customer services, chatbots and messaging tools, business intelligence tools powered by machine learning, and virtual reality & augmented reality. Moreover, we performed a survey (n = 178), asking respondents about their perceptions and attitudes toward AI, including its implementation within a hotel space. The paper attempts to discuss how the hotel industry can be motivated by potential customers to apply selected AI solutions. In our opinion, these results provide useful insights for understanding the phenomenon under investigation. Nevertheless, since the results are not conclusive, more research is still needed on this topic. Future studies may concern both qualitative and quantitative methods, devoted to developing models that: a) quantify the potential benefits and risks of AI implementations, b) determine and evaluate the factors affecting the AI adoption by the customers, and c) measure the user (guest) experience of the hotel services, fueled by AI-based technologies.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.4103/jpi.jpi_100_20,Journal,Journal of Pathology Informatics,scopus,2021-01-01,sciencedirect,"Browser-based data annotation, active learning, and real-time distribution of artificial intelligence models: From tumor tissue microarrays to COVID-19 radiology",https://api.elsevier.com/content/abstract/scopus_id/85116859715,"Background: Artificial intelligence (AI) is fast becoming the tool of choice for scalable and reliable analysis of medical images. However, constraints in sharing medical data outside the institutional or geographical space, as well as difficulties in getting AI models and modeling platforms to work across different environments, have led to a “reproducibility crisis” in digital medicine. Methods: This study details the implementation of a web platform that can be used to mitigate these challenges by orchestrating a digital pathology AI pipeline, from raw data to model inference, entirely on the local machine. We discuss how this federated platform provides governed access to data by consuming the Application Program Interfaces exposed by cloud storage services, allows the addition of user-defined annotations, facilitates active learning for training models iteratively, and provides model inference computed directly in the web browser at practically zero cost. The latter is of particular relevance to clinical workflows because the code, including the AI model, travels to the user's data, which stays private to the governance domain where it was acquired. Results: We demonstrate that the web browser can be a means of democratizing AI and advancing data socialization in medical imaging backed by consumer-facing cloud infrastructure such as Box.com. As a case study, we test the accompanying platform end-to-end on a large dataset of digital breast cancer tissue microarray core images. We also showcase how it can be applied in contexts separate from digital pathology by applying it to a radiology dataset containing COVID-19 computed tomography images. Conclusions: The platform described in this report resolves the challenges to the findable, accessible, interoperable, reusable stewardship of data and AI models by integrating with cloud storage to maintain user-centric governance over the data. It also enables distributed, federated computation for AI inference over those data and proves the viability of client-side AI in medical imaging.
                  
                     Availability: The open-source application is publicly available at https://episphere.github.io/path, with a short video demonstration at https://youtu.be/z59jToy2TxE.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jvssci.2020.11.032,Journal,JVS-Vascular Science,scopus,2021-01-01,sciencedirect,Patient-specific computational flow modelling for assessing hemodynamic changes following fenestrated endovascular aneurysm repair,https://api.elsevier.com/content/abstract/scopus_id/85116756005,"Objective
                  This study aimed to develop an accessible patient-specific computational flow modelling pipeline for evaluating the hemodynamic performance of fenestrated endovascular aneurysm repair (fEVAR), with the hypothesis that computational flow modelling can detect aortic branch hemodynamic changes associated with fEVAR graft implantation.
               
                  Methods
                  Patients who underwent fEVAR for juxtarenal aortic aneurysms with the Cook ZFEN were retrospectively selected. Using open-source SimVascular software, preoperative and postoperative visceral aortic anatomy was manually segmented from computed tomography angiograms. Three-dimensional geometric models were then discretized into tetrahedral finite element meshes. Patient-specific pulsatile in-flow conditions were derived from known supraceliac aortic flow waveforms and adjusted for patient body surface area, average resting heart rate, and blood pressure. Outlet boundary conditions consisted of three-element Windkessel models approximated from physiologic flow splits. Rigid wall flow simulations were then performed on preoperative and postoperative models with the same inflow and outflow conditions. We used SimVascular's incompressible Navier-Stokes solver to perform blood flow simulations on a cluster using 72 cores.
               
                  Results
                  Preoperative and postoperative flow simulations were performed for 10 patients undergoing fEVAR with a total of 30 target vessels (20 renal stents, 10 mesenteric scallops). Postoperative models required a higher mean number of mesh elements to reach mesh convergence (3.2 ± 1.8 × 106 vs 2.6 ± 1.1 × 106; P = .005) with a longer mean computational time (10.3 ± 6.3 hours vs 7.8 ± 3.5 hours; P = .04) compared with preoperative models. fEVAR was associated with small but statistically significant increases in mean peak proximal aortic arterial pressure (140.3 ± 11.0 mm Hg vs 136.9 ± 8.7 mm Hg; P = .02) and peak renal artery pressure (131.6 ± 14.8 mm Hg vs 128.9 ± 11.8 mm Hg; P = .04) compared with preoperative simulations. No differences were observed in peak pressure in the celiac, superior mesenteric, or distal aortic arteries (P = .17-.96). When measuring blood flow, the only observed difference was an increase in peak renal flow rate after fEVAR (17.5 ± 3.8 mL/s vs 16.9 ± 3.5 mL/s; P = .04). fEVAR was not associated with changes in the mean pressure or the mean flow rate in the celiac, superior mesenteric, or renal arteries (P = .06-.98). Stenting of the renal arteries did not induce significant changes time-averaged wall shear stress in the proximal renal artery (23.4 ± 8.1 dynes/cm2 vs 23.2 ± 8.4 dynes/cm2; P = .98) or distal renal artery (32.7 ± 13.9 dynes/cm2 vs 29.6 ± 11.8 dynes/cm2; P = .23). In addition, computational visualization of cross-sectional velocity profiles revealed low flow disturbances associated with protrusion of renal graft fabric into the aortic lumen.
               
                  Conclusions
                  In a pilot study involving a selective cohort of patients who underwent uncomplicated fEVAR, patient-specific flow modelling was a feasible method for assessing the hemodynamic performance of various two-vessel fenestrated device configurations and revealed subtle differences in computationally derived peak branch pressure and blood flow rates. Structural changes in aortic flow geometry after fEVAR do not seem to affect computationally estimated renovisceral branch perfusion or wall shear stress adversely. Additional studies with invasive angiography or phase contrast magnetic resonance imaging are required to clinically validate these findings. (JVS–Vascular Science 2021;2:53-69.)
               
                  Clinical Relevance
                  Using a computational flow modelling for assessing the hemodynamic performance of fenestrated endovascular aneurysm repair (fEVAR), this real-world, patient-specific study included 10 participants and found that structural changes in aortic flow geometry after fEVAR did not seem to adversely impact estimated renal or visceral branch perfusion metrics (eg, peak and mean arterial pressure and flow rates) or wall shear stress. These findings overall support the ongoing clinical use of commercially available fEVAR devices for repair of juxtarenal aortic aneurysms, and provides a computational framework for future evaluation of fEVAR configurations in a preoperative or postoperative settings.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.csbj.2021.08.023,Journal,Computational and Structural Biotechnology Journal,scopus,2021-01-01,sciencedirect,Docking-generated multiple ligand poses for bootstrapping bioactivity classifying Machine Learning: Repurposing covalent inhibitors for COVID-19-related TMPRSS2 as case study,https://api.elsevier.com/content/abstract/scopus_id/85113957136,"In the present work we introduce the use of multiple docked poses for bootstrapping machine learning-based QSAR modelling. Ligand-receptor contact fingerprints are implemented as descriptor variables. We implemented this method for the discovery of potential inhibitors of the serine protease enzyme TMPRSS2 involved the infectivity of coronaviruses. Several machine learners were scanned, however, Xgboost, support vector machines (SVM) and random forests (RF) were the best with testing set accuracies reaching 90%. Three potential hits were identified upon using the method to scan known untested FDA approved drugs against TMPRSS2. Subsequent molecular dynamics simulation and covalent docking supported the results of the new computational approach.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2021.03.074,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Requirements towards optimizing analytics in industrial processes,https://api.elsevier.com/content/abstract/scopus_id/85106735396,"Modern production systems are composed of complex manufacturing processes with highly technology specific cause-effect relationships. Developments in sensor technology and computational science allow for data-driven decision making that facilitate effcient and objective production management. However, process data may only be beneficial if it is enriched with meta information and process expertise, reduced to relevant information and modelling results interpreted correctly. The importance of data integration in the heterogeneous industrial environment rises at the same momentum as new metrology techniques are deployed. In this paper, we focus on optimizing analytics, containing data-driven decision making for predictive quality and maintenance. We summarize key requirements for data analytics and machine learning application in industrial processes. With a use case from automotive component manufacturing we characterize industrial production, categorize process data and put requirements in context to a real-world example.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.imu.2021.100591,Journal,Informatics in Medicine Unlocked,scopus,2021-01-01,sciencedirect,The diagnostic accuracy of Artificial Intelligence-Assisted CT imaging in COVID-19 disease: A systematic review and meta-analysis,https://api.elsevier.com/content/abstract/scopus_id/85105522693,"Artificial intelligence (AI) systems have become critical in support of decision-making. This systematic review summarizes all the data currently available on the AI-assisted CT-Scan prediction accuracy for COVID-19. The ISI Web of Science, Cochrane Library, PubMed, Scopus, CINAHL, Science Direct, PROSPERO, and EMBASE were systematically searched. We used the revised Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2) tool to assess all included studies' quality and potential bias. A hierarchical receiver-operating characteristic summary (HSROC) curve and a summary receiver operating characteristic (SROC) curve have been implemented. The area under the curve (AUC) was computed to determine the diagnostic accuracy. Finally, 36 studies (a total of 39,246 image data) were selected for inclusion into the final meta-analysis. The pooled sensitivity for AI was 0.90 (95% CI, 0.90–0.91), specificity was 0.91 (95% CI, 0.90–0.92) and the AUC was 0.96 (95% CI, 0.91–0.98). For deep learning (DL) method, the pooled sensitivity was 0.90 (95% CI, 0.90–0.91), specificity was 0.88 (95% CI, 0.87–0.88) and the AUC was 0.96 (95% CI, 0.93–0.97). In case of machine learning (ML), the pooled sensitivity was 0.90 (95% CI, 0.90–0.91), specificity was 0.95 (95% CI, 0.94–0.95) and the AUC was 0.97 (95% CI, 0.96–0.99). AI in COVID-19 patients is useful in identifying symptoms of lung involvement. More prospective real-time trials are required to confirm AI's role for high and quick COVID-19 diagnosis due to the possible selection bias and retrospective existence of currently available studies.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2021.03.075,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Input doubling method based on SVR with RBF kernel in clinical practice: Focus on small data,https://api.elsevier.com/content/abstract/scopus_id/85104314419,"In recent years, machine-learning-based approaches have become of considerable interest to the efficient processing of short or limited data samples. Its so-called small data approach. This is due to the significant growth of new intellectual analysis tasks in various industries, which are characterized by limited historical data. These include Materials Science, Economics, Medicine, and so on. An effective processing of short datasets is especially acute in medicine. Insufficient number of vectors, significant gaps in the data collected during the supervision of patient’s treatment or rehabilitation, reduces the effectiveness or prevents effective intellectual analysis based on them. This paper presents a new approach to processing short medical data samples. The basis of the developed method is SVR with RBF kernel. The algorithmic implementation of the method in both operation modes is described. Experimental modeling on a real short data set (Trabecular bone data) is conducted. It contained only 35 observations. A comparison of the method with a number of existing machine learning methods is conducted. It is experimental established the highest accuracy of the method among those considered. The developed method has potential opportunities for wide application in various fields of medicine.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.imu.2021.100566,Journal,Informatics in Medicine Unlocked,scopus,2021-01-01,sciencedirect,COVID-19 prediction using LSTM algorithm: GCC case study,https://api.elsevier.com/content/abstract/scopus_id/85104093246,"Coronavirus-19 (COVID-19) is the black swan of 2020. Still, the human response to restrain the virus is also creating massive ripples through different systems, such as health, economy, education, and tourism. This paper focuses on research and applying Artificial Intelligence (AI) algorithms to predict COVID-19 propagation using the available time-series data and study the effect of the quality of life, the number of tests performed, and the awareness of citizens on the virus in the Gulf Cooperation Council (GCC) countries at the Gulf area. So we focused on cases in the Kingdom of Saudi Arabia (KSA), United Arab of Emirates (UAE), Kuwait, Bahrain, Oman, and Qatar. For this aim, we accessed the time-series real-datasets collected from Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE). The timeline of our data is from January 22, 2020 to January 25, 2021. We have implemented the proposed model based on Long Short-Term Memory (LSTM) with ten hidden units (neurons) to predict COVID-19 confirmed and death cases. From the experimental results, we confirmed that KSA and Qatar would take the most extended period to recover from the COVID-19 virus, and the situation will be controllable in the second half of March 2021 in UAE, Kuwait, Oman, and Bahrain. Also, we calculated the root mean square error (RMSE) between the actual and predicted values of each country for confirmed and death cases, and we found that the best values for both confirmed and death cases are 320.79 and 1.84, respectively, and both are related to Bahrain. While the worst values are 1768.35 and 21.78, respectively, and both are related to KSA. On the other hand, we also calculated the mean absolute relative errors (MARE) between the actual and predicted values of each country for confirmed and death cases, and we found that the best values for both confirmed and deaths cases are 37.76 and 0.30, and these are related to Kuwait and Qatar respectively. While the worst values are 71.45 and 1.33, respectively, and both are related to KSA.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2021.01.128,Conference Proceeding,Procedia CIRP,scopus,2021-01-01,sciencedirect,A Machine Vision-based Cyber-Physical Production System for Energy Efficiency and Enhanced Teaching-Learning Using a Learning Factory,https://api.elsevier.com/content/abstract/scopus_id/85102656008,"Machine vision (MV) can help in achieving real-time data analysis in a manufacturing environment. This can be implemented in any industry to achieve real-time monitoring of workpieces for geometric defects and material irregularities. Identification of defects, sorting of workpieces based on their physical parameters, and analysis of process abnormalities can be achieved by using the real-time data from simple and cost-effective raspberry pi with camera and open source machine learning platform TensorFlow to run convolutional neural network (CNN) model. The proposed cyber-physical production system enables to develop a MV based system for data acquisition integrating physical entities of learning factory (LF) with the cyber world. Nowadays, LFs are widely used to train the workforce for developing competencies for emerging technologies and challenges faced due to technological advancements in Industry 4.0. This paper demonstrates the application of a cost-effective MV system in a learning factory environment to achieve real-time data acquisition and energy efficiency. The proposed low-cost machine vision is found to detect geometric irregularities, colours and surface defects. The simple cost effective MV system has enhanced the energy efficiency and reduced the total carbon footprint by 18.37 % and 78.83 % depending upon the location of MV system along the flow. The teaching-learning experience is also enhanced through action-based learning strategies. This not only ensures less rework, better control, unbiased decisions, 100% quality assurance but also the need of workers/operators can be reduced.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2021.01.115,Conference Proceeding,Procedia CIRP,scopus,2021-01-01,sciencedirect,Development of a Decision Support System for 3D Printing Processes based on Cyber Physical Production Systems,https://api.elsevier.com/content/abstract/scopus_id/85102637852,"3D printing, an additive manufacturing (AM) technology, potentially provides sustainability advantages such as less waste generation, lightweight geometries, reduced material and energy consumption, lower inventory waste, etc. This paper proposes a decision support system for the 3D printing process based on Cyber Physical Production System (CPPS). The user is enabled to dynamically assess the carbon footprint based on the energy and material usage for their 3D printed object. A CPPS framework for the environmental sustainability of the 3D printing process is presented, which supports the derivation of improved strategies for product design and production. A physical world for 3D printing is used with the internet of things (IoT) devices like sensor node, webcam, smart plugs, and raspberry pi to host printer Management Software (PMS) for real-time monitoring and control of material and energy consumption during the printing process. Experiments have been conducted based on Taguchi L9 orthogonal array with polylactic Acid (PLA) as a filament material to estimate the product-related manufacturing energy consumption with the carbon footprint. The proposed framework can be effectively used by the users to supports the decision-making process for saving resources and energy; and minimizing the effect on the environment.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ejor.2020.12.024,Journal,European Journal of Operational Research,scopus,2021-01-01,sciencedirect,Robust low-rank multiple kernel learning with compound regularization,https://api.elsevier.com/content/abstract/scopus_id/85099124915,"Kernel learning is widely used in nonlinear models during the implementation of forecasting tasks in analytics. However, existing forecasting models lack robustness and accuracy. Therefore, in this study, a novel supervised forecasting approach based on robust low-rank multiple kernel learning with compound regularization is investigated. The proposed method extracts the benefits from robust regression, multiple kernel learning with low-rank approximation, and sparse learning systems. Unlike existing hybrid forecasting methods, which frequently combine different models in parallel, we embed a Huber or quantile loss function and a compound regularization composed of smoothly clipped absolute deviation and ridge regularizations in a support vector machine with predefined number of kernels. To select the optimal kernels, 
                        
                           L
                           1
                        
                      penalization with positive constraint is also considered. The proposed model exhibits robustness, forecasting accuracy, and sparsity in the reproducing kernel Hilbert space. For computation, a simple algorithm is designed based on local quadratic approximation to implement the proposed method. Theoretically, the forecasting and estimation error bounds of the proposed estimators are derived under a null consistency assumption. Real data experiments using datasets from various scientific research fields demonstrate the superior performances of the proposed approach compared with other state-of-the-art competitors.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patrec.2020.09.032,Journal,Pattern Recognition Letters,scopus,2021-01-01,sciencedirect,Gradient clustering algorithm based on deep learning aerial image detection,https://api.elsevier.com/content/abstract/scopus_id/85098118591,"In recent years, computer vision, especially deep learning, has been widely used in various fields. Through the deep learning aerial image detection gradient clustering algorithm automatic recognition, it can solve the limitations of manual shooting by humans, can shoot from a high altitude to a panoramic view of a specific area, and provide a more comprehensive solution. The traditional forest resource management and management work is mainly carried out by forestry personnel to carry out a large number of investigations and investigations on the forest. This method not only consumes a lot of manpower and material resources, but also does not have real-time nature. It is difficult to deal with all kinds of forest management. Problems, causing unnecessary losses. In this regard, this paper proposes an aerial image change detection algorithm based on H-KFCM, and designs related experiments to verify and demonstrate the performance of the algorithm. In this paper, we conduct a parallel study based on deep learning on the gradient clustering algorithm of deep learning in aerial image processing. By using CUDA (Compute Unified Device Architecture) to perform large-scale parallel processing of aerial data. Can greatly shorten the time to obtain results, improve the efficiency of relevant personnel. Experiment analysis. It can be seen from the results that the deep learning parallelization program implemented in this paper has a faster calculation speed and uses less time in high-resolution images, and has a good acceleration ratio compared to the CPU.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.psychres.2020.113585,Journal,Psychiatry Research,scopus,2021-01-01,sciencedirect,"Digital Gaming Interventions in Psychiatry: Evidence, Applications and Challenges",https://api.elsevier.com/content/abstract/scopus_id/85097734134,"Human evolution has regularly intersected with technology. Digitalization of various services has brought a paradigm shift in consumerism. Treading this path, mental health practice has gradually moved to Digital Mental Health Interventions (DMHI), to improve service access and delivery. Applied games are one such innovation that has gained recent popularity in psychiatry. Based on the principles of gamification, they target psychosocial and cognitive domains, according to the deficits in various psychiatric disorders. They have been used to deliver cognitive behaviour therapy, cognitive training and rehabilitation, behavioural modification, social motivation, attention enhancement, and biofeedback. Research shows their utility in ADHD, autistic spectrum disorders, eating disorders, post-traumatic stress, impulse control disorders, depression, schizophrenia, dementia, and even healthy aging. Virtual reality and artificial intelligence have been used in conjunction with gaming interventions to improvise their scope. Even though these interventions hold promise in engagement, ease of use, reduction of stigma, and bridging the mental-health gap, there are pragmatic challenges, especially in developing countries. These include network quality, infrastructure, feasibility, socio-cultural adaptability, and potential for abuse. Keeping this in the background, this review summarizes the scope, promise, and evidence of digital gaming in psychiatric practice, and highlights the potential caveats in their implementation.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cogsys.2020.10.005,Journal,Cognitive Systems Research,scopus,2021-01-01,sciencedirect,Cogmic space for narrative-based world representation,https://api.elsevier.com/content/abstract/scopus_id/85096684889,"Representing a world or a physical/social environment in an agent’s cognitive system is essential for creating human-like artificial intelligence. This study takes a story-centered approach to this issue. In this context, a story refers to an internal representation involving a narrative structure, which is assumed to be a common form of organizing past, present, future, and fictional events and situations. In the artificial intelligence field, a story or narrative is traditionally treated as a symbolic representation. However, a symbolic story representation is limited in its representational power to construct a rich world. For example, a symbolic story representation is unfit to handle the sensory/bodily dimension of a world. In search of a computational theory for narrative-based world representation, this study proposes the conceptual framework of a Cogmic Space for a comic strip-like representation of a world. In the proposed framework, a story is positioned as a mid-level representation, in which the conceptual and sensory/bodily dimensions of a world are unified. The events and their background situations that constitute a story are unified into a sequence of panels. Based on this structure, a representation (i.e., a story) and the represented environment are connected via an isomorphism of their temporal, spatial, and relational structures. Furthermore, the framework of a Cogmic Space is associated with the generative aspect of representations, which is conceptualized in terms of unconscious- and conscious-level processes/representations. Finally, a proof-of-concept implementation is presented to provide a concrete account of the proposed framework.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2020.10.002,Journal,Neural Networks,scopus,2021-01-01,sciencedirect,Gradient-based training and pruning of radial basis function networks with an application in materials physics,https://api.elsevier.com/content/abstract/scopus_id/85096164921,"Many applications, especially in physics and other sciences, call for easily interpretable and robust machine learning techniques. We propose a fully gradient-based technique for training radial basis function networks with an efficient and scalable open-source implementation. We derive novel closed-form optimization criteria for pruning the models for continuous as well as binary data which arise in a challenging real-world material physics problem. The pruned models are optimized to provide compact and interpretable versions of larger models based on informed assumptions about the data distribution. Visualizations of the pruned models provide insight into the atomic configurations that determine atom-level migration processes in solid matter; these results may inform future research on designing more suitable descriptors for use with machine learning algorithms.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scs.2020.102582,Journal,Sustainable Cities and Society,scopus,2021-01-01,sciencedirect,Towards the sustainable development of smart cities through mass video surveillance: A response to the COVID-19 pandemic,https://api.elsevier.com/content/abstract/scopus_id/85096158767,"Sustainable smart city initiatives around the world have recently had great impact on the lives of citizens and brought significant changes to society. More precisely, data-driven smart applications that efficiently manage sparse resources are offering a futuristic vision of smart, efficient, and secure city operations. However, the ongoing COVID-19 pandemic has revealed the limitations of existing smart city deployment; hence; the development of systems and architectures capable of providing fast and effective mechanisms to limit further spread of the virus has become paramount. An active surveillance system capable of monitoring and enforcing social distancing between people can effectively slow the spread of this deadly virus. In this paper, we propose a data-driven deep learning-based framework for the sustainable development of a smart city, offering a timely response to combat the COVID-19 pandemic through mass video surveillance. To implementing social distancing monitoring, we used three deep learning-based real-time object detection models for the detection of people in videos captured with a monocular camera. We validated the performance of our system using a real-world video surveillance dataset for effective deployment.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ajo.2020.07.020,Journal,American Journal of Ophthalmology,scopus,2021-01-01,sciencedirect,Lightweight Learning-Based Automatic Segmentation of Subretinal Blebs on Microscope-Integrated Optical Coherence Tomography Images,https://api.elsevier.com/content/abstract/scopus_id/85092610123,"Purpose
                  Subretinal injections of therapeutics are commonly used to treat ocular diseases. Accurate dosing of therapeutics at target locations is crucial but difficult to achieve using subretinal injections due to leakage, and there is no method available to measure the volume of therapeutics successfully administered to the subretinal location during surgery. Here, we introduce the first automatic method for quantifying the volume of subretinal blebs, using porcine eyes injected with Ringer's lactate solution as samples.
               
                  Design
                  Ex vivo animal study.
               
                  Methods
                  Microscope-integrated optical coherence tomography was used to obtain 3D visualization of subretinal blebs in porcine eyes at Duke Eye Center. Two different injection phases were imaged and analyzed in 15 eyes (30 volumes), selected from a total of 37 eyes. The inclusion/exclusion criteria were set independently from the algorithm-development and testing team. A novel lightweight, deep learning–based algorithm was designed to segment subretinal bleb boundaries. A cross-validation method was used to avoid selection bias. An ensemble-classifier strategy was applied to generate final results for the test dataset.
               
                  Results
                  The algorithm performs notably better than 4 other state-of-the-art deep learning–based segmentation methods, achieving an F1 score of 93.86 ± 1.17% and 96.90 ± 0.59% on the independent test data for entry and full blebs, respectively.
               
                  Conclusion
                  The proposed algorithm accurately segmented the volumetric boundaries of Ringer's lactate solution delivered into the subretinal space of porcine eyes with robust performance and real-time speed. This is the first step for future applications in computer-guided delivery of therapeutics into the subretinal space in human subjects.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jobe.2020.101854,Journal,Journal of Building Engineering,scopus,2021-01-01,sciencedirect,Modeling for indoor temperature prediction based on time-delay and Elman neural network in air conditioning system,https://api.elsevier.com/content/abstract/scopus_id/85092148207,"An effective indoor temperature model would assist in improving energy efficiency and indoor thermal comfort of air conditioning system. However, it is difficult to build an accurate model due to lag response characteristic in the regulation process of indoor temperature. To solve this problem, the modeling and prediction methods for indoor temperature lag response characteristic based on time-delay neural network (TDNN) and Elman network neural (ENN) are presented. Then, taking variable air volume (VAV) air conditioning system as the study object, the effectiveness and practicability of proposed methods are validated using simulation sampling data and real-time operating data. Results indicate that ENN could be considered as a better modeling method for indoor temperature prediction for its simpler network structure, smaller storing space and better prediction accuracy. The contribution of this study is to provide an applicable online ANN modeling method for indoor temperature lag characteristic, and detailed training and validation for online implementation are presented, which will benefit for engineers and technicians to use in practical engineering. Meanwhile, this study provides the reference for online application of advanced intelligent algorithms in the building engineering.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engfailanal.2020.104958,Journal,Engineering Failure Analysis,scopus,2021-01-01,sciencedirect,Wear prediction of a mechanism with multiple joints based on ANFIS,https://api.elsevier.com/content/abstract/scopus_id/85092083385,"Condition monitoring data of joints in a mechanism contains enormous useful information, and can comprehensively improve the wear prediction accuracy. However, condition data of the joints is sometimes hard to obtain due to technical reasons or cost reasons, especially for some complicated mechanical systems. To obtain the real-time wear data of joints in a mechanism with multiple joints, an ANFIS-based (adaptive-network-based fuzzy inference system) joints clearance size prognostic method is developed based on monitored motion outputs of the mechanism. Then, a framework for wear prediction based on multi-body dynamics theory is proposed to predict joints wear more accurately. In the framework, the Archard’s wear model is used. To reduce the uncertainty in the wear coefficient, wear coefficient is treated as a random variable, then a Bayesian updating process is implemented according to the wear data from the ANFIS-based method. The proposed framework is validated using wear experiments of a lock mechanism with three joints in a cabin door. The results show the prediction error is within 3%.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.envres.2020.110141,Journal,Environmental Research,scopus,2021-01-01,sciencedirect,Assessing personal exposure using Agent Based Modelling informed by sensors technology,https://api.elsevier.com/content/abstract/scopus_id/85092078286,"Technology innovations create possibilities to capture exposure-related data at a great depth and breadth. Considering, though, the substantial hurdles involved in collecting individual data for whole populations, this study introduces a first approach of simulating human movement and interaction behaviour, using Agent Based Modelling (ABM).
                  A city scale ABM was developed for urban Thessaloniki, Greece that feeds into population-based exposure assessment without imposing prior bias, basing its estimations onto emerging properties of the behaviour of the computerised autonomous decision makers (agents) that compose the city-system. Population statistics, road and buildings networks data were transformed into human, road and building agents, respectively. Survey outputs with time-use patterns were associated with human agent rules, aiming to model representative to real-world behaviours. Moreover, time-geography of exposure data, derived from a local sensors campaign, was used to inform and enhance the model. As a prevalence of an agent-specific decision-making, virtual individuals of different sociodemographic backgrounds express different spatiotemporal behaviours and their trajectories are coupled with spatially resolved pollution levels.
                  Personal exposure was evaluated by assigning PM concentrations to human agents based on coordinates, type of location and intensity of encountered activities. Study results indicated that PM2.5 inhalation adjusted exposure between housemates can differ by 56.5% whereas exposure between two neighbours can vary by as much as 87%, due to the prevalence of different behaviours.
                  This study provides details of a new methodology that permits the cost-effective construction of refined time-activity diaries and daily exposure profiles, taking into account different microenvironments and sociodemographic characteristics. The proposed method leads to a refined exposure assessment model, addressing effectively vulnerable subgroups of population. It can be used for evaluating the probable impacts of different public health policies prior to implementation reducing, therefore, the time and expense required to identify efficient measures.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jneumeth.2020.108927,Journal,Journal of Neuroscience Methods,scopus,2021-01-01,sciencedirect,Automatic classification methods for detecting drowsiness using wavelet packet transform extracted time-domain features from single-channel EEG signal,https://api.elsevier.com/content/abstract/scopus_id/85091767602,"Background
                  Detecting human drowsiness during some critical works like vehicle driving, crane operating, mining blasting, etc. is one of the safeguards to prevent accidents. Among several drowsiness detection (DD) methods, a combination of neuroscience and computer science knowledge has a better ability to differentiate awake and sleep states. Most of the current models are implemented using multi-sensors electroencephalogram (EEG) signals, multi-domain features, predefined features selection algorithms. Therefore, there is great interest in the method of detecting drowsiness on embedded platforms with improved accuracy using generalized best features.
               
                  New-method
                  Single-channel EEG based drowsiness detection (DD) model is proposed in this by utilizing wavelet packet transform (WPT) to extract the time-domain features from considered channel EEG. The dimension of the feature vector is reduced by the proposed novel feature selection method.
               
                  Results
                  The proposed model on freely available real-time sleep analysis EEG and Simulated Virtual Driving Driver (SVDD) EEG achieves 94.45% and 85.3% accuracy, respectively.
               
                  Comparison-with-existing-method
                  The results show that the proposed DD method produces better accuracy compared to the state-of-the-art using the physiological dataset with the proposed time-domain sub-band-based features and feature selection method. This task of detecting drowsiness by analyzing the 5-seconds EEG signal with four features is an improvement to my previous work on detecting drowsiness using a 30-seconds EEG signal with 66 features.
               
                  Conclusions
                  Time-domain features obtained from EEG time-domain sub-bands collected using WPT achieving excellent accuracy rate by selecting unique optimization features for all subjects by the proposed feature selection algorithm.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.prro.2020.07.003,Journal,Practical Radiation Oncology,scopus,2021-01-01,sciencedirect,Time Analysis of Online Adaptive Magnetic Resonance–Guided Radiation Therapy Workflow According to Anatomical Sites,https://api.elsevier.com/content/abstract/scopus_id/85090017005,"Purpose
                  To document time analysis of detailed workflow steps for the online adaptive magnetic resonance–guided radiation therapy treatments (MRgRT) with the ViewRay MRIdian system and to identify the barriers to and solutions for shorter treatment times.
               
                  Methods and Materials
                  A total of 154 patients were treated with the ViewRay MRIdian system between September 2018 and October 2019. The time process of MRgRT workflow steps of 962 fractions for 166 treatment sites was analyzed in terms of patient and online adaptive treatment (ART) characteristics.
               
                  Results
                  Overall, 774 of 962 fractions were treated with online ART, and 83.2% of adaptive fractions were completed in less than 60 minutes. Sixty-three percent, 50.3%, and 4.2% of fractions were completed in less than 50 minutes, 45 minutes, and 30 minutes, respectively. Eight-point-three percent and 3% of fractions were completed in more than 70 minutes and 80 minutes, respectively. The median time (tmed) for ART workflow steps were as follows: (1) setup tmed: 5.0 minutes, (2) low-resolution scanning tmed: 1 minute, (3) high-resolution scanning tmed: 3 minutes, (4) online contouring tmed: 9 minutes, (5) reoptimization with online quality assurance tmed: 5 minutes, (6) real targeting tmed: 3 minutes, (7) beam delivery with gating tmed: 17 minutes, and (8) net total treatment time tmed: 45 minutes. The shortest and longest tmean rates of net total treatment time were 41.59 minutes and 64.43 minutes for upper-lung-lobe-located thoracic tumors and ultracentrally located thoracic tumors, respectively.
               
                  Conclusions
                  To our knowledge, this is the first broad treatment-time analysis for online ART in the literature. Although treatment times are long due to human- and technology-related limitations, benefits offered by MRgRT might be clinically important. In the future, implementation of artificial intelligence segmentation, an increase in dose rate, and faster multileaf collimator and gantry speeds may lead to achieving shorter MRgRT treatments.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmsy.2020.06.012,Journal,Journal of Manufacturing Systems,scopus,2021-01-01,sciencedirect,"A digital twin to train deep reinforcement learning agent for smart manufacturing plants: Environment, interfaces and intelligence",https://api.elsevier.com/content/abstract/scopus_id/85087690907,"Filling the gaps between virtual and physical systems will open new doors in Smart Manufacturing. This work proposes a data-driven approach to utilize digital transformation methods to automate smart manufacturing systems. This is fundamentally enabled by using a digital twin to represent manufacturing cells, simulate system behaviors, predict process faults, and adaptively control manipulated variables. First, the manufacturing cell is accommodated to environments such as computer-aided applications, industrial Product Lifecycle Management solutions, and control platforms for automation systems. Second, a network of interfaces between the environments is designed and implemented to enable communication between the digital world and physical manufacturing plant, so that near-synchronous controls can be achieved. Third, capabilities of some members in the family of Deep Reinforcement Learning (DRL) are discussed with manufacturing features within the context of Smart Manufacturing. Trained results for Deep Q Learning algorithms are finally presented in this work as a case study to incorporate DRL-based artificial intelligence to the industrial control process. As a result, developed control methodology, named Digital Engine, is expected to acquire process knowledges, schedule manufacturing tasks, identify optimal actions, and demonstrate control robustness. The authors show that integrating a smart agent into the industrial platforms further expands the usage of the system-level digital twin, where intelligent control algorithms are trained and verified upfront before deployed to the physical world for implementation. Moreover, DRL approach to automated manufacturing control problems under facile optimization environments will be a novel combination between data science and manufacturing industries.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ymssp.2020.107061,Journal,Mechanical Systems and Signal Processing,scopus,2021-01-01,sciencedirect,Recovering compressed images for automatic crack segmentation using generative models,https://api.elsevier.com/content/abstract/scopus_id/85086994715,"In a structural health monitoring (SHM) system that uses digital cameras to monitor cracks of structural surfaces, techniques for reliable and effective data compression are essential to ensure a stable and energy-efficient crack images transmission in wireless devices, e.g., drones and robots with high definition cameras installed. Compressive sensing (CS) is a signal processing technique that allows accurate recovery of a signal from a sampling rate much smaller than the limitation of the Nyquist sampling theorem. Different from the popular approach of simultaneously training encoder and decoder using neural network models, the CS theory ensures a high probability of accurate signal reconstruction based on random measurements that is shorter than the length of the original signal under a sparsity constraint. Such method is particularly useful when measurements are expensive, such as wireless sensing of civil structures, because its hardware implementation allows down sampling of signals during the sensing process. Hence, CS methods can achieve significant energy saving for the sensing devices. However, the strong assumption of the signals being highly sparse in an invertible space is relatively hard to guarantee for many real images, such as image of cracks. In this paper, we present a new approach of CS that replaces the sparsity regularization with a generative model that is able to effectively capture a low dimension representation of targeted images. We develop a recovery framework for automatic crack segmentation of compressed crack images based on this new CS method. We demonstrate the remarkable performance of our method that takes advantage of the strong capability of generative models to capture the necessary features required in the crack segmentation task even the backgrounds of the generated images are not well reconstructed. The superior performance of our recovery framework is illustrated by comparisons to three existing CS algorithms. Furthermore, we show that our framework is potentially extensible to other common problems in automatic crack segmentation, such as defect recovery from motion blurring and occlusion.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2019.12.006,Journal,Neurocomputing,scopus,2020-12-22,sciencedirect,Learning salient features to prevent model drift for correlation tracking,https://api.elsevier.com/content/abstract/scopus_id/85089801054,"Correlation Filter (CF) based algorithms play an important role in the field of Visual Object Tracking (VOT) due to their high accuracy and low computational complexity. While existing CF tracking algorithms suffer performance degradation due to inaccurate object modeling. In this paper, we improve the object modeling accuracy in both CF training stage and target detection procedure to preventing the drift problem. Specifically, we propose a multi-model structure for CF trackers to capture the target appearance changes, where different appearance models are trained with specific samples to catch the salient features of the target and reduce the computational cost. Furthermore, a space filter for detection features is designed to suppress the boundary effect under Gaussian motion prior, which contributes to improving the accuracy of position estimation. We deploy our method to three hand-crafted features based CF trackers to perform real-time visual tracking on popular benchmarks. The experimental results demonstrate the efficacy of our proposed scheme and the efficiency of our trackers. In addition, we provide a comprehensive analysis of the proposed method to facilitate application.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100145,Journal,Patterns,scopus,2020-12-11,sciencedirect,A Machine Learning-Aided Global Diagnostic and Comparative Tool to Assess Effect of Quarantine Control in COVID-19 Spread,https://api.elsevier.com/content/abstract/scopus_id/85097386310,"We have developed a globally applicable diagnostic COVID-19 model by augmenting the classical SIR epidemiological model with a neural network module. Our model does not rely upon previous epidemics like SARS/MERS and all parameters are optimized via machine learning algorithms used on publicly available COVID-19 data. The model decomposes the contributions to the infection time series to analyze and compare the role of quarantine control policies used in highly affected regions of Europe, North America, South America, and Asia in controlling the spread of the virus. For all continents considered, our results show a generally strong correlation between strengthening of the quarantine controls as learnt by the model and actions taken by the regions' respective governments. In addition, we have hosted our quarantine diagnosis results for the top 70 affected countries worldwide, on a public platform.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100139,Journal,Patterns,scopus,2020-12-11,sciencedirect,scTenifoldNet: A Machine Learning Workflow for Constructing and Comparing Transcriptome-wide Gene Regulatory Networks from Single-Cell Data,https://api.elsevier.com/content/abstract/scopus_id/85096558897,"We present scTenifoldNet—a machine learning workflow built upon principal-component regression, low-rank tensor approximation, and manifold alignment—for constructing and comparing single-cell gene regulatory networks (scGRNs) using data from single-cell RNA sequencing. scTenifoldNet reveals regulatory changes in gene expression between samples by comparing the constructed scGRNs. With real data, scTenifoldNet identifies specific gene expression programs associated with different biological processes, providing critical insights into the underlying mechanism of regulatory networks governing cellular transcriptional activities.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100137,Journal,Patterns,scopus,2020-12-11,sciencedirect,Parallel Factor Analysis Enables Quantification and Identification of Highly Convolved Data-Independent-Acquired Protein Spectra,https://api.elsevier.com/content/abstract/scopus_id/85096522758,"High-throughput data-independent acquisition (DIA) is the method of choice for quantitative proteomics, combining the best practices of targeted and shotgun approaches. The resultant DIA spectra are, however, highly convolved and with no direct precursor-fragment correspondence, complicating biological sample analysis. Here, we present CANDIA (canonical decomposition of data-independent-acquired spectra), a GPU-powered unsupervised multiway factor analysis framework that deconvolves multispectral scans to individual analyte spectra, chromatographic profiles, and sample abundances, using parallel factor analysis. The deconvolved spectra can be annotated with traditional database search engines or used as high-quality input for de novo sequencing methods. We demonstrate that spectral libraries generated with CANDIA substantially reduce the false discovery rate underlying the validation of spectral quantification. CANDIA covers up to 33 times more total ion current than library-based approaches, which typically use less than 5% of total recorded ions, thus allowing quantification and identification of signals from unexplored DIA spectra.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.comnet.2020.107573,Journal,Computer Networks,scopus,2020-12-09,sciencedirect,AI-enabled mobile multimedia service instance placement scheme in mobile edge computing,https://api.elsevier.com/content/abstract/scopus_id/85091771160,"Leveraging cloud infrastructure to the mobile edge computing helps the mobile users to get real time multimedia services in Fifth Generation (5G) network system. To ensure higher Quality-of-Experience (QoE), faster migration of mobile multimedia service instances is required to cope up with user mobility. By deploying the mobile multimedia service instances proactively in multiple edge nodes (ENs) helps the users to get higher QoE. However, excessive deployment of service replicas might increase the cost of the overall network. To establish trade-off between these two conflicting objectives, we have formulated the problem as a Multi-objective Integer Linear Programming (MILP) by integrating the users’ path prediction model. This problem is proven to be an NP-hard one for large networks, thus we develop an artificial intelligence (AI) based meta-heuristic Binary Particle Swarm Optimization (BPSO) algorithm to achieve near-optimal solution within polynomial time. The performance analysis results show the significant performance improvement in terms of QoE and user satisfaction as compared to other state-of-the-art works.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.iot.2020.100301,Journal,Internet of Things (Netherlands),scopus,2020-12-01,sciencedirect,Predicting parking occupancy via machine learning in the web of things,https://api.elsevier.com/content/abstract/scopus_id/85098729769,"The Web of Things (WoT) enables information gathered by sensors deployed in urban environments to be easily shared utilizing open Web standards and semantic technologies, creating easier integration with other Web-based information, towards advanced knowledge. Besides WoT, an essential aspect of understanding dynamic urban systems is artificial intelligence (AI). Via AI, data produced by WoT-enabled sensory observations can be analyzed and transformed into meaningful information, which describes and predicts current and future situations in time and space. This paper examines the impact of WoT and AI in smart cities, considering a real-world problem, the one of predicting parking availability. Traffic cameras are used as WoT sensors, together with weather forecasting Web services. Machine learning (ML) is employed for AI analysis, using predictive models based on neural networks and random forests. The performance of the ML models for the prediction of parking occupancy is better than the state of the art work in the problem under study, scoring an MSE of 7.18 at a time horizon of 60 minutes.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2020.106754,Journal,Applied Soft Computing Journal,scopus,2020-12-01,sciencedirect,Sentiment Analysis of COVID-19 tweets by Deep Learning Classifiers—A study to show how popularity is affecting accuracy in social media,https://api.elsevier.com/content/abstract/scopus_id/85092457474,"COVID-19 originally known as Corona VIrus Disease of 2019, has been declared as a pandemic by World Health Organization (WHO) on 11th March 2020. Unprecedented pressures have mounted on each country to make compelling requisites for controlling the population by assessing the cases and properly utilizing available resources. The rapid number of exponential cases globally has become the apprehension of panic, fear and anxiety among people. The mental and physical health of the global population is found to be directly proportional to this pandemic disease. The current situation has reported more than twenty four million people being tested positive worldwide as of 27th August, 2020. Therefore, it is the need of the hour to implement different measures to safeguard the countries by demystifying the pertinent facts and information. This paper aims to bring out the fact that tweets containing all handles related to COVID-19 and WHO have been unsuccessful in guiding people around this pandemic outbreak appositely. This study analyzes two types of tweets gathered during the pandemic times. In one case, around twenty three thousand most re-tweeted tweets within the time span from 1st Jan 2019 to 23rd March 2020 have been analyzed and observation says that the maximum number of the tweets portrays neutral or negative sentiments. On the other hand, a dataset containing 226,668 tweets collected within the time span between December 2019 and May 2020 have been analyzed which contrastingly show that there were a maximum number of positive and neutral tweets tweeted by netizens. The research demonstrates that though people have tweeted mostly positive regarding COVID-19, yet netizens were busy engrossed in re-tweeting the negative tweets and that no useful words could be found in WordCloud or computations using word frequency in tweets. The claims have been validated through a proposed model using deep learning classifiers with admissible accuracy up to 81%. Apart from these the authors have proposed the implementation of a Gaussian membership function based fuzzy rule base to correctly identify sentiments from tweets. The accuracy for the said model yields up to a permissible rate of 79%.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.arr.2020.101174,Journal,Ageing Research Reviews,scopus,2020-12-01,sciencedirect,"A research agenda for ageing in China in the 21st century (2nd edition): Focusing on basic and translational research, long-term care, policy and social networks",https://api.elsevier.com/content/abstract/scopus_id/85091870837,"One of the key issues facing public healthcare is the global trend of an increasingly ageing society which continues to present policy makers and caregivers with formidable healthcare and socio-economic challenges. Ageing is the primary contributor to a broad spectrum of chronic disorders all associated with a lower quality of life in the elderly. In 2019, the Chinese population constituted 18 % of the world population, with 164.5 million Chinese citizens aged 65 and above (65+), and 26 million aged 80 or above (80+). China has become an ageing society, and as it continues to age it will continue to exacerbate the burden borne by current family and public healthcare systems. Major healthcare challenges involved with caring for the elderly in China include the management of chronic non-communicable diseases (CNCDs), physical frailty, neurodegenerative diseases, cardiovascular diseases, with emerging challenges such as providing sufficient dental care, combating the rising prevalence of sexually transmitted diseases among nursing home communities, providing support for increased incidences of immune diseases, and the growing necessity to provide palliative care for the elderly. At the governmental level, it is necessary to make long-term strategic plans to respond to the pressures of an ageing society, especially to establish a nationwide, affordable, annual health check system to facilitate early diagnosis and provide access to affordable treatments. China has begun work on several activities to address these issues including the recent completion of the of the Ten-year Health-Care Reform project, the implementation of the Healthy China 2030 Action Plan, and the opening of the National Clinical Research Center for Geriatric Disorders. There are also societal challenges, namely the shift from an extended family system in which the younger provide home care for their elderly family members, to the current trend in which young people are increasingly migrating towards major cities for work, increasing reliance on nursing homes to compensate, especially following the outcomes of the ‘one child policy’ and the ‘empty-nest elderly’ phenomenon. At the individual level, it is important to provide avenues for people to seek and improve their own knowledge of health and disease, to encourage them to seek medical check-ups to prevent/manage illness, and to find ways to promote modifiable health-related behaviors (social activity, exercise, healthy diets, reasonable diet supplements) to enable healthier, happier, longer, and more productive lives in the elderly. Finally, at the technological or treatment level, there is a focus on modern technologies to counteract the negative effects of ageing. Researchers are striving to produce drugs that can mimic the effects of ‘exercising more, eating less’, while other anti-ageing molecules from molecular gerontologists could help to improve ‘healthspan’ in the elderly. Machine learning, ‘Big Data’, and other novel technologies can also be used to monitor disease patterns at the population level and may be used to inform policy design in the future. Collectively, synergies across disciplines on policies, geriatric care, drug development, personal awareness, the use of big data, machine learning and personalized medicine will transform China into a country that enables the most for its elderly, maximizing and celebrating their longevity in the coming decades. This is the 2nd edition of the review paper (Fang EF et al., Ageing Re. Rev. 2015).",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jpdc.2020.08.008,Journal,Journal of Parallel and Distributed Computing,scopus,2020-12-01,sciencedirect,Towards cost-effective service migration in mobile edge: A Q-learning approach,https://api.elsevier.com/content/abstract/scopus_id/85090113588,"Service migration in mobile edge computing is a promising approach to improving the quality of service (QoS) for mobile users and reducing the network operational cost for service providers as well. However, these benefits are not free, coming at costs of bulk-data transfer, and likely service disruption, which could consequently increase the overall service costs. To gain the benefits of service migration while minimizing its cost across the edge nodes, in this paper, we leverage reinforcement learning (RL) method to design a cost-effective framework, called Mig-RL, for the service migration with a reduction of total service costs as a goal in a mobile edge environment. The Mig-RL leverages the infrastructure of edge network and deploys a migration agent through Q-learning to learn the optimal policy with respect to the service migration status. We distinguish the Mig-RL from other existing works in several major aspects. First, we fully exploit the nature of this problem in a modest migration space, which allows us to constrain the number of service replicas whereby a defined state–action space could be effectively handled, as opposed to those methods that need to always approximate a huge state–action space for policy optimality. Second, we advocate a migration policy-base as a cache to save the learning process by retrieving the most effective policy whenever a similar migration pattern is encountered as time goes on. Finally, by exploiting the idea of software defined network, we also investigate the efficient implementation of Mig-RL in mobile edge network. Experimental results based on some real and synthesized access sequences show that Mig-RL, compared with the selected existing algorithms, can substantially minimize the service costs, and in the meantime, efficiently improve the QoS by adapting to the changes of mobile access patterns.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cma.2020.113371,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2020-12-01,sciencedirect,Stochastic nonlocal damage analysis by a machine learning approach,https://api.elsevier.com/content/abstract/scopus_id/85089593784,"A machine learning aided stochastic nonlocal damage analysis framework is proposed for quasi-brittle materials. The uncertain system parameters, including the material properties and loading actions, have been incorporated and analysed within a unified safety assessment framework against various working conditions. A three-dimensional integral-type nonlocal damage model through finite element method (FEM) has been adopted. For the purpose of investigating the probabilistic damage analysis problems, a freshly established machine learning approach, namely the capped-extended-support vector regression method (C-X-SVR), is proposed to eliminate the influences of random outliers in the first step, then establish the relationship between the uncertain systemic inputs and structural responses. Such that the training robustness and computational adaptability of the proposed regression model can be reinforced. Moreover, the proposed approach is competent of efficiently predicting the statistical information (i.e., means, standard deviations, probability density functions and cumulative density functions) of structural behaviours under continuous information update of the uncertain working condition from mercurial environment. One real-life experimental validation and two numerical investigations are implemented to further verify the effectiveness and efficiency of the uncertainty quantification framework against probabilistic damage analysis.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.inffus.2020.07.003,Journal,Information Fusion,scopus,2020-12-01,sciencedirect,"Data fusion strategies for energy efficiency in buildings: Overview, challenges and novel orientations",https://api.elsevier.com/content/abstract/scopus_id/85087624082,"Recently, tremendous interest has been devoted to develop data fusion strategies for energy efficiency in buildings, where various kinds of information can be processed. However, applying the appropriate data fusion strategy to design an efficient energy efficiency system is not straightforward; it requires a priori knowledge of existing fusion strategies, their applications and their properties. To this regard, seeking to provide the energy research community with a better understanding of data fusion strategies in building energy saving systems, their principles, advantages, and potential applications, this paper proposes an extensive survey of existing data fusion mechanisms deployed to reduce excessive consumption and promote sustainability. We investigate their conceptualizations, advantages, challenges and drawbacks, as well as performing a taxonomy of existing data fusion strategies and other contributing factors. Following, a comprehensive comparison of the state-of-the-art data fusion based energy efficiency frameworks is conducted using various parameters, including data fusion level, data fusion techniques, behavioral change influencer, behavioral change incentive, recorded data, platform architecture, IoT technology and application scenario. Moreover, a novel method for electrical appliance identification is proposed based on the fusion of 2D local texture descriptors, where 1D power signals are transformed into 2D space and treated as images. The empirical evaluation, conducted on three real datasets, shows promising performance, in which up to 99.68% accuracy and 99.52% F1 score have been attained. In addition, various open research challenges and future orientations to improve data fusion based energy efficiency ecosystems are explored.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.pcd.2020.05.005,Journal,Primary Care Diabetes,scopus,2020-12-01,sciencedirect,The prevalence of chronic kidney disease and screening of renal function in type 2 diabetic patients in Finnish primary healthcare,https://api.elsevier.com/content/abstract/scopus_id/85086126998,"Aims
                  To estimate the prevalence of chronic kidney disease (CKD) in patients with type 2 diabetes (T2D) in Finnish primary healthcare, and to evaluate the screening for CKD and the proportions of patients receiving antihyperglycemic and cardiovascular preventive medication.
               
                  Material and methods
                  T2D patients treated at the Rovaniemi Health Center, Finland during the years 2015–2019. Data included patient characteristics, blood pressure, HbA1c, lipid levels, kidney function and albuminuria, and medications prescribed. CKD was defined as estimated glomerular filtration rate (eGFR) <60 ml/min/1.72 m2 and/or albuminuria.
               
                  Results
                  The study population comprised of 5112 T2D patients with a mean (SD) age of 66.7 (13.0) years. Of these, 60.2% were screened for CKD with both eGFR and albuminuria, and 30.1% of these patients had CKD. The prevalence of moderately increased and severely increased albuminuria was 19.6% and 3.2%, respectively. A total of 57.0% of the study population received angiotensin-converting enzyme (ACE) inhibitors or angiotensin receptor blockers (ARB).
               
                  Conclusions
                  Screening for CKD with both recommended measures (eGFR and albuminuria) was insufficiently performed among this T2D population. Additionally, just over half of the study population had been prescribed ACE inhibitors or ARB. These results suggest an incongruity between the gold standard of diabetes care and real-world clinical practice.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2020.08.012,Journal,Neural Networks,scopus,2020-12-01,sciencedirect,Latent Dirichlet allocation based generative adversarial networks,https://api.elsevier.com/content/abstract/scopus_id/85083895792,"Generative adversarial networks have been extensively studied in recent years and powered a wide range of applications, ranging from image generation, image-to-image translation, to text-to-image generation, and visual recognition. These methods typically model the mapping from latent space to image with single or multiple generators. However, they have obvious drawbacks: (i) ignoring the multi-modal structure of images, and (ii) lacking model interpretability. Importantly, the existing methods mostly assume one or more generators can cover all image modes even if we do not know the structure of data. Thus, mode dropping and collapse often take place along with GANs training. Despite the importance of exploring the data structure in generation, it has been almost unexplored. In this work, aiming at generating multi-modal images and interpreting model explicitly, we explore the theory on how to integrate GANs with data structure prior, and propose latent Dirichlet allocation based generative adversarial networks (LDAGAN). This framework is extended to combine with a variety of state-of-the-art single-generator GANs and achieves improved performance. Extensive experiments on synthetic and real datasets demonstrate the efficacy of LDAGAN for multi-modal image generation. An implementation of LDAGAN is available at https://github.com/Sumching/LDAGAN.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2020.106457,Journal,Knowledge-Based Systems,scopus,2020-11-15,sciencedirect,Mining high utility itemsets using extended chain structure and utility machine,https://api.elsevier.com/content/abstract/scopus_id/85091059855,"High utility itemsets are sets of items that have a high utility (e.g. a high profit or a high importance) in a transaction database. Discovering high utility itemsets has many important applications in real-life such as market basket analysis. Nonetheless, mining these patterns is a time-consuming process due to the huge search space and the high cost of utility computation. Most of previous work is devoted to search space pruning but pay little attention to utility computation. Factually, not only search space pruning but also high utility itemset identification have to resort to the computation of various utilities. This paper proposes a novel algorithm named REX (Rapid itEmset eXtraction), which extends the classic d
                        
                           
                           
                              2
                           
                        
                     HUP algorithm with an improved structure, a 
                        k
                     -item utility machine, and an efficient switch strategy. The structure can significantly reduce the time complexity of utility computation compared with the original structure used in d
                        
                           
                           
                              2
                           
                        
                     HUP. The machine can quickly merge identical transactions and applies an efficient procedure for computing the utilities of extensions of a given itemset. The strategy derived from trial and error drastically gives rise to performance improvement on some databases and is also competitive with the switch strategy used in d
                        
                           
                           
                              2
                           
                        
                     HUP on other databases. Experimental results show that REX achieves a speedup of from fifty percent to three orders of magnitude over d
                        
                           
                           
                              2
                           
                        
                     HUP even though they use identical pruning techniques and that REX considerably outperforms state-of-the-art algorithms on real-life and synthetic databases.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100107,Journal,Patterns,scopus,2020-11-13,sciencedirect,Wiz: A Web-Based Tool for Interactive Visualization of Big Data,https://api.elsevier.com/content/abstract/scopus_id/85097417500,"In an age of information, visualizing and discerning meaning from data is as important as its collection. Interactive data visualization addresses both fronts by allowing researchers to explore data beyond what static images can offer. Here, we present Wiz, a web-based application for handling and visualizing large amounts of data. Wiz does not require programming or downloadable software for its use and allows scientists and non-scientists to unravel the complexity of data by splitting their relationships through 5D visual analytics, performing multivariate data analysis, such as principal component and linear discriminant analyses, all in vivid, publication-ready figures. With the explosion of high-throughput practices for materials discovery, information streaming capabilities, and the emphasis on industrial digitalization and artificial intelligence, we expect Wiz to serve as an invaluable tool to have a broad impact in our world of big data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.comnet.2020.107436,Journal,Computer Networks,scopus,2020-11-09,sciencedirect,Arena: A 64-antenna SDR-based ceiling grid testing platform for sub-6 GHz 5G-and-Beyond radio spectrum research,https://api.elsevier.com/content/abstract/scopus_id/85090236272,"Arena is an open-access wireless testing platform based on a grid of antennas mounted on the ceiling of a large office-space environment. Each antenna is connected to programmable software-defined radios (SDR) enabling sub-6 GHz 5G-and-beyond spectrum research. With 12 computational servers, 24 SDRs synchronized at the symbol level, and a total of 64 antennas, Arena provides the computational power and the scale to foster new technology development in some of the most crowded spectrum bands. Arena is based on a three-tier design, where the servers and the SDRs are housed in a double rack in a dedicated room, while the antennas are hung off the ceiling of a 2240 square feet office space and cabled to the radios through 100 ft-long cables. This ensures a reconfigurable, scalable, and repeatable real-time experimental evaluation in a real wireless indoor environment.
                  In this paper, we introduce the architecture, capabilities, and system design choices of Arena, and provides details of the software and hardware implementation of various testbed components. Furthermore, we describe key capabilities by providing examples of published work that employed Arena for applications as diverse as synchronized MIMO transmission schemes, multi-hop ad hoc networking, multi-cell 5G networks, AI-powered Radio-Frequency fingerprinting, secure wireless communications, and spectrum sensing for cognitive radio.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mechatronics.2020.102436,Journal,Mechatronics,scopus,2020-11-01,sciencedirect,Modeling the thermo-mechanical deformations of machine tool structures in CFRP material adopting data-driven prediction schemes,https://api.elsevier.com/content/abstract/scopus_id/85092002525,"The thermo-mechanical effects in machine tools (MTs) are represented by complex models since they may produce non-linear distortions overtime, impacting significantly on the machining accuracy. This paper aims to model the deformation of CFRP (Carbon-Fiber-Reinforced-Polymers) structures using data-driven schemes to predict and compensate the structural thermo-mechanical behavior. A novel study is presented to investigate the thermally-induced distortions of CFPR structural materials, selecting and positioning sensors, simulating and validating models to compensate the error in real-time. Anisotropic materials are becoming an effective solution to reduce structure mass and increase damping of a MT, nevertheless their physical complexity and the different thermal-coefficients at the interface with conventional materials may generate undesired effects, limiting the obtained advantages. The proposed strategy is based on the evaluation of a set of data-driven models simultaneously, identifying the most suitable solution and comparing finite element simulations with machine learning approach. The study is developed on a vertical axis frame made of CFRP material. The experimental validation is executed on a commercial 5-axis machine tool by varying the temperature conditions and evaluating the structural thermo-mechanical deformation effect on the Tool-Tip-Point (TTP) displacement. The thermo-mechanical behavior is measured by fiber Bragg grating (FBG) sensing technology embedded in the CFRP structure. Data-driven lab tests are evaluated in operational conditions during 36 h, considering: i) training-deployment periods (875 min interval), ii) typical machining stresses and iii) environmental perturbations. The final selected data-driven model is able to reduce the detected error lower than 10 μm range. In particular, the achieved results indicate a congruence between the TTP displacement measured and predicted with a residual error lower than 7.0 μm (Y-direction) using the ANN- multilayer perceptron algorithm.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mpdhp.2020.08.004,Journal,Diagnostic Histopathology,scopus,2020-11-01,sciencedirect,Artificial intelligence in pathology: an overview,https://api.elsevier.com/content/abstract/scopus_id/85090478810,"Artificial intelligence (AI) is at the forefront of modern technology and emerging uses within the healthcare sector are now being realised. Pathology will be a key area where the impact of AI will be felt. With more and more laboratories making the transition to digital pathology this will provide the key infrastructure in which to deploy these tools and their use will start to become a reality in diagnostic practice. The potential of AI in pathology is to create image analysis tools which could either be used for diagnostic support or to derive novel insights into disease biology, in addition to those achievable with a human observer. Some examples providing diagnostic support currently exist for a limited, but expanding number of applications, such as tumour detection, automated tumour grading, immunohistochemistry scoring, and predicting mutation status. There are a number of challenges to consider, not least the validation and regulatory framework for these tools. In this article, we set out an overview of AI in histopathology, discuss its potential workflow applications, and give key examples of the potential for AI in clinical practice. Considerations for the implementation of AI in practice are also explored.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2020.07.028,Journal,Neural Networks,scopus,2020-11-01,sciencedirect,Compressing 3DCNNs based on tensor train decomposition,https://api.elsevier.com/content/abstract/scopus_id/85089391288,"Three-dimensional convolutional neural networks (3DCNNs) have been applied in many tasks, e.g., video and 3D point cloud recognition. However, due to the higher dimension of convolutional kernels, the space complexity of 3DCNNs is generally larger than that of traditional two-dimensional convolutional neural networks (2DCNNs). To miniaturize 3DCNNs for the deployment in confining environments such as embedded devices, neural network compression is a promising approach. In this work, we adopt the tensor train (TT) decomposition, a straightforward and simple in situ training compression method, to shrink the 3DCNN models. Through proposing tensorizing 3D convolutional kernels in TT format, we investigate how to select appropriate TT ranks for achieving higher compression ratio. We have also discussed the redundancy of 3D convolutional kernels for compression, core significance and future directions of this work, as well as the theoretical computation complexity versus practical executing time of convolution in TT. In the light of multiple contrast experiments based on VIVA challenge, UCF11, UCF101, and ModelNet40 datasets, we conclude that TT decomposition can compress 3DCNNs by around one hundred times without significant accuracy loss, which will enable its applications in extensive real world scenarios.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.sigpro.2020.107717,Journal,Signal Processing,scopus,2020-11-01,sciencedirect,Fast and efficient implementation of image filtering using a side window convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85088128229,"Convolutional neural networks (CNNs) designed for object recognition have been successfully applied to low-level tasks such as image filtering. However, these networks are usually very large which occupy large memory space and demand very high computational capacity. This makes them unsuitable for real time low-level applications on smart and portable devices with limited memory and computational capacities. In this paper, we specifically design a novel CNN, side window convolutional neural network (SW-CNN), for the fast and efficient implementation of image filtering. In SW-CNN, a new convolutional strategy, called side kernel convolution (SKC) is proposed which aligns the side or corner of the convolutional window with the pixels under processing to preserve edges during convolution. By combining SKC and the representational power of CNNs, SW-CNN can learn various image-filtering tasks very effectively. Compared to the state-of-the-art networks, the superiority of SW-CNN includes three aspects. First, the number of learnable parameters is reduced by 96%. Second, the memory consumption is reduced to 50%. Third, the running time is decreased to 50%. Results of extensive experiments demonstrate that SW-CNN not only has good performance on implementing various edge-preserving filters, but also has the adaptability and flexibility on other low-level image processing applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.physd.2020.132615,Journal,Physica D: Nonlinear Phenomena,scopus,2020-11-01,sciencedirect,A Reduced Order Deep Data Assimilation model,https://api.elsevier.com/content/abstract/scopus_id/85087917230,"A new Reduced Order Deep Data Assimilation (RODDA) model combining Reduced order models (ROM), Data Assimilation (DA) and Machine Learning is proposed in this paper. The RODDA model aims to improve the accuracy of Computational Fluid Dynamics (CFD) simulations. The DA model ingests information from observed data in the simulation provided by the CFD model. The results of the DA are used to train a neural network learning a function which predicts the misfit between the results of the CFD model and the DA model. Thus, the trained function is combined with the original CFD model in order to generate forecasts with implicit DA given by neural network. Due to the time complexity of the numerical models used to implement DA and the neural network, and due to the scale of the forecasting area considered for forecasting problems in real case scenarios, the implementation of RODDA mandated the introduction of opportune reduced spaces. Here, RODDA is applied to a CFD simulation for air pollution, using the CFD software Fluidity, in South London (UK). We show that, using this framework, the data forecasted by the coupled model CFD+RODDA are closer to the observations with a gain in terms of execution time with respect to the classic prediction–correction cycle given by coupling CFD with a standard DA. Additionally, RODDA predicts future observations, if not available, since these are embedded in the data assimilated state in which the network is trained on. The RODDA framework is not exclusive to air pollution, Fluidity, or the study area in South London, and therefore the workflow could be applied to different physical models if enough temporal data are available.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ipm.2020.102340,Journal,Information Processing and Management,scopus,2020-11-01,sciencedirect,A topic modeling framework for spatio-temporal information management,https://api.elsevier.com/content/abstract/scopus_id/85087504158,"Real-time processing and learning of conflicting data, especially messages coming from different ideas, locations, and time, in a dynamic environment such as Twitter is a challenging task that recently gained lots of attention. This paper introduces a framework for managing, processing, analyzing, detecting, and tracking topics in streaming data. We propose a model selector procedure with a hybrid indicator to tackle the challenge of online topic detection. In this framework, we built an automatic data processing pipeline with two levels of cleaning. Regular and deep cleaning are applied using multiple sources of meta knowledge to enhance data quality. Deep learning and transfer learning techniques are used to classify health-related tweets, with high accuracy and improved F1-Score. In this system, we used visualization to have a better understanding of trending topics. To demonstrate the validity of this framework, we implemented and applied it to health-related twitter data from users originating in the USA over nine months. The results of this implementation show that this framework was able to detect and track the topics at a level comparable to manual annotation. To better explain the emerging and changing topics in various locations over time the result is graphically displayed on top of the United States map.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.petrol.2020.107509,Journal,Journal of Petroleum Science and Engineering,scopus,2020-11-01,sciencedirect,"Design and construction of the knowledge base system for geological outfield cavities classifications: An example of the fracture-cavity reservoir outfield in Tarim basin, NW China",https://api.elsevier.com/content/abstract/scopus_id/85087076723,"Tahe oilfield, located in NW Tarim Basin, is one of the largest and most difficult fracture cavity reservoirs in the world. Different fracture cavities, different generated mechanisms, and different oil production capacities. In order to study the significant parameters that can characterize the categories of facture-cavity. This research adopted outfield manual measurement, 3D digital modeling technique to obtain characterization parameters. According to experienced geological survey, typical outcrops were selected, then scanned by UAV (Unmanned aerial vehicle). Consequently, 3D digital models, including real coordinates and parameter information, were established by Agisoft Photoscan. Through geological testing results, various combination characteristic patterns of relative categories were analyzed. By using digital measure tool, combined with manually measured data, the parameters were extracted from the 3D digital model (DM). Then an initial geological database was established. For furtherly analyzing the database, the mathematic statistics methods of multiple linear regression (MLR), neural network technique (NNT) and discriminative classification technique (DCT) were applied. Using software of SPSS statistics 17.0, more than 200 groups of geological data (various categories of fracture-cavity) were optimally processed. Consequently, the significant characteristic parameters were interpreted to determine diverse categories. The results showed that: (1) cavity width, height, fracture length and cavity aspect ratio were significant parameters to classify runoff cavity categories. (2) Fault-controlled cavities could be accurately classified by fracture length and fracture density. (3) The main cavity categories could be distinguished by cavity width, cavity height and fracture density. Performances of the approach have been examined with 10 percentages of the samples, and a good agreement performed in the simulated results, and anastomosis rate was more than 80%. The researched results have critical guiding significance to evaluate types of fracture-cavity, develop and explore of fracture-cavity reservoirs. The construction technique of knowledge base can be applied for diverse fracture-cavity reservoirs in the various formations in different areas in the world.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jpdc.2020.06.010,Journal,Journal of Parallel and Distributed Computing,scopus,2020-11-01,sciencedirect,Performance enhancement of a dynamic K-means algorithm through a parallel adaptive strategy on multicore CPUs,https://api.elsevier.com/content/abstract/scopus_id/85086986038,"The K-means algorithm is one of the most popular algorithms in Data Science, and it is aimed to discover similarities among the elements belonging to large datasets, partitioning them in 
                        K
                      distinct groups called clusters. The main weakness of this technique is that, in real problems, it is often impossible to define the value of 
                        K
                      as input data. Furthermore, the large amount of data used for useful simulations makes impracticable the execution of the algorithm on traditional architectures. In this paper, we address the previous two issues. On the one hand, we propose a method to dynamically define the value of 
                        K
                      by optimizing a suitable quality index with special care to the computational cost. On the other hand, to improve the performance and the effectiveness of the algorithm, we propose a strategy for parallel implementation on modern multicore CPUs.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cpc.2020.107365,Journal,Computer Physics Communications,scopus,2020-11-01,sciencedirect,CONUNDrum: A program for orbital-free density functional theory calculations,https://api.elsevier.com/content/abstract/scopus_id/85086471143,"We present a new code for energy minimization, structure relaxation and evaluation of bulk parameters in the framework of orbital-free density functional theory (OF-DFT). The implementation is based on solving the Euler–Lagrange equation on an equidistant real space grid on which density dependent variables and derivatives are computed. Some potential components are computed in Fourier space. The code is able to use semilocal and non-local kinetic energy functionals (KEF) as well as neural network based KEFs thus facilitating testing and development of emerging machine-learned KEFs. For semi-local and machine-learned KEFs the kinetic energy potentials are evaluated with real-space differentiation of the components, which are partial derivatives of the KE with respect to the electron density, its gradient and Laplacian.
               
                  Program summary
                  
                     Program title: CONUNDrum.
                  
                     CPC Library link to program files: 
                     http://dx.doi.org/10.17632/phnz2gg8mz.1
                  
                  
                     Licensing provision: GNU GPL v3
                  
                     Programming language: C++
                  
                     External routines: Fastest Fourier Transform in the West (FFTW) library (http://www.fftw.org/)
                  
                     Nature of problem: Calculation of the electronic and structural properties of molecules and extended systems in the framework of the orbital-free density functional theory. Evaluation of the bulk parameters of solid compounds.
                  
                     Solution method: High-order central finite-difference method and fast Fourier transform are used for calculation of different total energy components. Density optimization is performed with the steepest descent or the Polak–Ribière variant of the non-linear conjugate-gradient method with a line search procedure based on the Armijo condition. A numerical approach is used for structural optimization — the total energies with respect to small variations in lattice geometries are computed directly, with subsequent evaluation of the force components via a high-order central-finite difference method. The same numerical procedure is used for evaluation of bulk properties.
                  
                     Restrictions: Local pseudopotentials.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jpba.2020.113544,Journal,Journal of Pharmaceutical and Biomedical Analysis,scopus,2020-10-25,sciencedirect,Development and validation of UHPLC-PDA method for simultaneous determination of bioactive polyphenols of horse-chestnut bark using numerical optimization with MS Excel Solver,https://api.elsevier.com/content/abstract/scopus_id/85089903464,"A fast and eﬃcient UHPLC-PDA method was developed for quantification of polyphenols of horse-chestnut (Aesculus hippocastanum) bark, an herbal medicinal agent used for the treatment of vascular ailments. To optimize a simple one step-gradient separation, four main factors were selected (initial acetonitrile concentration, gradient slope, flow rate and temperature). Retention times and widths of ten target peaks were modelled using central composite design, and the optimal compromise between the time of the analysis and resolution was found using Derringer’s desirability function and numerical optimization procedure with the use of MS Excel software. The optimal separation conditions were as follows: initial acetonitrile concentration of 9.9 %, gradient slope of 2.4 %/min, flow rate of 0.7 mL/min and temperature of 35 °C. Chromatographic separation was carried out on a Titan C18 column (1.9 μm, 100 × 2.1 mm i.d.; Supelco) and was completed within 5 min with minimal resolution between the observed critical pairs of 1.93. The experimental results were in good accordance with the ones calculated from the models. Stability of the analytes in standard solutions and processed plant samples was found acceptable up to 14 days of storage at 4 °C. The validation proved also good linearity (r > 0.99995), precision (RSD < 4 %), accuracy (96.8–99.2 %), and sensitivity (LOQs 0.14−0.61 ng; LODs 0.05–0.20 ng) of the method, and its applicability for quantification of six primary coumarins and flavan-3-ols in A. hippocastanum bark was demonstrated for real commercial samples (different providers and years of collection). Additionally, the good separation of the plant matrix allowed for determination of the approximate contents of three minor constituents. The developed procedure proved to be a useful tool in quality control of the herbal material, and MS Excel software was demonstrated to be valuable for optimization of Derringer’s function and visualization of the modelled separation.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cels.2020.08.016,Journal,Cell Systems,scopus,2020-10-21,sciencedirect,Fast and Flexible Protein Design Using Deep Graph Neural Networks,https://api.elsevier.com/content/abstract/scopus_id/85092248944,"Protein structure and function is determined by the arrangement of the linear sequence of amino acids in 3D space. We show that a deep graph neural network, ProteinSolver, can precisely design sequences that fold into a predetermined shape by phrasing this challenge as a constraint satisfaction problem (CSP), akin to Sudoku puzzles. We trained ProteinSolver on over 70,000,000 real protein sequences corresponding to over 80,000 structures. We show that our method rapidly designs new protein sequences and benchmark them in silico using energy-based scores, molecular dynamics, and structure prediction methods. As a proof-of-principle validation, we use ProteinSolver to generate sequences that match the structure of serum albumin, then synthesize the top-scoring design and validate it in vitro using circular dichroism. ProteinSolver is freely available at http://design.proteinsolver.org and https://gitlab.com/ostrokach/proteinsolver. A record of this paper’s transparent peer review process is included in the Supplemental Information.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2020.106256,Journal,Knowledge-Based Systems,scopus,2020-10-12,sciencedirect,Community detection based on the Matthew effect,https://api.elsevier.com/content/abstract/scopus_id/85088031223,"Community structure exists in most real-world networks, such as social networks, smart grids, and transportation networks. Established approaches for community detection usually depend on some user-defined criteria (e.g., minimum cut, normalized cut, modularity, etc.). These criteria-based methods usually involve some optimization procedures and need to specify some parameters, which are thus time consuming and sensitive to parameters. In this paper, inspired by the Mathew effect of human society, we view a network as a social system and design a new algorithm called CDME (community detection based on the Matthew effect). Relying on the new concept, CDME has many desirable properties. It allows uncovering high-quality communities driven by dynamic CDME is also parameter free. More importantly, since CDME works in a local way and only needs to calculate the attractiveness of neighboring nodes, which lend itself to handling large-scale networks. Experiments on both synthetic and real-world data sets have demonstrated that CDME has many benefits and outperforms many state-of-the-art algorithms.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100108,Journal,Patterns,scopus,2020-10-09,sciencedirect,Using Machine Learning to Identify Adverse Drug Effects Posing Increased Risk to Women,https://api.elsevier.com/content/abstract/scopus_id/85102228908,"Adverse drug reactions are the fourth leading cause of death in the US. Although women take longer to metabolize medications and experience twice the risk of developing adverse reactions compared with men, these sex differences are not comprehensively understood. Real-world clinical data provide an opportunity to estimate safety effects in otherwise understudied populations, i.e., women. These data, however, are subject to confounding biases and correlated covariates. We present AwareDX, a pharmacovigilance algorithm that leverages advances in machine learning to predict sex risks. Our algorithm mitigates these biases and quantifies the differential risk of a drug causing an adverse event in either men or women. AwareDX demonstrates high precision during validation against clinical literature and pharmacogenetic mechanisms. We present a resource of 20,817 adverse drug effects posing sex-specific risks. AwareDX, and this resource, present an opportunity to minimize adverse events by tailoring drug prescription and dosage to sex.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.nucengdes.2020.110817,Journal,Nuclear Engineering and Design,scopus,2020-10-01,sciencedirect,Machine learning enabled advanced manufacturing in nuclear engineering applications,https://api.elsevier.com/content/abstract/scopus_id/85089553568,"Advanced manufacturing has gained tremendous interest in both research and industry in the past few years. Over nearly the same period of time, machine learning (ML) has made phenomenal advancements, finding its way into many aspects of manufacturing. For the nuclear engineering field, the adoption of advanced manufacturing is a compelling argument due to the ambitious challenges the field faces. The combination of advanced manufacturing with ML holds great potential in the nuclear engineering field, and even further development is needed to accelerate their deployment towards real-world applications. This review paper seeks to detail several key aspects of ML enabled advanced manufacturing that are used or could prove useful to nuclear applications ranging from radiation detector materials to reactor parts fabrication. The applications covered here include new material extrapolation, manufacturing defect detection, and additive manufacturing parameters’ optimization.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ohx.2020.e00131,Journal,HardwareX,scopus,2020-10-01,sciencedirect,Partially RepRapable automated open source bag valve mask-based ventilator,https://api.elsevier.com/content/abstract/scopus_id/85089470505,"This study describes the development of a simple and easy-to-build portable automated bag valve mask (BVM) compression system, which, during acute shortages and supply chain disruptions can serve as a temporary emergency ventilator. The resuscitation system is based on the Arduino controller with a real-time operating system installed on a largely RepRap 3-D printable parametric component-based structure. The cost of the materials for the system is under $170, which makes it affordable for replication by makers around the world. The device provides a controlled breathing mode with tidal volumes from 100 to 800 mL, breathing rates from 5 to 40 breaths/minute, and inspiratory-to-expiratory ratio from 1:1 to 1:4. The system is designed for reliability and scalability of measurement circuits through the use of the serial peripheral interface and has the ability to connect additional hardware due to the object-oriented algorithmic approach. Experimental results after testing on an artificial lung for peak inspiratory pressure (PIP), respiratory rate (RR), positive end-expiratory pressure (PEEP), tidal volume, proximal pressure, and lung pressure demonstrate repeatability and accuracy exceeding human capabilities in BVM-based manual ventilation. Future work is necessary to further develop and test the system to make it acceptable for deployment outside of emergencies such as with COVID-19 pandemic in clinical environments, however, the nature of the design is such that desired features are relatively easy to add using protocols and parametric design files provided.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cbpa.2020.06.002,Journal,Current Opinion in Chemical Biology,scopus,2020-10-01,sciencedirect,Sequencing enabling design and learning in synthetic biology,https://api.elsevier.com/content/abstract/scopus_id/85089023322,"The ability to read and quantify nucleic acids such as DNA and RNA using sequencing technologies has revolutionized our understanding of life. With the emergence of synthetic biology, these tools are now being put to work in new ways — enabling de novo biological design. Here, we show how sequencing is supporting the creation of a new wave of biological parts and systems, as well as providing the vast data sets needed for the machine learning of design rules for predictive bioengineering. However, we believe this is only the tip of the iceberg and end by providing an outlook on recent advances that will likely broaden the role of sequencing in synthetic biology and its deployment in real-world environments.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.berh.2020.101559,Journal,Best Practice and Research: Clinical Rheumatology,scopus,2020-10-01,sciencedirect,Innovations to improve access to musculoskeletal care,https://api.elsevier.com/content/abstract/scopus_id/85088788188,"Innovation is a form of realising a new way of doing something, often ignoring traditional wisdom, in order to meet new challenges. Globally, particularly in emerging economies, the high burden of musculoskeletal conditions and their contribution to multimorbidity continue to rise, as does the gap for services to deliver essential care. There is a growing need to find solutions to this challenge and deliver person-centred and integrated care, wherein empowering patients with the capacity for self-management is critical. Whilst there is an abundance of information available online to support consumer education, the number of sources for credible medical information is diluted by uninformed anecdotal social media solutions. Even with the provision of high-quality information, behavioural change does not necessarily follow, and more robust educational approaches are required.
                  In this chapter, we examine innovation, its management and the strategic directions required to improve musculoskeletal healthcare at macro (policy), meso (service delivery) and micro (clinical practice) levels. We discuss the critical role of consumer agency (patients and their families/carers) in driving innovation and the need to leverage this through empowerment by education.
                  We provide a snapshot of real-world examples of innovative practices including capacity building in consumer and interprofessional musculoskeletal education and practice; recommendations to transform the access and delivery of integrated, person-centred care; and initiatives in musculoskeletal care and implementation of models of care, enabled by digital health solutions including telehealth, remote monitoring, artificial intelligence, blockchain technology and big data. We provide emerging evidence for how innovation can support systems' strengthening and build capacity to support improved access to ‘right’ musculoskeletal care, and explore some of the ways to best manage innovations.
                  We conclude with recommended systematic steps to establish required leadership, collaboration, research, networking, dissemination, implementation and evaluation of future innovations in musculoskeletal health and care.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jobcr.2020.07.015,Journal,Journal of Oral Biology and Craniofacial Research,scopus,2020-10-01,sciencedirect,Present and future of artificial intelligence in dentistry,https://api.elsevier.com/content/abstract/scopus_id/85088647471,"The last decennary has marked as the breakthrough in the advancement of technology with evolution of artificial intelligence, which is rapidly gaining the attention of researchers across the globe. Every field opted artificial intelligence with huge enthusiasm and so the field of dental science is no exception. With huge increases in patient documented information and data this is the need of the hour to use intelligent software to compile and save this data. From the basic step of taking a patient's history to data processing and then to extract the information from the data for diagnosis, artificial intelligence has many applications in dental and medical science. While in no case artificial intelligence can replace the role of a dental surgeon but it is important to be acquainted with the scope to amalgamate this advancement of technology in future for betterment of dental practice.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compeleceng.2020.106766,Journal,Computers and Electrical Engineering,scopus,2020-10-01,sciencedirect,Imputation of Missing Values Affecting the Software Performance of Component-based Robots,https://api.elsevier.com/content/abstract/scopus_id/85088022516,"Intelligent robots are foreseen as a technology that would be soon present in most public and private environments. In order to increase the trust of humans, robotic systems must be reliable while both response and down times are minimized. In keeping with this idea, present paper proposes the application of machine learning (regression models more precisely) to preprocess data in order to improve the detection of failures. Such failures deeply affect the performance of the software components embedded in human-interacting robots. To address one of the most common problems of real-life datasets (missing values), some traditional (such as linear regression) as well as innovative (decision tree and neural network) models are applied. The aim is to impute missing values with minimum error in order to improve the quality of data and consequently maximize the failure-detection rate. Experiments are run on a public and up-to-date dataset and the obtained results support the viability of the proposed models.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijleo.2020.165205,Journal,Optik,scopus,2020-10-01,sciencedirect,Pattern recognition based on pulse scanning imaging and convolutional neural network for vibrational events in Φ-OTDR,https://api.elsevier.com/content/abstract/scopus_id/85087790249,"Feature extraction method of a phase-sensitive optical time-domain reflectometer distributed optical fiber vibration detection system requires a priori knowledge. A lack of feature evaluation methods leads to a low pattern recognition accuracy. Traditional pattern recognition methods cannot be widely applied. This paper presents the implementation of a deep learning-based method to identify vibration signal categories. First, the vibration signal was reconstructed in the time and space domain, which is regarded as a pulse scanning image. Secondly, moving average was used to reduce noise, and seeking the signal envelope surface as an image sample. Finally, the image sample was inputted into the trained convolutional neural network (CNN) to obtain recognition results. Experiments showed that the phase-sensitive optical time-domain reflectometer pulse scanning imaging pattern recognition method based on deep learning proposed in this paper improved recognition accuracy while ensuring recognition efficiency. The algorithm is easy to implement and apply and satisfies the requirements of real-time online monitoring.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ast.2020.105953,Journal,Aerospace Science and Technology,scopus,2020-10-01,sciencedirect,A reliable data-driven model for Ablative Pulsed Plasma Thruster,https://api.elsevier.com/content/abstract/scopus_id/85087284442,"Ablative Pulsed Plasma Thrusters (APPTs) are high specific impulse electric space propulsion system, but a reliable model equivalent of the experimental model is still unavailable. In this paper, a reliable model is developed based on APPT experimental data by using Machine Learning (ML) ecosystem. The goals of this study are to justify the accuracy and reliability of the newly built APPT model with the existing experimental and simulation model. For four sets of operating conditions, 600 experimental and simulation test operations are done. The experimental voltages and currents are measured with a high-voltage probe and a Rogowski coil, respectively. The simulation voltages and currents are gathered by running the respective simulation program. Comparison results show that the newly built APPT model has better accuracy and reliability than the simulated APPT model as compared to real APPT used in the experiment. This data-driven approach provides a novel way of designing a reliable alternative model of physical APPTs.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mcp.2020.101619,Journal,Molecular and Cellular Probes,scopus,2020-10-01,sciencedirect,Multiplex real-time SYBR Green I PCR assays for simultaneous detection of 15 common enteric pathogens in stool samples,https://api.elsevier.com/content/abstract/scopus_id/85087216854,"Diarrheal diseases account for more than 50% of foodborne diseases worldwide, the majority of which occur in infants and young children. The traditional bacterial detection method is complex and time-consuming; therefore, it is necessary to establish a rapid and convenient detection method that can detect multiple pathogens simultaneously. In this study, we developed a set of five multiplex real-time SYBR Green I PCR assays to simultaneously detect 15 common enteric pathogens based on the Homo-Tag Assisted Non-Dimer system. These assays effectively reduced primer-dimer formation and improved the stability, uniformity, and amplification efficiency of multiplex PCR. The detection limit of the multiplex SYBR Green I PCR system was approximately 104–106 CFU/mL for stool specimens. Furthermore, we vitrified heat-unstable components on the cap of a reaction tube, showing that Taq DNA polymerase, dNTPs, primers, and SYBR Green I remained stable at 25 °C. In summary, we developed multiplex SYBR Green I PCR assays that can simultaneously detect 15 enteric pathogens. This method is comprehensive, rapid, inexpensive, accurate, and simple and displays high specificity.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ast.2020.105965,Journal,Aerospace Science and Technology,scopus,2020-10-01,sciencedirect,Towards a PDE-based large-scale decentralized solution for path planning of UAVs in shared airspace,https://api.elsevier.com/content/abstract/scopus_id/85086828428,"Recently, there has been a tremendous increase of interest in utilizing Unmanned Aerial Vehicles (UAVs) for a number of civilian applications. With this increased interest, it is imperative that these UAVs are able to operate in shared airspace for enhanced efficiency. Multi-UAV systems are inherently safety-critical systems, which means that safety guarantees must be made to ensure no undesirable configurations, such as collisions, occur. This paper proposes a decentralized method based on a Partial Differential Equation (PDE) to generate collision-free 3D trajectories for multiple UAVs operating in a shared airspace. This method exploits the dynamical properties of multi-phase fluids flowing through a porous medium by modeling the porosity values as a function of the risk of collision. To highlight the feasibility for on-board implementation, we propose propose a machine learning technique for obtaining computationally efficient solutions of the PDE describing flow movements in porous medium. This method has been compared via a simulation study to two other path planning strategies, centralized and sequential planning, and the advantages of this method are presented. Furthermore, results from an experiment using three UAVs have been presented to demonstrate the applicability of the proposed method to real-world implementation.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2020.06.004,Journal,Information Sciences,scopus,2020-10-01,sciencedirect,Finding dense subgraphs with maximum weighted triangle density,https://api.elsevier.com/content/abstract/scopus_id/85086798490,"Finding dense subgraphs from sparse graphs is a fundamental graph mining task that has been applied in various domains, such as social networks, biology, and spam detection. Because the standard formulation of this problem is difficult to solve owing to connections with the Maximum Clique Problem, some tractable formulations have been proposed. These formulations find a dense subgraph by optimizing some density function, such as the degree density or triangle density. In this paper, we introduce the weighted k-clique density, a novel formulation for dense subgraph extraction. We show that the problem of maximizing weighted k-clique density can be solved optimally in polynomial time by solving a series of minimum cut problems. For scalability, we also propose a more efficient greedy algorithm with performance guarantee. The experimental results on real-world network datasets show that, compared with established state-of-the-art algorithms, the proposed algorithm can find a much denser subgraph in terms of edge density and triangle density.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmi.2020.02.006,Journal,Clinical Microbiology and Infection,scopus,2020-10-01,sciencedirect,Machine learning in the clinical microbiology laboratory: has the time come for routine practice?,https://api.elsevier.com/content/abstract/scopus_id/85081582683,"Background
                  Machine learning (ML) allows the analysis of complex and large data sets and has the potential to improve health care. The clinical microbiology laboratory, at the interface of clinical practice and diagnostics, is of special interest for the development of ML systems.
               
                  Aims
                  This narrative review aims to explore the current use of ML In clinical microbiology.
               
                  Sources
                  References for this review were identified through searches of MEDLINE/PubMed, EMBASE, Google Scholar, biorXiv, arXiV, ACM Digital Library and IEEE Xplore Digital Library up to November 2019.
               
                  Content
                  We found 97 ML systems aiming to assist clinical microbiologists. Overall, 82 ML systems (85%) targeted bacterial infections, 11 (11%) parasitic infections, nine (9%) viral infections and three (3%) fungal infections. Forty ML systems (41%) focused on microorganism detection, identification and quantification, 36 (37%) evaluated antimicrobial susceptibility, and 21 (22%) targeted the diagnosis, disease classification and prediction of clinical outcomes. The ML systems used very diverse data sources: 21 (22%) used genomic data of microorganisms, 19 (20%) microbiota data obtained by metagenomic sequencing, 19 (20%) analysed microscopic images, 17 (18%) spectroscopy data, eight (8%) targeted gene sequencing, six (6%) volatile organic compounds, four (4%) photographs of bacterial colonies, four (4%) transcriptome data, three (3%) protein structure, and three (3%) clinical data. Most systems used data from high-income countries (n = 71, 73%) but a significant number used data from low- and middle-income countries (n = 36, 37%). Performance measures were reported for the 97 ML systems, but no article described their use in clinical practice or reported impact on processes or clinical outcomes.
               
                  Implications
                  In clinical microbiology, ML has been used with various data sources and diverse practical applications. The evaluation and implementation processes represent the main gap in existing ML systems, requiring a focus on their interpretability and potential integration into real-world settings.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jaim.2018.02.140,Journal,Journal of Ayurveda and Integrative Medicine,scopus,2020-10-01,sciencedirect,Effect of seeds of Entada phaseoloides on chronic restrain stress in mice,https://api.elsevier.com/content/abstract/scopus_id/85059584549,"Background
                  
                     Entada phaseoloides is a well-known medicinal plant traditionally used in Ayurvedic medicine for centuries.
               
                  Objective
                  To evaluate the anti-stress activity of seeds of E. phaseoloides in endoplasmic reticulum stress during chronic restrain stress in mice, based on our preliminary screening.
               
                  Materials and Methods
                  Mice (n = 6/group) were restrained daily for 6 h in 50 ml polystyrene tubes for 28 days. Methanolic extract of E. phaseoloides (MEEP) (100 and 200 mg/kg, p.o.) and standard drug, imipramine (10 mg/kg i.p.) were administered daily 45 min prior to restrain from day 22–28. Then, forced swim test (FST) was performed to assess despair behavior. Lipid peroxidation (LPO) and antioxidant enzymes Reduced glutathione (GSH), Superoxide dismutase (SOD) were measured in the hippocampus of mice. 78 kDa Glucose-regulated Protein, 94 kDa Glucose-regulated Protein, C/EBP homologous protein, Caspase-12 expression were quantified by Real Time PCR.
               
                  Results
                  MEEP significantly reduced the immobility time in FST (P < 0.001). Significant reduction of LPO (P < 0.05) level and restored antioxidant enzymes viz. GSH (P < 0.001) and SOD towards vehicle control group were observed. Down-regulation of genes GRP 78, GRP 94 (P < 0.001), CHOP and Caspase-12 (P < 0.001) as compared to the chronic restrain stress group was evident, which were upregulated following treatment. Isolation of the active components of the seeds revealed the presence of Oleic acid (1), Entadamide A (2), Entadamide A-beta-d-glucopyranoside (3) and 1-O-protocatechuoyl-β-d-glucose.
               
                  Conclusion
                  MEEP altered endoplasmic reticulum stress in chronic restrain stressed mice; however, as an antidepressant it showed a weaker response.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100093,Journal,Patterns,scopus,2020-09-11,sciencedirect,Uncovering Effective Explanations for Interactive Genomic Data Analysis,https://api.elsevier.com/content/abstract/scopus_id/85102976970,"Better tools are needed to enable researchers to quickly identify and explore effective and interpretable feature-based explanations for discriminating multi-class genomic datasets, e.g., healthy versus diseased samples. We develop an interactive exploration tool, GENVISAGE, which rapidly discovers the most discriminative feature pairs that separate two classes of genomic objects and then displays the corresponding visualizations. Since quickly finding top feature pairs is computationally challenging, especially for large numbers of objects and features, we propose a suite of optimizations to make GENVISAGE responsive at scale and demonstrate that our optimizations lead to a 400× speedup over competitive baselines for multiple biological datasets. We apply our rapid and interpretable tool to identify literature-supported pairs of genes whose transcriptomic responses significantly discriminate several chemotherapy drug treatments. With its generalizable optimizations and framework, GENVISAGE opens up real-time feature-based explanation generation to data from massive sequencing efforts, as well as many other scientific domains.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100083,Journal,Patterns,scopus,2020-09-11,sciencedirect,"The Veterans Affairs Precision Oncology Data Repository, a Clinical, Genomic, and Imaging Research Database",https://api.elsevier.com/content/abstract/scopus_id/85102968026,"The Veterans Affairs Precision Oncology Data Repository (VA-PODR) is a large, nationwide repository of de-identified data on patients diagnosed with cancer at the Department of Veterans Affairs (VA). Data include longitudinal clinical data from the VA's nationwide electronic health record system and the VA Central Cancer Registry, targeted tumor sequencing data, and medical imaging data including computed tomography (CT) scans and pathology slides. A subset of the repository is available at the Genomic Data Commons (GDC) and The Cancer Imaging Archive (TCIA), and the full repository is available through the Veterans Precision Oncology Data Commons (VPODC). By releasing this de-identified dataset, we aim to advance Veterans' health care through enabling translational research on the Veteran population by a wide variety of researchers.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100057,Journal,Patterns,scopus,2020-09-11,sciencedirect,Explaining the Genetic Causality for Complex Phenotype via Deep Association Kernel Learning,https://api.elsevier.com/content/abstract/scopus_id/85102966019,"The genetic effect explains the causality from genetic mutations to the development of complex diseases. Existing genome-wide association study (GWAS) approaches are always built under a linear assumption, restricting their generalization in dissecting complicated causality such as the recessive genetic effect. Therefore, a sophisticated and general GWAS model that can work with different types of genetic effects is highly desired. Here, we introduce a deep association kernel learning (DAK) model to enable automatic causal genotype encoding for GWAS at pathway level. DAK can detect both common and rare variants with complicated genetic effects where existing approaches fail. When applied to four real-world GWAS datasets including cancers and schizophrenia, our DAK discovered potential casual pathways, including the association between dilated cardiomyopathy pathway and schizophrenia.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rser.2020.109920,Journal,Renewable and Sustainable Energy Reviews,scopus,2020-09-01,sciencedirect,Virtual testbed for model predictive control development in district cooling systems,https://api.elsevier.com/content/abstract/scopus_id/85086021217,"Recently, with increasing cooling demands, district cooling has assumed an important role as it is more efficient than stand-alone cooling systems. District cooling reduces the environmental impact and promotes the use of renewable sources. Earlier studies to optimise the production plants of district cooling systems were focused primarily on plants with compressor chillers and thermal energy storage devices. Although absorption chillers are crucial for integrating renewable sources into these systems, very few studies have considered them from the cooling perspective. In this regard, this paper presents the progress and results of the implementation of a virtual testbed based on a digital twin of a district cooling production plant with both compressor and absorption chillers. The aim of this study, carried out within the framework of INDIGO, a European Union-funded project, was (i) to develop a reliable model that can be used in a model predictive controller and (ii) to simulate the plant using this controller. The production plant components, which included absorption and compressor chillers, as well as cooling towers, were built using the equation-based Modelica programming language, and were calibrated using information from the manufacturer, together with real operation data. The remainder of the plant was modelled in Python. To integrate the Modelica models into the Python environment, a combination of machine learning techniques and state-space representation models was used. With these techniques, models with a high computational speed were obtained, which were suitable for real-time applications. These models were then used to build a model predictive control for the production plant to minimise the primary energy usage. The improvements in the control and the resultant energy savings achieved were compared with a baseline case working on a standard cascade control. Energy savings up to 50% were obtained in the simulation-based experiments.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mineng.2020.106457,Journal,Minerals Engineering,scopus,2020-09-01,sciencedirect,Effects of process history on the surface morphology of uranium ore concentrates extracted from ore,https://api.elsevier.com/content/abstract/scopus_id/85085988966,"The effects of process history on the particle morphology of uranium ore concentrates (UOC) synthesized from natural uranium ores were investigated. A purified UOC was extracted from a uranium-rich ore by sulfuric acid leaching and purified by two commercial solvent extraction processes: the Dapex process using di-(2-ethylhexyl) phosphoric acid (DEHPA), and the Amex process using Alamine® 336. The UOC from either route was precipitated from its respective strip solution by ammonia and calcined. Powder X-ray diffraction (P-XRD) was used to confirm the crystallography of the UOC; while Rietveld refinement was performed for quantification of U oxide phase composition. Inductively coupled plasma - mass spectrometry (ICP-MS) was used to quantify impurity concentrations of the calcined material. As expected, different impurities were present due to processing via the Dapex and Amex process. To further correlate the impurities to the process history, particle morphology was quantified from scanning electron microscopy (SEM) micrographs using the MAMA segmentation software. In addition, a deep neural network was trained on the SEM images to distinguish between process histories. The results provide a real-world representation of how particle morphology will likely change based on processing at commercial facilities as opposed to high purity material experiments in a laboratory setting.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijmedinf.2020.104176,Journal,International Journal of Medical Informatics,scopus,2020-09-01,sciencedirect,The development an artificial intelligence algorithm for early sepsis diagnosis in the intensive care unit,https://api.elsevier.com/content/abstract/scopus_id/85085579350,"Background
                  Severe sepsis and septic shock are still the leading causes of death in Intensive Care Units (ICUs), and timely diagnosis is crucial for treatment outcomes. The progression of electronic medical records (EMR) offers the possibility of storing a large quantity of clinical data that can facilitate the development of artificial intelligence (AI) in medicine. However, several difficulties, such as poor structure and heterogenicity of the raw EMR data, are encountered when introducing AI with ICU data. Labor-intensive work, including manual data entry, personal medical records sorting, and laboratory results interpretation may hinder the progress of AI. In this article, we introduce the developing of an AI algorithm designed for sepsis diagnosis using pre-selected features; and compare the performance of the AI algorithm with SOFA score based diagnostic method.
               
                  Materials and methods
                  This is a prospective open-label cohort study. A specialized EMR, named TED_ICU, was implemented for continuous data recording. One hundred six clinical features relevant to sepsis diagnosis were selected prospectively. A labeling work to allocate SEPSIS or NON_SEPSIS status for each ICU patient was performed by the in-charge intensivist according to SEPSIS-3 criteria, along with the automatic recording of selected features every day by TED_ICU. Afterward, we use de-identified data to develop the AI algorithm. Several machine learning methods were evaluated using 5-fold cross-validation, and XGBoost, a decision-tree based algorithm was adopted for our AI algorithm development due to best performance.
               
                  Results
                  The study was conducted between August 2018 and December 2018 for the first stage of analysis. We collected 1588 instances, including 444 SEPSIS and 1144 NON-SEPSIS, from 434 patients. The 434 patients included 259 (59.6%) male patients and 175 female patients. The mean age was 67.6-year-old, and the mean APACHE II score was 13.8. The SEPSIS cohort had a higher SOFA score and increased use of organ support treatment. The AI algorithm was developed with a shuffle method using 80% of the instances for training and 20% for testing. The established AI algorithm achieved the following: accuracy = 82% ± 1%; sensitivity = 65% ± 5%; specificity = 88% ± 2%; precision = 67% ± 3%; and F1 = 0.66 ± 0.02. The area under the receiver operating characteristic curve (AUROC) was approximately 0.89. The SOFA score was used on the same 1588 instances for sepsis diagnosis, and the result was inferior to our AI algorithm (AUROC = 0.596).
               
                  Conclusion
                  Using real-time data, collected by EMR, from the ICU daily practice, our AI algorithm established with pre-selected features and XGBoost can provide a timely diagnosis of sepsis with an accuracy greater than 80%. AI algorithm also outperforms the SOFA score in sepsis diagnosis and exhibits practicality as clinicians can deploy appropriate treatment earlier. The early and precise response of this AI algorithm will result in cost reduction, outcome improvement, and benefit for healthcare systems, medical staff, and patients as well.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compind.2020.103226,Journal,Computers in Industry,scopus,2020-09-01,sciencedirect,Perspective on holonic manufacturing systems: PROSA becomes ARTI,https://api.elsevier.com/content/abstract/scopus_id/85085261123,"Looking back at 30 years of research into holonic manufacturing systems, these explorations made a lasting scientific contribution to the overall architecture of intelligent manufacturing systems. Most notably, holonic architectures are defined in terms of their world-of-interest (Van Brussel et al., 1998). They do not have an information layer, a communication layer, etc. Instead, they have components that relate to real-world assets (e.g. machine tools) and activities (e.g. assembly). And, they mirror and track the structure of their world-of-interest, which allows them to scale and adapt accordingly.
                  This research has wandered around, at times learning from its mistakes, and progressively carved out an invariant structure while it translated and applied scientific insights from complex-adaptive systems theory (e.g. autocatalytic sets) and from bounded rationality (e.g. holons). This paper presents and discusses the outcome of these research efforts.
                  At the top level, the holonic structure distinguishes intelligent beings (or digital twins) from intelligent agents. These digital twins inherit the consistency from reality, which they mirror. They are intelligent beings when they reflect what exists in the world without imposing artificial limitations in this reality. Consequently, a conflict with a digital twin is a conflict with reality.
                  In contrast, intelligent agents typically transform NP-hard challenges into computations with low-polynomial complexity. Unavoidably, this involves arbitrariness (e.g. don’t care choices). Likewise, relying on case-specific properties, to ensure an outcome in polynomial time, usually renders the validity of an agent’s choices both short-lived and situation-dependent. Here, intelligent agents create conflicts by imposing limitations of their own making in their world-of-interest.
                  Real-world smart systems are aggregates comprising both intelligent beings and intelligent agents. They are performers. Inside these performers, digital twins may constitute the foundations, supporting walls, support beams and pillars because these intelligent beings are protected by their real-world counterpart. Further refining the top-level of this architecture, a holonic structure enables these digital twins to shadow their real-world counterpart whenever it changes, adapts and evolves.
                  In contrast, the artificial limitations, imposed by the intelligent agents, cannot be allowed to build up inertia, which would hamper the undoing of arbitrary or case-specific limitations. To this end, performers explicitly manage the rights over their assets. Revoking such rights from a limitation-imposing agent will free the assets. This will be at the cost of reduced services from the agent. When other service providers rely on this agent, their services may be affected as well; that’s how the inertia builds up and how harmful legacy is created. Thus, the services of digital twins are to be preferred over the services of an intelligent agent by developers of holonic manufacturing systems.
                  Finally, digital twins corresponding to the decision making in the world-of-interest (a non-physical asset) allow to mirror the world-of-interest in a predictive mode (in addition to track and trace). It allows to generate short-term forecasts while preserving the benefits of intelligent beings. These twins are the intentions of the decision-making intelligent agents. Evidently, when intentions change, the forecasts needs to be regenerated (i.e. tracking the corresponding reality by the twin). This advanced feature can be deployed in a number of configurations (cf. annex).",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2020.04.018,Journal,Future Generation Computer Systems,scopus,2020-09-01,sciencedirect,Software-Defined Network for End-to-end Networked Science at the Exascale,https://api.elsevier.com/content/abstract/scopus_id/85083299223,"Domain science applications and workflow processes are currently forced to view the network as an opaque infrastructure into which they inject data and hope that it emerges at the destination with an acceptable Quality of Experience. There is little ability for applications to interact with the network to exchange information, negotiate performance parameters, discover expected performance metrics, or receive status/troubleshooting information in real time. The work presented here is motivated by a vision for a new smart network and smart application ecosystem that will provide a more deterministic and interactive environment for domain science workflows. The Software-Defined Network for End-to-end Networked Science at Exascale (SENSE) system includes a model-based architecture, implementation, and deployment which enables automated end-to-end network service instantiation across administrative domains. An intent based interface allows applications to express their high-level service requirements, an intelligent orchestrator and resource control systems allow for custom tailoring of scalability and real-time responsiveness based on individual application and infrastructure operator requirements. This allows the science applications to manage the network as a first-class schedulable resource as is the current practice for instruments, compute, and storage systems. Deployment and experiments on production networks and testbeds have validated SENSE functions and performance. Emulation based testing verified the scalability needed to support research and education infrastructures. Key contributions of this work include an architecture definition, reference implementation, and deployment. This provides the basis for further innovation of smart network services to accelerate scientific discovery in the era of big data, cloud computing, machine learning and artificial intelligence.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cpc.2020.107275,Journal,Computer Physics Communications,scopus,2020-09-01,sciencedirect,freud: A software suite for high throughput analysis of particle simulation data,https://api.elsevier.com/content/abstract/scopus_id/85082555873,"The freud Python package is a library for analyzing simulation data. Written with modern simulation and data analysis workflows in mind, freud provides a Python interface to fast, parallelized C++ routines that run efficiently on laptops, workstations, and supercomputing clusters. The package provides the core tools for finding particle neighbors in periodic systems, and offers a uniform API to a wide variety of methods implemented using these tools. As such, freud users can access standard methods such as the radial distribution function as well as newer, more specialized methods such as the potential of mean force and torque and local crystal environment analysis with equal ease. Rather than providing its own trajectory data structure, freud operates either directly on NumPy arrays or on trajectory data structures provided by other Python packages. This design allows freud to transparently interface with many trajectory file formats by leveraging the file parsing abilities of other trajectory management tools. By remaining agnostic to its data source, freud is suitable for analyzing any particle simulation, regardless of the original data representation or simulation method. When used for on-the-fly analysis in conjunction with scriptable simulation software such as HOOMD-blue, freud enables smart simulations that adapt to the current state of the system, allowing users to study phenomena such as nucleation and growth.
               
                  Program summary
                  
                     Program Title: 
                     freud
                  
                  
                     Program Files doi: 
                     http://dx.doi.org/10.17632/v7wmv9xcct.1
                  
                  
                     Licensing provisions: BSD 3-Clause
                  
                     Programming language: Python, C++
                  
                     Nature of problem: Simulations of coarse-grained, nano-scale, and colloidal particle systems typically require analyses specialized to a particular system. Certain more standardized techniques – including correlation functions, order parameters, and clustering – are computationally intensive tasks that must be carefully implemented to scale to the larger systems common in modern simulations.
                  
                     Solution method: 
                     freud performs a wide variety of particle system analyses, offering a Python API that interfaces with many other tools in computational molecular sciences via NumPy array inputs and outputs. The algorithms in freud leverage parallelized C++ to scale to large systems and enable real-time analysis. The library’s broad set of features encode few assumptions compared to other analysis packages, enabling analysis of a broader class of data ranging from biomolecular simulations to colloidal experiments.
                  
                     Additional comments including restrictions and unusual features:
                  
                  1. freud provides very fast parallel implementations of standard analysis methods like RDFs and correlation functions.
                  2. freud includes the reference implementation for the potential of mean force and torque (PMFT).
                  3. freud provides various novel methods for characterizing particle environments, including the calculation of descriptors useful for machine learning. The source code is hosted on GitHub (https://github.com/glotzerlab/freud), and documentation is available online (https://freud.readthedocs.io/). The package may be installed via pip install freud-analysis or conda install -c conda-forge freud.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scitotenv.2020.139158,Journal,Science of the Total Environment,scopus,2020-08-20,sciencedirect,Development of a decision support system for the selection of wastewater treatment technologies,https://api.elsevier.com/content/abstract/scopus_id/85084373810,"Multiple factors including technical, social, economic, regulatory, governmental, and environmental add complexity in the process of selecting a suitable wastewater treatment technology. To overcome this issue, this paper aims to propose a decision support system (DSS) for the selection of wastewater treatment technologies. The proposed system has been developed using a detailed review of the state-of-the-art in wastewater treatment, implemented using Microsoft Visual Studio 2010 and validated through real-time case studies. The system is categorized into four treatment levels based on wastewater complexity and the required degree of treatment. These include preliminary, primary, secondary, and tertiary treatment. Based on the identified treatment levels, the proposed system suggests using any physical, biological, chemical, or hybrid treatment process. The developed DSS will aid the selection of suitable wastewater treatment technology from a set of alternatives while keeping user constraints, conflicting requirements, and prevailing conditions under consideration. Moreover, the system is capable to customize the treatment assembly at the planning stage with minimized costs, eliminate mistakes at the planning and design stage, facilitate decision making by narrowing down the alternative solution as per user requirements and prevailing conditions, incorporate customer demand, and promote sustainable development.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2020.02.104,Journal,Neurocomputing,scopus,2020-08-18,sciencedirect,An overview of recent multi-view clustering,https://api.elsevier.com/content/abstract/scopus_id/85083344834,"With the widespread deployment of sensors and the Internet-of-Things, multi-view data has become more common and publicly available. Compared to traditional data that describes objects from single perspective, multi-view data is semantically richer, more useful, however more complex. Since traditional clustering algorithms cannot handle such data, multi-view clustering has become a research hotspot. In this paper, we review some of the latest multi-view clustering algorithms, which are reasonably divided into three categories. To evaluate their performance, we perform extensive experiments on seven real-world data sets. Three mainstream metrics are used, including clustering accuracy, normalized mutual information and purity. Based on the experimental results and a large number of literature reading, we also discuss existing problems in current multi-view clustering and point out possible research directions in the future. This research provides some insights for researchers in related fields and may further promote the development of multi-view clustering algorithms.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100073,Journal,Patterns,scopus,2020-08-14,sciencedirect,dtoolAI: Reproducibility for Deep Learning,https://api.elsevier.com/content/abstract/scopus_id/85102966352,"Deep learning, a set of approaches using artificial neural networks, has generated rapid recent advancements in machine learning. Deep learning does, however, have the potential to reduce the reproducibility of scientific results. Model outputs are critically dependent on the data and processing approach used to initially generate the model, but this provenance information is usually lost during model training. To avoid a future reproducibility crisis, we need to improve our deep-learning model management. The FAIR principles for data stewardship and software/workflow implementation give excellent high-level guidance on ensuring effective reuse of data and software. We suggest some specific guidelines for the generation and use of deep-learning models in science and explain how these relate to the FAIR principles. We then present dtoolAI, a Python package that we have developed to implement these guidelines. The package implements automatic capture of provenance information during model training and simplifies model distribution.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100074,Journal,Patterns,scopus,2020-08-14,sciencedirect,Machine-Learning Approaches in COVID-19 Survival Analysis and Discharge-Time Likelihood Prediction Using Clinical Data,https://api.elsevier.com/content/abstract/scopus_id/85092796371,"As a highly contagious respiratory disease, COVID-19 has yielded high mortality rates since its emergence in December 2019. As the number of COVID-19 cases soars in epicenters, health officials are warning about the possibility of the designated treatment centers being overwhelmed by coronavirus patients. In this study, several computational techniques are implemented to analyze the survival characteristics of 1,182 patients. The computational results agree with the outcome reported in early clinical reports released for a group of patients from China that confirmed a higher mortality rate in men compared with women and in older age groups. The discharge-time prediction of COVID-19 patients was also evaluated using different machine-learning and statistical analysis methods. The results indicate that the Gradient Boosting survival model outperforms other models for patient survival prediction in this study. This research study is aimed to help health officials make more educated decisions during the outbreak.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jclepro.2020.121426,Journal,Journal of Cleaner Production,scopus,2020-08-10,sciencedirect,A sentiment reporting framework for major city events: Case study on the China-United States trade war,https://api.elsevier.com/content/abstract/scopus_id/85084032594,"Smart cities are conceptualized as a vehicle for sustainable urban development and a means to deliver high quality of life for residents. One of the core functions of a smart city consists in the continuous monitoring of events, assets and people and the use of this information and intelligence for the streamlining of the city’s operations. Public opinion represents one type of intelligence of particular importance and value. By monitoring public opinion, governments seek to understand prevalent views about the current events and policies, as well as identify extreme views and trends that may represent problematic situations or precursors to violent actions. Ultimately, maintaining a constant awareness of public opinion means that authorities can better assess and predict public reactions in relation to ongoing events, and thus take appropriate actions to maintain public safety. Due to the popular use of social media to express sentiments and emotions about current events, social media content analysis has been contemplated as a promising solution to capture public opinion. However, existing approaches take a coarse-grained retrospective approach to social media content analysis. Furthermore, those approaches suffer from the lack of scalability and efficiency, as they necessitate the collection and analysis of large volumes of social media content (often millions of posts), to come up with relevant conclusions. In this work, we address those limitations by proposing a novel framework for the real-time monitoring of public opinion. To ensure efficiency and scalability, our framework focuses on the analysis of high impact social media content generated by opinion leaders and their followers as means to offer in-depth insights and sentiment intelligence reports about events, as they are occurring in real time. The proposed framework was implemented and tested on data harvested from 52 economic opinion leaders, with a focus on the China-US trade war as case study. The results show that the convolutional neural network (CNN) classifier used for sentiment analysis yielded a classification accuracy of 86% when differentiating between four sentiment categories: Support, strong support, dissent, and strong dissent. The Support Vector Machine (SVM) classifier employed to perform in-depth emotional analysis attained an accuracy of 82% when differentiating between five emotions: Angry, depressed, excited, happy, and worried. Unlike existing retrospective social media analysis approaches that require the analysis of millions of posts, our approach focuses on the analysis of high-impact social media content in real-time, thus constituting an efficient, sustainable, and timely solution to public opinion monitoring.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S2352-3018(20)30190-9,Journal,The Lancet HIV,scopus,2020-08-01,sciencedirect,Modern diagnostic technologies for HIV,https://api.elsevier.com/content/abstract/scopus_id/85088944280,"Novel diagnostic technologies, including nanotechnology, microfluidics, -omics science, next-generation sequencing, genomics big data, and machine learning, could contribute to meeting the UNAIDS 95-95-95 targets to end the HIV epidemic by 2030. Novel technologies include multiplexed technologies (including biomarker-based point-of-care tests and molecular platform technologies), biomarker-based combination antibody and antigen technologies, dried-blood-spot testing, and self-testing. Although biomarker-based rapid tests, in particular antibody-based tests, have dominated HIV diagnostics since the development of the first HIV test in the mid-1980s, targets such as nucleic acids and genes are now used in nanomedicine, biosensors, microfluidics, and -omics to enable early diagnosis of HIV. These novel technologies show promise as they are associated with ease of use, high diagnostic accuracy, rapid detection, and the ability to detect HIV-specific markers. Additional clinical and implementation research is needed to generate evidence for use of novel technologies and a public health approach will be required to address clinical and operational challenges to optimise their global deployment.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.trc.2020.102649,Journal,Transportation Research Part C: Emerging Technologies,scopus,2020-08-01,sciencedirect,Differential variable speed limits control for freeway recurrent bottlenecks via deep actor-critic algorithm,https://api.elsevier.com/content/abstract/scopus_id/85086802562,"Variable speed limit (VSL) control is a flexible way to improve traffic conditions, increase safety, and reduce emissions. There is an emerging trend of using reinforcement learning methods for VSL control. Currently, deep learning is enabling reinforcement learning to develop autonomous control agents for problems that were previously intractable. In this paper, a more effective deep reinforcement learning (DRL) model is developed for differential variable speed limit (DVSL) control, in which dynamic and distinct speed limits among lanes can be imposed. The proposed DRL model uses a novel actor-critic architecture to learn a large number of discrete speed limits in a continuous action space. Different reward signals, such as total travel time, bottleneck speed, emergency braking, and vehicular emissions are used to train the DVSL controller, and a comparison between these reward signals is conducted. The proposed DRL-based DVSL controllers are tested on a freeway with a simulated recurrent bottleneck. The simulation results show that the DRL based DVSL control strategy is able to improve the safety, efficiency and environment-friendliness of the freeway. In order to verify whether the controller generalizes to real world implementation, we also evaluate the generalization of the controllers on environments with different driving behavior attributes. and the robustness of the DRL agent is observed from the results.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compag.2020.105526,Journal,Computers and Electronics in Agriculture,scopus,2020-08-01,sciencedirect,Application of random forest classification to predict daily oviposition events in broiler breeders fed by precision feeding system,https://api.elsevier.com/content/abstract/scopus_id/85085736722,"In group-housed poultry, hormone and environment modulated variability in the processes of follicle maturation and egg formation make it difficult to predict a daily egg-laying event (oviposition). Recording daily egg laying events has required individual cages or expensive technology such as RFID equipped nests or labor intensive trap nests. The current study implemented the random forest classification algorithm to predict oviposition events of 202 free run Ross 708 broiler breeder hens fed by a precision feeding system from week 21 to 55, based on a dataset recording information of all visits to the station. The raw dataset from the precision feeding system was processed for 6 classes of features (34 features in total) in relation to feeding activity and real-time body weight of birds. The dataset of the features was then combined with a corresponding daily individual oviposition record. The processed data were shuffled and separated into 2 subsets: 90% for training, and 10% for testing. Important features were selected using random forest-recursive feature elimination with 5-fold cross-validation, and 28 features were selected to build a random forest classification model. Overall accuracy of the model using the testing samples was 0.8482, and out-of-bag score was 0.8510. Precision (a measure of purity in retrieving) of no egg-laying and egg-laying, recall (a measure of completeness in retrieving) of no egg-laying and egg-laying were 0.8814, 0.8090, 0.8520 and 0.8453, respectively. The Kappa coefficient of the model was 0.6931, indicating substantial agreement (substantial agreement range: 0.61–0.80). This model was able to identify whether a free run broiler breeder laid an egg or not on a certain day during the laying period with around 85% accuracy.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.automatica.2020.109032,Journal,Automatica,scopus,2020-08-01,sciencedirect,Efficient spatio-temporal Gaussian regression via Kalman filtering,https://api.elsevier.com/content/abstract/scopus_id/85084595084,"We study the non-parametric reconstruction of spatio-temporal dynamical processes via Gaussian Processes (GPs) regression from sparse and noisy data. GPs have been mainly applied to spatial regression where they represent one of the most powerful estimation approaches also thanks to their universal representing properties. Their extension to dynamical processes has been instead elusive so far since classical implementations lead to unscalable algorithms or require some sort of approximation. We propose a novel procedure to address this problem by coupling GPs regression and Kalman filtering. In particular, assuming space/time separability of the covariance (kernel) of the process and rational time spectrum, we build a finite-dimensional discrete-time state-space process representation amenable to Kalman filtering. With sampling over a finite set of fixed spatial locations, our major finding is that the current Kalman filter state represents a sufficient statistic to compute the minimum variance estimate of the process at any future time over the entire spatial domain. In machine learning, a representer theorem states that an important class of infinite-dimensional variational problems admits a computable and finite-dimensional exact solution. In view of this, our result can be interpreted as a novel Dynamic Representer Theorem for GPs. We then extend the study to situations where the spatial input locations set varies over time. The proposed algorithms are tested on both synthetic and real field data, providing comparisons with standard GP and truncated GP regression techniques.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scitotenv.2020.138895,Journal,Science of the Total Environment,scopus,2020-08-01,sciencedirect,A serious gaming framework for decision support on hydrological hazards,https://api.elsevier.com/content/abstract/scopus_id/85083823562,"With increasing population and human intervention on the natural environment, hazards are a growing threat, coming in many forms, including floods, droughts, soil erosion, and water pollution. A key approach to mitigate hydrological disaster risk at the community level is informed planning with decision support systems. The literature shows emerging efforts on multi-hazard decision support systems for hydrological disasters and demonstrates the need for an engaging, accessible, and collaborative serious game environment facilitating the relationship between the environment and communities. In this study, a web-based decision support tool (DST) was developed for hydrological multi-hazard analysis while employing gamification techniques to introduce a competitive element. The serious gaming environment provides functionalities for intuitive management, visualization, and analysis of geospatial, hydrological, and economic data to help stakeholders in the decision-making process regarding hydrological hazard preparedness and response. Major contributions of the presented DST include involving the community in environmental decision making by reducing the technical complexity required for analysis, increasing community awareness for the environmental and socio-economic consequences of hydrological hazards, and allowing stakeholders to discover and discuss potential trade-offs to hazardous scenarios considering the limitations in budget, regulations, and technicality. The paper describes the software design approaches and system architecture applied for a modular, secure, and scalable software as well as the framework's intuitive web-based user interfaces for real-time and collaborative data analysis and damage assessment. Finally, a case study was conducted to demonstrate the usability of DST in a formal setting and to measure user satisfaction with surveys.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2020.04.023,Journal,Information Sciences,scopus,2020-08-01,sciencedirect,Recurrent neural variational model for follower-based influence maximization,https://api.elsevier.com/content/abstract/scopus_id/85083696721,"Influence Maximization, aiming at selecting a small set of seed users in a social network to maximize the spread of influence, has attracted considerable attention recently. Most of the existing influence maximization algorithms focus on the diffusion model of one single-entity, which assumes that only one entity is propagated by users in social network. However, the diffusion situations in real world social networks often involve multiple entities, competitive or complementary, spreading through the whole network, and are more complex than the situations of single independent entity.
                  In this paper, we propose a novel optimization problem, namely, the follower-based influence maximization, which aims to promote a new product into the market by maximizing the influence of a social network where other competitive and complementary products have already been propagating. We tackle this problem by proposing a Recurrent Neural Variational model (RNV) and a follower-based greedy algorithm (RNVGA). The RNV model dynamically tracks entity correlations and cascade correlations through a deep generative model and recurrent neural variational inference, while the RNVGA algorithm applies the greedy approach for submodular maximization and efficiently computes the seed node set for the target product. Extensive experiments have been conducted to evaluate effectiveness and efficiency of our method, and the results show the superiority of our method compared with the state-of-the-art methods.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2020.03.030,Journal,Information Sciences,scopus,2020-08-01,sciencedirect,Efficient approach of recent high utility stream pattern mining with indexed list structure and pruning strategy considering arrival times of transactions,https://api.elsevier.com/content/abstract/scopus_id/85083463056,"One of various pattern mining techniques, the High Utility Pattern Mining (HUPM) is a method for finding meaningful patterns from non-binary databases by considering the characteristics of the items. Recently, new data continues to flow over time in diverse fields such as sales data of market, heartbeat sensor data, and social network service. Since these data have a feature that recently generated data have higher influence than the old data, research has been focused on how to efficiently extract hidden knowledge from time-sensitive databases. In this paper, we propose indexed list-based algorithm that mines recent high utility pattern considering the arrival time of inserted data in an environment where new data is continuously accumulated. In other words, to treat the importance of recent data higher than the that of old data, our algorithms reduces the utility values of old transactions according to the time the data is inserted by applying damped window model concept. Moreover, we carry out various experiments to compare our method with state-of-the-art algorithms using real and synthetic datasets in diverse circumstances. Experimental results show that our algorithm outperforms competitors in terms of execution time, memory usage, and scalability test.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2020.02.035,Journal,Neurocomputing,scopus,2020-07-20,sciencedirect,Sparse low rank factorization for deep neural network compression,https://api.elsevier.com/content/abstract/scopus_id/85081399638,"Storing and processing millions of parameters in deep neural networks is highly challenging during the deployment of model in real-time application on resource constrained devices. Popular low-rank approximation approach singular value decomposition (SVD) is generally applied to the weights of fully connected layers where compact storage is achieved by keeping only the most prominent components of the decomposed matrices. Years of research on pruning-based neural network model compression revealed that the relative importance or contribution of each neuron in a layer highly vary among each other. Recently, synapses pruning has also demonstrated that having sparse matrices in network architecture achieve lower space and faster computation during inference time. We extend these arguments by proposing that the low-rank decomposition of weight matrices should also consider significance of both input as well as output neurons of a layer. Combining the ideas of sparsity and existence of unequal contributions of neurons towards achieving the target, we propose sparse low rank (SLR) method which sparsifies SVD matrices to achieve better compression rate by keeping lower rank for unimportant neurons. We demonstrate the effectiveness of our method in compressing famous convolutional neural networks based image recognition frameworks which are trained on popular datasets. Experimental results show that the proposed approach SLR outperforms vanilla truncated SVD and a pruning baseline, achieving better compression rates with minimal or no loss in the accuracy. Code of the proposed approach is avaialble at https://github.com/sridarah/slr.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.09.104,Journal,Neurocomputing,scopus,2020-07-05,sciencedirect,A data-efficient deep learning approach for deployable multimodal social robots,https://api.elsevier.com/content/abstract/scopus_id/85065221778,"The deep supervised and reinforcement learning paradigms (among others) have the potential to endow interactive multimodal social robots with the ability of acquiring skills autonomously. But it is still not very clear yet how they can be best deployed in real world applications. As a step in this direction, we propose a deep learning-based approach for efficiently training a humanoid robot to play multimodal games—and use the game of ‘Noughts and Crosses’ with two variants as a case study. Its minimum requirements for learning to perceive and interact are based on a few hundred example images, a few example multimodal dialogues and physical demonstrations of robot manipulation, and automatic simulations. In addition, we propose novel algorithms for robust visual game tracking and for competitive policy learning with high winning rates, which substantially outperform DQN-based baselines. While an automatic evaluation shows evidence that the proposed approach can be easily extended to new games with competitive robot behaviours, a human evaluation with 130 humans playing with the Pepper robot confirms that highly accurate visual perception is required for successful game play.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.pmcj.2020.101210,Journal,Pervasive and Mobile Computing,scopus,2020-07-01,sciencedirect,A Deep Learning approach for Path Prediction in a Location-based IoT system,https://api.elsevier.com/content/abstract/scopus_id/85086567816,"Knowing in real-time the position of objects and people, both in indoor and outdoor spaces, allows companies and organizations to improve their processes and offer new kind of services. Nowadays Location-based Services (LBS) generate a significant amount of data thank to the widespread of the Internet of Things; since they have been quickly perceived as a potential source of profit, several companies have started to design and develop a wide range of such services. One of the most challenging research tasks is undoubtedly represented by the analysis of LBS data through Machine Learning algorithms and methodologies in order to infer new knowledge and build-up even more customized services. Cultural Heritage is a domain that can benefit from such studies since it is characterized by a strong interaction between people, cultural items and spaces. Data gathered in a museum on visitor movements and behaviours can constitute the knowledge base to realize an advanced monitoring system able to offer museum stakeholders a complete and real-time snapshot of the museum locations occupancy. Furthermore, exploiting such data through Deep Learning methodologies can lead to the development of a predictive monitoring system able to suggest stakeholders the museum locations occupancy not only in real-time but also in the next future, opening new scenarios in the management of a museum. In this paper, we present and discuss a Deep Learning methodology applied to data coming from a non-invasive Bluetooth IoT monitoring system deployed inside a cultural space. Through the analysis of visitors’ paths, the main goal is to predict the occupancy of the available rooms. Experimental results on real data demonstrate the feasibility of the proposed approach; it can represent a useful instrument, in the hands of the museum management, to enhance the quality-of-service within this kind of spaces.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.comcom.2020.05.042,Journal,Computer Communications,scopus,2020-07-01,sciencedirect,Fastest adaptive estimation algorithms for topological structure errors in smart grid networks,https://api.elsevier.com/content/abstract/scopus_id/85086375513,"Compared with traditional wired networks, wireless sensor networks(WSN) have the characteristics of low cost and rapid deployment, and also guarantee the same level of fault tolerance as wired networks. The WSN can also monitor the operating status of the power grid in real time, collect physical information such as related parameters, and provide more comprehensive and complete power grid operation data as a reference basis for smart grid operation and related management personnel, and complete the diagnosis, monitoring and power statistics of smart grid equipment The rapid construction of the data communication network has become a key technology to effectively solve the problems of difficult optimization management and high cost and economic benefits in the smart grid. This paper discusses the application of WSNs in smart grids from two aspects. Firstly, construct a WSN topology that complies with the smart grid architecture, and establish a real-time routing mechanism that meets the requirements of smart distribution network communication reliability; secondly, propose a fastest adaptive algorithm for the fault of the WSN topology in the smart grid . The proposed adaptive routing mechanism has certain advantages in node energy consumption, which reduces energy consumption by nearly 4% compared to the directional diffusion method and the LEACH algorithm. Therefore, the algorithm is more suitable for the adaptation of WSN topology, and the method can Improve the life cycle of sensor nodes and networks.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jobe.2020.101222,Journal,Journal of Building Engineering,scopus,2020-07-01,sciencedirect,Economy-energy trade off automation – A decision support system for building design development,https://api.elsevier.com/content/abstract/scopus_id/85081177322,"Building energy simulation is traditionally applied at late phases of the design, when most decisions on specifications of building systems are made. There has been a growing attempt in the literature to enable such simulations at earlier phases of design, when decisions’ impact on the lifecycle behavior is the strongest. While researchers have developed tools/models to support planning and conceptualization phases from this aspect; there have been not much developments for early design development stage (which is usually the scope of semi-detailed cost estimates). This paper introduces a software tool for generating multiple design scenarios and evaluating them, by combining energy simulation and economic analyses, at schematic design and early design development phases of building projects. In this regard, we used state-of-the art of open source technologies, as well as cloud computing, to integrate energy simulation into the alternative selection procedure. The developed system focuses on architectural parameters; lighting power density; and heating, ventilation and air conditioning (HVAC). Analysis of sensitivity of lifecycle energy to such parameters, in a group of representative real-world projects, helped us to limit variations of such parameters, and subsequently their combinations. Using OpenStudio measures and the computational power offered by the cloud, our system generates/simulates all possible design scenarios (combinations of alternative variations for design parameters); and compares them based on building economics performance measures. The workflow is showcased in a case study project, by automatically creating and evaluating 97 design scenarios, based on economic efficiency and liquidity.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ipm.2020.102231,Journal,Information Processing and Management,scopus,2020-07-01,sciencedirect,Discovering web services in social web service repositories using deep variational autoencoders,https://api.elsevier.com/content/abstract/scopus_id/85081050739,"Web Service registries have progressively evolved to social networks-like software repositories. Users cooperate to produce an ever-growing, rich source of Web APIs upon which new value-added Web applications can be built. Such users often interact in order to follow, comment on, consume and compose services published by other users. In this context, Web Service discovery is a core functionality of modern registries as needed Web Services must be discovered before being consumed or composed. Many efforts to provide effective keyword-based service discovery mechanisms are based on Information Retrieval techniques as services are described using structured or unstructured textdocuments that specify the provided functionality. However, traditional techniques suffer from term-mismatch, which means that only the terms that are contained in both user queries and descriptions are exploited to perform service retrieval. Early feature learning techniques such as LSA or LDA tried to solve this problem by finding hidden or latent features in text documents. Recently, alternative feature learning based techniques such as Word Embeddings achieved state of the art results for Web Service discovery. In this paper, we propose to learn features from service descriptions by using Variational Autoencoders, a special kind of autoencoder which restricts the encoded representation to model latent variables. Autoencoders in turn are deep neural networks used for unsupervised learning of efficient codings. We train our autoencoder using a real 17 113-service dataset extracted from the ProgrammableWeb.com API social repository. We measure discovery efficacy by using both Recall and Precision metrics, achieving significant gains compared to both Word Embeddings and classic latent features modelling techniques. Also, performance-oriented experiments show that the proposed approach can be readily exploited in practice.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.petrol.2019.106741,Journal,Journal of Petroleum Science and Engineering,scopus,2020-07-01,sciencedirect,Connectionist and mutual information tools to determine water saturation and rank input log variables,https://api.elsevier.com/content/abstract/scopus_id/85081011589,"Characterization of petroleum reservoirs plays an important role to effectively manage and forecast the recovery performance. A number of subset log variables such as gamma-ray, resistivity, density, neutron, and sonic porosity logs are generally used to characterize/predict the reservoir properties. The data attributes selection and ranking in reservoir characterization are vital to determine the output variables with the best performance and cost-effective manner during exploration and production operations. The objectives of this research work are to estimate the water saturation in the reservoir with an acceptable accuracy and to rank the log variables according to their importance. To achieve the objectives, the mutual information (MI) and artificial neural network (ANN) techniques are implemented with the non-linear predictors using log variables. The feed-forward ANN model is employed and optimized to predict the water saturation, where the Levenberg-Marquardt algorithm is used for the network training. There is a good match between the real data and predictions so that the regression coefficient and the maximum error is 99.98% and 5.55%, respectively. In addition, both ANN and MI approaches lead to the same ranking levels of log variables, implying high accuracy and reliability of the introduced strategies. It is found that the primary (or most important) log variables are the true resistivity and bulk density to obtain the pore fluid saturation. The approach suggested in this study (connectionist and MI strategies) can assist engineers/operators to run a few numbers of logging tools for prediction of water saturation, resulting in saving the exploration costs through an efficient manner. In addition, further understanding is attained to conduct proper data selection for determination of reservoir petrophysical properties.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.buildenv.2020.106854,Journal,Building and Environment,scopus,2020-06-15,sciencedirect,A daylight-linked shading strategy for automated blinds based on model-based control and Radial Basis Function (RBF) optimization,https://api.elsevier.com/content/abstract/scopus_id/85084048092,"Addressing both daylight maximization and glare control over the entire workplace is always challenging for developing the automated shading control system. For the sake of cost and space usage, it is impractical to mount multiple sensors or cameras for real-time daylight environment monitoring to guarantee the control precision. Cut-off control is popular while it cannot attenuate the glare caused by excessive diffuse daylight. This paper introduces a model-based shading control for predetermining shading positions at each time step. A Useful Daylight Illuminance paradigm modality called rUDI is proposed as a variable criterion added to assist the cut-off strategy for further eliminating glare. The controller could be developed through real-time daylight simulations and an optimizer based on the surrogate model. This method was implemented in a full-scale office in Harbin, China. The surrogate model grounded on the Radial Basis Function Neural Network (RBF) was trained, validated and test with the experimental data sets. The control strategy was further incorporated with an adaptive light-switch model. The comparative simulations were conducted, and their corresponding results were generated for evaluating their performance in visual comfort, daylighting and electrical energy savings, demonstrating the advantages of the proposed control approach in terms of its adequate performance.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100042,Journal,Patterns,scopus,2020-06-12,sciencedirect,Deep Learning Identifies Digital Biomarkers for Self-Reported Parkinson's Disease,https://api.elsevier.com/content/abstract/scopus_id/85095745471,"Large-scale population screening and in-home monitoring for patients with Parkinson's disease (PD) has so far been mainly carried out by traditional healthcare methods and systems. Development of mobile health may provide an independent, future method to detect PD. Current PD detection algorithms will benefit from better generalizability with data collected in real-world situations. In this paper, we report the top-performing smartphone-based method in the recent DREAM Parkinson's Disease Digital Biomarker Challenge for digital diagnosis of PD. Utilizing real-world accelerometer records, this approach differentiated PD from control subjects with an area under the receiver-operating characteristic curve of 0.87 by 3D augmentation of accelerometer records, a significant improvement over other state-of-the-art methods. This study paves the way for future at-home screening of PD and other neurodegenerative conditions affecting movement.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2020.e03966,Journal,Heliyon,scopus,2020-06-01,sciencedirect,Regression analysis for thermal properties of Al<inf>2</inf>O<inf>3</inf>/H<inf>2</inf>O nanofluid using machine learning techniques,https://api.elsevier.com/content/abstract/scopus_id/85086086334,"Nanofluids possess higher thermal properties than the other conventional base fluids. Many investigators suggested that the nanofluids have the potential to apply in various engineering fields. In real time situation it is challenging to determine the thermal conductivity of nanofluids with accuracy as they have many depending factors. Moreover, numerous experimental tests are required to acquire the thermal conductivity of nanofluids accurately. In this research paper, thermal conductivity ratio and dynamic viscosity ratio of Al2O3/H2O nanofluid are predicted accurately by using Gaussian Process Regression (GPR) methods. The input predictor variables used in this model are temperature, volume fraction and size of the nanoparticles. 222 experimental data sets are taken to predict the thermal conductivity ratio (TCR), dynamic viscosity ratio (DVR) and also the effectiveness of the predictor variables in predicting the response variables are extensively studied and found that the temperature is the crucial factor to enhance the thermal conductivity ratio. The proposed modeling is performed by using MATLAB software. The predictions were evaluated by various evaluation criterions. It is observed that an optimized Gaussian process regression (GPR) method with matern kernel function shows an accurate agreement with experimental data with Root Mean Square Error (RMSE) value of 0.000126 for TCR and squared exponential kernel function show good agreement with experimental data with Root Mean Square Error (RMSE) value of 0.000045 for DVR. Regression coefficient value (R2) is 0.99; nearer to one hence the predicted results are reliable.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cola.2020.100970,Journal,Journal of Computer Languages,scopus,2020-06-01,sciencedirect,"Visual Programming Environments for End-User Development of intelligent and social robots, a systematic review",https://api.elsevier.com/content/abstract/scopus_id/85085272330,"Robots are becoming interactive and robust enough to be adopted outside laboratories and in industrial scenarios as well as interacting with humans in social activities. However, the design of engaging robot-based applications requires the availability of usable, flexible and accessible development frameworks, which can be adopted and mastered by researchers and practitioners in social sciences and adult end users as a whole. This paper surveys Visual Programming Environments aimed at enabling a paradigm fostering the so-called End-User Development of applications involving robots with social capabilities. The focus of this article is on those Visual Programming Environments that are designed to support social research goals as well as to cater for professional needs of people not trained in more traditional text-based computer programming languages. This survey excludes interfaces aimed at supporting expert programmers, at allowing industrial robots to perform typical industrial tasks (such as pick and place operations), and at teaching children how to code. After having performed a systematic search, sixteen programming environments have been included in this survey. Our goal is two-fold: first, to present these software tools with their technical features and Authoring Artificial Intelligence modeling approaches, and second, to present open challenges in the development of Visual Programming Environments for end users and social researchers, which can be informative and valuable to the community. The results show that the most recent such tools are adopting distributed and Component-Based Software Engineering approaches and web technologies. However, few of them have been designed to enable the independence of end users from high-tech scribes. Moreover, findings indicate the need for (i) more objective and comparative evaluations, as well as usability and user experience studies with real end users; and (ii) validations of these tools for designing applications aimed at working “in-the-wild” rather than only in laboratories and structured settings.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2020.103800,Journal,Computers in Biology and Medicine,scopus,2020-06-01,sciencedirect,ECG signal classification with binarized convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85084584293,"Arrhythmias are a group of common conditions associated with irregular heart rhythms. Some of these conditions, for instance, atrial fibrillation (AF), might develop into serious syndromes if not treated in time. Therefore, for high-risk patients, early detection of arrhythmias is crucial. In this study, we propose employing deep convolutional neural network (CNN)-based algorithms for real-time arrhythmia detection. We first build a full-precision deep convolutional network model. With our proposed construction, we are able to achieve state-of-the-art level performance on the PhysioNet/CinC AF Classification Challenge 2017 dataset with our full-precision model. It is desirable to employ models with low computing resource requirements. It has been shown that a binarized model requires much less computing power and memory space than a full-precision model. We proceed to verify the feasibility of binarization in our neural network model. Network binarization can cause significant model performance degradation. Therefore, we propose employing a full-precision model as the teacher to regularize the training of the binarized model through knowledge distillation. With our proposed approach, we observe that network binarization only causes a small performance loss (the F1 score decreases from 0.88 to 0.87 for the validation set). Given that binarized convolutional networks can achieve favorable model performance while dramatically reducing computing cost, they are ideal for deployment on long-term cardiac condition monitoring devices. (Source code is available at https://github.com/yangfansun/bnn-ecg).",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2020.103792,Journal,Computers in Biology and Medicine,scopus,2020-06-01,sciencedirect,Automated detection of COVID-19 cases using deep neural networks with X-ray images,https://api.elsevier.com/content/abstract/scopus_id/85083900518,"The novel coronavirus 2019 (COVID-2019), which first appeared in Wuhan city of China in December 2019, spread rapidly around the world and became a pandemic. It has caused a devastating effect on both daily lives, public health, and the global economy. It is critical to detect the positive cases as early as possible so as to prevent the further spread of this epidemic and to quickly treat affected patients. The need for auxiliary diagnostic tools has increased as there are no accurate automated toolkits available. Recent findings obtained using radiology imaging techniques suggest that such images contain salient information about the COVID-19 virus. Application of advanced artificial intelligence (AI) techniques coupled with radiological imaging can be helpful for the accurate detection of this disease, and can also be assistive to overcome the problem of a lack of specialized physicians in remote villages. In this study, a new model for automatic COVID-19 detection using raw chest X-ray images is presented. The proposed model is developed to provide accurate diagnostics for binary classification (COVID vs. No-Findings) and multi-class classification (COVID vs. No-Findings vs. Pneumonia). Our model produced a classification accuracy of 98.08% for binary classes and 87.02% for multi-class cases. The DarkNet model was used in our study as a classifier for the you only look once (YOLO) real time object detection system. We implemented 17 convolutional layers and introduced different filtering on each layer. Our model (available at (https://github.com/muhammedtalo/COVID-19)) can be employed to assist radiologists in validating their initial screening, and can also be employed via cloud to immediately screen patients.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2020.103670,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-06-01,sciencedirect,"Detecting, locating and recognising human touches in social robots with contact microphones",https://api.elsevier.com/content/abstract/scopus_id/85083676413,"There are many situations in our daily life where touch gestures during natural human–human interaction take place: meeting people (shaking hands), personal relationships (caresses), moments of celebration or sadness (hugs), etc. Considering that robots are expected to form part of our daily life in the future, they should be endowed with the capacity of recognising these touch gestures and the part of its body that has been touched since the gesture’s meaning may differ. Therefore, this work presents a learning system for both purposes: detect and recognise the type of touch gesture (stroke, tickle, tap and slap) and its localisation. The interpretation of the meaning of the gesture is out of the scope of this paper.
                  Different technologies have been applied to perceive touch by a social robot, commonly using a large number of sensors. Instead, our approach uses 3 contact microphones installed inside some parts of the robot. The audio signals generated when the user touches the robot are sensed by the contact microphones and processed using Machine Learning techniques. We acquired information from sensors installed in two social robots, Maggie and Mini (both developed by the RoboticsLab at the Carlos III University of Madrid), and a real-time version of the whole system has been deployed in the robot Mini. The system allows the robot to sense if it has been touched or not, to recognise the kind of touch gesture, and its approximate location. The main advantage of using contact microphones as touch sensors is that by using just one, it is possible to “cover” a whole solid part of the robot. Besides, the sensors are unaffected by ambient noises, such as human voice, TV, music etc. Nevertheless, the fact of using several contact microphones makes possible that a touch gesture is detected by all of them, and each may recognise a different gesture at the same time. The results show that this system is robust against this phenomenon. Moreover, the accuracy obtained for both robots is about 86%.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compag.2020.105434,Journal,Computers and Electronics in Agriculture,scopus,2020-06-01,sciencedirect,Dynamic Simulation Tool of fertigation in drip irrigation subunits,https://api.elsevier.com/content/abstract/scopus_id/85083338592,"Agriculture consumes approximately 95 million tonnes of fertilizers and 97,000 tonnes of active ingredients of pesticides and herbicides. Reducing external input systems can result in significant economic, social and environmental impact. Therefore, establishing an optimal fertigation schedule is essential to achieve efficient drip irrigation management and, therefore, achieve an optimal irrigated agriculture management system that ensures productive, environmental and economic viability. The objective of this study was to develop a decision support system (DSS) to facilitate farmers’ decision-making process and optimize the design and management of farm fertigation scheduling. Implemented in MATLAB®, FERTI-DRIP, was tested in a regular irrigation subunit and in an irregular irrigation subunit of a real water user association. Both irrigation subunits were tested with two irrigation emitter types: pressure-compensating emitters and non-pressure-compensating emitters. Thus, FERTI-DRIP was applied to four scenarios to analyse the effect of the size and shape of the irrigation subunit on the fertigation process. The effect of the pressure head in the irrigation subunit and the effect of the fertilizer dynamics during the fertigation event were also analysed. FERTI-DRIP allows users to compute fertilizer quality parameters to determine how to implement fertigation. FERTI-DRIP also allows users to accurately select pre-fertigation and post-fertigation processes to optimize hydraulic stability at the beginning of the fertigation event and ensure that there is no fertilizer remaining in the irrigation system after the fertigation event. FERTI-DRIP can be very helpful for start-time irrigation events, such in the case of sandy soils where pulse drip irrigation should be performed.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aca.2020.04.007,Journal,Analytica Chimica Acta,scopus,2020-06-01,sciencedirect,Dual-emission CdTe/AgInS<inf>2</inf> photoluminescence probe coupled to neural network data processing for the simultaneous determination of folic acid and iron (II),https://api.elsevier.com/content/abstract/scopus_id/85083073504,"This work focused on the combination of CdTe and AgInS2 quantum dots in a dual-emission nanoprobe for the simultaneous determination of folic acid and Fe(II) in pharmaceutical formulations. The surface chemistry of the used QDs was amended with suitable capping ligands to obtain appropriate reactivity in terms of selectivity and sensitivity towards the target analytes. The implementation of PL-based sensing schemes combining multiple QDs of different nature, excited at the same wavelength and emitting at different ones, allowed to obtain a specific analyte-response profile. The first-order fluorescence data obtained from the whole emission spectra of the CdTe/AgInS2 combined nanoprobe upon interaction with folic acid and Fe(II) were processed by using chemometric tools, namely partial least-squares (PLS) and artificial neural network (ANN). This enabled to circumvent the selectivity issues commonly associated with the use of QDs prone to indiscriminate interaction with multiple species, which impair reliable and accurate quantification in complex matrices samples.
                  ANN demonstrated to be the most efficient chemometric model for the simultaneous determination of both analytes in binary mixtures and pharmaceutical formulations due to the non-linear relationship between analyte concentration and fluorescence data that it could handle. The R2
                     P and SEP% obtained for both analytes quantification in pharmaceutical formulations through ANN modelling ranged from 0.92 to 0.99 and 5.7–9.1%, respectively. The obtained results revealed that the developed approach is able to quantify, with high reliability and accuracy, more than one analyte in complex mixtures and real samples with pharmaceutical interest.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scitotenv.2020.137459,Journal,Science of the Total Environment,scopus,2020-06-01,sciencedirect,NO<inf>x</inf> removal efficiency of urban photocatalytic pavements at pilot scale,https://api.elsevier.com/content/abstract/scopus_id/85081197829,"Photocatalytic technology implemented in construction materials is a promising solution to contribute to alleviate air quality issues found in big cities. Photocatalysis has been proved able to mineralise most harmful contaminants. However, important problems associated with monitoring the efficiency of these solutions under real conditions still remain, including the lack of affordable analytical tools to measure NOx concentrations with enough accuracy. In this work, two pilot scale demonstration platforms were built at two different locations to assess the photocatalytic NOX removal efficiency of ten selected materials exposed outdoors for AQmesh low-cost sensor PODs were used to measure ground-level to measure NO and NO2 concentrations during nearly one year. The pollutant removal efficiency of the materials was then calculated based on a comparison with simultaneously concentration measurements carried-out on reference, non-active materials. It was found that the NO2 removal efficiency presented large variations across the seasons, with maxima during the warmer months, while NO efficiencies were comparatively steadier. Statistical analysis delivered evidence that the efficiencies significantly depend on different meteorological variables (irradiance and relative humidity) besides NO, NO2 ambient concentrations. Lower efficiencies were observed for higher concentration levels and vice versa. The influence of water vapour could be related to two different effects: a short-term contribution by the instantaneous air humidity and a long-term component associated with the hygroscopic state of the material. The contribution of wind to the pollutant removal efficiencies was principally related to the humidity of air masses moving above the location and to the advection of pollutants from specific emission sources.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.renene.2020.01.092,Journal,Renewable Energy,scopus,2020-06-01,sciencedirect,Solar irradiance forecasting models without on-site training measurements,https://api.elsevier.com/content/abstract/scopus_id/85078400450,"Much effort has been made to increase the integration of solar photovoltaic (PV) systems to reduce the environmental impacts of fossil fuels. An essential process in PV systems is the forecasting of solar irradiance to avoid safety and stability problems due to its intermittent nature. Most of the research has been focused on improving the prediction accuracy based on the assumption that enough on-site training data are available. However, in many situations, it is required for the implementation of PV systems in locations where not enough solar irradiance measurements have been collected. Our hypothesis is that measurements from other sites can be used to train accurate forecasting models, given an appropriate definition of site similarity. We propose a methodology that takes information from exogenous variables that are correlated to on-site solar irradiance and constructs a multidimensional space equipped with a metric. Each site is a point in this space, and the learned metric is used to select those sites that can provide measurements to train an accurate forecasting model on an unobserved site. We show through experiments with real data that using the learned metric provides better predictions than using the measurements collected from the whole set of available sites.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.inffus.2019.12.012,Journal,Information Fusion,scopus,2020-06-01,sciencedirect,"Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI",https://api.elsevier.com/content/abstract/scopus_id/85077515399,"In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cels.2020.04.006,Journal,Cell Systems,scopus,2020-05-20,sciencedirect,Lattice Light-Sheet Microscopy Multi-dimensional Analyses (LaMDA) of T-Cell Receptor Dynamics Predict T-Cell Signaling States,https://api.elsevier.com/content/abstract/scopus_id/85084658613,"Lattice light-sheet microscopy provides large amounts of high-dimensional, high-spatiotemporal resolution imaging data of cell surface receptors across the 3D surface of live cells, but user-friendly analysis pipelines are lacking. Here, we introduce lattice light-sheet microscopy multi-dimensional analyses (LaMDA), an end-to-end pipeline comprised of publicly available software packages that combines machine learning, dimensionality reduction, and diffusion maps to analyze surface receptor dynamics and classify cellular signaling states without the need for complex biochemical measurements or other prior information. We use LaMDA to analyze images of T-cell receptor (TCR) microclusters on the surface of live primary T cells under resting and stimulated conditions. We observe global spatial and temporal changes of TCRs across the 3D cell surface, accurately differentiate stimulated cells from unstimulated cells, precisely predict attenuated T-cell signaling after CD4 and CD28 receptor blockades, and reliably discriminate between structurally similar TCR ligands. All instructions needed to implement LaMDA are included in this paper.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.enbuild.2020.109825,Journal,Energy and Buildings,scopus,2020-05-15,sciencedirect,Building temperature regulation in a multi-zone HVAC system using distributed adaptive control,https://api.elsevier.com/content/abstract/scopus_id/85081129562,"During recent years there have been considerable research efforts on improving energy efficiency of buildings. Since Heating, Ventilation and Air-Conditioning (HVAC) systems are responsible for a big part of energy consumption, developing efficient HVAC control systems is crucial. In most of the developed approaches, precise knowledge of system parameters and/or adequate historical data is required. However, these approaches may not perform as well in the presence of dynamic parameter changes due to human activity, material degradation, and wear and tear, or disturbances and other operational uncertainties due to occupancy, solar gains, electrical equipment, and weather conditions. In this paper, we consider buildings with several climate zones and propose a distributed adaptive control scheme for a multi-zone HVAC system which can effectively regulate zone temperature by applying on-line learning and assuming exchange of information between neighboring zones. The controller of each zone achieves the local objective of controlling zone temperature by compensating for the effects of neighboring zones as well as for possible changes in the parameters of the system. Despite the exchange of information, each local controller does not know how the control actions and temperature of a neighboring zone affect the temperature of its own zone. For this reason, each local controller is estimating the parameters of the interconnections in real time and uses them together with the exchanged information to provide a more accurate local zone temperature control. The proposed method is illustrated using an example of temperature control in a six-zone building as well as a large school building, which are implemented in a Building Controls Virtual Test Bed (BCVTB) environment using EnergyPlus and MATLAB/Simulink.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2020.105645,Journal,Knowledge-Based Systems,scopus,2020-05-11,sciencedirect,Bayesian optimisation in unknown bounded search domains,https://api.elsevier.com/content/abstract/scopus_id/85079889517,"Bayesian optimisation (BO) is one of the most sample efficient methods for determining the optima of expensive, noisy black-box functions. Despite its tremendous success in scientific discovery and hyperparameter tuning, it still requires a bounded search space. The search spaces boundaries are, however, often chosen heuristically with an educated guess. If the boundaries are misspecified, then the search space may either be unnecessarily large and hence more expensive to optimise, or it may simply not contain the global optimum. In this paper, we introduce a method for dynamically determining the bound directly from the data. This is done using a distribution of the bound derived in a Bayesian setting. The prior is chosen by the user and the likelihood is derived with Thompson sampling. This results in a bound that is both cheap to optimise and has a high probability of containing the global optimum. We compare the performance of our method with the alternative methods on a range of synthetic and real-world problems and demonstrate that our method achieves consistently superior results.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100013,Journal,Patterns,scopus,2020-05-08,sciencedirect,Random Forest Models for Accurate Identification of Coordination Environments from X-Ray Absorption Near-Edge Structure,https://api.elsevier.com/content/abstract/scopus_id/85088690454,"Analyzing coordination environments using X-ray absorption spectroscopy has broad applications in solid-state physics and material chemistry. Here, we show that random forest models trained on 190,000 K-edge X-ray absorption near-edge structure (XANES) spectra can identify the main atomic coordination environment with a high accuracy of 85.4% and all associated coordination environments with a high Jaccard score of 81.8% for 33 cation elements in oxides, significantly outperforming other machine-learning models. In a departure from prior works, the coordination environment is described as a distribution over 25 distinct coordination motifs with coordination numbers ranging from 1 to 12. More importantly, we show that the random forest models can be used to predict coordination environments from experimental K-edge XANES with minimal loss in accuracy. A drop-variable feature importance analysis highlights the key roles that the pre-edge and main-peak regions play in coordination environment identification.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rse.2020.111717,Journal,Remote Sensing of Environment,scopus,2020-05-01,sciencedirect,Assessing the relationship between macro-faunal burrowing activity and mudflat geomorphology from UAV-based Structure-from-Motion photogrammetry,https://api.elsevier.com/content/abstract/scopus_id/85079899077,"Characterisation of the ecosystem functioning of mudflats requires insight on the morphology and facies of these coastal features, but also on biological processes that influence mudflat geomorphology, such as crab bioturbation and the formation of benthic biofilms, as well as their heterogeneity at cm or less scales. Insight into this fine scale of ecosystem functioning is also important as far as minimizing errors in upscaling are concerned. The realisation of high-resolution ground surveys of these mudflats without perturbing their surface is a real challenge. Here, we address this challenge using UAV-supported photogrammetry based on the Structure-from-Motion (SfM) workflow. We produced a Digital Surface Model (DSM) and an orthophotograph at 1 cm and 0.5 cm pixel resolutions, respectively, of a mudflat in French Guiana, and mapped and classed into different size ranges intricate morphological features, including crab burrow apertures, tidal drainage creeks and depressions. We also determined subtle facies and elevation changes and slopes, and the footprint of different degrees of benthic biofilm development. The results generated at this scale of photogrammetric analysis also enabled us to relate macrofaunal crab burrowing activity to various parameters, including mudflat elevation, spatial distribution and sizes of creeks and depressions, benthic biofilm distribution, and flooding duration. SfM photogrammetry offers interesting new perspectives in fine-scale characterisation of the geomorphology, benthic activity and degree of biofilm development of dynamic muddy intertidal environments that are generally difficult of access. The main shortcomings highlighted in this study are a drift of accuracy of the DSM outside areas of ground control points and the deployment of which perturb the mudflat morphology and biology, the water-logged or very wet surfaces which generate reconstruction artefacts through the sun glint effect, and the time-consuming task of manual interpretation of extraction of features such as crab burrow apertures. On-going developments in UAV positioning integrating RTK/PPK GPS solutions for image-georeferencing and precise orientation with high-quality inertial measurement units will limit the difficulties inherent to ground control points, while conduction of surveys during homogeneous cloudy conditions could reduce the sun-glint effect. Manual extraction of image features could be automated in the future through the use of deep-learning algorithms.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijmultiphaseflow.2019.103194,Journal,International Journal of Multiphase Flow,scopus,2020-05-01,sciencedirect,Bubble patterns recognition using neural networks: Application to the analysis of a two-phase bubbly jet,https://api.elsevier.com/content/abstract/scopus_id/85079560188,"Gas-liquid two-phase bubbly flows are found in different areas of science and technology such as nuclear energy, chemical industry, or piping systems. Optical diagnostics of two-phase bubbly flows with modern panoramic techniques makes it possible to capture simultaneously instantaneous characteristics of both continuous and dispersed phases with a high spatial resolution. In this paper, we introduce a novel approach based on neural networks to recognize bubble patterns in images and identify their geometric parameters. The originality of the proposed method consists in training of a neural network ensemble using synthetic images that resemble real photographs gathered in experiment. The use of neural networks in combination with automatically generated data allowed us to detect overlapping, blurred, and non-spherical bubbles in a broad range of volume gas fractions. Experiments on a turbulent bubbly jet proved that the implemented method increases the identification accuracy, reducing errors of various kinds, and lowers the processing time compared to conventional recognition methods. Furthermore, utilizing the new method of bubbles recognition, the primary physical parameters of a dispersed phase, such as bubble size distribution and local gas content, were calculated in a near-to-nozzle region of the bubbly jet. The obtained results and integral experimental parameters, especially volume gas fraction, are in good agreement with each other.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ress.2020.106821,Journal,Reliability Engineering and System Safety,scopus,2020-05-01,sciencedirect,Towards Efficient Robust Optimization using Data based Optimal Segmentation of Uncertain Space,https://api.elsevier.com/content/abstract/scopus_id/85078707908,"Performing multi-objective optimization under uncertainty is a common requirement in industries and academia. Robust optimization (RO) is considered as an efficient and tractable approach provided one has access to behavioral data for the uncertain parameters. However, solutions of RO may be far from the real solution and less reliable due to inability to map the uncertain space accurately, especially when the data appears discontinuous and scattered in the uncertain domain. Amalgamating machine learning algorithms with RO, this paper proposes a data-driven methodology, where a novel fuzzy clustering mechanism is implemented along-with boundary construction, to transcript the uncertain space such that the specific regions of uncertainty are identified. Subsequently, using intelligent Sobol sampling, samples are generated in the mapped uncertain regions. Results of two test cases are presented along with a comprehensive comparison study. Considered case-studies include highly nonlinear model for continuous casting process from steelmaking industries, where a multi-objective optimization problem under uncertainty is solved to balance the conflict between productivity and energy consumption. The Pareto-optimal solutions of the resulting RO problem are obtained through Non-Dominated Sorting Genetic Algorithm – II, and ~23–29% improvement is observed in the uncertain objective function. Further, the spread and diversity metrics are enhanced by ~10–95% as compared to those obtained using other standard uncertainty sets.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijfatigue.2019.105458,Journal,International Journal of Fatigue,scopus,2020-05-01,sciencedirect,Steel railway bridge fatigue damage detection using numerical models and machine learning: Mitigating influence of modeling uncertainty,https://api.elsevier.com/content/abstract/scopus_id/85077500262,"Stringer-to-floor beam connections were reported as one of the most fatigue-prone details in riveted steel railway bridges. To detect stiffness degradation that results from the initiation and growth of fatigue cracks, an automated damage detection framework was proposed by the authors (Eftekhar Azam et al., 2019; Rageh et al., 2018). The proposed method relies on Proper Orthogonal Decomposition (POD) and Artificial Neural Networks (ANNs) to identify damage location and intensity under non-stationary, unknown train loads. Bridge computational models were used to simulate damage scenarios and for training the ANNs. Damage detection method efficiency and accuracy were shown to be significantly influenced by the level of modeling uncertainties (MUs). To investigate the applicability of the proposed framework to in-service bridges, a systematic analysis of the effect of MUs on the proposed POD-ANN framework was necessary. MU influence on the performance of the POD-ANN damage detection method was investigated and a new procedure for generating training data for ANNs was proposed. The procedure was based on synergizing Proper Orthogonal Modes (POMs) extracted from measured structural response and POMs calculated from the numerical model. The current study integrated numerical and field investigations. The main objective of the numerical investigation was to identify a robust damage feature independent of the level and location of assumed MUs. Results showed that Damage Location (DL) and Damage Intensity (DI) were detected with high accuracy for studied uncertainty cases; however, as expected, damage detection accuracy reduced as MU increased. A hybrid experimental-numerical approach was then implemented for the field investigation studies. This approach applied identified damage features from the numerical investigation to measurements from an in-service railway bridge to produce damage scenarios used to train the framework. MATLAB algorithms were developed that preprocessed field data and eliminated POM variations resulted from loading uncertainties. ANNs were trained and tested using the field strain estimated POMs from the hybrid approach and DL and DI results were obtained for the studied railway bridge under non-stationary, unknown train loads. These results show the promise of the POD-ANN method as a robust, real-time fatigue damage identification tool for steel railway bridges.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2019.105263,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-05-01,sciencedirect,Parallelized collision detection with applications in virtual bone machining,https://api.elsevier.com/content/abstract/scopus_id/85076248977,"Background and objectives
                  Virtual reality surgery simulators have been proved effective for training in several surgical disciplines. Nevertheless, this technology is presently underutilized in orthopaedics, especially for bone machining procedures, due to the limited realism in haptic simulation of bone interactions. Collision detection is an integral part of surgery simulators and its accuracy and computational efficiency play a determinant role on the fidelity of simulations. To address this, the primary objective of this study was to develop a new algorithm that enables faster and more accurate collision detection within 1 ms (required for stable haptic rendering) in order to facilitate the improvement of the realism of virtual bone machining procedures.
               
                  Methods
                  The core of the developed algorithm is constituted by voxmap point shell method according to which tool and osseous tissue geometries were sampled by points and voxels, respectively. The algorithm projects tool sampling points into the voxmap coordinates and compute an intersection condition for each point-voxel pair. This step is massively parallelized using Graphical Processing Units and it is further accelerated by an early culling of the unnecessary threads as instructed by the rapid estimation of the possible intersection volume. A contiguous array was used for implicit definition of voxmap in order to guarantee a fast access to voxels and thereby enable efficient material removal. A sparse representation of tool points was employed for efficient memory reductions. The effectiveness of the algorithm was evaluated at various bone sampling resolutions and was compared with prior relevant implementations.
               
                  Results
                  The results obtained with an average hardware configuration have indicated that the developed algorithm is capable to reliably maintain < 1 ms running time in severe tool-bone collisions, both sampled at 10243 resolutions. The results also showed the algorithm running time has a low sensitivity to bone sampling resolution. The comparisons performed suggested that the proposed approach is significantly faster than comparable methods while relying on lower or similar memory requirements.
               
                  Conclusions
                  The algorithm proposed through this study enables a higher numerical efficiency and is capable to significantly enlarge the maximum resolution that can be used by high fidelity/high realism haptic simulators targeting surgical orthopaedic procedures.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2020.105580,Journal,Knowledge-Based Systems,scopus,2020-04-22,sciencedirect,Finding influential nodes in social networks based on neighborhood correlation coefficient,https://api.elsevier.com/content/abstract/scopus_id/85078759029,"Finding the most influential nodes in social networks has significant applications. A number of methods have been recently proposed to estimate influentiality of nodes based on their structural location in the network. It has been shown that the number of neighbors shared by a node and its neighbors accounts for determining its influence. In this paper, an improved cluster rank approach is presented that takes into account common hierarchy of nodes and their neighborhood set. A number of experiments are conducted on synthetic and real networks to reveal effectiveness of the proposed ranking approach. We also consider ground-truth influence ranking based on Susceptible–Infected–Recovered model, on which performance of the proposed ranking algorithm is verified. The experiments show that the proposed method outperforms state-of-the-art algorithms.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jpowsour.2020.227964,Journal,Journal of Power Sources,scopus,2020-04-15,sciencedirect,Data-driven reinforcement-learning-based hierarchical energy management strategy for fuel cell/battery/ultracapacitor hybrid electric vehicles,https://api.elsevier.com/content/abstract/scopus_id/85080125591,"A reinforcement-learning-based energy management strategy is proposed in this paper for managing energy system of Fuel Cell Hybrid Electric Vehicles (FCHEV) equipped with three power sources. A hierarchical power splitting structure is employed to shrink large state-action space based on an adaptive fuzzy filter. Then, the reinforcement-learning-based algorithm using Equivalent Consumption Minimization Strategy (ECMS) is proposed for tackling high-dimensional state-action space, and finding a trade-off between global learning and real-time implementation. The power splitting policy based on experimental data is obtained by using reinforcement learning algorithm, which allows for many different driving cycles and traffic conditions. The proposed energy management strategy can achieve low computation cost, optimal fuel cell efficiency and energy consumption economy. Simulation results confirm that, compared with existing learning algorithms and optimization methods, the proposed reinforcement-learning-based energy management strategy using ECMS can achieve high computation efficiency, lower power fluctuation of fuel cell and optimal fuel economy of FCHEV.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.apenergy.2020.114680,Journal,Applied Energy,scopus,2020-04-15,sciencedirect,Household standards and socio-economic aspects as a factor determining energy consumption in the city,https://api.elsevier.com/content/abstract/scopus_id/85079833073,"Political or economic attempts to mitigate climate change by increasing fossil fuel prices lead to and an increase in energy poverty, i.e., social effects. The ideal solution would be to combine modernisation activities in terms of energy use in cities with sustainable strategies and redevelopment policies. The article's purpose is to estimate the potential for reducing energy consumption depending on socioeconomic factors (household standard and its location in the city) based on built-in scenarios and searching for the optimal way of conducting development policy at the local level. This assumption enables the implementation of the European Union climate policy. To this aim, modelling based on real and estimated data on the diversity of energy consumption in the structure of a medium-sized city in Europe (Zielona Góra) carried out. While creating scenarios, there used a modelling method based on radial artificial neural networks, which map the input set into the output set by matching many individual approximating functions to setpoints. This approach works well for data whose geolocation is in the city quarters. As a result of the simulations, the minimum and maximum achievable energy saving potential for low-intensity buildings in the quarters was estimated, taking into account the possibilities of investing in renewable energy by individual households. The observations included in the article may be relevant to other regions that are interested in reducing the energy consumption of buildings and pollution emissions from the cities. This is particularly important for the regions of Europe that benefit from the financial support of the European Union (including local development programmes based on financing European priority axes for economic development).",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cma.2019.112790,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2020-04-15,sciencedirect,"An energy approach to the solution of partial differential equations in computational mechanics via machine learning: Concepts, implementation and applications",https://api.elsevier.com/content/abstract/scopus_id/85077809695,"Partial Differential Equations (PDEs) are fundamental to model different phenomena in science and engineering mathematically. Solving them is a crucial step towards a precise knowledge of the behavior of natural and engineered systems. In general, in order to solve PDEs that represent real systems to an acceptable degree, analytical methods are usually not enough. One has to resort to discretization methods. For engineering problems, probably the best-known option is the finite element method (FEM). However, powerful alternatives such as mesh-free methods and Isogeometric Analysis (IGA) are also available. The fundamental idea is to approximate the solution of the PDE by means of functions specifically built to have some desirable properties. In this contribution, we explore Deep Neural Networks (DNNs) as an option for approximation. They have shown impressive results in areas such as visual recognition. DNNs are regarded here as function approximation machines. There is great flexibility to define their structure and important advances in the architecture and the efficiency of the algorithms to implement them make DNNs a very interesting alternative to approximate the solution of a PDE. We concentrate on applications that have an interest for Computational Mechanics. Most contributions explore this possibility have adopted a collocation strategy. In this work, we concentrate on mechanical problems and analyze the energetic format of the PDE. The energy of a mechanical system seems to be the natural loss function for a machine learning method to approach a mechanical problem. In order to prove the concepts, we deal with several problems and explore the capabilities of the method for applications in engineering.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brainresbull.2020.01.009,Journal,Brain Research Bulletin,scopus,2020-04-01,sciencedirect,MicroRNAs expressed in neuronal differentiation and their associated pathways: Systematic review and bioinformatics analysis,https://api.elsevier.com/content/abstract/scopus_id/85079431489,"MicroRNAs (miRNAs) plays an important role in the human brain from the embryonic period to adulthood. In this sense, they influence the development of neural stem cells (NSCs), regulating cellular differentiation and survival. Therefore, due to the importance of better comprehending the regulation of miRNAs in NSCs differentiation and the lack of studies that show the panorama of miRNAs and their signaling pathways studied until now we aimed to systematically review the literature to identify which miRNAs are currently being associated with neuronal differentiation and using bioinformatics analysis to identify their related pathways. A search was carried out in the following databases: Scientific Electronic Library Online (Scielo), National Library of Medicine National Institutes of Health (PubMed), Scopus, Web of Science and Science Direct, using the descriptors “(microRNA [MeSH])” and “(neurogenesis [MeSH])”. From the articles found, two independent and previously calibrated reviewers, using the EndNote X7 (Thomson Reuters, New York, NY, US), selected those that concern miRNA in the development of NSCs, based on in vitro studies. After, bioinformatic analysis was performed using the software DIANA Tools, mirPath v.3. Subsequently, data was tabulated, analyzed and interpreted. Among the 106 miRNAs cited by included studies, 55 were up-regulated and 47 were down-regulated. The bioinformatics analysis revealed that among the up-regulated miRNAs there were 24 total and 6 union pathways, and 3 presented a statistically significant difference (p ≤ 0.05). Among the down-regulated miRNAs, 46 total and 13 union pathways were found, with 7 presenting a significant difference (p ≤ 0.05). The miR-125a-5p, miR-423-5p, miR-320 were the most frequently found miRNAs in the pathways determined by bioinformatics. In this study a panel of altered miRNAs in neuronal differentiation was created with their related pathways, which could be a step towards understanding the complex network of miRNAs in neuronal differentiation.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2019.12.033,Journal,Information Sciences,scopus,2020-04-01,sciencedirect,Relation constrained attributed network embedding,https://api.elsevier.com/content/abstract/scopus_id/85076856635,"Network embedding aims at learning a low-dimensional dense vector for each node in the network. In recent years, it has attracted great research attention due to its wide applications. Most existing studies model the graph structure only and neglect the attribute information. Although several attributed network embedding methods take the node attribute into account, they mainly focus on the basic relations between the nodes and their attributes like a user and his/her interests (attributes). The composite relations between two nodes, and two nodes’ attributes, and the related nodes and their attributes, contain rich information and can enhance the performance of many network analysis tasks. For example, two scholars having the common interests as “nature language processing” and “knowledge graph” may collaborate in the future and there will be a new edge in the network. However, such important information is still under-exploited.
                  To address this limitation, we propose a novel framework to exploit the abundant relation information to enhance attributed network embedding. The main idea is to employ the multiple types of relations in attributed networks as the constraints to improve the network representation. To this end, we first construct the composite relations between two nodes and their attributes in addition to the commonly used basic relations. We then develop a relation constrained attributed network (RCAN) framework to learn the node representations by constraining them with these relations. We conduct extensive experiments on three real-world datasets to show the effectiveness of our proposed RCAN as an attributed network embedding method for modeling various social networks. The results demonstrate that our method achieves significantly better performance than the state-of-the-art baselines in both the link prediction and node clustering tasks.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.talanta.2019.120664,Journal,Talanta,scopus,2020-04-01,sciencedirect,Modelling of bioprocess non-linear fluorescence data for at-line prediction of etanercept based on artificial neural networks optimized by response surface methodology,https://api.elsevier.com/content/abstract/scopus_id/85076829838,"In the last years, regulatory agencies in biopharmaceutical industry have promoted the design and implementation of Process Analytical Technology (PAT), which aims to develop rapid and high-throughput strategies for real-time monitoring of bioprocesses key variables, in order to improve their quality control lines. In this context, spectroscopic techniques for data generation in combination with chemometrics represent alternative analytical methods for on-line critical process variables prediction. In this work, a novel multivariate calibration strategy for the at-line prediction of etanercept, a recombinant protein produced in a mammalian cells-based perfusion process, is presented. For data generation, samples from etanercept processes were daily obtained, from which fluorescence excitation-emission matrices were generated in the spectral ranges of 225.0 and 495.0 nm and 250.0 and 599.5 nm for excitation and emission modes, respectively. These data were correlated with etanercept concentration in supernatant (measured by an off-line HPLC-based reference univariate technique) by implementing different chemometric strategies, in order to build predictive models. Partial least squares (PLS) regression evidenced a non-linear relation between signal and concentration when observing actual vs. predicted concentrations. Hence, a non-parametric approach was implemented, based on a multilayer perceptron artificial neural network (MLP). The MLP topology was optimized by means of the response surface methodology. The prediction performance of MLP model was superior to PLS, since the first is able to cope with non-linearity in calibration models, reaching percentage mean relative error in predictions of about 7.0% (against 12.6% for PLS). This strategy represents a fast and inexpensive approach for etanercept monitoring, which conforms the principles of PAT.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2019.11.018,Journal,Information Sciences,scopus,2020-04-01,sciencedirect,EHAUSM: An efficient algorithm for high average utility sequence mining,https://api.elsevier.com/content/abstract/scopus_id/85076715468,"Identifying high utility sequences in a quantitative sequence database is an important data mining task. However, a key problem of current approaches is that extensions of a high utility sequence often have a high utility. Hence, traditional techniques are often biased toward finding long patterns. To circumvent this problem, this paper proposes techniques for the problem of high average-utility sequence (HAUS) mining (
                        
                           H
                           A
                           U
                           S
                           M
                        
                     ). HAUSs are more meaningful than high utility sequences because the former are found using the average-utility measure, which consider the length of patterns in utility calculations. 
                        
                           H
                           A
                           U
                           S
                           M
                        
                      is more general than high average-utility itemset mining but it is also a more difficult problem because the downward-closure property used for search space reduction does not hold for the average-utility. To overcome that challenge, this paper introduces two upper bounds and a weak upper bound on the average-utility measure, and four width pruning, depth pruning, reducing, and tightening strategies. These strategies are designed to eliminate candidate HAUSs to speed up HAUS mining. Based on these theoretical results, a novel algorithm named EHAUSM is proposed for 
                        
                           H
                           A
                           U
                           S
                           M
                        
                     . Experiments on both real-life and synthetic quantitative sequence databases have confirmed its efficiency in terms of memory consumption and runtime.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2019.113083,Journal,Expert Systems with Applications,scopus,2020-04-01,sciencedirect,Real-time biomechanical modeling of the liver using Machine Learning models trained on Finite Element Method simulations,https://api.elsevier.com/content/abstract/scopus_id/85074768700,"The development of accurate real-time models of the biomechanical behavior of different organs and tissues still poses a challenge in the field of biomechanical engineering. In the case of the liver, specifically, such a model would constitute a great leap forward in the implementation of complex applications such as surgical simulators, computed-assisted surgery or guided tumor irradiation.
                  In this work, a relatively novel approach for developing such a model is presented. It consists in the use of a machine learning algorithm, which provides real-time inference, trained on tens of thousands of simulations of the biomechanical behavior of the liver carried out by the finite element method on more than 100 different liver geometries.
                  Considering a target accuracy threshold of 3 mm for the Euclidean Error, four different scenarios were modeled and assessed: a single liver with an arbitrary force applied (99.96% of samples within the accepted error range), a single liver with two simultaneous forces applied (99.84% samples in range), a single liver with different material properties and an arbitrary force applied (98.46% samples in range), and a much more general model capable of modeling the behavior of any liver with an arbitrary force applied (99.01% samples in range for the median liver).
                  The results show that the Machine Learning models perform extremely well on all the scenarios, managing to keep the Mean Euclidean Error under 1 mm in all cases. Furthermore, the proposed model achieves working frequencies above 100Hz on modest hardware (with frequencies above 1000Hz being easily achievable on more powerful GPUs) thus fulfilling the real-time requirements. These results constitute a remarkable improvement in this field and may involve a prompt implementation in clinical practice.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2019.105099,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-04-01,sciencedirect,Augmented reality navigation for liver resection with a stereoscopic laparoscope,https://api.elsevier.com/content/abstract/scopus_id/85073003483,"Objective
                  Understanding the three-dimensional (3D) spatial position and orientation of vessels and tumor(s) is vital in laparoscopic liver resection procedures. Augmented reality (AR) techniques can help surgeons see the patient's internal anatomy in conjunction with laparoscopic video images.
               
                  Method
                  In this paper, we present an AR-assisted navigation system for liver resection based on a rigid stereoscopic laparoscope. The stereo image pairs from the laparoscope are used by an unsupervised convolutional network (CNN) framework to estimate depth and generate an intraoperative 3D liver surface. Meanwhile, 3D models of the patient's surgical field are segmented from preoperative CT images using V-Net architecture for volumetric image data in an end-to-end predictive style. A globally optimal iterative closest point (Go-ICP) algorithm is adopted to register the pre- and intraoperative models into a unified coordinate space; then, the preoperative 3D models are superimposed on the live laparoscopic images to provide the surgeon with detailed information about the subsurface of the patient's anatomy, including tumors, their resection margins and vessels.
               
                  Results
                  The proposed navigation system is tested on four laboratory ex vivo porcine livers and five operating theatre in vivo porcine experiments to validate its accuracy. The ex vivo and in vivo reprojection errors (RPE) are 6.04 ± 1.85 mm and 8.73 ± 2.43 mm, respectively.
               
                  Conclusion and Significance
                  Both the qualitative and quantitative results indicate that our AR-assisted navigation system shows promise and has the potential to be highly useful in clinical practice.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2019.105019,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-04-01,sciencedirect,Automatic diagnosis of fungal keratitis using data augmentation and image fusion with deep convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85070552720,"Background and objectives
                  Fungal keratitis is caused by inflammation of the cornea that results from infection by fungal organisms. The lack of an early effective diagnosis often results in serious complications even blindness. Confocal microscopy is one of the most effective methods in the diagnosis of fungal keratitis, but the diagnosis depends on the subjective judgment of medical experts.
               
                  Methods
                  To address this problem, this paper proposes a novel convolutional neural network framework for the automatic diagnosis of fungal keratitis using data augmentation and image fusion. Firstly, a normal image is augmented by flipping to solve the problem of having a limited and imbalanced database. Secondly, a sub-area contrast stretching algorithm is proposed for image preprocessing to highlight the key structures in the images and to filter out irrelevant information. Thirdly, the histogram matching fusion algorithm is implemented, then the preprocessed image is fused with the original image to form a new algorithm framework and a new database. Finally, the traditional convolutional neural network is integrated into the novel algorithm framework to perform the experiments.
               
                  Results
                  Experiments show that the accuracy of traditional AlexNet and VGGNet is 99.35% and 99.14%, that of AlexNet and VGGNet based on MF fusion is 99.80% and 99.83%, and that of AlexNet and VGGNet based on histogram matching fusion (HMF) is 99.95% and 99.89%. The experimental results show that the AlexNet framework using data augmentation and image fusion achieves a perfect trade-off between the diagnostic performance and the computational complexity, with a diagnostic accuracy of 99.95%.
               
                  Conclusions
                  These experimental results demonstrate the novel convolutional neural network framework perfectly balances the diagnostic performance and computational complexity, and can improve the effect and real-time performance in the diagnosis of fungal keratitis.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ejor.2019.02.046,Journal,European Journal of Operational Research,scopus,2020-03-16,sciencedirect,Merging anomalous data usage in wireless mobile telecommunications: Business analytics with a strategy-focused data-driven approach for sustainability,https://api.elsevier.com/content/abstract/scopus_id/85063225278,"Mobile internet usage has exploded with the mass popularity of smartphones that offer more convenient and efficient ways of doing anything from watching movies, playing games, and streaming music. Understanding the patterns of data usage is thus essential for strategy-focused data-driven business analytics. However, data usage has several unique stylized facts (such as high dimensionality, heteroscedasticity, and sparsity) due to a great variety of user behaviour. To manage these facts, we propose a novel density-based subspace clustering approach (i.e., a three-stage iterative optimization procedure) for intelligent segmentation of consumer data usage/demand. We discuss the characteristics of the proposed method and illustrate its performance in both simulation with synthetic data and business analytics with real data. In a field experiment of wireless mobile telecommunications for data-driven strategic design and managerial implementation, we show that our method is adequate for business analytics and plausible for sustainability in search of business value.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.amar.2020.100113,Journal,Analytic Methods in Accident Research,scopus,2020-03-01,sciencedirect,"Big data, traditional data and the tradeoffs between prediction and causality in highway-safety analysis",https://api.elsevier.com/content/abstract/scopus_id/85078666924,"The analysis of highway accident data is largely dominated by traditional statistical methods (standard regression-based approaches), advanced statistical methods (such as models that account for unobserved heterogeneity), and data-driven methods (artificial intelligence, neural networks, machine learning, and so on). These methods have been applied mostly using data from observed crashes, but this can create a problem in uncovering causality since individuals that are inherently riskier than the population as a whole may be over-represented in the data. In addition, when and where individuals choose to drive could affect data analyses that use real-time data since the population of observed drivers could change over time. This issue, the nature of the data, and the implementation target of the analysis imply that analysts must often tradeoff the predictive capability of the resulting analysis and its ability to uncover the underlying causal nature of crash-contributing factors. The selection of the data-analysis method is often made without full consideration of this tradeoff, even though there are potentially important implications for the development of safety countermeasures and policies. This paper provides a discussion of the issues involved in this tradeoff with regard to specific methodological alternatives and presents researchers with a better understanding of the trade-offs often being inherently made in their analysis.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.prro.2019.11.011,Journal,Practical Radiation Oncology,scopus,2020-03-01,sciencedirect,"Computed Tomography to Cone Beam Computed Tomography Deformable Image Registration for Contour Propagation Using Head and Neck, Patient-Based Computational Phantoms: A Multicenter Study",https://api.elsevier.com/content/abstract/scopus_id/85078045320,"Purpose
                  To investigate the performance of various algorithms for deformable image registration (DIR) for propagating regions of interest (ROIs) using multiple commercial platforms, from computed tomography to cone beam computed tomography (CBCT) and megavoltage computed tomography.
               
                  Methods and Materials
                  Fourteen institutions participated in the study using 5 commercial platforms: RayStation (RaySearch Laboratories, Stockholm, Sweden), MIM (Cleveland, OH), VelocityAI and SmartAdapt (Varian Medical Systems, Palo Alto, CA), and ABAS (Elekta AB, Stockholm, Sweden). Algorithms were tested on synthetic images generated with the ImSimQA (Oncology Systems Limited, Shrewsbury, UK) package by applying 2 specific deformation vector fields (DVF) to real head and neck patient datasets. On-board images from 3 systems were used: megavoltage computed tomography from Tomotherapy and 2 kinds of CBCT from a clinical linear accelerator. Image quality of the system was evaluated. The algorithms’ accuracy was assessed by comparing the DIR-mapped ROIs returned by each center with those of the reference, using the Dice similarity coefficient and mean distance to conformity metrics. Statistical inference on the validation results was carried out to identify the prognostic factors of DIR performance.
               
                  Results
                  Analyzing 840 DIR-mapped ROIs returned by the centers, it was demonstrated that DVF intensity and image quality were significant prognostic factors of DIR performance. The accuracy of the propagated contours was generally high, and acceptable DIR performance can be obtained with lower-dose CBCT image protocols.
               
                  Conclusions
                  The performance of the systems proved to be image quality specific, depending on the DVF type and only partially on the platforms. All systems proved to be robust against image artifacts and noise, except the demon-based software.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ast.2019.105657,Journal,Aerospace Science and Technology,scopus,2020-03-01,sciencedirect,Reinforcement learning in dual-arm trajectory planning for a free-floating space robot,https://api.elsevier.com/content/abstract/scopus_id/85077502803,"A free-floating space robot exhibits strong dynamic coupling between the arm and the base, and the resulting position of the end of the arm depends not only on the joint angles but also on the state of the base. Dynamic modeling is complicated for multiple degree of freedom (DOF) manipulators, especially for a space robot with two arms. Therefore, the trajectories are typically planned offline and tracked online. However, this approach is not suitable if the target has relative motion with respect to the servicing space robot. To handle this issue, a model-free reinforcement learning strategy is proposed for training a policy for online trajectory planning without establishing the dynamic and kinematic models of the space robot. The model-free learning algorithm learns a policy that maps states to actions via trial and error in a simulation environment. With the learned policy, which is represented by a feedforward neural network with 2 hidden layers, the space robot can schedule and perform actions quickly and can be implemented for real-time applications. The feasibility of the trained policy is demonstrated for both fixed and moving targets.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.entcom.2019.100336,Journal,Entertainment Computing,scopus,2020-03-01,sciencedirect,Smart Reckoning: Reducing the traffic of online multiplayer games using machine learning for movement prediction,https://api.elsevier.com/content/abstract/scopus_id/85077019240,"Massively Multiplayer Online Game (MMOG) players maintain consistent views of the positions of each other by periodically exchanging messages. Besides the fact that these messages can suffer delays that cause rendering inconsistencies, they also represent an overhead on the network. This overhead can be significant, as the number of MMOG players is very large, but reducing the number of messages is not trivial. The classic strategy to predict movement avoiding message exchange is based on the Dead Reckoning algorithm, which has several limitations. Other strategies have been proposed more recently that improve the results, but rely on expert knowledge. In this work we propose Smart Reckoning, a movement prediction strategy based on machine learning. The strategy consists of two phases. In the first phase, a learning model classifies whether the classical Dead Reckoning algorithm is able to predict the new avatar position correctly or not. In case the conclusion is negative, another learning model is used to predict the new direction. The proposed strategy was applied to the World of Warcraft game. The learning models were implemented with the Weka tool using real game trace data, and results are presented for the accuracy of multiple algorithms.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.envres.2019.109024,Journal,Environmental Research,scopus,2020-03-01,sciencedirect,An efficient tool for the continuous monitoring on adsorption of sub-ppm level gaseous benzene using an automated analytical system based on thermal desorption-gas chromatography/mass spectrometry approach,https://api.elsevier.com/content/abstract/scopus_id/85076492466,"It became an important task to effectively adsorb volatile organic compounds (VOCs) at or near real-world levels for efficient control of airborne pollution in ambient environments. Nonetheless, most studies carried out previously for the control of VOCs are confined to significantly polluted conditions (e.g., >100 ppm) that are far different from real-world or ambient conditions. To help acquire the meaningful data for the adsorptive removal of VOCs at near real-world levels, a new approach was designed and implemented to measure adsorption of gaseous benzene (as a representative or model VOC) at trace-level quantities (as low as 0.14 ng (0.43 ppb) for a 100 mL sample) using activated carbon (sieved to 212 μm mesh size) as a model sorbent. With the aid of a thermal desorption-gas chromatography/mass spectrometry system, the key adsorption performance metrics (such as 10% breakthrough volume (10% BTV) points: 10% as the key reference) were determined: 1018 L atm g−1 at 0.1 ppm benzene with the corresponding partition coefficient of 3.85 mol kg−1 Pa−1. If the adsorption capacity values (at 10% BTV) are compared across the varying concentration levels of benzene, the maximum value of 1.07 mg g−1 was observed at 1 ppm benzene (within the concentration range selected in this work). As such, it was possible to quantitatively assess the sorbate-sorbent interactions at significantly low concentrations of VOCs that actually prevail under the near real-world conditions.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.actaastro.2019.11.037,Journal,Acta Astronautica,scopus,2020-03-01,sciencedirect,Pattern recognition in time series for space missions: A rosetta magnetic field case study,https://api.elsevier.com/content/abstract/scopus_id/85076239823,"Time series analysis is a technique widely employed in space science. In unpredictable environments like space, scientific analysis relies on large data sets to enable interpretation of observations. Artificial signal interferences caused by the spacecraft itself further impede this process. The most time consuming part of these studies is the efficient identification of recurrent pattern in observations, both of artificial and natural origin, often forcing researchers to limit their analysis to a reduced set of observations. While pattern recognition techniques for time series are well known, their application is discussed and evaluated primarily on purpose built or heavily preprocessed data sets. The aim of this paper is to evaluate the performance of state of the art pattern recognition techniques in terms of computational efficiency and validity on a real-life testcase. For this purpose the most suitable techniques for different types of pattern are discussed and subsequently evaluated on various hardware in comparison to manual identification. Using magnetic field observations of the ESA Rosetta mission as a representative example, both disturbances and natural patterns are identified. Compared to manual selection a speed-up of a factor up to 100 is achieved, with values for recall and precision above 80%. Moreover, the detection process is fully automated and reproducible. Using the presented method it was possible to detect and correct artificial interference. Finally, the feasibility of onboard deployment is briefly discussed.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2019.105132,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-03-01,sciencedirect,Virtual reality-based measurement of ocular deviation in strabismus,https://api.elsevier.com/content/abstract/scopus_id/85073938186,"Background and objective
                  Strabismus is an eye movement disorder in which shows the abnormal ocular deviation. Cover tests have mainly been used in the clinical diagnosis of strabismus for treatment. However, the whole process depends on the doctor's level of experience, which could be subjected to several factors. In this study, an automated technique for measurement of ocular deviation using a virtual reality (VR) device is developed.
               
                  Methods
                  A VR display system in which the screens that have the fixation target are changed alternately between on and off stages is used to simulate the normal strabismus diagnosis steps. Patients watch special-designed 3D scenes, and their eye motions are recorded by two infrared (IR) cameras. An image-processing-based pupil tracking technique is then applied to track their eye movement. After recording eye motion, two strategies for strabismus angle estimation are implemented: direct measurement and stepwise approximation. The direct measurement converts the eye movement to a strabismus angle after considering the eyeball diameter, while the stepwise approximation measures the ocular deviation through the feedback calibration process.
               
                  Results
                  Experiments are carried out with various strabismus patients. The results are compared to those of their doctors’ measurement, which shows good agreement.
               
                  Conclusions
                  The results clearly indicate that these techniques could identify ocular deviation with high accuracy and efficiency. The proposed system can be applied in small space and has high tolerance for the unexpected head movements compared with other camera-based system.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.renene.2019.09.092,Journal,Renewable Energy,scopus,2020-03-01,sciencedirect,Wind turbine fatigue reduction based on economic-tracking NMPC with direct ANN fatigue estimation,https://api.elsevier.com/content/abstract/scopus_id/85072713179,"The aim of this work is to deploy an advanced Nonlinear Model Predictive Control (NMPC) approach for reducing the tower fatigue of a wind turbine (WT) tower while guaranteeing efficient energy extraction from the wind. To achieve this, different Artificial Neural Network (ANN) architectures are trained and tested in order to estimate the tower fatigue as a surrogate of the traditional Rainflow Counting (RFC) method. The ANNs receive data stemming from the tower top oscillation velocity and the previous fatigue state to directly estimate the fatigue progression. The results are compared to select the most convenient architecture for control implementation. Once an ANN is selected, an economic-tracking NMPC (etNMPC) solution to reduce the fatigue of the WT tower is deployed in real-time. The closed-loop results are then compared to a baseline controller from a renowned WT simulation tool and a classic etNMPC implementation with indirect fatigue minimisation to demonstrate the improvement achieved with the proposed strategy. Finally, conclusions regarding computational cost and real-time deployment capabilities are discussed, as well as future lines of research.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2019.105308,Journal,Knowledge-Based Systems,scopus,2020-02-29,sciencedirect,An OWA-based hierarchical clustering approach to understanding users’ lifestyles,https://api.elsevier.com/content/abstract/scopus_id/85076253160,"Based on users’ interactions with social networks, a method to understand users’ life-styles is developed. Descriptions of their lifestyles are obtained from previously reported experiences on these sites. Contextual information and contributed reviews lend insight into which elements are important for different lifestyles. In this paper, an ordered weighted averaging operator (OWA) is integrated with hierarchical clustering in order to find the similarity between users and clusters. Specifically, a two step measure is defined to compare and aggregate two clusters. To illustrate the efficiency of the methodology, a real case is implemented for 499 Yelp reviewers associated with 134,102 reviews across 11 variables and 373 Airbnb reviewers associated with 1,826 reviews across 14 variables.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.apenergy.2019.114232,Journal,Applied Energy,scopus,2020-02-15,sciencedirect,Greedy search based data-driven algorithm of centralized thermoelectric generation system under non-uniform temperature distribution,https://api.elsevier.com/content/abstract/scopus_id/85076006670,"The generation efficiency of thermoelectric generation system is relatively low, thus how maximize its power production is of great importance. This paper designs a novel greedy search based data-driven method for centralized thermoelectric generation system to achieve maximum power point tracking under non-uniform temperature distribution. In order to effectively distinguish the local maximum power points and the global maximum power point under non-uniform temperature distribution, greedy search based data-driven employs a two-layer feed-forward neural network to accurately fit the curve between the power output and the controllable variable based on the real-time updated operation data. Based on the approximation curve, a greedy search is designed to efficiently approach the global maximum power point from a shrinking search space. Cases studies such as start-up test, step variation of temperature, stochastic temperature change, and analyse of sensitivity, are implemented to prove the effectiveness and superiority of the proposed algorithm. Simulation results verify that the proposed method can generate the highest energy under non-uniform temperature distribution condition, e.g., 391.34%, 115.71%, 110.92%, and 109.43% to that of perturb and observe, particle swarm optimization, whale optimization algorithm, and grey wolf optimizer in the stochastic temperature change. Lastly, the implementation feasibility of the proposed method is demonstrated by the hardware-in-the-loop experiment based on dSpace platform.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.physa.2019.123151,Journal,Physica A: Statistical Mechanics and its Applications,scopus,2020-02-15,sciencedirect,Early warning system: From face recognition by surveillance cameras to social media analysis to detecting suspicious people,https://api.elsevier.com/content/abstract/scopus_id/85074532417,"Surveillance security cameras are increasingly deployed in almost every location for monitoring purposes, including watching people and their actions for security purposes. For criminology, images collected from these cameras are usually used after an incident occurs to analyze who could be the people involved. While this usage of the cameras is important for a post crime action, there exists the need for real time monitoring to act as an early warning to prevent or avoid an incident before it occurs. In this paper, we describe the development and implementation of an early warning system that recognizes people automatically in a surveillance camera environment and then use data from various sources to identify these people and build their profile and network. The current literature is still missing a complete workflow from identifying people/criminals from a video surveillance to building a criminal information extraction framework and identifying those people and their interactions with others We train a feature extraction model for face recognition using convolutional neural networks to get a good recognition rate on the Chokepoint dataset collected using surveillance cameras. The system also provides the function to record people appearance in a location, such that unknown people passing through a scene excessive number of times (above a threshold decided by a security expert) will then be further analyzed to collect information about them. We implemented a queue based system to record people entrance. We try to avoid missing relevant individuals passing through as in some cases it is not possible to add every passing person to the queue which is maintained using some cache handling techniques. We collect and analyze information about unknown people by comparing their images from the cameras to a list of social media profiles collected from Facebook and intelligent services archives. After locating the profile of a person, traditional news and other social media platforms are crawled to collect and analyze more information about the identified person. The analyzed information is then presented to the analyst where a list of keywords and verb phrases are shown. We also construct the person’s network from individuals mentioned with him/her in the text. Further analysis will allow security experts to mark this person as a suspect or safe. This work shows that building a complete early warning system is feasible to tackle and identify criminals so that authorities can take the required actions on the spot.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.physa.2019.123174,Journal,Physica A: Statistical Mechanics and its Applications,scopus,2020-02-15,sciencedirect,Fake news detection within online social media using supervised artificial intelligence algorithms,https://api.elsevier.com/content/abstract/scopus_id/85074460484,"Along with the development of the Internet, the emergence and widespread adoption of the social media concept have changed the way news is formed and published. News has become faster, less costly and easily accessible with social media. This change has come along with some disadvantages as well. In particular, beguiling content, such as fake news made by social media users, is becoming increasingly dangerous. The fake news problem, despite being introduced for the first time very recently, has become an important research topic due to the high content of social media. Writing fake comments and news on social media is easy for users. The main challenge is to determine the difference between real and fake news. In this paper, a two-step method for identifying fake news on social media has been proposed, focusing on fake news. In the first step of the method, a number of pre-processing is applied to the data set to convert un-structured data sets into the structured data set. The texts in the data set containing the news are represented by vectors using the obtained TF weighting method and Document-Term Matrix. In the second step, twenty-three supervised artificial intelligence algorithms have been implemented in the data set transformed into the structured format with the text mining methods. In this work, an experimental evaluation of the twenty-three intelligent classification methods has been performed within existing public data sets and these classification models have been compared depending on four evaluation metrics.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2019.105277,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-02-01,sciencedirect,An extensible software platform for interdisciplinary cardiovascular imaging research,https://api.elsevier.com/content/abstract/scopus_id/85076945151,"Background and objective
                  Cardiovascular imaging is an exponentially growing field with aspects ranging from image acquisition and analysis to disease characterization, and evaluation of therapy approaches.The transfer of innovative new technological and algorithmic solutions into clinical practice is still slow. In addition to the verification of solutions, their integration in the clinical processing workflow must be enabled for the assessment of clinical impact and risks. The goal of our software platform for cardiac image processing – CAIPI – is to support researchers from different specialties such as imaging physics, computer science, and medicine by a common extensible platform to address typical challenges and hurdles in interdisciplinary cardiovascular imaging research. It provides an integrated solution for method comparison, integrated analysis, and validation in the clinical context. The interface concept enables a combination with existing frameworks that address specific aspects of the pipeline, such as modeling (e.g., OpenCMISS, CARP) or image reconstruction (Gadgetron).
               
                  Methods
                  In our platform, we developed a concept for import, integration, and management of cardiac image data. The integration approach considers the spatiotemporal properties of the beating heart through a specific data model. The solution is based on MeVisLab and provides functionalities for data retrieval and storage. Two types of plugins can be added. While ToolPlugins usually provide processing algorithms such as image correction and segmentation, AnalysisPlugins enable interactive data exploration and reporting. GUI integration concepts are presented for both plugin types. We developed domain-specific reporting and visualization tools (e.g., AHA segment model) to enable validation studies by clinical experts. The platform offers plugins for calculating and reporting quantitative parameters such as cardiac function, which can be used to, e.g., evaluate the effect of processing algorithms on clinical parameters. Export functionalities include quantitative measurements to Excel, image data to PACS, and STL models to modeling and simulation tools.
               
                  Results
                  To demonstrate the applicability of this concept both for method development and clinical application, we present use cases representing different problems along the innovation chain in cardiac MR imaging.
                  Validation of an image reconstruction method (MRI T1 mapping)
                  Validation of an image correction method for real-time 2D-PC MRI
                  Comparison of quantification methods for blood flow analysis
                  Training and integration of machine learning solutions with expert annotations
                  Clinical studies with new imaging techniques (flow measurements in the carotid arteries and peripheral veins as well as cerebral spinal fluid).
               
                  Conclusion
                  The presented platform can be used in interdisciplinary teams, in which engineers or data scientists perform the method validation, followed by clinical research studies in patient collectives. The demonstrated use cases show how it enables the transfer of innovations through validation in the cardiovascular application context.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cie.2019.106225,Journal,Computers and Industrial Engineering,scopus,2020-02-01,sciencedirect,Fuzzy possibility regression integrated with fuzzy adaptive neural network for predicting and optimizing electrical discharge machining parameters,https://api.elsevier.com/content/abstract/scopus_id/85076689961,"An electrical discharge machining (EDM) is one of the special production methods that are widely used in moldings, repairs and production of specific industrial components. Due to extensive production costs, optimal machining specifications are significant. Machining specifications are effective on output quality and thus attract more customers leading to higher profits. In this study, the impact of EDM parameters on surface roughness, material removal rate and electrode corrosion percentage have been investigated. In order to consider uncertainty of real production environments, the fuzzy theory is employed. Also, using the design of experiment (DOE) parameters calibration is performed and mathematical programming approach is applied for optimization purpose. The relationship between the machining parameters and the output process specification is examined by a fuzzy possibility regression model. Then, the mathematical relation of exact inputs and fuzzy outputs of the EDM process are extracted. The effectiveness of the three outputs is evaluated by interfacing models and fuzzy hypothesis testing. To determine the optimal levels of each output, a fuzzy adaptive neural network is used and appropriate models are prepared to be adapted with a fitted model of fuzzy possibility regression for comparison purposes. Validation tests imply the effectiveness of the proposed method. The integrated model is implemented in real case study. The results show that, fitted models can predict the material removal rate, surface fineness, and corrosion percentage of the electrode. The prediction accuracy of the proposed method is shown in comparison with the optimal fuzzy adaptive neural network outputs considering error value. Also, the proposed method is successful in identifying the optimal process parameters for EDM with reliable accuracy. The proposed integrated prediction and optimization model can be used as a calibration decision support in production systems to handle dynamic data structures and provide real time machining specifications to increase the output quality.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.breast.2019.10.001,Journal,Breast,scopus,2020-02-01,sciencedirect,"The ethical, legal and social implications of using artificial intelligence systems in breast cancer care",https://api.elsevier.com/content/abstract/scopus_id/85074099299,"Breast cancer care is a leading area for development of artificial intelligence (AI), with applications including screening and diagnosis, risk calculation, prognostication and clinical decision-support, management planning, and precision medicine. We review the ethical, legal and social implications of these developments. We consider the values encoded in algorithms, the need to evaluate outcomes, and issues of bias and transferability, data ownership, confidentiality and consent, and legal, moral and professional responsibility. We consider potential effects for patients, including on trust in healthcare, and provide some social science explanations for the apparent rush to implement AI solutions. We conclude by anticipating future directions for AI in breast cancer care. Stakeholders in healthcare AI should acknowledge that their enterprise is an ethical, legal and social challenge, not just a technical challenge. Taking these challenges seriously will require broad engagement, imposition of conditions on implementation, and pre-emptive systems of oversight to ensure that development does not run ahead of evaluation and deliberation. Once artificial intelligence becomes institutionalised, it may be difficult to reverse: a proactive role for government, regulators and professional groups will help ensure introduction in robust research contexts, and the development of a sound evidence base regarding real-world effectiveness. Detailed public discussion is required to consider what kind of AI is acceptable rather than simply accepting what is offered, thus optimising outcomes for health systems, professionals, society and those receiving care.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.talanta.2019.120446,Journal,Talanta,scopus,2020-02-01,sciencedirect,Paper-based colorimetric spot test utilizing smartphone sensing for detection of biomarkers,https://api.elsevier.com/content/abstract/scopus_id/85073026488,"The need for a continuous, real-time monitoring of specific diseases represents an unmet scientific need. Evidently, cancer is one of the most important diseases where it is crucial to increase the rates of patient survival and monitor disease prognosis. Herein, a novel type of immunoassay was developed for detection of cancer biomarkers, using alpha-fetoprotein (AFP) and mucin-16 (MUC16) as model analytes. Using gold nanoparticle (AuNP) bioconjugates as a signal production tool, relevant antibody (Ab)-conjugated AuNPs were prepared on the nitrocellulose (NC) membrane. To construct a spot-like point-of-care (POC) immunoassay, cysteamine conjugated AuNPs (AuNP-Cys) were immobilized on the NC membrane and antibodies were conjugated to the nanoparticle on the detection pad, following a treatment with the samples that contains AFP or MUC16 which are well-known protein biomarkers for liver and ovarian cancer. By using the change in the colorimetric properties of AuNPs, detection of tumor markers was achieved by using a smartphone image and color analysis software at the final stage. Image J application was used for the evaluation of color changes depending on the biomarker concentration in buffer or spiked synthetic serum samples. The linear range was found as 0.1 ng/mL-100 ng/mL for AFP and 0.1–10 ng/mL for MUC16. Limit-of-detection (LOD) was calculated as 1.054 ng/mL and 0.413 ng/mL for AFP and MUC16, respectively. Interferent molecules, Her2, Immunoglobulin G (IgG) and bovine serum albumin (BSA) were tested on the system. Furthermore, synthetic serum samples spiked with selected analyte molecule were applied on the system and measured successfully.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.chb.2019.09.008,Journal,Computers in Human Behavior,scopus,2020-02-01,sciencedirect,A collaborative working model for enhancing the learning process of science &amp; engineering students,https://api.elsevier.com/content/abstract/scopus_id/85072768570,"Science and engineering education are mostly based on content assimilation and development of skills. However, to adequately prepare students for today's world, it is also necessary to stimulate critical thinking and make them reflect on how to improve current practices using new tools and technologies. In this line, the main motivation of this research consists in exploring ways supported by technology to enhance the learning process of students and to better prepare them to face the challenges of today's world. To this end, the purpose of this work is to design an innovative learning project based on collaborative work among students, and research its impact in achieving better learning outcomes, generating of collective intelligence and further motivation. The proposed collaborative working model is based on peer review assessment methodology implemented through a learning web-platform. Thus, students were encouraged to peer review their classmates' works. They had to make comments, suggest improvements, and assess final assignments. Teaching staff managed and supervised the whole process. Students were selected from computer science engineering at the University of Alicante (Spain). Results suggested greater content assimilation and enhanced learning in several scientific skills. The students' final grade exceeded what any student could produce individually, but we cannot conclude that real collective intelligence was generated. Learning methodologies based on the possibilities of Information and Communication Technologies (ICT) provide new ways to transmit and manage knowledge in higher education. Collaborating in peer assessment enhances the students' motivation and promotes the active learning. In addition, this method can be very helpful and time saving for instructors in the management of large groups.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2019.07.015,Journal,Knowledge-Based Systems,scopus,2020-01-05,sciencedirect,User intimacy model for question recommendation in community question answering,https://api.elsevier.com/content/abstract/scopus_id/85069593237,"In this paper, we address the problem of automatic recommendation of new questions to suitable users in community question answering (CQA). The major challenge is the accurate selection of suitable users to answer a given question. Most approaches seek suitable users for a question by estimating their capability, interests or a blend of both. However, this ignores intimacy between the user and the asker of a question over different topics. Intimacy between askers and answerers is an important factor in question recommendation. For example, a user is likely to post an answer if interested in a question and intimate with its asker. We propose to model and learn intimacy between users over topics with social interaction in CQA for question recommendation using a novel topic model. We believe this paper is the first to estimate the intimacy between users over different topics and investigate influences on the performance of question recommendation in CQA. We propose a user intimacy model (UIM), an LDA-style model that incorporates social interaction in the generative process of a question-answer (QA) pair to model and learn intimacy between users over topics. Experiments using real-world data from Stack Overflow show that our UIM-based approach consistently and significantly improves the performance of question recommendation, demonstrating that our approach can increase question recommendation accuracy in CQA by utilizing the intimacy between users over topics and that this is an important factor in question recommendation.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2019.09.004,Journal,Neurocomputing,scopus,2020-01-02,sciencedirect,Digital neuromorphic real-time platform,https://api.elsevier.com/content/abstract/scopus_id/85072526243,"Hardware implementations of spiking neural networks in portable devices can improve many applications of robotics, neurorobotics or prosthetic fields in terms of power consumption, high-speed processing and learning mechanisms. Analog and digital platforms have been previously proposed to run these networks. Analog designs are closer to biology since they implement the original mathematical model. However, digital platforms are, to some extent, abstractions of this model so far. In this paper, a full digital platform to design, implement and run real-time analog-like spiking neural networks is presented. Specifically, we present the design and implementation of digital circuits to run real-time biologically plausible spiking neural networks on a Field Programmable Gate Array (FPGA). The circuit designed for the neuron implements the Leaky Integrate and Fire (LIF) model. The synapsis implemented is a bi-exponential current-based one. The synaptic circuit design consists of one static memory with the baseline current and a dynamic memory which stores the updated contribution over time of each pre-synaptic connection. All the parameters of both the neuron and the synapse are configurable. The results of the circuits are validated by running the same experiments on the Brian simulator. The circuits, which are totally original and independent of the technology, use only 136 slice registers of hardware resources. Thus, these designs allow the scale of the network. These circuits aim to be the basis of the spiking neural networks on digital devices. This platform allows the user to first simulate their network within the Brian simulator and then, confidently, move to the hardware platform replicating the same performance or even replace their analog platform with the digital one.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-814675-0.00015-4,Book,Tree Kangaroos: Science and Conservation,scopus,2020-01-01,sciencedirect,"Investigating Matschie’s Tree Kangaroos With ‘Modern’ Methods: Digital Workflows, Big Data Project Infrastructure, and Mandated Approaches for a Holistic Conservation Governance",https://api.elsevier.com/content/abstract/scopus_id/85126412284,"Matschie's tree kangaroo (also known as Huon tree kangaroo Dendrolagus matschiei) is only found in the Huon Peninsula of Papua New Guinea and is poorly understood. Essential metrics like science-based habitat maps or abundance and distribution estimates are missing in a reliable large-scale fashion. While the Matschie's tree kangaroo is an ancient but cryptic species and understandably difficult to investigate due to the difficulty in accessing its habitat, the statuses of many tropical communities worldwide are likewise in equal dire need of urgent, science-based conservation management. Available modern study methods are presented and readily available for use for inference in order to help safeguard this species in a very complex socio-economic environment. Those concepts cover geographic information systems (GIS) – open source and commercial software – and (digital) database techniques, different information sources including available open access data in the Global Biodiversity Information Facility website and the relevance of citizen science. Linked with many publicly available GIS and Remote Sensing layers freely available online ‘in the cloud’, data mining is discussed using ‘latest’ and ‘best’ AI and Machine Learning ensembles, namely stochastic boosting and bagging. A standardized predictive modeling workflow is suggested to show how such methods can help obtain more reliable and updated online status-reports in real-time for this species and its habitats. The evolution of field database delivery, international data sharing online, GIS, software algorithms, cloud computing, workflows, and ISO-compliant metadata is set in context with conservation progress and sustainable landscapes worldwide. This will better serve nations, their people, and ancient livelihoods in an otherwise globally operating and highly complicated telecoupled supply chain that currently marginalizes the environment.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2020.12.1251,Conference Proceeding,IFAC-PapersOnLine,scopus,2020-01-01,sciencedirect,A Framework for Ethics in Cyber-Physical-Human Systems,https://api.elsevier.com/content/abstract/scopus_id/85113481995,"This paper proposes a conceptual framework for consideration of ethical issues in the emerging category of smart cyber-physical systems. Cyber-physical systems (CPS) that bring together controls, communications, computing, and physical systems are being developed in a wide variety of application domains ranging from transportation, energy, and manufacturing, to biomedical and agriculture. Smart CPS are already being and will increasingly be deployed to work with humans, in workplaces, homes, or public spaces, resulting in the creation of cyber-physical human systems (CPHS). Ethical issues in smart CPS and CPHS can be examined within the larger frameworks of ethics of technology and ethics of artificial intelligence. We begin with a description of trends and visions for the future development of smart CPS. We next outline fundamental theories of ethics that offer foundations for thinking about ethical issues in smart CPHS. We argue that it is necessary to fight the tendency toward technological determinism. We argue that in analyzing ethics of smart CPHS, we need to anticipate increasing capabilities and the future deployment of such systems. Ultimately, if these systems are widely deployed in society, they will have a very significant impact, including possible negative consequences, on individuals, communities, nations, and the world. Our framework has two main dimensions: (i) stage of development of CPHS domain from early stage research to mature technologies; and (ii) locus of decision making: individual, corporate, and government settings. We illustrate the framework with some specific examples.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2021.04.197,Conference Proceeding,IFAC-PapersOnLine,scopus,2020-01-01,sciencedirect,Cognitive Artificial Population System: Framework and Application,https://api.elsevier.com/content/abstract/scopus_id/85107879835,"Agent-based social simulation has been comprehensively applied in the research of social and ecological systems. At its core is an artificial population, which endogenously drives the system evolution for particular applications, such as urban transportation, reginal economics, analysis of infectious disease transmission, and military simulation. In contrast with the previous population simulations where simple mathematical models are used to ‘reproduce’ actual demographic features, this paper proposes a self-evolutionary digital population system, named as Cognitive Artificial Population System (CAPS). At a more fine-grained level, CAPS focuses on the agent cognitive, reasoning and learning process in their surrounding environment, thus can exploit most advantages from cognitive computing and Artificial Intelligence. As a case study, Chinese population evolution is implemented using the proposed framework. Computational experiments indicate that CAPS is able to achieve good predicted population structures for real social systems.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-819445-4.00007-2,Book,"Cognitive Informatics, Computer Modelling, and Cognitive Science: Volume 2: Application to Neural Engineering, Robotics, and STEM",scopus,2020-01-01,sciencedirect,Application of virtual reality systems to psychology and cognitive neuroscience research,https://api.elsevier.com/content/abstract/scopus_id/85103705213,"With the advancement of virtual reality, it is extensively used in the field of the cognitive neuroscience. They are used by many numbers of developers and researchers for the visualization of behavioral aspects of individuals with the help of programing in it. With the help of the virtual reality, things such as heartbeats, eye tracking, and gaming are visualized based on users’ emotional capability through spatial navigation techniques and anxiety disorder technique and others. The actions are visualized with the help of various tools creating a library of three-dimensional models. The Graphical User interface (GUI) and the custom systems differ on the level of their interaction and utility. Those are implemented using python, reducing the level of complexity for a user. The outcomes can be improved by the help of the principles like Artificial Intelligence and deep learning",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2020.07.006,Conference Proceeding,Procedia CIRP,scopus,2020-01-01,sciencedirect,Operator support in human-robot collaborative environments using AI enhanced wearable devices,https://api.elsevier.com/content/abstract/scopus_id/85100836551,"Nowadays, in order to cover the needs of market for product mass customization, industries have started to move to hybrid production cells, involving both robots and human operators. Research has been done during previous years to promote and improve the collaboration between humans and robots, trying to address topics such as safety, awareness and cognitive support in form of Augmented Reality based instructions. Results of previous research show bottlenecks related to the way of interaction of the operators with such supportive systems though. Direct interaction approach with the use of push buttons or indirect-gesture based interaction, which are most often adopted by the researchers, require operators to constantly occupy their hands performing the relevant button presses or gestures. Moreover, previous approaches are hardware dependent and need a lot of customization to work with different hardware. This work tries to address these bottlenecks proposing the usage of wearable devices enhanced with AI in order to support the interaction of human operators with robots in human-robot collaborative environments in a seamless and non-intrusive way, wrapped around a framework called “Operator Support Module” (OSM). Among others, OSM supports a variety of hardware to easily fit in various industrial scenarios. Two case studies will be presented to demonstrate the approach.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.promfg.2020.11.012,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,Application of machine learning and vision for real-time condition monitoring and acceleration of product development cycles,https://api.elsevier.com/content/abstract/scopus_id/85100766330,"Development work within an experimental environment, in which certain properties are investigated and optimized, requires many test runs and is therefore often associated with long execution times, costs and risks. This can affect product, material and technology development in industry and research. New digital driver technologies offer the possibility to automate complex manual work steps in a cost-effective way, to increase the relevance of the results and to accelerate the processes many times over. In this context, this article presents a low-cost, modular and open-source machine vision system for test execution and evaluates it on the basis of a real industrial application. For this purpose a methodology for the automated execution of the load intervals, the process documentation and for the evaluation of the generated data by means of machine learning to classify wear levels. The software and the mechanical structure are designed to be adaptable to different conditions, components and for a variety of tasks in industry and research. The mechanical structure is required for tracking the test object and represents a motion platform with independent positioning by machine vision operators or machine learning. An evaluation of the state of the test object is performed by the transfer learning after the initial documentation run. The manual procedure for classifying the visually recorded data on the state of the test object is described for the training material. This leads to an increased resource efficiency on the material as well as on the personnel side since on the one hand the significance of the tests performed is increased by the continuous documentation and on the other hand the responsible experts can be assigned time efficiently. The presence and know-how of the experts are therefore only required for defined and decisive events during the execution of the experiments. Furthermore, the generated data are suitable for later use as an additional source of data for predictive maintenance of the developed object.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.promfg.2020.05.123,Conference Proceeding,,scopus,2020-01-01,sciencedirect,Integrated tool condition monitoring systems and their applications: A comprehensive review,https://api.elsevier.com/content/abstract/scopus_id/85095576577,"In conventional metal cutting, different tool wear modes, and their individual deterioration rates play vital roles in overall production performance. For a given tool (i.e., geometry or materials), many shop floors still follow a standard rule by pre-setting a tool life, which is conservative but not realistic. Premature failure of a tool can cause unexpected machine downtime and material losses, while another tool could serve beyond that pre-set life. As a result, optimized tool life and productivity cannot be achieved. Moreover, nowadays, there is an increased demand of process monitoring and optimization on the unmanned and the semi-automated shop floors.
                  Tool condition monitoring (TCM) systems for process improvement and optimization have been in research for several decades. Both offline and online TCM systems are invented and discussed. A wide range of original publications are reported focusing on different sub-topics, e.g., specific machining process-based TCM methods, measurement or signal acquisition methods, processing methods, and classifiers. With the recent evolution of smart sensors in the era of Industry 4.0, development of online TCM systems received much attention to the researchers. Accordingly, research on some sub-topics also gets motivated into different directions, such as, feasibility of power or current sensors, machine vision technique, and combination of multi-sensors. Thus, from the industrial viewpoint, the current state of implementation of the proposed TCM systems for (near) real-time process monitoring and control needs to be clear. This paper presents the state-of-the-art of the TCM systems covering three major machining operations, discusses their application feasibility in industry environments, and states some current TCMS implementations. Challenges being faced by the industry are concluded, along with direction and suggestions for future researches.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jksuci.2020.09.013,Journal,Journal of King Saud University - Computer and Information Sciences,scopus,2020-01-01,sciencedirect,Affect detection from arabic tweets using ensemble and deep learning techniques,https://api.elsevier.com/content/abstract/scopus_id/85095572698,"Affect detection from text has captured the attention of researchers recently. This is due to the rapid use of social media sites (e.g. Twitter, Facebook), which allows users to express their feelings, emotions, and thoughts in textual format. Analyzing emotion-rich textual data of social networks has many real-life applications. The context of an emotional text can be measured by analyzing certain features of this rich source of emotional information. Classifying text into emotional labels/intensities is considered a difficult problem. This paper resolves one of the state-of-the-art NLP research emotion and intensity detection tasks using Deep Learning and ensemble implementations. In this paper, we developed several innovative approaches; (a) bidirectional GRU_CNN (BiGRU_CNN), (b) conventional neural networks (CNN), and (c) XGBoost regressor (XGB). The ensemble of BiGRU_CNN, CNN, and XGB is used to solve an emotion intensity (EI-reg) task of the SemEval-2018 Task1 (Affect in Tweets). Our proposed ensemble approach was evaluated using a reference dataset of the SemEval-2018 Task1. Results show that our approach is well above the baseline for this task. It also achieved a Pearson of (69.2%), with an enhancement of 0.7% in comparison with previous best performing models.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2020.12.1188,Conference Proceeding,IFAC-PapersOnLine,scopus,2020-01-01,sciencedirect,Efficient calibration of embedded MPC,https://api.elsevier.com/content/abstract/scopus_id/85089860108,"Model Predictive Control (MPC) is a powerful and flexible design tool of high-performance controllers for physical systems in the presence of input and output constraints. A challenge for the practitioner applying MPC is the need of tuning a large number of parameters such as prediction and control horizons, weight matrices of the MPC cost function, and observer gains, according to different trade-offs. The MPC design task is even more involved when the control law has to be deployed to an embedded hardware unit endowed with limited computational resources. In this case, real-time implementation requirements limit the complexity of the applicable MPC configuration, giving rise to additional design tradeoffs and requiring to tune further parameters, such as the sampling time and the tolerances of the on-line numerical solver. To take into account closed-loop performance and real-time requirements, in this paper we tackle the embedded MPC design problem using a global, data-driven optimization approach. We showcase the potential of this approach by tuning an MPC controller on two hardware platforms characterized by largely different computational capabilities.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2020.04.220,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Design and Fabrication of SHRALA: Social Humanoid Robot Based on Autonomous Learning Algorithm,https://api.elsevier.com/content/abstract/scopus_id/85086626621,"This paper presents the preliminary research work in the Design, Fabrication of a Social Humanoid Robot based on Autonomous Learning Algorithm (SHRALA). Virtual Model of the humanoid robot was developed using Solidworks environment. This model is then fabricated using Creality Ender-3 3D printer. The electronic control circuit was designed and interfaced to computer using ATMEGA 2650 controller board, based on 8-bit AVR microcontroller. In order to easily and efficiently control the SHRALA a Graphical User Interface (GUI) was created using Unity3D editor, where a simple USB joystick was used to actuate the motions of the SHRALA in the virtual environment. The fabricated SHRALA was controlled in real time using a serial communication interface created between the GUI and Arduino Mega 2650 board. The humanoid robot was successfully controlled using the GUI environment and the preliminary results are satisfactory as it is performing the task as per the desired instructions. This research work is a part of the real time humanoid robot development project “SHRALA”, In near future autonomous learning algorithm will also be implemented in the robot and the same will be published as research article in a modular approach.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.csbj.2020.05.022,Journal,Computational and Structural Biotechnology Journal,scopus,2020-01-01,sciencedirect,Software tools for 3D nuclei segmentation and quantitative analysis in multicellular aggregates,https://api.elsevier.com/content/abstract/scopus_id/85086379946,"Today, we are fully immersed into the era of 3D biology. It has been extensively demonstrated that 3D models: (a) better mimic the physiology of human tissues; (b) can effectively replace animal models; (c) often provide more reliable results than 2D ones. Accordingly, anti-cancer drug screenings and toxicology studies based on multicellular 3D biological models, the so-called “-oids” (e.g. spheroids, tumoroids, organoids), are blooming in the literature. However, the complex nature of these systems limit the manual quantitative analyses of single cells’ behaviour in the culture. Accordingly, the demand for advanced software tools that are able to perform phenotypic analysis is fundamental. In this work, we describe the freely accessible tools that are currently available for biologists and researchers interested in analysing the effects of drugs/treatments on 3D multicellular -oids at a single-cell resolution level. In addition, using publicly available nuclear stained datasets we quantitatively compare the segmentation performance of 9 specific tools.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2020.03.027,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Strategic zoning approach for urban areas: Towards a shared transportation system,https://api.elsevier.com/content/abstract/scopus_id/85085571988,"Investigating downstream freight demand is a prerequisite to accomplishing the overall strategic implementation of transportation systems. Machine learning has recently become widely applied in order to support decision-making in several logistic operational levels: travel/arrival time prediction, occupancy forecasting of logistic spaces, route optimization and so on. Nevertheless, strategic decision-making often overlooks flow tendencies forecasting. Targeting this perspective, the present paper aims at proposing an urban zoning approach based on time series forecasting of supply chain demand through clustering customers. To conduct our approach, we have selected a set of machine learning algorithms that are believed to be robust according to the literature and the achieved accuracy benchmarks. Considering real-life data-based computational results, a number of analytical insights are illustrated.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.promfg.2020.04.037,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,Implementing AR/MR - Learning factories as protected learning space to rise the acceptance for mixed and augmented reality devices in production,https://api.elsevier.com/content/abstract/scopus_id/85085498037,"When talking about digitization, changes in the way of working are inevitable: The implementation of intelligent machines or dealing with real-time data lead to new tasks supported by new technology. Also digital technologies such as Augmented and Mixed Reality (AR/MR) are pushing the market and setting new standards in collaboration, prototyping or maintenance. The correct handling of AR/MR devices requires a change in the employees’ behavior; changing working routines are followed by a new skill set and a change in the culture. The acceptance of employees can therefore be regarded as a critical success factor for the implementation of such technologies. Thus, the present paper answers the research question ‘what factors influence the employee’s acceptance of AR and MR data glasses in industry’. On the basis of a comprehensive literature analysis, an implementation workshop was developed and validated in cooperation with an industrial partner. The results were transformed into a workshop within the learning and research factory ‘Smart Production Lab’ to give employees and students the opportunity to train the handling of data glasses in a protected learning space in order to increase the acceptance for the technology.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/bs.pmbts.2020.04.003,Book Series,Progress in Molecular Biology and Translational Science,scopus,2020-01-01,sciencedirect,Correlation and association analyses in microbiome study integrating multiomics in health and disease,https://api.elsevier.com/content/abstract/scopus_id/85085165614,"Correlation and association analyses are one of the most widely used statistical methods in research fields, including microbiome and integrative multiomics studies. Correlation and association have two implications: dependence and co-occurrence. Microbiome data are structured as phylogenetic tree and have several unique characteristics, including high dimensionality, compositionality, sparsity with excess zeros, and heterogeneity. These unique characteristics cause several statistical issues when analyzing microbiome data and integrating multiomics data, such as large p and small n, dependency, overdispersion, and zero-inflation. In microbiome research, on the one hand, classic correlation and association methods are still applied in real studies and used for the development of new methods; on the other hand, new methods have been developed to target statistical issues arising from unique characteristics of microbiome data. Here, we first provide a comprehensive view of classic and newly developed univariate correlation and association-based methods. We discuss the appropriateness and limitations of using classic methods and demonstrate how the newly developed methods mitigate the issues of microbiome data. Second, we emphasize that concepts of correlation and association analyses have been shifted by introducing network analysis, microbe-metabolite interactions, functional analysis, etc. Third, we introduce multivariate correlation and association-based methods, which are organized by the categories of exploratory, interpretive, and discriminatory analyses and classification methods. Fourth, we focus on the hypothesis testing of univariate and multivariate regression-based association methods, including alpha and beta diversities-based, count-based, and relative abundance (or compositional)-based association analyses. We demonstrate the characteristics and limitations of each approaches. Fifth, we introduce two specific microbiome-based methods: phylogenetic tree-based association analysis and testing for survival outcomes. Sixth, we provide an overall view of longitudinal methods in analysis of microbiome and omics data, which cover standard, static, regression-based time series methods, principal trend analysis, and newly developed univariate overdispersed and zero-inflated as well as multivariate distance/kernel-based longitudinal models. Finally, we comment on current association analysis and future direction of association analysis in microbiome and multiomics studies.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2020.02.122,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Theoretical and hypothetical pathways to real-time neuromorphic AGI/post-AGI ecosystems,https://api.elsevier.com/content/abstract/scopus_id/85084485262,"While Homo sapiens is without doubt our planet’s most advanced species capable of imagining, creating and implementing tools, one of the many observable trends in evolution is the accelerating merger of biology and technology at increasing levels of scale. This is not surprising, given that our technology can be seen from a perspective in which the sensorimotor and, subsequently, prefrontal areas of our brain increasingly extending its motor (as did our evolutionary predecessors), perceptual, and—with computational advances, cognitive and memory capacities—into the exogenous environment. As such, this trajectory has taken us to a point in the above-mentioned merger at which the brain itself is beginning to meld with its physically expressed hardware and software counterparts—functionally at first, but increasingly structurally as well, initially by way of neural prostheses and brain-machine interfaces. Envisioning the extension of this trend, I propose theoretical technological pathways to a point at which humans and non-biological human counterparts may have the option to have identical neural substrates that—when integrated with Artificial General Intelligence (AGI), counterfactual quantum communications and computation, and AGI ecosystems—provide a global advance in shared knowledge and cognitive function while ameliorating current concerns associated with advanced AGI, as well as suggesting (and, if realized, accelerating) the far-future emergence of Transentity Universal Intelligence (TUI).",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.softx.2020.100426,Journal,SoftwareX,scopus,2020-01-01,sciencedirect,Connecting the CoppeliaSim robotics simulator to virtual reality,https://api.elsevier.com/content/abstract/scopus_id/85080071825,"The CoppeliaSim VR Toolbox provides a set of tools to experience CoppeliaSim robot simulation software in Virtual Reality and to return user interactions. Its primary focus is to create a platform that enables the fast prototyping and verification of robotic systems. Moreover, the generality of the toolbox ensures that it can be valuable in other contexts like robotics education, human–robot interaction or reinforcement learning. The software is designed to have a low entry threshold for moderately complex use cases, but can be extended to perform very complex visualizations for more experienced users.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.softx.2020.100419,Journal,SoftwareX,scopus,2020-01-01,sciencedirect,TWINKLE: A digital-twin-building kernel for real-time computer-aided engineering,https://api.elsevier.com/content/abstract/scopus_id/85079158568,"TWINKLE is a library for building families of solvers to perform Canonical Polyadic Decomposition (CPD) of tensors. The common characteristic of these solvers is that the data structure supporting the tuneable solution strategy is based on a Galerkin projection of the phase space. This allows processing and recovering tensors described by highly sparse and unstructured data. For achieving high performance, TWINKLE is written in C++ and uses the Armadillo open source library for linear algebra and scientific computing, based on LAPACK (Linear Algebra PACKage) and BLAS (Basic Linear Algebra Subprograms) routines. The library has been implemented keeping in mind its future extensibility and adaptability to fulfil the different users’ needs in academia and industry regarding Reduced Order Modelling (ROM) and data analysis by means of tensor decomposition. It is especially focused on post-processing data from Computer-Aided-Engineering (CAE) simulation tools.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/bs.adcom.2019.09.008,Book Series,Advances in Computers,scopus,2020-01-01,sciencedirect,Stepping into the digitally instrumented and interconnected era,https://api.elsevier.com/content/abstract/scopus_id/85078358345,"This chapter is to tell all about the digitization-inspired possibilities and opportunities and how software-defined cloud centers are the best fit for hosting and running digital applications. Also, how the next-generation data analytics can be smartly accomplished through cloud platforms and infrastructures is also explained in detail. We are to describe some of the impactful developments and technological advancements brewing in the IT space, how the tremendous amount of data getting produced and processed through cloud systems is to impact the IT and business domains, and how next-generation IT infrastructures are accordingly getting refactored, remedied and readied for the impending big data-induced challenges, how likely the move of the data analytics discipline toward fulfilling the digital universe requirements of extracting and extrapolating actionable insights for the knowledge-parched is, and finally for the establishment and sustenance of the dreamt smarter planet. In short, the uninhibited explosion of digitized systems and connected devices pour out a tremendous amount of multi-structured data and the impending challenge is to make sense out of the data heaps. Data analytics is the way to go and in the recent past, the overwhelming trend is to empower our everyday systems with machine and deep learning algorithms to automatically learn out of data heaps and streams in order to be distinctively intelligent in their actions and reactions. This chapter is specially prepared to put a stimulating foundation for explaining the nitty-gritty of the Digital Twin paradigm.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cogsys.2019.09.015,Journal,Cognitive Systems Research,scopus,2020-01-01,sciencedirect,Multi-Agent neurocognitive models of semantics of spatial localization of events,https://api.elsevier.com/content/abstract/scopus_id/85072851037,"The purpose of the study is to develop a learning system for internal representation of the events localization space to realize orientation and navigation of autonomous mobile systems. The task of the research is the development of simulation models of the semantics of the event localization space based on multi-agent neurocognitive architectures. The paper proves that the multi-agent neurocognitive architecture is an effective formalism for describing the semantics of the spatial localization of events. Main theoretical foundations have been developed for the simulation of spatial relations using the so-called multi-agent facts, consisting of software agents-concepts, reflecting semantic categories corresponding to parts of speech. It is shown that locative software agents that describe the spatial location of objects and events, forming homogeneous connections, compose the so-called field locations. The latter describes a holistic view of the intellectual agent about the environment. The paper defines conceptual foundations of multi-agent modeling of the semantics of subjective reflexive mapping of the interaction between real objects, space and time.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2019.07.020,Journal,Neural Networks,scopus,2020-01-01,sciencedirect,Deep neural network and data augmentation methodology for off-axis iris segmentation in wearable headsets,https://api.elsevier.com/content/abstract/scopus_id/85072296970,"A data augmentation methodology is presented and applied to generate a large dataset of off-axis iris regions and train a low-complexity deep neural network. Although of low complexity the resulting network achieves a high level of accuracy in iris region segmentation for challenging off-axis eye-patches. Interestingly, this network is also shown to achieve high levels of performance for regular, frontal, segmentation of iris regions, comparing favourably with state-of-the-art techniques of significantly higher complexity. Due to its lower complexity this network is well suited for deployment in embedded applications such as augmented and mixed reality headsets.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2019.07.014,Journal,Knowledge-Based Systems,scopus,2020-01-01,sciencedirect,A new decision support system for knowledge management in archaeological activities”,https://api.elsevier.com/content/abstract/scopus_id/85068965128,"The use of Information Technologies (IT) has today become an added value for appropriate decision making. This has contributed to improving the companies’ strategies in the market. However, the full potential of these technologies in the relevant field of Archaeology has yet to be fully exploited. To contribute to reducing this gap, this paper presents a new and original design of a Process Maturity Framework for archaeological knowledge and data management which may be applied for high-level timely decision making, supported by an ‘IT Governance’ reference frame, in order to improve the quality and efficiency of the services provided by the Diagnostic, Prospecting, Monitoring and Excavation processes of the Preemptive Archaeology Program.
                  This new Process Maturity Model (PMM) takes the processes which are currently established in each phase of archaeological projects as its reference to improve information analysis, reports generation and support decision-making processes, as well as to manage and control the materials and context found in the field. This is achieved by emphasizing the use of the information required for future queries and projections, ensuring its’ quality and integrity in order to generate reports more efficiently, whilst also allowing a more agile and timely decision-making process. Said information has been collected during the field and laboratory processes by analysing the proper application and management of the technology from an ‘IT Governance’ framework in companies which offer archaeological services.
                  The different phases of the implementation of the model designed, based in ITIL, since it is the most holistic of the current benchmarks in Technology Services Management, are shown by means of a hypothetical, yet real, application of the PMM in an Archaeology Consultancy firm. Thus, a set of basic parameters is initially established in order to implement a PMM. Then, a diagnostic on the processes and IT Service Management applied to each archaeological phase is performed. Afterwards, an evaluation of the current maturity level of the processes is carried out and, finally, the continuous improvement plan is described.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.comcom.2019.09.014,Journal,Computer Communications,scopus,2019-12-15,sciencedirect,VARMAN: Multi-plane security framework for software defined networks,https://api.elsevier.com/content/abstract/scopus_id/85072873993,"In the context of future networking technologies, Software-Defined paradigm offers compelling solutions and advantages for traffic orchestration and shaping, flexible and dynamic routing, programmable control and smart application-driven resource management. But the SDN operation has to confront critical issues and technical vulnerabilities, security problems and threats in the enabling technical architecture itself. To address the critical security problems in SDN enabled data centers, we propose a collaborative “Network Security and Intrusion Detection System(NIDS)” scheme called ‘
                        VARMAN
                     : adVanced multi-plAne secuRity fraMework for softwAre defined Networks’. The SDN security scheme comprises of coarse-grained flow monitoring algorithms on the dataplane for rapid anomaly detection and prediction of network-centric DDoS/botnet attacks. In addition, this is combined with a fine-grained hybrid deep-learning based classifier pipeline on the control plane. It is observed that existing ML-based classifiers improve the accuracy of NIDS, however, at the cost of higher processing power and memory requirement, thus unrealistic for real-time solutions. To address these problems and still achieve accuracy and speed, we designed a hybrid model, combining both deep and shallow learning techniques, that are implemented in an improved SDN stack. The data plane deploys attack prediction and behavioral trigger mechanisms, efficient data filtering, feature selection, and data reduction techniques. To demonstrate the practical feasibility of our security scheme in real modern datacenters, we utilized the popular NSL-KDD dataset, most recent CICIDS2017 dataset, and refined it to a balanced dataset containing a comparable number of normal traffic and malware samples. We further augmented the training by organically generating datasets from lab-simulated and public-network hosted hackathon websites. The results show that VARMAN framework is capable of detecting attacks in real-time with accuracy more than 98% under attack intensities up to 50k packets/second. In a multi-controller interconnected SDN domain, the flow setup time improves by 70% on an average, and controller response time reduces by 40%, without incurring additional latency due to security intelligence processing overhead in SDN stack. The comparisons of VARMAN under similar attack scenarios and test environment, with related recent works that utilized ML-based NIDS, demonstrate that our scheme offers higher accuracy, less than 5% false positive rate for various attack intensities and significant training space/time reduction.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2019.06.066,Journal,Expert Systems with Applications,scopus,2019-12-15,sciencedirect,Double Q-PID algorithm for mobile robot control,https://api.elsevier.com/content/abstract/scopus_id/85068505390,"Many expert systems have been developed for self-adaptive PID controllers of mobile robots. However, the high computational requirements of the expert systems layers, developed for the tuning of the PID controllers, still require previous expert knowledge and high efficiency in algorithmic and software execution for real-time applications. To address these problems, in this paper we propose an expert agent-based system, based on a reinforcement learning agent, for self-adapting multiple low-level PID controllers in mobile robots. For the formulation of the artificial expert agent, we develop an incremental model-free algorithm version of the double Q-Learning algorithm for fast on-line adaptation of multiple low-level PID controllers. Fast learning and high on-line adaptability of the artificial expert agent is achieved by means of a proposed incremental active-learning exploration-exploitation procedure, for a non-uniform state space exploration, along with an experience replay mechanism for multiple value functions updates in the double Q-learning algorithm. A comprehensive comparative simulation study and experiments in a real mobile robot demonstrate the high performance of the proposed algorithm for a real-time simultaneous tuning of multiple adaptive low-level PID controllers of mobile robots in real world conditions.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmapro.2019.10.020,Journal,Journal of Manufacturing Processes,scopus,2019-12-01,sciencedirect,Data-driven smart manufacturing: Tool wear monitoring with audio signals and machine learning,https://api.elsevier.com/content/abstract/scopus_id/85074281429,"Tool wear in machining could result in poor surface finish, excessive vibration and energy consumption. Monitoring tool wear in real-time is crucial to improve manufacturing productivity and quality. While numerous sensor-based tool wear monitoring techniques have been demonstrated in laboratory environments, few tool wear monitoring systems have been deployed in factories because it is not realistic to install some of the important sensors such as dynamometers on manufacturing machines. To address this issue, a novel audio signal processing approach is introduced. This technique does not require expensive sensors but audio sensors only. A blind source separation method is used to separate source signals from noise. An extended principal component analysis is used for dimensionality reduction. Real-time multi-channel audio signals are collected during a set of milling tests under varying cutting conditions. The experimental data are used to develop and validate a predictive model. Experimental results have shown that the predictive model is capable of classifying tool wear conditions with high accuracy.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2019.105056,Journal,Computer Methods and Programs in Biomedicine,scopus,2019-12-01,sciencedirect,An iterative finite element-based method for solving inverse problems in traction force microscopy,https://api.elsevier.com/content/abstract/scopus_id/85072277991,"Background and Objective
                  During the last years different model solutions were proposed for solving cell forces under different conditions. The solution relies on a deformation field that is obtained under cell relaxation with a chemical cocktail. Once the deformation field of the matrix is determined, cell forces can be computed by an inverse algorithm, given the mechanical properties of the matrix. Most of the Traction Force Microscopy (TFM) methods presented so far relied on a linear stress-strain response of the matrix. However, the mechanical response of some biopolymer networks, such as collagen gels is more complex. In this work, we present a numerical method for solving cell forces on non-linear materials.
               
                  Methods
                  The proposed method relies on solving the inverse problem based on an iterative optimization. The objective function is defined by least-square minimization of the difference between the target and the current computed deformed configuration of the cell, and the iterative formulation is based on the solution of several direct mechanical problems. The model presents a well-posed discretized inverse elasticity problem in the absence of regularization. The algorithm can be easily implemented in any kind of Finite Element (FE) code as a sequence of different standard FE analysis.
               
                  Results
                  To illustrate the proposed iterative formulation we apply the theoretical model to some illustrative examples by using real experimental data of Normal Human Dermal Fibroblast cells (NHDF) migrating inside a 2 mg/ml collagen-based gel. Different examples of application have been simulated to test the inverse numerical model proposed and to investigate the effect of introducing the correct cell properties onto the obtained cell forces. The algorithm converges after a small number of iterations, generating errors of around 5% for the tractions field in the cell contour domain. The resulting maximum traction values increased by 11% as a consequence of doubling the mechanical properties of the cell domain.
               
                  Conclusions
                  With the results generated from computations we demonstrate the application of the algorithm and explain how the mechanical properties of both, the cell and the gel, domains are important for arriving to the correct results when using inverse traction force reconstruction algorithms, however, have only a minor effect on the resulting traction values.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2019.07.098,Journal,Information Sciences,scopus,2019-12-01,sciencedirect,Counting the frequency of time-constrained serial episodes in a streaming sequence,https://api.elsevier.com/content/abstract/scopus_id/85069902935,"As a representative sequential pattern mining problem, counting the frequency of serial episodes from a streaming sequence has drawn continuous attention in academia due to its wide application in practice, e.g., telecommunication alarms, stock market, transaction logs, bioinformatics, etc. Although a number of serial episodes mining algorithms have been developed recently, most of them are neither stream-oriented, as they require processing the whole dataset multiple times, nor time-aware, as they fail to take into account the time constraint of serial episodes. In this paper, we propose two novel one-pass algorithms, ONCE and ONCE+, each of which can respectively compute two popular frequencies of given episodes satisfying predefined time-constraint as signals in a stream arrives one-after-another. ONCE is only used for non-overlapped frequency where the occurrences of a serial episode in sequence are not intersected. ONCE+ is designed for the distinct frequency where the occurrences of a serial episode do not share any event. Theoretical study proves that our algorithm can correctly mine the frequency of target time constraint serial episodes in a given stream. Experimental study over both real-world and synthetic datasets demonstrates that the proposed algorithm can work, with little time and space, in signal-intensive streams where millions of signals arrive within a single second. Moreover, the algorithm has been applied in a real stream processing system, where the efficacy and efficiency of this work are tested in practical applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ssci.2019.06.025,Journal,Safety Science,scopus,2019-12-01,sciencedirect,Securing instant messaging based on blockchain with machine learning,https://api.elsevier.com/content/abstract/scopus_id/85067872085,"Instant Messaging (IM) offers real-time communications between two or more participants on Internet. Nowadays, most IMs take place on mobile applications, such as WhatsApp, WeChat, Viber and Facebook Messenger, which have more users than social networks, such as Twitter and Facebook. Among the applications of IMs, online shopping has become a part of our everyday life, primarily those who are busiest. However, transaction disputes are often occurred online shopping. Since most IMs are centralized and message history is not stored in the center, the messaging between users and owners of online shops are not reliable and traceable. In China, online shopping sales have soared from practically zero in 2003 to nearly 600 hundred million dollars last year, and now top those in the United States. It is very crucial to secure the instant messaging in online shopping in China. We present techniques to exploit blockchain and machine learning algorithms to secure instant messaging. Since the cryptography of Chinese national standard is encouraged to adopt in security applications of China, we propose a blockchain-based IM scheme with the Chinese cryptographic bases. First, we design a message authentication model based on SM2 to avoid the counterfeit attack and replay attack. Second, we design a cryptographic hash mode based on SM3 to verify the integrity of message. Third, we design a message encryption model based on SM4 to protect the privacy of users. Besides, we propose a method based on machine learning algorithms to monitor the activity on blockchain to detect anomaly. To prove and verify the blockchain-based IM scheme, a blockchain-based IM system has been designed on Linux platforms. The implementation result shows that it is a practical and secure IM system, which can be applied to a variety of instant messaging applications directly.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patrec.2018.04.009,Journal,Pattern Recognition Letters,scopus,2019-12-01,sciencedirect,A real-time and unsupervised face re-identification system for human-robot interaction,https://api.elsevier.com/content/abstract/scopus_id/85046146958,"In the context of Human-Robot Interaction (HRI), face Re-Identification (face Re-ID) aims to verify if certain detected faces have already been observed by robots. The ability of distinguishing between different users is crucial in social robots as it will enable the robot to tailor the interaction strategy toward the users’ individual preferences. So far face recognition research has achieved great success, however little attention has been paid to the realistic applications of Face Re-ID in social robots. In this paper, we present an effective and unsupervised face Re-ID system which simultaneously re-identifies multiple faces for HRI. This Re-ID system employs Deep Convolutional Neural Networks to extract features, and an online clustering algorithm to determine the face's ID. Its performance is evaluated on two datasets: the TERESA video dataset collected by the TERESA robot, and the YouTube Face Dataset (YTF Dataset). We demonstrate that the optimised combination of techniques achieves an overall 93.55% accuracy on TERESA dataset and an overall 90.41% accuracy on YTF dataset. We have implemented the proposed method into a software module in the HCI^2 Framework [1] for it to be further integrated into the TERESA robot [2], and has achieved real-time performance at 10–26 Frames per second.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2019.05.052,Journal,Expert Systems with Applications,scopus,2019-11-30,sciencedirect,Unsupervised collective-based framework for dynamic retraining of supervised real-time spam tweets detection model,https://api.elsevier.com/content/abstract/scopus_id/85067174995,"Twitter is one of the most popular social platforms. It has changed the way of communication and information dissemination through its real-time messaging mechanism. Recently, it has been used by researchers and industries as a new source of data for various intelligent systems, such as tweet sentiment analysis and recommendation systems, which require high data quality. However, due to its flexibility and popularity, Twitter has become the main target for spamming activities such as phishing legitimate users or spreading malicious software, which introduces new security issues and waste resources. Therefore, researchers have developed various machine-learning algorithms to reveal Twitter spam. However, as spammers have become smarter and more crafty, the characteristics of the spam tweets are varying over time making these methods inefficient to detect new spammers tricks and strategies. In addition, some of the employed methods (e.g. blacklisting) or spammer features (e.g. graph-based features) are extremely time-consuming, which hinders the ability to detect spammer activities in real-time. In this paper, we introduce a framework to deal with the volatility of the spam contents and new spamming patterns, called the spam drift. The framework combines the strength of unsupervised machine learning approach, which learns from unlabeled tweets, to retrain a real-time supervised tweet-level spam detection model in a batch mode. A set of experiments on a large-scale data set show the effectiveness of the proposed online unsupervised method in adaptively discovers and learns the patterns of new spam activities and achieve stable recall values reaching more than 95%. Although the average spam precision of our method is around 60%, the high spam recall values show the ability of our proposed method in reducing spam drift problems compared to traditional machine learning algorithms.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2019.08.031,Journal,Neurocomputing,scopus,2019-11-20,sciencedirect,Deep network for human action recognition using Weber motion,https://api.elsevier.com/content/abstract/scopus_id/85070678569,"Effective motion estimation is one of the prime steps for any human action recognition (HAR) algorithm. Optical flow (OF) and motion history image (MHI) are two well-known methods for motion estimation in videos. OF has several advantages over MHI. But the major drawback with OF is that it is computationally very expensive as compared to the MHI. Therefore, in this paper, a new motion estimation technique named as Weber Motion History Image (WMHI) is proposed. Here, an extremely fast algorithm is proposed for HAR using WMHI, pose information, and convolutional neural network (CNN). In spite of being fast and less space consuming, the algorithm outperforms the existing pose based CNN results on five benchmark datasets namely JHMDB [1], sub-JHMDB [1], MPII [2] and HMDB51 [3] and UCF101 [4]. The work mainly focuses on a new efficient algorithm which can be implemented for real-time HAR in videos. For real-time implementation, the two basic criteria on which an algorithm can be analyzed are space and time complexity. The proposed algorithm is faster as compared to the existing OF based HAR systems. In terms of space complexity, the feature size of the proposed algorithm is almost 50% of the existing OF based algorithm. The recognition results still outperform the existing result by a significant margin.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.geoderma.2019.07.004,Journal,Geoderma,scopus,2019-11-15,sciencedirect,Optimisation in machine learning: An application to topsoil organic stocks prediction in a dry forest ecosystem,https://api.elsevier.com/content/abstract/scopus_id/85069648816,"Soil organic carbon (SOC) sequestration plays a key role in reducing the atmospheric greenhouse gas concentration. However, dry forest ecosystems in Ecuador are endangered to become a source of carbon emissions because of deforestation. Often spatial information, necessary to quantify potential carbon loss to the atmosphere, is missing. This particularly applies to remote areas of limited accessibility. This study aims to regionalise the SOC stocks of a small and poorly accessible dry forest ecosystem in southwestern Ecuador by using boosted regression tree (BRT) models. Resampling in a nested repeated k-fold cross validation approach was applied to develop robust models for a dataset of 118 samples with limited predictor information. To select an optimal set of model parameters, optimisation by differential evolution (DE) was applied for parameter tuning. Predictor selection was implemented using the same optimisation algorithm. This study demonstrates how the predictive performance of BRT models can be improved by applying an optimisation approach for parameter tuning and predictor selection. Model performance was improved by approximately 40% concerning the R2. Still, the results also demonstrated the difficulties of machine learning applications in small and highly heterogeneous natural areas. Very variable or even random factors were assumed to distort the relationship between predictor and response variables. We assume that the presented approach is particularly successful in the case of a real-valued multivariate space of tuning parameters. However, this requires testing in further machine learning applications and algorithms.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2019.05.035,Journal,Expert Systems with Applications,scopus,2019-11-15,sciencedirect,Social mimic optimization algorithm and engineering applications,https://api.elsevier.com/content/abstract/scopus_id/85066806914,"Increase in complexity of real world problems has provided an area to explore efficient methods to solve computer science problems. Meta-heuristic methods based on evolutionary computations and swarm intelligence are instances of techniques inspired by nature. This paper presents a novel social mimic optimization (SMO) algorithm inspired by mimicking behavior to solve optimization problems. The proposed algorithm is evaluated using 23 test functions. Obtained results are compared with 14 known optimization algorithms including Whale optimization algorithm (WOA), Grasshopper optimization algorithm (GOA), Particle Swarm Optimization (PSO), Stochastic fractal search (SFS), Grey Wolf Optimizer (GWO), Optics Inspired Optimization (OIO), League Championship Algorithm (LCA), Wind Driven Optimization (WDO), Harmony search (HS), Firefly Algorithm (FA), Artificial Bee Colony (ABC), Biogeography Based Optimization (BBO), Bat Algorithm (BA), and Teaching Learning Based Optimization (TLBO). Obtained results indicate higher capability of the SMO algorithm in solving high-dimensional decision variables. Furthermore, SMO is used to solve two classic engineering design problems. Three important features of SMO are simple implementation, solving optimization problems with minimum population size and not requiring control parameters. Results of various evaluations show superiority of the proposed method in finding the optimal solution with minimum function evaluations. This superiority is achieved based on reducing number of initial population. The proposed method can be applied to applications like automatic evolution of robotics, automatic control of machines and innovation of machines in finding better solutions with less cost.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.enbuild.2019.109440,Journal,Energy and Buildings,scopus,2019-11-01,sciencedirect,A deep reinforcement learning-based autonomous ventilation control system for smart indoor air quality management in a subway station,https://api.elsevier.com/content/abstract/scopus_id/85072289855,"Mechanical ventilation has been widely implemented to alleviate poor indoor air quality (IAQ) in confined underground public facilities. However, due to time-varying IAQ properties that are influenced by unpredictable factors, including outdoor air quality, subway schedules, and passenger volumes, real-time control that incorporates a trade-off between energy saving and IAQ is limited in conventional rule-based and model-based approaches. We propose a data-driven and intelligent approach for a smart ventilation control system based on a deep reinforcement learning (DeepRL) algorithm. This study utilized a deep Q-network (DQN) algorithm of DeepRL to design the ventilation system. The DQN agent was trained in a virtual environment defined by a gray-box model to simulate an IAQ system in a subway station. Performance of the proposed method over three weeks was evaluated by a comprehensive indoor air-quality index (CIAI) and energy consumption under different outdoor air quality scenarios. The results show that the proposed DeepRL-based ventilation control system reduced energy consumption by up to 14.4% for the validation dataset time interval and improved IAQ from unhealthy to acceptable.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cie.2019.106031,Journal,Computers and Industrial Engineering,scopus,2019-11-01,sciencedirect,Machine learning based concept drift detection for predictive maintenance,https://api.elsevier.com/content/abstract/scopus_id/85071975175,"In this work we present a machine learning based approach for detecting drifting behavior – so-called concept drifts – in continuous data streams. The motivation for this contribution originates from the currently intensively investigated topic Predictive Maintenance (PdM), which refers to a proactive way of triggering servicing actions for industrial machinery. The aim of this maintenance strategy is to identify wear and tear, and consequent malfunctioning by analyzing condition monitoring data, recorded by sensor equipped machinery, in real-time. Recent developments in this area have shown potential to save time and material by preventing breakdowns and improving the overall predictability of industrial processes. However, due to the lack of high quality monitoring data and only little experience concerning the applicability of analysis methods, real-world implementations of Predictive Maintenance are still rare. Within this contribution, we present a method, to detect concept drift in data streams as potential indication for defective system behavior and depict initial tests on synthetic data sets. Further on, we present a real-world case study with industrial radial fans and discuss promising results gained from applying the detailed approach in this scope.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cose.2019.101590,Journal,Computers and Security,scopus,2019-11-01,sciencedirect,Volatile memory analysis using the MinHash method for efficient and secured detection of malware in private cloud,https://api.elsevier.com/content/abstract/scopus_id/85070387186,"Today, most organizations employ cloud computing environments for both computational reasons and for storing their critical files and data. Virtual servers are an example of widely used virtual resources provided by cloud computing architecture. Therefore, virtual servers are considered an attractive target for cyber-attackers, who launch their attacks by malware such as the well-known remote access trojans (RATs) and more modern malware such as ransomware and cryptojacking. Existing security solutions implemented on virtual servers fail to detect these newly created malware (zero-day attacks). In fact, by the time the security solution is updated, the organization has likely already been attacked. In this study, we present a designated framework aimed at trusted and secured detection of newly created and unknown instances of malware on virtual machines in an organization's private cloud. We took volatile memory dumps from a virtual machine (VM) in a secured and trusted manner, and analyzed all of the data within the memory dumps using the MinHash method; MinHash is well suited for the accurate detection of malware in VMs based on efficient volatile memory dump comparisons. The proposed framework is evaluated in a comprehensive set of experiments of increasing difficulty in which we also measured the detection performance of different classifiers (both similarity and machine learning-based classifiers, using collections of real-world, professional, notorious malware and legitimate applications. The evaluation results show that our framework can detect the anomalous state of a virtual server, as well as known, new, and unknown malware, with very high TPRs (100% for ransomware and RATs) and very low FPRs (1.8% for ransomware and no FPR for RATs). We also show how the methodology's performance can be improved, in terms of required time and storage space, saving more than 86% of these resources. Finally, we demonstrate the generalization capabilities and practicality of our methodology by using transfer learning and learning from just one virtual server in order to detect unknown malware on a different virtual server.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2019.102853,Journal,Microprocessors and Microsystems,scopus,2019-11-01,sciencedirect,Using Machine Learning for predicting area and Firmware metrics of hardware designs from abstract specifications,https://api.elsevier.com/content/abstract/scopus_id/85070295298,"Advancements of Machine Learning (ML) in the field of computer vision have paved the way for its potential application in many other fields. Researchers and Hardware domain experts are exploring possible applications of Machine Learning in optimizing many aspects of the Hardware development process.
                  In this paper, we propose a novel approach for predicting area and multiple Firmware metrics of Hardware components from specifications. The flow uses an existing RTL generation framework for generating valid data samples that enable ML algorithms to train the learning models. The approach has been successfully employed to predict the area and Firmware measurements of real-life Hardware components such as Control and Status Register (CSR) interfaces, that are ubiquitous in embedded systems. With our method we are able to perform an estimation on the area of an Hardware component with more than 98% accuracy and 600x faster than the existing methods. In addition, we are able to rank the features according to their importance in final area estimations. Finally, we are as well able to predict with an accuracy of approx. 85% the size and the CPU running cycles of a Firmware program embedded on the same Hardware component. This method, as a whole, is an important approach towards an accurate and fast estimation in the context of Hardware/Software trade-off analysis.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2019.07.019,Journal,Information Sciences,scopus,2019-11-01,sciencedirect,Labeled graph sketches: Keeping up with real-time graph streams,https://api.elsevier.com/content/abstract/scopus_id/85068588796,"Currently, graphs serve as fundamental data structures for many applications, such as road networks, social and communication networks, and web requests. In many applications, graph edges stream in and users are only interested in the recent data. In data exploration, the storage and processing of such massive amounts of graph stream data has become a significant problem. As the categorical attributes of vertices and edges are often referred to as labels, we propose a labeled graph sketch that stores real-time graph structural information using only sublinear space and that supports graph queries of diverse types. This sketch also works for sliding-window queries. We conduct extensive experiments on real-world datasets in six different domains and compare the results with a state-of-the-art method to show the accuracy, efficiency, and practicability of our proposed approach.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ress.2019.106555,Journal,Reliability Engineering and System Safety,scopus,2019-11-01,sciencedirect,A cognitive architecture safety design for safety critical systems,https://api.elsevier.com/content/abstract/scopus_id/85068360978,"This research is presented as a safety analysis of a cognitive architecture with an intelligent decision support model (IDSM) that is embedded into an autonomous non-deterministic safety-critical system.
                  Cognitive technology is currently simulated within safety-critical systems in order to highlight variables of interest, interface with intelligent technologies, and provide an environment that improves the system's cognitive performance. In this research, the safety of the architecture was analyzed on an actual safety-critical system, an unmanned surface vehicle (USV). The safety analysis was conducted in both a simulated and a real world nautical based environment. The objective was to define the safety design of a cognitive architecture. The input to the safety design was provided through an approach that identified and mitigated hazards associated with a USV controlled by a cognitive architecture. This analysis provided a structured, task-oriented approach for the dissemination of information concerning safety requirements. This approach was necessary to achieve a safe execution of the USV's capabilities through a design that reduces the potential for injury to personnel and damage to equipment.
                  Other real time applications that would benefit from advancing the safety of cognitive technologies are unmanned platforms, transportation technologies, and service robotics. The results will provide cognitive science researchers with a reference for safety engineering of artificially intelligent safety-critical systems.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jagp.2019.05.013,Journal,American Journal of Geriatric Psychiatry,scopus,2019-11-01,sciencedirect,A Future Research Agenda for Digital Geriatric Mental Healthcare,https://api.elsevier.com/content/abstract/scopus_id/85067070294,"The proliferation of mobile, online, and remote monitoring technologies in digital geriatric mental health has the potential to lead to the next major breakthrough in mental health treatments. Unlike traditional mental health services, digital geriatric mental health has the benefit of serving a large number of older adults, and in many instances, does not rely on mental health clinics to offer real-time interventions. As technology increasingly becomes essential in the everyday lives of older adults with mental health conditions, these technologies will provide a fundamental service delivery strategy to support older adults’ mental health recovery. Although ample research on digital geriatric mental health is available, fundamental gaps in the scientific literature still exist. To begin to address these gaps, we propose the following recommendations for a future research agenda: 1) additional proof-of-concept studies are needed; 2) integrating engineering principles in methodologically rigorous research may help science keep pace with technology; 3) studies are needed that identify implementation issues; 4) inclusivity of people with a lived experience of a mental health condition can offer valuable perspectives and new insights; and 5) formation of a workgroup specific for digital geriatric mental health to set standards and principles for research and practice. We propose prioritizing the advancement of digital geriatric mental health research in several areas that are of great public health significance, including 1) simultaneous and integrated treatment of physical health and mental health conditions; 2) effectiveness studies that explore diagnostics and treatment of social determinants of health such as “social isolation” and “loneliness;” and 3) tailoring the development and testing of innovative strategies to minority older adult populations.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2019.06.003,Journal,Knowledge-Based Systems,scopus,2019-10-15,sciencedirect,Efficient processing of top k group skyline queries,https://api.elsevier.com/content/abstract/scopus_id/85067023283,"For a given multi-dimensional data set, a group skyline query returns the optimal groups not dominated by any other group of equal size. The group skyline query is a powerful tool in many applications that call for optimal groups. However, it is common to return a large number of results which make users overwhelmed since it prevents them from making quick and rational decisions. To address this problem, we first identify and formulate a top 
                        k
                      group skyline (T
                        k
                     GSky) query which returns 
                        k
                      optimal groups dominating the highest number of points in the given data set. Next, new pruning strategies are presented to reduce the search space. Then, we propose efficient algorithms by exploiting novel techniques including a grouping strategy, a hybrid strategy, and a point-based replacement strategy, respectively. Finally, we also develop an approximate algorithm to further improve the T
                        k
                     GSky query performance. The performance of the proposed algorithms is studied by extensive experiments over synthetic and real datasets.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2019.07.015,Journal,Neurocomputing,scopus,2019-10-14,sciencedirect,Merging visual features and temporal dynamics in sequential recommendation,https://api.elsevier.com/content/abstract/scopus_id/85069687170,"With the development of social networking and mobile computing technologies, data analysis in the fashion field has increasingly focused on visual features. The main features currently used in the recommendation methods include non-visual user attributes, item attributes, explicit ratings, and implicit feedbacks. How to understand visual features and integrate them with non-visual features becomes the key to building a good recommender system. In this paper, we consider both non-visual text data and visual image data and their time dynamics to build a large-scale recommender system. An advanced visual Bayesian personalized ranking (aVBPR) model is proposed, which integrates three models. Factorized personalized Markov chains (FPMC) model is used to simulate users’ sequence behaviors, intelligent field-aware factorization machine (iFFM) model also put forward by us is used to predict users’ preferences based on non-visual features, and visual Bayesian personalized ranking (VBPR) model is used to analyze users’ visual preferences. We design a learning algorithm based on AdaGrad method to optimize model aVBPR. The high complexity of the model does not affect the performance of the system by adopting multi-thread technology in the implementation of the learning algorithm. Experimental results of two real-world datasets Women's and Men's Clothing & Accessories from Amazon demonstrate that our model can obtain better recommendation results than the recent popular models for Amazon datasets. Although the model is complicated, multi-thread technique can be used to greatly improve the speed of the implementation.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2019.111549,Journal,Biosensors and Bioelectronics,scopus,2019-10-01,sciencedirect,Efficient electron-mediated electrochemical biosensor of gold wire for the rapid detection of C-reactive protein: A predictive strategy for heart failure,https://api.elsevier.com/content/abstract/scopus_id/85071785022,"C-reactive protein (CRP) is considered a promising biomarker for the rapid and high-throughput real-time monitoring of cardiovascular disease and inflammation in unprocessed clinical samples. Implementation of this monitoring would enable various transformative biomedical applications. We have fabricated a highly specific sensor chip to detect CRP with a detection limit of 2.25 fg/mL. The protein was immobilized on top of a gold (Au) wire/polycarbonate (PC) substrate using 1-ethyl-3-(3-dimethylamino-propyl) carbodiimide hydrochloride/N-hydroxy succinimide-activated 3-mercaptoproponic acid (MPA) as a self-assembled monolayer agent and bovine serum albumin (BSA) as a blocking agent. In contrast to the bare PC substrate, the CRP/BSA/anti-CRP/MPA/Au substrate exhibited a considerably high electrochemical signal toward CRP. The influence of the experimental parameters on CRP detection was assessed via various analysis methods, and these parameters were then optimized. The linear dynamic range of the CRP was 5–220 fg/mL for voltammetric and impedance analysis. Morever, the strategy exhibited high selectivity against various potential interfering species and was capable of directly probing trace amounts of the target CRP in human serum with excellent selectivity. The analytical assay based on the CRP/BSA/anti-CRP/MPA/Au substrate could be exploited as a potentially useful tool for detecting CRP in clinical samples.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engfracmech.2019.106642,Journal,Engineering Fracture Mechanics,scopus,2019-10-01,sciencedirect,Necking-induced fracture prediction using an artificial neural network trained on virtual test data,https://api.elsevier.com/content/abstract/scopus_id/85071523401,"The imperfection-based necking model by Marciniak and Kuczyński (MK) is frequently used for predicting the onset of localized necking under proportional and non-proportional loading, which can be considered a lower limit for the occurrence of fracture in a vehicle body structure subjected to crash loading. A large number of virtual imperfection lines at different orientation angles have to be analysed simultaneously in order to find the critical imperfection causing necking under arbitrary loading. This, and the continuous computation of a “distance to necking” quantity, representing a crucial output quantity for the simulation engineer, makes the model computationally expensive and limits industrial use in full-scale vehicle crash simulations.
                  In this work, an extended MK model is used for creating a virtual test data base under proportional and non-proportional loading for training of a computationally more efficient simple feed-forward neural network (NN). Both models are implemented in a User Material routine of an explicit crash code, where the predictions of the NN are in good agreement with the predictions of the MK reference model, however at a significantly reduced computational cost. Besides a pure numerical validation study, an experimental validation study has been performed, imposing biaxial tension loading followed by plane strain tension loading until necking using a special punch test apparatus. Whereas MK and NN are in good agreement with the experimental observations, the agreement of classical necking models, applied in conjunction with a linear damage accumulation (forming severity) concept was less accurate.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jacr.2019.06.009,Journal,Journal of the American College of Radiology,scopus,2019-10-01,sciencedirect,Bending the Artificial Intelligence Curve for Radiology: Informatics Tools From ACR and RSNA,https://api.elsevier.com/content/abstract/scopus_id/85071398084,"Artificial intelligence (AI) will reshape radiology over the coming years. The radiology community has a strong history of embracing new technology for positive change, and AI is no exception. As with any new technology, rapid, successful implementation faces several challenges that will require creation and adoption of new integration technology. Use cases important to real-world application of AI are described, including clinical registries, AI research, AI product validation, and computer assistance for radiology reporting. Furthermore, the informatics technologies required for successful implementation of the use cases are described, including open Computer-Assisted Radiologist Decision Support, ACR Assist, ACR Data Science Institute use cases, common data elements (radelement.org), RadLex (radlex.org), LOINC/RSNA RadLex Playbook (loinc.org), and Radiology Report Templates (radreport.org).",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compag.2019.104948,Journal,Computers and Electronics in Agriculture,scopus,2019-10-01,sciencedirect,Depthwise separable convolution architectures for plant disease classification,https://api.elsevier.com/content/abstract/scopus_id/85071251967,"Convolutional neural network has a huge partake and is still a dominating tool in the field of computer vision. In this study, we introduce a model with depthwise separable convolution architecture for plant disease detection based on images of leaves. We present two versions of depthwise separable convolution comprising two varieties of building blocks. Training and testing of the models were performed on a subset of publicly available PlantVillage dataset of 82,161 images containing 55 distinct classes of healthy and diseased plants. These depthwise separable convolutions achieved less accuracy and high gain in convergence speed. Several models were trained and tested, of which Reduced MobileNet achieved a classification accuracy of 98.34% with 29 times fewer parameters compared to VGG and 6 times lesser than that of MobileNet. However, MobileNet outperformed existing models with 36.03% accuracy when testing the model on a set of images taken under conditions different from those of the images used for training. Thin models were also introduced, which showed effective trade-off between latency and accuracy. The satisfactory accuracy and small size of this model makes it suitable for real-time crop diagnosis in resource constrained mobile devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.sna.2019.111561,Journal,"Sensors and Actuators, A: Physical",scopus,2019-10-01,sciencedirect,High-precision smart calibration system for temperature sensors,https://api.elsevier.com/content/abstract/scopus_id/85071100929,"High precision and smart sensors make up an indispensable data entry for the Internet of Things technology. Nonetheless, conventional calibration algorithms mainly implemented on the software, such as least squares, polynomial fitting, and interpolation, exhibit limited calibration accuracy that does not reflect a real-time measurement of the sensors. The problem can be resolved with an MCU-based sensor calibration system proposed herein, which mainly employs particle swarm optimization (PSO)-back propagation (BP) neural network. The system firstly reads sensor data through I2C bus and then uses the BP neural network and PSO algorithm to automatically calibrate these data in real time. Sigmoid activation function was implemented via a piecewise polynomial fitting to create a trade-off between hardware resource and precision. A performance test conducted on temperature sensors showed a maximum error of 0.16 °C within the measurement range of −40–100 °C with three times the standard deviation (3
                        σ
                     ) error of ±0.23 °C and overall linearity of 0.1143% after the calibration system was added as compared to the significantly higher error of ±0.63 °C without the calibration.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2019.07.008,Journal,Engineering Applications of Artificial Intelligence,scopus,2019-10-01,sciencedirect,A semisupervised autoencoder-based approach for anomaly detection in high performance computing systems,https://api.elsevier.com/content/abstract/scopus_id/85069910646,"High Performance Computing (HPC) systems are complex machines with heterogeneous components that can break or malfunction. Automated anomaly detection in these systems is a challenging and critical task, as HPC systems are expected to work 24/7. The majority of the current state-of-the-art methods dealing with this problem are Machine Learning techniques or statistical models that rely on a supervised approach, namely the detection mechanism is trained to recognize a fixed number of different states (i.e. normal and anomalous conditions).
                  In this paper a novel semi-supervised approach for anomaly detection in supercomputers is proposed, based on a type of neural network called autoencoder. The approach learns the normal state of the supercomputer nodes and after the training phase can be used to discern anomalous conditions from normal behavior; in doing so it relies only on the availability of data characterizing only the normal state of the system. This is different from supervised methods that require data sets with many examples of anomalous states, which are in general very rare and/or hard to obtain.
                  The approach was tested on a real-life High Performance Computing system equipped with a monitoring infrastructure capable to generate large amount of data describing the system state. The proposed approach definitely outperforms the best current techniques for semi-supervised anomaly detection, with an increase in accuracy detection of around 12%. Two different implementations are discussed: one where each supercomputer node has a specific model and one with a single, generalized model for all nodes, in order to explore the trade-off between accuracy and ease of deployment.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cie.2019.07.007,Journal,Computers and Industrial Engineering,scopus,2019-10-01,sciencedirect,Artificial search agents with cognitive intelligence for binary optimization problems,https://api.elsevier.com/content/abstract/scopus_id/85068529900,"Artificial intelligence techniques bring about new opportunities in problem solving. The notion such techniques have in common is learning mechanisms that are mostly problem and environment dependent. Although optimality is not guaranteed by these techniques, they draw attention due to being able to solve challenging optimization problems efficiently. Accordingly, the present study introduces a swarm-based optimization algorithm that is comprised of artificial search agents each with individual cognitive intelligence. In this technique, each agent is allowed to learn from problem space individually. Therefore, each of the search agents exhibits a different search characteristic. Nevertheless, they occasionally share information of the promising regions with each other. Thus, central swarm intelligence is also allowed to lead those independent search agents. Moreover, information-sharing techniques in the developed algorithm are designed as adaptive procedures so that search agents learn throughout generations by avoiding premature convergence and local optima problems as much as possible. The performance of the proposed algorithm is tested on a set of binary optimization problems including the set-union knapsack problem and the uncapacitated facility location problem, which have numerous real-life applications. All reported benchmarking problems are solved by the developed algorithm. As demonstrated by the comprehensive computational study and statistical tests, the proposed swarm-based algorithm significantly improves most of the published results.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.talanta.2019.05.089,Journal,Talanta,scopus,2019-10-01,sciencedirect,Combination of LEDs and cognitive modeling to quantify sheep cheese whey in watercourses,https://api.elsevier.com/content/abstract/scopus_id/85066257571,"The concentration of sheep cheese whey (CW) in water obtained from two Spanish reservoirs, two Spanish rivers, and distilled water has been estimated by combining spectroscopic measurements, obtained with light-emitting diodes (LEDs), and linear or non-linear algorithms. The concentration range of CW that has been studied covers from 0 to 25% in weight. Every sample was measured by six different types of LEDs possessing different emission wavelengths (blue, orange, green, pink, white, and UV). 1,800 fluorescence measurements were carried out and used to design different types of models to estimate the concentration of CW in water. The fluorescence spectra provided by the pink LED originated the most accurate mathematical models, with mean square errors lower than 3.3% and 2.5% for the linear and non-linear approaches, respectively. The pink LED combined with the non-linear model, which was an artificial neural network, was further validated through a k-fold cross-validation and an internal validation. It should be noted that the sensor used here has been designed and produced by a 3D printer and has the potential of being implemented in situ for real-time and cost-effective analysis of natural watercourses.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2019.04.035,Journal,Expert Systems with Applications,scopus,2019-10-01,sciencedirect,Classifying Periodic Astrophysical Phenomena from non-survey optimized variable-cadence observational data,https://api.elsevier.com/content/abstract/scopus_id/85064934432,"Modern time-domain astronomy is capable of collecting a staggeringly large amount of data on millions of objects in real time. Therefore, the production of methods and systems for the automated classification of time-domain astronomical objects is of great importance. The Liverpool Telescope has a number of wide-field image gathering instruments mounted upon its structure, the Small Telescopes Installed at the Liverpool Telescope. These instruments have been in operation since March 2009 gathering data of large areas of sky around the current field of view of the main telescope generating a large dataset containing millions of light sources. The instruments are inexpensive to run as they do not require a separate telescope to operate but this style of surveying the sky introduces structured artifacts into our data due to the variable cadence at which sky fields are resampled. These artifacts can make light sources appear variable and must be addressed in any processing method.
                  The data from large sky surveys can lead to the discovery of interesting new variable objects. Efficient software and analysis tools are required to rapidly determine which potentially variable objects are worthy of further telescope time. Machine learning offers a solution to the quick detection of variability by characterising the detected signals relative to previously seen exemplars. In this paper, we introduce a processing system designed for use with the Liverpool Telescope identifying potentially interesting objects through the application of a novel representation learning approach to data collected automatically from the wide-field instruments. Our method automatically produces a set of classification features by applying Principal Component Analysis on set of variable light curves using a piecewise polynomial fitted via a genetic algorithm applied to the epoch-folded data. The epoch-folding requires the selection of a candidate period for variable light curves identified using a genetic algorithm period estimation method specifically developed for this dataset. A Random Forest classifier is then used to classify the learned features to determine if a light curve is generated by an object of interest. This system allows for the telescope to automatically identify new targets through passive observations which do not affect day-to-day operations as the unique artifacts resulting from such a survey method are incorporated into the methods.
                  We demonstrate the power of this feature extraction method compared to feature engineering performed by previous studies by training classification models on 859 light curves of 12 known variable star classes from our dataset. We show that our new features produce a model with a superior mean cross-validation F1 score of 0.4729 with a standard deviation of 0.0931 compared with the engineered features at 0.3902 with a standard deviation of 0.0619. We show that the features extracted from the representation learning are given relatively high importance in the final classification model. Additionally, we compare engineered features computed on the interpolated polynomial fits and show that they produce more reliable distributions than those fit to the raw light curve when the period estimation is correct.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2019.05.064,Journal,Neurocomputing,scopus,2019-09-17,sciencedirect,Improving novelty detection with generative adversarial networks on hand gesture data,https://api.elsevier.com/content/abstract/scopus_id/85066314268,"We propose a novel way of solving the issue of classification of out-of-vocabulary gestures using Artificial Neural Networks (ANNs) trained in the Generative Adversarial Network (GAN) framework. A generative model augments the data set in an online fashion with new samples and stochastic target vectors, while a discriminative model determines the class of the samples. The approach was evaluated on the UC2017 SG and UC2018 DualMyo data sets. The generative models’ performance was measured with a distance metric between generated and real samples. The discriminative models were evaluated by their accuracy on trained and novel classes. In terms of sample generation quality, the GAN is significantly better than a random distribution (noise) in mean distance, for all classes. In the classification tests, the baseline neural network was not capable of identifying untrained gestures. When the proposed methodology was implemented, we found that there is a trade-off between the detection of trained and untrained gestures, with some trained samples being mistaken as novelty. Nevertheless, a novelty detection accuracy of 95.4% or 90.2% (depending on the data set) was achieved with just 5% loss of accuracy on trained classes.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2019.11.102,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-09-01,sciencedirect,Sustainable operations management for industry 4.0 and its social return,https://api.elsevier.com/content/abstract/scopus_id/85078948022,"In today’s industrial environment, where concepts of smart factories are consolidating their application in companies, it is still necessary to approach management decision making from a perspective that encompasses all aspects of sustainability without losing sight of the social return to which they must contribute. In order to obtain a reliable prediction, of the operation of a Sustainable Manufacturing System (SMS) and its Social Return (SR), this paper develops a methodology and procedures that allow predicting the system performance as a whole. This will allow us to assist management decision making in industries 4.0, supported by multi-criteria methods in knowledge management, simulation, value analysis and operational research by means of:
                  a) Study the economic, social and environmental impacts in the organization and management of the efficient operation of an SMS with the selection of strategies and alternatives in production chains to minimize and / or mitigate environmental and labor risks.
                  b) Encourage of industrial symbiosis or eco-industries networks that create opportunities increasing eco-efficiency and the positive social return of production systems.
                  This proposed methodology will facilitate changes in the structure of production systems in order to implement industry 4.0 paradigms through facilitator technologies such as simulation and virtual reality. This framework will allow Small and Medium Enterprises (SMEs) and other companies to address the decision-making activities that improve the economic-functional efficiency, which will lead to reduce the environmental impact and increase the positive social return of certain production strategies, considering working conditions.
                  The proposed approach went validated, in the area of the Euroregion Galicia North of Portugal, to favour the implementation of the decision-making through the Industry 4.0 Technologies.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2019.11.172,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-09-01,sciencedirect,Machine learning framework for predictive maintenance in milling,https://api.elsevier.com/content/abstract/scopus_id/85078904429,"In the Industry 4.0 era, artificial intelligence is transforming the manufacturing industry. With the advent of Internet of Things (IoT) and machine learning methods, manufacturing systems are able to monitor physical processes and make smart decisions through realtime communication and cooperation with humans, machines, sensors, and so forth. Artificial intelligence enables manufacturers to reduce equipment downtime, spot production defects, improve the supply chain, and shorten design times by using machine learning technologies which learn from experiences. One of the last application of these technologies is the development of Predictive Maintenance systems. Predictive maintenance combines Industrial IoT technologies with machine learning to forecast the exact time in which manufacturing equipment will need maintenance, allowing problems to be solved and adaptive decisions to be made in a timely fashion. This study will discuss the implementation of a milling Cutting-tool Predictive Maintenance solution (including Wear Monitoring), applied to a real milling data set as validation of the framework. More generally, this work provides a basic framework for creating a tool to monitor the wear level, preventing the breakdown, of a generic manufacturing tool, in order to improve human-machine interaction and optimize the production process.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2019.11.385,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-09-01,sciencedirect,Towards a data-driven predictive-reactive production scheduling approach based on inventory availability,https://api.elsevier.com/content/abstract/scopus_id/85078884096,"To survive in a competitive business environment, manufacturing systems require the proper deployment of advanced technologies coming from Industry 4.0. These technologies allow access to quasi-real-time data that provide a continuously updated picture of the production system, including the state of available inventory. Data-driven predictive-reactive production scheduling has the potential to support the anticipation and prompt reaction to overcome different kinds of disruptions that occur in production execution nowadays. This research paper aims to propose a conceptual model for a data-driven predictive-reactive production scheduling approach combining machine learning and simulation-based optimization, considering current inventory of raw material, work in process and final products inventory to characterize a job-shop production execution state. The approach supports decision-making in dynamic situations related to inventory availability that can affect production schedules.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.tips.2019.07.005,Journal,Trends in Pharmacological Sciences,scopus,2019-09-01,sciencedirect,Artificial Intelligence for Drug Toxicity and Safety,https://api.elsevier.com/content/abstract/scopus_id/85071055144,"Interventional pharmacology is one of medicine’s most potent weapons against disease. These drugs, however, can result in damaging side effects and must be closely monitored. Pharmacovigilance is the field of science that monitors, detects, and prevents adverse drug reactions (ADRs). Safety efforts begin during the development process, using in vivo and in vitro studies, continue through clinical trials, and extend to postmarketing surveillance of ADRs in real-world populations. Future toxicity and safety challenges, including increased polypharmacy and patient diversity, stress the limits of these traditional tools. Massive amounts of newly available data present an opportunity for using artificial intelligence (AI) and machine learning to improve drug safety science. Here, we explore recent advances as applied to preclinical drug safety and postmarketing surveillance with a specific focus on machine and deep learning (DL) approaches.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.clineuro.2019.105442,Journal,Clinical Neurology and Neurosurgery,scopus,2019-09-01,sciencedirect,Artificial intelligence for assisting diagnostics and assessment of Parkinson's disease—A review,https://api.elsevier.com/content/abstract/scopus_id/85069629950,"Artificial intelligence, specifically machine learning, has found numerous applications in computer-aided diagnostics, monitoring and management of neurodegenerative movement disorders of parkinsonian type. These tasks are not trivial due to high inter-subject variability and similarity of clinical presentations of different neurodegenerative disorders in the early stages. This paper aims to give a comprehensive, high-level overview of applications of artificial intelligence through machine learning algorithms in kinematic analysis of movement disorders, specifically Parkinson’s disease (PD). We surveyed papers published between January 2007 and January 2019, within online databases, including PubMed and Science Direct, with a focus on the most recently published studies. The search encompassed papers dealing with the implementation of machine learning algorithms for diagnosis and assessment of PD using data describing motion of upper and lower extremities. This systematic review presents an overview of 48 relevant studies published in the abovementioned period, which investigate the use of artificial intelligence for diagnostics, therapy assessment and progress prediction in PD based on body kinematics. Different machine learning algorithms showed promising results, particularly for early PD diagnostics. The investigated publications demonstrated the potentials of collecting data from affordable and globally available devices. However, to fully exploit artificial intelligence technologies in the future, more widespread collaboration is advised among medical institutions, clinicians and researchers, to facilitate aligning of data collection protocols, sharing and merging of data sets.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jngse.2019.102933,Journal,Journal of Natural Gas Science and Engineering,scopus,2019-09-01,sciencedirect,Machine learning for surveillance of fluid leakage from reservoir using only injection rates and bottomhole pressures,https://api.elsevier.com/content/abstract/scopus_id/85068973220,"Carbon-neutral economies would require preventing the release of industrial-scale CO2 into the atmosphere by injecting into geologic formations. Large-scale injection of CO2 into deep reservoirs carries a potential for its undesired leakage into above zones, which can act as an obstacle to its large-scale implementation. Current methods for surveillance of CO2 leaks are costly and not very robust, especially the methods that simulate expected pressure behavior based on an assumed reservoir model.
                  This study proposes a machine learning method for surveillance of fluid leakage using deconvolution response function (a non-linear function of time varying bottomhole pressure and injection rates) from injection and monitoring wells as a measure of leakage that is simulated via multivariate linear regression of all the wells present in the reservoir. Leakage is detected by comparing “expected” (baseline without leaks) deconvolution response of all monitoring wells with their “observed” deconvolution response. Three key advantages of the proposed method are that it i) uses only injection rates and bottomhole pressure data (with no reservoir or geological model), ii) is independent of physical process parameterization uncertainties, and iii) applicable to both conventional and unconventional (e.g. fractured tight formations) reservoirs with any fluid (e.g. compressible, incompressible). The proposed method is first trained to learn well history with no leakage, followed by its validation after which it can be used to detect leakage by tracking a meaningful deviation error (at least twenty times the error of no leakage base scenario over same time period) between expected well response and observed well response at all monitoring wells. The well history required for the proposed method comes directly from measurements made at wells in a real field, but in absence of field data the proposed method is illustrated through well history simulated by reservoir simulations; no such numerical simulations are required for application of this method in a real world scenario with well measurements.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2019.06.029,Journal,Computer Methods and Programs in Biomedicine,scopus,2019-09-01,sciencedirect,C-HMOSHSSA: Gene selection for cancer classification using multi-objective meta-heuristic and machine learning methods,https://api.elsevier.com/content/abstract/scopus_id/85068374888,"Background and objective: Over the last two decades, DNA microarray technology has emerged as a powerful tool for early cancer detection and prevention. It helps to provide a detailed overview of disease complex microenvironment. Moreover, online availability of thousands of gene expression assays made microarray data classification an active research area. A common goal is to find a minimum subset of genes and maximizing the classification accuracy.
                  
                     Methods: In pursuit of a similar objective, we have proposed framework (C-HMOSHSSA) for gene selection using multi-objective spotted hyena optimizer (MOSHO) and salp swarm algorithm (SSA). The real-life optimization problems with more than one objective usually face the challenge to maintain convergence and diversity. Salp Swarm Algorithm (SSA) maintains diversity but, suffers from the overhead of maintaining the necessary information. On the other hand, the calculation of MOSHO requires low computational efforts hence is used for maintaining the necessary information. Therefore, the proposed algorithm is a hybrid algorithm that utilizes the features of both SSA and MOSHO to facilitate its exploration and exploitation capability.
                  
                     Results:Four different classifiers are trained on seven high-dimensional datasets using a subset of features (genes), which are obtained after applying the proposed hybrid gene selection algorithm. The results show that the proposed technique significantly outperforms existing state-of-the-art techniques.
                  
                     Conclusion: It is also shown that the new sets of informative and biologically relevant genes are successfully identified by the proposed technique. The proposed approach can also be applied to other problem domains of interest which involve feature selection.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cie.2019.06.040,Journal,Computers and Industrial Engineering,scopus,2019-09-01,sciencedirect,"Bernard, an energy intelligent system for raising residential users awareness",https://api.elsevier.com/content/abstract/scopus_id/85067600850,"Energy efficiency is still a hot topic today. Coming roughly the 25% of the energy consumption in EU from the residential sector, very few cheap and simple tools to promote energy efficiency in home users have been developed. The purpose of this paper is to present Bernard, a concept proof designed for filling this gap. This aims that householders become aware of their energy habits and have useful information that help them to redirect their consumption pattern. To achieve these goals, Bernard offers, through a mobile application, the home energy consumption monitoring in real time, the energy price forecast for the next hour and the appliances which are switched on, among others. Furthermore, it is important to highlight that the system has been designed with the premises of being cheap, non-intrusive, reliable and easily scalable, in order that utilities can gradually deploy and provide it to their customers, gaining at the same time valuable information for decision making and improving its corporate social image. Therefore, the adopted solution is based on a real time streaming data architecture suitable for handling huge volumes of data and applying predictive techniques on a cloud-computing environment. The paper provides a detailed description of the system and experimental results evaluating the performance of the predictive modules built. As case study, REFIT and REDD datasets were used.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2019.05.010,Journal,Knowledge-Based Systems,scopus,2019-09-01,sciencedirect,Augmented label propagation for seed set expansion,https://api.elsevier.com/content/abstract/scopus_id/85065873438,"In many applications such as social network analysis and recommendation systems, it is of particular interest to identify a group of similar nodes/users/items. However, in networks of massive size, manual labeling process becomes intractable. A practical means is to mark a small number of nodes as seeds, and then expand them to the rest (unlabeled) ones, which is also known as seed set expansion. We present a novel method for seed set expansion by leveraging information spreading dynamics through label propagation. In particular, by devising an augmented, community-based label propagation, we can fully exploit the information of the limited seed nodes, and apply the connectivity structure of the whole network in imposing a larger number of constraints on the label propagation process, thus achieving an improved estimation. Our method can increase the effective number of seed nodes in that it can achieve a better estimation than other propagation methods using the same number of seeds. Extensive experiments on real-world datasets demonstrate the effectiveness and adaptiveness of our method, compared to the state-of-the-art approaches.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.sysarc.2019.01.007,Journal,Journal of Systems Architecture,scopus,2019-09-01,sciencedirect,A Survey and Taxonomy of FPGA-based Deep Learning Accelerators,https://api.elsevier.com/content/abstract/scopus_id/85063404030,"Deep learning, the fastest growing segment of Artificial Neural Network (ANN), has led to the emergence of many machine learning applications and their implementation across multiple platforms such as CPUs, GPUs and reconfigurable hardware (Field-Programmable Gate Arrays or FPGAs). However, inspired by the structure and function of ANNs, large-scale deep learning topologies require a considerable amount of parallel processing, memory resources, high throughput and significant processing power. Consequently, in the context of real time hardware systems, it is crucial to find the right trade-off between performance, energy efficiency, fast development, and cost. Although limited in size and resources, several approaches have showed that FPGAs provide a good starting point for the development of future deep learning implementation architectures. Through this paper, we briefly review recent work related to the implementation of deep learning algorithms in FPGAs. We will analyze and compare the design requirements and features of existing topologies to finally propose development strategies and implementation architectures for better use of FPGA-based deep learning topologies. In this context, we will examine the frameworks used in these studies, which will allow testing a lot of topologies to finally arrive at the best implementation alternatives in terms of performance and energy efficiency.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1038/s41436-019-0439-8,Journal,Genetics in Medicine,scopus,2019-09-01,sciencedirect,Xrare: a machine learning method jointly modeling phenotypes and genetic evidence for rare disease diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85060610025,"Purpose
                  Despite the successful progress next-generation sequencing technologies has achieved in diagnosing the genetic cause of rare Mendelian diseases, the current diagnostic rate is still far from satisfactory because of heterogeneity, imprecision, and noise in disease phenotype descriptions and insufficient utilization of expert knowledge in clinical genetics. To overcome these difficulties, we present a novel method called Xrare for the prioritization of causative gene variants in rare disease diagnosis.
               
                  Methods
                  We propose a new phenotype similarity scoring method called Emission-Reception Information Content (ERIC), which is highly tolerant of noise and imprecision in clinical phenotypes. We utilize medical genetic domain knowledge by designing genetic features implementing American College of Medical Genetics and Genomics (ACMG) guidelines.
               
                  Results
                  ERIC score ranked consistently higher for disease genes than other phenotypic similarity scores in the presence of imprecise and noisy phenotypes. Extensive simulations and real clinical data demonstrated that Xrare outperforms existing alternative methods by 10–40% at various genetic diagnosis scenarios.
               
                  Conclusion
                  The Xrare model is learned from a large database of clinical variants, and derives its strength from the tight integration of medical genetics features and phenotypic features similarity scores. Xrare provides the clinical community with a robust and powerful tool for variant prioritization.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.dsx.2018.07.014,Journal,Diabetes and Metabolic Syndrome: Clinical Research and Reviews,scopus,2019-09-01,sciencedirect,Prevalence of metabolic syndrome in Iranian patients with schizophrenia: A systematic review and meta-analysis,https://api.elsevier.com/content/abstract/scopus_id/85050864479,"Industry 4.0 is an updated concept of smart production, which is identified with the fourth industrial revolution and the emergence of cyber-physical systems. Industry 4.0 is the next stage in the digitization of productions and industries, where such technologies and concepts as the Internet of things, big data, predictive analytics, cloud computing, machine learning, machine interaction, artificial intelligence, robotics, 3D printing, augmented reality.
                  As an area of therapy with the best market potential and one of the most expensive global diseases, diabetes attracts the best healthcare players, who use innovative technologies.
                  Current trends in digitalization of diabetes management are presented.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patrec.2018.02.013,Journal,Pattern Recognition Letters,scopus,2019-09-01,sciencedirect,Biometric surveillance using visual question answering,https://api.elsevier.com/content/abstract/scopus_id/85042474147,"Surveillance of individuals using visual data requires human-level capabilities for understanding the characteristics that differentiate one person from another. However, because the influx of both video and imagery is increasing at a greater rate than humans can cope with, biometric-based surveillance systems are required to assist with the triage of information based on human-generated queries. Unfortunately, current systems are not robust enough to tackle new tasks, as they involve specialized models that do not leverage existing, pre-trained components. To mitigate these issues, we propose a novel system for biometric-based surveillance that utilizes models that are relevance-aware to triage images and videos based on interaction with single or multiple users. As the system is initially focused on detection of people via their appearance and clothing, we have named the system Context and Collaborative (C2) Visual Question Answering (VQA) for Biometric Object-Attribute Relevance and Surveillance (C2VQA-BOARS). To validate the usefulness of C2VQA-BOARS in real-world scenarios, we provide an implementation of two novel components (Relevance and Triage) and apply them in tasks against two datasets created for biometric surveillance. Our results outperform baseline approaches, proving that a system with a minimal amount of fine-tuned components can robustly handle new datasets and problems as needed.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.095,Journal,Neurocomputing,scopus,2019-08-18,sciencedirect,Speeding up k-Nearest Neighbors classifier for large-scale multi-label learning on GPUs,https://api.elsevier.com/content/abstract/scopus_id/85065140025,"Multi-label classification is one of the most dynamically growing fields of machine learning, due to its numerous real-life applications in solving problems that can be described by multiple labels at the same time. While most of works in this field focus on proposing novel and accurate classification algorithms, the issue of the computational complexity on growing dataset sizes is somehow marginalized. Owning to the ever-increasing capabilities of data capturing, we are faced with the problem of large-scale data mining that forces learners to be not only highly accurate, but also fast and scalable on high-dimensional spaces of instances, features, and labels. In this paper, we propose a highly efficient parallel approach for computing the multi-label k-Nearest Neighbor classifier on GPUs. While this method is highly effective due to its accuracy and simplicity, its computational complexity makes it prohibitive for large-scale data. We propose a four-step implementation that takes an advantage of the GPU architecture, allowing for an efficient execution of the multi-label k-Nearest Neighbors classifier without any loss of accuracy. Experiments carried out on a number of real and artificial benchmarks show that we are able to achieve speedups up to 200 times when compared to a sequential CPU execution, while efficiently scaling up to varying number of instances and features.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.oceaneng.2019.106129,Journal,Ocean Engineering,scopus,2019-08-15,sciencedirect,Study on wavelet neural network based anomaly detection in ocean observing data series,https://api.elsevier.com/content/abstract/scopus_id/85067611959,"In this paper, a novel method is presented for detecting anomalies in ocean fixed-point observing time series, which combines wavelet neural network (WNN), classifying threshold and two detecting strategies. The WNN was developed without any labeled training data to simulate the non-anomalous behaviors for next-step prediction. The classifying threshold was constructed according to the estimated distribution of long-term historical residual errors. The observation strategy (OS) and prediction strategy (PS) were designed to detect new unknown anomalies. Two types of marine observing time series from a buoy, deployed at the National Ocean Test Site of China, were selected for verifying the method. The results show that 99% of classifying confidence level is adequate to provide a reasonable trade-off between the false negative and false positive. By using the two detecting strategies and selecting proper estimated distribution of the threshold, the method is efficient for identifying the anomalous points and patterns which were caused by the natural factors or equipment failures. Compared with traditional ANN and wavelet-ANN, the WNN-based method is more tolerant to noise and more sensitive to anomalies with temporal dependencies. Furthermore, this approach introduced here can work in a real-time way and will help ocean engineering managers to obtain informed decisions.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ymeth.2019.03.012,Journal,Methods,scopus,2019-08-15,sciencedirect,IVS2vec: A tool of Inverse Virtual Screening based on word2vec and deep learning techniques,https://api.elsevier.com/content/abstract/scopus_id/85064277603,"Inverse Virtual Screening is a powerful technique in the early stage of drug discovery process. This technique can provide important clues for biologically active molecules, which is useful in the following researches of durg discovery. In this work, combining with Word2vec, a natural language processing technique, dense fully connected neural network (DFCNN) algorithm is utilized to build up a prediction model. This model is able to perform a binary classification. Based on the query molecule, the input protein candidates can be classified into two subsets. One set is that potential targets with high possibilities to bind with the query molecule and the other one is that the proteins with low possibilities to bind with the query molecule. This model is named as IVS2vec. IVS2vec also can output a score reflecting binding possibility of the association between a protein and a molecule, which is useful to improve efficiency of research. We applied IVS2vec on several databases related to drug development and shown that our model can detect possible therapeutic targets. In addition, our model can identify targets related to adverse drug reactions which is useful to improve medication safety and repurpose drugs. Moreover, IVS2vec can give a very fast speed to perform prediction jobs. It is suitable for processing a large number of compounds in the chemical databases. We also find that IVS2vec has potential capabilities and outperform other state-of-the-art docking tools such as Autodock vina. In this study, IVS2vec brings many convincing results than Autodock vina in the reverse target searching case of Quercetin.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S1361-3723(19)30083-1,Journal,Computer Fraud and Security,scopus,2019-08-01,sciencedirect,AI vs AI: fraudsters turn defensive technology into an attack tool,https://api.elsevier.com/content/abstract/scopus_id/85070686326,"The first rule of managing online fraud and mitigating risk is to remember that fraudsters are entrepreneurs. While it's tempting to think of those committing digital fraud as hoody-wearing lone wolves spending hours in their bedroom working to weasel their way into someone's online account, in reality professional fraud operations look more like the JP Morgan trading floor.
                  Cyber criminals are not simple, hoodie-wearing lone wolves. Many are sophisticated fraud operations using the most advanced technology, including artificial intelligence (AI).
                  The energy and ingenuity with which fraud rings and cyber criminals have deployed AI-based solutions has matched that of the businesses and organisations that work to protect themselves from bad actors. Machines have been put to malicious use in ways ranging from click farms to complex model extraction schemes, explains Swami Vaithianathasamy of Signifyd.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ufug.2019.126365,Journal,Urban Forestry and Urban Greening,scopus,2019-07-01,sciencedirect,Exploring the effect of urban features and immediate environment on body responses,https://api.elsevier.com/content/abstract/scopus_id/85067818650,"This study investigates the relationship between urban features (sky exposure, green spaces, visual complexity, and built-up area), immediate environmental factors (air temperature, relative humidity, Heat Stress Index, Wet Bulb Globe Temperature, wind speed, and noise), personal characteristics (perceived restorativeness) and body reactions (body skin temperature and skin conductance responses). The proposed framework is based on multi-sensor data fusion from wearable physiological sensors, wireless environmental sensors, smartphones, images, geographic information systems datasets, and questionnaires. An experimental setup in a real-world setting is conducted and machine learning algorithms for regression problems and feature selection for variable importance are implemented. The results suggest a significant association between immediate environmental factors and body reactions; however, urban features are found to be weak explanatory variables. A deeper analysis of the identified stress hotspots revealed that locations with more dense green spaces, greater sky exposure, and smaller built-up area tended to report lower levels of stress reaction.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ece.2019.05.003,Journal,Education for Chemical Engineers,scopus,2019-07-01,sciencedirect,"Learning distillation by a combined experimental and simulation approach in a three steps laboratory: Vapor pressure, vapor-liquid equilibria and distillation column",https://api.elsevier.com/content/abstract/scopus_id/85066038830,"Distillation is one of the most important separation process in industrial chemistry. This operation is based on a deep knowledge of the fluid phase equilibria involved in the mixture to be separated. In particular, the most important aspects are the determination of the vapor pressures of the single compounds and the correct representation of the eventual not ideality of the mixture. Simulation science is a fundamental tool for managing these complex topics and chemical engineers students have to learn and to use it on real case-studies. To give to the students a complete overview of these complex aspects, a laboratory experience is proposed. Three different work stations were set up: i) determination of vapor pressure of two pure compounds; ii) the study of vapor-liquid equilibria of a binary mixture; iii) the use of a continuous multistage distillation column in dynamic and steady-state conditions. The simulation of all these activities by a commercial software, PRO II by AVEVA, allows to propose and verify the thermodynamic characteristics of the mixture and to correctly interpret the distillation column data. Moreover, the experimental plants and the data elaboration by classical equations are presented. The students are request to prepare a final report in which the description of the experimental plants and experimental procedure, the interpretation of the results and the simulation study are critically discussed in order to encourage them to reason and to acquire the concepts of the course.
                  Two different questionnaires each with 7 questions, for the course and for the laboratory, are proposed and analyzed. The final evaluation of the students was strongly positive both for the course as a whole and for the proposed laboratory activities.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.media.2019.05.001,Journal,Medical Image Analysis,scopus,2019-07-01,sciencedirect,Denoising of 3D magnetic resonance images using a residual encoder–decoder Wasserstein generative adversarial network,https://api.elsevier.com/content/abstract/scopus_id/85065426790,"Structure-preserved denoising of 3D magnetic resonance imaging (MRI) images is a critical step in medical image analysis. Over the past few years, many algorithms with impressive performances have been proposed. In this paper, inspired by the idea of deep learning, we introduce an MRI denoising method based on the residual encoder–decoder Wasserstein generative adversarial network (RED-WGAN). Specifically, to explore the structure similarity between neighboring slices, a 3D configuration is utilized as the basic processing unit. Residual autoencoders combined with deconvolution operations are introduced into the generator network. Furthermore, to alleviate the oversmoothing shortcoming of the traditional mean squared error (MSE) loss function, the perceptual similarity, which is implemented by calculating the distances in the feature space extracted by a pretrained VGG-19 network, is incorporated with the MSE and adversarial losses to form the new loss function. Extensive experiments are implemented to assess the performance of the proposed method. The experimental results show that the proposed RED-WGAN achieves performance superior to several state-of-the-art methods in both simulated and real clinical data. In particular, our method demonstrates powerful abilities in both noise suppression and structure preservation.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scs.2019.101523,Journal,Sustainable Cities and Society,scopus,2019-07-01,sciencedirect,Cost efficient resource allocation for real-time tasks in embedded systems,https://api.elsevier.com/content/abstract/scopus_id/85065049277,"Various application classes are being deployed to the cloud these days making use of a pay-as-you-go policy. However, existing cloud technologies are still at an early stage of maturity for applications with real-time constraints. With the emergence of Internet of Things (IoT) deployments and embedded systems in smart infrastructure, requirements for off-loading computation to cloud are increasing. In real-time systems, the resource allocation problem is NP-hard, especially when these systems are deployed in cloud computing environments where task execution involves deadline constraints. As a solution, hybrid approaches provide the opportunities to investigate efficient resource allocation for task scheduling problems. We propose a hybridized form of cuckoo search and genetic algorithms known as HGCS (hybrid genetic and cuckoo search) by embedding genetic operators that optimize makespan and cost of real-time tasks scheduled on cloud virtual machines. The inclusion of genetic operators in the cuckoo search algorithm leads to a rigorous search of the solution space, finding the best feasible schedule that can execute tasks in the lowest time, which in turn reduces the total resources usage cost. The performance of the proposed algorithm is tested by using real-time tasks that need data files for successful completion. The HGCS algorithm is evaluated by comparing the results with genetic and cuckoo search algorithms individually. The experimental results favor HGCS over the other two counterparts in providing a schedule respecting the time constraints of the system with reduced makespan and execution cost.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2019.04.007,Journal,Computer Methods and Programs in Biomedicine,scopus,2019-07-01,sciencedirect,MLSeq: Machine learning interface for RNA-sequencing data,https://api.elsevier.com/content/abstract/scopus_id/85064937612,"Background and Objective
                  In the last decade, RNA-sequencing technology has become method-of-choice and prefered to microarray technology for gene expression based classification and differential expression analysis since it produces less noisy data. Although there are many algorithms proposed for microarray data, the number of available algorithms and programs are limited for classification of RNA-sequencing data. For this reason, we developed MLSeq, to bring not only frequently used classification algorithms but also novel approaches together and make them available to be used for classification of RNA sequencing data. This package is developed using R language environment and distributed through BIOCONDUCTOR network.
               
                  Methods
                  Classification of RNA-sequencing data is not straightforward since raw data should be preprocessed before downstream analysis. With MLSeq package, researchers can easily preprocess (normalization, filtering, transformation etc.) and classify raw RNA-sequencing data using two strategies: (i) to perform algorithms which are directly proposed for RNA-sequencing data structure or (ii) to transform RNA-sequencing data in order to bring it distributionally closer to microarray data structure, and perform algorithms which are developed for microarray data. Moreover, we proposed novel algorithms such as voom (an acronym for variance modelling at observational level) based nearest shrunken centroids (voomNSC), diagonal linear discriminant analysis (voomDLDA), etc. through MLSeq.
               
                  Materials
                  Three real RNA-sequencing datasets (i.e cervical cancer, lung cancer and aging datasets) were used to evalute model performances. Poisson linear discriminant analysis (PLDA) and negative binomial linear discriminant analysis (NBLDA) were selected as algorithms based on dicrete distributions, and voomNSC, nearest shrunken centroids (NSC) and support vector machines (SVM) were selected as algorithms based on continuous distributions for model comparisons. Each algorithm is compared using classification accuracies and sparsities on an independent test set.
               
                  Results
                  The algorithms which are based on discrete distributions performed better in cervical cancer and aging data with accuracies above 0.92. In lung cancer data, the most of algorithms performed similar with accuracies of 0.88 except that SVM achieved 0.94 of accuracy. Our voomNSC algorithm was the most sparse algorithm, and able to select 2.2% and 6.6% of all features for cervical cancer and lung cancer datasets respectively. However, in aging data, sparse classifiers were not able to select an optimal subset of all features.
               
                  Conclusion
                  MLSeq is comprehensive and easy-to-use interface for classification of gene expression data. It allows researchers perform both preprocessing and classification tasks through single platform. With this property, MLSeq can be considered as a pipeline for the classification of RNA-sequencing data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2019.03.044,Journal,Information Sciences,scopus,2019-07-01,sciencedirect,A hybrid group decision making framework for achieving agreed solutions based on stable opinions,https://api.elsevier.com/content/abstract/scopus_id/85063603136,"Polarization in a group’s opinions drives to disagreements and dissent among individuals, which make it harder to achieve group satisfactory decisions. Within Group Decision Making (GDM) problems to soften disagreements, lots of consensus reaching processes (CRPs) have been proposed to converge opinions but rarely consider the existing dynamic relationships among the experts. Meanwhile, Opinion Dynamics studies the evolution of opinions based on the relationships existing among the group members by using Social Network Analysis (SNA). In real-world GDM problems the application of CRPs alone may not be enough to achieve the desired level of agreement when there is too much dissent among experts. In this paper, a novel framework is proposed that hybridizes both the process of making closer opinions realized by CRPs and the evolving relationships among experts based on SNA. This new framework addresses when it might be impossible to achieve the agreement through CRPs, which tries to achieve a potential consensus considering that if opinions are too polarized, maybe different stable opinions states are still suitable and easier to achieve by applying a SNA together with the CRP. This framework is further analyzed through simulation experiments for demonstrating its validity and some properties.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2019.01.077,Journal,Expert Systems with Applications,scopus,2019-07-01,sciencedirect,Deep learning in material recovery: Development of method to create training database,https://api.elsevier.com/content/abstract/scopus_id/85061339627,"Increasing the rate of material identification, separation and recovery is a priority in resource management and recovery, and rapid, low cost imaging and interpretation is key. This study uses different combinations of cameras, illuminations and data augmentation techniques to create databases of images to train deep neural networks for the recognition of fibre materials. Using a limited set of 24 material samples sized 1200 cm2, it compares the outcome of reducing them to 30 cm2. The best classification accuracies obtained range from 76.6% to 77.5% indicating it is possible to overcome problems such as limited available materials, time, or storage capabilities, by using a setup with 5 cameras, 5 lights and applying simple software image manipulation techniques. The same method can be used to create deep neural network training databases to recognise a wider range of materials typically found in solid waste streams, in real-time. Furthermore, it offers flexibility as the classification cameras could be deployed at different stages within solid waste processing plants, providing feedback for process control, with the potential of increasing plant efficiency and reducing costs.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2018.01.043,Journal,Future Generation Computer Systems,scopus,2019-07-01,sciencedirect,Combining humans and machines for the future: A novel procedure to predict human interest,https://api.elsevier.com/content/abstract/scopus_id/85042366370,"This paper proposes a method to quantify interest. In common terminology, when we engage with an object, e.g. Online Games, Social Networking Websites, Mobile Apps, etc., there is a degree of interest between us and the object. But, owing to the lack of a procedure that can quantify interest, we are unable to tell by how ‘much’ of a factor are we interested in the object. In other words, can we find a number for someone’s interest? In this article, we propose a method that uses the principle of Bayesian Inference to tackle this issue. We formulate the “interest estimation problem” as a state estimation problem to deduce interest (in any object) indirectly from user activity. Activity caused by interest is computed through a subjective–objectiveweighted approach, then using indirect inference rules, we provide numerical estimates of interest. To do that, we model the dynamics of interest through the Ornstein–Uhlenbeck process. To further enhance the base performance, we draw inspiration from Stochastic Volatility models from Finance. Subsequently, drawing upon a self-adapting transfer function, we provide an avant-garde statistical procedure to model the transformation of interest into activity. The individual contributions are then combined and a solution is provided via Particle filters. Validation of the method is done in two ways. (1) Experimentation is performed on real datasets. Through numerical investigation we have found that the method shows good performance. (2) We implement the framework as a Web application and deploy it on an Enterprise Service Bus. The framework has been successfully hosted on a Cloud based Virtualized testbed consisting of several Virtual Machines constructed over XENServer as the underlying hypervisor. Through this experimental setup, we show the efficacy of the proposed algorithm in estimating interest, at much the same time, we demonstrate the viability of the method in practical cloud based deployment scenarios.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2019.e01806,Journal,Heliyon,scopus,2019-06-01,sciencedirect,Prediction of students’ awareness level towards ICT and mobile technology in Indian and Hungarian University for the real-time: preliminary results,https://api.elsevier.com/content/abstract/scopus_id/85067313361,"An experimental study was conducted to predict the student's awareness of Information and Communication Technology (ICT) and Mobile Technology (MT) in Indian and Hungarian university's students. A primary dataset was gathered from two popular universities located in India and Hungary in the academic year 2017–2018. This paper focuses on the prediction of two major parameters from dataset such as usability and educational benefits using four machine learning classifiers multilayer perceptron (ANN), Support vector machine (SVM), K-nearest neighbor (KNN) and Discriminant (DISC). The multi-classification problem was solved with test, train and validated datasets using machine learning classifiers. One hand, feature aggregation with the train-test-validation technique improved the ANN's prediction accuracy of educational benefits for both countries. Another hand, ANN's accuracy decreases significantly in the prediction of usability. Further, SVM and ANN outperformed the KNN and the DISC in the prediction of awareness level towards ICT and MT in India and Hungary. Also, this paper reveals that the future awareness level for the educational benefits will be Very High or Moderate in both countries. Also, the awareness level is predicted as High and Moderate for usability parameter in both countries. Further, ANN and SVM accuracy and prediction time is compared with T-test at 0.05 significance level which distinguished CPU training time is taken by ANN and SVM using K-fold and Hold out method. Also, K-fold enhanced the significant prediction accuracy of SVM and ANN. the authors also used a STAC web platform to compare the accuracy datasets using T-test and ANOVA test at 0.05 significant level and we found ANN and SVM classifier has no significant difference in prediction accuracy in each dataset. Also, the authors recommend presented predictive models to be deployed as a real-time module of the institute's website for the real-time prediction of ICT & MT awareness level.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mimet.2019.03.003,Journal,Journal of Microbiological Methods,scopus,2019-06-01,sciencedirect,A duplex quantitative real-time PCR assay for the detection and quantification of Xanthomonas phaseoli pv. dieffenbachiae from diseased and latently infected anthurium tissue,https://api.elsevier.com/content/abstract/scopus_id/85064711930,"Anthurium bacterial blight caused by Xanthomonas phaseoli pv. dieffenbachiae (formerly Xanthomonas axonopodis pv. dieffenbachiae) is the major phytosanitary threat in many anthurium growing areas worldwide. Reliable and sensitive diagnostic tools are required for surveillance and certification programs. A duplex real–time quantitative PCR assay was developed for the detection and quantification of X. phaseoli pv. dieffenbachiae from anthurium tissue. This PCR assay targeted a X. phaseoli pv. dieffenbachiae–specific gene encoding an ABC transporter and an internal control encoding for chalcone synthase in Anthurium andreanum. A cycle threshold (Ct), using a receiver-operating characteristic approach (ROC), was implemented to ensure that the declaration of a positive sample was reliable. The duplex real–time assay displayed very high performance with regards to analytical specificity (100% inclusivity, 98.9% exclusivity), analytical sensitivity (LOD95% = 894 bacteria/ml corresponding to 18 bacteria per reaction) and repeatability. We demonstrated the pertinence of this real–time quantitative PCR assay for detecting X. phaseoli pv. dieffenbachiae from diseased leaf tissue (collected from outbreaks on anthurium) and from asymptomatic, latently infected anthurium plants. This assay could be useful for surveillance, as well as for indexing propagative plant material for the presence of X. phaseoli pv. dieffenbachiae.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2019.03.057,Journal,Applied Soft Computing Journal,scopus,2019-06-01,sciencedirect,Compression of recurrent neural networks for efficient language modeling,https://api.elsevier.com/content/abstract/scopus_id/85064251763,"Recurrent neural networks have proved to be an effective method for statistical language modeling. However, in practice their memory and run-time complexity are usually too large to be implemented in real-time offline mobile applications. In this paper we consider several compression techniques for recurrent neural networks including Long–Short Term Memory models. We make particular attention to the high-dimensional output problem caused by the very large vocabulary size. We focus on effective compression methods in the context of their exploitation on devices: pruning, quantization, and matrix decomposition approaches (low-rank factorization and tensor train decomposition, in particular). For each model we investigate the trade-off between its size, suitability for fast inference and perplexity. We propose a general pipeline for applying the most suitable methods to compress recurrent neural networks for language modeling. It has been shown in the experimental study with the Penn Treebank (PTB) dataset that the most efficient results in terms of speed and compression–perplexity balance are obtained by matrix decomposition techniques.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiolchem.2019.03.014,Journal,Computational Biology and Chemistry,scopus,2019-06-01,sciencedirect,Discovery of perturbation gene targets via free text metadata mining in Gene Expression Omnibus,https://api.elsevier.com/content/abstract/scopus_id/85063864313,"There exists over 2.5 million publicly available gene expression samples across 101,000 data series in NCBI's Gene Expression Omnibus (GEO) database. Due to the lack of the use of standardised ontology terms in GEO's free text metadata to annotate the experimental type and sample type, this database remains difficult to harness computationally without significant manual intervention.
                  In this work, we present an interactive R/Shiny tool called GEOracle that utilises text mining and machine learning techniques to automatically identify perturbation experiments, group treatment and control samples and perform differential expression. We present applications of GEOracle to discover conserved signalling pathway target genes and identify an organ specific gene regulatory network.
                  GEOracle is effective in discovering perturbation gene targets in GEO by harnessing its free text metadata. Its effectiveness and applicability has been demonstrated by cross validation and two real-life case studies. It opens up new avenues to unlock the gene regulatory information embedded inside large biological databases such as GEO. GEOracle is available at https://github.com/VCCRI/GEOracle.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.envsoft.2019.02.015,Journal,Environmental Modelling and Software,scopus,2019-06-01,sciencedirect,Building complex event processing capability for intelligent environmental monitoring,https://api.elsevier.com/content/abstract/scopus_id/85061785554,"Rapid evolution of Internet-of-Things is driving the increased deployment of smart sensors in environmental applications, contributing to many big data characteristics of environmental monitoring. Most of the current environmental monitoring systems are not designed to handle real-time datastreams, and the best practices for datastream processing and predictive analytics are yet to be established. This work presents a complex event processing (CEP) engine for detecting anomalies in real time, and demonstrates it using a series of real monitoring data from the geological carbon sequestration domain. We show that the service-based CEP engine is instrumental for enabling environmental intelligent monitoring systems to ingest heterogeneous datastreams with scalable performance. Our CEP framework requires minimal coding from the user and can be easily extended to other similar environmental monitoring applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cogsys.2019.01.003,Journal,Cognitive Systems Research,scopus,2019-06-01,sciencedirect,The CORTEX cognitive robotics architecture: Use cases,https://api.elsevier.com/content/abstract/scopus_id/85060622773,"CORTEX is a cognitive robotics architecture inspired by three key ideas: modularity, internal modelling and graph representations. CORTEX is also a computational framework designed to support early forms of intelligence in real world, human interacting robots, by selecting an a priori functional decomposition of the capabilities of the robot. This set of abilities was then translated to computational modules or agents, each one built as a network of software interconnected components. The nature of these agents can range from pure reactive modules connected to sensors and/or actuators, to pure deliberative ones, but they can only communicate with each other through a graph structure called Deep State Representation (DSR). DSR is a short-term dynamic representation of the space surrounding the robot, the objects and the humans in it, and the robot itself. All these entities are perceived and transformed into different levels of abstraction, ranging from geometric data to high-level symbolic relations such as “the person is talking and gazing at me”. The combination of symbolic and geometric information endows the architecture with the potential to simulate and anticipate the outcome of the actions executed by the robot. In this paper we present recent advances in the CORTEX architecture and several real-world human-robot interaction scenarios in which they have been tested. We describe our interpretation of the ideas inspiring the architecture and the reasons why this specific computational framework is a promising architecture for the social robots of tomorrow.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2018.12.038,Journal,Future Generation Computer Systems,scopus,2019-06-01,sciencedirect,Code authorship identification using convolutional neural networks,https://api.elsevier.com/content/abstract/scopus_id/85059761266,"Although source code authorship identification creates a privacy threat for many open source contributors, it is an important topic for the forensics field and enables many successful forensic applications, including ghostwriting detection, copyright dispute settlements, and other code analysis applications. This work proposes a convolutional neural network (CNN) based code authorship identification system. Our proposed system exploits term frequency-inverse document frequency, word embedding modeling, and feature learning techniques for code representation. This representation is then fed into a CNN-based code authorship identification model to identify the code’s author. Evaluation results from using our approach on data from Google Code Jam demonstrate an identification accuracy of up to 99.4% with 150 candidate programmers, and 96.2% with 1,600 programmers. The evaluation of our approach also shows high accuracy for programmers identification over real-world code samples from 1987 public repositories on GitHub with 95% accuracy for 745 C programmers and 97% for the C++ programmers. These results indicate that the proposed approaches are not language-specific techniques and can identify programmers of different programming languages.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.net.2018.12.020,Journal,Nuclear Engineering and Technology,scopus,2019-06-01,sciencedirect,Numerical evaluation of gamma radiation monitoring,https://api.elsevier.com/content/abstract/scopus_id/85059358720,"Airborne Gamma Ray Spectrometry (AGRS) with its important applications such as gathering radiation information of ground surface, geochemistry measuring of the abundance of Potassium, Thorium and Uranium in outer earth layer, environmental and nuclear site surveillance has a key role in the field of nuclear science and human life. The Broyden–Fletcher–Goldfarb–Shanno (BFGS), with its advanced numerical unconstrained nonlinear optimization in collaboration with Artificial Neural Networks (ANNs) provides a noteworthy opportunity for modern AGRS. In this study a new AGRS system empowered by ANN-BFGS has been proposed and evaluated on available empirical AGRS data. To that effect different architectures of adaptive ANN-BFGS were implemented for a sort of published experimental AGRS outputs. The selected approach among of various training methods, with its low iteration cost and non-diagonal scaling allocation is a new powerful algorithm for AGRS data due to its inherent stochastic properties. Experiments were performed by different architectures and trainings, the selected scheme achieved the smallest number of epochs, the minimum Mean Square Error (MSE) and the maximum performance in compare with different types of optimization strategies and algorithms. The proposed method is capable to be implemented on a cost effective and minimum electronic equipment to present its real-time process, which will let it to be used on board a light Unmanned Aerial Vehicle (UAV). The advanced adaptation properties and models of neural network, the training of stochastic process and its implementation on DSP outstands an affordable, reliable and low cost AGRS design. The main outcome of the study shows this method increases the quality of curvature information of AGRS data while cost of the algorithm is reduced in each iteration so the proposed ANN-BFGS is a trustworthy appropriate model for Gamma-ray data reconstruction and analysis based on advanced novel artificial intelligence systems.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.datak.2019.05.003,Journal,Data and Knowledge Engineering,scopus,2019-05-01,sciencedirect,SubspaceDB: In-database subspace clustering for analytical query processing,https://api.elsevier.com/content/abstract/scopus_id/85066093010,"High dimensional data analysis within relational database management systems (RDBMS) is challenging because of inadequate support from SQL. Currently, subspace clustering of high dimensional data is implemented either outside DBMS using wrapper code or inside DBMS using SQL User Defined Functions/Aggregates(UDFs/UDAs). However, both these approaches have potential disadvantages from performance, resource usage, and security perspective for voluminous and frequently updated data. Hence, we propose an efficient querying system, named SubspaceDB, that implements subspace clustering directly within an RDBMS. SubspaceDB provides a novel set of query operators, each with an optimization objective, to facilitate interactive analysis for subspace clustering. The query operators focus on retrieving optimal answers to four key query types : (a) Medoid queries, (b) Neighbourhood queries, (c) Partial similarity queries, and (d) Prominence queries, that aid the formation of subspace clusters. Experimental studies on real and synthetic databases of size 
                        15
                        M
                      tuples and 104 attributes show that our proposed approach SubspaceDB can be over 10 times faster as compared to a conventional wrapper-based or SQL UDF approach. The proposed approach is also efficient in retrieving at least 50% data with performance improvement of at least 25%.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.amsu.2019.04.001,Journal,Annals of Medicine and Surgery,scopus,2019-05-01,sciencedirect,"Artificial intelligence, regenerative surgery, robotics? What is realistic for the future of surgery?",https://api.elsevier.com/content/abstract/scopus_id/85064430299,"The potential of surgery lies in the technological advances that would complement it. The landscape of the field will differ depending on the time period being looked at and would no doubt include conjecture. Initial breakthroughs will need to pave the way for future medical technology and apply to the surgical sciences. Within the next 10 years we would expect to see the emergence of big data analysis, cuttingedge image processing techniques for surgical planning and better implementation of virtual and augmented reality in operating theatres for both patient care and teaching purposes. Over the next 50 to 100 years, the use of quantum computing should lead to increased automation in our healthcare systems. The inception of novel biomaterial invention and advanced genetic engineering will usher in the new age of regenerative medicine in the clinical setting. The future of surgery includes many predictions and promises, but it is apparent that the development will lead to bettering outcome and focus on patient care.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.enconman.2019.02.086,Journal,Energy Conversion and Management,scopus,2019-05-01,sciencedirect,"Multi-step short-term wind speed forecasting approach based on multi-scale dominant ingredient chaotic analysis, improved hybrid GWO-SCA optimization and ELM",https://api.elsevier.com/content/abstract/scopus_id/85063231962,"Accurate wind speed prediction possesses a significant impact on reasonable scheduling and safe operation of power system. For this purpose, a novel hybrid approach based on multi-scale dominant ingredient chaotic analysis, improved hybrid GWO-SCA (IHGWOSCA) algorithm and extreme learning machine (ELM) is proposed for multi-step short-term wind speed prediction, in which the multi-scale dominant ingredient chaotic analysis combines the proposed optimal variational mode decomposition (OVMD), singular spectrum analysis (SSA) and phase space reconstruction (PSR). To begin with, the mode number and updating step of VMD are pre-determined by center frequency observation method and the proposed least-squares error index (LSEI), thus decomposing the non-stationary wind speed series into a set of intrinsic mode functions (IMFs). Later, the extraction of the dominant ingredient and residuary ingredient for each sub-series is implemented by SSA for the construction of forecasting components. Subsequently, the proposed IHGWOSCA algorithm coded with discrete integers and real-valued are investigated to search optimal parameters in PSR and ELM successively. Lastly, the ultimate forecasting results of the original wind speed are calculated by accumulating results of all the predicted components. Furthermore, seven data sets from Sotavento Galicia and Inner Mongolia have been employed to evaluate the proposed approach. The results illustrate that: (1) the proposed OVMD-based models obtained better RMSE, MAE and MAPE indexes comparing with the benchmark models through weakening the non-stationary of the original signal; (2) the proposed dominant ingredient chaotic analysis combining SSA and PSR enhanced the multi-steps prediction performance effectively; (3) the proposed IHGWOSCA optimization algorithm possessed good capability for optimal parameters searching and fast convergence.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2019.03.001,Journal,Engineering Applications of Artificial Intelligence,scopus,2019-05-01,sciencedirect,Affective analytics of demonstration sites,https://api.elsevier.com/content/abstract/scopus_id/85062991999,"Multiple-criteria decision-making (MCDM) typically assumes that crowds make completely rational decisions. In MCDM, a crowd as a whole, or its individual members, generally make decisions free from any influence of valence, arousal, emotional state or environment. In contrast, various theories dealing with crowd psychology (Gustave Le Bon, Freudian, Deindividuation, Convergence, Emergent norm, Social identity) analyze, in one form or another, the emotions of the crowd. According to above theories, crowd is influenced by a range of behavioral factors, such as physical, social, psychological, culture, norms, and emotions. It can be argued that the emotional state, valence and arousal of crowds affect their decision making to a considerable degree and multiple criteria crowd behavior modeling must, therefore, consider this impact as well. In this light, the integration of crowd simulation and biometric methods, behavioral operations research and emotions in decision making has taken a prominent place as it leads to a better understanding of crowd emotions and crowd decision making. In this context, the authors developed the Affective Analytics of Demonstration Sites (ANDES) that added to this body of research in four ways. The crowd analysis and simulations conducted with ANDES used a neuro decision matrix. The matrix contains a detailed description of demonstration sites (public spaces) in question and the emotions, valence, arousal and physiological parameters of people present there. With ANDES’s Remote Sensor Network, emotional (emotions, valence, arousal) and physiological (average crowd facial temperature, crowd composition by gender and age group, etc.) parameters of people present at demonstration sites can be mapped. ANDES can assist experts in more effective implementations of public spaces planning and a participation process by attendees by collecting and examining various layers of data on the emotional and physiological parameters of visitors based on a visitors-centric public spaces planning approach. ANDES can determine the public space and real estate values.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2018.11.017,Journal,Robotics and Autonomous Systems,scopus,2019-05-01,sciencedirect,A real-time framework for kinodynamic planning in dynamic environments with application to quadrotor obstacle avoidance,https://api.elsevier.com/content/abstract/scopus_id/85062619374,"The objective of this paper is to present a full-stack, real-time motion planning framework for kinodynamic robots and then show how it is applied and demonstrated on a physical quadrotor system operating in a laboratory environment. The proposed framework utilizes an offline–online computation paradigm, neighborhood classification through machine learning, sampling-based motion planning with an optimal cost distance metric, and trajectory smoothing to achieve real-time planning for aerial vehicles. This framework accounts for dynamic obstacles with an event-based replanning structure and a locally reactive control layer that minimizes replanning events. The approach is demonstrated on a quadrotor navigating moving obstacles in an indoor space and stands as, arguably, one of the first demonstrations of full-online kinodynamic motion planning, with execution cycles of 3 Hz to 5 Hz. For the quadrotor, a simplified dynamics model is used during the planning phase to accelerate online computation. A trajectory smoothing phase, which leverages the differentially flat nature of quadrotor dynamics, is then implemented to guarantee a dynamically feasible trajectory.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jad.2019.03.044,Journal,Journal of Affective Disorders,scopus,2019-05-01,sciencedirect,Short-term prediction of suicidal thoughts and behaviors in adolescents: Can recent developments in technology and computational science provide a breakthrough?,https://api.elsevier.com/content/abstract/scopus_id/85062497590,"Background
                  Suicide is one of the leading causes of death among adolescents, and developing effective methods to improve short-term prediction of suicidal thoughts and behaviors (STBs) is critical. Currently, the most robust predictors of STBs are demographic or clinical indicators that have relatively weak predictive value. However, there is an emerging literature on short-term prediction of suicide risk that has identified a number of promising candidates, including (but not limited to) rapid escalation of: (a) emotional distress, (b) social dysfunction (e.g., bullying, rejection), and (c) sleep disturbance. However, these prior studies are limited in two critical ways. First, they rely almost entirely on self-report. Second, most studies have not focused on assessment of these risk factors using intensive longitudinal assessment techniques that are able to capture the dynamics of changes in risk states at the individual level.
               
                  Method
                  In this paper we explore how to capitalize on recent developments in real-time monitoring methods and computational analysis in order to address these fundamental problems.
               
                  Results
                  We now have the capacity to use: (a) smartphone, wearable computing, and smart home technology to conduct intensive longitudinal assessments monitoring of putative risk factors with minimal participant burden and (b) modern computational techniques to develop predictive algorithms for STBs. Current research and theory on short-term risk processes for STBs, combined with the emergent capabilities of new technologies, suggest that this is an important research agenda for the future.
               
                  Limitations
                  Although these approaches have enormous potential to create new knowledge, the current empirical literature is limited. Moreover, passive monitoring of risk for STBs raises complex ethical issues that will need to be resolved before large scale clinical applications are feasible.
               
                  Conclusions
                  Smartphone, wearable, and smart home technology may provide one point of access that might facilitate both early identification and intervention implementation, and thus, represents a key area for future STB research.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.petrol.2019.01.089,Journal,Journal of Petroleum Science and Engineering,scopus,2019-05-01,sciencedirect,Predicting seismic-based risk of lost circulation using machine learning,https://api.elsevier.com/content/abstract/scopus_id/85061035639,"Lost circulation during well drilling and completion wastes productive time, and even kills the well in severe cases. Timely identifying lost circulation events and taking countermeasures has been the focus of related study. However, a real prediction of lost circulation risk before drilling would be an active response to the challenge. In this paper, a technical solution is proposed to evaluate geological lost-circulation risk in the field using 3D seismic data attributes and machine learning technique. First, four seismic attributes (variance, attenuation, sweetness, RMS amplitude) that are the most correlated with lost circulation incidents are recommended. Then a prediction model is built by conducting supervised learning that involves a majority voting algorithm. The performance of the model is illustrated by six unseen drilled wells and shows the ability and potential to forecast lost circulation probability both along well trajectory and in the region far away from the drilled wells. The prediction resolution in the lateral and vertical direction is about 25 m and 6 m (2 ms), respectively, which are distinct advantages over the traditional description of geological structures using seismic data. It shows that the lost circulation risk can be hardly recognized by interpreting one specific seismic attribute, which is a common practice. Finally, the challenges in predicting lost circulation risk using seismic data are summarized. Overall, the study suggests that machine learning would be a practical solution to predict various construction risks that are related to seismic-based geological issues. Knowing in advance the risks, people could avoid or at least minimize the losses by optimizing well deployment in the field and taking preventive measures.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2019.01.028,Journal,Information Sciences,scopus,2019-05-01,sciencedirect,A divide and agglomerate algorithm for community detection in social networks,https://api.elsevier.com/content/abstract/scopus_id/85059953640,"Communities, or clusters, are usually subgraphs of nodes densely interconnected but sparsely linked with others. The nodes with similar properties or behaviors are more likely to be in the same community, and vice versa. However, due to the complexity and diversity of networks, the accurate organization or function of communities in many real networks is often extremely difficult to be recognized. Hence, methods for community detection would have immediate impact on understanding the organizations and functions of networks. Therefore, algorithm design becomes a fundamental problem for many networks. In this paper, the local and global information are applied together to propose a divide and agglomerate (DA) algorithm for community detection in social networks. The DA algorithm achieves the result with a two-stage strategy: Dividing a network into small groups according to node pairs’ similarities, and merging a group with the other who has the biggest attraction for it until the community criterion is steady. The novel similarity, constrained AA index captures the local and global information ensuring the optimal communities detection. The results of experiments show that DA algorithm obtains superior community results compared with six other widely used algorithms, which indicate that DA algorithm has advantages for community detection.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ipm.2018.04.011,Journal,Information Processing and Management,scopus,2019-05-01,sciencedirect,Real-time processing of social media with SENTINEL: A syndromic surveillance system incorporating deep learning for health classification,https://api.elsevier.com/content/abstract/scopus_id/85048575075,"Interest in real-time syndromic surveillance based on social media data has greatly increased in recent years. The ability to detect disease outbreaks earlier than traditional methods would be highly useful for public health officials. This paper describes a software system which is built upon recent developments in machine learning and data processing to achieve this goal. The system is built from reusable modules integrated into data processing pipelines that are easily deployable and configurable. It applies deep learning to the problem of classifying health-related tweets and is able to do so with high accuracy. It has the capability to detect illness outbreaks from Twitter data and then to build up and display information about these outbreaks, including relevant news articles, to provide situational awareness. It also provides nowcasting functionality of current disease levels from previous clinical data combined with Twitter data.
                  The preliminary results are promising, with the system being able to detect outbreaks of influenza-like illness symptoms which could then be confirmed by existing official sources. The Nowcasting module shows that using social media data can improve prediction for multiple diseases over simply using traditional data sources.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cels.2019.03.003,Journal,Cell Systems,scopus,2019-04-24,sciencedirect,DoubletFinder: Doublet Detection in Single-Cell RNA Sequencing Data Using Artificial Nearest Neighbors,https://api.elsevier.com/content/abstract/scopus_id/85064396876,"Single-cell RNA sequencing (scRNA-seq) data are commonly affected by technical artifacts known as “doublets,” which limit cell throughput and lead to spurious biological conclusions. Here, we present a computational doublet detection tool—DoubletFinder—that identifies doublets using only gene expression data. DoubletFinder predicts doublets according to each real cell’s proximity in gene expression space to artificial doublets created by averaging the transcriptional profile of randomly chosen cell pairs. We first use scRNA-seq datasets where the identity of doublets is known to show that DoubletFinder identifies doublets formed from transcriptionally distinct cells. When these doublets are removed, the identification of differentially expressed genes is enhanced. Second, we provide a method for estimating DoubletFinder input parameters, allowing its application across scRNA-seq datasets with diverse distributions of cell types. Lastly, we present “best practices” for DoubletFinder applications and illustrate that DoubletFinder is insensitive to an experimentally validated kidney cell type with “hybrid” expression features.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.15232/aas.2018-01801,Journal,Applied Animal Science,scopus,2019-04-01,sciencedirect,INVITED REVIEW: Current state of wearable precision dairy technologies in disease detection,https://api.elsevier.com/content/abstract/scopus_id/85067379776,"Purpose
                  The primary objective of this review article is to provide insight into the role of wearable precision dairy technologies (WPDT) in detection of lameness, mastitis, metabolic disorders, and metritis.
               
                  Sources
                  This review is separated into 3 sections: overview of technology development; WPDT behavioral variables linked to disease; and WPDT detection of disease and disorders. Through Web of Science, Google Scholar, and SPAC (Searchable Proceedings of Animal Conferences, ADSA), 99 publications were identified that discuss WPDT that can be used for disease detection and associated similar abnormal behaviors.
               
                  Synthesis
                  Precision dairy technology is the real-time monitoring of animals through behavior monitoring, milk constituents, milk yield, video analysis, record analysis, and physiological monitoring. Technologies can be wearable, incorporated into the milking system, stand alone, or part of the management software. Real-time monitoring has the potential to improve individual cow management and overall farm efficiency. Wearable precision dairy technologies reside on or within the cow for some amount of time. These WPDT currently can measure an individual cow’s time spent at the feed bunk, rumination time, eating time, lying time, standing time, walking time, activity, lying-to-standing transitions, temperature, and rumen pH and provide a cow’s location. Recently, WPDT marketed for estrus detection were adapted for disease detection.
               
                  Conclusions and Applications
                  Potential does exist for WPDT disease detection. Technologies can identify changes in behavior associated with disease or disorders, although no technologies currently provide disease-specific alerts. Future studies should focus on incorporating multiple behavior, physiological, and herd records with machine-learning techniques to create timely, disease-specific alerts.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mfglet.2019.05.003,Journal,Manufacturing Letters,scopus,2019-04-01,sciencedirect,A blockchain enabled Cyber-Physical System architecture for Industry 4.0 manufacturing systems,https://api.elsevier.com/content/abstract/scopus_id/85066168835,"Cyber-Physical Production Systems (CPPSs) are complex manufacturing systems which aim to integrate and synchronize machine world and manufacturing facility to the cyber computational space. However, having intensive interconnectivity and a computational platform is crucial for real-world implementation of CPPSs. In this paper, the potential impacts of blockchain technology in development and realization of real-world CPPSs are discussed. A unified three-level blockchain architecture is proposed as a guideline for researchers and industries to clearly identify the potentials of blockchain and adapt, develop, and incorporate this technology with their manufacturing developments towards Industry 4.0.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eng.2018.11.027,Journal,Engineering,scopus,2019-04-01,sciencedirect,The State of the Art of Data Science and Engineering in Structural Health Monitoring,https://api.elsevier.com/content/abstract/scopus_id/85062663661,"Structural health monitoring (SHM) is a multi-discipline field that involves the automatic sensing of structural loads and response by means of a large number of sensors and instruments, followed by a diagnosis of the structural health based on the collected data. Because an SHM system implemented into a structure automatically senses, evaluates, and warns about structural conditions in real time, massive data are a significant feature of SHM. The techniques related to massive data are referred to as data science and engineering, and include acquisition techniques, transition techniques, management techniques, and processing and mining algorithms for massive data. This paper provides a brief review of the state of the art of data science and engineering in SHM as investigated by these authors, and covers the compressive sampling-based data-acquisition algorithm, the anomaly data diagnosis approach using a deep learning algorithm, crack identification approaches using computer vision techniques, and condition assessment approaches for bridges using machine learning algorithms. Future trends are discussed in the conclusion.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.resuscitation.2019.02.019,Journal,Resuscitation,scopus,2019-04-01,sciencedirect,Development of a novel cardiopulmonary resuscitation measurement tool using real-time feedback from wearable wireless instrumentation,https://api.elsevier.com/content/abstract/scopus_id/85062471861,"Aim
                  The design and implementation of a wearable training device to improve cardiopulmonary resuscitation (CPR) is presented.
               
                  Methods
                  The MYO contains both Electromyography (EMG) and Inertial Measurement Unit (IMU) sensors which are used to detect effective CPR, and the four common incorrect hand and arm positions viz. relaxed fingers; hands too low on the sternum; patient too close; or patient too far. The device determines the rate and depth of compressions calculated using a Fourier transform and dual-quaternions respectively. In addition, common positional mistakes are determined using classification algorithms (six machine learning algorithms are considered and tested). Feedback via Graphical User Interface (GUI) and audio is integrated.
               
                  Results
                  The system is tested by performing CPR on a mannequin and comparing real-time results to theoretical values. Tests show that although the classification algorithm performed well in testing (98%), in real time, it had low accuracy for certain categories (60%), which are attributable to the MYO calibration, sampling rate and misclassification of similar hand positions. Combining these similar incorrect positions into more general categories significantly improves accuracy, and produces the same improved outcome of improved CPR. The rate and depth measures have a general accuracy of 97%.
               
                  Conclusion
                  The system allows for portable, real-time feedback for use in training and in the field, and shows promise toward classifying and improving the administration of CPR.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.forsciint.2019.02.028,Journal,Forensic Science International,scopus,2019-04-01,sciencedirect,Chat Analysis Triage Tool: Differentiating contact-driven vs. fantasy-driven child sex offenders,https://api.elsevier.com/content/abstract/scopus_id/85062400557,"Investigating crimes against children, specifically sexual solicitations, are complicated because not all offenders are contact-driven, meaning they want to meet the minor for sex in the physical world; instead, some offenders are fantasy-driven, in that they are more interested in cybersex and role-play. In addition, the sheer volume of cases involving the online sexual solicitation of minors makes it difficult for law enforcement to determine whether an offender is contact-driven vs. fantasy-driven. However, research shows that there are language-based differences between minors and contact-driven offenders vs. fantasy driven-offenders. Thus, we developed the Chat Analysis Triage Tool (CATT), a forensically sound investigative tool that, based on natural language processing methods, analyzes and compares chats between minors and contact-driven vs. non-contract driven offenders. Using an SVM classifier, we were successful in differentiating the classes based on character trigrams. In a matter of seconds, the existing algorithms provide an identification of an offender’s risk level based on the likelihood of contact offending as inferred from the model, which assists law enforcement in their ability to triage and prioritize cases involving the sexual solicitation of minors.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mehy.2019.02.021,Journal,Medical Hypotheses,scopus,2019-04-01,sciencedirect,Percolation theory for the recognition of patterns in topographic images of the cortical activity,https://api.elsevier.com/content/abstract/scopus_id/85061357293,"Electroencephalogram (EEG) is one of the mechanisms used to collect complex data. Its use includes evaluating neurological disorders, investigating brain function and correlations between EEG signals and real or imagined movements. The Topographic Image of Cortical Activity (TICA) records obtained by the EEG make it possible to observe, through color discrimination, the cortical areas that represent greater or lesser activity. Percolation Theory (PT) reveals properties on the aspects of fluid spreading from a central point, these properties being related to the aspects of the medium, topological characteristics and ease of penetration of a fluid in materials. The hypothesis presented so far considers that synaptic activities originate in points and spread from them, causing different areas of the brain to interact in a diffusive associative behavior, generating electric and magnetic fields by the currents that spread through the brain tissue and have an effect on the scalp sensors. Brain areas spatially separated create large-scale dynamic networks that are described by functional and effective connectivity. The proposition is that this phenomenon behaves like a fluidic spreading, so we can use the PT, through the topological analysis we detect specific signatures related to neural phenomena that manifest changes in the behavior of synaptic diffusion. This signature must be characterized by the Fractal Dimension (FD) values of the scattering clusters, these values will be used as properties in the k-Nearest Neighbors (kNN) method, an TICA will be categorized according to the degree of similarity to the preexisting patterns. In this context, our hypothesis will consolidate as a more computational resource in the service of medicine and another way that opens with the possibility of analysis and detailed inferences of the brain through TICA that go beyond a simply visual observation, as it happens in the present day.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2018.11.028,Journal,Information Sciences,scopus,2019-04-01,sciencedirect,Machine learning based privacy-preserving fair data trading in big data market,https://api.elsevier.com/content/abstract/scopus_id/85056879362,"In the era of big data, the produced and collected data explode due to the emerging technologies and applications that pervade everywhere in our daily lives, including internet of things applications such as smart home, smart city, smart grid, e-commerce applications and social network. Big data market can carry out efficient data trading, which provides a way to share data and further enhances the utility of data. However, to realize effective data trading in big data market, several challenges need to be resolved. The first one is to verify the data availability for a data consumer. The second is privacy of a data provider who is unwilling to reveal his real identity to the data consumer. The third is the payment fairness between a data provider and a data consumer with atomic exchange. In this paper, we address these challenges by proposing a new blockchain-based fair data trading protocol in big data market. The proposed protocol integrates ring signature, double-authentication-preventing signature and similarity learning to guarantee the availability of trading data, privacy of data providers and fairness between data providers and data consumers. We show the proposed protocol achieves the desirable security properties that a secure data trading protocol should have. The implementation results with Solidity smart contract demonstrate the validity of the proposed blockchain-based fair data trading protocol.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2018.01.054,Journal,Future Generation Computer Systems,scopus,2019-04-01,sciencedirect,Scalable distributed control plane for On-line social networks support cognitive neural computing in software defined networks,https://api.elsevier.com/content/abstract/scopus_id/85042335028,"Though most of the current proposed distributed control planes maintain strong consistency among their controllers, this paper argues the strong consistency is not a prerequisite and proposes an Event Coordination System (ECS) that enables an efficient event replaying system and a distributed control plane (DisCon) using this event replaying system to construct eventually consistent global network topologies among its controllers without sacrificing scalability. Our ECS implements a novel request handling procedure that ensures a firstly received write request is firstly multi-casted, notified, and updated, so thus our DisCon can maximally ensure the same time sequence in which topology events get updated at different controllers and the constructed topologies can reflect the real network change in practice. We highlight the major mechanisms used, discuss the major causes of this eventual consistency, estimate the inconsistency window among controllers, and show how this eventual consistency does not make a big difference in supporting network applications. Experiments are conducted to evaluate our ECS and DisCon. The results show our DisCon has a larger event replay throughput and a lower event converging delay than HyperFlow, and larger flow setup rate and lower flow setup delay than most of the current distributed control planes.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2019.01.019,Journal,Neurocomputing,scopus,2019-03-28,sciencedirect,Multi-view transfer learning with privileged learning framework,https://api.elsevier.com/content/abstract/scopus_id/85060576231,"In this paper, we present a multi-view transfer learning model named Multi-view Transfer Discriminative Model (MTDM) for both image and text classification tasks. Transfer learning, which aims to learn a robust classifier for the target domain using data from a different distribution, has been proved to be effective in many real-world applications. However, most of the existing transfer learning methods map across domain data into a high-dimension space which the distance between domains is closed. This strategy always fails in the multi-view scenario. On the contrary, the multi-view learning methods are also difficult to extend in the transfer learning settings. One of our goals in this paper is to develop a model which can perform better in both multi-view and transfer learning settings. On the one hand, the problem of multi-view is implemented by the paradigm of learning using privileged information (LUPI), which could guarantee the principle of complementary and consensus. On the other hand, the model adequately utilizes the source domain data to build a robust classifier for the target domain. We evaluate our model on both image and text classification tasks and show the effectiveness compared with other baseline approaches.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.matdes.2018.107577,Journal,Materials and Design,scopus,2019-03-05,sciencedirect,Ensemble Kalman filter-based data assimilation for three-dimensional multi-phase-field model: Estimation of anisotropic grain boundary properties,https://api.elsevier.com/content/abstract/scopus_id/85059744257,"Data assimilation (DA) has been used as a machine learning approach to estimate a system's state and the unknown parameters in its numerical model by integrating observed data into model predictions. In this paper, we propose using the DA methodology based on the ensemble Kalman filter (EnKF) to improve the accuracy of microstructure prediction using three-dimensional multi-phase-field (3D-MPF) model and estimate the model parameters simultaneously. To demonstrate the applicability of the DA methodology, we performed numerical experiments in which a priori assumed true parameters related to the grain boundary (GB) energy cusp and GB mobility peak of Σ7 coincidence site lattice GB were estimated from synthetic data of time-evolving polycrystalline microstructure. Four model parameters related to the Σ7 GB properties were successfully estimated by assimilating the synthetic microstructure data to the 3D-MPF model predictions using the EnKF-based DA method. Furthermore, we accurately reproduced the preliminarily assumed true shapes of GB energy cusp and GB mobility peak by using the estimated parameters. The results suggest that implementation of the EnKF-based DA method in the MPF model has great potential for identifying unknown material properties and estimating unmeasurable microstructure evolutions in polycrystalline materials based on real time-series 3D microstructure observation data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.dss.2019.01.003,Journal,Decision Support Systems,scopus,2019-03-01,sciencedirect,Deep learning based personalized recommendation with multi-view information integration,https://api.elsevier.com/content/abstract/scopus_id/85060338648,"With the rapid proliferation of images on e-commerce platforms today, embracing and integrating versatile information sources have become increasingly important in recommender systems. Owing to the heterogeneity in information sources and consumers, it is necessary and meaningful to consider the potential synergy between visual and textual content as well as consumers' different cognitive styles. This paper proposes a multi-view model, namely, Deep Multi-view Information iNtEgration (Deep-MINE), to take multiple sources of content (i.e., product images, descriptions and review texts) into account and design an end-to-end recommendation model. In doing so, stacked auto-encoder networks are deployed to map multi-view information into a unified latent space, a cognition layer is added to depict consumers' heterogeneous cognition styles and an integration module is introduced to reflect the interaction of multi-view latent representations. Extensive experiments on real world data demonstrate that Deep-MINE achieves high accuracy in product ranking, especially in the cold-start case. In addition, Deep-MINE is able to boost overall model performance compared with models taking a single view, further verifying the proposed model's effectiveness on information integration.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.solener.2019.01.027,Journal,Solar Energy,scopus,2019-03-01,sciencedirect,ANN based automatic slat angle control of venetian blind for minimized total load in an office building,https://api.elsevier.com/content/abstract/scopus_id/85059868380,"Windows are the only part of a building that can directly penetrate the solar radiation into the occupied space and thus the shading devices are needed to control the solar penetration. A variety of research have been conducted to develop the optimized slat angle control in the existing literature, but the research incorporating artificial intelligence technique with slat angle control is limited thus far. Therefore, in this study, the ANN (Artificial Neural Network) model was applied to minimize the combined total load consisting of lighting, cooling, and heating loads through automatic slat angle control of venetian blinds. A three-story rectangular office building was simulated using EnergyPlus, and dimming control was applied to control the lighting. The interlocked simulation between Matlab and EnergyPlus was conducted through BCVTB. As a result of comparing automatic blind control via the ANN to fixed blind slat angle, the automatic blind control via the ANN showed 9.1% lower total load than the blind angle fixed at 50°. It was confirmed that the cooling and heating load could be significantly reduced by real-time automatic control via the ANN under various operating conditions, rather than fixing the blinds at one angle.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.resourpol.2018.12.013,Journal,Resources Policy,scopus,2019-03-01,sciencedirect,State of the art about metaheuristics and artificial neural networks applied to open pit mining,https://api.elsevier.com/content/abstract/scopus_id/85059167765,"In search of the best way to extract and take advantage of minerals, highlighting that these are part of the most important raw materials for the economic development of today's society, the following bibliographical review is presented, which covers the main metaheuristic techniques highlighted in the optimization of mining processes and artificial neural networks (ANN), fundamental for predicting them; With this, the applications and results of these methods can be observed in mining unit operations such as: blasting, transport and mineral processing, which until now have models or techniques for their prediction that are not applicable in all mining complexes, as well as metaheuristics for three fundamental variables of open-pit planning, which are: geological uncertainty, cutting law and extraction programming. In addition to this, the proposals that have been developed in the global optimization of mining complexes are shown. There is also a brief description of how these techniques were applied to optimize the operations and previous variables of the mining planning, as well as their implementation in several mines around the world. The information shown shows available alternatives for the implementation of new actions in favor of reaching the objectives for real and hypothetical sites, yielding satisfactory results. Finally, the conclusions of this work are presented.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ress.2018.07.024,Journal,Reliability Engineering and System Safety,scopus,2019-03-01,sciencedirect,A new approach for estimating the parameters of Weibull distribution via particle swarm optimization: An application to the strengths of glass fibre data,https://api.elsevier.com/content/abstract/scopus_id/85056745362,"Three-parameter Weibull is one of the most popular and most widely-used distribution in many fields of science. Therefore, many studies have been conducted concerning the statistical inferences of the parameters of Weibull distribution. In general, the maximum likelihood (ML) methodology is used in the estimation process of unknown parameters. In this study, the ML estimation of the parameters of Weibull distribution is considered using particle swarm optimization (PSO). As in other heuristic optimization methods, the performance of PSO is affected by initial conditions. The novelty of this study comes from the fact that we propose a new adaptive search space based on confidence intervals in PSO. The modified maximum likelihood (MML) estimators are utilized for constructing the confidence intervals. MML based confidence intervals allow a narrower search space for the parameters of Weibull distribution than the search space used in the literature. Therefore, the performance of PSO increases, since the search space is wisely narrowed. In order to show the performance of the proposed approach, an extensive Monte-Carlo simulation study is conducted. Simulation results show that the proposed approach works well. In addition, real world data is analyzed to show implementation of the proposed method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2018.02.011,Journal,Future Generation Computer Systems,scopus,2019-03-01,sciencedirect,Collaborative prognostics in Social Asset Networks,https://api.elsevier.com/content/abstract/scopus_id/85042391186,"With the spread of Internet of Things (IoT) technologies, assets have acquired communication, processing and sensing capabilities. In response, the field of Asset Management has moved from fleet-wide failure models to individualised asset prognostics. Individualised models are seldom truly distributed, and often fail to capitalise the processing power of the asset fleet. This leads to hardly scalable machine learning centralised models that often must find a compromise between accuracy and computational power. In order to overcome this, we present a novel theoretical approach to collaborative prognostics within the Social Internet of Things. We introduce the concept of Social Asset Networks, defined as networks of cooperating assets with sensing, communicating and computing capabilities. In the proposed approach, the information obtained from the medium by means of sensors is synthesised into a Health Indicator, which determines the state of the asset. The Health Indicator of each asset evolves according to an equation determined by a triplet of parameters. Assets are given the form of the equation but they ignore their parametric values. To obtain these values, assets use the equation in order to perform a non-linear least squares fit of their Health Indicator data. Using these estimated parameters, they are interconnected to a subset of collaborating assets by means of a similarity metric. We show how by simply interchanging their estimates, networked assets are able to precisely determine their Health Indicator dynamics and reduce maintenance costs. This is done in real time, with no centralised library, and without the need for extensive historical data. We compare Social Asset Networks with the typical self-learning and fleet-wide approaches, and show that Social Asset Networks have a faster convergence and lower cost. This study serves as a conceptual proof for the potential of collaborative prognostics for solving maintenance problems, and can be used to justify the implementation of such a system in a real industrial fleet.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.oceaneng.2019.01.003,Journal,Ocean Engineering,scopus,2019-02-01,sciencedirect,Data management for structural integrity assessment of offshore wind turbine support structures: data cleansing and missing data imputation,https://api.elsevier.com/content/abstract/scopus_id/85061324147,"Structural Health Monitoring (SHM) and Condition Monitoring (CM) Systems are currently utilised to collect data from offshore wind turbines (OWTs), to enhance the accurate estimation of their operational performance. However, industry accepted practices for effectively managing the information that these systems provide have not been widely established yet. This paper presents a four-step methodological framework for the effective data management of SHM systems of OWTs and illustrates its applicability in real-time continuous data collected from three operational units, with the aim of utilising more complete and accurate datasets for fatigue life assessment of support structures. Firstly, a time-efficient synchronisation method that enables the continuous monitoring of these systems is presented, followed by a novel approach to noise cleansing and the posterior missing data imputation (MDI). By the implementation of these techniques those data-points containing excessive noise are removed from the dataset (Step 2), advanced numerical tools are employed to regenerate missing data (Step 3) and fatigue is estimated for the results of these two methodologies (Step 4). Results show that after cleansing, missing data can be imputed with an average absolute error of 2.1%, while this error is kept within the [+ 15.2%−11.0%] range in 95% of cases. Furthermore, only 0.15% of the imputed data fell outside the noise thresholds. Fatigue is found to be underestimated both, when data cleansing does not take place and when it takes place but MDI does not. This makes this novel methodology an enhancement to conventional structural integrity assessment techniques that do not employ continuous datasets in their analyses.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jhydrol.2018.11.069,Journal,Journal of Hydrology,scopus,2019-02-01,sciencedirect,"An enhanced extreme learning machine model for river flow forecasting: State-of-the-art, practical applications in water resource engineering area and future research direction",https://api.elsevier.com/content/abstract/scopus_id/85059162436,"Despite the massive diversity in the modeling requirements for practical hydrological applications, there remains a need to develop more reliable and intelligent expert systems used for real-time prediction purposes. The challenge in meeting the standards of an expert system is primarily due to the influence and behavior of hydrological processes that is driven by natural fluctuations over the physical scale, and the resulting variance in the underlying model input datasets. River flow forecasting is an imperative task for water resources operation and management, water demand assessments, irrigation and agriculture, early flood warning and hydropower generations. This paper aims to investigate the viability of the enhanced version of extreme learning machine (EELM) model in river flow forecasting applied in a tropical environment. Herein, we apply the complete orthogonal decomposition (COD) learning tool to tune the output-hidden layer of the ELM model’s internal neuronal system, instead of the conventional multi-resolution tool (e.g., singular value decomposition). To demonstrate the application of EELM model, the Kelantan River, located in the Malaysian peninsular, selected as a case study. For a comparison of the EELM model, and further model evaluation, two distinct data-intelligent models are developed (i.e., the classical ELM and the support vector regression, SVR model). An exhaustive list of diagnostic indicators are used to evaluate the EELM model in respect to the benchmark algorithms, namely, SVR and ELM. The model performance indicators exhibit superior results for the EELM model relative to ELM and SVR models. In addition, the EELM model is presented as a more accurate, alternative predictive tool for modelling the tropical river flow patterns and its underlying characteristic perturbations in the physical space. Several statistical metrics defined as the coefficient of determination (r), Nash-Sutcliffe efficiency (Ens
                     ), Willmott’s Index (WI), root-mean-square error (RMSE) and mean absolute error (MAE) are computed to assess the model’s effectiveness. In quantitative terms, superiority of EELM over ELM and SVR models was exhibited by Ens
                      = 0.7995, 0.7434 and 0.665, r = 0.894, 0.869 and 0.818 and WI = 0.9380, 0.9180 and 0.8921, respectively. Whereas, EELM model attained lower (RMSE and MAE) values by approximately (11.61–22.53%) and (8.26–8.72%) relative to ELM and SVR models, respectively. The obtained results reveal that the EELM model is a robust expert model and can be embraced practically in real-life water resources management and river sustainability decisions. As a complementary component of this paper, we also review state-of-art research works where scholars have embraced extensive implementation of the ELM model in water resource engineering problems. A comprehensive evaluation is carried out to recognize the current limitations, and also to propose potential opportunities of applying improved variants of the ELM model presented as a future research direction.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.esd.2018.12.002,Journal,Energy for Sustainable Development,scopus,2019-02-01,sciencedirect,Identifying urban geometric types as energy performance patterns,https://api.elsevier.com/content/abstract/scopus_id/85058706592,"This paper aims to find the impact of geometric parameters on the energy performance of buildings, to using them to identify types regarding major geometric characteristics of a target area. Conventional approaches to control energy efficiency of buildings mainly focus on materials and capacity of insulation, but rarely consider urban and building geometries. By examining energy impacts on urban blocks by urban geometric forms, this paper seeks to identify urban geometric types and energy patterns on urban blocks. To achieve the aims of this study, this paper follows two steps: First, significant indicators for analyzing energy performance are identified in urban geometries; second, the types that capture urban geometry of a real city are categorized. As a result, as a reference for urban planning and design, the paper identifies 13 types that represent the characteristics of urban geometries regarding energy performance. The geometric indicators are carefully measured and their significance to energy performance of buildings is examined through regression analysis. According to these indicators, the 13 types are categorized using a hierarchical clustering algorithm, a machine learning method. Additionally, the 13 types are discussed for implementation as references in urban planning and design, particularly in block planning for a city.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.gaitpost.2018.11.029,Journal,Gait and Posture,scopus,2019-02-01,sciencedirect,"Three-dimensional cameras and skeleton pose tracking for physical function assessment: A review of uses, validity, current developments and Kinect alternatives",https://api.elsevier.com/content/abstract/scopus_id/85057183966,"Background
                  Three-dimensional camera systems that integrate depth assessment with traditional two-dimensional images, such as the Microsoft Kinect, Intel Realsense, StereoLabs Zed and Orbecc, hold great promise as physical function assessment tools. When combined with point cloud and skeleton pose tracking software they can be used to assess many different aspects of physical function and anatomy. These assessments have received great interest over the past decade, and will likely receive further study as the integration of depth sensing and augmented reality smartphone cameras occurs more in everyday life.
               
                  Research Question
                  The aim of this review is to discuss how these devices work, what options are available, the best methods for performing assessments and how they can be used in the future.
               
                  Methods
                  Firstly, a review of the Microsoft Kinect devices and associated artificial intelligence, automated skeleton tracking algorithms is provided. This includes a narrative critique of the validity and clinical utility of these devices for assessing different aspects of physical function including spatiotemporal, kinematic and inverse dynamics data derived from gait and balance trials, and anatomical assessments performed using the depth sensor information. Methods for improving the accuracy of data are examined, including multiple-camera systems and sensor fusion with inertial monitoring units, model fitting, and marker tracking. Secondly, alternative hardware, including other structured light and time of flight methods, stereoscopic cameras and augmented reality leveraging smartphone and tablet cameras to perform measurements in three-dimensional space are summarised. Software options related to depth sensing cameras are then discussed, focussing on recent advances such as OpenPose and web-based methods such as PoseNet.
               
                  Results and Significance
                  The clinical and non-laboratory utility of these devices holds great promise for physical function assessment, and recent developments could strengthen their ability to provide important and impactful health-related data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.robot.2018.10.015,Journal,Robotics and Autonomous Systems,scopus,2019-02-01,sciencedirect,Time-dependent genetic algorithm and its application to quadruped's locomotion,https://api.elsevier.com/content/abstract/scopus_id/85056925953,"Genetic algorithms (GAs) are widely used in machine learning and optimization. This paper proposes a time-dependent genetic algorithm (TDGA) based on real-coded genetic algorithm (RCGA) to improve the convergence performance of functions over time such as a foot trajectory. TDGA has several distinguishing features when compared with traditional RCGA. First, individuals are arranged over time, and then the individuals are optimized in sequence. Second, search spaces of design variables are newly comprised of processes of reductions for search spaces. Third, the search space for crossover operations is expanded to avoid local minima traps that can occur in new search spaces up to the previous search space before performing any reduction of search space, and boundary mutation operation is performed to the new search spaces. Computer simulations are implemented to verify the convergence performance of the robot locomotion optimized by TDGA. Then, TDGA optimizes the desired feet trajectories of quadruped robots that climb up a slope and the impedance parameters of admittance control so that quadruped robots can trot stably over irregular terrains. Simulation results clearly represent that the convergence performance is improved by TDGA, which also shows that TDGA could be broadly used in robot locomotion research.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2018.10.014,Journal,Engineering Applications of Artificial Intelligence,scopus,2019-02-01,sciencedirect,An effective Decision Support System for social media listening based on cross-source sentiment analysis models,https://api.elsevier.com/content/abstract/scopus_id/85056789877,"Nowadays, companies and enterprises are more and more incline to exploit the pervasive action of on-line social media, such as Facebook, Twitter and Instagram. Indeed, several promotional and marketing campaigns are carried out by concurrently adopting several social medial channels. These campaigns reach very quickly a wide range of different categories of users, since many people spend most of their time on on-line social media during the day.
                  In this work, a Decision Support System (DSS) is presented, which is able to efficiently support companies and enterprises in managing promotional and marketing campaigns on multiple social media channels. The proposed DSS continuously monitors multiple social channels, by collecting social media users’ comments on promotions, products, and services. Then, through the analysis of these data, the DSS estimates the reputation of brands related to specific companies and provides feedbacks about a digital marketing campaign.
                  The core of the proposed DSS is a Sentiment Analysis Engine (SAE), which is able to estimate the users’ sentiment in terms of positive, negative or neutral polarity, expressed in a comment. The SAE is based on a machine learning text classification model, which is initially trained by using real data streams coming from different social media platforms specialized in user reviews (e.g., TripAdvisor). Then, the monitoring and the sentiment classification are carried out on the comments continuously extracted from a set of public pages and channels of publicly available social networking platforms (e.g., Facebook, Twitter, and Instagram). This approach is labeled as cross-source sentiment analysis.
                  After some discussions on the design and the implementation of the proposed DSS, some results are shown about the experimentation of the proposed DSS on two scenarios, namely restaurants and consumer electronics online shops. Specifically, first the application of effective sentiment analysis models, created relying on user reviews is discussed: the models achieve accuracies higher than 90%. Then, such models are embedded into the proposed DSS. Finally, the results of a social listening campaign are presented. The campaign was carried out by fusing data streams coming from real social channels of popular companies belonging to the selected scenarios.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2018.09.008,Journal,Microprocessors and Microsystems,scopus,2019-02-01,sciencedirect,Autonomous power management in mobile devices using dynamic frequency scaling and reinforcement learning for energy minimization,https://api.elsevier.com/content/abstract/scopus_id/85053917815,"Embedded systems execute applications that execute hardware differently depending on the computation task, generating time-varying workloads. Energy minimization can be reached by using the low-power central processing unit (CPU) frequency for each workload. We propose an autonomous and online approach, capable of reducing energy consumption from adaptation to workload variations even in an unknown environment. In this approach, we improved the AEWMA algorithm into a new algorithm called AEWMA-MSE, adding new functionality to detect workload changes and demonstrating why it is better to use statistical analysis for real user cases in a mobile environment. Also, a new power model for mobile devices based on k-NN algorithm for regression was proposed and validated proving to have a better trade-off between execution time and precision than neural networks and linear regression-based models. AEWMA-MSE and the proposed power model are integrated into a novel algorithm for energy management based on reinforcement learning that suitably selects the appropriate CPU frequency based on workload predictions to minimize energy consumption. The proposed approach is validated through simulation by using real smartphone data from an ARM Cortex A7 processor used in a commercial smartphone. Our proposal proved to have an improvement in the Q-learning cost function and can effectively minimize the average energy consumption by 21% and up to 29% when compared to the already existing approaches.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cie.2018.08.018,Journal,Computers and Industrial Engineering,scopus,2019-02-01,sciencedirect,Ensemble-based big data analytics of lithofacies for automatic development of petroleum reservoirs,https://api.elsevier.com/content/abstract/scopus_id/85052098750,"Big data-driven ensemble learning is explored in this paper for quantitative geological lithofacies modeling, which is an integral and challenging part of petroleum reservoir development and characterization. Quantitative lithofacies modeling involves detection and recognition of underlying subsurface rock’s lithofacies. It requires real-time data acquisition, handling, storage, conditioning, analysis, and interpretation of raw sensory petroleum logging data. The real-time well-logs data collected from the sensor-based tools suffer from complications such as noise, nonlinearity, imbalance, and high-dimensionality which makes the prediction task more challenging. The existing literature on quantitative lithofacies modeling includes several data-driven techniques ranging from conventional well-logs to artificial intelligence (AI). Recently, multiple classifiers based Ensemble learners have been found to be more robust and reliable paradigms for detection and identification tasks in various machine learning applications, however, these are not well embraced in the petroleum industry. Ensemble methodology combines diverse expert’s opinions to obtain overall ensemble decision which in turn reduces the risk of a wrong decision. Thus, the uncertainties associated with complex reservoir data can be better handled by the use of Ensemble learners than the existing single learner based conventional models. Ensemble-based big data analytics, proposed in the paper, includes development and comparative performance testing of five popular ensemble methods (viz. Bagging, AdaBoost, Rotation forest, Random subspace, and DECORATE) for quantitative lithofacies modeling. Seven state-of-the-art base classifiers were used as members of different Ensemble learners for the analysis of Kansas (U.S.A.) oil-field data. The proposed techniques have been implemented on the widely used WEKA platform. The comparative performance analysis of the proposed techniques, presented in the paper, confirms its supremacy over the existing techniques used for quantitative lithofacies modeling.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.comnet.2018.11.013,Journal,Computer Networks,scopus,2019-01-15,sciencedirect,Towards automatic fingerprinting of IoT devices in the cyberspace,https://api.elsevier.com/content/abstract/scopus_id/85056904979,"Nowadays, the cyberspace consists of an increasing number of IoT devices, such as net-printers, webcams, and routers. Illuminating the nature of online devices would provide insights into detecting potentially vulnerable devices on the Internet. However, there is a lack of device discovery in large-scale due to the massive number of device models (i.e., types, vendors, and products). In this paper, we propose an efficient approach to generate fingerprints of IoT devices. We observe that device manufacturers have different network system implementations on their products. We explore features spaces of IoT devices in three network layers, including the network-layer, transport-layer, and application-layer. Utilizing the feature of network protocols, we generate IoT device fingerprints based on neural network algorithms. Furthermore, we implement the prototype system and conduct real experiments to validate the performance of device fingerprints. Results show that our classification can generate device class labels with a 94% precision and 95% recall. We use those device fingerprints to discover 15.3 million network-connected devices and analyze their distribution characteristics in cyberspace.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-817356-5.00012-7,Book,Internet of Things in Biomedical Engineering,scopus,2019-01-01,sciencedirect,Internet of Things Application in Life Sciences,https://api.elsevier.com/content/abstract/scopus_id/85124928251,"Sensors, smart devices, and automated systems have been used in life sciences industries for the benefit of patients and medical personnel for the diagnosis of disease, monitoring of patient conditions, treatment of chronic conditions, and manufacturing and distribution of drugs. The Internet of Things (IoT) has been implemented for connecting sensors and networked devices and collecting and analyzing the experimental data obtained from those sensors and actuators. IoT-based devices and microchips have been used to collect patient health history and records, to understand the functions of the internal organs, and to capture pictures and videos of the human body from the inside. They have proven to be of great benefit in research and to facilitate patient treatment and efficient drug manufacturing. In recent years, inventions such as smart wheelchairs for disabled people to move around more easily; wristbands for analyzing oxygen levels and monitoring heartbeat, temperature, and blood pressure; a pill-shaped camera to capture pictures; and the linking of these devices with smartphone apps have made it possible to monitor, study, and keep track of the conditions of patients and their daily life in real time. With its recent advances, the application of IoT in the life sciences fields has provided better tools and devices to diagnose diseases in their initial stages, to study the effectiveness of a drug in the patient’s body, and to invent and test new drugs efficiently in less time and for less money. The IoT enables remote monitoring of patients and products connecting these sensors and devices. This provides real-time information on patients, which reduces effort and cost and improves treatment outcomes and efficiency. Also, the data collected from these devices have provided information for study and research into the betterment of human health in the field of life sciences. With the application of machine learning and deep learning approaches, vital conclusions can be drawn from big data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/C2018-0-04060-8,Book,Innovation in Health Informatics: A Smart Healthcare Primer,scopus,2019-01-01,sciencedirect,Innovation in health informatics: A smart healthcare primer,https://api.elsevier.com/content/abstract/scopus_id/85093486650,Unknown,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/C2018-0-01886-1,Book,Multi-robot Exploration for Environmental Monitoring: The Resource Constrained Perspective,scopus,2019-01-01,sciencedirect,Multi-robot exploration for environmental monitoring: The resource constrained perspective,https://api.elsevier.com/content/abstract/scopus_id/85089697302,Unknown,science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-815956-9.00006-5,Book,Technology in Supply Chain Management and Logistics: Current Practice and Future Applications,scopus,2019-01-01,sciencedirect,Emerging technologies in the health-care supply chain,https://api.elsevier.com/content/abstract/scopus_id/85082603106,"In this chapter, the background and organization of the health-care supply chain are reviewed, and the impact of emerging technologies is described. Maturing technologies, including optimization software, sensors/telematics, cloud computing, data warehouse systems, and automated storage and retrieval, are examined. Growth technologies, including mobility, wearable devices, data analytics, and social media, are examined as they potentially relate to the health-care supply chain. Emerging technologies, including 3D printing, drone delivery, and autonomous vehicles, are presented and examples provided on their use in the health-care supply chain. Exponential technologies, including blockchain, the Internet of Things, virtual/augmented reality, and artificial intelligence, are described with respect to potential applications in the health-care supply chain. Future changes in the external environment of health care, including decentralization, new competitors, and the increased use of telemedicine, are described with respect to impacts on the health-care supply chain.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-816176-0.00045-4,Book,Handbook of Medical Image Computing and Computer Assisted Intervention,scopus,2019-01-01,sciencedirect,Challenges in computer assisted interventions,https://api.elsevier.com/content/abstract/scopus_id/85082596227,"Challenges in design, implementation, clinical evaluation, and deployment of computer assisted intervention solutions are manifold. Some of these challenges will be discussed in this chapter.
               Computer assistance in both surgical procedures and radiology interventions aim at augmenting the clinicians with the overall objective of providing better clinical outcome. Multimodal imaging, robotics, artificial intelligence, and augmented reality play a major role in computer assisted interventions. After a brief analysis of the state-of-the-art and practice in this field, we discuss the challenges in design and development, as well as translation and deployment of the technology, from research projects motivated by clinical needs to solutions routinely used within clinical setups. We also consider the required training of surgeons and the surgical team as a major component for smooth and successful translation. We present simulation as an important tool not only for the design and development of computer assisted intervention solutions but also in their fast and smooth translation into daily practice.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-815956-9.00002-8,Book,Technology in Supply Chain Management and Logistics: Current Practice and Future Applications,scopus,2019-01-01,sciencedirect,Technologies in supply chain management and logistics,https://api.elsevier.com/content/abstract/scopus_id/85082571600,"Until recently, technology has been considered an enabler for improvements in underlying supply chain and logistics operations. However, recent trends in society and business, such as mobile computing, social media, and online retailing, have significantly changed almost every aspect of the supply chain and logistics landscape. In this chapter the following technologies were found to have a pervasive role in altering this landscape:
               
                  
                     
                        •
                        Maturing technologies
                     
                     
                        •
                        Optimization software
                     
                     
                        •
                        Sensors/Telematics
                     
                     
                        •
                        Cloud computing
                     
                     
                        •
                        Data warehouse and integration
                     
                     
                        •
                        Automated storage and retrieval
                     
                     
                        •
                        Growth technologies
                     
                     
                        •
                        Mobility
                     
                     
                        •
                        Wearability
                     
                     
                        •
                        Data analytics
                     
                     
                        •
                        Social media
                     
                     
                        •
                        Emerging technologies
                     
                     
                        •
                        3D printing
                     
                     
                        •
                        Drones
                     
                     
                        •
                        Autonomous vehicles
                     
                     
                        •
                        Exponential
                     
                     
                        •
                        Blockchain
                     
                     
                        •
                        Internet of Things
                     
                     
                        •
                        Virtual reality
                     
                     
                        •
                        Machine learning
                     
                  
               
               Each of these technologies will be discussed along with videos illustrating their use.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2019.05.017,Conference Proceeding,Procedia CIRP,scopus,2019-01-01,sciencedirect,The growing path in search of an industrial design identity,https://api.elsevier.com/content/abstract/scopus_id/85076752868,"Knowing that the education system must be reinvented periodically to face the changes of social and cultural paradigm, was reviewed the pedagogical organization of a set of disciplines of an industrial design course that were in operation for a decade. Thus, in view of the objective of restructuring the disciplinary group of industrial design, a new structure has been developed and implemented that could offer students the opportunity to explore problems and challenges that have real applications, increasing the possibility of acquiring competences effectively needed to practice the profession of designer.
                  This restructuring had as its starting point the concept of Project-based learning, which is designated as student-centered pedagogy that involves a dynamic classroom approach in which it is believed that students acquire a deeper knowledge through active exploration of real-world challenges and problems. Consequently, resulting in a learning process organized into levels with increasing degree of complexity. As well, different assimilations of markets and design scenarios.
                  Starting from the first year of the course, where students are still understanding the context of industrial design and its potentialities. At a time when their techniques, principles and methods are still very raw and basic. They are initiated in a LOW-ID and local industry context, to acquire basic skills. The second year allows embark on an intermediate level called MID-ID, with new skills in international brands approach. In the last year of the course the 3rd level is reached, HIGH-ID, with projects with the national industry.
                  The first year of implementation of this curriculum structure showed good results. Thus, favoring a solid interdisciplinary formation with, skills and competences that allow future designers to intervene creatively and competently in a variety of fields. This process allows to progress to the next academic degree to complete and validate the entire formation of the student.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2019.05.057,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Educating I-Shaped Computer Science Students to Become T-Shaped System Engineers,https://api.elsevier.com/content/abstract/scopus_id/85074996601,"With every passing day, software becomes more and more important to the success of the artifacts that we make, sell, buy, use, and evolve. Software increasingly provides a competitive differentiator for products, ways of tailoring them for various uses and users, and ways of fixing or evolving them without expensive product recalls.
                  Unfortunately, as software becomes more and more ubiquitous and complex, an increasing number of new computer science (CS) courses in web services, big-data analytics, computing security, and machine learning fill up CS students’ schedules, leaving little room for non-CS courses providing skills outside of CS. This paper summarizes our experiences in developing and evolving an MS-level software engineering (MSCS-SE) curriculum that takes I-shaped CS BA graduates and enables them to become sufficiently T-shaped to be able to immediately contribute to overall system definition and development on being hired, and to improve their T-shaped skills along their careers.
                  Section 2 summarizes the primary origins and problems with an I-shaped software workforce. Section 3 describes the origins, development, and evolution of the USC MSCS-Software Engineering program and its foundation-stone, real-client, 2-semester project course. Section 4 elaborates on the team-project course and its mechanisms for strengthening the transition from I-shaped to T-shaped systems thinking. Section 5 provides conclusions.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.entcs.2019.04.014,Journal,Electronic Notes in Theoretical Computer Science,scopus,2019-01-01,sciencedirect,IoT sensors in sea water environment: Ahoy! Experiences from a short summer trial,https://api.elsevier.com/content/abstract/scopus_id/85074842288,"IoT sensors for measuring various sea water parameters, are explored here, aiming towards an educational context, in order to lead to a deeper understanding of the use of aquatic environments as natural resources, and towards the adoption of environmentally friendly behaviors. Sea-water sensing via IoT has not been extensively explored, due to practical difficulties in deployment, and the same applies to devising appropriate scenaria for understanding aquatic parameters in STEM education. A short hands-on IoT sensing trial, that has been conducted in various location of the Aegean sea, is reported in this paper. This research set out to gain insight into real data sets on which to base observations for devising realistic educational scenaria pertaining aquatic parameters. The results of this experiment are meant to guide research further, by shedding light into the IoT sensing issues that are involved in an educational scientific context. The goal is conducting broader research in the area of IoT water sensing towards its further utilization in STEM education.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.entcs.2019.04.012,Journal,Electronic Notes in Theoretical Computer Science,scopus,2019-01-01,sciencedirect,An Augmented Reality Prototype for supporting IoT-based Educational Activities for Energy-efficient School Buildings,https://api.elsevier.com/content/abstract/scopus_id/85074700429,"The use of Augmented Reality (AR) technologies is currently being investigated in numerous and diverse application domains. In this work, we discuss the ways in which we are integrating AR into educational in-class activities for the GAIA project, aiming to enhance existing tools that target behavioral changes towards energy efficiency in schools. We combine real-time IoT data from a sensing infrastructure inside a fleet of school buildings with AR software running on tablets and smartphones, as companions to a set of educational lab activities aimed at promoting energy awareness in a STEM context. We also utilize this software as a means to ease access to IoT data and simplify device maintenance. We report on the design and current status of our implementation, describing functionality in the context of our target applications, while also relaying our experiences from the use of such technologies in this application domain.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2019.09.007,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Increase the interest in learning by implementing augmented reality: Case studies studying rail transportation.,https://api.elsevier.com/content/abstract/scopus_id/85073117730,"Learn a subject, for some people, might be an uninteresting and boring activity, especially when the subject to learn are difficult subjects to understand. Many methods used to change learning activities become more enjoyable and interested. This study proposed a new method in learning activities, by applied augmented reality technology in the learning process. The case study used in this paper are implementation the augmented reality in studied subjects related to train technology. In this study, author implement augmented reality on learning material, combines real and virtual things in one media, in this case a mobile device. The impact of implementation of augmented studied, at the end of experiment, author can conclude when implement augmented reality technology in learning material helps the learning process and increasing the impressive and fun factor in learning process and make the learning process more interested. Implementation of Augmented Reality in learning material gives more information about the object being studied, information about on shapes, textures, and provide more visualization for the object.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.promfg.2018.12.017,Conference Proceeding,Procedia Manufacturing,scopus,2019-01-01,sciencedirect,AI based injection molding process for consistent product quality,https://api.elsevier.com/content/abstract/scopus_id/85072584818,"In manufacturing processes, Injection Molding is widely used for producing plastic components with large lot size. So, continuous improvements in product quality consistency is crucial to maintaining a competitive edge in the injection molding industry. Various optimization techniques like ANN, GA, Iterative method, and simulation based are being used for optimization of Injection Molding process and obtaining optimal processing conditions. But still due to variation during molding cycles, quality failure occurs. As many constituents like process, Material, machine together yields product quality. This paper is focused on Real time AI based control of process parameters in injection molding cycle. Process parameters and their interrelationship with quality failure has been studied and later supposed to be used to generate algorithm for compensating the deviation of process parameters. Pressure and temperature sensor assisted monitoring system is used to collect data in real time and based on its comparison with the standard values an interrelationship is formed between parameters and plastic material properties. Algorithm generates new process parameter values to compensate the deviation and machine control follows the same. The entire process is supposed to be smart and automatic after being trained with AI and machine learning techniques. Simulation using Moldflow software and real industry collected data has been used for understanding whole molding process establishing relationship between failure and parameters. An automotive product in real industry is chosen for data acquisition, implementation and validation of entire AI based system.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2019.03.041,Conference Proceeding,Procedia CIRP,scopus,2019-01-01,sciencedirect,"Design, implementation and evaluation of reinforcement learning for an adaptive order dispatching in job shop manufacturing systems",https://api.elsevier.com/content/abstract/scopus_id/85068485505,"Modern production systems tend to have smaller batch sizes, a larger product variety and more complex material flow systems. Since a human oftentimes can no longer act in a sufficient manner as a decision maker under these circumstances, the demand for efficient and adaptive control systems is rising. This paper introduces a methodical approach as well as guideline for the design, implementation and evaluation of Reinforcement Learning (RL) algorithms for an adaptive order dispatching. Thereby, it addresses production engineers willing to apply RL. Moreover, a real-world use case shows the successful application of the method and remarkable results supporting real-time decision-making. These findings comprehensively illustrate and extend the knowledge on RL.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2019.01.012,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Combining supervised and unsupervised machine learning algorithms to predict the learners' learning styles,https://api.elsevier.com/content/abstract/scopus_id/85062675875,"The implementation of an efficient adaptive e-learning system requires the construction of an effective student model that represents the student’s characteristics, among those characteristics, there is the learning style that refers to the way in which a student prefers to learn. Knowing learning styles helps adaptive E-learning systems to improve the learning process by providing customized materials to students. In this work, we have proposed an approach to identify the learning style automatically based on the existing learners’ behaviors and using web usage mining techniques and machine learning algorithms. The web usage mining techniques were used to pre-process the log file extracted from the E-learning environment and capture the learners’ sequences. The captured learners’ sequences were given as an input to the K-modes clustering algorithm to group them into 16 learning style combinations based on the Felder and Silverman learning style model. Then the naive Bayes classifier was used to predict the learning style of a student in real time. To perform our approach, we used a real dataset extracted from an e-learning system’s log file, and in order to evaluate the performance of the used classifier, the confusion matrix method was used. The obtained results demonstrate that our approach yields excellent results.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.impact.2018.12.001,Journal,NanoImpact,scopus,2019-01-01,sciencedirect,SUNDS probabilistic human health risk assessment methodology and its application to organic pigment used in the automotive industry,https://api.elsevier.com/content/abstract/scopus_id/85058641247,"The increasing use of engineered nanomaterials (ENMs) in nano-enabled products (NEPs) has raised societal concerns about their possible health and ecological implications. To ensure a high level of human and environmental protection it is essential to properly estimate the risks of these new materials and to develop adequate risk management strategies. To this end, we propose a quantitative Human Health Risk Assessment (HHRA) methodology, which was developed in the European Seventh Framework research project SUN (Sustainable Nanotechnologies) and implemented in the web-based SUN Decision Support System (SUNDS). One of the major strengths of this probabilistic approach as compared to its deterministic alternatives is its ability to clearly communicate the uncertainties in the estimated risks in order to support better risk communication for more objective decision making by industries and regulators.
                  To demonstrate this methodology, we applied it in a real case study involving a nanoscale organic red pigment used in the automotive industry. Our analysis clearly showed that the main source of uncertainty was the extrapolation from (sub)acute in vivo toxicity data to long-term risk. This extrapolation was necessary due to a lack of (sub)chronic in vivo studies for the investigated nanomaterial. Despite the high uncertainty in the final results due to the conservative assumptions made in the risks assessment, the estimated risks are acceptable for all investigated exposure scenarios along the product lifecycle.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.iree.2018.12.001,Journal,International Review of Economics Education,scopus,2019-01-01,sciencedirect,Active financial analysis: Stimulating engagement using Bloomberg for introductory finance students,https://api.elsevier.com/content/abstract/scopus_id/85058411728,"There is increasing interest in the adoption of real-world interactive and participative learning techniques within economics and finance teaching through the use of trading room software. Previous research suggests that the integration of trading room software can improve knowledge development and performance. However, the time constraints of providing software training and requirements for foundation knowledge of basic maths and economics has restricted the adoption of trading room software to advanced courses. This paper outlines how the Bloomberg Professional Software was used in an introductory finance course and analyses student engagement, learning and attainment using feedback and performance data. We find that students valued the novelty of Bloomberg as part of a mix of different learning activities which facilitated the practical application of theory. Results also indicate that the alignment of teaching, learning and assessment promotes deeper engagement, and is associated with higher attainment. We demonstrate that trading room software can be effectively used in introductory courses to enhance the student experience and deepen understanding.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2018.11.002,Journal,Computer Methods and Programs in Biomedicine,scopus,2019-01-01,sciencedirect,Predicting combinative drug pairs via multiple classifier system with positive samples only,https://api.elsevier.com/content/abstract/scopus_id/85056787891,"Background and Objective
                  Due to the synergistic effects of drugs, drug combination is one of the effective approaches for treating complex diseases. However, the identification of drug combinations by dose-response methods is still costly. It is promising to develop supervised learning-based approaches to predict potential drug combinations on a large scale. Nevertheless, these approaches have the inadequate utilization of heterogeneous features, which causes the loss of information useful to classification. Moreover, they have an intrinsic bias, because they assume unknown drug pairs as non-combinations, of which some could be real drug combinations in practice.
               
                  Methods
                  To address above issues, this work first designs a two-layer multiple classifier system (TLMCS) to effectively integrate heterogeneous features involving anatomical therapeutic chemical codes of drugs, drug-drug interactions, drug-target interactions, gene ontology of drug targets, and side effects. To avoid the bias caused by labelling unknown samples as negative, it then utilizes the one-class support vector machines, (which requires no negative instance and only labels approved drug combinations as positive instances), as the member classifiers in TLMCS. Last, both a 10-fold cross validation (10-CV) and a novel prediction are performed to validate the performance of TLMCS.
               
                  Results
                  The comparison with three state-of-the-art approaches under 10-CV exhibits the superiority of TLMCS, which achieves the area under the receiver operating characteristic curve = 0.824 and the area under the precision-recall curve = 0.372. Moreover, the experiment under the novel prediction demonstrates its ability, where 9 out of the top-20 predicted combinative drug pairs are validated by checking the published literature. Furthermore, for each of the newly-validated drug combinations, this work analyses the combining mode of the member drugs and investigates their relationship in terms of drug targeting pathways.
               
                  Conclusions
                  The proposed TLMCS provides an effective framework to integrate those heterogeneous features and is trained by only positive samples such that the bias of taking unknown drug pairs as negative samples can be avoided. Furthermore, its results in the novel prediction reveal five types of drug combinations and three types of drug relationships in terms of pathways.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2018.10.010,Journal,Applied Soft Computing Journal,scopus,2019-01-01,sciencedirect,A hybridization of extended Kalman filter and Ant Colony Optimization for state estimation of nonlinear systems,https://api.elsevier.com/content/abstract/scopus_id/85056208326,"In this paper, a new nonlinear heuristic filter based on the hybridization of an extended Kalman filter and an ant colony estimator is proposed to estimate the states of a nonlinear system. In this filter, a group of virtual ants searches the state space stochastically and dynamically to find and track the best state estimation while the position of each ant is updated at the measurement time using the extended Kalman filter. The performance of the proposed filter is compared with well-known heuristic filters using a nonlinear benchmark problem. The statistical results show that this algorithm is able to provide promising and competitive results. Then, the new filter is tested on a nonlinear engineering problem with more than one state. The problem is to estimate simultaneously the states of an unmanned aerial vehicle as well as the wind disturbances, applied to the system. In this case, a processor-in-the-loop experiment is also performed to verify the implementation capability of the proposed approach. This paper also investigates the real-time implementation capability of the proposed filter in the attitude estimation of a three degrees of freedom experimental setup of a quadrotor to further investigate its effectiveness in practice.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.euromechsol.2018.10.011,Journal,"European Journal of Mechanics, A/Solids",scopus,2019-01-01,sciencedirect,A dual interpolation boundary face method for elasticity problems,https://api.elsevier.com/content/abstract/scopus_id/85055917199,"A dual interpolation boundary face method (DiBFM) is proposed to unify the conforming and nonconforming elements in boundary element method (BEM) implementation. In the DiBFM, the nodes of a conventional conforming element are sorted into two groups: the nodes on the boundary (called virtual nodes) and the internal nodes (called source nodes). Without virtual nodes, the conforming element turns to be a conventional nonconforming element of a lower order. Physical variables are interpolated using the conforming elements, the same way as conforming BEM. Boundary integral equations are collocated at source nodes, the same way as nonconforming BEM. To make the final system of linear equations solvable, additional constraint equations are required to condense the degrees of freedom for all the virtual nodes. These constraints are constructed using the moving least-squares (MLS). Besides, both boundary integration and MLS are performed in the parametric spaces of curves, namely, the geometric data, such as coordinates, out normals and Jacobians, are calculated directly from curves rather than from elements. Thus, no geometric errors are introduced no matter how coarse the discretization is. The method has been implemented successfully for solving two-dimensional elasticity problems. A number of numerical examples with real engineering background have demonstrated the accuracy and efficiency of the new method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2018.09.023,Journal,Information Sciences,scopus,2019-01-01,sciencedirect,On analyzing and evaluating privacy measures for social networks under active attack,https://api.elsevier.com/content/abstract/scopus_id/85053787383,"Widespread usage of complex interconnected social networks such as Facebook, Twitter and LinkedInin modern internet era has also unfortunately opened the door for privacy violation of users of such networks by malicious entities. In this article we investigate, both theoretically and empirically, privacy violation measures of large networks under active attacks that was recently introduced in Trujillo-Rasua and Yero (2016). Our theoretical result indicates that the network manager responsible for prevention of privacy violation must be very careful in designing the network if its topology does not contain a cycle. Our empirical results shed light on privacy violation properties of eight real social networks as well as a large number of synthetic networks generated by both the classical Erdös–Rényi model and the scale-free random networks generated by the Barábasi–Albert preferential-attachment model.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.infsof.2018.08.003,Journal,Information and Software Technology,scopus,2019-01-01,sciencedirect,An extensible framework for software configuration optimization on heterogeneous computing systems: Time and energy case study,https://api.elsevier.com/content/abstract/scopus_id/85051630181,"Context: Application of component based software engineering methods to heterogeneous computing (HC) enables different software configurations to realize the same function with different non–functional properties (NFP). Finding the best software configuration with respect to multiple NFPs is a non–trivial task.
                  
                     Objective: We propose a Software Component Allocation Framework (SCAF) with the goal to acquire a (sub–) optimal software configuration with respect to multiple NFPs, thus providing performance prediction of a software configuration in its early design phase. We focus on the software configuration optimization for the average energy consumption and average execution time.
                  
                     Method: We validated SCAF through its instantiation on a real–world demonstrator and a simulation. Firstly, we verified the correctness of our model through comparing the performance prediction of six software configurations to the actual performance, obtained through extensive measurements with a confidence interval of 95%. Secondly, to demonstrate how SCAF scales up, we performed software configuration optimization on 55 generated use–cases (with solution spaces ranging from 1030 to 3070) and benchmark the results against best performing random configurations.
                  
                     Results: The performance of a configuration as predicted by our framework matched the configuration implemented and measured on a real–world platform. Furthermore, by applying the genetic algorithm and simulated annealing to the weight function given in SCAF, we obtain sub–optimal software configurations differing in performance at most 7% and 13% from the optimal configuration (respectfully).
                  
                     Conclusion: SCAF is capable of correctly describing a HC platform and reliably predict the performance of software configuration in the early design phase. Automated in the form of an Eclipse plugin, SCAF allows software architects to model architectural constraints and preferences, acting as a multi–criterion software architecture decision support system. In addition to said, we also point out several interesting research directions, to further investigate and improve our approach.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jvs.2017.10.069,Journal,Journal of Vascular Surgery,scopus,2019-01-01,sciencedirect,Optimization of rifampin coating on covered Dacron endovascular stent grafts for infected aortic aneurysms,https://api.elsevier.com/content/abstract/scopus_id/85042558741,"Objective
                  In the treatment of an infected aorta, open repair and replacement with a rifampin-impregnated Dacron vascular graft decrease the risk of prosthetic graft infections, with several protocols available in the literature. We hypothesize that the same holds true for endovascular aneurysm repair, and after studying and optimizing rifampin solution concentration and incubation period to maximize the coating process of rifampin on Dacron endovascular stent grafts (ESGs), we propose a rapid real-time perioperative protocol.
               
                  Methods
                  Several prepared rifampin solutions, including a negative control solution, were used to coat multiple triplicate sets of Dacron endovascular aortic stent grafts at different but set incubation periods. Rifampin elution from the grafts was studied by spectroscopic analysis. Once an optimized solution concentration and incubation time were determined, the elution of rifampin over time from the graft and the graft's surface characteristics were studied by ultraviolet-visible spectroscopy and atomic force microscopy.
               
                  Results
                  All coated ESGs with any concentration of prepared rifampin solution, regardless of incubation time, immediately demonstrated a visible bright orange discoloration and subsequently after elution procedures returned to the original noncolored state. At the 25-minute incubation time (standard flush), there was no statistical difference in the amount of rifampin coated to the ESGs with 10-mg/mL, 30-mg/mL, and 60-mg/mL solutions (0.06 ± 0.01, 0.07 ± 0.05, and 0.044 ± 0.01, respectively; P > .05). This was also true for a 10-minute incubation time (express flush) of 10-mg/mL and 60-mg/mL rifampin solution concentrations (0.04 ± 0.007 and 0.066 ± 0.014, respectively; P = .22). The elution-over-time of coated rifampin ESG, although not statistically significant, did seem to plateau and to reach a steady state by 50 hours and was confirmed by surface characteristics using atomic force microscopy.
               
                  Conclusions
                  Having studied two variables of rifampin coating techniques to Dacron ESGs, the authors propose a rapid real-time perioperative coating protocol by using a 10-mg/mL rifampin solution for a 10-minute incubation period. As rifampin loosely binds to Dacron ESGs by weak intermolecular forces, a rifampin-coated ESG would need to be inserted in a timely fashion to treat the diseased aorta and to deliver its antibiotic affect. A rapid perioperative coating protocol followed by immediate deployment makes our proposed technique especially useful in an urgent and unstable clinical scenario.
               
                  Clinical Relevance
                  In the treatment of an infected aorta, open repair with rifampin-impregnated vascular grafts has been described to minimize the risk of prosthetic graft infections, with several protocols available in the literature. We hypothesize that the same holds true for endovascular aneurysm repair. After studying and optimizing several variables to maximize the coating process of rifampin on Dacron endovascular stent grafts (ESGs), we propose a standardized rapid real-time perioperative protocol especially useful in an urgent and unstable clinical scenario. To further provide greater personalized patient care, future directions to ESG coating may include coating with a broader spectrum antibiotic (eg, piperacillin and tazobactam) as well as testing of antibiotic-coated ESG elution properties in vivo with animal models.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbiotec.2018.10.003,Journal,Journal of Biotechnology,scopus,2018-12-20,sciencedirect,Monitoring of antibody-drug conjugation reactions with UV/Vis spectroscopy,https://api.elsevier.com/content/abstract/scopus_id/85055668476,"The conjugation reaction of monoclonal antibodies (mAbs) with small-molecule drugs is a central step during production of antibody-drug conjugates (ADCs). The ability to monitor this step in real time can be advantageous for process understanding and control. Here, we propose a method based on UV/Vis spectroscopy in conjunction with partial least squares (PLS) regression for non-invasive monitoring of conjugation reactions. In experiments, the method was applied to conjugation reactions with two surrogate drugs in microplate format as well as at 20 ml scale. All calibrated PLS models performed well in cross-validation (
                        
                           Q
                           2
                        
                        >
                        0.975
                      for all models). In microplate format, the PLS models were furthermore successfully validated with an independent prediction set (
                        
                           R
                           
                              p
                              r
                              e
                              d
                           
                           2
                        
                         
                        =
                         
                        0.9770
                      resp. 0.8940). In summary, the proposed method provides a quick and easily implementable tool for reaction monitoring of ADC conjugation reactions and may in the future support the implementation of Process Analytical Technologies (PAT).",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jnca.2018.09.023,Journal,Journal of Network and Computer Applications,scopus,2018-12-15,sciencedirect,Dynamic workload patterns prediction for proactive auto-scaling of web applications,https://api.elsevier.com/content/abstract/scopus_id/85054442625,"Proactive auto-scaling methods dynamically manage the resources for an application according to the current and future load predictions to preserve the desired performance at a reduced cost. However, auto-scaling web applications remain challenging mainly due to dynamic workload intensity and characteristics which are difficult to predict. Most existing methods mainly predict the request arrival rate which only partially captures the workload characteristics and the changing system dynamics that influence the resource needs. This may lead to inappropriate resource provisioning decisions. In this paper, we address these challenges by proposing a framework for prediction of dynamic workload patterns as follows. First, we use an unsupervised learning method to analyze the web application access logs to discover URI (Uniform Resource Identifier) space partitions based on the response time and the document size features. Then for each application URI, we compute its distribution across these partitions based on historical access logs to accurately capture the workload characteristics compared to just representing the workload using the request arrival rate. These URI distributions are then used to compute the Probabilistic Workload Pattern (PWP), which is a probability vector describing the overall distribution of incoming requests across URI partitions. Finally, the identified workload patterns for a specific number of last time intervals are used to predict the workload pattern of the next interval. The latter is used for future resource demand prediction and proactive auto-scaling to dynamically control the provisioning of resources. The framework is implemented and experimentally evaluated using historical access logs of three real web applications, each with increasing, decreasing, periodic, and randomly varying arrival rate behaviors. Results show that the proposed solution yields significantly more accurate predictions of workload patterns and resource demands of web applications compared to existing approaches.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.pmcj.2018.10.008,Journal,Pervasive and Mobile Computing,scopus,2018-12-01,sciencedirect,Asfault: A low-cost system to evaluate pavement conditions in real-time using smartphones and machine learning,https://api.elsevier.com/content/abstract/scopus_id/85055864820,"Modern smartphones have a large variety of built-in sensors that can measure different information about users and the environment around them. Given the increasing popularity of these devices, their high processing power, and the ability to transfer data over wireless networks, different smartphone-based applications have emerged in the last years to solve old problems with new approaches more efficiently and cheaply. One example is the assessment and monitoring of asphalt quality. This task has been done manually by experts since the 1930s, and with the help of expensive equipment since the 1960s. Currently, we are experiencing the emergence of next-generation tools to perform this monitoring with smartphones, significantly reducing costs, time, and effort of experts. However, there is a trade-off between the costs and precision of smartphone sensors, requiring the use of sophisticated software solutions. In this paper, we propose Asfault, a low-cost system to evaluate and monitor road pavement conditions in real-time using smartphone sensors and machine learning algorithms. The system is composed of an Android application responsible for doing automatic evaluations and a web application that aims to show the evaluations in an informative way. We propose to employ accelerometer sensors to measure the vehicle vibration while driving and use this data to evaluate the pavement conditions. Asfault achieves a classification performance superior to 90% in a 5-class problem considering the following road qualities: Good, Average, Fair, and Poor, as well the occurrence of obstacles in the road. Our system is publicly available for use and could be useful for practitioners responsible for urban and highway maintenance, as well for regular drivers in the planning of better routes based on the pavement quality and comfort of the travel.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cag.2018.10.004,Journal,Computers and Graphics (Pergamon),scopus,2018-12-01,sciencedirect,Simulating complex social behaviours of virtual agents through case-based planning,https://api.elsevier.com/content/abstract/scopus_id/85055350464,"In commercial video games and simulations, non-player characters are capable of quite complex behaviour. Very often though, each class of non-player characters (that we further call virtual agents) is manually programmed or scripted. This means that instead of possessing some level of intelligence, allowing the agent to decide dynamically on the actions it needs to perform, we supply the agent with a list of possible situations that may arise in the game. For each such situation, we give the agent a pre-programmed script that tells it how to behave. Producing such scripts for every role an agent might play in a game or simulation is a very costly exercise. This may be acceptable in commercial game development, where budgets for modern games are sometimes comparable to budgets of Hollywood movies, but not adequate for research simulations and indie games. In this paper, we discuss how indie games and research simulations can be enriched with the sophisticated social behaviour of virtual agents in a semi-automatic manner through the use of AI planning. By supplying agents with roles and developing a computational model of their needs, we can use AI planning (also known as dynamic planning) to increase the complexity of agent behaviour dramatically and at the same time achieve a high degree of automation and reduce the development costs. AI planning is gaining popularity in games development, but it is often discarded due to performance issues. We will show how to improve the performance of planning process through the use of dynamic institutions and case-based planning. We will illustrate the aforementioned ideas on an example of developing a Virtual Reality simulation of everyday life in Ancient Mesopotamia.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2018.09.035,Journal,Applied Soft Computing Journal,scopus,2018-12-01,sciencedirect,Data-driven MIMO model-free reference tracking control with nonlinear state-feedback and fractional order controllers,https://api.elsevier.com/content/abstract/scopus_id/85054906128,"In this paper we suggest an extension of the Virtual Reference Feedback Tuning (VRFT) framework to nonlinear state-feedback and fractional order (FO) controllers. Theoretical analysis incentivizes the use of VRFT for tuning general nonlinear controllers to achieve model reference matching because it is expected that the more complex controller parameterization of the nonlinear-state-feedback and FO controllers leads to improved control performance. Key factors needed for successful controller tuning are discussed: good exploration of process dynamics depending on careful input excitation signal selection, the influence of the controller parameterization and the selection of the reference model. VRFT is next applied to a Multi Input-Multi Output (MIMO) nonlinear coupled vertical tank system as a case study, to tune MIMO proportional–integral (PI), fractional order-proportional–integral (FO-PI) and neural network state-feedback controllers. PI and FO-PI controllers are tuned in continuous time but implemented in discrete time to enable their real-world applications. Controllers’ complexity vs. control performance trade-off is revealed. For comparisons purposes, an original combination of VRFT and Batch Fitted Q-Learning is employed as a two-step model-free controller tuning procedure for dramatic performance improvement.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neuroimage.2018.08.031,Journal,NeuroImage,scopus,2018-12-01,sciencedirect,Phase shift invariant imaging of coherent sources (PSIICOS) from MEG data,https://api.elsevier.com/content/abstract/scopus_id/85054308167,"Increasing evidence suggests that neuronal communication is a defining property of functionally specialized brain networks and that it is implemented through synchronization between population activities of distinct brain areas. The detection of long-range coupling in electroencephalography (EEG) and magnetoencephalography (MEG) data using conventional metrics (such as coherence or phase-locking value) is by definition contaminated by spatial leakage. Methods such as imaginary coherence, phase-lag index or orthogonalized amplitude correlations tackle spatial leakage by ignoring zero-phase interactions. Although useful, these metrics will by construction lead to false negatives in cases where true zero-phase coupling exists in the data and will underestimate interactions with phase lags in the vicinity of zero. Yet, empirically observed neuronal synchrony in invasive recordings indicates that it is not uncommon to find zero or close-to-zero phase lag between the activity profiles of coupled neuronal assemblies.
                  Here, we introduce a novel method that allows us to mitigate the undesired spatial leakage effects and detect zero and near zero phase interactions. To this end, we propose a projection operation that operates on sensor-space cross-spectrum and suppresses the spatial leakage contribution but retains the true zero-phase interaction component. We then solve the network estimation task as a source estimation problem defined in the product space of interacting source topographies. We show how this framework provides reliable interaction detection for all phase-lag values and we thus refer to the method as Phase Shift Invariant Imaging of Coherent Sources (PSIICOS).
                  Realistic simulations demonstrate that PSIICOS has better detector characteristics than existing interaction metrics. Finally, we illustrate the performance of PSIICOS by applying it to real MEG dataset recorded during a standard mental rotation task. Taken together, using analytical derivations, data simulations and real brain data, this study presents a novel source-space MEG/EEG connectivity method that overcomes previous limitations and for the first time allows for the estimation of true zero-phase coupling via non-invasive electrophysiological recordings.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2018.07.013,Journal,Future Generation Computer Systems,scopus,2018-12-01,sciencedirect,Using behavioral features in tablet-based auditory emotion recognition studies,https://api.elsevier.com/content/abstract/scopus_id/85050510126,"The recognition of emotions in spoken words is one of the most important aspects in human communication and social relationships. Traditional approaches to the study of vocal emotional recognition involve instructing listeners to choose which one of several words describing emotion categories best characterize linguistically neutral utterances or vocalizations uttered by actors portraying various emotional states. To this end, generic experiment control software is usually used, which has some disadvantages. In this paper, we present a system that digitalizes the whole process involved in understanding how people perceive and understand vocal emotions, improving data collection, processing and analysis. Moreover, this system provides a new group of features that allows a more comprehensive characterization of the behavioral dimension underlying vocal emotional recognition. In this paper we describe this system and analyze the relationship between emotional perception, gender, age and Human–Computer Interaction.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.07.044,Journal,Neurocomputing,scopus,2018-11-13,sciencedirect,Detection of spam-posting accounts on Twitter,https://api.elsevier.com/content/abstract/scopus_id/85052064942,"Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs. non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.06.045,Journal,Neurocomputing,scopus,2018-11-03,sciencedirect,Adaptive Neighborhood MinMax Projections,https://api.elsevier.com/content/abstract/scopus_id/85049433041,"Dimensionality reduction as one of most attractive topics in machine learning research area has aroused extensive attentions in recent years. In order to preserve the local structure of data, most of dimensionality reduction methods consider constructing the relationships among each sample and its k nearest neighbors, and they find the neighbors in original space by using Euclidean distance. Since the data in original space contain some noises and redundant features, finding the neighbors in original space is incorrect and may degrade the subsequent performance. Therefore, how to find the optimal k nearest neighbors for each sample is the key point to improve the robustness of model. In this paper, we propose a novel dimensionality reduction method, named Adaptive Neighborhood MinMax Projections (ANMMP) which finds the neighbors in the optimal subspace by solving Trace Ratio problem in which the noises and redundant features have been removed already. Meanwhile, the samples within same class are pulled together while the samples between different classes are pushed far away in such learned subspace. Besides, proposed model is a general approach which can be implemented easily and applied on other methods to improve the robustness. Extensive experiments conducted on several synthetic data and real-world data sets and achieve some encouraging performance with comparison to metric learning and feature extraction methods, which demonstrates the efficiency of our method.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2018.e00972,Journal,Heliyon,scopus,2018-11-01,sciencedirect,Modeling the output power of heterogeneous photovoltaic panels based on artificial neural networks using low cost microcontrollers,https://api.elsevier.com/content/abstract/scopus_id/85057181952,"Many implementations of artificial neural networks have been reported in scientific papers. However, few of these implementations allow the direct use of off-line trained networks. Moreover, no implementation reported the use of relatively small network adequate to run on low cost microcontroller. Hence, this work, which presents a small artificial neural network, which models the output power of heterogeneous photovoltaic panel. In addition, the work discuss the hardware implementation that allows such network to run on low cost microcontroller. The hardware implementation has the ability to model heterogeneous photovoltaic panel's output power with very high accuracy and fast response time. Feedforward back propagation has been used because of its high resolution and accurate activation function. Real-time measured parameters can be used as inputs for the developed system. The resulting hardware data is tested with data from real photovoltaic panels; to confirm that it can efficiently implement the models prepared off-line with Matlab. The comparison revealed the robustness of the proposed heterogeneous photovoltaic model system at different conditions. The proposed heterogeneous photovoltaic model system offer a proper and efficient tool that can be used in monitoring photovoltaic panels, such as the ones used in smart-house applications.",science,'science' AND 'machine learning' AND ('real-world' AND 'deploy')
